Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Iter:99, L1 loss=0.05724, Total loss=0.07876, Time:14
Iter:199, L1 loss=0.0344, Total loss=0.04979, Time:13
Iter:299, L1 loss=0.02211, Total loss=0.03344, Time:13
Iter:399, L1 loss=0.01344, Total loss=0.02137, Time:8
Iter:499, L1 loss=0.008442, Total loss=0.01517, Time:13
Iter:599, L1 loss=0.006814, Total loss=0.0118, Time:9
Iter:699, L1 loss=0.005665, Total loss=0.009678, Time:9
Iter:799, L1 loss=0.005006, Total loss=0.008088, Time:13
Iter:899, L1 loss=0.003726, Total loss=0.005711, Time:13
Iter:999, L1 loss=0.00447, Total loss=0.006746, Time:12
Iter:1099, L1 loss=0.003391, Total loss=0.005109, Time:11
Iter:1199, L1 loss=0.003447, Total loss=0.004956, Time:13
Iter:1299, L1 loss=0.002725, Total loss=0.003588, Time:11
Iter:1399, L1 loss=0.002296, Total loss=0.002899, Time:13
Iter:1499, L1 loss=0.002552, Total loss=0.003298, Time:14
Iter:1599, L1 loss=0.002679, Total loss=0.003367, Time:11
Iter:1699, L1 loss=0.002572, Total loss=0.003219, Time:11
Iter:1799, L1 loss=0.001685, Total loss=0.001878, Time:15
Iter:1899, L1 loss=0.001719, Total loss=0.001961, Time:15
Iter:1999, L1 loss=0.001495, Total loss=0.001825, Time:14
Testing Speed: 232.60337178349602 fps
Testing Time: 0.21495819091796875 s

[ITER 2000] Evaluating test: SSIM = 0.8523035597801208, PSNR = 17.89594018936157
Testing Speed: 264.4691243852201 fps
Testing Time: 0.01134347915649414 s

[ITER 2000] Evaluating train: SSIM = 0.9999495546023051, PSNR = 48.407441457112625
Iter:2000, total_points:42307
Iter:2099, L1 loss=0.001586, Total loss=0.00167, Time:13
Iter:2199, L1 loss=0.001425, Total loss=0.001538, Time:15
Iter:2299, L1 loss=0.001361, Total loss=0.001513, Time:16
Iter:2399, L1 loss=0.00122, Total loss=0.001268, Time:13
Iter:2499, L1 loss=0.001178, Total loss=0.001229, Time:16
Iter:2599, L1 loss=0.001003, Total loss=0.00103, Time:15
Iter:2699, L1 loss=0.001149, Total loss=0.001179, Time:14
Iter:2799, L1 loss=0.001243, Total loss=0.001256, Time:16
Iter:2899, L1 loss=0.0008724, Total loss=0.0008436, Time:16
Iter:2999, L1 loss=0.0007018, Total loss=0.0006691, Time:17
Iter:3099, L1 loss=0.0008893, Total loss=0.0008751, Time:15
Iter:3199, L1 loss=0.0007627, Total loss=0.0007432, Time:15
Iter:3299, L1 loss=0.001269, Total loss=0.001258, Time:18
Iter:3399, L1 loss=0.00118, Total loss=0.001247, Time:18
Iter:3499, L1 loss=0.0006467, Total loss=0.00062, Time:19
Iter:3599, L1 loss=0.0006355, Total loss=0.0005817, Time:19
Iter:3699, L1 loss=0.001023, Total loss=0.000943, Time:18
Iter:3799, L1 loss=0.0007808, Total loss=0.0007401, Time:19
Iter:3899, L1 loss=0.0007424, Total loss=0.0006813, Time:20
Iter:3999, L1 loss=0.0008476, Total loss=0.0007745, Time:20
Iter:4099, L1 loss=0.000955, Total loss=0.0009384, Time:25
Iter:4199, L1 loss=0.0007765, Total loss=0.0007352, Time:22
Iter:4299, L1 loss=0.0008438, Total loss=0.0007938, Time:26
Iter:4399, L1 loss=0.0005786, Total loss=0.0005268, Time:26
Iter:4499, L1 loss=0.0007967, Total loss=0.0007482, Time:26
Iter:4599, L1 loss=0.0006712, Total loss=0.0006169, Time:26
Iter:4699, L1 loss=0.000607, Total loss=0.0005596, Time:25
Iter:4799, L1 loss=0.0005986, Total loss=0.0005477, Time:26
Iter:4899, L1 loss=0.000659, Total loss=0.0005755, Time:25
Iter:4999, L1 loss=0.0005059, Total loss=0.0004477, Time:27
Iter:5099, L1 loss=0.0005907, Total loss=0.0005129, Time:27
Iter:5199, L1 loss=0.0005408, Total loss=0.0004812, Time:27
Iter:5299, L1 loss=0.0006348, Total loss=0.0005375, Time:27
Iter:5399, L1 loss=0.0005166, Total loss=0.000426, Time:28
Iter:5499, L1 loss=0.0005198, Total loss=0.0004835, Time:28
Iter:5599, L1 loss=0.0004713, Total loss=0.0004164, Time:27
Iter:5699, L1 loss=0.0004889, Total loss=0.0004444, Time:27
Iter:5799, L1 loss=0.0004453, Total loss=0.000397, Time:28
Iter:5899, L1 loss=0.0004812, Total loss=0.0004241, Time:25
Iter:5999, L1 loss=0.0004717, Total loss=0.0004155, Time:25
Iter:6099, L1 loss=0.0004513, Total loss=0.0003996, Time:23
Iter:6199, L1 loss=0.0003857, Total loss=0.0003308, Time:24
Iter:6299, L1 loss=0.0005063, Total loss=0.0004601, Time:25
Iter:6399, L1 loss=0.0004382, Total loss=0.0003889, Time:25
Iter:6499, L1 loss=0.0005152, Total loss=0.0004645, Time:24
Iter:6599, L1 loss=0.0004187, Total loss=0.0003702, Time:24
Iter:6699, L1 loss=0.0004783, Total loss=0.0004212, Time:25
Iter:6799, L1 loss=0.0003596, Total loss=0.0003069, Time:26
Iter:6899, L1 loss=0.0004742, Total loss=0.0004197, Time:25
Iter:6999, L1 loss=0.0004685, Total loss=0.0004293, Time:24
Iter:7099, L1 loss=0.0004339, Total loss=0.0003744, Time:29
Iter:7199, L1 loss=0.000374, Total loss=0.0003278, Time:29
Iter:7299, L1 loss=0.0004398, Total loss=0.0003914, Time:26
Iter:7399, L1 loss=0.0005606, Total loss=0.0004383, Time:29
Iter:7499, L1 loss=0.0003999, Total loss=0.0003504, Time:29
Iter:7599, L1 loss=0.0003626, Total loss=0.0003137, Time:30
Iter:7699, L1 loss=0.000337, Total loss=0.0002931, Time:25
Iter:7799, L1 loss=0.0003467, Total loss=0.0003055, Time:26
Iter:7899, L1 loss=0.0004065, Total loss=0.0003607, Time:25
Iter:7999, L1 loss=0.0003744, Total loss=0.0003238, Time:28
Iter:8099, L1 loss=0.0005297, Total loss=0.0004776, Time:32
Iter:8199, L1 loss=0.000487, Total loss=0.0004319, Time:31
Iter:8299, L1 loss=0.0003785, Total loss=0.0003302, Time:30
Iter:8399, L1 loss=0.0003566, Total loss=0.0003064, Time:33
Iter:8499, L1 loss=0.000439, Total loss=0.0003848, Time:31
Iter:8599, L1 loss=0.0003104, Total loss=0.0002635, Time:30
Iter:8699, L1 loss=0.0003606, Total loss=0.0003182, Time:32
Iter:8799, L1 loss=0.0004147, Total loss=0.0003635, Time:31
Iter:8899, L1 loss=0.0003271, Total loss=0.0002886, Time:30
Iter:8999, L1 loss=0.0003149, Total loss=0.0002709, Time:28
Iter:9099, L1 loss=0.0004465, Total loss=0.0003815, Time:31
Iter:9199, L1 loss=0.0003206, Total loss=0.0002911, Time:31
Iter:9299, L1 loss=0.0003016, Total loss=0.0002498, Time:28
Iter:9399, L1 loss=0.0004391, Total loss=0.0003671, Time:31
Iter:9499, L1 loss=0.0003331, Total loss=0.0002792, Time:30
Iter:9599, L1 loss=0.0003941, Total loss=0.0003497, Time:30
Iter:9699, L1 loss=0.0004889, Total loss=0.000414, Time:27
Iter:9799, L1 loss=0.0003028, Total loss=0.0002585, Time:31
Iter:9899, L1 loss=0.0004588, Total loss=0.0003546, Time:30
Iter:9999, L1 loss=0.0004926, Total loss=0.0004419, Time:31
Iter:10099, L1 loss=0.0002988, Total loss=0.0002563, Time:30
Iter:10199, L1 loss=0.0003408, Total loss=0.0002862, Time:31
Iter:10299, L1 loss=0.0002803, Total loss=0.0002477, Time:31
Iter:10399, L1 loss=0.0002891, Total loss=0.0002442, Time:31
Iter:10499, L1 loss=0.000288, Total loss=0.0002404, Time:28
Iter:10599, L1 loss=0.0002687, Total loss=0.000233, Time:30
Iter:10699, L1 loss=0.0003083, Total loss=0.0002678, Time:30
Iter:10799, L1 loss=0.0002668, Total loss=0.000231, Time:27
Iter:10899, L1 loss=0.0003279, Total loss=0.0002914, Time:31
Iter:10999, L1 loss=0.0002984, Total loss=0.0002487, Time:30
Iter:11099, L1 loss=0.0002956, Total loss=0.000249, Time:31
Iter:11199, L1 loss=0.0002896, Total loss=0.0002436, Time:32
Iter:11299, L1 loss=0.0002445, Total loss=0.0002143, Time:26
Iter:11399, L1 loss=0.0003176, Total loss=0.0002663, Time:30
Iter:11499, L1 loss=0.000385, Total loss=0.0003163, Time:29
Iter:11599, L1 loss=0.000273, Total loss=0.0002251, Time:30
Iter:11699, L1 loss=0.0002393, Total loss=0.0002088, Time:27
Iter:11799, L1 loss=0.000269, Total loss=0.0002254, Time:26
Iter:11899, L1 loss=0.0002931, Total loss=0.0002349, Time:31
Iter:11999, L1 loss=0.000243, Total loss=0.0002085, Time:30
Iter:12099, L1 loss=0.0005629, Total loss=0.0004567, Time:29
Iter:12199, L1 loss=0.000337, Total loss=0.000299, Time:32
Iter:12299, L1 loss=0.0003609, Total loss=0.0003142, Time:32
Iter:12399, L1 loss=0.0002521, Total loss=0.0002191, Time:31
Iter:12499, L1 loss=0.0003061, Total loss=0.0002393, Time:29
Iter:12599, L1 loss=0.0003578, Total loss=0.0003086, Time:32
Iter:12699, L1 loss=0.0002996, Total loss=0.0002664, Time:33
Iter:12799, L1 loss=0.000275, Total loss=0.0002156, Time:33
Iter:12899, L1 loss=0.0002581, Total loss=0.000206, Time:33
Iter:12999, L1 loss=0.000228, Total loss=0.0002017, Time:33
Iter:13099, L1 loss=0.0002748, Total loss=0.0002217, Time:33
Iter:13199, L1 loss=0.0002671, Total loss=0.0002291, Time:33
Iter:13299, L1 loss=0.000227, Total loss=0.0001865, Time:29
Iter:13399, L1 loss=0.000228, Total loss=0.0001908, Time:33
Iter:13499, L1 loss=0.0002637, Total loss=0.000222, Time:32
Iter:13599, L1 loss=0.0002417, Total loss=0.0002005, Time:31
Iter:13699, L1 loss=0.0002844, Total loss=0.0002404, Time:28
Iter:13799, L1 loss=0.0002688, Total loss=0.0002288, Time:31
Iter:13899, L1 loss=0.000293, Total loss=0.0002526, Time:32
Iter:13999, L1 loss=0.0002232, Total loss=0.0001879, Time:31
Iter:14099, L1 loss=0.000254, Total loss=0.0002058, Time:28
Iter:14199, L1 loss=0.0002246, Total loss=0.000194, Time:31
Iter:14299, L1 loss=0.000231, Total loss=0.0001917, Time:31
Iter:14399, L1 loss=0.0002118, Total loss=0.0001747, Time:28
Iter:14499, L1 loss=0.0002318, Total loss=0.0002032, Time:31
Iter:14599, L1 loss=0.00026, Total loss=0.000217, Time:31
Iter:14699, L1 loss=0.0002375, Total loss=0.0002036, Time:30
Iter:14799, L1 loss=0.0003409, Total loss=0.0002763, Time:27
Iter:14899, L1 loss=0.0002126, Total loss=0.0001797, Time:31
Iter:14999, L1 loss=0.000319, Total loss=0.0002575, Time:31
Iter:15099, L1 loss=0.0001921, Total loss=0.000165, Time:29
Iter:15199, L1 loss=0.0002116, Total loss=0.0001759, Time:29
Iter:15299, L1 loss=0.000229, Total loss=0.0002036, Time:33
Iter:15399, L1 loss=0.0001839, Total loss=0.0001618, Time:32
Iter:15499, L1 loss=0.0002376, Total loss=0.0001883, Time:30
Iter:15599, L1 loss=0.0002028, Total loss=0.0001715, Time:30
Iter:15699, L1 loss=0.0002148, Total loss=0.0001744, Time:31
Iter:15799, L1 loss=0.0001905, Total loss=0.0001572, Time:28
Iter:15899, L1 loss=0.0001778, Total loss=0.000149, Time:26
Iter:15999, L1 loss=0.0002109, Total loss=0.0001738, Time:27
Iter:16099, L1 loss=0.0003108, Total loss=0.0002674, Time:28
Iter:16199, L1 loss=0.0002941, Total loss=0.0002509, Time:28
Iter:16299, L1 loss=0.000316, Total loss=0.0002486, Time:32
Iter:16399, L1 loss=0.0002187, Total loss=0.0001815, Time:31
Iter:16499, L1 loss=0.0002516, Total loss=0.0002389, Time:32
Iter:16599, L1 loss=0.0002315, Total loss=0.0001875, Time:28
Iter:16699, L1 loss=0.0002251, Total loss=0.0001938, Time:31
Iter:16799, L1 loss=0.0002606, Total loss=0.0002125, Time:27
Iter:16899, L1 loss=0.0002623, Total loss=0.0002115, Time:32
Iter:16999, L1 loss=0.0002153, Total loss=0.0001864, Time:28
Iter:17099, L1 loss=0.0002045, Total loss=0.000161, Time:33
Iter:17199, L1 loss=0.0001946, Total loss=0.0001674, Time:31
Iter:17299, L1 loss=0.0002156, Total loss=0.0001791, Time:31
Iter:17399, L1 loss=0.0002059, Total loss=0.0001654, Time:32
Iter:17499, L1 loss=0.0001963, Total loss=0.0001686, Time:31
Iter:17599, L1 loss=0.0002088, Total loss=0.000181, Time:31
Iter:17699, L1 loss=0.0001843, Total loss=0.0001522, Time:28
Iter:17799, L1 loss=0.0003292, Total loss=0.0002682, Time:33
Iter:17899, L1 loss=0.0001841, Total loss=0.0001594, Time:31
Iter:17999, L1 loss=0.000183, Total loss=0.0001482, Time:28
Iter:18099, L1 loss=0.0002902, Total loss=0.0002518, Time:31
Iter:18199, L1 loss=0.0001956, Total loss=0.0001692, Time:32
Iter:18299, L1 loss=0.0002808, Total loss=0.0002251, Time:32
Iter:18399, L1 loss=0.000193, Total loss=0.0001622, Time:29
Iter:18499, L1 loss=0.0002007, Total loss=0.0001688, Time:27
Iter:18599, L1 loss=0.0002509, Total loss=0.0001885, Time:28
Iter:18699, L1 loss=0.0001812, Total loss=0.0001489, Time:31
Iter:18799, L1 loss=0.0001766, Total loss=0.0001397, Time:31
Iter:18899, L1 loss=0.0001907, Total loss=0.0001682, Time:27
Iter:18999, L1 loss=0.0001702, Total loss=0.0001408, Time:31
Iter:19099, L1 loss=0.0001982, Total loss=0.0001628, Time:31
Iter:19199, L1 loss=0.0002636, Total loss=0.0001944, Time:30
Iter:19299, L1 loss=0.0001783, Total loss=0.000148, Time:30
Iter:19399, L1 loss=0.0001872, Total loss=0.0001552, Time:30
Iter:19499, L1 loss=0.0002107, Total loss=0.000179, Time:27
Iter:19599, L1 loss=0.000198, Total loss=0.0001662, Time:28
Iter:19699, L1 loss=0.0001898, Total loss=0.0001645, Time:30
Iter:19799, L1 loss=0.0001923, Total loss=0.0001608, Time:31
Iter:19899, L1 loss=0.0002077, Total loss=0.0001764, Time:30
Iter:19999, L1 loss=0.0001657, Total loss=0.0001416, Time:30
Testing Speed: 136.2222216448372 fps
Testing Time: 0.3670473098754883 s

[ITER 20000] Evaluating test: SSIM = 0.8506614017486572, PSNR = 18.51963394165039
Testing Speed: 149.42123950552778 fps
Testing Time: 0.02007746696472168 s

[ITER 20000] Evaluating train: SSIM = 0.9999996622403462, PSNR = 69.42729949951172
Iter:20000, total_points:199287

[ITER 20000] Saving Gaussians
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...

Starting training...
Total iterations: 20000
Total iterations: 20000
==================================================
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327880 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327880 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123930 (Best: 0.1098392 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 40/20000] Loss: 0.1123930 (Best: 0.1098392 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993453 (Best: 0.0965435 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 50/20000] Loss: 0.0993453 (Best: 0.0965435 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936766 (Best: 0.0908527 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 60/20000] Loss: 0.0936766 (Best: 0.0908527 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884504 (Best: 0.0869384 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 70/20000] Loss: 0.0884504 (Best: 0.0869384 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851861 (Best: 0.0831026 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 80/20000] Loss: 0.0851861 (Best: 0.0831026 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824127 (Best: 0.0801649 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
[Iter 90/20000] Loss: 0.0824127 (Best: 0.0801649 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07878, Time:14
Iter:99, L1 loss=0.05723, Total loss=0.07878, Time:14
[Iter 100/20000] Loss: 0.0786700 (Best: 0.0766176 @iter97) ([92m↓4.54%[0m) [31.25% of initial]
[Iter 100/20000] Loss: 0.0786700 (Best: 0.0766176 @iter97) ([92m↓4.54%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753264 (Best: 0.0731388 @iter106) ([92m↓4.25%[0m) [29.93% of initial]
[Iter 110/20000] Loss: 0.0753264 (Best: 0.0731388 @iter106) ([92m↓4.25%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714306 (Best: 0.0685537 @iter118) ([92m↓5.17%[0m) [28.38% of initial]
[Iter 120/20000] Loss: 0.0714306 (Best: 0.0685537 @iter118) ([92m↓5.17%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0666951 (Best: 0.0641874 @iter130) ([92m↓6.63%[0m) [26.50% of initial]
[Iter 130/20000] Loss: 0.0666951 (Best: 0.0641874 @iter130) ([92m↓6.63%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635276 (Best: 0.0612695 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 140/20000] Loss: 0.0635276 (Best: 0.0612695 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612530 (Best: 0.0583437 @iter148) ([92m↓3.58%[0m) [24.34% of initial]
[Iter 150/20000] Loss: 0.0612530 (Best: 0.0583437 @iter148) ([92m↓3.58%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590401 (Best: 0.0559317 @iter157) ([92m↓3.61%[0m) [23.46% of initial]
[Iter 160/20000] Loss: 0.0590401 (Best: 0.0559317 @iter157) ([92m↓3.61%[0m) [23.46% of initial]
[Iter 170/20000] Loss: 0.0563388 (Best: 0.0534640 @iter167) ([92m↓4.58%[0m) [22.38% of initial]
[Iter 170/20000] Loss: 0.0563388 (Best: 0.0534640 @iter167) ([92m↓4.58%[0m) [22.38% of initial]
[Iter 180/20000] Loss: 0.0523150 (Best: 0.0500024 @iter179) ([92m↓7.14%[0m) [20.78% of initial]
[Iter 180/20000] Loss: 0.0523150 (Best: 0.0500024 @iter179) ([92m↓7.14%[0m) [20.78% of initial]
[Iter 190/20000] Loss: 0.0495360 (Best: 0.0478174 @iter188) ([92m↓5.31%[0m) [19.68% of initial]
[Iter 190/20000] Loss: 0.0495360 (Best: 0.0478174 @iter188) ([92m↓5.31%[0m) [19.68% of initial]
Iter:199, L1 loss=0.0344, Total loss=0.04975, Time:15
Iter:199, L1 loss=0.0344, Total loss=0.04975, Time:15
[Iter 200/20000] Loss: 0.0477899 (Best: 0.0456806 @iter198) ([92m↓3.52%[0m) [18.99% of initial]
[Iter 200/20000] Loss: 0.0477899 (Best: 0.0456806 @iter198) ([92m↓3.52%[0m) [18.99% of initial]
[Iter 210/20000] Loss: 0.0451126 (Best: 0.0429467 @iter209) ([92m↓5.60%[0m) [17.92% of initial]
[Iter 210/20000] Loss: 0.0451126 (Best: 0.0429467 @iter209) ([92m↓5.60%[0m) [17.92% of initial]
[Iter 220/20000] Loss: 0.0440793 (Best: 0.0411946 @iter219) ([92m↓2.29%[0m) [17.51% of initial]
[Iter 220/20000] Loss: 0.0440793 (Best: 0.0411946 @iter219) ([92m↓2.29%[0m) [17.51% of initial]
[Iter 230/20000] Loss: 0.0423805 (Best: 0.0399105 @iter227) ([92m↓3.85%[0m) [16.84% of initial]
[Iter 230/20000] Loss: 0.0423805 (Best: 0.0399105 @iter227) ([92m↓3.85%[0m) [16.84% of initial]
[Iter 240/20000] Loss: 0.0402768 (Best: 0.0377957 @iter238) ([92m↓4.96%[0m) [16.00% of initial]
[Iter 240/20000] Loss: 0.0402768 (Best: 0.0377957 @iter238) ([92m↓4.96%[0m) [16.00% of initial]
[Iter 250/20000] Loss: 0.0379678 (Best: 0.0362037 @iter248) ([92m↓5.73%[0m) [15.08% of initial]
[Iter 250/20000] Loss: 0.0379678 (Best: 0.0362037 @iter248) ([92m↓5.73%[0m) [15.08% of initial]
[Iter 260/20000] Loss: 0.0358894 (Best: 0.0343046 @iter260) ([92m↓5.47%[0m) [14.26% of initial]
[Iter 260/20000] Loss: 0.0358894 (Best: 0.0343046 @iter260) ([92m↓5.47%[0m) [14.26% of initial]
[Iter 270/20000] Loss: 0.0350643 (Best: 0.0329351 @iter269) ([92m↓2.30%[0m) [13.93% of initial]
[Iter 270/20000] Loss: 0.0350643 (Best: 0.0329351 @iter269) ([92m↓2.30%[0m) [13.93% of initial]
[Iter 280/20000] Loss: 0.0346071 (Best: 0.0318444 @iter277) ([92m↓1.30%[0m) [13.75% of initial]
[Iter 280/20000] Loss: 0.0346071 (Best: 0.0318444 @iter277) ([92m↓1.30%[0m) [13.75% of initial]
[Iter 290/20000] Loss: 0.0330132 (Best: 0.0304691 @iter287) ([92m↓4.61%[0m) [13.12% of initial]
[Iter 290/20000] Loss: 0.0330132 (Best: 0.0304691 @iter287) ([92m↓4.61%[0m) [13.12% of initial]
Iter:299, L1 loss=0.02227, Total loss=0.03323, Time:14
Iter:299, L1 loss=0.02227, Total loss=0.03323, Time:14
[Iter 300/20000] Loss: 0.0307210 (Best: 0.0289390 @iter300) ([92m↓6.94%[0m) [12.21% of initial]
[Iter 300/20000] Loss: 0.0307210 (Best: 0.0289390 @iter300) ([92m↓6.94%[0m) [12.21% of initial]
[Iter 310/20000] Loss: 0.0291664 (Best: 0.0271414 @iter310) ([92m↓5.06%[0m) [11.59% of initial]
[Iter 310/20000] Loss: 0.0291664 (Best: 0.0271414 @iter310) ([92m↓5.06%[0m) [11.59% of initial]
[Iter 320/20000] Loss: 0.0278591 (Best: 0.0263752 @iter320) ([92m↓4.48%[0m) [11.07% of initial]
[Iter 320/20000] Loss: 0.0278591 (Best: 0.0263752 @iter320) ([92m↓4.48%[0m) [11.07% of initial]
[Iter 330/20000] Loss: 0.0274840 (Best: 0.0255639 @iter330) ([92m↓1.35%[0m) [10.92% of initial]
[Iter 330/20000] Loss: 0.0274840 (Best: 0.0255639 @iter330) ([92m↓1.35%[0m) [10.92% of initial]
[Iter 340/20000] Loss: 0.0251910 (Best: 0.0240706 @iter340) ([92m↓8.34%[0m) [10.01% of initial]
[Iter 340/20000] Loss: 0.0251910 (Best: 0.0240706 @iter340) ([92m↓8.34%[0m) [10.01% of initial]
[Iter 350/20000] Loss: 0.0257059 (Best: 0.0233537 @iter349) ([91m↑2.04%[0m) [10.21% of initial]
[Iter 350/20000] Loss: 0.0257059 (Best: 0.0233537 @iter349) ([91m↑2.04%[0m) [10.21% of initial]
[Iter 360/20000] Loss: 0.0243030 (Best: 0.0223619 @iter358) ([92m↓5.46%[0m) [9.66% of initial]
[Iter 360/20000] Loss: 0.0243030 (Best: 0.0223619 @iter358) ([92m↓5.46%[0m) [9.66% of initial]
[Iter 370/20000] Loss: 0.0238550 (Best: 0.0216121 @iter368) ([92m↓1.84%[0m) [9.48% of initial]
[Iter 370/20000] Loss: 0.0238550 (Best: 0.0216121 @iter368) ([92m↓1.84%[0m) [9.48% of initial]
[Iter 380/20000] Loss: 0.0217723 (Best: 0.0206253 @iter379) ([92m↓8.73%[0m) [8.65% of initial]
[Iter 380/20000] Loss: 0.0217723 (Best: 0.0206253 @iter379) ([92m↓8.73%[0m) [8.65% of initial]
[Iter 390/20000] Loss: 0.0212732 (Best: 0.0198484 @iter385) ([92m↓2.29%[0m) [8.45% of initial]
[Iter 390/20000] Loss: 0.0212732 (Best: 0.0198484 @iter385) ([92m↓2.29%[0m) [8.45% of initial]
Iter:399, L1 loss=0.01368, Total loss=0.02116, Time:15
Iter:399, L1 loss=0.01368, Total loss=0.02116, Time:15
[Iter 400/20000] Loss: 0.0203142 (Best: 0.0188691 @iter400) ([92m↓4.51%[0m) [8.07% of initial]
[Iter 400/20000] Loss: 0.0203142 (Best: 0.0188691 @iter400) ([92m↓4.51%[0m) [8.07% of initial]
[Iter 410/20000] Loss: 0.0192205 (Best: 0.0182095 @iter410) ([92m↓5.38%[0m) [7.64% of initial]
[Iter 410/20000] Loss: 0.0192205 (Best: 0.0182095 @iter410) ([92m↓5.38%[0m) [7.64% of initial]
[Iter 420/20000] Loss: 0.0200487 (Best: 0.0179178 @iter413) ([91m↑4.31%[0m) [7.97% of initial]
[Iter 420/20000] Loss: 0.0200487 (Best: 0.0179178 @iter413) ([91m↑4.31%[0m) [7.97% of initial]
[Iter 430/20000] Loss: 0.0178783 (Best: 0.0169955 @iter430) ([92m↓10.83%[0m) [7.10% of initial]
[Iter 430/20000] Loss: 0.0178783 (Best: 0.0169955 @iter430) ([92m↓10.83%[0m) [7.10% of initial]
[Iter 440/20000] Loss: 0.0181216 (Best: 0.0163775 @iter438) ([91m↑1.36%[0m) [7.20% of initial]
[Iter 440/20000] Loss: 0.0181216 (Best: 0.0163775 @iter438) ([91m↑1.36%[0m) [7.20% of initial]
[Iter 450/20000] Loss: 0.0171034 (Best: 0.0152643 @iter449) ([92m↓5.62%[0m) [6.80% of initial]
[Iter 450/20000] Loss: 0.0171034 (Best: 0.0152643 @iter449) ([92m↓5.62%[0m) [6.80% of initial]
[Iter 460/20000] Loss: 0.0163657 (Best: 0.0146089 @iter458) ([92m↓4.31%[0m) [6.50% of initial]
[Iter 460/20000] Loss: 0.0163657 (Best: 0.0146089 @iter458) ([92m↓4.31%[0m) [6.50% of initial]
[Iter 470/20000] Loss: 0.0149304 (Best: 0.0138979 @iter470) ([92m↓8.77%[0m) [5.93% of initial]
[Iter 470/20000] Loss: 0.0149304 (Best: 0.0138979 @iter470) ([92m↓8.77%[0m) [5.93% of initial]
[Iter 480/20000] Loss: 0.0155361 (Best: 0.0134709 @iter475) ([91m↑4.06%[0m) [6.17% of initial]
[Iter 480/20000] Loss: 0.0155361 (Best: 0.0134709 @iter475) ([91m↑4.06%[0m) [6.17% of initial]
[Iter 490/20000] Loss: 0.0138112 (Best: 0.0125381 @iter490) ([92m↓11.10%[0m) [5.49% of initial]
[Iter 490/20000] Loss: 0.0138112 (Best: 0.0125381 @iter490) ([92m↓11.10%[0m) [5.49% of initial]
Iter:499, L1 loss=0.008315, Total loss=0.01456, Time:13
Iter:499, L1 loss=0.008315, Total loss=0.01456, Time:13
[Iter 500/20000] Loss: 0.0138060 (Best: 0.0124244 @iter493) ([92m↓0.04%[0m) [5.48% of initial]
[Iter 500/20000] Loss: 0.0138060 (Best: 0.0124244 @iter493) ([92m↓0.04%[0m) [5.48% of initial]
[Iter 510/20000] Loss: 0.0134649 (Best: 0.0120804 @iter507) ([92m↓2.47%[0m) [5.35% of initial]
[Iter 510/20000] Loss: 0.0134649 (Best: 0.0120804 @iter507) ([92m↓2.47%[0m) [5.35% of initial]
[Iter 520/20000] Loss: 0.0128722 (Best: 0.0115923 @iter514) ([92m↓4.40%[0m) [5.11% of initial]
[Iter 520/20000] Loss: 0.0128722 (Best: 0.0115923 @iter514) ([92m↓4.40%[0m) [5.11% of initial]
[Iter 530/20000] Loss: 0.0129946 (Best: 0.0115923 @iter514) ([91m↑0.95%[0m) [5.16% of initial]
[Iter 530/20000] Loss: 0.0129946 (Best: 0.0115923 @iter514) ([91m↑0.95%[0m) [5.16% of initial]
[Iter 540/20000] Loss: 0.0126180 (Best: 0.0112063 @iter538) ([92m↓2.90%[0m) [5.01% of initial]
[Iter 540/20000] Loss: 0.0126180 (Best: 0.0112063 @iter538) ([92m↓2.90%[0m) [5.01% of initial]
[Iter 550/20000] Loss: 0.0120649 (Best: 0.0108897 @iter548) ([92m↓4.38%[0m) [4.79% of initial]
[Iter 550/20000] Loss: 0.0120649 (Best: 0.0108897 @iter548) ([92m↓4.38%[0m) [4.79% of initial]
[Iter 560/20000] Loss: 0.0127218 (Best: 0.0108897 @iter548) ([91m↑5.44%[0m) [5.05% of initial]
[Iter 560/20000] Loss: 0.0127218 (Best: 0.0108897 @iter548) ([91m↑5.44%[0m) [5.05% of initial]
[Iter 570/20000] Loss: 0.0119315 (Best: 0.0105568 @iter569) ([92m↓6.21%[0m) [4.74% of initial]
[Iter 570/20000] Loss: 0.0119315 (Best: 0.0105568 @iter569) ([92m↓6.21%[0m) [4.74% of initial]
[Iter 580/20000] Loss: 0.0117174 (Best: 0.0103750 @iter572) ([92m↓1.79%[0m) [4.66% of initial]
[Iter 580/20000] Loss: 0.0117174 (Best: 0.0103750 @iter572) ([92m↓1.79%[0m) [4.66% of initial]
[Iter 590/20000] Loss: 0.0116257 (Best: 0.0103601 @iter583) ([92m↓0.78%[0m) [4.62% of initial]
[Iter 590/20000] Loss: 0.0116257 (Best: 0.0103601 @iter583) ([92m↓0.78%[0m) [4.62% of initial]
Iter:599, L1 loss=0.006954, Total loss=0.01233, Time:11
Iter:599, L1 loss=0.006954, Total loss=0.01233, Time:11
[Iter 600/20000] Loss: 0.0113687 (Best: 0.0101016 @iter598) ([92m↓2.21%[0m) [4.52% of initial]
[Iter 600/20000] Loss: 0.0113687 (Best: 0.0101016 @iter598) ([92m↓2.21%[0m) [4.52% of initial]
[Iter 610/20000] Loss: 0.0218150 (Best: 0.0101016 @iter598) ([91m↑91.89%[0m) [8.67% of initial]
[Iter 610/20000] Loss: 0.0218150 (Best: 0.0101016 @iter598) ([91m↑91.89%[0m) [8.67% of initial]
[Iter 620/20000] Loss: 0.0147221 (Best: 0.0101016 @iter598) ([92m↓32.51%[0m) [5.85% of initial]
[Iter 620/20000] Loss: 0.0147221 (Best: 0.0101016 @iter598) ([92m↓32.51%[0m) [5.85% of initial]
[Iter 630/20000] Loss: 0.0124683 (Best: 0.0101016 @iter598) ([92m↓15.31%[0m) [4.95% of initial]
[Iter 630/20000] Loss: 0.0124683 (Best: 0.0101016 @iter598) ([92m↓15.31%[0m) [4.95% of initial]
[Iter 640/20000] Loss: 0.0106826 (Best: 0.0097433 @iter640) ([92m↓14.32%[0m) [4.24% of initial]
[Iter 640/20000] Loss: 0.0106826 (Best: 0.0097433 @iter640) ([92m↓14.32%[0m) [4.24% of initial]
[Iter 650/20000] Loss: 0.0108664 (Best: 0.0094847 @iter646) ([91m↑1.72%[0m) [4.32% of initial]
[Iter 650/20000] Loss: 0.0108664 (Best: 0.0094847 @iter646) ([91m↑1.72%[0m) [4.32% of initial]
[Iter 660/20000] Loss: 0.0104396 (Best: 0.0090039 @iter655) ([92m↓3.93%[0m) [4.15% of initial]
[Iter 660/20000] Loss: 0.0104396 (Best: 0.0090039 @iter655) ([92m↓3.93%[0m) [4.15% of initial]
[Iter 670/20000] Loss: 0.0096440 (Best: 0.0086746 @iter667) ([92m↓7.62%[0m) [3.83% of initial]
[Iter 670/20000] Loss: 0.0096440 (Best: 0.0086746 @iter667) ([92m↓7.62%[0m) [3.83% of initial]
[Iter 680/20000] Loss: 0.0092896 (Best: 0.0085333 @iter680) ([92m↓3.67%[0m) [3.69% of initial]
[Iter 680/20000] Loss: 0.0092896 (Best: 0.0085333 @iter680) ([92m↓3.67%[0m) [3.69% of initial]
[Iter 690/20000] Loss: 0.0093479 (Best: 0.0080952 @iter682) ([91m↑0.63%[0m) [3.71% of initial]
[Iter 690/20000] Loss: 0.0093479 (Best: 0.0080952 @iter682) ([91m↑0.63%[0m) [3.71% of initial]
Iter:699, L1 loss=0.005645, Total loss=0.009931, Time:13
Iter:699, L1 loss=0.005645, Total loss=0.009931, Time:13
[Iter 700/20000] Loss: 0.0090446 (Best: 0.0080371 @iter695) ([92m↓3.25%[0m) [3.59% of initial]
[Iter 700/20000] Loss: 0.0090446 (Best: 0.0080371 @iter695) ([92m↓3.25%[0m) [3.59% of initial]
[Iter 710/20000] Loss: 0.0084209 (Best: 0.0078206 @iter710) ([92m↓6.90%[0m) [3.35% of initial]
[Iter 710/20000] Loss: 0.0084209 (Best: 0.0078206 @iter710) ([92m↓6.90%[0m) [3.35% of initial]
[Iter 720/20000] Loss: 0.0084288 (Best: 0.0076561 @iter715) ([91m↑0.09%[0m) [3.35% of initial]
[Iter 720/20000] Loss: 0.0084288 (Best: 0.0076561 @iter715) ([91m↑0.09%[0m) [3.35% of initial]
[Iter 730/20000] Loss: 0.0085844 (Best: 0.0072767 @iter727) ([91m↑1.85%[0m) [3.41% of initial]
[Iter 730/20000] Loss: 0.0085844 (Best: 0.0072767 @iter727) ([91m↑1.85%[0m) [3.41% of initial]
[Iter 740/20000] Loss: 0.0086158 (Best: 0.0072767 @iter727) ([91m↑0.37%[0m) [3.42% of initial]
[Iter 740/20000] Loss: 0.0086158 (Best: 0.0072767 @iter727) ([91m↑0.37%[0m) [3.42% of initial]
[Iter 750/20000] Loss: 0.0082090 (Best: 0.0070241 @iter748) ([92m↓4.72%[0m) [3.26% of initial]
[Iter 750/20000] Loss: 0.0082090 (Best: 0.0070241 @iter748) ([92m↓4.72%[0m) [3.26% of initial]
[Iter 760/20000] Loss: 0.0074935 (Best: 0.0070044 @iter754) ([92m↓8.72%[0m) [2.98% of initial]
[Iter 760/20000] Loss: 0.0074935 (Best: 0.0070044 @iter754) ([92m↓8.72%[0m) [2.98% of initial]
[Iter 770/20000] Loss: 0.0076322 (Best: 0.0069560 @iter764) ([91m↑1.85%[0m) [3.03% of initial]
[Iter 770/20000] Loss: 0.0076322 (Best: 0.0069560 @iter764) ([91m↑1.85%[0m) [3.03% of initial]
[Iter 780/20000] Loss: 0.0078663 (Best: 0.0067595 @iter778) ([91m↑3.07%[0m) [3.13% of initial]
[Iter 780/20000] Loss: 0.0078663 (Best: 0.0067595 @iter778) ([91m↑3.07%[0m) [3.13% of initial]
[Iter 790/20000] Loss: 0.0075725 (Best: 0.0066825 @iter787) ([92m↓3.74%[0m) [3.01% of initial]
[Iter 790/20000] Loss: 0.0075725 (Best: 0.0066825 @iter787) ([92m↓3.74%[0m) [3.01% of initial]
Iter:799, L1 loss=0.005003, Total loss=0.008577, Time:13
Iter:799, L1 loss=0.005003, Total loss=0.008577, Time:13
[Iter 800/20000] Loss: 0.0077045 (Best: 0.0066825 @iter787) ([91m↑1.74%[0m) [3.06% of initial]
[Iter 800/20000] Loss: 0.0077045 (Best: 0.0066825 @iter787) ([91m↑1.74%[0m) [3.06% of initial]
[Iter 810/20000] Loss: 0.0157766 (Best: 0.0066825 @iter787) ([91m↑104.77%[0m) [6.27% of initial]
[Iter 810/20000] Loss: 0.0157766 (Best: 0.0066825 @iter787) ([91m↑104.77%[0m) [6.27% of initial]
[Iter 820/20000] Loss: 0.0106748 (Best: 0.0066825 @iter787) ([92m↓32.34%[0m) [4.24% of initial]
[Iter 820/20000] Loss: 0.0106748 (Best: 0.0066825 @iter787) ([92m↓32.34%[0m) [4.24% of initial]
[Iter 830/20000] Loss: 0.0089570 (Best: 0.0066825 @iter787) ([92m↓16.09%[0m) [3.56% of initial]
[Iter 830/20000] Loss: 0.0089570 (Best: 0.0066825 @iter787) ([92m↓16.09%[0m) [3.56% of initial]
[Iter 840/20000] Loss: 0.0080939 (Best: 0.0066825 @iter787) ([92m↓9.64%[0m) [3.22% of initial]
[Iter 840/20000] Loss: 0.0080939 (Best: 0.0066825 @iter787) ([92m↓9.64%[0m) [3.22% of initial]
[Iter 850/20000] Loss: 0.0075539 (Best: 0.0066441 @iter847) ([92m↓6.67%[0m) [3.00% of initial]
[Iter 850/20000] Loss: 0.0075539 (Best: 0.0066441 @iter847) ([92m↓6.67%[0m) [3.00% of initial]
[Iter 860/20000] Loss: 0.0070855 (Best: 0.0061816 @iter856) ([92m↓6.20%[0m) [2.81% of initial]
[Iter 860/20000] Loss: 0.0070855 (Best: 0.0061816 @iter856) ([92m↓6.20%[0m) [2.81% of initial]
[Iter 870/20000] Loss: 0.0067098 (Best: 0.0060721 @iter862) ([92m↓5.30%[0m) [2.67% of initial]
[Iter 870/20000] Loss: 0.0067098 (Best: 0.0060721 @iter862) ([92m↓5.30%[0m) [2.67% of initial]
[Iter 880/20000] Loss: 0.0067138 (Best: 0.0060175 @iter872) ([91m↑0.06%[0m) [2.67% of initial]
[Iter 880/20000] Loss: 0.0067138 (Best: 0.0060175 @iter872) ([91m↑0.06%[0m) [2.67% of initial]
[Iter 890/20000] Loss: 0.0063600 (Best: 0.0057006 @iter887) ([92m↓5.27%[0m) [2.53% of initial]
[Iter 890/20000] Loss: 0.0063600 (Best: 0.0057006 @iter887) ([92m↓5.27%[0m) [2.53% of initial]
Iter:899, L1 loss=0.003705, Total loss=0.005563, Time:14
Iter:899, L1 loss=0.003705, Total loss=0.005563, Time:14
[Iter 900/20000] Loss: 0.0064237 (Best: 0.0055635 @iter899) ([91m↑1.00%[0m) [2.55% of initial]
[Iter 900/20000] Loss: 0.0064237 (Best: 0.0055635 @iter899) ([91m↑1.00%[0m) [2.55% of initial]
[Iter 910/20000] Loss: 0.0065461 (Best: 0.0054166 @iter907) ([91m↑1.91%[0m) [2.60% of initial]
[Iter 910/20000] Loss: 0.0065461 (Best: 0.0054166 @iter907) ([91m↑1.91%[0m) [2.60% of initial]
[Iter 920/20000] Loss: 0.0058887 (Best: 0.0052917 @iter916) ([92m↓10.04%[0m) [2.34% of initial]
[Iter 920/20000] Loss: 0.0058887 (Best: 0.0052917 @iter916) ([92m↓10.04%[0m) [2.34% of initial]
[Iter 930/20000] Loss: 0.0061841 (Best: 0.0052397 @iter928) ([91m↑5.02%[0m) [2.46% of initial]
[Iter 930/20000] Loss: 0.0061841 (Best: 0.0052397 @iter928) ([91m↑5.02%[0m) [2.46% of initial]
[Iter 940/20000] Loss: 0.0062588 (Best: 0.0050953 @iter938) ([91m↑1.21%[0m) [2.49% of initial]
[Iter 940/20000] Loss: 0.0062588 (Best: 0.0050953 @iter938) ([91m↑1.21%[0m) [2.49% of initial]
[Iter 950/20000] Loss: 0.0057767 (Best: 0.0050953 @iter938) ([92m↓7.70%[0m) [2.30% of initial]
[Iter 950/20000] Loss: 0.0057767 (Best: 0.0050953 @iter938) ([92m↓7.70%[0m) [2.30% of initial]
[Iter 960/20000] Loss: 0.0059417 (Best: 0.0050953 @iter938) ([91m↑2.86%[0m) [2.36% of initial]
[Iter 960/20000] Loss: 0.0059417 (Best: 0.0050953 @iter938) ([91m↑2.86%[0m) [2.36% of initial]
[Iter 970/20000] Loss: 0.0058643 (Best: 0.0049995 @iter964) ([92m↓1.30%[0m) [2.33% of initial]
[Iter 970/20000] Loss: 0.0058643 (Best: 0.0049995 @iter964) ([92m↓1.30%[0m) [2.33% of initial]
[Iter 980/20000] Loss: 0.0059217 (Best: 0.0049995 @iter964) ([91m↑0.98%[0m) [2.35% of initial]
[Iter 980/20000] Loss: 0.0059217 (Best: 0.0049995 @iter964) ([91m↑0.98%[0m) [2.35% of initial]
[Iter 990/20000] Loss: 0.0059092 (Best: 0.0049785 @iter988) ([92m↓0.21%[0m) [2.35% of initial]
[Iter 990/20000] Loss: 0.0059092 (Best: 0.0049785 @iter988) ([92m↓0.21%[0m) [2.35% of initial]
Iter:999, L1 loss=0.004417, Total loss=0.006591, Time:13
Iter:999, L1 loss=0.004417, Total loss=0.006591, Time:13
[Iter 1000/20000] Loss: 0.0061891 (Best: 0.0049785 @iter988) ([91m↑4.74%[0m) [2.46% of initial]
[Iter 1000/20000] Loss: 0.0061891 (Best: 0.0049785 @iter988) ([91m↑4.74%[0m) [2.46% of initial]
[Iter 1010/20000] Loss: 0.0119219 (Best: 0.0049785 @iter988) ([91m↑92.63%[0m) [4.74% of initial]
[Iter 1010/20000] Loss: 0.0119219 (Best: 0.0049785 @iter988) ([91m↑92.63%[0m) [4.74% of initial]
[Iter 1020/20000] Loss: 0.0084147 (Best: 0.0049785 @iter988) ([92m↓29.42%[0m) [3.34% of initial]
[Iter 1020/20000] Loss: 0.0084147 (Best: 0.0049785 @iter988) ([92m↓29.42%[0m) [3.34% of initial]
[Iter 1030/20000] Loss: 0.0067732 (Best: 0.0049785 @iter988) ([92m↓19.51%[0m) [2.69% of initial]
[Iter 1030/20000] Loss: 0.0067732 (Best: 0.0049785 @iter988) ([92m↓19.51%[0m) [2.69% of initial]
[Iter 1040/20000] Loss: 0.0059919 (Best: 0.0049785 @iter988) ([92m↓11.53%[0m) [2.38% of initial]
[Iter 1040/20000] Loss: 0.0059919 (Best: 0.0049785 @iter988) ([92m↓11.53%[0m) [2.38% of initial]
[Iter 1050/20000] Loss: 0.0058304 (Best: 0.0049785 @iter988) ([92m↓2.70%[0m) [2.32% of initial]
[Iter 1050/20000] Loss: 0.0058304 (Best: 0.0049785 @iter988) ([92m↓2.70%[0m) [2.32% of initial]
[Iter 1060/20000] Loss: 0.0057052 (Best: 0.0048423 @iter1051) ([92m↓2.15%[0m) [2.27% of initial]
[Iter 1060/20000] Loss: 0.0057052 (Best: 0.0048423 @iter1051) ([92m↓2.15%[0m) [2.27% of initial]
[Iter 1070/20000] Loss: 0.0054270 (Best: 0.0044673 @iter1066) ([92m↓4.88%[0m) [2.16% of initial]
[Iter 1070/20000] Loss: 0.0054270 (Best: 0.0044673 @iter1066) ([92m↓4.88%[0m) [2.16% of initial]
[Iter 1080/20000] Loss: 0.0052490 (Best: 0.0044624 @iter1075) ([92m↓3.28%[0m) [2.09% of initial]
[Iter 1080/20000] Loss: 0.0052490 (Best: 0.0044624 @iter1075) ([92m↓3.28%[0m) [2.09% of initial]
[Iter 1090/20000] Loss: 0.0050781 (Best: 0.0044526 @iter1082) ([92m↓3.26%[0m) [2.02% of initial]
[Iter 1090/20000] Loss: 0.0050781 (Best: 0.0044526 @iter1082) ([92m↓3.26%[0m) [2.02% of initial]
Iter:1099, L1 loss=0.003366, Total loss=0.005153, Time:13
Iter:1099, L1 loss=0.003366, Total loss=0.005153, Time:13
[Iter 1100/20000] Loss: 0.0050017 (Best: 0.0042022 @iter1093) ([92m↓1.51%[0m) [1.99% of initial]
[Iter 1100/20000] Loss: 0.0050017 (Best: 0.0042022 @iter1093) ([92m↓1.51%[0m) [1.99% of initial]
[Iter 1110/20000] Loss: 0.0050290 (Best: 0.0042022 @iter1093) ([91m↑0.55%[0m) [2.00% of initial]
[Iter 1110/20000] Loss: 0.0050290 (Best: 0.0042022 @iter1093) ([91m↑0.55%[0m) [2.00% of initial]
[Iter 1120/20000] Loss: 0.0049670 (Best: 0.0041100 @iter1117) ([92m↓1.23%[0m) [1.97% of initial]
[Iter 1120/20000] Loss: 0.0049670 (Best: 0.0041100 @iter1117) ([92m↓1.23%[0m) [1.97% of initial]
[Iter 1130/20000] Loss: 0.0052191 (Best: 0.0041100 @iter1117) ([91m↑5.07%[0m) [2.07% of initial]
[Iter 1130/20000] Loss: 0.0052191 (Best: 0.0041100 @iter1117) ([91m↑5.07%[0m) [2.07% of initial]
[Iter 1140/20000] Loss: 0.0048011 (Best: 0.0040585 @iter1135) ([92m↓8.01%[0m) [1.91% of initial]
[Iter 1140/20000] Loss: 0.0048011 (Best: 0.0040585 @iter1135) ([92m↓8.01%[0m) [1.91% of initial]
[Iter 1150/20000] Loss: 0.0044463 (Best: 0.0039652 @iter1145) ([92m↓7.39%[0m) [1.77% of initial]
[Iter 1150/20000] Loss: 0.0044463 (Best: 0.0039652 @iter1145) ([92m↓7.39%[0m) [1.77% of initial]
[Iter 1160/20000] Loss: 0.0049878 (Best: 0.0039652 @iter1145) ([91m↑12.18%[0m) [1.98% of initial]
[Iter 1160/20000] Loss: 0.0049878 (Best: 0.0039652 @iter1145) ([91m↑12.18%[0m) [1.98% of initial]
[Iter 1170/20000] Loss: 0.0046104 (Best: 0.0039652 @iter1145) ([92m↓7.57%[0m) [1.83% of initial]
[Iter 1170/20000] Loss: 0.0046104 (Best: 0.0039652 @iter1145) ([92m↓7.57%[0m) [1.83% of initial]
[Iter 1180/20000] Loss: 0.0042875 (Best: 0.0039009 @iter1180) ([92m↓7.01%[0m) [1.70% of initial]
[Iter 1180/20000] Loss: 0.0042875 (Best: 0.0039009 @iter1180) ([92m↓7.01%[0m) [1.70% of initial]
[Iter 1190/20000] Loss: 0.0045635 (Best: 0.0038843 @iter1186) ([91m↑6.44%[0m) [1.81% of initial]
[Iter 1190/20000] Loss: 0.0045635 (Best: 0.0038843 @iter1186) ([91m↑6.44%[0m) [1.81% of initial]
Iter:1199, L1 loss=0.003426, Total loss=0.004866, Time:10
Iter:1199, L1 loss=0.003426, Total loss=0.004866, Time:10
[Iter 1200/20000] Loss: 0.0045477 (Best: 0.0037491 @iter1195) ([92m↓0.35%[0m) [1.81% of initial]
[Iter 1200/20000] Loss: 0.0045477 (Best: 0.0037491 @iter1195) ([92m↓0.35%[0m) [1.81% of initial]
[Iter 1210/20000] Loss: 0.0109541 (Best: 0.0037491 @iter1195) ([91m↑140.87%[0m) [4.35% of initial]
[Iter 1210/20000] Loss: 0.0109541 (Best: 0.0037491 @iter1195) ([91m↑140.87%[0m) [4.35% of initial]
[Iter 1220/20000] Loss: 0.0070703 (Best: 0.0037491 @iter1195) ([92m↓35.46%[0m) [2.81% of initial]
[Iter 1220/20000] Loss: 0.0070703 (Best: 0.0037491 @iter1195) ([92m↓35.46%[0m) [2.81% of initial]
[Iter 1230/20000] Loss: 0.0059922 (Best: 0.0037491 @iter1195) ([92m↓15.25%[0m) [2.38% of initial]
[Iter 1230/20000] Loss: 0.0059922 (Best: 0.0037491 @iter1195) ([92m↓15.25%[0m) [2.38% of initial]
[Iter 1240/20000] Loss: 0.0054752 (Best: 0.0037491 @iter1195) ([92m↓8.63%[0m) [2.18% of initial]
[Iter 1240/20000] Loss: 0.0054752 (Best: 0.0037491 @iter1195) ([92m↓8.63%[0m) [2.18% of initial]
[Iter 1250/20000] Loss: 0.0048716 (Best: 0.0037491 @iter1195) ([92m↓11.02%[0m) [1.94% of initial]
[Iter 1250/20000] Loss: 0.0048716 (Best: 0.0037491 @iter1195) ([92m↓11.02%[0m) [1.94% of initial]
[Iter 1260/20000] Loss: 0.0045982 (Best: 0.0037491 @iter1195) ([92m↓5.61%[0m) [1.83% of initial]
[Iter 1260/20000] Loss: 0.0045982 (Best: 0.0037491 @iter1195) ([92m↓5.61%[0m) [1.83% of initial]
[Iter 1270/20000] Loss: 0.0041154 (Best: 0.0037491 @iter1195) ([92m↓10.50%[0m) [1.64% of initial]
[Iter 1270/20000] Loss: 0.0041154 (Best: 0.0037491 @iter1195) ([92m↓10.50%[0m) [1.64% of initial]
[Iter 1280/20000] Loss: 0.0043320 (Best: 0.0034406 @iter1273) ([91m↑5.26%[0m) [1.72% of initial]
[Iter 1280/20000] Loss: 0.0043320 (Best: 0.0034406 @iter1273) ([91m↑5.26%[0m) [1.72% of initial]
[Iter 1290/20000] Loss: 0.0043017 (Best: 0.0034406 @iter1273) ([92m↓0.70%[0m) [1.71% of initial]
[Iter 1290/20000] Loss: 0.0043017 (Best: 0.0034406 @iter1273) ([92m↓0.70%[0m) [1.71% of initial]
Iter:1299, L1 loss=0.002798, Total loss=0.00382, Time:13
Iter:1299, L1 loss=0.002798, Total loss=0.00382, Time:13
[Iter 1300/20000] Loss: 0.0040387 (Best: 0.0034406 @iter1273) ([92m↓6.11%[0m) [1.60% of initial]
[Iter 1300/20000] Loss: 0.0040387 (Best: 0.0034406 @iter1273) ([92m↓6.11%[0m) [1.60% of initial]
[Iter 1310/20000] Loss: 0.0040355 (Best: 0.0034337 @iter1301) ([92m↓0.08%[0m) [1.60% of initial]
[Iter 1310/20000] Loss: 0.0040355 (Best: 0.0034337 @iter1301) ([92m↓0.08%[0m) [1.60% of initial]
[Iter 1320/20000] Loss: 0.0039112 (Best: 0.0031813 @iter1319) ([92m↓3.08%[0m) [1.55% of initial]
[Iter 1320/20000] Loss: 0.0039112 (Best: 0.0031813 @iter1319) ([92m↓3.08%[0m) [1.55% of initial]
[Iter 1330/20000] Loss: 0.0039328 (Best: 0.0031390 @iter1321) ([91m↑0.55%[0m) [1.56% of initial]
[Iter 1330/20000] Loss: 0.0039328 (Best: 0.0031390 @iter1321) ([91m↑0.55%[0m) [1.56% of initial]
[Iter 1340/20000] Loss: 0.0037215 (Best: 0.0031390 @iter1321) ([92m↓5.37%[0m) [1.48% of initial]
[Iter 1340/20000] Loss: 0.0037215 (Best: 0.0031390 @iter1321) ([92m↓5.37%[0m) [1.48% of initial]
[Iter 1350/20000] Loss: 0.0037146 (Best: 0.0031390 @iter1321) ([92m↓0.19%[0m) [1.48% of initial]
[Iter 1350/20000] Loss: 0.0037146 (Best: 0.0031390 @iter1321) ([92m↓0.19%[0m) [1.48% of initial]
[Iter 1360/20000] Loss: 0.0038512 (Best: 0.0031390 @iter1321) ([91m↑3.68%[0m) [1.53% of initial]
[Iter 1360/20000] Loss: 0.0038512 (Best: 0.0031390 @iter1321) ([91m↑3.68%[0m) [1.53% of initial]
[Iter 1370/20000] Loss: 0.0036475 (Best: 0.0031390 @iter1321) ([92m↓5.29%[0m) [1.45% of initial]
[Iter 1370/20000] Loss: 0.0036475 (Best: 0.0031390 @iter1321) ([92m↓5.29%[0m) [1.45% of initial]
[Iter 1380/20000] Loss: 0.0039128 (Best: 0.0031082 @iter1375) ([91m↑7.27%[0m) [1.55% of initial]
[Iter 1380/20000] Loss: 0.0039128 (Best: 0.0031082 @iter1375) ([91m↑7.27%[0m) [1.55% of initial]
[Iter 1390/20000] Loss: 0.0037640 (Best: 0.0031082 @iter1375) ([92m↓3.80%[0m) [1.50% of initial]
[Iter 1390/20000] Loss: 0.0037640 (Best: 0.0031082 @iter1375) ([92m↓3.80%[0m) [1.50% of initial]
Iter:1399, L1 loss=0.002275, Total loss=0.003007, Time:11
Iter:1399, L1 loss=0.002275, Total loss=0.003007, Time:11
[Iter 1400/20000] Loss: 0.0034410 (Best: 0.0030020 @iter1394) ([92m↓8.58%[0m) [1.37% of initial]
[Iter 1400/20000] Loss: 0.0034410 (Best: 0.0030020 @iter1394) ([92m↓8.58%[0m) [1.37% of initial]
[Iter 1410/20000] Loss: 0.0088258 (Best: 0.0030020 @iter1394) ([91m↑156.49%[0m) [3.51% of initial]
[Iter 1410/20000] Loss: 0.0088258 (Best: 0.0030020 @iter1394) ([91m↑156.49%[0m) [3.51% of initial]
[Iter 1420/20000] Loss: 0.0057154 (Best: 0.0030020 @iter1394) ([92m↓35.24%[0m) [2.27% of initial]
[Iter 1420/20000] Loss: 0.0057154 (Best: 0.0030020 @iter1394) ([92m↓35.24%[0m) [2.27% of initial]
[Iter 1430/20000] Loss: 0.0048303 (Best: 0.0030020 @iter1394) ([92m↓15.49%[0m) [1.92% of initial]
[Iter 1430/20000] Loss: 0.0048303 (Best: 0.0030020 @iter1394) ([92m↓15.49%[0m) [1.92% of initial]
[Iter 1440/20000] Loss: 0.0043855 (Best: 0.0030020 @iter1394) ([92m↓9.21%[0m) [1.74% of initial]
[Iter 1440/20000] Loss: 0.0043855 (Best: 0.0030020 @iter1394) ([92m↓9.21%[0m) [1.74% of initial]
[Iter 1450/20000] Loss: 0.0035099 (Best: 0.0030020 @iter1394) ([92m↓19.96%[0m) [1.39% of initial]
[Iter 1450/20000] Loss: 0.0035099 (Best: 0.0030020 @iter1394) ([92m↓19.96%[0m) [1.39% of initial]
[Iter 1460/20000] Loss: 0.0035351 (Best: 0.0029076 @iter1459) ([91m↑0.72%[0m) [1.40% of initial]
[Iter 1460/20000] Loss: 0.0035351 (Best: 0.0029076 @iter1459) ([91m↑0.72%[0m) [1.40% of initial]
[Iter 1470/20000] Loss: 0.0034121 (Best: 0.0029076 @iter1459) ([92m↓3.48%[0m) [1.36% of initial]
[Iter 1470/20000] Loss: 0.0034121 (Best: 0.0029076 @iter1459) ([92m↓3.48%[0m) [1.36% of initial]
[Iter 1480/20000] Loss: 0.0032993 (Best: 0.0027681 @iter1480) ([92m↓3.31%[0m) [1.31% of initial]
[Iter 1480/20000] Loss: 0.0032993 (Best: 0.0027681 @iter1480) ([92m↓3.31%[0m) [1.31% of initial]
[Iter 1490/20000] Loss: 0.0032108 (Best: 0.0027681 @iter1480) ([92m↓2.68%[0m) [1.28% of initial]
[Iter 1490/20000] Loss: 0.0032108 (Best: 0.0027681 @iter1480) ([92m↓2.68%[0m) [1.28% of initial]
Iter:1499, L1 loss=0.002628, Total loss=0.003301, Time:13
Iter:1499, L1 loss=0.002628, Total loss=0.003301, Time:13
[Iter 1500/20000] Loss: 0.0031942 (Best: 0.0027681 @iter1480) ([92m↓0.52%[0m) [1.27% of initial]
[Iter 1500/20000] Loss: 0.0031942 (Best: 0.0027681 @iter1480) ([92m↓0.52%[0m) [1.27% of initial]
[Iter 1510/20000] Loss: 0.0030330 (Best: 0.0025855 @iter1504) ([92m↓5.05%[0m) [1.20% of initial]
[Iter 1510/20000] Loss: 0.0030330 (Best: 0.0025855 @iter1504) ([92m↓5.05%[0m) [1.20% of initial]
[Iter 1520/20000] Loss: 0.0030070 (Best: 0.0025770 @iter1520) ([92m↓0.86%[0m) [1.19% of initial]
[Iter 1520/20000] Loss: 0.0030070 (Best: 0.0025770 @iter1520) ([92m↓0.86%[0m) [1.19% of initial]
[Iter 1530/20000] Loss: 0.0031093 (Best: 0.0025667 @iter1526) ([91m↑3.40%[0m) [1.24% of initial]
[Iter 1530/20000] Loss: 0.0031093 (Best: 0.0025667 @iter1526) ([91m↑3.40%[0m) [1.24% of initial]
[Iter 1540/20000] Loss: 0.0030313 (Best: 0.0025667 @iter1526) ([92m↓2.51%[0m) [1.20% of initial]
[Iter 1540/20000] Loss: 0.0030313 (Best: 0.0025667 @iter1526) ([92m↓2.51%[0m) [1.20% of initial]
[Iter 1550/20000] Loss: 0.0030381 (Best: 0.0025667 @iter1526) ([91m↑0.22%[0m) [1.21% of initial]
[Iter 1550/20000] Loss: 0.0030381 (Best: 0.0025667 @iter1526) ([91m↑0.22%[0m) [1.21% of initial]
[Iter 1560/20000] Loss: 0.0032427 (Best: 0.0025116 @iter1558) ([91m↑6.73%[0m) [1.29% of initial]
[Iter 1560/20000] Loss: 0.0032427 (Best: 0.0025116 @iter1558) ([91m↑6.73%[0m) [1.29% of initial]
[Iter 1570/20000] Loss: 0.0028689 (Best: 0.0025116 @iter1558) ([92m↓11.53%[0m) [1.14% of initial]
[Iter 1570/20000] Loss: 0.0028689 (Best: 0.0025116 @iter1558) ([92m↓11.53%[0m) [1.14% of initial]
[Iter 1580/20000] Loss: 0.0028212 (Best: 0.0023468 @iter1573) ([92m↓1.67%[0m) [1.12% of initial]
[Iter 1580/20000] Loss: 0.0028212 (Best: 0.0023468 @iter1573) ([92m↓1.67%[0m) [1.12% of initial]
[Iter 1590/20000] Loss: 0.0027021 (Best: 0.0023468 @iter1573) ([92m↓4.22%[0m) [1.07% of initial]
[Iter 1590/20000] Loss: 0.0027021 (Best: 0.0023468 @iter1573) ([92m↓4.22%[0m) [1.07% of initial]
Iter:1599, L1 loss=0.00271, Total loss=0.003367, Time:13
Iter:1599, L1 loss=0.00271, Total loss=0.003367, Time:13
[Iter 1600/20000] Loss: 0.0030720 (Best: 0.0022941 @iter1591) ([91m↑13.69%[0m) [1.22% of initial]
[Iter 1600/20000] Loss: 0.0030720 (Best: 0.0022941 @iter1591) ([91m↑13.69%[0m) [1.22% of initial]
[Iter 1610/20000] Loss: 0.0083737 (Best: 0.0022941 @iter1591) ([91m↑172.58%[0m) [3.33% of initial]
[Iter 1610/20000] Loss: 0.0083737 (Best: 0.0022941 @iter1591) ([91m↑172.58%[0m) [3.33% of initial]
[Iter 1620/20000] Loss: 0.0053207 (Best: 0.0022941 @iter1591) ([92m↓36.46%[0m) [2.11% of initial]
[Iter 1620/20000] Loss: 0.0053207 (Best: 0.0022941 @iter1591) ([92m↓36.46%[0m) [2.11% of initial]
[Iter 1630/20000] Loss: 0.0040729 (Best: 0.0022941 @iter1591) ([92m↓23.45%[0m) [1.62% of initial]
[Iter 1630/20000] Loss: 0.0040729 (Best: 0.0022941 @iter1591) ([92m↓23.45%[0m) [1.62% of initial]
[Iter 1640/20000] Loss: 0.0038738 (Best: 0.0022941 @iter1591) ([92m↓4.89%[0m) [1.54% of initial]
[Iter 1640/20000] Loss: 0.0038738 (Best: 0.0022941 @iter1591) ([92m↓4.89%[0m) [1.54% of initial]
[Iter 1650/20000] Loss: 0.0033793 (Best: 0.0022941 @iter1591) ([92m↓12.77%[0m) [1.34% of initial]
[Iter 1650/20000] Loss: 0.0033793 (Best: 0.0022941 @iter1591) ([92m↓12.77%[0m) [1.34% of initial]
[Iter 1660/20000] Loss: 0.0029043 (Best: 0.0022941 @iter1591) ([92m↓14.06%[0m) [1.15% of initial]
[Iter 1660/20000] Loss: 0.0029043 (Best: 0.0022941 @iter1591) ([92m↓14.06%[0m) [1.15% of initial]
[Iter 1670/20000] Loss: 0.0026979 (Best: 0.0022461 @iter1669) ([92m↓7.11%[0m) [1.07% of initial]
[Iter 1670/20000] Loss: 0.0026979 (Best: 0.0022461 @iter1669) ([92m↓7.11%[0m) [1.07% of initial]
[Iter 1680/20000] Loss: 0.0028724 (Best: 0.0022461 @iter1669) ([91m↑6.47%[0m) [1.14% of initial]
[Iter 1680/20000] Loss: 0.0028724 (Best: 0.0022461 @iter1669) ([91m↑6.47%[0m) [1.14% of initial]
[Iter 1690/20000] Loss: 0.0030466 (Best: 0.0022461 @iter1669) ([91m↑6.06%[0m) [1.21% of initial]
[Iter 1690/20000] Loss: 0.0030466 (Best: 0.0022461 @iter1669) ([91m↑6.06%[0m) [1.21% of initial]
Iter:1699, L1 loss=0.002568, Total loss=0.003164, Time:14
Iter:1699, L1 loss=0.002568, Total loss=0.003164, Time:14
[Iter 1700/20000] Loss: 0.0027774 (Best: 0.0022461 @iter1669) ([92m↓8.83%[0m) [1.10% of initial]
[Iter 1700/20000] Loss: 0.0027774 (Best: 0.0022461 @iter1669) ([92m↓8.83%[0m) [1.10% of initial]
[Iter 1710/20000] Loss: 0.0029364 (Best: 0.0022461 @iter1669) ([91m↑5.73%[0m) [1.17% of initial]
[Iter 1710/20000] Loss: 0.0029364 (Best: 0.0022461 @iter1669) ([91m↑5.73%[0m) [1.17% of initial]
[Iter 1720/20000] Loss: 0.0025260 (Best: 0.0022289 @iter1715) ([92m↓13.98%[0m) [1.00% of initial]
[Iter 1720/20000] Loss: 0.0025260 (Best: 0.0022289 @iter1715) ([92m↓13.98%[0m) [1.00% of initial]
[Iter 1730/20000] Loss: 0.0026393 (Best: 0.0022289 @iter1715) ([91m↑4.49%[0m) [1.05% of initial]
[Iter 1730/20000] Loss: 0.0026393 (Best: 0.0022289 @iter1715) ([91m↑4.49%[0m) [1.05% of initial]
[Iter 1740/20000] Loss: 0.0026273 (Best: 0.0022271 @iter1738) ([92m↓0.46%[0m) [1.04% of initial]
[Iter 1740/20000] Loss: 0.0026273 (Best: 0.0022271 @iter1738) ([92m↓0.46%[0m) [1.04% of initial]
[Iter 1750/20000] Loss: 0.0023780 (Best: 0.0021381 @iter1742) ([92m↓9.49%[0m) [0.94% of initial]
[Iter 1750/20000] Loss: 0.0023780 (Best: 0.0021381 @iter1742) ([92m↓9.49%[0m) [0.94% of initial]
[Iter 1760/20000] Loss: 0.0026346 (Best: 0.0021381 @iter1742) ([91m↑10.79%[0m) [1.05% of initial]
[Iter 1760/20000] Loss: 0.0026346 (Best: 0.0021381 @iter1742) ([91m↑10.79%[0m) [1.05% of initial]
[Iter 1770/20000] Loss: 0.0024193 (Best: 0.0020959 @iter1762) ([92m↓8.17%[0m) [0.96% of initial]
[Iter 1770/20000] Loss: 0.0024193 (Best: 0.0020959 @iter1762) ([92m↓8.17%[0m) [0.96% of initial]
[Iter 1780/20000] Loss: 0.0024524 (Best: 0.0020845 @iter1771) ([91m↑1.37%[0m) [0.97% of initial]
[Iter 1780/20000] Loss: 0.0024524 (Best: 0.0020845 @iter1771) ([91m↑1.37%[0m) [0.97% of initial]
[Iter 1790/20000] Loss: 0.0021747 (Best: 0.0018077 @iter1789) ([92m↓11.32%[0m) [0.86% of initial]
[Iter 1790/20000] Loss: 0.0021747 (Best: 0.0018077 @iter1789) ([92m↓11.32%[0m) [0.86% of initial]
Iter:1799, L1 loss=0.001693, Total loss=0.001925, Time:14
Iter:1799, L1 loss=0.001693, Total loss=0.001925, Time:14
[Iter 1800/20000] Loss: 0.0021650 (Best: 0.0018077 @iter1789) ([92m↓0.44%[0m) [0.86% of initial]
[Iter 1800/20000] Loss: 0.0021650 (Best: 0.0018077 @iter1789) ([92m↓0.44%[0m) [0.86% of initial]
[Iter 1810/20000] Loss: 0.0076185 (Best: 0.0018077 @iter1789) ([91m↑251.89%[0m) [3.03% of initial]
[Iter 1810/20000] Loss: 0.0076185 (Best: 0.0018077 @iter1789) ([91m↑251.89%[0m) [3.03% of initial]
[Iter 1820/20000] Loss: 0.0044429 (Best: 0.0018077 @iter1789) ([92m↓41.68%[0m) [1.77% of initial]
[Iter 1820/20000] Loss: 0.0044429 (Best: 0.0018077 @iter1789) ([92m↓41.68%[0m) [1.77% of initial]
[Iter 1830/20000] Loss: 0.0039384 (Best: 0.0018077 @iter1789) ([92m↓11.36%[0m) [1.56% of initial]
[Iter 1830/20000] Loss: 0.0039384 (Best: 0.0018077 @iter1789) ([92m↓11.36%[0m) [1.56% of initial]
[Iter 1840/20000] Loss: 0.0027575 (Best: 0.0018077 @iter1789) ([92m↓29.98%[0m) [1.10% of initial]
[Iter 1840/20000] Loss: 0.0027575 (Best: 0.0018077 @iter1789) ([92m↓29.98%[0m) [1.10% of initial]
[Iter 1850/20000] Loss: 0.0026272 (Best: 0.0018077 @iter1789) ([92m↓4.73%[0m) [1.04% of initial]
[Iter 1850/20000] Loss: 0.0026272 (Best: 0.0018077 @iter1789) ([92m↓4.73%[0m) [1.04% of initial]
[Iter 1860/20000] Loss: 0.0023710 (Best: 0.0018077 @iter1789) ([92m↓9.75%[0m) [0.94% of initial]
[Iter 1860/20000] Loss: 0.0023710 (Best: 0.0018077 @iter1789) ([92m↓9.75%[0m) [0.94% of initial]
[Iter 1870/20000] Loss: 0.0022475 (Best: 0.0018077 @iter1789) ([92m↓5.21%[0m) [0.89% of initial]
[Iter 1870/20000] Loss: 0.0022475 (Best: 0.0018077 @iter1789) ([92m↓5.21%[0m) [0.89% of initial]
[Iter 1880/20000] Loss: 0.0021118 (Best: 0.0018077 @iter1789) ([92m↓6.03%[0m) [0.84% of initial]
[Iter 1880/20000] Loss: 0.0021118 (Best: 0.0018077 @iter1789) ([92m↓6.03%[0m) [0.84% of initial]
[Iter 1890/20000] Loss: 0.0018878 (Best: 0.0017169 @iter1890) ([92m↓10.61%[0m) [0.75% of initial]
[Iter 1890/20000] Loss: 0.0018878 (Best: 0.0017169 @iter1890) ([92m↓10.61%[0m) [0.75% of initial]
Iter:1899, L1 loss=0.001756, Total loss=0.001889, Time:13
Iter:1899, L1 loss=0.001756, Total loss=0.001889, Time:13
[Iter 1900/20000] Loss: 0.0019664 (Best: 0.0015890 @iter1891) ([91m↑4.16%[0m) [0.78% of initial]
[Iter 1900/20000] Loss: 0.0019664 (Best: 0.0015890 @iter1891) ([91m↑4.16%[0m) [0.78% of initial]
[Iter 1910/20000] Loss: 0.0020467 (Best: 0.0015890 @iter1891) ([91m↑4.09%[0m) [0.81% of initial]
[Iter 1910/20000] Loss: 0.0020467 (Best: 0.0015890 @iter1891) ([91m↑4.09%[0m) [0.81% of initial]
[Iter 1920/20000] Loss: 0.0020881 (Best: 0.0015890 @iter1891) ([91m↑2.02%[0m) [0.83% of initial]
[Iter 1920/20000] Loss: 0.0020881 (Best: 0.0015890 @iter1891) ([91m↑2.02%[0m) [0.83% of initial]
[Iter 1930/20000] Loss: 0.0017517 (Best: 0.0015675 @iter1930) ([92m↓16.11%[0m) [0.70% of initial]
[Iter 1930/20000] Loss: 0.0017517 (Best: 0.0015675 @iter1930) ([92m↓16.11%[0m) [0.70% of initial]
[Iter 1940/20000] Loss: 0.0019250 (Best: 0.0015619 @iter1939) ([91m↑9.89%[0m) [0.76% of initial]
[Iter 1940/20000] Loss: 0.0019250 (Best: 0.0015619 @iter1939) ([91m↑9.89%[0m) [0.76% of initial]
[Iter 1950/20000] Loss: 0.0020812 (Best: 0.0015619 @iter1939) ([91m↑8.11%[0m) [0.83% of initial]
[Iter 1950/20000] Loss: 0.0020812 (Best: 0.0015619 @iter1939) ([91m↑8.11%[0m) [0.83% of initial]
[Iter 1960/20000] Loss: 0.0018402 (Best: 0.0015619 @iter1939) ([92m↓11.58%[0m) [0.73% of initial]
[Iter 1960/20000] Loss: 0.0018402 (Best: 0.0015619 @iter1939) ([92m↓11.58%[0m) [0.73% of initial]
[Iter 1970/20000] Loss: 0.0016844 (Best: 0.0014912 @iter1963) ([92m↓8.46%[0m) [0.67% of initial]
[Iter 1970/20000] Loss: 0.0016844 (Best: 0.0014912 @iter1963) ([92m↓8.46%[0m) [0.67% of initial]
[Iter 1980/20000] Loss: 0.0020318 (Best: 0.0014912 @iter1963) ([91m↑20.62%[0m) [0.81% of initial]
[Iter 1980/20000] Loss: 0.0020318 (Best: 0.0014912 @iter1963) ([91m↑20.62%[0m) [0.81% of initial]
[Iter 1990/20000] Loss: 0.0017726 (Best: 0.0014912 @iter1963) ([92m↓12.76%[0m) [0.70% of initial]
[Iter 1990/20000] Loss: 0.0017726 (Best: 0.0014912 @iter1963) ([92m↓12.76%[0m) [0.70% of initial]
Iter:1999, L1 loss=0.001496, Total loss=0.001688, Time:14
Iter:1999, L1 loss=0.001496, Total loss=0.001688, Time:14
[Iter 2000/20000] Loss: 0.0019066 (Best: 0.0014440 @iter1996) ([91m↑7.56%[0m) [0.76% of initial]
[Iter 2000/20000] Loss: 0.0019066 (Best: 0.0014440 @iter1996) ([91m↑7.56%[0m) [0.76% of initial]
Testing Speed: 230.08004493750877 fps
Testing Speed: 230.08004493750877 fps
Testing Time: 0.217315673828125 s
Testing Time: 0.217315673828125 s

[ITER 2000] Evaluating test: SSIM = 0.8517311704158783, PSNR = 17.86451017379761

[ITER 2000] Evaluating test: SSIM = 0.8517311704158783, PSNR = 17.86451017379761
Testing Speed: 266.1979733017411 fps
Testing Speed: 266.1979733017411 fps
Testing Time: 0.011269807815551758 s
Testing Time: 0.011269807815551758 s

[ITER 2000] Evaluating train: SSIM = 0.9999508460362752, PSNR = 49.11960983276367

[ITER 2000] Evaluating train: SSIM = 0.9999508460362752, PSNR = 49.11960983276367
Iter:2000, total_points:43188
Iter:2000, total_points:43188
[Iter 2010/20000] Loss: 0.0066659 (Best: 0.0014440 @iter1996) ([91m↑249.61%[0m) [2.65% of initial]
[Iter 2010/20000] Loss: 0.0066659 (Best: 0.0014440 @iter1996) ([91m↑249.61%[0m) [2.65% of initial]
[Iter 2020/20000] Loss: 0.0037287 (Best: 0.0014440 @iter1996) ([92m↓44.06%[0m) [1.48% of initial]
[Iter 2020/20000] Loss: 0.0037287 (Best: 0.0014440 @iter1996) ([92m↓44.06%[0m) [1.48% of initial]
[Iter 2030/20000] Loss: 0.0028463 (Best: 0.0014440 @iter1996) ([92m↓23.67%[0m) [1.13% of initial]
[Iter 2030/20000] Loss: 0.0028463 (Best: 0.0014440 @iter1996) ([92m↓23.67%[0m) [1.13% of initial]
[Iter 2040/20000] Loss: 0.0024982 (Best: 0.0014440 @iter1996) ([92m↓12.23%[0m) [0.99% of initial]
[Iter 2040/20000] Loss: 0.0024982 (Best: 0.0014440 @iter1996) ([92m↓12.23%[0m) [0.99% of initial]
[Iter 2050/20000] Loss: 0.0020582 (Best: 0.0014440 @iter1996) ([92m↓17.61%[0m) [0.82% of initial]
[Iter 2050/20000] Loss: 0.0020582 (Best: 0.0014440 @iter1996) ([92m↓17.61%[0m) [0.82% of initial]
[Iter 2060/20000] Loss: 0.0017213 (Best: 0.0014440 @iter1996) ([92m↓16.37%[0m) [0.68% of initial]
[Iter 2060/20000] Loss: 0.0017213 (Best: 0.0014440 @iter1996) ([92m↓16.37%[0m) [0.68% of initial]
[Iter 2070/20000] Loss: 0.0019735 (Best: 0.0014440 @iter1996) ([91m↑14.65%[0m) [0.78% of initial]
[Iter 2070/20000] Loss: 0.0019735 (Best: 0.0014440 @iter1996) ([91m↑14.65%[0m) [0.78% of initial]
[Iter 2080/20000] Loss: 0.0018752 (Best: 0.0014440 @iter1996) ([92m↓4.98%[0m) [0.74% of initial]
[Iter 2080/20000] Loss: 0.0018752 (Best: 0.0014440 @iter1996) ([92m↓4.98%[0m) [0.74% of initial]
[Iter 2090/20000] Loss: 0.0018079 (Best: 0.0014129 @iter2089) ([92m↓3.59%[0m) [0.72% of initial]
[Iter 2090/20000] Loss: 0.0018079 (Best: 0.0014129 @iter2089) ([92m↓3.59%[0m) [0.72% of initial]
Iter:2099, L1 loss=0.001594, Total loss=0.0017, Time:15
Iter:2099, L1 loss=0.001594, Total loss=0.0017, Time:15
[Iter 2100/20000] Loss: 0.0016948 (Best: 0.0014129 @iter2089) ([92m↓6.26%[0m) [0.67% of initial]
[Iter 2100/20000] Loss: 0.0016948 (Best: 0.0014129 @iter2089) ([92m↓6.26%[0m) [0.67% of initial]
[Iter 2110/20000] Loss: 0.0015839 (Best: 0.0014129 @iter2089) ([92m↓6.54%[0m) [0.63% of initial]
[Iter 2110/20000] Loss: 0.0015839 (Best: 0.0014129 @iter2089) ([92m↓6.54%[0m) [0.63% of initial]
[Iter 2120/20000] Loss: 0.0014286 (Best: 0.0012930 @iter2120) ([92m↓9.80%[0m) [0.57% of initial]
[Iter 2120/20000] Loss: 0.0014286 (Best: 0.0012930 @iter2120) ([92m↓9.80%[0m) [0.57% of initial]
[Iter 2130/20000] Loss: 0.0015920 (Best: 0.0012231 @iter2125) ([91m↑11.44%[0m) [0.63% of initial]
[Iter 2130/20000] Loss: 0.0015920 (Best: 0.0012231 @iter2125) ([91m↑11.44%[0m) [0.63% of initial]
[Iter 2140/20000] Loss: 0.0017049 (Best: 0.0012231 @iter2125) ([91m↑7.09%[0m) [0.68% of initial]
[Iter 2140/20000] Loss: 0.0017049 (Best: 0.0012231 @iter2125) ([91m↑7.09%[0m) [0.68% of initial]
[Iter 2150/20000] Loss: 0.0017383 (Best: 0.0012231 @iter2125) ([91m↑1.96%[0m) [0.69% of initial]
[Iter 2150/20000] Loss: 0.0017383 (Best: 0.0012231 @iter2125) ([91m↑1.96%[0m) [0.69% of initial]
[Iter 2160/20000] Loss: 0.0015923 (Best: 0.0012231 @iter2125) ([92m↓8.40%[0m) [0.63% of initial]
[Iter 2160/20000] Loss: 0.0015923 (Best: 0.0012231 @iter2125) ([92m↓8.40%[0m) [0.63% of initial]
[Iter 2170/20000] Loss: 0.0016146 (Best: 0.0012231 @iter2125) ([91m↑1.40%[0m) [0.64% of initial]
[Iter 2170/20000] Loss: 0.0016146 (Best: 0.0012231 @iter2125) ([91m↑1.40%[0m) [0.64% of initial]
[Iter 2180/20000] Loss: 0.0013476 (Best: 0.0012231 @iter2125) ([92m↓16.54%[0m) [0.54% of initial]
[Iter 2180/20000] Loss: 0.0013476 (Best: 0.0012231 @iter2125) ([92m↓16.54%[0m) [0.54% of initial]
[Iter 2190/20000] Loss: 0.0015892 (Best: 0.0012231 @iter2125) ([91m↑17.93%[0m) [0.63% of initial]
[Iter 2190/20000] Loss: 0.0015892 (Best: 0.0012231 @iter2125) ([91m↑17.93%[0m) [0.63% of initial]
Iter:2199, L1 loss=0.001458, Total loss=0.001526, Time:16
Iter:2199, L1 loss=0.001458, Total loss=0.001526, Time:16
[Iter 2200/20000] Loss: 0.0015879 (Best: 0.0012231 @iter2125) ([92m↓0.08%[0m) [0.63% of initial]
[Iter 2200/20000] Loss: 0.0015879 (Best: 0.0012231 @iter2125) ([92m↓0.08%[0m) [0.63% of initial]
[Iter 2210/20000] Loss: 0.0079680 (Best: 0.0012231 @iter2125) ([91m↑401.80%[0m) [3.17% of initial]
[Iter 2210/20000] Loss: 0.0079680 (Best: 0.0012231 @iter2125) ([91m↑401.80%[0m) [3.17% of initial]
[Iter 2220/20000] Loss: 0.0043428 (Best: 0.0012231 @iter2125) ([92m↓45.50%[0m) [1.73% of initial]
[Iter 2220/20000] Loss: 0.0043428 (Best: 0.0012231 @iter2125) ([92m↓45.50%[0m) [1.73% of initial]
[Iter 2230/20000] Loss: 0.0026793 (Best: 0.0012231 @iter2125) ([92m↓38.31%[0m) [1.06% of initial]
[Iter 2230/20000] Loss: 0.0026793 (Best: 0.0012231 @iter2125) ([92m↓38.31%[0m) [1.06% of initial]
[Iter 2240/20000] Loss: 0.0022858 (Best: 0.0012231 @iter2125) ([92m↓14.69%[0m) [0.91% of initial]
[Iter 2240/20000] Loss: 0.0022858 (Best: 0.0012231 @iter2125) ([92m↓14.69%[0m) [0.91% of initial]
[Iter 2250/20000] Loss: 0.0021165 (Best: 0.0012231 @iter2125) ([92m↓7.41%[0m) [0.84% of initial]
[Iter 2250/20000] Loss: 0.0021165 (Best: 0.0012231 @iter2125) ([92m↓7.41%[0m) [0.84% of initial]
[Iter 2260/20000] Loss: 0.0017172 (Best: 0.0012231 @iter2125) ([92m↓18.86%[0m) [0.68% of initial]
[Iter 2260/20000] Loss: 0.0017172 (Best: 0.0012231 @iter2125) ([92m↓18.86%[0m) [0.68% of initial]
[Iter 2270/20000] Loss: 0.0018301 (Best: 0.0012231 @iter2125) ([91m↑6.57%[0m) [0.73% of initial]
[Iter 2270/20000] Loss: 0.0018301 (Best: 0.0012231 @iter2125) ([91m↑6.57%[0m) [0.73% of initial]
[Iter 2280/20000] Loss: 0.0014707 (Best: 0.0012231 @iter2125) ([92m↓19.64%[0m) [0.58% of initial]
[Iter 2280/20000] Loss: 0.0014707 (Best: 0.0012231 @iter2125) ([92m↓19.64%[0m) [0.58% of initial]
[Iter 2290/20000] Loss: 0.0014241 (Best: 0.0011960 @iter2285) ([92m↓3.17%[0m) [0.57% of initial]
[Iter 2290/20000] Loss: 0.0014241 (Best: 0.0011960 @iter2285) ([92m↓3.17%[0m) [0.57% of initial]
Iter:2299, L1 loss=0.001281, Total loss=0.001478, Time:15
Iter:2299, L1 loss=0.001281, Total loss=0.001478, Time:15
[Iter 2300/20000] Loss: 0.0017630 (Best: 0.0011960 @iter2285) ([91m↑23.80%[0m) [0.70% of initial]
[Iter 2300/20000] Loss: 0.0017630 (Best: 0.0011960 @iter2285) ([91m↑23.80%[0m) [0.70% of initial]
[Iter 2310/20000] Loss: 0.0015605 (Best: 0.0011960 @iter2285) ([92m↓11.49%[0m) [0.62% of initial]
[Iter 2310/20000] Loss: 0.0015605 (Best: 0.0011960 @iter2285) ([92m↓11.49%[0m) [0.62% of initial]
[Iter 2320/20000] Loss: 0.0013107 (Best: 0.0011700 @iter2320) ([92m↓16.01%[0m) [0.52% of initial]
[Iter 2320/20000] Loss: 0.0013107 (Best: 0.0011700 @iter2320) ([92m↓16.01%[0m) [0.52% of initial]
[Iter 2330/20000] Loss: 0.0012913 (Best: 0.0011132 @iter2327) ([92m↓1.47%[0m) [0.51% of initial]
[Iter 2330/20000] Loss: 0.0012913 (Best: 0.0011132 @iter2327) ([92m↓1.47%[0m) [0.51% of initial]
[Iter 2340/20000] Loss: 0.0013510 (Best: 0.0011050 @iter2338) ([91m↑4.62%[0m) [0.54% of initial]
[Iter 2340/20000] Loss: 0.0013510 (Best: 0.0011050 @iter2338) ([91m↑4.62%[0m) [0.54% of initial]
[Iter 2350/20000] Loss: 0.0015044 (Best: 0.0011050 @iter2338) ([91m↑11.36%[0m) [0.60% of initial]
[Iter 2350/20000] Loss: 0.0015044 (Best: 0.0011050 @iter2338) ([91m↑11.36%[0m) [0.60% of initial]
[Iter 2360/20000] Loss: 0.0013122 (Best: 0.0011050 @iter2338) ([92m↓12.78%[0m) [0.52% of initial]
[Iter 2360/20000] Loss: 0.0013122 (Best: 0.0011050 @iter2338) ([92m↓12.78%[0m) [0.52% of initial]
[Iter 2370/20000] Loss: 0.0014097 (Best: 0.0011050 @iter2338) ([91m↑7.43%[0m) [0.56% of initial]
[Iter 2370/20000] Loss: 0.0014097 (Best: 0.0011050 @iter2338) ([91m↑7.43%[0m) [0.56% of initial]
[Iter 2380/20000] Loss: 0.0014880 (Best: 0.0011050 @iter2338) ([91m↑5.56%[0m) [0.59% of initial]
[Iter 2380/20000] Loss: 0.0014880 (Best: 0.0011050 @iter2338) ([91m↑5.56%[0m) [0.59% of initial]
[Iter 2390/20000] Loss: 0.0016085 (Best: 0.0011050 @iter2338) ([91m↑8.10%[0m) [0.64% of initial]
[Iter 2390/20000] Loss: 0.0016085 (Best: 0.0011050 @iter2338) ([91m↑8.10%[0m) [0.64% of initial]
Iter:2399, L1 loss=0.00123, Total loss=0.001306, Time:14
Iter:2399, L1 loss=0.00123, Total loss=0.001306, Time:14
[Iter 2400/20000] Loss: 0.0013480 (Best: 0.0011050 @iter2338) ([92m↓16.20%[0m) [0.54% of initial]
[Iter 2400/20000] Loss: 0.0013480 (Best: 0.0011050 @iter2338) ([92m↓16.20%[0m) [0.54% of initial]
[Iter 2410/20000] Loss: 0.0061113 (Best: 0.0011050 @iter2338) ([91m↑353.36%[0m) [2.43% of initial]
[Iter 2410/20000] Loss: 0.0061113 (Best: 0.0011050 @iter2338) ([91m↑353.36%[0m) [2.43% of initial]
[Iter 2420/20000] Loss: 0.0034878 (Best: 0.0011050 @iter2338) ([92m↓42.93%[0m) [1.39% of initial]
[Iter 2420/20000] Loss: 0.0034878 (Best: 0.0011050 @iter2338) ([92m↓42.93%[0m) [1.39% of initial]
[Iter 2430/20000] Loss: 0.0025936 (Best: 0.0011050 @iter2338) ([92m↓25.64%[0m) [1.03% of initial]
[Iter 2430/20000] Loss: 0.0025936 (Best: 0.0011050 @iter2338) ([92m↓25.64%[0m) [1.03% of initial]
[Iter 2440/20000] Loss: 0.0020421 (Best: 0.0011050 @iter2338) ([92m↓21.26%[0m) [0.81% of initial]
[Iter 2440/20000] Loss: 0.0020421 (Best: 0.0011050 @iter2338) ([92m↓21.26%[0m) [0.81% of initial]
[Iter 2450/20000] Loss: 0.0019604 (Best: 0.0011050 @iter2338) ([92m↓4.00%[0m) [0.78% of initial]
[Iter 2450/20000] Loss: 0.0019604 (Best: 0.0011050 @iter2338) ([92m↓4.00%[0m) [0.78% of initial]
[Iter 2460/20000] Loss: 0.0016919 (Best: 0.0011050 @iter2338) ([92m↓13.69%[0m) [0.67% of initial]
[Iter 2460/20000] Loss: 0.0016919 (Best: 0.0011050 @iter2338) ([92m↓13.69%[0m) [0.67% of initial]
[Iter 2470/20000] Loss: 0.0016763 (Best: 0.0011050 @iter2338) ([92m↓0.92%[0m) [0.67% of initial]
[Iter 2470/20000] Loss: 0.0016763 (Best: 0.0011050 @iter2338) ([92m↓0.92%[0m) [0.67% of initial]
[Iter 2480/20000] Loss: 0.0016986 (Best: 0.0011050 @iter2338) ([91m↑1.33%[0m) [0.67% of initial]
[Iter 2480/20000] Loss: 0.0016986 (Best: 0.0011050 @iter2338) ([91m↑1.33%[0m) [0.67% of initial]
[Iter 2490/20000] Loss: 0.0014873 (Best: 0.0011050 @iter2338) ([92m↓12.44%[0m) [0.59% of initial]
[Iter 2490/20000] Loss: 0.0014873 (Best: 0.0011050 @iter2338) ([92m↓12.44%[0m) [0.59% of initial]
Iter:2499, L1 loss=0.00121, Total loss=0.001238, Time:17
Iter:2499, L1 loss=0.00121, Total loss=0.001238, Time:17
[Iter 2500/20000] Loss: 0.0013036 (Best: 0.0011050 @iter2338) ([92m↓12.35%[0m) [0.52% of initial]
[Iter 2500/20000] Loss: 0.0013036 (Best: 0.0011050 @iter2338) ([92m↓12.35%[0m) [0.52% of initial]
[Iter 2510/20000] Loss: 0.0013616 (Best: 0.0010396 @iter2504) ([91m↑4.46%[0m) [0.54% of initial]
[Iter 2510/20000] Loss: 0.0013616 (Best: 0.0010396 @iter2504) ([91m↑4.46%[0m) [0.54% of initial]
[Iter 2520/20000] Loss: 0.0012312 (Best: 0.0009997 @iter2519) ([92m↓9.58%[0m) [0.49% of initial]
[Iter 2520/20000] Loss: 0.0012312 (Best: 0.0009997 @iter2519) ([92m↓9.58%[0m) [0.49% of initial]
[Iter 2530/20000] Loss: 0.0011107 (Best: 0.0009715 @iter2528) ([92m↓9.79%[0m) [0.44% of initial]
[Iter 2530/20000] Loss: 0.0011107 (Best: 0.0009715 @iter2528) ([92m↓9.79%[0m) [0.44% of initial]
[Iter 2540/20000] Loss: 0.0012009 (Best: 0.0009715 @iter2528) ([91m↑8.12%[0m) [0.48% of initial]
[Iter 2540/20000] Loss: 0.0012009 (Best: 0.0009715 @iter2528) ([91m↑8.12%[0m) [0.48% of initial]
[Iter 2550/20000] Loss: 0.0014044 (Best: 0.0009715 @iter2528) ([91m↑16.95%[0m) [0.56% of initial]
[Iter 2550/20000] Loss: 0.0014044 (Best: 0.0009715 @iter2528) ([91m↑16.95%[0m) [0.56% of initial]
[Iter 2560/20000] Loss: 0.0011707 (Best: 0.0009707 @iter2557) ([92m↓16.64%[0m) [0.47% of initial]
[Iter 2560/20000] Loss: 0.0011707 (Best: 0.0009707 @iter2557) ([92m↓16.64%[0m) [0.47% of initial]
[Iter 2570/20000] Loss: 0.0014235 (Best: 0.0009707 @iter2557) ([91m↑21.59%[0m) [0.57% of initial]
[Iter 2570/20000] Loss: 0.0014235 (Best: 0.0009707 @iter2557) ([91m↑21.59%[0m) [0.57% of initial]
[Iter 2580/20000] Loss: 0.0012661 (Best: 0.0009270 @iter2578) ([92m↓11.06%[0m) [0.50% of initial]
[Iter 2580/20000] Loss: 0.0012661 (Best: 0.0009270 @iter2578) ([92m↓11.06%[0m) [0.50% of initial]
[Iter 2590/20000] Loss: 0.0013089 (Best: 0.0009270 @iter2578) ([91m↑3.38%[0m) [0.52% of initial]
[Iter 2590/20000] Loss: 0.0013089 (Best: 0.0009270 @iter2578) ([91m↑3.38%[0m) [0.52% of initial]
Iter:2599, L1 loss=0.001054, Total loss=0.001008, Time:16
Iter:2599, L1 loss=0.001054, Total loss=0.001008, Time:16
[Iter 2600/20000] Loss: 0.0011908 (Best: 0.0009210 @iter2594) ([92m↓9.02%[0m) [0.47% of initial]
[Iter 2600/20000] Loss: 0.0011908 (Best: 0.0009210 @iter2594) ([92m↓9.02%[0m) [0.47% of initial]
[Iter 2610/20000] Loss: 0.0060264 (Best: 0.0009210 @iter2594) ([91m↑406.07%[0m) [2.39% of initial]
[Iter 2610/20000] Loss: 0.0060264 (Best: 0.0009210 @iter2594) ([91m↑406.07%[0m) [2.39% of initial]
[Iter 2620/20000] Loss: 0.0033234 (Best: 0.0009210 @iter2594) ([92m↓44.85%[0m) [1.32% of initial]
[Iter 2620/20000] Loss: 0.0033234 (Best: 0.0009210 @iter2594) ([92m↓44.85%[0m) [1.32% of initial]
[Iter 2630/20000] Loss: 0.0022542 (Best: 0.0009210 @iter2594) ([92m↓32.17%[0m) [0.90% of initial]
[Iter 2630/20000] Loss: 0.0022542 (Best: 0.0009210 @iter2594) ([92m↓32.17%[0m) [0.90% of initial]
[Iter 2640/20000] Loss: 0.0017778 (Best: 0.0009210 @iter2594) ([92m↓21.14%[0m) [0.71% of initial]
[Iter 2640/20000] Loss: 0.0017778 (Best: 0.0009210 @iter2594) ([92m↓21.14%[0m) [0.71% of initial]
[Iter 2650/20000] Loss: 0.0014611 (Best: 0.0009210 @iter2594) ([92m↓17.81%[0m) [0.58% of initial]
[Iter 2650/20000] Loss: 0.0014611 (Best: 0.0009210 @iter2594) ([92m↓17.81%[0m) [0.58% of initial]
[Iter 2660/20000] Loss: 0.0016189 (Best: 0.0009210 @iter2594) ([91m↑10.80%[0m) [0.64% of initial]
[Iter 2660/20000] Loss: 0.0016189 (Best: 0.0009210 @iter2594) ([91m↑10.80%[0m) [0.64% of initial]
[Iter 2670/20000] Loss: 0.0015562 (Best: 0.0009210 @iter2594) ([92m↓3.87%[0m) [0.62% of initial]
[Iter 2670/20000] Loss: 0.0015562 (Best: 0.0009210 @iter2594) ([92m↓3.87%[0m) [0.62% of initial]
[Iter 2680/20000] Loss: 0.0012256 (Best: 0.0009210 @iter2594) ([92m↓21.24%[0m) [0.49% of initial]
[Iter 2680/20000] Loss: 0.0012256 (Best: 0.0009210 @iter2594) ([92m↓21.24%[0m) [0.49% of initial]
[Iter 2690/20000] Loss: 0.0011885 (Best: 0.0009210 @iter2594) ([92m↓3.03%[0m) [0.47% of initial]
[Iter 2690/20000] Loss: 0.0011885 (Best: 0.0009210 @iter2594) ([92m↓3.03%[0m) [0.47% of initial]
Iter:2699, L1 loss=0.00114, Total loss=0.001157, Time:16
Iter:2699, L1 loss=0.00114, Total loss=0.001157, Time:16
[Iter 2700/20000] Loss: 0.0014467 (Best: 0.0009210 @iter2594) ([91m↑21.73%[0m) [0.57% of initial]
[Iter 2700/20000] Loss: 0.0014467 (Best: 0.0009210 @iter2594) ([91m↑21.73%[0m) [0.57% of initial]
[Iter 2710/20000] Loss: 0.0012612 (Best: 0.0009210 @iter2594) ([92m↓12.82%[0m) [0.50% of initial]
[Iter 2710/20000] Loss: 0.0012612 (Best: 0.0009210 @iter2594) ([92m↓12.82%[0m) [0.50% of initial]
[Iter 2720/20000] Loss: 0.0011277 (Best: 0.0009210 @iter2594) ([92m↓10.59%[0m) [0.45% of initial]
[Iter 2720/20000] Loss: 0.0011277 (Best: 0.0009210 @iter2594) ([92m↓10.59%[0m) [0.45% of initial]
[Iter 2730/20000] Loss: 0.0010149 (Best: 0.0008751 @iter2727) ([92m↓10.00%[0m) [0.40% of initial]
[Iter 2730/20000] Loss: 0.0010149 (Best: 0.0008751 @iter2727) ([92m↓10.00%[0m) [0.40% of initial]
[Iter 2740/20000] Loss: 0.0008781 (Best: 0.0007820 @iter2740) ([92m↓13.48%[0m) [0.35% of initial]
[Iter 2740/20000] Loss: 0.0008781 (Best: 0.0007820 @iter2740) ([92m↓13.48%[0m) [0.35% of initial]
[Iter 2750/20000] Loss: 0.0011353 (Best: 0.0007820 @iter2740) ([91m↑29.29%[0m) [0.45% of initial]
[Iter 2750/20000] Loss: 0.0011353 (Best: 0.0007820 @iter2740) ([91m↑29.29%[0m) [0.45% of initial]
[Iter 2760/20000] Loss: 0.0011704 (Best: 0.0007820 @iter2740) ([91m↑3.09%[0m) [0.46% of initial]
[Iter 2760/20000] Loss: 0.0011704 (Best: 0.0007820 @iter2740) ([91m↑3.09%[0m) [0.46% of initial]
[Iter 2770/20000] Loss: 0.0012931 (Best: 0.0007820 @iter2740) ([91m↑10.49%[0m) [0.51% of initial]
[Iter 2770/20000] Loss: 0.0012931 (Best: 0.0007820 @iter2740) ([91m↑10.49%[0m) [0.51% of initial]
[Iter 2780/20000] Loss: 0.0011058 (Best: 0.0007820 @iter2740) ([92m↓14.48%[0m) [0.44% of initial]
[Iter 2780/20000] Loss: 0.0011058 (Best: 0.0007820 @iter2740) ([92m↓14.48%[0m) [0.44% of initial]
[Iter 2790/20000] Loss: 0.0011605 (Best: 0.0007820 @iter2740) ([91m↑4.95%[0m) [0.46% of initial]
[Iter 2790/20000] Loss: 0.0011605 (Best: 0.0007820 @iter2740) ([91m↑4.95%[0m) [0.46% of initial]
Iter:2799, L1 loss=0.001278, Total loss=0.001304, Time:16
Iter:2799, L1 loss=0.001278, Total loss=0.001304, Time:16
[Iter 2800/20000] Loss: 0.0011854 (Best: 0.0007820 @iter2740) ([91m↑2.15%[0m) [0.47% of initial]
[Iter 2800/20000] Loss: 0.0011854 (Best: 0.0007820 @iter2740) ([91m↑2.15%[0m) [0.47% of initial]
[Iter 2810/20000] Loss: 0.0050917 (Best: 0.0007820 @iter2740) ([91m↑329.52%[0m) [2.02% of initial]
[Iter 2810/20000] Loss: 0.0050917 (Best: 0.0007820 @iter2740) ([91m↑329.52%[0m) [2.02% of initial]
[Iter 2820/20000] Loss: 0.0027653 (Best: 0.0007820 @iter2740) ([92m↓45.69%[0m) [1.10% of initial]
[Iter 2820/20000] Loss: 0.0027653 (Best: 0.0007820 @iter2740) ([92m↓45.69%[0m) [1.10% of initial]
[Iter 2830/20000] Loss: 0.0018263 (Best: 0.0007820 @iter2740) ([92m↓33.95%[0m) [0.73% of initial]
[Iter 2830/20000] Loss: 0.0018263 (Best: 0.0007820 @iter2740) ([92m↓33.95%[0m) [0.73% of initial]
[Iter 2840/20000] Loss: 0.0015724 (Best: 0.0007820 @iter2740) ([92m↓13.90%[0m) [0.62% of initial]
[Iter 2840/20000] Loss: 0.0015724 (Best: 0.0007820 @iter2740) ([92m↓13.90%[0m) [0.62% of initial]
[Iter 2850/20000] Loss: 0.0013431 (Best: 0.0007820 @iter2740) ([92m↓14.58%[0m) [0.53% of initial]
[Iter 2850/20000] Loss: 0.0013431 (Best: 0.0007820 @iter2740) ([92m↓14.58%[0m) [0.53% of initial]
[Iter 2860/20000] Loss: 0.0014726 (Best: 0.0007820 @iter2740) ([91m↑9.64%[0m) [0.59% of initial]
[Iter 2860/20000] Loss: 0.0014726 (Best: 0.0007820 @iter2740) ([91m↑9.64%[0m) [0.59% of initial]
[Iter 2870/20000] Loss: 0.0012416 (Best: 0.0007820 @iter2740) ([92m↓15.69%[0m) [0.49% of initial]
[Iter 2870/20000] Loss: 0.0012416 (Best: 0.0007820 @iter2740) ([92m↓15.69%[0m) [0.49% of initial]
[Iter 2880/20000] Loss: 0.0011669 (Best: 0.0007820 @iter2740) ([92m↓6.02%[0m) [0.46% of initial]
[Iter 2880/20000] Loss: 0.0011669 (Best: 0.0007820 @iter2740) ([92m↓6.02%[0m) [0.46% of initial]
[Iter 2890/20000] Loss: 0.0011449 (Best: 0.0007820 @iter2740) ([92m↓1.88%[0m) [0.45% of initial]
[Iter 2890/20000] Loss: 0.0011449 (Best: 0.0007820 @iter2740) ([92m↓1.88%[0m) [0.45% of initial]
Iter:2899, L1 loss=0.0008878, Total loss=0.0008848, Time:19
Iter:2899, L1 loss=0.0008878, Total loss=0.0008848, Time:19
[Iter 2900/20000] Loss: 0.0010884 (Best: 0.0007820 @iter2740) ([92m↓4.94%[0m) [0.43% of initial]
[Iter 2900/20000] Loss: 0.0010884 (Best: 0.0007820 @iter2740) ([92m↓4.94%[0m) [0.43% of initial]
[Iter 2910/20000] Loss: 0.0011314 (Best: 0.0007820 @iter2740) ([91m↑3.94%[0m) [0.45% of initial]
[Iter 2910/20000] Loss: 0.0011314 (Best: 0.0007820 @iter2740) ([91m↑3.94%[0m) [0.45% of initial]
[Iter 2920/20000] Loss: 0.0011826 (Best: 0.0007820 @iter2740) ([91m↑4.53%[0m) [0.47% of initial]
[Iter 2920/20000] Loss: 0.0011826 (Best: 0.0007820 @iter2740) ([91m↑4.53%[0m) [0.47% of initial]
[Iter 2930/20000] Loss: 0.0011536 (Best: 0.0007820 @iter2740) ([92m↓2.45%[0m) [0.46% of initial]
[Iter 2930/20000] Loss: 0.0011536 (Best: 0.0007820 @iter2740) ([92m↓2.45%[0m) [0.46% of initial]
[Iter 2940/20000] Loss: 0.0009692 (Best: 0.0007820 @iter2740) ([92m↓15.98%[0m) [0.39% of initial]
[Iter 2940/20000] Loss: 0.0009692 (Best: 0.0007820 @iter2740) ([92m↓15.98%[0m) [0.39% of initial]
[Iter 2950/20000] Loss: 0.0009331 (Best: 0.0007767 @iter2950) ([92m↓3.73%[0m) [0.37% of initial]
[Iter 2950/20000] Loss: 0.0009331 (Best: 0.0007767 @iter2950) ([92m↓3.73%[0m) [0.37% of initial]
[Iter 2960/20000] Loss: 0.0010308 (Best: 0.0007767 @iter2950) ([91m↑10.48%[0m) [0.41% of initial]
[Iter 2960/20000] Loss: 0.0010308 (Best: 0.0007767 @iter2950) ([91m↑10.48%[0m) [0.41% of initial]
[Iter 2970/20000] Loss: 0.0009184 (Best: 0.0007197 @iter2969) ([92m↓10.91%[0m) [0.36% of initial]
[Iter 2970/20000] Loss: 0.0009184 (Best: 0.0007197 @iter2969) ([92m↓10.91%[0m) [0.36% of initial]
[Iter 2980/20000] Loss: 0.0008411 (Best: 0.0007197 @iter2969) ([92m↓8.42%[0m) [0.33% of initial]
[Iter 2980/20000] Loss: 0.0008411 (Best: 0.0007197 @iter2969) ([92m↓8.42%[0m) [0.33% of initial]
[Iter 2990/20000] Loss: 0.0009022 (Best: 0.0006887 @iter2983) ([91m↑7.26%[0m) [0.36% of initial]
[Iter 2990/20000] Loss: 0.0009022 (Best: 0.0006887 @iter2983) ([91m↑7.26%[0m) [0.36% of initial]
Iter:2999, L1 loss=0.0007087, Total loss=0.0006713, Time:18
Iter:2999, L1 loss=0.0007087, Total loss=0.0006713, Time:18
[Iter 3000/20000] Loss: 0.0008657 (Best: 0.0006713 @iter2999) ([92m↓4.04%[0m) [0.34% of initial]
[Iter 3000/20000] Loss: 0.0008657 (Best: 0.0006713 @iter2999) ([92m↓4.04%[0m) [0.34% of initial]
[Iter 3010/20000] Loss: 0.0046394 (Best: 0.0006713 @iter2999) ([91m↑435.91%[0m) [1.84% of initial]
[Iter 3010/20000] Loss: 0.0046394 (Best: 0.0006713 @iter2999) ([91m↑435.91%[0m) [1.84% of initial]
[Iter 3020/20000] Loss: 0.0027093 (Best: 0.0006713 @iter2999) ([92m↓41.60%[0m) [1.08% of initial]
[Iter 3020/20000] Loss: 0.0027093 (Best: 0.0006713 @iter2999) ([92m↓41.60%[0m) [1.08% of initial]
[Iter 3030/20000] Loss: 0.0021167 (Best: 0.0006713 @iter2999) ([92m↓21.87%[0m) [0.84% of initial]
[Iter 3030/20000] Loss: 0.0021167 (Best: 0.0006713 @iter2999) ([92m↓21.87%[0m) [0.84% of initial]
[Iter 3040/20000] Loss: 0.0016990 (Best: 0.0006713 @iter2999) ([92m↓19.73%[0m) [0.67% of initial]
[Iter 3040/20000] Loss: 0.0016990 (Best: 0.0006713 @iter2999) ([92m↓19.73%[0m) [0.67% of initial]
[Iter 3050/20000] Loss: 0.0014227 (Best: 0.0006713 @iter2999) ([92m↓16.26%[0m) [0.57% of initial]
[Iter 3050/20000] Loss: 0.0014227 (Best: 0.0006713 @iter2999) ([92m↓16.26%[0m) [0.57% of initial]
[Iter 3060/20000] Loss: 0.0013843 (Best: 0.0006713 @iter2999) ([92m↓2.70%[0m) [0.55% of initial]
[Iter 3060/20000] Loss: 0.0013843 (Best: 0.0006713 @iter2999) ([92m↓2.70%[0m) [0.55% of initial]
[Iter 3070/20000] Loss: 0.0011546 (Best: 0.0006713 @iter2999) ([92m↓16.59%[0m) [0.46% of initial]
[Iter 3070/20000] Loss: 0.0011546 (Best: 0.0006713 @iter2999) ([92m↓16.59%[0m) [0.46% of initial]
[Iter 3080/20000] Loss: 0.0011452 (Best: 0.0006713 @iter2999) ([92m↓0.81%[0m) [0.45% of initial]
[Iter 3080/20000] Loss: 0.0011452 (Best: 0.0006713 @iter2999) ([92m↓0.81%[0m) [0.45% of initial]
[Iter 3090/20000] Loss: 0.0010643 (Best: 0.0006713 @iter2999) ([92m↓7.07%[0m) [0.42% of initial]
[Iter 3090/20000] Loss: 0.0010643 (Best: 0.0006713 @iter2999) ([92m↓7.07%[0m) [0.42% of initial]
Iter:3099, L1 loss=0.0009215, Total loss=0.000855, Time:18
Iter:3099, L1 loss=0.0009215, Total loss=0.000855, Time:18
[Iter 3100/20000] Loss: 0.0010017 (Best: 0.0006713 @iter2999) ([92m↓5.88%[0m) [0.40% of initial]
[Iter 3100/20000] Loss: 0.0010017 (Best: 0.0006713 @iter2999) ([92m↓5.88%[0m) [0.40% of initial]
[Iter 3110/20000] Loss: 0.0010856 (Best: 0.0006713 @iter2999) ([91m↑8.37%[0m) [0.43% of initial]
[Iter 3110/20000] Loss: 0.0010856 (Best: 0.0006713 @iter2999) ([91m↑8.37%[0m) [0.43% of initial]
[Iter 3120/20000] Loss: 0.0010447 (Best: 0.0006713 @iter2999) ([92m↓3.76%[0m) [0.42% of initial]
[Iter 3120/20000] Loss: 0.0010447 (Best: 0.0006713 @iter2999) ([92m↓3.76%[0m) [0.42% of initial]
[Iter 3130/20000] Loss: 0.0008586 (Best: 0.0006713 @iter2999) ([92m↓17.82%[0m) [0.34% of initial]
[Iter 3130/20000] Loss: 0.0008586 (Best: 0.0006713 @iter2999) ([92m↓17.82%[0m) [0.34% of initial]
[Iter 3140/20000] Loss: 0.0008658 (Best: 0.0006713 @iter2999) ([91m↑0.84%[0m) [0.34% of initial]
[Iter 3140/20000] Loss: 0.0008658 (Best: 0.0006713 @iter2999) ([91m↑0.84%[0m) [0.34% of initial]
[Iter 3150/20000] Loss: 0.0008860 (Best: 0.0006713 @iter2999) ([91m↑2.33%[0m) [0.35% of initial]
[Iter 3150/20000] Loss: 0.0008860 (Best: 0.0006713 @iter2999) ([91m↑2.33%[0m) [0.35% of initial]
[Iter 3160/20000] Loss: 0.0008144 (Best: 0.0006713 @iter2999) ([92m↓8.08%[0m) [0.32% of initial]
[Iter 3160/20000] Loss: 0.0008144 (Best: 0.0006713 @iter2999) ([92m↓8.08%[0m) [0.32% of initial]
[Iter 3170/20000] Loss: 0.0008377 (Best: 0.0006713 @iter2999) ([91m↑2.86%[0m) [0.33% of initial]
[Iter 3170/20000] Loss: 0.0008377 (Best: 0.0006713 @iter2999) ([91m↑2.86%[0m) [0.33% of initial]
[Iter 3180/20000] Loss: 0.0008571 (Best: 0.0006713 @iter2999) ([91m↑2.32%[0m) [0.34% of initial]
[Iter 3180/20000] Loss: 0.0008571 (Best: 0.0006713 @iter2999) ([91m↑2.32%[0m) [0.34% of initial]
[Iter 3190/20000] Loss: 0.0008445 (Best: 0.0006713 @iter2999) ([92m↓1.47%[0m) [0.34% of initial]
[Iter 3190/20000] Loss: 0.0008445 (Best: 0.0006713 @iter2999) ([92m↓1.47%[0m) [0.34% of initial]
Iter:3199, L1 loss=0.0007892, Total loss=0.0007318, Time:18
Iter:3199, L1 loss=0.0007892, Total loss=0.0007318, Time:18
[Iter 3200/20000] Loss: 0.0008220 (Best: 0.0006418 @iter3196) ([92m↓2.66%[0m) [0.33% of initial]
[Iter 3200/20000] Loss: 0.0008220 (Best: 0.0006418 @iter3196) ([92m↓2.66%[0m) [0.33% of initial]
[Iter 3210/20000] Loss: 0.0052154 (Best: 0.0006418 @iter3196) ([91m↑534.43%[0m) [2.07% of initial]
[Iter 3210/20000] Loss: 0.0052154 (Best: 0.0006418 @iter3196) ([91m↑534.43%[0m) [2.07% of initial]
[Iter 3220/20000] Loss: 0.0028213 (Best: 0.0006418 @iter3196) ([92m↓45.90%[0m) [1.12% of initial]
[Iter 3220/20000] Loss: 0.0028213 (Best: 0.0006418 @iter3196) ([92m↓45.90%[0m) [1.12% of initial]
[Iter 3230/20000] Loss: 0.0017170 (Best: 0.0006418 @iter3196) ([92m↓39.14%[0m) [0.68% of initial]
[Iter 3230/20000] Loss: 0.0017170 (Best: 0.0006418 @iter3196) ([92m↓39.14%[0m) [0.68% of initial]
[Iter 3240/20000] Loss: 0.0015272 (Best: 0.0006418 @iter3196) ([92m↓11.05%[0m) [0.61% of initial]
[Iter 3240/20000] Loss: 0.0015272 (Best: 0.0006418 @iter3196) ([92m↓11.05%[0m) [0.61% of initial]
[Iter 3250/20000] Loss: 0.0011228 (Best: 0.0006418 @iter3196) ([92m↓26.48%[0m) [0.45% of initial]
[Iter 3250/20000] Loss: 0.0011228 (Best: 0.0006418 @iter3196) ([92m↓26.48%[0m) [0.45% of initial]
[Iter 3260/20000] Loss: 0.0009681 (Best: 0.0006418 @iter3196) ([92m↓13.77%[0m) [0.38% of initial]
[Iter 3260/20000] Loss: 0.0009681 (Best: 0.0006418 @iter3196) ([92m↓13.77%[0m) [0.38% of initial]
[Iter 3270/20000] Loss: 0.0010060 (Best: 0.0006418 @iter3196) ([91m↑3.91%[0m) [0.40% of initial]
[Iter 3270/20000] Loss: 0.0010060 (Best: 0.0006418 @iter3196) ([91m↑3.91%[0m) [0.40% of initial]
[Iter 3280/20000] Loss: 0.0010620 (Best: 0.0006418 @iter3196) ([91m↑5.57%[0m) [0.42% of initial]
[Iter 3280/20000] Loss: 0.0010620 (Best: 0.0006418 @iter3196) ([91m↑5.57%[0m) [0.42% of initial]
[Iter 3290/20000] Loss: 0.0008013 (Best: 0.0006418 @iter3196) ([92m↓24.55%[0m) [0.32% of initial]
[Iter 3290/20000] Loss: 0.0008013 (Best: 0.0006418 @iter3196) ([92m↓24.55%[0m) [0.32% of initial]
Iter:3299, L1 loss=0.001253, Total loss=0.001328, Time:15
Iter:3299, L1 loss=0.001253, Total loss=0.001328, Time:15
[Iter 3300/20000] Loss: 0.0010777 (Best: 0.0006418 @iter3196) ([91m↑34.49%[0m) [0.43% of initial]
[Iter 3300/20000] Loss: 0.0010777 (Best: 0.0006418 @iter3196) ([91m↑34.49%[0m) [0.43% of initial]
[Iter 3310/20000] Loss: 0.0008085 (Best: 0.0006418 @iter3196) ([92m↓24.98%[0m) [0.32% of initial]
[Iter 3310/20000] Loss: 0.0008085 (Best: 0.0006418 @iter3196) ([92m↓24.98%[0m) [0.32% of initial]
[Iter 3320/20000] Loss: 0.0009283 (Best: 0.0006418 @iter3196) ([91m↑14.82%[0m) [0.37% of initial]
[Iter 3320/20000] Loss: 0.0009283 (Best: 0.0006418 @iter3196) ([91m↑14.82%[0m) [0.37% of initial]
[Iter 3330/20000] Loss: 0.0009393 (Best: 0.0006418 @iter3196) ([91m↑1.18%[0m) [0.37% of initial]
[Iter 3330/20000] Loss: 0.0009393 (Best: 0.0006418 @iter3196) ([91m↑1.18%[0m) [0.37% of initial]
[Iter 3340/20000] Loss: 0.0010740 (Best: 0.0006418 @iter3196) ([91m↑14.35%[0m) [0.43% of initial]
[Iter 3340/20000] Loss: 0.0010740 (Best: 0.0006418 @iter3196) ([91m↑14.35%[0m) [0.43% of initial]
[Iter 3350/20000] Loss: 0.0008690 (Best: 0.0006418 @iter3196) ([92m↓19.09%[0m) [0.35% of initial]
[Iter 3350/20000] Loss: 0.0008690 (Best: 0.0006418 @iter3196) ([92m↓19.09%[0m) [0.35% of initial]
[Iter 3360/20000] Loss: 0.0011032 (Best: 0.0006418 @iter3196) ([91m↑26.95%[0m) [0.44% of initial]
[Iter 3360/20000] Loss: 0.0011032 (Best: 0.0006418 @iter3196) ([91m↑26.95%[0m) [0.44% of initial]
[Iter 3370/20000] Loss: 0.0007862 (Best: 0.0006418 @iter3196) ([92m↓28.74%[0m) [0.31% of initial]
[Iter 3370/20000] Loss: 0.0007862 (Best: 0.0006418 @iter3196) ([92m↓28.74%[0m) [0.31% of initial]
[Iter 3380/20000] Loss: 0.0007741 (Best: 0.0006289 @iter3379) ([92m↓1.54%[0m) [0.31% of initial]
[Iter 3380/20000] Loss: 0.0007741 (Best: 0.0006289 @iter3379) ([92m↓1.54%[0m) [0.31% of initial]
[Iter 3390/20000] Loss: 0.0010080 (Best: 0.0006289 @iter3379) ([91m↑30.23%[0m) [0.40% of initial]
[Iter 3390/20000] Loss: 0.0010080 (Best: 0.0006289 @iter3379) ([91m↑30.23%[0m) [0.40% of initial]
Iter:3399, L1 loss=0.001241, Total loss=0.00124, Time:18
Iter:3399, L1 loss=0.001241, Total loss=0.00124, Time:18
[Iter 3400/20000] Loss: 0.0010314 (Best: 0.0006289 @iter3379) ([91m↑2.32%[0m) [0.41% of initial]
[Iter 3400/20000] Loss: 0.0010314 (Best: 0.0006289 @iter3379) ([91m↑2.32%[0m) [0.41% of initial]
[Iter 3410/20000] Loss: 0.0043589 (Best: 0.0006289 @iter3379) ([91m↑322.61%[0m) [1.73% of initial]
[Iter 3410/20000] Loss: 0.0043589 (Best: 0.0006289 @iter3379) ([91m↑322.61%[0m) [1.73% of initial]
[Iter 3420/20000] Loss: 0.0023098 (Best: 0.0006289 @iter3379) ([92m↓47.01%[0m) [0.92% of initial]
[Iter 3420/20000] Loss: 0.0023098 (Best: 0.0006289 @iter3379) ([92m↓47.01%[0m) [0.92% of initial]
[Iter 3430/20000] Loss: 0.0015330 (Best: 0.0006289 @iter3379) ([92m↓33.63%[0m) [0.61% of initial]
[Iter 3430/20000] Loss: 0.0015330 (Best: 0.0006289 @iter3379) ([92m↓33.63%[0m) [0.61% of initial]
[Iter 3440/20000] Loss: 0.0013342 (Best: 0.0006289 @iter3379) ([92m↓12.96%[0m) [0.53% of initial]
[Iter 3440/20000] Loss: 0.0013342 (Best: 0.0006289 @iter3379) ([92m↓12.96%[0m) [0.53% of initial]
[Iter 3450/20000] Loss: 0.0011990 (Best: 0.0006289 @iter3379) ([92m↓10.14%[0m) [0.48% of initial]
[Iter 3450/20000] Loss: 0.0011990 (Best: 0.0006289 @iter3379) ([92m↓10.14%[0m) [0.48% of initial]
[Iter 3460/20000] Loss: 0.0010892 (Best: 0.0006289 @iter3379) ([92m↓9.16%[0m) [0.43% of initial]
[Iter 3460/20000] Loss: 0.0010892 (Best: 0.0006289 @iter3379) ([92m↓9.16%[0m) [0.43% of initial]
[Iter 3470/20000] Loss: 0.0009957 (Best: 0.0006289 @iter3379) ([92m↓8.58%[0m) [0.40% of initial]
[Iter 3470/20000] Loss: 0.0009957 (Best: 0.0006289 @iter3379) ([92m↓8.58%[0m) [0.40% of initial]
[Iter 3480/20000] Loss: 0.0009311 (Best: 0.0006289 @iter3379) ([92m↓6.49%[0m) [0.37% of initial]
[Iter 3480/20000] Loss: 0.0009311 (Best: 0.0006289 @iter3379) ([92m↓6.49%[0m) [0.37% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327878 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123922 (Best: 0.1098378 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993461 (Best: 0.0965453 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936759 (Best: 0.0908450 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884556 (Best: 0.0869402 @iter70) ([92m↓5.57%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851898 (Best: 0.0831016 @iter80) ([92m↓3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824184 (Best: 0.0801595 @iter88) ([92m↓3.25%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07877, Time:13
[Iter 100/20000] Loss: 0.0786774 (Best: 0.0766314 @iter97) ([92m↓4.54%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753295 (Best: 0.0731336 @iter106) ([92m↓4.26%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714518 (Best: 0.0685731 @iter118) ([92m↓5.15%[0m) [28.39% of initial]
[Iter 130/20000] Loss: 0.0667159 (Best: 0.0642162 @iter130) ([92m↓6.63%[0m) [26.51% of initial]
[Iter 140/20000] Loss: 0.0635590 (Best: 0.0613103 @iter140) ([92m↓4.73%[0m) [25.25% of initial]
[Iter 150/20000] Loss: 0.0613015 (Best: 0.0584095 @iter148) ([92m↓3.55%[0m) [24.35% of initial]
[Iter 160/20000] Loss: 0.0590986 (Best: 0.0559598 @iter157) ([92m↓3.59%[0m) [23.48% of initial]
[Iter 170/20000] Loss: 0.0564072 (Best: 0.0535446 @iter167) ([92m↓4.55%[0m) [22.41% of initial]
[Iter 180/20000] Loss: 0.0523819 (Best: 0.0500636 @iter179) ([92m↓7.14%[0m) [20.81% of initial]
[Iter 190/20000] Loss: 0.0495916 (Best: 0.0478368 @iter188) ([92m↓5.33%[0m) [19.70% of initial]
Iter:199, L1 loss=0.03439, Total loss=0.04979, Time:13
[Iter 200/20000] Loss: 0.0478299 (Best: 0.0457557 @iter198) ([92m↓3.55%[0m) [19.00% of initial]
[Iter 210/20000] Loss: 0.0450539 (Best: 0.0428284 @iter209) ([92m↓5.80%[0m) [17.90% of initial]
[Iter 220/20000] Loss: 0.0440717 (Best: 0.0412574 @iter219) ([92m↓2.18%[0m) [17.51% of initial]
[Iter 230/20000] Loss: 0.0422844 (Best: 0.0398593 @iter227) ([92m↓4.06%[0m) [16.80% of initial]
[Iter 240/20000] Loss: 0.0402716 (Best: 0.0377602 @iter238) ([92m↓4.76%[0m) [16.00% of initial]
[Iter 250/20000] Loss: 0.0379821 (Best: 0.0362288 @iter248) ([92m↓5.68%[0m) [15.09% of initial]
[Iter 260/20000] Loss: 0.0359069 (Best: 0.0343433 @iter260) ([92m↓5.46%[0m) [14.27% of initial]
[Iter 270/20000] Loss: 0.0349451 (Best: 0.0328457 @iter269) ([92m↓2.68%[0m) [13.88% of initial]
[Iter 280/20000] Loss: 0.0346833 (Best: 0.0316945 @iter277) ([92m↓0.75%[0m) [13.78% of initial]
[Iter 290/20000] Loss: 0.0331149 (Best: 0.0304131 @iter287) ([92m↓4.52%[0m) [13.16% of initial]
Iter:299, L1 loss=0.02212, Total loss=0.03347, Time:13
[Iter 300/20000] Loss: 0.0308962 (Best: 0.0289975 @iter300) ([92m↓6.70%[0m) [12.27% of initial]
[Iter 310/20000] Loss: 0.0294044 (Best: 0.0274145 @iter310) ([92m↓4.83%[0m) [11.68% of initial]
[Iter 320/20000] Loss: 0.0279572 (Best: 0.0266253 @iter320) ([92m↓4.92%[0m) [11.11% of initial]
[Iter 330/20000] Loss: 0.0275480 (Best: 0.0256602 @iter330) ([92m↓1.46%[0m) [10.94% of initial]
[Iter 340/20000] Loss: 0.0255335 (Best: 0.0244979 @iter340) ([92m↓7.31%[0m) [10.14% of initial]
[Iter 350/20000] Loss: 0.0261390 (Best: 0.0235734 @iter349) ([91m↑2.37%[0m) [10.38% of initial]
[Iter 360/20000] Loss: 0.0248085 (Best: 0.0227957 @iter358) ([92m↓5.09%[0m) [9.86% of initial]
[Iter 370/20000] Loss: 0.0245300 (Best: 0.0222807 @iter368) ([92m↓1.12%[0m) [9.75% of initial]
[Iter 380/20000] Loss: 0.0221990 (Best: 0.0210888 @iter379) ([92m↓9.50%[0m) [8.82% of initial]
[Iter 390/20000] Loss: 0.0216734 (Best: 0.0202980 @iter385) ([92m↓2.37%[0m) [8.61% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179126 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693029 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374910 (Best: 0.1327884 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123923 (Best: 0.1098377 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993442 (Best: 0.0965458 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936773 (Best: 0.0908518 @iter59) ([92m↓5.70%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884541 (Best: 0.0869403 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851913 (Best: 0.0831070 @iter80) ([92m↓3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824093 (Best: 0.0801457 @iter88) ([92m↓3.27%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07877, Time:15
[Iter 100/20000] Loss: 0.0786736 (Best: 0.0766262 @iter97) ([92m↓4.53%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753214 (Best: 0.0731315 @iter106) ([92m↓4.26%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714356 (Best: 0.0685524 @iter118) ([92m↓5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0667052 (Best: 0.0641990 @iter130) ([92m↓6.62%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635378 (Best: 0.0612905 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612754 (Best: 0.0583912 @iter148) ([92m↓3.56%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590545 (Best: 0.0559516 @iter157) ([92m↓3.62%[0m) [23.46% of initial]
[Iter 170/20000] Loss: 0.0563547 (Best: 0.0535233 @iter167) ([92m↓4.57%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523423 (Best: 0.0500117 @iter179) ([92m↓7.12%[0m) [20.80% of initial]
[Iter 190/20000] Loss: 0.0495550 (Best: 0.0478360 @iter188) ([92m↓5.33%[0m) [19.69% of initial]
Iter:199, L1 loss=0.0345, Total loss=0.04972, Time:15
[Iter 200/20000] Loss: 0.0478118 (Best: 0.0456420 @iter198) ([92m↓3.52%[0m) [19.00% of initial]
[Iter 210/20000] Loss: 0.0450592 (Best: 0.0428094 @iter209) ([92m↓5.76%[0m) [17.90% of initial]
[Iter 220/20000] Loss: 0.0440960 (Best: 0.0412433 @iter219) ([92m↓2.14%[0m) [17.52% of initial]
[Iter 230/20000] Loss: 0.0423347 (Best: 0.0399214 @iter227) ([92m↓3.99%[0m) [16.82% of initial]
[Iter 240/20000] Loss: 0.0402544 (Best: 0.0377645 @iter238) ([92m↓4.91%[0m) [15.99% of initial]
[Iter 250/20000] Loss: 0.0378963 (Best: 0.0362103 @iter248) ([92m↓5.86%[0m) [15.06% of initial]
[Iter 260/20000] Loss: 0.0358194 (Best: 0.0343163 @iter260) ([92m↓5.48%[0m) [14.23% of initial]
[Iter 270/20000] Loss: 0.0349925 (Best: 0.0328234 @iter269) ([92m↓2.31%[0m) [13.90% of initial]
[Iter 280/20000] Loss: 0.0346987 (Best: 0.0318360 @iter277) ([92m↓0.84%[0m) [13.79% of initial]
[Iter 290/20000] Loss: 0.0329342 (Best: 0.0303293 @iter287) ([92m↓5.09%[0m) [13.08% of initial]
Iter:299, L1 loss=0.02213, Total loss=0.03328, Time:14
[Iter 300/20000] Loss: 0.0307077 (Best: 0.0288353 @iter300) ([92m↓6.76%[0m) [12.20% of initial]
[Iter 310/20000] Loss: 0.0293528 (Best: 0.0274127 @iter310) ([92m↓4.41%[0m) [11.66% of initial]
[Iter 320/20000] Loss: 0.0278957 (Best: 0.0264356 @iter320) ([92m↓4.96%[0m) [11.08% of initial]
[Iter 330/20000] Loss: 0.0274280 (Best: 0.0255223 @iter330) ([92m↓1.68%[0m) [10.90% of initial]
[Iter 340/20000] Loss: 0.0254151 (Best: 0.0242836 @iter340) ([92m↓7.34%[0m) [10.10% of initial]
[Iter 350/20000] Loss: 0.0262118 (Best: 0.0236180 @iter349) ([91m↑3.13%[0m) [10.41% of initial]
[Iter 360/20000] Loss: 0.0247579 (Best: 0.0228129 @iter358) ([92m↓5.55%[0m) [9.84% of initial]
[Iter 370/20000] Loss: 0.0245303 (Best: 0.0220905 @iter368) ([92m↓0.92%[0m) [9.75% of initial]
[Iter 380/20000] Loss: 0.0222081 (Best: 0.0208801 @iter379) ([92m↓9.47%[0m) [8.82% of initial]
[Iter 390/20000] Loss: 0.0215881 (Best: 0.0201034 @iter385) ([92m↓2.79%[0m) [8.58% of initial]
Iter:399, L1 loss=0.0135, Total loss=0.02074, Time:14
[Iter 400/20000] Loss: 0.0201813 (Best: 0.0188199 @iter400) ([92m↓6.52%[0m) [8.02% of initial]
[Iter 410/20000] Loss: 0.0194163 (Best: 0.0184918 @iter410) ([92m↓3.79%[0m) [7.71% of initial]
[Iter 420/20000] Loss: 0.0196879 (Best: 0.0176556 @iter418) ([91m↑1.40%[0m) [7.82% of initial]
[Iter 430/20000] Loss: 0.0176803 (Best: 0.0168277 @iter430) ([92m↓10.20%[0m) [7.02% of initial]
[Iter 440/20000] Loss: 0.0179882 (Best: 0.0163067 @iter438) ([91m↑1.74%[0m) [7.15% of initial]
[Iter 450/20000] Loss: 0.0169663 (Best: 0.0150741 @iter449) ([92m↓5.68%[0m) [6.74% of initial]
[Iter 460/20000] Loss: 0.0163023 (Best: 0.0145428 @iter458) ([92m↓3.91%[0m) [6.48% of initial]
[Iter 470/20000] Loss: 0.0150412 (Best: 0.0141654 @iter470) ([92m↓7.74%[0m) [5.98% of initial]
[Iter 480/20000] Loss: 0.0145188 (Best: 0.0132563 @iter479) ([92m↓3.47%[0m) [5.77% of initial]
[Iter 490/20000] Loss: 0.0133655 (Best: 0.0123795 @iter490) ([92m↓7.94%[0m) [5.31% of initial]
Iter:499, L1 loss=0.009606, Total loss=0.01424, Time:14
[Iter 500/20000] Loss: 0.0133361 (Best: 0.0123666 @iter498) ([92m↓0.22%[0m) [5.30% of initial]
[Iter 510/20000] Loss: 0.0129957 (Best: 0.0116650 @iter508) ([92m↓2.55%[0m) [5.16% of initial]
[Iter 520/20000] Loss: 0.0125337 (Best: 0.0112668 @iter514) ([92m↓3.55%[0m) [4.98% of initial]
[Iter 530/20000] Loss: 0.0124352 (Best: 0.0112668 @iter514) ([92m↓0.79%[0m) [4.94% of initial]
[Iter 540/20000] Loss: 0.0123632 (Best: 0.0110053 @iter538) ([92m↓0.58%[0m) [4.91% of initial]
[Iter 550/20000] Loss: 0.0120421 (Best: 0.0108774 @iter548) ([92m↓2.60%[0m) [4.78% of initial]
[Iter 560/20000] Loss: 0.0121320 (Best: 0.0105929 @iter556) ([91m↑0.75%[0m) [4.82% of initial]
[Iter 570/20000] Loss: 0.0115544 (Best: 0.0103515 @iter569) ([92m↓4.76%[0m) [4.59% of initial]
[Iter 580/20000] Loss: 0.0112463 (Best: 0.0101078 @iter578) ([92m↓2.67%[0m) [4.47% of initial]
[Iter 590/20000] Loss: 0.0111812 (Best: 0.0098618 @iter583) ([92m↓0.58%[0m) [4.44% of initial]
Iter:599, L1 loss=0.006972, Total loss=0.01181, Time:14
[Iter 600/20000] Loss: 0.0108481 (Best: 0.0098265 @iter598) ([92m↓2.98%[0m) [4.31% of initial]
[Iter 610/20000] Loss: 0.0219235 (Best: 0.0098265 @iter598) ([91m↑102.10%[0m) [8.71% of initial]
[Iter 620/20000] Loss: 0.0139308 (Best: 0.0098265 @iter598) ([92m↓36.46%[0m) [5.53% of initial]
[Iter 630/20000] Loss: 0.0113820 (Best: 0.0098265 @iter598) ([92m↓18.30%[0m) [4.52% of initial]
[Iter 640/20000] Loss: 0.0097134 (Best: 0.0087348 @iter640) ([92m↓14.66%[0m) [3.86% of initial]
[Iter 650/20000] Loss: 0.0101924 (Best: 0.0087348 @iter640) ([91m↑4.93%[0m) [4.05% of initial]
[Iter 660/20000] Loss: 0.0098577 (Best: 0.0086701 @iter655) ([92m↓3.28%[0m) [3.92% of initial]
[Iter 670/20000] Loss: 0.0095230 (Best: 0.0085171 @iter662) ([92m↓3.40%[0m) [3.78% of initial]
[Iter 680/20000] Loss: 0.0087994 (Best: 0.0081828 @iter680) ([92m↓7.60%[0m) [3.50% of initial]
[Iter 690/20000] Loss: 0.0090191 (Best: 0.0078638 @iter685) ([91m↑2.50%[0m) [3.58% of initial]
Iter:699, L1 loss=0.005709, Total loss=0.009483, Time:14
[Iter 700/20000] Loss: 0.0086682 (Best: 0.0077984 @iter695) ([92m↓3.89%[0m) [3.44% of initial]
[Iter 710/20000] Loss: 0.0081832 (Best: 0.0075088 @iter703) ([92m↓5.60%[0m) [3.25% of initial]
[Iter 720/20000] Loss: 0.0083543 (Best: 0.0075088 @iter703) ([91m↑2.09%[0m) [3.32% of initial]
[Iter 730/20000] Loss: 0.0084563 (Best: 0.0072739 @iter727) ([91m↑1.22%[0m) [3.36% of initial]
[Iter 740/20000] Loss: 0.0085234 (Best: 0.0072609 @iter736) ([91m↑0.79%[0m) [3.39% of initial]
[Iter 750/20000] Original Loss: 0.0079809 Pseudo Loss: 0.0006230 (7.81% of original) (Best: 0.0070075 @iter748) ([92m↓6.36%[0m) [3.17% of initial]
[Iter 760/20000] Original Loss: 0.0075642 Pseudo Loss: 0.0006230 (8.24% of original) (Best: 0.0069672 @iter751) ([92m↓5.22%[0m) [3.01% of initial]
[Iter 770/20000] Original Loss: 0.0075694 Pseudo Loss: 0.0006230 (8.23% of original) (Best: 0.0069672 @iter751) ([91m↑0.07%[0m) [3.01% of initial]
[Iter 780/20000] Original Loss: 0.0077240 Pseudo Loss: 0.0006230 (8.07% of original) (Best: 0.0066586 @iter778) ([91m↑2.04%[0m) [3.07% of initial]
[Iter 790/20000] Original Loss: 0.0075748 Pseudo Loss: 0.0006230 (8.22% of original) (Best: 0.0065663 @iter787) ([92m↓1.93%[0m) [3.01% of initial]
Iter:799, L1 loss=0.005173, Total loss=0.008172, Time:13
[Iter 800/20000] Original Loss: 0.0073677 Pseudo Loss: 0.0009475 (12.86% of original) (Best: 0.0065663 @iter787) ([92m↓2.73%[0m) [2.93% of initial]
[Iter 810/20000] Original Loss: 0.0176260 Pseudo Loss: 0.0009475 (5.38% of original) (Best: 0.0065663 @iter787) ([91m↑139.24%[0m) [7.00% of initial]
[Iter 820/20000] Original Loss: 0.0110942 Pseudo Loss: 0.0009475 (8.54% of original) (Best: 0.0065663 @iter787) ([92m↓37.06%[0m) [4.41% of initial]
[Iter 830/20000] Original Loss: 0.0089393 Pseudo Loss: 0.0009475 (10.60% of original) (Best: 0.0065663 @iter787) ([92m↓19.42%[0m) [3.55% of initial]
[Iter 840/20000] Original Loss: 0.0080431 Pseudo Loss: 0.0009475 (11.78% of original) (Best: 0.0065663 @iter787) ([92m↓10.03%[0m) [3.20% of initial]
[Iter 850/20000] Original Loss: 0.0074344 Pseudo Loss: 0.0009475 (12.74% of original) (Best: 0.0065663 @iter787) ([92m↓7.57%[0m) [2.95% of initial]
[Iter 860/20000] Original Loss: 0.0069914 Pseudo Loss: 0.0009475 (13.55% of original) (Best: 0.0061829 @iter856) ([92m↓5.96%[0m) [2.78% of initial]
[Iter 870/20000] Original Loss: 0.0066168 Pseudo Loss: 0.0009475 (14.32% of original) (Best: 0.0060683 @iter862) ([92m↓5.36%[0m) [2.63% of initial]
[Iter 880/20000] Original Loss: 0.0066689 Pseudo Loss: 0.0009475 (14.21% of original) (Best: 0.0058796 @iter875) ([91m↑0.79%[0m) [2.65% of initial]
[Iter 890/20000] Original Loss: 0.0063531 Pseudo Loss: 0.0009475 (14.91% of original) (Best: 0.0057174 @iter884) ([92m↓4.73%[0m) [2.52% of initial]
Iter:899, L1 loss=0.003843, Total loss=0.005669, Time:13
[Iter 900/20000] Original Loss: 0.0064935 Pseudo Loss: 0.0009475 (14.59% of original) (Best: 0.0056691 @iter899) ([91m↑2.21%[0m) [2.58% of initial]
[Iter 910/20000] Original Loss: 0.0064959 Pseudo Loss: 0.0009475 (14.59% of original) (Best: 0.0054179 @iter907) ([91m↑0.04%[0m) [2.58% of initial]
[Iter 920/20000] Original Loss: 0.0059476 Pseudo Loss: 0.0009475 (15.93% of original) (Best: 0.0053485 @iter919) ([92m↓8.44%[0m) [2.36% of initial]
[Iter 930/20000] Original Loss: 0.0062029 Pseudo Loss: 0.0009475 (15.27% of original) (Best: 0.0052557 @iter925) ([91m↑4.29%[0m) [2.46% of initial]
[Iter 940/20000] Original Loss: 0.0062181 Pseudo Loss: 0.0009475 (15.24% of original) (Best: 0.0051307 @iter938) ([91m↑0.24%[0m) [2.47% of initial]
[Iter 950/20000] Original Loss: 0.0057619 Pseudo Loss: 0.0009475 (16.44% of original) (Best: 0.0051307 @iter938) ([92m↓7.34%[0m) [2.29% of initial]
[Iter 960/20000] Original Loss: 0.0059027 Pseudo Loss: 0.0009475 (16.05% of original) (Best: 0.0051307 @iter938) ([91m↑2.44%[0m) [2.35% of initial]
[Iter 970/20000] Original Loss: 0.0058900 Pseudo Loss: 0.0009475 (16.09% of original) (Best: 0.0051088 @iter964) ([92m↓0.21%[0m) [2.34% of initial]
[Iter 980/20000] Original Loss: 0.0059316 Pseudo Loss: 0.0009475 (15.97% of original) (Best: 0.0051088 @iter964) ([91m↑0.71%[0m) [2.36% of initial]
[Iter 990/20000] Original Loss: 0.0060478 Pseudo Loss: 0.0009475 (15.67% of original) (Best: 0.0051088 @iter964) ([91m↑1.96%[0m) [2.40% of initial]
Iter:999, L1 loss=0.004458, Total loss=0.006571, Time:13
[Iter 1000/20000] Original Loss: 0.0062016 Pseudo Loss: 0.0009475 (15.28% of original) (Best: 0.0051088 @iter964) ([91m↑2.54%[0m) [2.46% of initial]
[Iter 1010/20000] Original Loss: 0.0119825 Pseudo Loss: 0.0009475 (7.91% of original) (Best: 0.0051088 @iter964) ([91m↑93.22%[0m) [4.76% of initial]
[Iter 1020/20000] Original Loss: 0.0082529 Pseudo Loss: 0.0009475 (11.48% of original) (Best: 0.0051088 @iter964) ([92m↓31.13%[0m) [3.28% of initial]
[Iter 1030/20000] Original Loss: 0.0066951 Pseudo Loss: 0.0009475 (14.15% of original) (Best: 0.0051088 @iter964) ([92m↓18.87%[0m) [2.66% of initial]
[Iter 1040/20000] Original Loss: 0.0058962 Pseudo Loss: 0.0009475 (16.07% of original) (Best: 0.0051088 @iter964) ([92m↓11.93%[0m) [2.34% of initial]
[Iter 1050/20000] Original Loss: 0.0057196 Pseudo Loss: 0.0009475 (16.57% of original) (Best: 0.0049610 @iter1049) ([92m↓2.99%[0m) [2.27% of initial]
[Iter 1060/20000] Original Loss: 0.0056073 Pseudo Loss: 0.0009475 (16.90% of original) (Best: 0.0047969 @iter1051) ([92m↓1.96%[0m) [2.23% of initial]
[Iter 1070/20000] Original Loss: 0.0053432 Pseudo Loss: 0.0009475 (17.73% of original) (Best: 0.0044006 @iter1066) ([92m↓4.71%[0m) [2.12% of initial]
[Iter 1080/20000] Original Loss: 0.0051923 Pseudo Loss: 0.0011391 (21.94% of original) (Best: 0.0044006 @iter1066) ([92m↓2.82%[0m) [2.06% of initial]
[Iter 1090/20000] Original Loss: 0.0049910 Pseudo Loss: 0.0011391 (22.82% of original) (Best: 0.0044006 @iter1066) ([92m↓3.88%[0m) [1.98% of initial]
Iter:1099, L1 loss=0.003416, Total loss=0.004976, Time:14
[Iter 1100/20000] Original Loss: 0.0048783 Pseudo Loss: 0.0011391 (23.35% of original) (Best: 0.0041829 @iter1093) ([92m↓2.26%[0m) [1.94% of initial]
[Iter 1110/20000] Original Loss: 0.0049788 Pseudo Loss: 0.0011391 (22.88% of original) (Best: 0.0041829 @iter1093) ([91m↑2.06%[0m) [1.98% of initial]
[Iter 1120/20000] Original Loss: 0.0049953 Pseudo Loss: 0.0011391 (22.80% of original) (Best: 0.0040554 @iter1117) ([91m↑0.33%[0m) [1.98% of initial]
[Iter 1130/20000] Original Loss: 0.0051960 Pseudo Loss: 0.0011391 (21.92% of original) (Best: 0.0040554 @iter1117) ([91m↑4.02%[0m) [2.06% of initial]
[Iter 1140/20000] Original Loss: 0.0047054 Pseudo Loss: 0.0011391 (24.21% of original) (Best: 0.0040135 @iter1135) ([92m↓9.44%[0m) [1.87% of initial]
[Iter 1150/20000] Original Loss: 0.0043500 Pseudo Loss: 0.0011391 (26.19% of original) (Best: 0.0039109 @iter1145) ([92m↓7.55%[0m) [1.73% of initial]
[Iter 1160/20000] Original Loss: 0.0049763 Pseudo Loss: 0.0011391 (22.89% of original) (Best: 0.0039109 @iter1145) ([91m↑14.40%[0m) [1.98% of initial]
[Iter 1170/20000] Original Loss: 0.0045984 Pseudo Loss: 0.0011391 (24.77% of original) (Best: 0.0039109 @iter1145) ([92m↓7.59%[0m) [1.83% of initial]
[Iter 1180/20000] Original Loss: 0.0042943 Pseudo Loss: 0.0011391 (26.53% of original) (Best: 0.0038771 @iter1180) ([92m↓6.61%[0m) [1.71% of initial]
[Iter 1190/20000] Original Loss: 0.0046151 Pseudo Loss: 0.0011391 (24.68% of original) (Best: 0.0038657 @iter1186) ([91m↑7.47%[0m) [1.83% of initial]
Iter:1199, L1 loss=0.003455, Total loss=0.004822, Time:12
[Iter 1200/20000] Original Loss: 0.0045219 Pseudo Loss: 0.0011391 (25.19% of original) (Best: 0.0037503 @iter1195) ([92m↓2.02%[0m) [1.80% of initial]
[Iter 1210/20000] Original Loss: 0.0104866 Pseudo Loss: 0.0011391 (10.86% of original) (Best: 0.0037503 @iter1195) ([91m↑131.91%[0m) [4.17% of initial]
[Iter 1220/20000] Original Loss: 0.0070417 Pseudo Loss: 0.0011391 (16.18% of original) (Best: 0.0037503 @iter1195) ([92m↓32.85%[0m) [2.80% of initial]
[Iter 1230/20000] Original Loss: 0.0059679 Pseudo Loss: 0.0011391 (19.09% of original) (Best: 0.0037503 @iter1195) ([92m↓15.25%[0m) [2.37% of initial]
[Iter 1240/20000] Original Loss: 0.0053647 Pseudo Loss: 0.0011391 (21.23% of original) (Best: 0.0037503 @iter1195) ([92m↓10.11%[0m) [2.13% of initial]
[Iter 1250/20000] Original Loss: 0.0047608 Pseudo Loss: 0.0011391 (23.93% of original) (Best: 0.0037503 @iter1195) ([92m↓11.26%[0m) [1.89% of initial]
[Iter 1260/20000] Original Loss: 0.0045834 Pseudo Loss: 0.0011391 (24.85% of original) (Best: 0.0036406 @iter1258) ([92m↓3.73%[0m) [1.82% of initial]
[Iter 1270/20000] Original Loss: 0.0040941 Pseudo Loss: 0.0011391 (27.82% of original) (Best: 0.0036406 @iter1258) ([92m↓10.67%[0m) [1.63% of initial]
[Iter 1280/20000] Original Loss: 0.0042822 Pseudo Loss: 0.0011391 (26.60% of original) (Best: 0.0034541 @iter1273) ([91m↑4.59%[0m) [1.70% of initial]
[Iter 1290/20000] Original Loss: 0.0041553 Pseudo Loss: 0.0011391 (27.41% of original) (Best: 0.0033003 @iter1285) ([92m↓2.96%[0m) [1.65% of initial]
Iter:1299, L1 loss=0.002749, Total loss=0.003566, Time:15
[Iter 1300/20000] Original Loss: 0.0039019 Pseudo Loss: 0.0011391 (29.19% of original) (Best: 0.0033003 @iter1285) ([92m↓6.10%[0m) [1.55% of initial]
[Iter 1310/20000] Original Loss: 0.0039406 Pseudo Loss: 0.0011391 (28.91% of original) (Best: 0.0033003 @iter1285) ([91m↑0.99%[0m) [1.57% of initial]
[Iter 1320/20000] Original Loss: 0.0038208 Pseudo Loss: 0.0011391 (29.81% of original) (Best: 0.0030676 @iter1319) ([92m↓3.04%[0m) [1.52% of initial]
[Iter 1330/20000] Original Loss: 0.0038777 Pseudo Loss: 0.0011391 (29.37% of original) (Best: 0.0030050 @iter1321) ([91m↑1.49%[0m) [1.54% of initial]
[Iter 1340/20000] Original Loss: 0.0036198 Pseudo Loss: 0.0011391 (31.47% of original) (Best: 0.0030050 @iter1321) ([92m↓6.65%[0m) [1.44% of initial]
[Iter 1350/20000] Original Loss: 0.0036390 Pseudo Loss: 0.0011391 (31.30% of original) (Best: 0.0030050 @iter1321) ([91m↑0.53%[0m) [1.45% of initial]
[Iter 1360/20000] Original Loss: 0.0037657 Pseudo Loss: 0.0011391 (30.25% of original) (Best: 0.0030050 @iter1321) ([91m↑3.48%[0m) [1.50% of initial]
[Iter 1370/20000] Original Loss: 0.0036094 Pseudo Loss: 0.0011391 (31.56% of original) (Best: 0.0030050 @iter1321) ([92m↓4.15%[0m) [1.43% of initial]
[Iter 1380/20000] Original Loss: 0.0039169 Pseudo Loss: 0.0011391 (29.08% of original) (Best: 0.0030050 @iter1321) ([91m↑8.52%[0m) [1.56% of initial]
[Iter 1390/20000] Original Loss: 0.0036564 Pseudo Loss: 0.0011391 (31.15% of original) (Best: 0.0030050 @iter1321) ([92m↓6.65%[0m) [1.45% of initial]
Iter:1399, L1 loss=0.002306, Total loss=0.002896, Time:13
[Iter 1400/20000] Original Loss: 0.0033707 Pseudo Loss: 0.0011391 (33.79% of original) (Best: 0.0028955 @iter1399) ([92m↓7.81%[0m) [1.34% of initial]
[Iter 1410/20000] Original Loss: 0.0086703 Pseudo Loss: 0.0011391 (13.14% of original) (Best: 0.0028955 @iter1399) ([91m↑157.22%[0m) [3.44% of initial]
[Iter 1420/20000] Original Loss: 0.0057129 Pseudo Loss: 0.0011391 (19.94% of original) (Best: 0.0028955 @iter1399) ([92m↓34.11%[0m) [2.27% of initial]
[Iter 1430/20000] Original Loss: 0.0048587 Pseudo Loss: 0.0011391 (23.44% of original) (Best: 0.0028955 @iter1399) ([92m↓14.95%[0m) [1.93% of initial]
[Iter 1440/20000] Original Loss: 0.0043162 Pseudo Loss: 0.0011391 (26.39% of original) (Best: 0.0028955 @iter1399) ([92m↓11.16%[0m) [1.71% of initial]
[Iter 1450/20000] Original Loss: 0.0035330 Pseudo Loss: 0.0011391 (32.24% of original) (Best: 0.0028955 @iter1399) ([92m↓18.14%[0m) [1.40% of initial]
[Iter 1460/20000] Original Loss: 0.0035091 Pseudo Loss: 0.0011391 (32.46% of original) (Best: 0.0028955 @iter1399) ([92m↓0.68%[0m) [1.39% of initial]
[Iter 1470/20000] Original Loss: 0.0033763 Pseudo Loss: 0.0011391 (33.74% of original) (Best: 0.0028955 @iter1399) ([92m↓3.78%[0m) [1.34% of initial]
[Iter 1480/20000] Original Loss: 0.0032763 Pseudo Loss: 0.0011391 (34.77% of original) (Best: 0.0027453 @iter1480) ([92m↓2.96%[0m) [1.30% of initial]
[Iter 1490/20000] Original Loss: 0.0031771 Pseudo Loss: 0.0011391 (35.85% of original) (Best: 0.0027453 @iter1480) ([92m↓3.03%[0m) [1.26% of initial]
Iter:1499, L1 loss=0.002584, Total loss=0.003304, Time:14
[Iter 1500/20000] Original Loss: 0.0031552 Pseudo Loss: 0.0011391 (36.10% of original) (Best: 0.0027453 @iter1480) ([92m↓0.69%[0m) [1.25% of initial]
[Iter 1510/20000] Original Loss: 0.0030085 Pseudo Loss: 0.0011391 (37.86% of original) (Best: 0.0025772 @iter1504) ([92m↓4.65%[0m) [1.20% of initial]
[Iter 1520/20000] Original Loss: 0.0030063 Pseudo Loss: 0.0011391 (37.89% of original) (Best: 0.0025659 @iter1520) ([92m↓0.07%[0m) [1.19% of initial]
[Iter 1530/20000] Original Loss: 0.0031075 Pseudo Loss: 0.0011391 (36.66% of original) (Best: 0.0025559 @iter1526) ([91m↑3.37%[0m) [1.23% of initial]
[Iter 1540/20000] Original Loss: 0.0030107 Pseudo Loss: 0.0011391 (37.83% of original) (Best: 0.0025559 @iter1526) ([92m↓3.12%[0m) [1.20% of initial]
[Iter 1550/20000] Original Loss: 0.0029342 Pseudo Loss: 0.0011391 (38.82% of original) (Best: 0.0025559 @iter1526) ([92m↓2.54%[0m) [1.17% of initial]
[Iter 1560/20000] Original Loss: 0.0031681 Pseudo Loss: 0.0011391 (35.95% of original) (Best: 0.0024920 @iter1558) ([91m↑7.97%[0m) [1.26% of initial]
[Iter 1570/20000] Original Loss: 0.0027489 Pseudo Loss: 0.0011391 (41.44% of original) (Best: 0.0024230 @iter1569) ([92m↓13.23%[0m) [1.09% of initial]
[Iter 1580/20000] Original Loss: 0.0027600 Pseudo Loss: 0.0011391 (41.27% of original) (Best: 0.0022971 @iter1573) ([91m↑0.40%[0m) [1.10% of initial]
[Iter 1590/20000] Original Loss: 0.0026558 Pseudo Loss: 0.0011391 (42.89% of original) (Best: 0.0022971 @iter1573) ([92m↓3.78%[0m) [1.06% of initial]
Iter:1599, L1 loss=0.002683, Total loss=0.003327, Time:13
[Iter 1600/20000] Original Loss: 0.0030132 Pseudo Loss: 0.0011391 (37.80% of original) (Best: 0.0022443 @iter1591) ([91m↑13.46%[0m) [1.20% of initial]
[Iter 1610/20000] Original Loss: 0.0082661 Pseudo Loss: 0.0011391 (13.78% of original) (Best: 0.0022443 @iter1591) ([91m↑174.33%[0m) [3.28% of initial]
[Iter 1620/20000] Original Loss: 0.0052745 Pseudo Loss: 0.0011391 (21.60% of original) (Best: 0.0022443 @iter1591) ([92m↓36.19%[0m) [2.10% of initial]
[Iter 1630/20000] Original Loss: 0.0039519 Pseudo Loss: 0.0021582 (54.61% of original) (Best: 0.0022443 @iter1591) ([92m↓25.07%[0m) [1.57% of initial]
[Iter 1640/20000] Original Loss: 0.0037665 Pseudo Loss: 0.0021582 (57.30% of original) (Best: 0.0022443 @iter1591) ([92m↓4.69%[0m) [1.50% of initial]
[Iter 1650/20000] Original Loss: 0.0032976 Pseudo Loss: 0.0021582 (65.45% of original) (Best: 0.0022443 @iter1591) ([92m↓12.45%[0m) [1.31% of initial]
[Iter 1660/20000] Original Loss: 0.0028874 Pseudo Loss: 0.0021582 (74.75% of original) (Best: 0.0022443 @iter1591) ([92m↓12.44%[0m) [1.15% of initial]
[Iter 1670/20000] Original Loss: 0.0027063 Pseudo Loss: 0.0021582 (79.75% of original) (Best: 0.0022443 @iter1591) ([92m↓6.27%[0m) [1.08% of initial]
[Iter 1680/20000] Original Loss: 0.0029185 Pseudo Loss: 0.0021582 (73.95% of original) (Best: 0.0022443 @iter1591) ([91m↑7.84%[0m) [1.16% of initial]
[Iter 1690/20000] Original Loss: 0.0030863 Pseudo Loss: 0.0021582 (69.93% of original) (Best: 0.0022443 @iter1591) ([91m↑5.75%[0m) [1.23% of initial]
Iter:1699, L1 loss=0.002653, Total loss=0.00314, Time:14
[Iter 1700/20000] Original Loss: 0.0027895 Pseudo Loss: 0.0021582 (77.37% of original) (Best: 0.0022443 @iter1591) ([92m↓9.62%[0m) [1.11% of initial]
[Iter 1710/20000] Original Loss: 0.0031226 Pseudo Loss: 0.0021582 (69.12% of original) (Best: 0.0022443 @iter1591) ([91m↑11.94%[0m) [1.24% of initial]
[Iter 1720/20000] Original Loss: 0.0025835 Pseudo Loss: 0.0021582 (83.54% of original) (Best: 0.0022443 @iter1591) ([92m↓17.26%[0m) [1.03% of initial]
[Iter 1730/20000] Original Loss: 0.0025578 Pseudo Loss: 0.0021582 (84.38% of original) (Best: 0.0022443 @iter1591) ([92m↓1.00%[0m) [1.02% of initial]
[Iter 1740/20000] Original Loss: 0.0025782 Pseudo Loss: 0.0021582 (83.71% of original) (Best: 0.0021903 @iter1738) ([91m↑0.80%[0m) [1.02% of initial]
[Iter 1750/20000] Original Loss: 0.0023107 Pseudo Loss: 0.0021582 (93.40% of original) (Best: 0.0020655 @iter1750) ([92m↓10.38%[0m) [0.92% of initial]
[Iter 1760/20000] Original Loss: 0.0025915 Pseudo Loss: 0.0021582 (83.28% of original) (Best: 0.0020655 @iter1750) ([91m↑12.15%[0m) [1.03% of initial]
[Iter 1770/20000] Original Loss: 0.0023933 Pseudo Loss: 0.0021582 (90.18% of original) (Best: 0.0020548 @iter1762) ([92m↓7.65%[0m) [0.95% of initial]
[Iter 1780/20000] Original Loss: 0.0024263 Pseudo Loss: 0.0021582 (88.95% of original) (Best: 0.0020548 @iter1762) ([91m↑1.38%[0m) [0.96% of initial]
[Iter 1790/20000] Original Loss: 0.0021545 Pseudo Loss: 0.0021582 (100.17% of original) (Best: 0.0018186 @iter1789) ([92m↓11.20%[0m) [0.86% of initial]
Iter:1799, L1 loss=0.001697, Total loss=0.001901, Time:13
[Iter 1800/20000] Original Loss: 0.0021872 Pseudo Loss: 0.0021582 (98.67% of original) (Best: 0.0018186 @iter1789) ([91m↑1.52%[0m) [0.87% of initial]
[Iter 1810/20000] Original Loss: 0.0076745 Pseudo Loss: 0.0021582 (28.12% of original) (Best: 0.0018186 @iter1789) ([91m↑250.88%[0m) [3.05% of initial]
[Iter 1820/20000] Original Loss: 0.0046133 Pseudo Loss: 0.0021582 (46.78% of original) (Best: 0.0018186 @iter1789) ([92m↓39.89%[0m) [1.83% of initial]
[Iter 1830/20000] Original Loss: 0.0040230 Pseudo Loss: 0.0021582 (53.65% of original) (Best: 0.0018186 @iter1789) ([92m↓12.80%[0m) [1.60% of initial]
[Iter 1840/20000] Original Loss: 0.0027763 Pseudo Loss: 0.0021582 (77.74% of original) (Best: 0.0018186 @iter1789) ([92m↓30.99%[0m) [1.10% of initial]
[Iter 1850/20000] Original Loss: 0.0025899 Pseudo Loss: 0.0021582 (83.33% of original) (Best: 0.0018186 @iter1789) ([92m↓6.71%[0m) [1.03% of initial]
[Iter 1860/20000] Original Loss: 0.0023493 Pseudo Loss: 0.0021582 (91.87% of original) (Best: 0.0018186 @iter1789) ([92m↓9.29%[0m) [0.93% of initial]
[Iter 1870/20000] Original Loss: 0.0021850 Pseudo Loss: 0.0021582 (98.78% of original) (Best: 0.0018151 @iter1867) ([92m↓6.99%[0m) [0.87% of initial]
[Iter 1880/20000] Original Loss: 0.0020894 Pseudo Loss: 0.0021582 (103.30% of original) (Best: 0.0018151 @iter1867) ([92m↓4.38%[0m) [0.83% of initial]
[Iter 1890/20000] Original Loss: 0.0019199 Pseudo Loss: 0.0021582 (112.41% of original) (Best: 0.0017793 @iter1887) ([92m↓8.11%[0m) [0.76% of initial]
Iter:1899, L1 loss=0.001769, Total loss=0.002015, Time:14
[Iter 1900/20000] Original Loss: 0.0020387 Pseudo Loss: 0.0021582 (105.86% of original) (Best: 0.0016294 @iter1891) ([91m↑6.19%[0m) [0.81% of initial]
[Iter 1910/20000] Original Loss: 0.0020801 Pseudo Loss: 0.0021582 (103.76% of original) (Best: 0.0016294 @iter1891) ([91m↑2.03%[0m) [0.83% of initial]
[Iter 1920/20000] Original Loss: 0.0020956 Pseudo Loss: 0.0021582 (102.99% of original) (Best: 0.0016294 @iter1891) ([91m↑0.74%[0m) [0.83% of initial]
[Iter 1930/20000] Original Loss: 0.0017826 Pseudo Loss: 0.0021582 (121.07% of original) (Best: 0.0015834 @iter1930) ([92m↓14.93%[0m) [0.71% of initial]
[Iter 1940/20000] Original Loss: 0.0018688 Pseudo Loss: 0.0021582 (115.49% of original) (Best: 0.0015336 @iter1939) ([91m↑4.84%[0m) [0.74% of initial]
[Iter 1950/20000] Original Loss: 0.0020481 Pseudo Loss: 0.0021582 (105.38% of original) (Best: 0.0015336 @iter1939) ([91m↑9.59%[0m) [0.81% of initial]
[Iter 1960/20000] Original Loss: 0.0018784 Pseudo Loss: 0.0021582 (114.90% of original) (Best: 0.0015336 @iter1939) ([92m↓8.29%[0m) [0.75% of initial]
[Iter 1970/20000] Original Loss: 0.0017125 Pseudo Loss: 0.0021582 (126.03% of original) (Best: 0.0015336 @iter1939) ([92m↓8.83%[0m) [0.68% of initial]
[Iter 1980/20000] Original Loss: 0.0020425 Pseudo Loss: 0.0021582 (105.67% of original) (Best: 0.0015336 @iter1939) ([91m↑19.27%[0m) [0.81% of initial]
[Iter 1990/20000] Original Loss: 0.0017953 Pseudo Loss: 0.0021582 (120.22% of original) (Best: 0.0015336 @iter1939) ([92m↓12.10%[0m) [0.71% of initial]
Iter:1999, L1 loss=0.001605, Total loss=0.001973, Time:14
[Iter 2000/20000] Original Loss: 0.0020271 Pseudo Loss: 0.0021582 (106.47% of original) (Best: 0.0015336 @iter1939) ([91m↑12.91%[0m) [0.81% of initial]
Testing Speed: 197.1400316604436 fps
Testing Time: 0.25362682342529297 s

[ITER 2000] Evaluating test: SSIM = 0.8478951263427734, PSNR = 17.5193744468689
Testing Speed: 180.88772605733016 fps
Testing Time: 0.01658487319946289 s

[ITER 2000] Evaluating train: SSIM = 0.9999496738115946, PSNR = 48.31907272338867
Iter:2000, total_points:43029
[Iter 2010/20000] Original Loss: 0.0066683 Pseudo Loss: 0.0021582 (32.37% of original) (Best: 0.0015336 @iter1939) ([91m↑228.96%[0m) [2.65% of initial]
[Iter 2020/20000] Original Loss: 0.0037955 Pseudo Loss: 0.0021582 (56.86% of original) (Best: 0.0015336 @iter1939) ([92m↓43.08%[0m) [1.51% of initial]
[Iter 2030/20000] Original Loss: 0.0028327 Pseudo Loss: 0.0021582 (76.19% of original) (Best: 0.0015336 @iter1939) ([92m↓25.37%[0m) [1.13% of initial]
[Iter 2040/20000] Original Loss: 0.0024956 Pseudo Loss: 0.0021582 (86.48% of original) (Best: 0.0015336 @iter1939) ([92m↓11.90%[0m) [0.99% of initial]
[Iter 2050/20000] Original Loss: 0.0021104 Pseudo Loss: 0.0021582 (102.27% of original) (Best: 0.0015336 @iter1939) ([92m↓15.44%[0m) [0.84% of initial]
[Iter 2060/20000] Original Loss: 0.0018543 Pseudo Loss: 0.0021582 (116.39% of original) (Best: 0.0015336 @iter1939) ([92m↓12.14%[0m) [0.74% of initial]
[Iter 2070/20000] Original Loss: 0.0020073 Pseudo Loss: 0.0021582 (107.52% of original) (Best: 0.0015336 @iter1939) ([91m↑8.25%[0m) [0.80% of initial]
[Iter 2080/20000] Original Loss: 0.0019970 Pseudo Loss: 0.0021582 (108.08% of original) (Best: 0.0015336 @iter1939) ([92m↓0.51%[0m) [0.79% of initial]
[Iter 2090/20000] Original Loss: 0.0018941 Pseudo Loss: 0.0021582 (113.95% of original) (Best: 0.0015223 @iter2087) ([92m↓5.15%[0m) [0.75% of initial]
Iter:2099, L1 loss=0.001603, Total loss=0.001741, Time:14
[Iter 2100/20000] Original Loss: 0.0017347 Pseudo Loss: 0.0021582 (124.41% of original) (Best: 0.0015223 @iter2087) ([92m↓8.41%[0m) [0.69% of initial]
[Iter 2110/20000] Original Loss: 0.0017356 Pseudo Loss: 0.0021582 (124.35% of original) (Best: 0.0014791 @iter2101) ([91m↑0.05%[0m) [0.69% of initial]
[Iter 2120/20000] Original Loss: 0.0014621 Pseudo Loss: 0.0021582 (147.62% of original) (Best: 0.0013332 @iter2120) ([92m↓15.76%[0m) [0.58% of initial]
[Iter 2130/20000] Original Loss: 0.0016182 Pseudo Loss: 0.0021582 (133.37% of original) (Best: 0.0013010 @iter2125) ([91m↑10.68%[0m) [0.64% of initial]
[Iter 2140/20000] Original Loss: 0.0017596 Pseudo Loss: 0.0021582 (122.66% of original) (Best: 0.0013010 @iter2125) ([91m↑8.74%[0m) [0.70% of initial]
[Iter 2150/20000] Original Loss: 0.0018168 Pseudo Loss: 0.0021582 (118.79% of original) (Best: 0.0013010 @iter2125) ([91m↑3.25%[0m) [0.72% of initial]
[Iter 2160/20000] Original Loss: 0.0016130 Pseudo Loss: 0.0021582 (133.80% of original) (Best: 0.0013010 @iter2125) ([92m↓11.22%[0m) [0.64% of initial]
[Iter 2170/20000] Original Loss: 0.0016499 Pseudo Loss: 0.0021582 (130.81% of original) (Best: 0.0013010 @iter2125) ([91m↑2.29%[0m) [0.66% of initial]
[Iter 2180/20000] Original Loss: 0.0013512 Pseudo Loss: 0.0021582 (159.73% of original) (Best: 0.0012242 @iter2180) ([92m↓18.10%[0m) [0.54% of initial]
[Iter 2190/20000] Original Loss: 0.0016139 Pseudo Loss: 0.0021582 (133.73% of original) (Best: 0.0012242 @iter2180) ([91m↑19.44%[0m) [0.64% of initial]
Iter:2199, L1 loss=0.001371, Total loss=0.00153, Time:14
[Iter 2200/20000] Original Loss: 0.0016833 Pseudo Loss: 0.0021582 (128.22% of original) (Best: 0.0012242 @iter2180) ([91m↑4.30%[0m) [0.67% of initial]
[Iter 2210/20000] Original Loss: 0.0075845 Pseudo Loss: 0.0021582 (28.46% of original) (Best: 0.0012242 @iter2180) ([91m↑350.58%[0m) [3.01% of initial]
[Iter 2220/20000] Original Loss: 0.0042555 Pseudo Loss: 0.0021582 (50.72% of original) (Best: 0.0012242 @iter2180) ([92m↓43.89%[0m) [1.69% of initial]
[Iter 2230/20000] Original Loss: 0.0027029 Pseudo Loss: 0.0021582 (79.85% of original) (Best: 0.0012242 @iter2180) ([92m↓36.48%[0m) [1.07% of initial]
[Iter 2240/20000] Original Loss: 0.0023134 Pseudo Loss: 0.0021582 (93.29% of original) (Best: 0.0012242 @iter2180) ([92m↓14.41%[0m) [0.92% of initial]
[Iter 2250/20000] Original Loss: 0.0021240 Pseudo Loss: 0.0021582 (101.61% of original) (Best: 0.0012242 @iter2180) ([92m↓8.19%[0m) [0.84% of initial]
[Iter 2260/20000] Original Loss: 0.0017317 Pseudo Loss: 0.0021582 (124.63% of original) (Best: 0.0012242 @iter2180) ([92m↓18.47%[0m) [0.69% of initial]
[Iter 2270/20000] Original Loss: 0.0018084 Pseudo Loss: 0.0021582 (119.35% of original) (Best: 0.0012242 @iter2180) ([91m↑4.43%[0m) [0.72% of initial]
[Iter 2280/20000] Original Loss: 0.0014682 Pseudo Loss: 0.0021582 (146.99% of original) (Best: 0.0012242 @iter2180) ([92m↓18.81%[0m) [0.58% of initial]
[Iter 2290/20000] Original Loss: 0.0014167 Pseudo Loss: 0.0021582 (152.34% of original) (Best: 0.0012177 @iter2285) ([92m↓3.51%[0m) [0.56% of initial]
Iter:2299, L1 loss=0.001299, Total loss=0.001447, Time:15
[Iter 2300/20000] Original Loss: 0.0017147 Pseudo Loss: 0.0021582 (125.87% of original) (Best: 0.0012177 @iter2285) ([91m↑21.03%[0m) [0.68% of initial]
[Iter 2310/20000] Original Loss: 0.0015584 Pseudo Loss: 0.0021582 (138.49% of original) (Best: 0.0012177 @iter2285) ([92m↓9.11%[0m) [0.62% of initial]
[Iter 2320/20000] Original Loss: 0.0013179 Pseudo Loss: 0.0021582 (163.76% of original) (Best: 0.0011661 @iter2320) ([92m↓15.43%[0m) [0.52% of initial]
[Iter 2330/20000] Original Loss: 0.0013347 Pseudo Loss: 0.0021582 (161.71% of original) (Best: 0.0011577 @iter2329) ([91m↑1.27%[0m) [0.53% of initial]
[Iter 2340/20000] Original Loss: 0.0013609 Pseudo Loss: 0.0021582 (158.59% of original) (Best: 0.0011378 @iter2338) ([91m↑1.96%[0m) [0.54% of initial]
[Iter 2350/20000] Original Loss: 0.0015297 Pseudo Loss: 0.0021582 (141.09% of original) (Best: 0.0011378 @iter2338) ([91m↑12.40%[0m) [0.61% of initial]
[Iter 2360/20000] Original Loss: 0.0013211 Pseudo Loss: 0.0021582 (163.36% of original) (Best: 0.0011006 @iter2359) ([92m↓13.63%[0m) [0.52% of initial]
[Iter 2370/20000] Original Loss: 0.0014354 Pseudo Loss: 0.0021582 (150.36% of original) (Best: 0.0011006 @iter2359) ([91m↑8.65%[0m) [0.57% of initial]
[Iter 2380/20000] Original Loss: 0.0014842 Pseudo Loss: 0.0019614 (132.16% of original) (Best: 0.0011006 @iter2359) ([91m↑3.40%[0m) [0.59% of initial]
[Iter 2390/20000] Original Loss: 0.0016105 Pseudo Loss: 0.0019614 (121.79% of original) (Best: 0.0011006 @iter2359) ([91m↑8.51%[0m) [0.64% of initial]
Iter:2399, L1 loss=0.001229, Total loss=0.001309, Time:15
[Iter 2400/20000] Original Loss: 0.0013510 Pseudo Loss: 0.0019614 (145.18% of original) (Best: 0.0011006 @iter2359) ([92m↓16.11%[0m) [0.54% of initial]
[Iter 2410/20000] Original Loss: 0.0060932 Pseudo Loss: 0.0019614 (32.19% of original) (Best: 0.0011006 @iter2359) ([91m↑351.01%[0m) [2.42% of initial]
[Iter 2420/20000] Original Loss: 0.0034902 Pseudo Loss: 0.0019614 (56.20% of original) (Best: 0.0011006 @iter2359) ([92m↓42.72%[0m) [1.39% of initial]
[Iter 2430/20000] Original Loss: 0.0025237 Pseudo Loss: 0.0019614 (77.72% of original) (Best: 0.0011006 @iter2359) ([92m↓27.69%[0m) [1.00% of initial]
[Iter 2440/20000] Original Loss: 0.0020381 Pseudo Loss: 0.0019614 (96.24% of original) (Best: 0.0011006 @iter2359) ([92m↓19.24%[0m) [0.81% of initial]
[Iter 2450/20000] Original Loss: 0.0019578 Pseudo Loss: 0.0019614 (100.19% of original) (Best: 0.0011006 @iter2359) ([92m↓3.94%[0m) [0.78% of initial]
[Iter 2460/20000] Original Loss: 0.0016858 Pseudo Loss: 0.0019614 (116.35% of original) (Best: 0.0011006 @iter2359) ([92m↓13.89%[0m) [0.67% of initial]
[Iter 2470/20000] Original Loss: 0.0016333 Pseudo Loss: 0.0019614 (120.09% of original) (Best: 0.0011006 @iter2359) ([92m↓3.12%[0m) [0.65% of initial]
[Iter 2480/20000] Original Loss: 0.0016483 Pseudo Loss: 0.0019614 (119.00% of original) (Best: 0.0011006 @iter2359) ([91m↑0.92%[0m) [0.65% of initial]
[Iter 2490/20000] Original Loss: 0.0014734 Pseudo Loss: 0.0019614 (133.13% of original) (Best: 0.0011006 @iter2359) ([92m↓10.62%[0m) [0.59% of initial]
Iter:2499, L1 loss=0.001205, Total loss=0.001214, Time:16
[Iter 2500/20000] Original Loss: 0.0013296 Pseudo Loss: 0.0019614 (147.52% of original) (Best: 0.0011006 @iter2359) ([92m↓9.76%[0m) [0.53% of initial]
[Iter 2510/20000] Original Loss: 0.0013639 Pseudo Loss: 0.0019614 (143.81% of original) (Best: 0.0010516 @iter2504) ([91m↑2.58%[0m) [0.54% of initial]
[Iter 2520/20000] Original Loss: 0.0012573 Pseudo Loss: 0.0019614 (156.01% of original) (Best: 0.0010516 @iter2504) ([92m↓7.82%[0m) [0.50% of initial]
[Iter 2530/20000] Original Loss: 0.0011183 Pseudo Loss: 0.0019614 (175.40% of original) (Best: 0.0009786 @iter2528) ([92m↓11.06%[0m) [0.44% of initial]
[Iter 2540/20000] Original Loss: 0.0012267 Pseudo Loss: 0.0019614 (159.90% of original) (Best: 0.0009786 @iter2528) ([91m↑9.69%[0m) [0.49% of initial]
[Iter 2550/20000] Original Loss: 0.0014369 Pseudo Loss: 0.0019614 (136.50% of original) (Best: 0.0009786 @iter2528) ([91m↑17.14%[0m) [0.57% of initial]
[Iter 2560/20000] Original Loss: 0.0011931 Pseudo Loss: 0.0019614 (164.39% of original) (Best: 0.0009786 @iter2528) ([92m↓16.97%[0m) [0.47% of initial]
[Iter 2570/20000] Original Loss: 0.0014066 Pseudo Loss: 0.0019614 (139.45% of original) (Best: 0.0009786 @iter2528) ([91m↑17.89%[0m) [0.56% of initial]
[Iter 2580/20000] Original Loss: 0.0012611 Pseudo Loss: 0.0019614 (155.54% of original) (Best: 0.0009781 @iter2578) ([92m↓10.34%[0m) [0.50% of initial]
[Iter 2590/20000] Original Loss: 0.0013450 Pseudo Loss: 0.0019614 (145.84% of original) (Best: 0.0009654 @iter2584) ([91m↑6.65%[0m) [0.53% of initial]
Iter:2599, L1 loss=0.00103, Total loss=0.001084, Time:16
[Iter 2600/20000] Original Loss: 0.0012225 Pseudo Loss: 0.0019614 (160.45% of original) (Best: 0.0009654 @iter2584) ([92m↓9.11%[0m) [0.49% of initial]
[Iter 2610/20000] Original Loss: 0.0062556 Pseudo Loss: 0.0019614 (31.35% of original) (Best: 0.0009654 @iter2584) ([91m↑411.72%[0m) [2.49% of initial]
[Iter 2620/20000] Original Loss: 0.0033023 Pseudo Loss: 0.0019614 (59.40% of original) (Best: 0.0009654 @iter2584) ([92m↓47.21%[0m) [1.31% of initial]
[Iter 2630/20000] Original Loss: 0.0022505 Pseudo Loss: 0.0019614 (87.16% of original) (Best: 0.0009654 @iter2584) ([92m↓31.85%[0m) [0.89% of initial]
[Iter 2640/20000] Original Loss: 0.0017598 Pseudo Loss: 0.0019614 (111.46% of original) (Best: 0.0009654 @iter2584) ([92m↓21.80%[0m) [0.70% of initial]
[Iter 2650/20000] Original Loss: 0.0014602 Pseudo Loss: 0.0019614 (134.32% of original) (Best: 0.0009654 @iter2584) ([92m↓17.02%[0m) [0.58% of initial]
[Iter 2660/20000] Original Loss: 0.0016229 Pseudo Loss: 0.0019614 (120.86% of original) (Best: 0.0009654 @iter2584) ([91m↑11.14%[0m) [0.64% of initial]
[Iter 2670/20000] Original Loss: 0.0015679 Pseudo Loss: 0.0027651 (176.36% of original) (Best: 0.0009654 @iter2584) ([92m↓3.39%[0m) [0.62% of initial]
[Iter 2680/20000] Original Loss: 0.0012234 Pseudo Loss: 0.0027651 (226.01% of original) (Best: 0.0009654 @iter2584) ([92m↓21.97%[0m) [0.49% of initial]
[Iter 2690/20000] Original Loss: 0.0011785 Pseudo Loss: 0.0027651 (234.62% of original) (Best: 0.0009654 @iter2584) ([92m↓3.67%[0m) [0.47% of initial]
Iter:2699, L1 loss=0.001128, Total loss=0.001149, Time:16
[Iter 2700/20000] Original Loss: 0.0014444 Pseudo Loss: 0.0027651 (191.43% of original) (Best: 0.0009654 @iter2584) ([91m↑22.56%[0m) [0.57% of initial]
[Iter 2710/20000] Original Loss: 0.0012418 Pseudo Loss: 0.0027651 (222.66% of original) (Best: 0.0009654 @iter2584) ([92m↓14.03%[0m) [0.49% of initial]
[Iter 2720/20000] Original Loss: 0.0011099 Pseudo Loss: 0.0027651 (249.12% of original) (Best: 0.0009654 @iter2584) ([92m↓10.62%[0m) [0.44% of initial]
[Iter 2730/20000] Original Loss: 0.0010123 Pseudo Loss: 0.0027565 (272.31% of original) (Best: 0.0008650 @iter2725) ([92m↓8.80%[0m) [0.40% of initial]
[Iter 2740/20000] Original Loss: 0.0008836 Pseudo Loss: 0.0027565 (311.97% of original) (Best: 0.0007981 @iter2740) ([92m↓12.71%[0m) [0.35% of initial]
[Iter 2750/20000] Original Loss: 0.0011270 Pseudo Loss: 0.0027565 (244.60% of original) (Best: 0.0007981 @iter2740) ([91m↑27.54%[0m) [0.45% of initial]
[Iter 2760/20000] Original Loss: 0.0012449 Pseudo Loss: 0.0027565 (221.42% of original) (Best: 0.0007981 @iter2740) ([91m↑10.47%[0m) [0.49% of initial]
[Iter 2770/20000] Original Loss: 0.0013686 Pseudo Loss: 0.0027565 (201.42% of original) (Best: 0.0007981 @iter2740) ([91m↑9.93%[0m) [0.54% of initial]
[Iter 2780/20000] Original Loss: 0.0011094 Pseudo Loss: 0.0027565 (248.47% of original) (Best: 0.0007981 @iter2740) ([92m↓18.94%[0m) [0.44% of initial]
[Iter 2790/20000] Original Loss: 0.0011580 Pseudo Loss: 0.0027565 (238.05% of original) (Best: 0.0007981 @iter2740) ([91m↑4.38%[0m) [0.46% of initial]
Iter:2799, L1 loss=0.001308, Total loss=0.001288, Time:16
[Iter 2800/20000] Original Loss: 0.0011408 Pseudo Loss: 0.0027565 (241.64% of original) (Best: 0.0007981 @iter2740) ([92m↓1.48%[0m) [0.45% of initial]
[Iter 2810/20000] Original Loss: 0.0052028 Pseudo Loss: 0.0027565 (52.98% of original) (Best: 0.0007981 @iter2740) ([91m↑356.08%[0m) [2.07% of initial]
[Iter 2820/20000] Original Loss: 0.0027497 Pseudo Loss: 0.0027565 (100.25% of original) (Best: 0.0007981 @iter2740) ([92m↓47.15%[0m) [1.09% of initial]
[Iter 2830/20000] Original Loss: 0.0017900 Pseudo Loss: 0.0027565 (153.99% of original) (Best: 0.0007981 @iter2740) ([92m↓34.90%[0m) [0.71% of initial]
[Iter 2840/20000] Original Loss: 0.0015124 Pseudo Loss: 0.0027565 (182.26% of original) (Best: 0.0007981 @iter2740) ([92m↓15.51%[0m) [0.60% of initial]
[Iter 2850/20000] Original Loss: 0.0012920 Pseudo Loss: 0.0027565 (213.35% of original) (Best: 0.0007981 @iter2740) ([92m↓14.57%[0m) [0.51% of initial]
[Iter 2860/20000] Original Loss: 0.0014040 Pseudo Loss: 0.0027565 (196.33% of original) (Best: 0.0007981 @iter2740) ([91m↑8.67%[0m) [0.56% of initial]
[Iter 2870/20000] Original Loss: 0.0011937 Pseudo Loss: 0.0027565 (230.93% of original) (Best: 0.0007981 @iter2740) ([92m↓14.98%[0m) [0.47% of initial]
[Iter 2880/20000] Original Loss: 0.0011784 Pseudo Loss: 0.0027565 (233.91% of original) (Best: 0.0007981 @iter2740) ([92m↓1.27%[0m) [0.47% of initial]
[Iter 2890/20000] Original Loss: 0.0011178 Pseudo Loss: 0.0027565 (246.59% of original) (Best: 0.0007981 @iter2740) ([92m↓5.14%[0m) [0.44% of initial]
Iter:2899, L1 loss=0.0008918, Total loss=0.0008703, Time:17
[Iter 2900/20000] Original Loss: 0.0010531 Pseudo Loss: 0.0027565 (261.75% of original) (Best: 0.0007981 @iter2740) ([92m↓5.79%[0m) [0.42% of initial]
[Iter 2910/20000] Original Loss: 0.0011174 Pseudo Loss: 0.0027565 (246.68% of original) (Best: 0.0007981 @iter2740) ([91m↑6.11%[0m) [0.44% of initial]
[Iter 2920/20000] Original Loss: 0.0011767 Pseudo Loss: 0.0027565 (234.25% of original) (Best: 0.0007981 @iter2740) ([91m↑5.31%[0m) [0.47% of initial]
[Iter 2930/20000] Original Loss: 0.0011121 Pseudo Loss: 0.0027565 (247.87% of original) (Best: 0.0007981 @iter2740) ([92m↓5.49%[0m) [0.44% of initial]
[Iter 2940/20000] Original Loss: 0.0009580 Pseudo Loss: 0.0027565 (287.74% of original) (Best: 0.0007981 @iter2740) ([92m↓13.86%[0m) [0.38% of initial]
[Iter 2950/20000] Original Loss: 0.0009534 Pseudo Loss: 0.0027565 (289.13% of original) (Best: 0.0007981 @iter2740) ([92m↓0.48%[0m) [0.38% of initial]
[Iter 2960/20000] Original Loss: 0.0010173 Pseudo Loss: 0.0027565 (270.96% of original) (Best: 0.0007981 @iter2740) ([91m↑6.71%[0m) [0.40% of initial]
[Iter 2970/20000] Original Loss: 0.0009059 Pseudo Loss: 0.0027565 (304.27% of original) (Best: 0.0007457 @iter2969) ([92m↓10.95%[0m) [0.36% of initial]
[Iter 2980/20000] Original Loss: 0.0008273 Pseudo Loss: 0.0027565 (333.19% of original) (Best: 0.0007412 @iter2977) ([92m↓8.68%[0m) [0.33% of initial]
[Iter 2990/20000] Original Loss: 0.0008748 Pseudo Loss: 0.0027565 (315.10% of original) (Best: 0.0007015 @iter2983) ([91m↑5.74%[0m) [0.35% of initial]
Iter:2999, L1 loss=0.0007107, Total loss=0.000675, Time:16
[Iter 3000/20000] Original Loss: 0.0008374 Pseudo Loss: 0.0027565 (329.16% of original) (Best: 0.0006750 @iter2999) ([92m↓4.27%[0m) [0.33% of initial]
[Iter 3010/20000] Original Loss: 0.0050904 Pseudo Loss: 0.0027565 (54.15% of original) (Best: 0.0006750 @iter2999) ([91m↑507.86%[0m) [2.02% of initial]
[Iter 3020/20000] Original Loss: 0.0028085 Pseudo Loss: 0.0027565 (98.15% of original) (Best: 0.0006750 @iter2999) ([92m↓44.83%[0m) [1.12% of initial]
[Iter 3030/20000] Original Loss: 0.0022045 Pseudo Loss: 0.0027565 (125.04% of original) (Best: 0.0006750 @iter2999) ([92m↓21.51%[0m) [0.88% of initial]
[Iter 3040/20000] Original Loss: 0.0017386 Pseudo Loss: 0.0027565 (158.55% of original) (Best: 0.0006750 @iter2999) ([92m↓21.14%[0m) [0.69% of initial]
[Iter 3050/20000] Original Loss: 0.0014633 Pseudo Loss: 0.0027565 (188.38% of original) (Best: 0.0006750 @iter2999) ([92m↓15.84%[0m) [0.58% of initial]
[Iter 3060/20000] Original Loss: 0.0013949 Pseudo Loss: 0.0027565 (197.62% of original) (Best: 0.0006750 @iter2999) ([92m↓4.68%[0m) [0.55% of initial]
[Iter 3070/20000] Original Loss: 0.0011309 Pseudo Loss: 0.0023083 (204.12% of original) (Best: 0.0006750 @iter2999) ([92m↓18.92%[0m) [0.45% of initial]
[Iter 3080/20000] Original Loss: 0.0011547 Pseudo Loss: 0.0023083 (199.90% of original) (Best: 0.0006750 @iter2999) ([91m↑2.11%[0m) [0.46% of initial]
[Iter 3090/20000] Original Loss: 0.0010851 Pseudo Loss: 0.0023083 (212.73% of original) (Best: 0.0006750 @iter2999) ([92m↓6.03%[0m) [0.43% of initial]
Iter:3099, L1 loss=0.0008991, Total loss=0.000898, Time:17
[Iter 3100/20000] Original Loss: 0.0010021 Pseudo Loss: 0.0023083 (230.36% of original) (Best: 0.0006750 @iter2999) ([92m↓7.65%[0m) [0.40% of initial]
[Iter 3110/20000] Original Loss: 0.0011305 Pseudo Loss: 0.0023083 (204.20% of original) (Best: 0.0006750 @iter2999) ([91m↑12.81%[0m) [0.45% of initial]
[Iter 3120/20000] Original Loss: 0.0010797 Pseudo Loss: 0.0023083 (213.79% of original) (Best: 0.0006750 @iter2999) ([92m↓4.49%[0m) [0.43% of initial]
[Iter 3130/20000] Original Loss: 0.0008631 Pseudo Loss: 0.0023083 (267.46% of original) (Best: 0.0006750 @iter2999) ([92m↓20.07%[0m) [0.34% of initial]
[Iter 3140/20000] Original Loss: 0.0008223 Pseudo Loss: 0.0023083 (280.72% of original) (Best: 0.0006733 @iter3139) ([92m↓4.72%[0m) [0.33% of initial]
[Iter 3150/20000] Original Loss: 0.0008538 Pseudo Loss: 0.0023083 (270.36% of original) (Best: 0.0006733 @iter3139) ([91m↑3.83%[0m) [0.34% of initial]
[Iter 3160/20000] Original Loss: 0.0008223 Pseudo Loss: 0.0023083 (280.71% of original) (Best: 0.0006733 @iter3139) ([92m↓3.69%[0m) [0.33% of initial]
[Iter 3170/20000] Original Loss: 0.0008330 Pseudo Loss: 0.0023083 (277.11% of original) (Best: 0.0006733 @iter3139) ([91m↑1.30%[0m) [0.33% of initial]
[Iter 3180/20000] Original Loss: 0.0009086 Pseudo Loss: 0.0023083 (254.05% of original) (Best: 0.0006733 @iter3139) ([91m↑9.08%[0m) [0.36% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 10] Gaussian 0 vs 1:
  Original Loss: 0.2126908
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 10] Gaussian 1 vs 0:
  Original Loss: 0.2126908
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693032 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 20] Gaussian 0 vs 1:
  Original Loss: 0.1693032
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1693032 (Pseudo: 0.00%)
[Iter 20] Gaussian 1 vs 0:
  Original Loss: 0.1693031
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1693031 (Pseudo: 0.00%)
[Iter 30/20000] Loss: 0.1374904 (Best: 0.1327874 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 30] Gaussian 0 vs 1:
  Original Loss: 0.1327874
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1327874 (Pseudo: 0.00%)
[Iter 30] Gaussian 1 vs 0:
  Original Loss: 0.1327881
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1327881 (Pseudo: 0.00%)
[Iter 40/20000] Loss: 0.1123929 (Best: 0.1098391 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 40] Gaussian 0 vs 1:
  Original Loss: 0.1098391
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1098391 (Pseudo: 0.00%)
[Iter 40] Gaussian 1 vs 0:
  Original Loss: 0.1098367
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1098367 (Pseudo: 0.00%)
[Iter 50/20000] Loss: 0.0993467 (Best: 0.0965446 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 50] Gaussian 0 vs 1:
  Original Loss: 0.0994881
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0994881 (Pseudo: 0.00%)
[Iter 50] Gaussian 1 vs 0:
  Original Loss: 0.0994867
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0994867 (Pseudo: 0.00%)
[Iter 60/20000] Loss: 0.0936726 (Best: 0.0908473 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 60] Gaussian 0 vs 1:
  Original Loss: 0.0940218
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0940218 (Pseudo: 0.00%)
[Iter 60] Gaussian 1 vs 0:
  Original Loss: 0.0940245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0940245 (Pseudo: 0.00%)
[Iter 70/20000] Loss: 0.0884486 (Best: 0.0869353 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 70] Gaussian 0 vs 1:
  Original Loss: 0.0869353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0869353 (Pseudo: 0.00%)
[Iter 70] Gaussian 1 vs 0:
  Original Loss: 0.0869347
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0869347 (Pseudo: 0.00%)
[Iter 80/20000] Loss: 0.0851862 (Best: 0.0831028 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 80] Gaussian 0 vs 1:
  Original Loss: 0.0831028
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0831028 (Pseudo: 0.00%)
[Iter 80] Gaussian 1 vs 0:
  Original Loss: 0.0831017
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0831017 (Pseudo: 0.00%)
[Iter 90/20000] Loss: 0.0824125 (Best: 0.0801463 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
[Iter 90] Gaussian 0 vs 1:
  Original Loss: 0.0823522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0823522 (Pseudo: 0.00%)
[Iter 90] Gaussian 1 vs 0:
  Original Loss: 0.0823472
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0823472 (Pseudo: 0.00%)
Iter:99, L1 loss=0.05723, Total loss=0.07875, Time:14
[Iter 100/20000] Loss: 0.0786595 (Best: 0.0766176 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 100] Gaussian 0 vs 1:
  Original Loss: 0.0782890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0782890 (Pseudo: 0.00%)
[Iter 100] Gaussian 1 vs 0:
  Original Loss: 0.0782995
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0782995 (Pseudo: 0.00%)
[Iter 110/20000] Loss: 0.0753305 (Best: 0.0731322 @iter106) ([92m↓4.23%[0m) [29.93% of initial]
[Iter 110] Gaussian 0 vs 1:
  Original Loss: 0.0744890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0744890 (Pseudo: 0.00%)
[Iter 110] Gaussian 1 vs 0:
  Original Loss: 0.0744969
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0744969 (Pseudo: 0.00%)
[Iter 120/20000] Loss: 0.0714365 (Best: 0.0685671 @iter118) ([92m↓5.17%[0m) [28.38% of initial]
[Iter 120] Gaussian 0 vs 1:
  Original Loss: 0.0723054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0723054 (Pseudo: 0.00%)
[Iter 120] Gaussian 1 vs 0:
  Original Loss: 0.0723218
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0723218 (Pseudo: 0.00%)
[Iter 130/20000] Loss: 0.0667060 (Best: 0.0642167 @iter130) ([92m↓6.62%[0m) [26.50% of initial]
[Iter 130] Gaussian 0 vs 1:
  Original Loss: 0.0642167
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0642167 (Pseudo: 0.00%)
[Iter 130] Gaussian 1 vs 0:
  Original Loss: 0.0642049
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0642049 (Pseudo: 0.00%)
[Iter 140/20000] Loss: 0.0635588 (Best: 0.0613106 @iter140) ([92m↓4.72%[0m) [25.25% of initial]
[Iter 140] Gaussian 0 vs 1:
  Original Loss: 0.0613106
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0613106 (Pseudo: 0.00%)
[Iter 140] Gaussian 1 vs 0:
  Original Loss: 0.0612862
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0612862 (Pseudo: 0.00%)
[Iter 150/20000] Loss: 0.0612936 (Best: 0.0584034 @iter148) ([92m↓3.56%[0m) [24.35% of initial]
[Iter 150] Gaussian 0 vs 1:
  Original Loss: 0.0605803
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0605803 (Pseudo: 0.00%)
[Iter 150] Gaussian 1 vs 0:
  Original Loss: 0.0605246
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0605246 (Pseudo: 0.00%)
[Iter 160/20000] Loss: 0.0590792 (Best: 0.0559436 @iter157) ([92m↓3.61%[0m) [23.47% of initial]
[Iter 160] Gaussian 0 vs 1:
  Original Loss: 0.0600219
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0600219 (Pseudo: 0.00%)
[Iter 160] Gaussian 1 vs 0:
  Original Loss: 0.0599866
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0599866 (Pseudo: 0.00%)
[Iter 170/20000] Loss: 0.0563707 (Best: 0.0535459 @iter167) ([92m↓4.58%[0m) [22.40% of initial]
[Iter 170] Gaussian 0 vs 1:
  Original Loss: 0.0574144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0574144 (Pseudo: 0.00%)
[Iter 170] Gaussian 1 vs 0:
  Original Loss: 0.0573768
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0573768 (Pseudo: 0.00%)
[Iter 180/20000] Loss: 0.0523170 (Best: 0.0499551 @iter179) ([92m↓7.19%[0m) [20.79% of initial]
[Iter 180] Gaussian 0 vs 1:
  Original Loss: 0.0518869
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0518869 (Pseudo: 0.00%)
[Iter 180] Gaussian 1 vs 0:
  Original Loss: 0.0518797
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0518797 (Pseudo: 0.00%)
[Iter 190/20000] Loss: 0.0495569 (Best: 0.0478060 @iter188) ([92m↓5.28%[0m) [19.69% of initial]
[Iter 190] Gaussian 0 vs 1:
  Original Loss: 0.0490611
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0490611 (Pseudo: 0.00%)
[Iter 190] Gaussian 1 vs 0:
  Original Loss: 0.0490043
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0490043 (Pseudo: 0.00%)
Iter:199, L1 loss=0.03439, Total loss=0.04972, Time:13
[Iter 200/20000] Loss: 0.0478035 (Best: 0.0456395 @iter198) ([92m↓3.54%[0m) [18.99% of initial]
[Iter 200] Gaussian 0 vs 1:
  Original Loss: 0.0467061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0467061 (Pseudo: 0.00%)
[Iter 200] Gaussian 1 vs 0:
  Original Loss: 0.0466626
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0466626 (Pseudo: 0.00%)
[Iter 210/20000] Loss: 0.0451214 (Best: 0.0429170 @iter209) ([92m↓5.61%[0m) [17.93% of initial]
[Iter 210] Gaussian 0 vs 1:
  Original Loss: 0.0449412
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0449412 (Pseudo: 0.00%)
[Iter 210] Gaussian 1 vs 0:
  Original Loss: 0.0448964
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0448964 (Pseudo: 0.00%)
[Iter 220/20000] Loss: 0.0441093 (Best: 0.0412987 @iter219) ([92m↓2.24%[0m) [17.52% of initial]
[Iter 220] Gaussian 0 vs 1:
  Original Loss: 0.0454830
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0454830 (Pseudo: 0.00%)
[Iter 220] Gaussian 1 vs 0:
  Original Loss: 0.0454687
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0454687 (Pseudo: 0.00%)
[Iter 230/20000] Loss: 0.0423580 (Best: 0.0399695 @iter227) ([92m↓3.97%[0m) [16.83% of initial]
[Iter 230] Gaussian 0 vs 1:
  Original Loss: 0.0410731
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0410731 (Pseudo: 0.00%)
[Iter 230] Gaussian 1 vs 0:
  Original Loss: 0.0410271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0410271 (Pseudo: 0.00%)
[Iter 240/20000] Loss: 0.0403109 (Best: 0.0378554 @iter238) ([92m↓4.83%[0m) [16.02% of initial]
[Iter 240] Gaussian 0 vs 1:
  Original Loss: 0.0394540
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0394540 (Pseudo: 0.00%)
[Iter 240] Gaussian 1 vs 0:
  Original Loss: 0.0393807
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0393807 (Pseudo: 0.00%)
[Iter 250/20000] Loss: 0.0380480 (Best: 0.0364345 @iter248) ([92m↓5.61%[0m) [15.12% of initial]
[Iter 250] Gaussian 0 vs 1:
  Original Loss: 0.0376637
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0376637 (Pseudo: 0.00%)
[Iter 250] Gaussian 1 vs 0:
  Original Loss: 0.0375876
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0375876 (Pseudo: 0.00%)
[Iter 260/20000] Loss: 0.0359541 (Best: 0.0344145 @iter260) ([92m↓5.50%[0m) [14.28% of initial]
[Iter 260] Gaussian 0 vs 1:
  Original Loss: 0.0344145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0344145 (Pseudo: 0.00%)
[Iter 260] Gaussian 1 vs 0:
  Original Loss: 0.0343649
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0343649 (Pseudo: 0.00%)
[Iter 270/20000] Loss: 0.0351133 (Best: 0.0329082 @iter269) ([92m↓2.34%[0m) [13.95% of initial]
[Iter 270] Gaussian 0 vs 1:
  Original Loss: 0.0349457
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0349457 (Pseudo: 0.00%)
[Iter 270] Gaussian 1 vs 0:
  Original Loss: 0.0346965
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0346965 (Pseudo: 0.00%)
[Iter 280/20000] Loss: 0.0348929 (Best: 0.0320895 @iter277) ([92m↓0.63%[0m) [13.86% of initial]
[Iter 280] Gaussian 0 vs 1:
  Original Loss: 0.0360350
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0360350 (Pseudo: 0.00%)
[Iter 280] Gaussian 1 vs 0:
  Original Loss: 0.0358975
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0358975 (Pseudo: 0.00%)
[Iter 290/20000] Loss: 0.0332877 (Best: 0.0307509 @iter287) ([92m↓4.60%[0m) [13.22% of initial]
[Iter 290] Gaussian 0 vs 1:
  Original Loss: 0.0321821
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0321821 (Pseudo: 0.00%)
[Iter 290] Gaussian 1 vs 0:
  Original Loss: 0.0320641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0320641 (Pseudo: 0.00%)
Iter:299, L1 loss=0.02223, Total loss=0.03345, Time:13
[Iter 300/20000] Loss: 0.0308694 (Best: 0.0289517 @iter300) ([92m↓7.26%[0m) [12.26% of initial]
[Iter 300] Gaussian 0 vs 1:
  Original Loss: 0.0289517
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0289517 (Pseudo: 0.00%)
[Iter 300] Gaussian 1 vs 0:
  Original Loss: 0.0288728
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0288728 (Pseudo: 0.00%)
[Iter 310/20000] Loss: 0.0294541 (Best: 0.0275258 @iter310) ([92m↓4.58%[0m) [11.70% of initial]
[Iter 310] Gaussian 0 vs 1:
  Original Loss: 0.0275258
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0275258 (Pseudo: 0.00%)
[Iter 310] Gaussian 1 vs 0:
  Original Loss: 0.0274410
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0274410 (Pseudo: 0.00%)
[Iter 320/20000] Loss: 0.0281077 (Best: 0.0268069 @iter320) ([92m↓4.57%[0m) [11.17% of initial]
[Iter 320] Gaussian 0 vs 1:
  Original Loss: 0.0268069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0268069 (Pseudo: 0.00%)
[Iter 320] Gaussian 1 vs 0:
  Original Loss: 0.0264823
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0264823 (Pseudo: 0.00%)
[Iter 330/20000] Loss: 0.0273802 (Best: 0.0254291 @iter330) ([92m↓2.59%[0m) [10.88% of initial]
[Iter 330] Gaussian 0 vs 1:
  Original Loss: 0.0254291
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0254291 (Pseudo: 0.00%)
[Iter 330] Gaussian 1 vs 0:
  Original Loss: 0.0255578
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0255578 (Pseudo: 0.00%)
[Iter 340/20000] Loss: 0.0252536 (Best: 0.0241521 @iter340) ([92m↓7.77%[0m) [10.03% of initial]
[Iter 340] Gaussian 0 vs 1:
  Original Loss: 0.0241521
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0241521 (Pseudo: 0.00%)
[Iter 340] Gaussian 1 vs 0:
  Original Loss: 0.0240770
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0240770 (Pseudo: 0.00%)
[Iter 350/20000] Loss: 0.0257944 (Best: 0.0230991 @iter349) ([91m↑2.14%[0m) [10.25% of initial]
[Iter 350] Gaussian 0 vs 1:
  Original Loss: 0.0271488
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0271488 (Pseudo: 0.00%)
[Iter 350] Gaussian 1 vs 0:
  Original Loss: 0.0272299
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0272299 (Pseudo: 0.00%)
[Iter 360/20000] Loss: 0.0242940 (Best: 0.0222765 @iter358) ([92m↓5.82%[0m) [9.65% of initial]
[Iter 360] Gaussian 0 vs 1:
  Original Loss: 0.0238383
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0238383 (Pseudo: 0.00%)
[Iter 360] Gaussian 1 vs 0:
  Original Loss: 0.0239671
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0239671 (Pseudo: 0.00%)
[Iter 370/20000] Loss: 0.0241734 (Best: 0.0218732 @iter361) ([92m↓0.50%[0m) [9.60% of initial]
[Iter 370] Gaussian 0 vs 1:
  Original Loss: 0.0253446
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0253446 (Pseudo: 0.00%)
[Iter 370] Gaussian 1 vs 0:
  Original Loss: 0.0250924
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0250924 (Pseudo: 0.00%)
[Iter 380/20000] Loss: 0.0217383 (Best: 0.0206792 @iter379) ([92m↓10.07%[0m) [8.64% of initial]
[Iter 380] Gaussian 0 vs 1:
  Original Loss: 0.0220522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0220522 (Pseudo: 0.00%)
[Iter 380] Gaussian 1 vs 0:
  Original Loss: 0.0221860
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0221860 (Pseudo: 0.00%)
[Iter 390/20000] Loss: 0.0213690 (Best: 0.0199424 @iter390) ([92m↓1.70%[0m) [8.49% of initial]
[Iter 390] Gaussian 0 vs 1:
  Original Loss: 0.0199424
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0199424 (Pseudo: 0.00%)
[Iter 390] Gaussian 1 vs 0:
  Original Loss: 0.0200245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0200245 (Pseudo: 0.00%)
Iter:399, L1 loss=0.01349, Total loss=0.02106, Time:13
[Iter 400/20000] Loss: 0.0203755 (Best: 0.0189369 @iter400) ([92m↓4.65%[0m) [8.09% of initial]
[Iter 400] Gaussian 0 vs 1:
  Original Loss: 0.0189369
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0189369 (Pseudo: 0.00%)
[Iter 400] Gaussian 1 vs 0:
  Original Loss: 0.0189504
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0189504 (Pseudo: 0.00%)
[Iter 410/20000] Loss: 0.0192299 (Best: 0.0182271 @iter410) ([92m↓5.62%[0m) [7.64% of initial]
[Iter 410] Gaussian 0 vs 1:
  Original Loss: 0.0182271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0182271 (Pseudo: 0.00%)
[Iter 410] Gaussian 1 vs 0:
  Original Loss: 0.0184672
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0184672 (Pseudo: 0.00%)
[Iter 420/20000] Loss: 0.0196615 (Best: 0.0175988 @iter418) ([91m↑2.24%[0m) [7.81% of initial]
[Iter 420] Gaussian 0 vs 1:
  Original Loss: 0.0208778
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0208778 (Pseudo: 0.00%)
[Iter 420] Gaussian 1 vs 0:
  Original Loss: 0.0213819
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0213819 (Pseudo: 0.00%)
[Iter 430/20000] Loss: 0.0175741 (Best: 0.0166156 @iter430) ([92m↓10.62%[0m) [6.98% of initial]
[Iter 430] Gaussian 0 vs 1:
  Original Loss: 0.0166156
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0166156 (Pseudo: 0.00%)
[Iter 430] Gaussian 1 vs 0:
  Original Loss: 0.0168131
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0168131 (Pseudo: 0.00%)
[Iter 440/20000] Loss: 0.0178229 (Best: 0.0162050 @iter438) ([91m↑1.42%[0m) [7.08% of initial]
[Iter 440] Gaussian 0 vs 1:
  Original Loss: 0.0185417
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0185417 (Pseudo: 0.00%)
[Iter 440] Gaussian 1 vs 0:
  Original Loss: 0.0190324
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0190324 (Pseudo: 0.00%)
[Iter 450/20000] Loss: 0.0168776 (Best: 0.0151192 @iter449) ([92m↓5.30%[0m) [6.71% of initial]
[Iter 450] Gaussian 0 vs 1:
  Original Loss: 0.0179629
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0179629 (Pseudo: 0.00%)
[Iter 450] Gaussian 1 vs 0:
  Original Loss: 0.0183206
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0183206 (Pseudo: 0.00%)
[Iter 460/20000] Loss: 0.0169664 (Best: 0.0149961 @iter458) ([91m↑0.53%[0m) [6.74% of initial]
[Iter 460] Gaussian 0 vs 1:
  Original Loss: 0.0176798
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0176798 (Pseudo: 0.00%)
[Iter 460] Gaussian 1 vs 0:
  Original Loss: 0.0169604
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0169604 (Pseudo: 0.00%)
[Iter 470/20000] Loss: 0.0151849 (Best: 0.0141054 @iter470) ([92m↓10.50%[0m) [6.03% of initial]
[Iter 470] Gaussian 0 vs 1:
  Original Loss: 0.0141054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0141054 (Pseudo: 0.00%)
[Iter 470] Gaussian 1 vs 0:
  Original Loss: 0.0141022
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0141022 (Pseudo: 0.00%)
[Iter 480/20000] Loss: 0.0147504 (Best: 0.0131768 @iter479) ([92m↓2.86%[0m) [5.86% of initial]
[Iter 480] Gaussian 0 vs 1:
  Original Loss: 0.0149577
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0149577 (Pseudo: 0.00%)
[Iter 480] Gaussian 1 vs 0:
  Original Loss: 0.0156600
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0156600 (Pseudo: 0.00%)
[Iter 490/20000] Loss: 0.0136229 (Best: 0.0125717 @iter490) ([92m↓7.64%[0m) [5.41% of initial]
[Iter 490] Gaussian 0 vs 1:
  Original Loss: 0.0125717
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0125717 (Pseudo: 0.00%)
[Iter 490] Gaussian 1 vs 0:
  Original Loss: 0.0129172
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0129172 (Pseudo: 0.00%)
Iter:499, L1 loss=0.008572, Total loss=0.01473, Time:13
[Iter 500/20000] Loss: 0.0138864 (Best: 0.0125717 @iter490) ([91m↑1.93%[0m) [5.52% of initial]
[Iter 500] Gaussian 0 vs 1:
  Original Loss: 0.0135728
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0135728 (Pseudo: 0.00%)
[Iter 500] Gaussian 1 vs 0:
  Original Loss: 0.0138634
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0138634 (Pseudo: 0.00%)
[Iter 510/20000] Loss: 0.0137117 (Best: 0.0122981 @iter508) ([92m↓1.26%[0m) [5.45% of initial]
[Iter 510] Gaussian 0 vs 1:
  Original Loss: 0.0138867
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0138867 (Pseudo: 0.00%)
[Iter 510] Gaussian 1 vs 0:
  Original Loss: 0.0140105
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0140105 (Pseudo: 0.00%)
[Iter 520/20000] Loss: 0.0130142 (Best: 0.0118542 @iter514) ([92m↓5.09%[0m) [5.17% of initial]
[Iter 520] Gaussian 0 vs 1:
  Original Loss: 0.0130147
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0130147 (Pseudo: 0.00%)
[Iter 520] Gaussian 1 vs 0:
  Original Loss: 0.0137921
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0137921 (Pseudo: 0.00%)
[Iter 530/20000] Loss: 0.0125349 (Best: 0.0113220 @iter529) ([92m↓3.68%[0m) [4.98% of initial]
[Iter 530] Gaussian 0 vs 1:
  Original Loss: 0.0127368
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0127368 (Pseudo: 0.00%)
[Iter 530] Gaussian 1 vs 0:
  Original Loss: 0.0128324
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0128324 (Pseudo: 0.00%)
[Iter 540/20000] Loss: 0.0123509 (Best: 0.0109954 @iter538) ([92m↓1.47%[0m) [4.91% of initial]
[Iter 540] Gaussian 0 vs 1:
  Original Loss: 0.0123127
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0123127 (Pseudo: 0.00%)
[Iter 540] Gaussian 1 vs 0:
  Original Loss: 0.0124902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0124902 (Pseudo: 0.00%)
[Iter 550/20000] Loss: 0.0120223 (Best: 0.0108873 @iter548) ([92m↓2.66%[0m) [4.78% of initial]
[Iter 550] Gaussian 0 vs 1:
  Original Loss: 0.0120178
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0120178 (Pseudo: 0.00%)
[Iter 550] Gaussian 1 vs 0:
  Original Loss: 0.0120192
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0120192 (Pseudo: 0.00%)
[Iter 560/20000] Loss: 0.0120279 (Best: 0.0107718 @iter554) ([91m↑0.05%[0m) [4.78% of initial]
[Iter 560] Gaussian 0 vs 1:
  Original Loss: 0.0117566
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0117566 (Pseudo: 0.00%)
[Iter 560] Gaussian 1 vs 0:
  Original Loss: 0.0120415
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0120415 (Pseudo: 0.00%)
[Iter 570/20000] Loss: 0.0116612 (Best: 0.0105740 @iter569) ([92m↓3.05%[0m) [4.63% of initial]
[Iter 570] Gaussian 0 vs 1:
  Original Loss: 0.0125414
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0125414 (Pseudo: 0.00%)
[Iter 570] Gaussian 1 vs 0:
  Original Loss: 0.0124742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0124742 (Pseudo: 0.00%)
[Iter 580/20000] Loss: 0.0111474 (Best: 0.0102315 @iter578) ([92m↓4.41%[0m) [4.43% of initial]
[Iter 580] Gaussian 0 vs 1:
  Original Loss: 0.0111191
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0111191 (Pseudo: 0.00%)
[Iter 580] Gaussian 1 vs 0:
  Original Loss: 0.0112327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0112327 (Pseudo: 0.00%)
[Iter 590/20000] Loss: 0.0112633 (Best: 0.0101339 @iter581) ([91m↑1.04%[0m) [4.47% of initial]
[Iter 590] Gaussian 0 vs 1:
  Original Loss: 0.0110161
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0110161 (Pseudo: 0.00%)
[Iter 590] Gaussian 1 vs 0:
  Original Loss: 0.0115692
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0115692 (Pseudo: 0.00%)
Iter:599, L1 loss=0.007102, Total loss=0.01171, Time:12
[Iter 600/20000] Loss: 0.0109169 (Best: 0.0099806 @iter597) ([92m↓3.08%[0m) [4.34% of initial]
[Iter 600] Gaussian 0 vs 1:
  Original Loss: 0.0109069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0109069 (Pseudo: 0.00%)
[Iter 600] Gaussian 1 vs 0:
  Original Loss: 0.0112734
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0112734 (Pseudo: 0.00%)
[Iter 610/20000] Loss: 0.0226870 (Best: 0.0099806 @iter597) ([91m↑107.82%[0m) [9.01% of initial]
[Iter 610] Gaussian 0 vs 1:
  Original Loss: 0.0201165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0201165 (Pseudo: 0.00%)
[Iter 610] Gaussian 1 vs 0:
  Original Loss: 0.0185503
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0185503 (Pseudo: 0.00%)
[Iter 620/20000] Loss: 0.0142463 (Best: 0.0099806 @iter597) ([92m↓37.20%[0m) [5.66% of initial]
[Iter 620] Gaussian 0 vs 1:
  Original Loss: 0.0128440
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0128440 (Pseudo: 0.00%)
[Iter 620] Gaussian 1 vs 0:
  Original Loss: 0.0127735
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0127735 (Pseudo: 0.00%)
[Iter 630/20000] Loss: 0.0121296 (Best: 0.0099806 @iter597) ([92m↓14.86%[0m) [4.82% of initial]
[Iter 630] Gaussian 0 vs 1:
  Original Loss: 0.0111938
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0111938 (Pseudo: 0.00%)
[Iter 630] Gaussian 1 vs 0:
  Original Loss: 0.0115964
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0115964 (Pseudo: 0.00%)
[Iter 640/20000] Loss: 0.0103583 (Best: 0.0093827 @iter640) ([92m↓14.60%[0m) [4.12% of initial]
[Iter 640] Gaussian 0 vs 1:
  Original Loss: 0.0093827
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0093827 (Pseudo: 0.00%)
[Iter 640] Gaussian 1 vs 0:
  Original Loss: 0.0096929
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0096929 (Pseudo: 0.00%)
[Iter 650/20000] Loss: 0.0106687 (Best: 0.0090992 @iter646) ([91m↑3.00%[0m) [4.24% of initial]
[Iter 650] Gaussian 0 vs 1:
  Original Loss: 0.0106487
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0106487 (Pseudo: 0.00%)
[Iter 650] Gaussian 1 vs 0:
  Original Loss: 0.0104906
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0104906 (Pseudo: 0.00%)
[Iter 660/20000] Loss: 0.0100758 (Best: 0.0088308 @iter655) ([92m↓5.56%[0m) [4.00% of initial]
[Iter 660] Gaussian 0 vs 1:
  Original Loss: 0.0107269
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0107269 (Pseudo: 0.00%)
[Iter 660] Gaussian 1 vs 0:
  Original Loss: 0.0105760
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0105760 (Pseudo: 0.00%)
[Iter 670/20000] Loss: 0.0096225 (Best: 0.0085632 @iter667) ([92m↓4.50%[0m) [3.82% of initial]
[Iter 670] Gaussian 0 vs 1:
  Original Loss: 0.0095038
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0095038 (Pseudo: 0.00%)
[Iter 670] Gaussian 1 vs 0:
  Original Loss: 0.0095573
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0095573 (Pseudo: 0.00%)
[Iter 680/20000] Loss: 0.0089444 (Best: 0.0083295 @iter680) ([92m↓7.05%[0m) [3.55% of initial]
[Iter 680] Gaussian 0 vs 1:
  Original Loss: 0.0083295
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0083295 (Pseudo: 0.00%)
[Iter 680] Gaussian 1 vs 0:
  Original Loss: 0.0084241
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0084241 (Pseudo: 0.00%)
[Iter 690/20000] Loss: 0.0091424 (Best: 0.0079674 @iter682) ([91m↑2.21%[0m) [3.63% of initial]
[Iter 690] Gaussian 0 vs 1:
  Original Loss: 0.0086427
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0086427 (Pseudo: 0.00%)
[Iter 690] Gaussian 1 vs 0:
  Original Loss: 0.0091220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0091220 (Pseudo: 0.00%)
Iter:699, L1 loss=0.005858, Total loss=0.009582, Time:12
[Iter 700/20000] Loss: 0.0090638 (Best: 0.0079674 @iter682) ([92m↓0.86%[0m) [3.60% of initial]
[Iter 700] Gaussian 0 vs 1:
  Original Loss: 0.0090543
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0090543 (Pseudo: 0.00%)
[Iter 700] Gaussian 1 vs 0:
  Original Loss: 0.0089196
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0089196 (Pseudo: 0.00%)
[Iter 710/20000] Loss: 0.0084859 (Best: 0.0079323 @iter710) ([92m↓6.38%[0m) [3.37% of initial]
[Iter 710] Gaussian 0 vs 1:
  Original Loss: 0.0079323
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0079323 (Pseudo: 0.00%)
[Iter 710] Gaussian 1 vs 0:
  Original Loss: 0.0078393
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0078393 (Pseudo: 0.00%)
[Iter 720/20000] Loss: 0.0084705 (Best: 0.0077359 @iter715) ([92m↓0.18%[0m) [3.37% of initial]
[Iter 720] Gaussian 0 vs 1:
  Original Loss: 0.0079169
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0079169 (Pseudo: 0.00%)
[Iter 720] Gaussian 1 vs 0:
  Original Loss: 0.0078790
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0078790 (Pseudo: 0.00%)
[Iter 730/20000] Loss: 0.0085133 (Best: 0.0074094 @iter727) ([91m↑0.50%[0m) [3.38% of initial]
[Iter 730] Gaussian 0 vs 1:
  Original Loss: 0.0084818
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0084818 (Pseudo: 0.00%)
[Iter 730] Gaussian 1 vs 0:
  Original Loss: 0.0085123
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0085123 (Pseudo: 0.00%)
[Iter 740/20000] Loss: 0.0084903 (Best: 0.0073121 @iter733) ([92m↓0.27%[0m) [3.37% of initial]
[Iter 740] Gaussian 0 vs 1:
  Original Loss: 0.0085625
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0085625 (Pseudo: 0.00%)
[Iter 740] Gaussian 1 vs 0:
  Original Loss: 0.0087329
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0087329 (Pseudo: 0.00%)
[Iter 750/20000] Loss: 0.0080259 (Best: 0.0069940 @iter748) ([92m↓5.47%[0m) [3.19% of initial]
[Iter 750] Gaussian 0 vs 1:
  Original Loss: 0.0080502
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0080502 (Pseudo: 0.00%)
[Iter 750] Gaussian 1 vs 0:
  Original Loss: 0.0081641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0081641 (Pseudo: 0.00%)
[Iter 760/20000] Loss: 0.0073984 (Best: 0.0069245 @iter751) ([92m↓7.82%[0m) [2.94% of initial]
[Iter 760] Gaussian 0 vs 1:
  Original Loss: 0.0070047
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0070047 (Pseudo: 0.00%)
[Iter 760] Gaussian 1 vs 0:
  Original Loss: 0.0070974
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0070974 (Pseudo: 0.00%)
[Iter 770/20000] Loss: 0.0077021 (Best: 0.0069245 @iter751) ([91m↑4.10%[0m) [3.06% of initial]
[Iter 770] Gaussian 0 vs 1:
  Original Loss: 0.0080962
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0080962 (Pseudo: 0.00%)
[Iter 770] Gaussian 1 vs 0:
  Original Loss: 0.0079177
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0079177 (Pseudo: 0.00%)
[Iter 780/20000] Loss: 0.0078750 (Best: 0.0068429 @iter778) ([91m↑2.24%[0m) [3.13% of initial]
[Iter 780] Gaussian 0 vs 1:
  Original Loss: 0.0084408
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0084408 (Pseudo: 0.00%)
[Iter 780] Gaussian 1 vs 0:
  Original Loss: 0.0083337
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0083337 (Pseudo: 0.00%)
[Iter 790/20000] Loss: 0.0077143 (Best: 0.0066965 @iter787) ([92m↓2.04%[0m) [3.06% of initial]
[Iter 790] Gaussian 0 vs 1:
  Original Loss: 0.0077066
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0077066 (Pseudo: 0.00%)
[Iter 790] Gaussian 1 vs 0:
  Original Loss: 0.0075599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0075599 (Pseudo: 0.00%)
Iter:799, L1 loss=0.005002, Total loss=0.008045, Time:12
[Iter 800/20000] Loss: 0.0073670 (Best: 0.0066757 @iter800) ([92m↓4.50%[0m) [2.93% of initial]
[Iter 800] Gaussian 0 vs 1:
  Original Loss: 0.0066757
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066757 (Pseudo: 0.00%)
[Iter 800] Gaussian 1 vs 0:
  Original Loss: 0.0067306
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067306 (Pseudo: 0.00%)
[Iter 810/20000] Loss: 0.0155931 (Best: 0.0066757 @iter800) ([91m↑111.66%[0m) [6.19% of initial]
[Iter 810] Gaussian 0 vs 1:
  Original Loss: 0.0143672
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0143672 (Pseudo: 0.00%)
[Iter 810] Gaussian 1 vs 0:
  Original Loss: 0.0140984
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0140984 (Pseudo: 0.00%)
[Iter 820/20000] Loss: 0.0108039 (Best: 0.0066757 @iter800) ([92m↓30.71%[0m) [4.29% of initial]
[Iter 820] Gaussian 0 vs 1:
  Original Loss: 0.0106544
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0106544 (Pseudo: 0.00%)
[Iter 820] Gaussian 1 vs 0:
  Original Loss: 0.0108468
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0108468 (Pseudo: 0.00%)
[Iter 830/20000] Loss: 0.0088772 (Best: 0.0066757 @iter800) ([92m↓17.83%[0m) [3.53% of initial]
[Iter 830] Gaussian 0 vs 1:
  Original Loss: 0.0093897
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0093897 (Pseudo: 0.00%)
[Iter 830] Gaussian 1 vs 0:
  Original Loss: 0.0090073
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0090073 (Pseudo: 0.00%)
[Iter 840/20000] Loss: 0.0080064 (Best: 0.0066757 @iter800) ([92m↓9.81%[0m) [3.18% of initial]
[Iter 840] Gaussian 0 vs 1:
  Original Loss: 0.0087939
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0087939 (Pseudo: 0.00%)
[Iter 840] Gaussian 1 vs 0:
  Original Loss: 0.0086543
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0086543 (Pseudo: 0.00%)
[Iter 850/20000] Loss: 0.0074728 (Best: 0.0066110 @iter841) ([92m↓6.66%[0m) [2.97% of initial]
[Iter 850] Gaussian 0 vs 1:
  Original Loss: 0.0072854
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0072854 (Pseudo: 0.00%)
[Iter 850] Gaussian 1 vs 0:
  Original Loss: 0.0073029
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0073029 (Pseudo: 0.00%)
[Iter 860/20000] Loss: 0.0069943 (Best: 0.0062077 @iter856) ([92m↓6.40%[0m) [2.78% of initial]
[Iter 860] Gaussian 0 vs 1:
  Original Loss: 0.0070418
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0070418 (Pseudo: 0.00%)
[Iter 860] Gaussian 1 vs 0:
  Original Loss: 0.0071603
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0071603 (Pseudo: 0.00%)
[Iter 870/20000] Loss: 0.0067155 (Best: 0.0060387 @iter862) ([92m↓3.99%[0m) [2.67% of initial]
[Iter 870] Gaussian 0 vs 1:
  Original Loss: 0.0062320
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062320 (Pseudo: 0.00%)
[Iter 870] Gaussian 1 vs 0:
  Original Loss: 0.0063596
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063596 (Pseudo: 0.00%)
[Iter 880/20000] Loss: 0.0067303 (Best: 0.0059206 @iter872) ([91m↑0.22%[0m) [2.67% of initial]
[Iter 880] Gaussian 0 vs 1:
  Original Loss: 0.0066641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066641 (Pseudo: 0.00%)
[Iter 880] Gaussian 1 vs 0:
  Original Loss: 0.0067342
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067342 (Pseudo: 0.00%)
[Iter 890/20000] Loss: 0.0062558 (Best: 0.0056485 @iter884) ([92m↓7.05%[0m) [2.49% of initial]
[Iter 890] Gaussian 0 vs 1:
  Original Loss: 0.0057310
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0057310 (Pseudo: 0.00%)
[Iter 890] Gaussian 1 vs 0:
  Original Loss: 0.0059526
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0059526 (Pseudo: 0.00%)
Iter:899, L1 loss=0.003776, Total loss=0.005591, Time:13
[Iter 900/20000] Loss: 0.0064417 (Best: 0.0055795 @iter896) ([91m↑2.97%[0m) [2.56% of initial]
[Iter 900] Gaussian 0 vs 1:
  Original Loss: 0.0065312
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0065312 (Pseudo: 0.00%)
[Iter 900] Gaussian 1 vs 0:
  Original Loss: 0.0066473
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066473 (Pseudo: 0.00%)
[Iter 910/20000] Loss: 0.0065861 (Best: 0.0053523 @iter907) ([91m↑2.24%[0m) [2.62% of initial]
[Iter 910] Gaussian 0 vs 1:
  Original Loss: 0.0069971
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0069971 (Pseudo: 0.00%)
[Iter 910] Gaussian 1 vs 0:
  Original Loss: 0.0068304
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0068304 (Pseudo: 0.00%)
[Iter 920/20000] Loss: 0.0059679 (Best: 0.0052495 @iter916) ([92m↓9.39%[0m) [2.37% of initial]
[Iter 920] Gaussian 0 vs 1:
  Original Loss: 0.0060867
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060867 (Pseudo: 0.00%)
[Iter 920] Gaussian 1 vs 0:
  Original Loss: 0.0062539
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062539 (Pseudo: 0.00%)
[Iter 930/20000] Loss: 0.0063876 (Best: 0.0052495 @iter916) ([91m↑7.03%[0m) [2.54% of initial]
[Iter 930] Gaussian 0 vs 1:
  Original Loss: 0.0068599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0068599 (Pseudo: 0.00%)
[Iter 930] Gaussian 1 vs 0:
  Original Loss: 0.0067122
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067122 (Pseudo: 0.00%)
[Iter 940/20000] Loss: 0.0064095 (Best: 0.0051416 @iter938) ([91m↑0.34%[0m) [2.55% of initial]
[Iter 940] Gaussian 0 vs 1:
  Original Loss: 0.0067858
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067858 (Pseudo: 0.00%)
[Iter 940] Gaussian 1 vs 0:
  Original Loss: 0.0066155
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066155 (Pseudo: 0.00%)
[Iter 950/20000] Loss: 0.0059223 (Best: 0.0051416 @iter938) ([92m↓7.60%[0m) [2.35% of initial]
[Iter 950] Gaussian 0 vs 1:
  Original Loss: 0.0055614
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0055614 (Pseudo: 0.00%)
[Iter 950] Gaussian 1 vs 0:
  Original Loss: 0.0058549
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058549 (Pseudo: 0.00%)
[Iter 960/20000] Loss: 0.0060871 (Best: 0.0051416 @iter938) ([91m↑2.78%[0m) [2.42% of initial]
[Iter 960] Gaussian 0 vs 1:
  Original Loss: 0.0062680
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062680 (Pseudo: 0.00%)
[Iter 960] Gaussian 1 vs 0:
  Original Loss: 0.0063805
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063805 (Pseudo: 0.00%)
[Iter 970/20000] Loss: 0.0059262 (Best: 0.0051416 @iter938) ([92m↓2.64%[0m) [2.35% of initial]
[Iter 970] Gaussian 0 vs 1:
  Original Loss: 0.0057799
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0057799 (Pseudo: 0.00%)
[Iter 970] Gaussian 1 vs 0:
  Original Loss: 0.0058966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058966 (Pseudo: 0.00%)
[Iter 980/20000] Loss: 0.0061291 (Best: 0.0050736 @iter979) ([91m↑3.42%[0m) [2.44% of initial]
[Iter 980] Gaussian 0 vs 1:
  Original Loss: 0.0069057
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0069057 (Pseudo: 0.00%)
[Iter 980] Gaussian 1 vs 0:
  Original Loss: 0.0066209
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066209 (Pseudo: 0.00%)
[Iter 990/20000] Loss: 0.0061184 (Best: 0.0050736 @iter979) ([92m↓0.17%[0m) [2.43% of initial]
[Iter 990] Gaussian 0 vs 1:
  Original Loss: 0.0061681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061681 (Pseudo: 0.00%)
[Iter 990] Gaussian 1 vs 0:
  Original Loss: 0.0064471
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0064471 (Pseudo: 0.00%)
Iter:999, L1 loss=0.004395, Total loss=0.006974, Time:13
[Iter 1000/20000] Loss: 0.0064544 (Best: 0.0050736 @iter979) ([91m↑5.49%[0m) [2.56% of initial]
[Iter 1000] Gaussian 0 vs 1:
  Original Loss: 0.0067566
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067566 (Pseudo: 0.00%)
[Iter 1000] Gaussian 1 vs 0:
  Original Loss: 0.0063786
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063786 (Pseudo: 0.00%)
[Iter 1010/20000] Loss: 0.0114101 (Best: 0.0050736 @iter979) ([91m↑76.78%[0m) [4.53% of initial]
[Iter 1010] Gaussian 0 vs 1:
  Original Loss: 0.0110085
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0110085 (Pseudo: 0.00%)
[Iter 1010] Gaussian 1 vs 0:
  Original Loss: 0.0111303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0111303 (Pseudo: 0.00%)
[Iter 1020/20000] Loss: 0.0084174 (Best: 0.0050736 @iter979) ([92m↓26.23%[0m) [3.34% of initial]
[Iter 1020] Gaussian 0 vs 1:
  Original Loss: 0.0080219
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0080219 (Pseudo: 0.00%)
[Iter 1020] Gaussian 1 vs 0:
  Original Loss: 0.0078563
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0078563 (Pseudo: 0.00%)
[Iter 1030/20000] Loss: 0.0069297 (Best: 0.0050736 @iter979) ([92m↓17.67%[0m) [2.75% of initial]
[Iter 1030] Gaussian 0 vs 1:
  Original Loss: 0.0060526
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060526 (Pseudo: 0.00%)
[Iter 1030] Gaussian 1 vs 0:
  Original Loss: 0.0062755
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062755 (Pseudo: 0.00%)
[Iter 1040/20000] Loss: 0.0061052 (Best: 0.0050736 @iter979) ([92m↓11.90%[0m) [2.43% of initial]
[Iter 1040] Gaussian 0 vs 1:
  Original Loss: 0.0060792
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060792 (Pseudo: 0.00%)
[Iter 1040] Gaussian 1 vs 0:
  Original Loss: 0.0063612
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063612 (Pseudo: 0.00%)
[Iter 1050/20000] Loss: 0.0059193 (Best: 0.0050736 @iter979) ([92m↓3.04%[0m) [2.35% of initial]
[Iter 1050] Gaussian 0 vs 1:
  Original Loss: 0.0060871
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060871 (Pseudo: 0.00%)
[Iter 1050] Gaussian 1 vs 0:
  Original Loss: 0.0062946
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062946 (Pseudo: 0.00%)
[Iter 1060/20000] Loss: 0.0058083 (Best: 0.0048987 @iter1055) ([92m↓1.88%[0m) [2.31% of initial]
[Iter 1060] Gaussian 0 vs 1:
  Original Loss: 0.0060189
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060189 (Pseudo: 0.00%)
[Iter 1060] Gaussian 1 vs 0:
  Original Loss: 0.0060832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060832 (Pseudo: 0.00%)
[Iter 1070/20000] Loss: 0.0055100 (Best: 0.0045490 @iter1066) ([92m↓5.13%[0m) [2.19% of initial]
[Iter 1070] Gaussian 0 vs 1:
  Original Loss: 0.0061190
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061190 (Pseudo: 0.00%)
[Iter 1070] Gaussian 1 vs 0:
  Original Loss: 0.0061778
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061778 (Pseudo: 0.00%)
[Iter 1080/20000] Loss: 0.0052826 (Best: 0.0045490 @iter1066) ([92m↓4.13%[0m) [2.10% of initial]
[Iter 1080] Gaussian 0 vs 1:
  Original Loss: 0.0049614
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049614 (Pseudo: 0.00%)
[Iter 1080] Gaussian 1 vs 0:
  Original Loss: 0.0051746
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051746 (Pseudo: 0.00%)
[Iter 1090/20000] Loss: 0.0051041 (Best: 0.0045490 @iter1066) ([92m↓3.38%[0m) [2.03% of initial]
[Iter 1090] Gaussian 0 vs 1:
  Original Loss: 0.0049920
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049920 (Pseudo: 0.00%)
[Iter 1090] Gaussian 1 vs 0:
  Original Loss: 0.0053022
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0053022 (Pseudo: 0.00%)
Iter:1099, L1 loss=0.003567, Total loss=0.005011, Time:13
[Iter 1100/20000] Loss: 0.0050463 (Best: 0.0042903 @iter1093) ([92m↓1.13%[0m) [2.00% of initial]
[Iter 1100] Gaussian 0 vs 1:
  Original Loss: 0.0048681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048681 (Pseudo: 0.00%)
[Iter 1100] Gaussian 1 vs 0:
  Original Loss: 0.0047489
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047489 (Pseudo: 0.00%)
[Iter 1110/20000] Loss: 0.0050618 (Best: 0.0042903 @iter1093) ([91m↑0.31%[0m) [2.01% of initial]
[Iter 1110] Gaussian 0 vs 1:
  Original Loss: 0.0047674
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047674 (Pseudo: 0.00%)
[Iter 1110] Gaussian 1 vs 0:
  Original Loss: 0.0047834
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047834 (Pseudo: 0.00%)
[Iter 1120/20000] Loss: 0.0050564 (Best: 0.0042158 @iter1117) ([92m↓0.11%[0m) [2.01% of initial]
[Iter 1120] Gaussian 0 vs 1:
  Original Loss: 0.0049531
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049531 (Pseudo: 0.00%)
[Iter 1120] Gaussian 1 vs 0:
  Original Loss: 0.0050849
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0050849 (Pseudo: 0.00%)
[Iter 1130/20000] Loss: 0.0053555 (Best: 0.0042158 @iter1117) ([91m↑5.91%[0m) [2.13% of initial]
[Iter 1130] Gaussian 0 vs 1:
  Original Loss: 0.0057057
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0057057 (Pseudo: 0.00%)
[Iter 1130] Gaussian 1 vs 0:
  Original Loss: 0.0056902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0056902 (Pseudo: 0.00%)
[Iter 1140/20000] Loss: 0.0048608 (Best: 0.0041515 @iter1135) ([92m↓9.24%[0m) [1.93% of initial]
[Iter 1140] Gaussian 0 vs 1:
  Original Loss: 0.0048785
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048785 (Pseudo: 0.00%)
[Iter 1140] Gaussian 1 vs 0:
  Original Loss: 0.0052467
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0052467 (Pseudo: 0.00%)
[Iter 1150/20000] Loss: 0.0045524 (Best: 0.0040602 @iter1145) ([92m↓6.35%[0m) [1.81% of initial]
[Iter 1150] Gaussian 0 vs 1:
  Original Loss: 0.0041553
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041553 (Pseudo: 0.00%)
[Iter 1150] Gaussian 1 vs 0:
  Original Loss: 0.0041444
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041444 (Pseudo: 0.00%)
[Iter 1160/20000] Loss: 0.0053142 (Best: 0.0040602 @iter1145) ([91m↑16.73%[0m) [2.11% of initial]
[Iter 1160] Gaussian 0 vs 1:
  Original Loss: 0.0052046
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0052046 (Pseudo: 0.00%)
[Iter 1160] Gaussian 1 vs 0:
  Original Loss: 0.0051235
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051235 (Pseudo: 0.00%)
[Iter 1170/20000] Loss: 0.0048004 (Best: 0.0040602 @iter1145) ([92m↓9.67%[0m) [1.91% of initial]
[Iter 1170] Gaussian 0 vs 1:
  Original Loss: 0.0044588
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044588 (Pseudo: 0.00%)
[Iter 1170] Gaussian 1 vs 0:
  Original Loss: 0.0044537
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044537 (Pseudo: 0.00%)
[Iter 1180/20000] Loss: 0.0044208 (Best: 0.0040134 @iter1180) ([92m↓7.91%[0m) [1.76% of initial]
[Iter 1180] Gaussian 0 vs 1:
  Original Loss: 0.0040134
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040134 (Pseudo: 0.00%)
[Iter 1180] Gaussian 1 vs 0:
  Original Loss: 0.0039972
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039972 (Pseudo: 0.00%)
[Iter 1190/20000] Loss: 0.0047045 (Best: 0.0039785 @iter1183) ([91m↑6.42%[0m) [1.87% of initial]
[Iter 1190] Gaussian 0 vs 1:
  Original Loss: 0.0044426
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044426 (Pseudo: 0.00%)
[Iter 1190] Gaussian 1 vs 0:
  Original Loss: 0.0045378
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0045378 (Pseudo: 0.00%)
Iter:1199, L1 loss=0.003503, Total loss=0.005189, Time:12
[Iter 1200/20000] Loss: 0.0047256 (Best: 0.0038068 @iter1195) ([91m↑0.45%[0m) [1.88% of initial]
[Iter 1200] Gaussian 0 vs 1:
  Original Loss: 0.0046813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046813 (Pseudo: 0.00%)
[Iter 1200] Gaussian 1 vs 0:
  Original Loss: 0.0047296
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047296 (Pseudo: 0.00%)
[Iter 1210/20000] Loss: 0.0109549 (Best: 0.0038068 @iter1195) ([91m↑131.82%[0m) [4.35% of initial]
[Iter 1210] Gaussian 0 vs 1:
  Original Loss: 0.0099916
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0099916 (Pseudo: 0.00%)
[Iter 1210] Gaussian 1 vs 0:
  Original Loss: 0.0096570
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0096570 (Pseudo: 0.00%)
[Iter 1220/20000] Loss: 0.0068332 (Best: 0.0038068 @iter1195) ([92m↓37.62%[0m) [2.71% of initial]
[Iter 1220] Gaussian 0 vs 1:
  Original Loss: 0.0060282
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060282 (Pseudo: 0.00%)
[Iter 1220] Gaussian 1 vs 0:
  Original Loss: 0.0063220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063220 (Pseudo: 0.00%)
[Iter 1230/20000] Loss: 0.0060294 (Best: 0.0038068 @iter1195) ([92m↓11.76%[0m) [2.40% of initial]
[Iter 1230] Gaussian 0 vs 1:
  Original Loss: 0.0063008
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063008 (Pseudo: 0.00%)
[Iter 1230] Gaussian 1 vs 0:
  Original Loss: 0.0064186
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0064186 (Pseudo: 0.00%)
[Iter 1240/20000] Loss: 0.0054698 (Best: 0.0038068 @iter1195) ([92m↓9.28%[0m) [2.17% of initial]
[Iter 1240] Gaussian 0 vs 1:
  Original Loss: 0.0055870
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0055870 (Pseudo: 0.00%)
[Iter 1240] Gaussian 1 vs 0:
  Original Loss: 0.0056606
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0056606 (Pseudo: 0.00%)
[Iter 1250/20000] Loss: 0.0048943 (Best: 0.0038068 @iter1195) ([92m↓10.52%[0m) [1.94% of initial]
[Iter 1250] Gaussian 0 vs 1:
  Original Loss: 0.0048327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048327 (Pseudo: 0.00%)
[Iter 1250] Gaussian 1 vs 0:
  Original Loss: 0.0047515
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047515 (Pseudo: 0.00%)
[Iter 1260/20000] Loss: 0.0046114 (Best: 0.0037392 @iter1258) ([92m↓5.78%[0m) [1.83% of initial]
[Iter 1260] Gaussian 0 vs 1:
  Original Loss: 0.0051861
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051861 (Pseudo: 0.00%)
[Iter 1260] Gaussian 1 vs 0:
  Original Loss: 0.0052220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0052220 (Pseudo: 0.00%)
[Iter 1270/20000] Loss: 0.0040766 (Best: 0.0037022 @iter1269) ([92m↓11.60%[0m) [1.62% of initial]
[Iter 1270] Gaussian 0 vs 1:
  Original Loss: 0.0040252
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040252 (Pseudo: 0.00%)
[Iter 1270] Gaussian 1 vs 0:
  Original Loss: 0.0042140
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0042140 (Pseudo: 0.00%)
[Iter 1280/20000] Loss: 0.0043350 (Best: 0.0033428 @iter1273) ([91m↑6.34%[0m) [1.72% of initial]
[Iter 1280] Gaussian 0 vs 1:
  Original Loss: 0.0041768
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041768 (Pseudo: 0.00%)
[Iter 1280] Gaussian 1 vs 0:
  Original Loss: 0.0043471
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043471 (Pseudo: 0.00%)
[Iter 1290/20000] Loss: 0.0042305 (Best: 0.0033112 @iter1285) ([92m↓2.41%[0m) [1.68% of initial]
[Iter 1290] Gaussian 0 vs 1:
  Original Loss: 0.0047379
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047379 (Pseudo: 0.00%)
[Iter 1290] Gaussian 1 vs 0:
  Original Loss: 0.0048158
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048158 (Pseudo: 0.00%)
Iter:1299, L1 loss=0.002804, Total loss=0.003782, Time:13
[Iter 1300/20000] Loss: 0.0040906 (Best: 0.0033112 @iter1285) ([92m↓3.31%[0m) [1.63% of initial]
[Iter 1300] Gaussian 0 vs 1:
  Original Loss: 0.0041029
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041029 (Pseudo: 0.00%)
[Iter 1300] Gaussian 1 vs 0:
  Original Loss: 0.0039666
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039666 (Pseudo: 0.00%)
[Iter 1310/20000] Loss: 0.0041188 (Best: 0.0033112 @iter1285) ([91m↑0.69%[0m) [1.64% of initial]
[Iter 1310] Gaussian 0 vs 1:
  Original Loss: 0.0038565
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038565 (Pseudo: 0.00%)
[Iter 1310] Gaussian 1 vs 0:
  Original Loss: 0.0038989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038989 (Pseudo: 0.00%)
[Iter 1320/20000] Loss: 0.0039904 (Best: 0.0031883 @iter1319) ([92m↓3.12%[0m) [1.59% of initial]
[Iter 1320] Gaussian 0 vs 1:
  Original Loss: 0.0046733
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046733 (Pseudo: 0.00%)
[Iter 1320] Gaussian 1 vs 0:
  Original Loss: 0.0045786
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0045786 (Pseudo: 0.00%)
[Iter 1330/20000] Loss: 0.0039792 (Best: 0.0031157 @iter1321) ([92m↓0.28%[0m) [1.58% of initial]
[Iter 1330] Gaussian 0 vs 1:
  Original Loss: 0.0041166
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041166 (Pseudo: 0.00%)
[Iter 1330] Gaussian 1 vs 0:
  Original Loss: 0.0041100
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041100 (Pseudo: 0.00%)
[Iter 1340/20000] Loss: 0.0037062 (Best: 0.0031157 @iter1321) ([92m↓6.86%[0m) [1.47% of initial]
[Iter 1340] Gaussian 0 vs 1:
  Original Loss: 0.0033376
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033376 (Pseudo: 0.00%)
[Iter 1340] Gaussian 1 vs 0:
  Original Loss: 0.0033620
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033620 (Pseudo: 0.00%)
[Iter 1350/20000] Loss: 0.0037873 (Best: 0.0031157 @iter1321) ([91m↑2.19%[0m) [1.50% of initial]
[Iter 1350] Gaussian 0 vs 1:
  Original Loss: 0.0033853
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033853 (Pseudo: 0.00%)
[Iter 1350] Gaussian 1 vs 0:
  Original Loss: 0.0033520
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033520 (Pseudo: 0.00%)
[Iter 1360/20000] Loss: 0.0038166 (Best: 0.0031157 @iter1321) ([91m↑0.77%[0m) [1.52% of initial]
[Iter 1360] Gaussian 0 vs 1:
  Original Loss: 0.0035835
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035835 (Pseudo: 0.00%)
[Iter 1360] Gaussian 1 vs 0:
  Original Loss: 0.0037782
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0037782 (Pseudo: 0.00%)
[Iter 1370/20000] Loss: 0.0037579 (Best: 0.0031157 @iter1321) ([92m↓1.54%[0m) [1.49% of initial]
[Iter 1370] Gaussian 0 vs 1:
  Original Loss: 0.0033161
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033161 (Pseudo: 0.00%)
[Iter 1370] Gaussian 1 vs 0:
  Original Loss: 0.0033149
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033149 (Pseudo: 0.00%)
[Iter 1380/20000] Loss: 0.0039391 (Best: 0.0031157 @iter1321) ([91m↑4.82%[0m) [1.56% of initial]
[Iter 1380] Gaussian 0 vs 1:
  Original Loss: 0.0039523
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039523 (Pseudo: 0.00%)
[Iter 1380] Gaussian 1 vs 0:
  Original Loss: 0.0039351
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039351 (Pseudo: 0.00%)
[Iter 1390/20000] Loss: 0.0037141 (Best: 0.0031157 @iter1321) ([92m↓5.71%[0m) [1.48% of initial]
[Iter 1390] Gaussian 0 vs 1:
  Original Loss: 0.0035930
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035930 (Pseudo: 0.00%)
[Iter 1390] Gaussian 1 vs 0:
  Original Loss: 0.0035677
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035677 (Pseudo: 0.00%)
Iter:1399, L1 loss=0.002301, Total loss=0.002911, Time:13
[Iter 1400/20000] Loss: 0.0034058 (Best: 0.0029115 @iter1399) ([92m↓8.30%[0m) [1.35% of initial]
[Iter 1400] Gaussian 0 vs 1:
  Original Loss: 0.0034453
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0034453 (Pseudo: 0.00%)
[Iter 1400] Gaussian 1 vs 0:
  Original Loss: 0.0035088
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035088 (Pseudo: 0.00%)
[Iter 1410/20000] Loss: 0.0090438 (Best: 0.0029115 @iter1399) ([91m↑165.54%[0m) [3.59% of initial]
[Iter 1410] Gaussian 0 vs 1:
  Original Loss: 0.0085932
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0085932 (Pseudo: 0.00%)
[Iter 1410] Gaussian 1 vs 0:
  Original Loss: 0.0081792
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0081792 (Pseudo: 0.00%)
[Iter 1420/20000] Loss: 0.0061622 (Best: 0.0029115 @iter1399) ([92m↓31.86%[0m) [2.45% of initial]
[Iter 1420] Gaussian 0 vs 1:
  Original Loss: 0.0058311
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058311 (Pseudo: 0.00%)
[Iter 1420] Gaussian 1 vs 0:
  Original Loss: 0.0055593
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0055593 (Pseudo: 0.00%)
[Iter 1430/20000] Loss: 0.0050902 (Best: 0.0029115 @iter1399) ([92m↓17.40%[0m) [2.02% of initial]
[Iter 1430] Gaussian 0 vs 1:
  Original Loss: 0.0043874
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043874 (Pseudo: 0.00%)
[Iter 1430] Gaussian 1 vs 0:
  Original Loss: 0.0043331
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043331 (Pseudo: 0.00%)
[Iter 1440/20000] Loss: 0.0045893 (Best: 0.0029115 @iter1399) ([92m↓9.84%[0m) [1.82% of initial]
[Iter 1440] Gaussian 0 vs 1:
  Original Loss: 0.0046832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046832 (Pseudo: 0.00%)
[Iter 1440] Gaussian 1 vs 0:
  Original Loss: 0.0044418
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044418 (Pseudo: 0.00%)
[Iter 1450/20000] Loss: 0.0035705 (Best: 0.0029115 @iter1399) ([92m↓22.20%[0m) [1.42% of initial]
[Iter 1450] Gaussian 0 vs 1:
  Original Loss: 0.0031571
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0031571 (Pseudo: 0.00%)
[Iter 1450] Gaussian 1 vs 0:
  Original Loss: 0.0031602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0031602 (Pseudo: 0.00%)
[Iter 1460/20000] Loss: 0.0035775 (Best: 0.0029115 @iter1399) ([91m↑0.20%[0m) [1.42% of initial]
[Iter 1460] Gaussian 0 vs 1:
  Original Loss: 0.0035905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035905 (Pseudo: 0.00%)
[Iter 1460] Gaussian 1 vs 0:
  Original Loss: 0.0036434
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036434 (Pseudo: 0.00%)
[Iter 1470/20000] Loss: 0.0034702 (Best: 0.0029115 @iter1399) ([92m↓3.00%[0m) [1.38% of initial]
[Iter 1470] Gaussian 0 vs 1:
  Original Loss: 0.0031478
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0031478 (Pseudo: 0.00%)
[Iter 1470] Gaussian 1 vs 0:
  Original Loss: 0.0030841
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030841 (Pseudo: 0.00%)
[Iter 1480/20000] Loss: 0.0033700 (Best: 0.0028405 @iter1480) ([92m↓2.89%[0m) [1.34% of initial]
[Iter 1480] Gaussian 0 vs 1:
  Original Loss: 0.0028405
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028405 (Pseudo: 0.00%)
[Iter 1480] Gaussian 1 vs 0:
  Original Loss: 0.0027969
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027969 (Pseudo: 0.00%)
[Iter 1490/20000] Loss: 0.0032900 (Best: 0.0028405 @iter1480) ([92m↓2.37%[0m) [1.31% of initial]
[Iter 1490] Gaussian 0 vs 1:
  Original Loss: 0.0033119
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033119 (Pseudo: 0.00%)
[Iter 1490] Gaussian 1 vs 0:
  Original Loss: 0.0033185
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033185 (Pseudo: 0.00%)
Iter:1499, L1 loss=0.002554, Total loss=0.003328, Time:13
[Iter 1500/20000] Loss: 0.0032415 (Best: 0.0028405 @iter1480) ([92m↓1.47%[0m) [1.29% of initial]
[Iter 1500] Gaussian 0 vs 1:
  Original Loss: 0.0029587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029587 (Pseudo: 0.00%)
[Iter 1500] Gaussian 1 vs 0:
  Original Loss: 0.0029637
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029637 (Pseudo: 0.00%)
[Iter 1510/20000] Loss: 0.0031027 (Best: 0.0026108 @iter1504) ([92m↓4.28%[0m) [1.23% of initial]
[Iter 1510] Gaussian 0 vs 1:
  Original Loss: 0.0028233
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028233 (Pseudo: 0.00%)
[Iter 1510] Gaussian 1 vs 0:
  Original Loss: 0.0028236
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028236 (Pseudo: 0.00%)
[Iter 1520/20000] Loss: 0.0030697 (Best: 0.0026014 @iter1520) ([92m↓1.06%[0m) [1.22% of initial]
[Iter 1520] Gaussian 0 vs 1:
  Original Loss: 0.0026014
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026014 (Pseudo: 0.00%)
[Iter 1520] Gaussian 1 vs 0:
  Original Loss: 0.0026043
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026043 (Pseudo: 0.00%)
[Iter 1530/20000] Loss: 0.0032212 (Best: 0.0025709 @iter1526) ([91m↑4.94%[0m) [1.28% of initial]
[Iter 1530] Gaussian 0 vs 1:
  Original Loss: 0.0032503
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032503 (Pseudo: 0.00%)
[Iter 1530] Gaussian 1 vs 0:
  Original Loss: 0.0032234
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032234 (Pseudo: 0.00%)
[Iter 1540/20000] Loss: 0.0031142 (Best: 0.0025709 @iter1526) ([92m↓3.32%[0m) [1.24% of initial]
[Iter 1540] Gaussian 0 vs 1:
  Original Loss: 0.0029162
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029162 (Pseudo: 0.00%)
[Iter 1540] Gaussian 1 vs 0:
  Original Loss: 0.0029088
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029088 (Pseudo: 0.00%)
[Iter 1550/20000] Loss: 0.0030425 (Best: 0.0025709 @iter1526) ([92m↓2.30%[0m) [1.21% of initial]
[Iter 1550] Gaussian 0 vs 1:
  Original Loss: 0.0029399
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029399 (Pseudo: 0.00%)
[Iter 1550] Gaussian 1 vs 0:
  Original Loss: 0.0030088
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030088 (Pseudo: 0.00%)
[Iter 1560/20000] Loss: 0.0032830 (Best: 0.0025565 @iter1558) ([91m↑7.90%[0m) [1.30% of initial]
[Iter 1560] Gaussian 0 vs 1:
  Original Loss: 0.0039155
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039155 (Pseudo: 0.00%)
[Iter 1560] Gaussian 1 vs 0:
  Original Loss: 0.0039436
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039436 (Pseudo: 0.00%)
[Iter 1570/20000] Loss: 0.0028300 (Best: 0.0024806 @iter1569) ([92m↓13.80%[0m) [1.12% of initial]
[Iter 1570] Gaussian 0 vs 1:
  Original Loss: 0.0027057
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027057 (Pseudo: 0.00%)
[Iter 1570] Gaussian 1 vs 0:
  Original Loss: 0.0028462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028462 (Pseudo: 0.00%)
[Iter 1580/20000] Loss: 0.0028738 (Best: 0.0023563 @iter1573) ([91m↑1.55%[0m) [1.14% of initial]
[Iter 1580] Gaussian 0 vs 1:
  Original Loss: 0.0029608
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029608 (Pseudo: 0.00%)
[Iter 1580] Gaussian 1 vs 0:
  Original Loss: 0.0032560
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032560 (Pseudo: 0.00%)
[Iter 1590/20000] Loss: 0.0027756 (Best: 0.0023563 @iter1573) ([92m↓3.42%[0m) [1.10% of initial]
[Iter 1590] Gaussian 0 vs 1:
  Original Loss: 0.0025154
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025154 (Pseudo: 0.00%)
[Iter 1590] Gaussian 1 vs 0:
  Original Loss: 0.0026211
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026211 (Pseudo: 0.00%)
Iter:1599, L1 loss=0.002751, Total loss=0.003428, Time:13
[Iter 1600/20000] Loss: 0.0031057 (Best: 0.0023563 @iter1573) ([91m↑11.89%[0m) [1.23% of initial]
[Iter 1600] Gaussian 0 vs 1:
  Original Loss: 0.0033145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033145 (Pseudo: 0.00%)
[Iter 1600] Gaussian 1 vs 0:
  Original Loss: 0.0033184
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033184 (Pseudo: 0.00%)
[Iter 1610/20000] Loss: 0.0086785 (Best: 0.0023563 @iter1573) ([91m↑179.44%[0m) [3.45% of initial]
[Iter 1610] Gaussian 0 vs 1:
  Original Loss: 0.0076747
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0076747 (Pseudo: 0.00%)
[Iter 1610] Gaussian 1 vs 0:
  Original Loss: 0.0075440
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0075440 (Pseudo: 0.00%)
[Iter 1620/20000] Loss: 0.0054409 (Best: 0.0023563 @iter1573) ([92m↓37.31%[0m) [2.16% of initial]
[Iter 1620] Gaussian 0 vs 1:
  Original Loss: 0.0058999
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058999 (Pseudo: 0.00%)
[Iter 1620] Gaussian 1 vs 0:
  Original Loss: 0.0062347
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062347 (Pseudo: 0.00%)
[Iter 1630/20000] Loss: 0.0044811 (Best: 0.0023563 @iter1573) ([92m↓17.64%[0m) [1.78% of initial]
[Iter 1630] Gaussian 0 vs 1:
  Original Loss: 0.0040060
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040060 (Pseudo: 0.00%)
[Iter 1630] Gaussian 1 vs 0:
  Original Loss: 0.0036977
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036977 (Pseudo: 0.00%)
[Iter 1640/20000] Loss: 0.0039505 (Best: 0.0023563 @iter1573) ([92m↓11.84%[0m) [1.57% of initial]
[Iter 1640] Gaussian 0 vs 1:
  Original Loss: 0.0043569
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043569 (Pseudo: 0.00%)
[Iter 1640] Gaussian 1 vs 0:
  Original Loss: 0.0042930
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0042930 (Pseudo: 0.00%)
[Iter 1650/20000] Loss: 0.0034588 (Best: 0.0023563 @iter1573) ([92m↓12.45%[0m) [1.37% of initial]
[Iter 1650] Gaussian 0 vs 1:
  Original Loss: 0.0034012
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0034012 (Pseudo: 0.00%)
[Iter 1650] Gaussian 1 vs 0:
  Original Loss: 0.0033312
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033312 (Pseudo: 0.00%)
[Iter 1660/20000] Loss: 0.0029397 (Best: 0.0023563 @iter1573) ([92m↓15.01%[0m) [1.17% of initial]
[Iter 1660] Gaussian 0 vs 1:
  Original Loss: 0.0025669
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025669 (Pseudo: 0.00%)
[Iter 1660] Gaussian 1 vs 0:
  Original Loss: 0.0025496
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025496 (Pseudo: 0.00%)
[Iter 1670/20000] Loss: 0.0027867 (Best: 0.0023075 @iter1669) ([92m↓5.20%[0m) [1.11% of initial]
[Iter 1670] Gaussian 0 vs 1:
  Original Loss: 0.0028154
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028154 (Pseudo: 0.00%)
[Iter 1670] Gaussian 1 vs 0:
  Original Loss: 0.0028748
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028748 (Pseudo: 0.00%)
[Iter 1680/20000] Loss: 0.0029164 (Best: 0.0023075 @iter1669) ([91m↑4.66%[0m) [1.16% of initial]
[Iter 1680] Gaussian 0 vs 1:
  Original Loss: 0.0027675
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027675 (Pseudo: 0.00%)
[Iter 1680] Gaussian 1 vs 0:
  Original Loss: 0.0028827
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028827 (Pseudo: 0.00%)
[Iter 1690/20000] Loss: 0.0030069 (Best: 0.0023075 @iter1669) ([91m↑3.10%[0m) [1.19% of initial]
[Iter 1690] Gaussian 0 vs 1:
  Original Loss: 0.0027275
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027275 (Pseudo: 0.00%)
[Iter 1690] Gaussian 1 vs 0:
  Original Loss: 0.0029747
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029747 (Pseudo: 0.00%)
Iter:1699, L1 loss=0.0026, Total loss=0.00316, Time:14
[Iter 1700/20000] Loss: 0.0027997 (Best: 0.0023075 @iter1669) ([92m↓6.89%[0m) [1.11% of initial]
[Iter 1700] Gaussian 0 vs 1:
  Original Loss: 0.0023884
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023884 (Pseudo: 0.00%)
[Iter 1700] Gaussian 1 vs 0:
  Original Loss: 0.0024271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024271 (Pseudo: 0.00%)
[Iter 1710/20000] Loss: 0.0030678 (Best: 0.0023075 @iter1669) ([91m↑9.58%[0m) [1.22% of initial]
[Iter 1710] Gaussian 0 vs 1:
  Original Loss: 0.0032399
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032399 (Pseudo: 0.00%)
[Iter 1710] Gaussian 1 vs 0:
  Original Loss: 0.0034713
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0034713 (Pseudo: 0.00%)
[Iter 1720/20000] Loss: 0.0025782 (Best: 0.0023075 @iter1669) ([92m↓15.96%[0m) [1.02% of initial]
[Iter 1720] Gaussian 0 vs 1:
  Original Loss: 0.0023834
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023834 (Pseudo: 0.00%)
[Iter 1720] Gaussian 1 vs 0:
  Original Loss: 0.0024817
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024817 (Pseudo: 0.00%)
[Iter 1730/20000] Loss: 0.0026438 (Best: 0.0023075 @iter1669) ([91m↑2.54%[0m) [1.05% of initial]
[Iter 1730] Gaussian 0 vs 1:
  Original Loss: 0.0023442
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023442 (Pseudo: 0.00%)
[Iter 1730] Gaussian 1 vs 0:
  Original Loss: 0.0024086
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024086 (Pseudo: 0.00%)
[Iter 1740/20000] Loss: 0.0025877 (Best: 0.0021688 @iter1738) ([92m↓2.12%[0m) [1.03% of initial]
[Iter 1740] Gaussian 0 vs 1:
  Original Loss: 0.0024534
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024534 (Pseudo: 0.00%)
[Iter 1740] Gaussian 1 vs 0:
  Original Loss: 0.0025344
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025344 (Pseudo: 0.00%)
[Iter 1750/20000] Loss: 0.0023591 (Best: 0.0021193 @iter1750) ([92m↓8.83%[0m) [0.94% of initial]
[Iter 1750] Gaussian 0 vs 1:
  Original Loss: 0.0021193
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021193 (Pseudo: 0.00%)
[Iter 1750] Gaussian 1 vs 0:
  Original Loss: 0.0021068
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021068 (Pseudo: 0.00%)
[Iter 1760/20000] Loss: 0.0026394 (Best: 0.0021193 @iter1750) ([91m↑11.89%[0m) [1.05% of initial]
[Iter 1760] Gaussian 0 vs 1:
  Original Loss: 0.0025693
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025693 (Pseudo: 0.00%)
[Iter 1760] Gaussian 1 vs 0:
  Original Loss: 0.0025467
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025467 (Pseudo: 0.00%)
[Iter 1770/20000] Loss: 0.0024132 (Best: 0.0021016 @iter1762) ([92m↓8.57%[0m) [0.96% of initial]
[Iter 1770] Gaussian 0 vs 1:
  Original Loss: 0.0023258
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023258 (Pseudo: 0.00%)
[Iter 1770] Gaussian 1 vs 0:
  Original Loss: 0.0024920
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024920 (Pseudo: 0.00%)
[Iter 1780/20000] Loss: 0.0025756 (Best: 0.0020700 @iter1771) ([91m↑6.73%[0m) [1.02% of initial]
[Iter 1780] Gaussian 0 vs 1:
  Original Loss: 0.0028361
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028361 (Pseudo: 0.00%)
[Iter 1780] Gaussian 1 vs 0:
  Original Loss: 0.0026267
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026267 (Pseudo: 0.00%)
[Iter 1790/20000] Loss: 0.0021820 (Best: 0.0019079 @iter1786) ([92m↓15.28%[0m) [0.87% of initial]
[Iter 1790] Gaussian 0 vs 1:
  Original Loss: 0.0021447
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021447 (Pseudo: 0.00%)
[Iter 1790] Gaussian 1 vs 0:
  Original Loss: 0.0022336
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022336 (Pseudo: 0.00%)
Iter:1799, L1 loss=0.001723, Total loss=0.00191, Time:14
[Iter 1800/20000] Loss: 0.0021893 (Best: 0.0019079 @iter1786) ([91m↑0.34%[0m) [0.87% of initial]
[Iter 1800] Gaussian 0 vs 1:
  Original Loss: 0.0021596
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021596 (Pseudo: 0.00%)
[Iter 1800] Gaussian 1 vs 0:
  Original Loss: 0.0022137
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022137 (Pseudo: 0.00%)
[Iter 1810/20000] Loss: 0.0076617 (Best: 0.0019079 @iter1786) ([91m↑249.95%[0m) [3.04% of initial]
[Iter 1810] Gaussian 0 vs 1:
  Original Loss: 0.0067294
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067294 (Pseudo: 0.00%)
[Iter 1810] Gaussian 1 vs 0:
  Original Loss: 0.0065935
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0065935 (Pseudo: 0.00%)
[Iter 1820/20000] Loss: 0.0046328 (Best: 0.0019079 @iter1786) ([92m↓39.53%[0m) [1.84% of initial]
[Iter 1820] Gaussian 0 vs 1:
  Original Loss: 0.0046501
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046501 (Pseudo: 0.00%)
[Iter 1820] Gaussian 1 vs 0:
  Original Loss: 0.0044780
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044780 (Pseudo: 0.00%)
[Iter 1830/20000] Loss: 0.0040344 (Best: 0.0019079 @iter1786) ([92m↓12.92%[0m) [1.60% of initial]
[Iter 1830] Gaussian 0 vs 1:
  Original Loss: 0.0038599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038599 (Pseudo: 0.00%)
[Iter 1830] Gaussian 1 vs 0:
  Original Loss: 0.0038179
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038179 (Pseudo: 0.00%)
[Iter 1840/20000] Loss: 0.0027951 (Best: 0.0019079 @iter1786) ([92m↓30.72%[0m) [1.11% of initial]
[Iter 1840] Gaussian 0 vs 1:
  Original Loss: 0.0024393
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024393 (Pseudo: 0.00%)
[Iter 1840] Gaussian 1 vs 0:
  Original Loss: 0.0024789
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024789 (Pseudo: 0.00%)
[Iter 1850/20000] Loss: 0.0026447 (Best: 0.0019079 @iter1786) ([92m↓5.38%[0m) [1.05% of initial]
[Iter 1850] Gaussian 0 vs 1:
  Original Loss: 0.0024306
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024306 (Pseudo: 0.00%)
[Iter 1850] Gaussian 1 vs 0:
  Original Loss: 0.0025061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025061 (Pseudo: 0.00%)
[Iter 1860/20000] Loss: 0.0024080 (Best: 0.0019079 @iter1786) ([92m↓8.95%[0m) [0.96% of initial]
[Iter 1860] Gaussian 0 vs 1:
  Original Loss: 0.0022176
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022176 (Pseudo: 0.00%)
[Iter 1860] Gaussian 1 vs 0:
  Original Loss: 0.0023248
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023248 (Pseudo: 0.00%)
[Iter 1870/20000] Loss: 0.0022293 (Best: 0.0018235 @iter1867) ([92m↓7.42%[0m) [0.89% of initial]
[Iter 1870] Gaussian 0 vs 1:
  Original Loss: 0.0020194
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020194 (Pseudo: 0.00%)
[Iter 1870] Gaussian 1 vs 0:
  Original Loss: 0.0020681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020681 (Pseudo: 0.00%)
[Iter 1880/20000] Loss: 0.0021073 (Best: 0.0018235 @iter1867) ([92m↓5.47%[0m) [0.84% of initial]
[Iter 1880] Gaussian 0 vs 1:
  Original Loss: 0.0018463
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018463 (Pseudo: 0.00%)
[Iter 1880] Gaussian 1 vs 0:
  Original Loss: 0.0018810
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018810 (Pseudo: 0.00%)
[Iter 1890/20000] Loss: 0.0018982 (Best: 0.0017544 @iter1890) ([92m↓9.92%[0m) [0.75% of initial]
[Iter 1890] Gaussian 0 vs 1:
  Original Loss: 0.0017544
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017544 (Pseudo: 0.00%)
[Iter 1890] Gaussian 1 vs 0:
  Original Loss: 0.0018244
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018244 (Pseudo: 0.00%)
Iter:1899, L1 loss=0.001802, Total loss=0.001931, Time:14
[Iter 1900/20000] Loss: 0.0020137 (Best: 0.0016192 @iter1891) ([91m↑6.09%[0m) [0.80% of initial]
[Iter 1900] Gaussian 0 vs 1:
  Original Loss: 0.0018894
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018894 (Pseudo: 0.00%)
[Iter 1900] Gaussian 1 vs 0:
  Original Loss: 0.0019089
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019089 (Pseudo: 0.00%)
[Iter 1910/20000] Loss: 0.0020443 (Best: 0.0016192 @iter1891) ([91m↑1.52%[0m) [0.81% of initial]
[Iter 1910] Gaussian 0 vs 1:
  Original Loss: 0.0018147
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018147 (Pseudo: 0.00%)
[Iter 1910] Gaussian 1 vs 0:
  Original Loss: 0.0018719
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018719 (Pseudo: 0.00%)
[Iter 1920/20000] Loss: 0.0020844 (Best: 0.0016192 @iter1891) ([91m↑1.96%[0m) [0.83% of initial]
[Iter 1920] Gaussian 0 vs 1:
  Original Loss: 0.0021109
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021109 (Pseudo: 0.00%)
[Iter 1920] Gaussian 1 vs 0:
  Original Loss: 0.0021875
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021875 (Pseudo: 0.00%)
[Iter 1930/20000] Loss: 0.0017584 (Best: 0.0015703 @iter1930) ([92m↓15.64%[0m) [0.70% of initial]
[Iter 1930] Gaussian 0 vs 1:
  Original Loss: 0.0015703
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015703 (Pseudo: 0.00%)
[Iter 1930] Gaussian 1 vs 0:
  Original Loss: 0.0016237
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016237 (Pseudo: 0.00%)
[Iter 1940/20000] Loss: 0.0019079 (Best: 0.0015630 @iter1939) ([91m↑8.50%[0m) [0.76% of initial]
[Iter 1940] Gaussian 0 vs 1:
  Original Loss: 0.0019935
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019935 (Pseudo: 0.00%)
[Iter 1940] Gaussian 1 vs 0:
  Original Loss: 0.0020324
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020324 (Pseudo: 0.00%)
[Iter 1950/20000] Loss: 0.0020725 (Best: 0.0015630 @iter1939) ([91m↑8.63%[0m) [0.82% of initial]
[Iter 1950] Gaussian 0 vs 1:
  Original Loss: 0.0018989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018989 (Pseudo: 0.00%)
[Iter 1950] Gaussian 1 vs 0:
  Original Loss: 0.0018829
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018829 (Pseudo: 0.00%)
[Iter 1960/20000] Loss: 0.0018455 (Best: 0.0015630 @iter1939) ([92m↓10.95%[0m) [0.73% of initial]
[Iter 1960] Gaussian 0 vs 1:
  Original Loss: 0.0017291
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017291 (Pseudo: 0.00%)
[Iter 1960] Gaussian 1 vs 0:
  Original Loss: 0.0017443
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017443 (Pseudo: 0.00%)
[Iter 1970/20000] Loss: 0.0016843 (Best: 0.0015053 @iter1963) ([92m↓8.74%[0m) [0.67% of initial]
[Iter 1970] Gaussian 0 vs 1:
  Original Loss: 0.0016038
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016038 (Pseudo: 0.00%)
[Iter 1970] Gaussian 1 vs 0:
  Original Loss: 0.0016612
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016612 (Pseudo: 0.00%)
[Iter 1980/20000] Loss: 0.0020370 (Best: 0.0015053 @iter1963) ([91m↑20.94%[0m) [0.81% of initial]
[Iter 1980] Gaussian 0 vs 1:
  Original Loss: 0.0024244
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024244 (Pseudo: 0.00%)
[Iter 1980] Gaussian 1 vs 0:
  Original Loss: 0.0024139
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024139 (Pseudo: 0.00%)
[Iter 1990/20000] Loss: 0.0017610 (Best: 0.0015053 @iter1963) ([92m↓13.55%[0m) [0.70% of initial]
[Iter 1990] Gaussian 0 vs 1:
  Original Loss: 0.0016106
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016106 (Pseudo: 0.00%)
[Iter 1990] Gaussian 1 vs 0:
  Original Loss: 0.0016746
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016746 (Pseudo: 0.00%)
Iter:1999, L1 loss=0.001565, Total loss=0.001666, Time:14
[Iter 2000/20000] Loss: 0.0018758 (Best: 0.0014433 @iter1996) ([91m↑6.51%[0m) [0.75% of initial]
Testing Speed: 232.01330245947253 fps
Testing Time: 0.21550488471984863 s

[ITER 2000] Evaluating test: SSIM = 0.8421867966651917, PSNR = 17.482737598419188
Testing Speed: 271.1191743336709 fps
Testing Time: 0.011065244674682617 s

[ITER 2000] Evaluating train: SSIM = 0.9999533891677856, PSNR = 49.29673131306966
Iter:2000, total_points:42649
[Iter 2000] Gaussian 0 vs 1:
  Original Loss: 0.0020144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020144 (Pseudo: 0.00%)
[Iter 2000] Gaussian 1 vs 0:
  Original Loss: 0.0020813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020813 (Pseudo: 0.00%)
[Iter 2010/20000] Loss: 0.0068129 (Best: 0.0014433 @iter1996) ([91m↑263.21%[0m) [2.71% of initial]
[Iter 2010] Gaussian 0 vs 1:
  Original Loss: 0.0061866
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061866 (Pseudo: 0.00%)
[Iter 2010] Gaussian 1 vs 0:
  Original Loss: 0.0060190
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060190 (Pseudo: 0.00%)
[Iter 2020/20000] Loss: 0.0037290 (Best: 0.0014433 @iter1996) ([92m↓45.27%[0m) [1.48% of initial]
[Iter 2020] Gaussian 0 vs 1:
  Original Loss: 0.0033068
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033068 (Pseudo: 0.00%)
[Iter 2020] Gaussian 1 vs 0:
  Original Loss: 0.0033086
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033086 (Pseudo: 0.00%)
[Iter 2030/20000] Loss: 0.0027863 (Best: 0.0014433 @iter1996) ([92m↓25.28%[0m) [1.11% of initial]
[Iter 2030] Gaussian 0 vs 1:
  Original Loss: 0.0024480
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024480 (Pseudo: 0.00%)
[Iter 2030] Gaussian 1 vs 0:
  Original Loss: 0.0024404
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024404 (Pseudo: 0.00%)
[Iter 2040/20000] Loss: 0.0024637 (Best: 0.0014433 @iter1996) ([92m↓11.58%[0m) [0.98% of initial]
[Iter 2040] Gaussian 0 vs 1:
  Original Loss: 0.0026871
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026871 (Pseudo: 0.00%)
[Iter 2040] Gaussian 1 vs 0:
  Original Loss: 0.0027984
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027984 (Pseudo: 0.00%)
[Iter 2050/20000] Loss: 0.0020773 (Best: 0.0014433 @iter1996) ([92m↓15.68%[0m) [0.83% of initial]
[Iter 2050] Gaussian 0 vs 1:
  Original Loss: 0.0017442
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017442 (Pseudo: 0.00%)
[Iter 2050] Gaussian 1 vs 0:
  Original Loss: 0.0018063
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018063 (Pseudo: 0.00%)
[Iter 2060/20000] Loss: 0.0017279 (Best: 0.0014433 @iter1996) ([92m↓16.82%[0m) [0.69% of initial]
[Iter 2060] Gaussian 0 vs 1:
  Original Loss: 0.0015585
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015585 (Pseudo: 0.00%)
[Iter 2060] Gaussian 1 vs 0:
  Original Loss: 0.0015658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015658 (Pseudo: 0.00%)
[Iter 2070/20000] Loss: 0.0019507 (Best: 0.0014433 @iter1996) ([91m↑12.90%[0m) [0.78% of initial]
[Iter 2070] Gaussian 0 vs 1:
  Original Loss: 0.0021781
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021781 (Pseudo: 0.00%)
[Iter 2070] Gaussian 1 vs 0:
  Original Loss: 0.0023145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023145 (Pseudo: 0.00%)
[Iter 2080/20000] Loss: 0.0018921 (Best: 0.0014433 @iter1996) ([92m↓3.00%[0m) [0.75% of initial]
[Iter 2080] Gaussian 0 vs 1:
  Original Loss: 0.0020830
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020830 (Pseudo: 0.00%)
[Iter 2080] Gaussian 1 vs 0:
  Original Loss: 0.0021600
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021600 (Pseudo: 0.00%)
[Iter 2090/20000] Loss: 0.0018262 (Best: 0.0014433 @iter1996) ([92m↓3.49%[0m) [0.73% of initial]
[Iter 2090] Gaussian 0 vs 1:
  Original Loss: 0.0020341
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020341 (Pseudo: 0.00%)
[Iter 2090] Gaussian 1 vs 0:
  Original Loss: 0.0021387
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021387 (Pseudo: 0.00%)
Iter:2099, L1 loss=0.001594, Total loss=0.001751, Time:14
[Iter 2100/20000] Loss: 0.0017001 (Best: 0.0014433 @iter1996) ([92m↓6.90%[0m) [0.68% of initial]
[Iter 2100] Gaussian 0 vs 1:
  Original Loss: 0.0015966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015966 (Pseudo: 0.00%)
[Iter 2100] Gaussian 1 vs 0:
  Original Loss: 0.0016208
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016208 (Pseudo: 0.00%)
[Iter 2110/20000] Loss: 0.0016327 (Best: 0.0014320 @iter2101) ([92m↓3.96%[0m) [0.65% of initial]
[Iter 2110] Gaussian 0 vs 1:
  Original Loss: 0.0015009
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015009 (Pseudo: 0.00%)
[Iter 2110] Gaussian 1 vs 0:
  Original Loss: 0.0014759
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014759 (Pseudo: 0.00%)
[Iter 2120/20000] Loss: 0.0014301 (Best: 0.0013033 @iter2120) ([92m↓12.41%[0m) [0.57% of initial]
[Iter 2120] Gaussian 0 vs 1:
  Original Loss: 0.0013033
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013033 (Pseudo: 0.00%)
[Iter 2120] Gaussian 1 vs 0:
  Original Loss: 0.0013208
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013208 (Pseudo: 0.00%)
[Iter 2130/20000] Loss: 0.0015714 (Best: 0.0012233 @iter2125) ([91m↑9.88%[0m) [0.62% of initial]
[Iter 2130] Gaussian 0 vs 1:
  Original Loss: 0.0016318
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016318 (Pseudo: 0.00%)
[Iter 2130] Gaussian 1 vs 0:
  Original Loss: 0.0017009
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017009 (Pseudo: 0.00%)
[Iter 2140/20000] Loss: 0.0017211 (Best: 0.0012233 @iter2125) ([91m↑9.52%[0m) [0.68% of initial]
[Iter 2140] Gaussian 0 vs 1:
  Original Loss: 0.0018433
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018433 (Pseudo: 0.00%)
[Iter 2140] Gaussian 1 vs 0:
  Original Loss: 0.0019330
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019330 (Pseudo: 0.00%)
[Iter 2150/20000] Loss: 0.0017331 (Best: 0.0012233 @iter2125) ([91m↑0.70%[0m) [0.69% of initial]
[Iter 2150] Gaussian 0 vs 1:
  Original Loss: 0.0015225
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015225 (Pseudo: 0.00%)
[Iter 2150] Gaussian 1 vs 0:
  Original Loss: 0.0016663
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016663 (Pseudo: 0.00%)
[Iter 2160/20000] Loss: 0.0015552 (Best: 0.0012233 @iter2125) ([92m↓10.27%[0m) [0.62% of initial]
[Iter 2160] Gaussian 0 vs 1:
  Original Loss: 0.0013719
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013719 (Pseudo: 0.00%)
[Iter 2160] Gaussian 1 vs 0:
  Original Loss: 0.0014847
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014847 (Pseudo: 0.00%)
[Iter 2170/20000] Loss: 0.0016037 (Best: 0.0012233 @iter2125) ([91m↑3.12%[0m) [0.64% of initial]
[Iter 2170] Gaussian 0 vs 1:
  Original Loss: 0.0016857
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016857 (Pseudo: 0.00%)
[Iter 2170] Gaussian 1 vs 0:
  Original Loss: 0.0017707
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017707 (Pseudo: 0.00%)
[Iter 2180/20000] Loss: 0.0013268 (Best: 0.0011927 @iter2180) ([92m↓17.27%[0m) [0.53% of initial]
[Iter 2180] Gaussian 0 vs 1:
  Original Loss: 0.0011927
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011927 (Pseudo: 0.00%)
[Iter 2180] Gaussian 1 vs 0:
  Original Loss: 0.0012543
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012543 (Pseudo: 0.00%)
[Iter 2190/20000] Loss: 0.0015875 (Best: 0.0011927 @iter2180) ([91m↑19.66%[0m) [0.63% of initial]
[Iter 2190] Gaussian 0 vs 1:
  Original Loss: 0.0018445
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018445 (Pseudo: 0.00%)
[Iter 2190] Gaussian 1 vs 0:
  Original Loss: 0.0019063
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019063 (Pseudo: 0.00%)
Iter:2199, L1 loss=0.001456, Total loss=0.001527, Time:14
[Iter 2200/20000] Loss: 0.0016030 (Best: 0.0011927 @iter2180) ([91m↑0.98%[0m) [0.64% of initial]
[Iter 2200] Gaussian 0 vs 1:
  Original Loss: 0.0017738
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017738 (Pseudo: 0.00%)
[Iter 2200] Gaussian 1 vs 0:
  Original Loss: 0.0018243
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018243 (Pseudo: 0.00%)
[Iter 2210/20000] Loss: 0.0077410 (Best: 0.0011927 @iter2180) ([91m↑382.90%[0m) [3.08% of initial]
[Iter 2210] Gaussian 0 vs 1:
  Original Loss: 0.0077021
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0077021 (Pseudo: 0.00%)
[Iter 2210] Gaussian 1 vs 0:
  Original Loss: 0.0071833
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0071833 (Pseudo: 0.00%)
[Iter 2220/20000] Loss: 0.0042461 (Best: 0.0011927 @iter2180) ([92m↓45.15%[0m) [1.69% of initial]
[Iter 2220] Gaussian 0 vs 1:
  Original Loss: 0.0038329
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038329 (Pseudo: 0.00%)
[Iter 2220] Gaussian 1 vs 0:
  Original Loss: 0.0038107
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038107 (Pseudo: 0.00%)
[Iter 2230/20000] Loss: 0.0026631 (Best: 0.0011927 @iter2180) ([92m↓37.28%[0m) [1.06% of initial]
[Iter 2230] Gaussian 0 vs 1:
  Original Loss: 0.0022700
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022700 (Pseudo: 0.00%)
[Iter 2230] Gaussian 1 vs 0:
  Original Loss: 0.0023216
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023216 (Pseudo: 0.00%)
[Iter 2240/20000] Loss: 0.0023037 (Best: 0.0011927 @iter2180) ([92m↓13.49%[0m) [0.92% of initial]
[Iter 2240] Gaussian 0 vs 1:
  Original Loss: 0.0020780
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020780 (Pseudo: 0.00%)
[Iter 2240] Gaussian 1 vs 0:
  Original Loss: 0.0021179
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021179 (Pseudo: 0.00%)
[Iter 2250/20000] Loss: 0.0021170 (Best: 0.0011927 @iter2180) ([92m↓8.11%[0m) [0.84% of initial]
[Iter 2250] Gaussian 0 vs 1:
  Original Loss: 0.0022340
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022340 (Pseudo: 0.00%)
[Iter 2250] Gaussian 1 vs 0:
  Original Loss: 0.0023895
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023895 (Pseudo: 0.00%)
[Iter 2260/20000] Loss: 0.0017067 (Best: 0.0011927 @iter2180) ([92m↓19.38%[0m) [0.68% of initial]
[Iter 2260] Gaussian 0 vs 1:
  Original Loss: 0.0015235
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015235 (Pseudo: 0.00%)
[Iter 2260] Gaussian 1 vs 0:
  Original Loss: 0.0015706
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015706 (Pseudo: 0.00%)
[Iter 2270/20000] Loss: 0.0018361 (Best: 0.0011927 @iter2180) ([91m↑7.58%[0m) [0.73% of initial]
[Iter 2270] Gaussian 0 vs 1:
  Original Loss: 0.0020544
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020544 (Pseudo: 0.00%)
[Iter 2270] Gaussian 1 vs 0:
  Original Loss: 0.0020416
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020416 (Pseudo: 0.00%)
[Iter 2280/20000] Loss: 0.0014657 (Best: 0.0011927 @iter2180) ([92m↓20.17%[0m) [0.58% of initial]
[Iter 2280] Gaussian 0 vs 1:
  Original Loss: 0.0013803
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013803 (Pseudo: 0.00%)
[Iter 2280] Gaussian 1 vs 0:
  Original Loss: 0.0013969
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013969 (Pseudo: 0.00%)
[Iter 2290/20000] Loss: 0.0014081 (Best: 0.0011847 @iter2287) ([92m↓3.93%[0m) [0.56% of initial]
[Iter 2290] Gaussian 0 vs 1:
  Original Loss: 0.0012662
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012662 (Pseudo: 0.00%)
[Iter 2290] Gaussian 1 vs 0:
  Original Loss: 0.0012692
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012692 (Pseudo: 0.00%)
Iter:2299, L1 loss=0.001383, Total loss=0.001363, Time:15
[Iter 2300/20000] Loss: 0.0016795 (Best: 0.0011847 @iter2287) ([91m↑19.27%[0m) [0.67% of initial]
[Iter 2300] Gaussian 0 vs 1:
  Original Loss: 0.0018161
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018161 (Pseudo: 0.00%)
[Iter 2300] Gaussian 1 vs 0:
  Original Loss: 0.0018484
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018484 (Pseudo: 0.00%)
[Iter 2310/20000] Loss: 0.0015421 (Best: 0.0011847 @iter2287) ([92m↓8.18%[0m) [0.61% of initial]
[Iter 2310] Gaussian 0 vs 1:
  Original Loss: 0.0014799
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014799 (Pseudo: 0.00%)
[Iter 2310] Gaussian 1 vs 0:
  Original Loss: 0.0014633
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014633 (Pseudo: 0.00%)
[Iter 2320/20000] Loss: 0.0013266 (Best: 0.0011847 @iter2287) ([92m↓13.98%[0m) [0.53% of initial]
[Iter 2320] Gaussian 0 vs 1:
  Original Loss: 0.0012061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012061 (Pseudo: 0.00%)
[Iter 2320] Gaussian 1 vs 0:
  Original Loss: 0.0012197
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012197 (Pseudo: 0.00%)
[Iter 2330/20000] Loss: 0.0012977 (Best: 0.0011217 @iter2327) ([92m↓2.17%[0m) [0.52% of initial]
[Iter 2330] Gaussian 0 vs 1:
  Original Loss: 0.0012593
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012593 (Pseudo: 0.00%)
[Iter 2330] Gaussian 1 vs 0:
  Original Loss: 0.0013112
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013112 (Pseudo: 0.00%)
[Iter 2340/20000] Loss: 0.0013585 (Best: 0.0011087 @iter2338) ([91m↑4.69%[0m) [0.54% of initial]
[Iter 2340] Gaussian 0 vs 1:
  Original Loss: 0.0012499
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012499 (Pseudo: 0.00%)
[Iter 2340] Gaussian 1 vs 0:
  Original Loss: 0.0012602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012602 (Pseudo: 0.00%)
[Iter 2350/20000] Loss: 0.0014826 (Best: 0.0011087 @iter2338) ([91m↑9.14%[0m) [0.59% of initial]
[Iter 2350] Gaussian 0 vs 1:
  Original Loss: 0.0013784
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013784 (Pseudo: 0.00%)
[Iter 2350] Gaussian 1 vs 0:
  Original Loss: 0.0014920
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014920 (Pseudo: 0.00%)
[Iter 2360/20000] Loss: 0.0012897 (Best: 0.0011040 @iter2359) ([92m↓13.01%[0m) [0.51% of initial]
[Iter 2360] Gaussian 0 vs 1:
  Original Loss: 0.0013252
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013252 (Pseudo: 0.00%)
[Iter 2360] Gaussian 1 vs 0:
  Original Loss: 0.0013850
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013850 (Pseudo: 0.00%)
[Iter 2370/20000] Loss: 0.0014302 (Best: 0.0011040 @iter2359) ([91m↑10.90%[0m) [0.57% of initial]
[Iter 2370] Gaussian 0 vs 1:
  Original Loss: 0.0012327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012327 (Pseudo: 0.00%)
[Iter 2370] Gaussian 1 vs 0:
  Original Loss: 0.0012409
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012409 (Pseudo: 0.00%)
[Iter 2380/20000] Loss: 0.0015188 (Best: 0.0011040 @iter2359) ([91m↑6.19%[0m) [0.60% of initial]
[Iter 2380] Gaussian 0 vs 1:
  Original Loss: 0.0016113
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016113 (Pseudo: 0.00%)
[Iter 2380] Gaussian 1 vs 0:
  Original Loss: 0.0016115
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016115 (Pseudo: 0.00%)
[Iter 2390/20000] Loss: 0.0016539 (Best: 0.0011040 @iter2359) ([91m↑8.90%[0m) [0.66% of initial]
[Iter 2390] Gaussian 0 vs 1:
  Original Loss: 0.0018041
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018041 (Pseudo: 0.00%)
[Iter 2390] Gaussian 1 vs 0:
  Original Loss: 0.0018221
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018221 (Pseudo: 0.00%)
Iter:2399, L1 loss=0.001238, Total loss=0.001247, Time:15
[Iter 2400/20000] Loss: 0.0013403 (Best: 0.0011040 @iter2359) ([92m↓18.96%[0m) [0.53% of initial]
[Iter 2400] Gaussian 0 vs 1:
  Original Loss: 0.0012132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012132 (Pseudo: 0.00%)
[Iter 2400] Gaussian 1 vs 0:
  Original Loss: 0.0011974
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011974 (Pseudo: 0.00%)
[Iter 2410/20000] Loss: 0.0058970 (Best: 0.0011040 @iter2359) ([91m↑339.99%[0m) [2.34% of initial]
[Iter 2410] Gaussian 0 vs 1:
  Original Loss: 0.0050345
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0050345 (Pseudo: 0.00%)
[Iter 2410] Gaussian 1 vs 0:
  Original Loss: 0.0049764
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049764 (Pseudo: 0.00%)
[Iter 2420/20000] Loss: 0.0034625 (Best: 0.0011040 @iter2359) ([92m↓41.28%[0m) [1.38% of initial]
[Iter 2420] Gaussian 0 vs 1:
  Original Loss: 0.0030360
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030360 (Pseudo: 0.00%)
[Iter 2420] Gaussian 1 vs 0:
  Original Loss: 0.0028888
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028888 (Pseudo: 0.00%)
[Iter 2430/20000] Loss: 0.0025139 (Best: 0.0011040 @iter2359) ([92m↓27.40%[0m) [1.00% of initial]
[Iter 2430] Gaussian 0 vs 1:
  Original Loss: 0.0026456
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026456 (Pseudo: 0.00%)
[Iter 2430] Gaussian 1 vs 0:
  Original Loss: 0.0026165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026165 (Pseudo: 0.00%)
[Iter 2440/20000] Loss: 0.0019958 (Best: 0.0011040 @iter2359) ([92m↓20.61%[0m) [0.79% of initial]
[Iter 2440] Gaussian 0 vs 1:
  Original Loss: 0.0016754
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016754 (Pseudo: 0.00%)
[Iter 2440] Gaussian 1 vs 0:
  Original Loss: 0.0016822
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016822 (Pseudo: 0.00%)
[Iter 2450/20000] Loss: 0.0019416 (Best: 0.0011040 @iter2359) ([92m↓2.72%[0m) [0.77% of initial]
[Iter 2450] Gaussian 0 vs 1:
  Original Loss: 0.0020349
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020349 (Pseudo: 0.00%)
[Iter 2450] Gaussian 1 vs 0:
  Original Loss: 0.0020311
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020311 (Pseudo: 0.00%)
[Iter 2460/20000] Loss: 0.0016926 (Best: 0.0011040 @iter2359) ([92m↓12.82%[0m) [0.67% of initial]
[Iter 2460] Gaussian 0 vs 1:
  Original Loss: 0.0015314
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015314 (Pseudo: 0.00%)
[Iter 2460] Gaussian 1 vs 0:
  Original Loss: 0.0015056
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015056 (Pseudo: 0.00%)
[Iter 2470/20000] Loss: 0.0016547 (Best: 0.0011040 @iter2359) ([92m↓2.24%[0m) [0.66% of initial]
[Iter 2470] Gaussian 0 vs 1:
  Original Loss: 0.0016678
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016678 (Pseudo: 0.00%)
[Iter 2470] Gaussian 1 vs 0:
  Original Loss: 0.0016647
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016647 (Pseudo: 0.00%)
[Iter 2480/20000] Loss: 0.0016521 (Best: 0.0011040 @iter2359) ([92m↓0.16%[0m) [0.66% of initial]
[Iter 2480] Gaussian 0 vs 1:
  Original Loss: 0.0014433
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014433 (Pseudo: 0.00%)
[Iter 2480] Gaussian 1 vs 0:
  Original Loss: 0.0014422
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014422 (Pseudo: 0.00%)
[Iter 2490/20000] Loss: 0.0014473 (Best: 0.0011040 @iter2359) ([92m↓12.40%[0m) [0.58% of initial]
[Iter 2490] Gaussian 0 vs 1:
  Original Loss: 0.0013627
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013627 (Pseudo: 0.00%)
[Iter 2490] Gaussian 1 vs 0:
  Original Loss: 0.0015037
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015037 (Pseudo: 0.00%)
Iter:2499, L1 loss=0.001207, Total loss=0.001236, Time:16
[Iter 2500/20000] Loss: 0.0012990 (Best: 0.0011040 @iter2359) ([92m↓10.25%[0m) [0.52% of initial]
[Iter 2500] Gaussian 0 vs 1:
  Original Loss: 0.0011932
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011932 (Pseudo: 0.00%)
[Iter 2500] Gaussian 1 vs 0:
  Original Loss: 0.0012108
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012108 (Pseudo: 0.00%)
[Iter 2510/20000] Loss: 0.0013522 (Best: 0.0010299 @iter2504) ([91m↑4.09%[0m) [0.54% of initial]
[Iter 2510] Gaussian 0 vs 1:
  Original Loss: 0.0015869
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015869 (Pseudo: 0.00%)
[Iter 2510] Gaussian 1 vs 0:
  Original Loss: 0.0015752
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015752 (Pseudo: 0.00%)
[Iter 2520/20000] Loss: 0.0012072 (Best: 0.0009926 @iter2519) ([92m↓10.72%[0m) [0.48% of initial]
[Iter 2520] Gaussian 0 vs 1:
  Original Loss: 0.0012450
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012450 (Pseudo: 0.00%)
[Iter 2520] Gaussian 1 vs 0:
  Original Loss: 0.0012666
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012666 (Pseudo: 0.00%)
[Iter 2530/20000] Loss: 0.0010637 (Best: 0.0009588 @iter2528) ([92m↓11.89%[0m) [0.42% of initial]
[Iter 2530] Gaussian 0 vs 1:
  Original Loss: 0.0009593
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009593 (Pseudo: 0.00%)
[Iter 2530] Gaussian 1 vs 0:
  Original Loss: 0.0009933
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009933 (Pseudo: 0.00%)
[Iter 2540/20000] Loss: 0.0011748 (Best: 0.0009588 @iter2528) ([91m↑10.45%[0m) [0.47% of initial]
[Iter 2540] Gaussian 0 vs 1:
  Original Loss: 0.0011936
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011936 (Pseudo: 0.00%)
[Iter 2540] Gaussian 1 vs 0:
  Original Loss: 0.0011846
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011846 (Pseudo: 0.00%)
[Iter 2550/20000] Loss: 0.0014118 (Best: 0.0009588 @iter2528) ([91m↑20.17%[0m) [0.56% of initial]
[Iter 2550] Gaussian 0 vs 1:
  Original Loss: 0.0015145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015145 (Pseudo: 0.00%)
[Iter 2550] Gaussian 1 vs 0:
  Original Loss: 0.0014685
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014685 (Pseudo: 0.00%)
[Iter 2560/20000] Loss: 0.0011933 (Best: 0.0009588 @iter2528) ([92m↓15.48%[0m) [0.47% of initial]
[Iter 2560] Gaussian 0 vs 1:
  Original Loss: 0.0010902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010902 (Pseudo: 0.00%)
[Iter 2560] Gaussian 1 vs 0:
  Original Loss: 0.0010795
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010795 (Pseudo: 0.00%)
[Iter 2570/20000] Loss: 0.0014361 (Best: 0.0009588 @iter2528) ([91m↑20.34%[0m) [0.57% of initial]
[Iter 2570] Gaussian 0 vs 1:
  Original Loss: 0.0015116
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015116 (Pseudo: 0.00%)
[Iter 2570] Gaussian 1 vs 0:
  Original Loss: 0.0014185
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014185 (Pseudo: 0.00%)
[Iter 2580/20000] Loss: 0.0012441 (Best: 0.0009550 @iter2578) ([92m↓13.36%[0m) [0.49% of initial]
[Iter 2580] Gaussian 0 vs 1:
  Original Loss: 0.0012727
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012727 (Pseudo: 0.00%)
[Iter 2580] Gaussian 1 vs 0:
  Original Loss: 0.0012890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012890 (Pseudo: 0.00%)
[Iter 2590/20000] Loss: 0.0013065 (Best: 0.0009482 @iter2584) ([91m↑5.02%[0m) [0.52% of initial]
[Iter 2590] Gaussian 0 vs 1:
  Original Loss: 0.0013726
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013726 (Pseudo: 0.00%)
[Iter 2590] Gaussian 1 vs 0:
  Original Loss: 0.0013809
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013809 (Pseudo: 0.00%)
Iter:2599, L1 loss=0.001045, Total loss=0.001041, Time:15
[Iter 2600/20000] Loss: 0.0012026 (Best: 0.0009432 @iter2594) ([92m↓7.96%[0m) [0.48% of initial]
[Iter 2600] Gaussian 0 vs 1:
  Original Loss: 0.0013100
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013100 (Pseudo: 0.00%)
[Iter 2600] Gaussian 1 vs 0:
  Original Loss: 0.0013116
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013116 (Pseudo: 0.00%)
[Iter 2610/20000] Loss: 0.0060346 (Best: 0.0009432 @iter2594) ([91m↑401.79%[0m) [2.40% of initial]
[Iter 2610] Gaussian 0 vs 1:
  Original Loss: 0.0054844
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0054844 (Pseudo: 0.00%)
[Iter 2610] Gaussian 1 vs 0:
  Original Loss: 0.0054556
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0054556 (Pseudo: 0.00%)
[Iter 2620/20000] Loss: 0.0033043 (Best: 0.0009432 @iter2594) ([92m↓45.24%[0m) [1.31% of initial]
[Iter 2620] Gaussian 0 vs 1:
  Original Loss: 0.0028631
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028631 (Pseudo: 0.00%)
[Iter 2620] Gaussian 1 vs 0:
  Original Loss: 0.0027693
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027693 (Pseudo: 0.00%)
[Iter 2630/20000] Loss: 0.0021755 (Best: 0.0009432 @iter2594) ([92m↓34.16%[0m) [0.86% of initial]
[Iter 2630] Gaussian 0 vs 1:
  Original Loss: 0.0021562
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021562 (Pseudo: 0.00%)
[Iter 2630] Gaussian 1 vs 0:
  Original Loss: 0.0021418
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021418 (Pseudo: 0.00%)
[Iter 2640/20000] Loss: 0.0017024 (Best: 0.0009432 @iter2594) ([92m↓21.75%[0m) [0.68% of initial]
[Iter 2640] Gaussian 0 vs 1:
  Original Loss: 0.0015691
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015691 (Pseudo: 0.00%)
[Iter 2640] Gaussian 1 vs 0:
  Original Loss: 0.0016036
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016036 (Pseudo: 0.00%)
[Iter 2650/20000] Loss: 0.0013940 (Best: 0.0009432 @iter2594) ([92m↓18.12%[0m) [0.55% of initial]
[Iter 2650] Gaussian 0 vs 1:
  Original Loss: 0.0011346
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011346 (Pseudo: 0.00%)
[Iter 2650] Gaussian 1 vs 0:
  Original Loss: 0.0011632
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011632 (Pseudo: 0.00%)
[Iter 2660/20000] Loss: 0.0016448 (Best: 0.0009432 @iter2594) ([91m↑17.99%[0m) [0.65% of initial]
[Iter 2660] Gaussian 0 vs 1:
  Original Loss: 0.0014212
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014212 (Pseudo: 0.00%)
[Iter 2660] Gaussian 1 vs 0:
  Original Loss: 0.0014193
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014193 (Pseudo: 0.00%)
[Iter 2670/20000] Loss: 0.0015510 (Best: 0.0009432 @iter2594) ([92m↓5.70%[0m) [0.62% of initial]
[Iter 2670] Gaussian 0 vs 1:
  Original Loss: 0.0016066
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016066 (Pseudo: 0.00%)
[Iter 2670] Gaussian 1 vs 0:
  Original Loss: 0.0016605
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016605 (Pseudo: 0.00%)
[Iter 2680/20000] Loss: 0.0011958 (Best: 0.0009432 @iter2594) ([92m↓22.90%[0m) [0.48% of initial]
[Iter 2680] Gaussian 0 vs 1:
  Original Loss: 0.0009974
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009974 (Pseudo: 0.00%)
[Iter 2680] Gaussian 1 vs 0:
  Original Loss: 0.0010313
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010313 (Pseudo: 0.00%)
[Iter 2690/20000] Loss: 0.0011470 (Best: 0.0009432 @iter2594) ([92m↓4.08%[0m) [0.46% of initial]
[Iter 2690] Gaussian 0 vs 1:
  Original Loss: 0.0009736
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009736 (Pseudo: 0.00%)
[Iter 2690] Gaussian 1 vs 0:
  Original Loss: 0.0010132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010132 (Pseudo: 0.00%)
Iter:2699, L1 loss=0.001131, Total loss=0.001151, Time:16
[Iter 2700/20000] Loss: 0.0014518 (Best: 0.0009432 @iter2594) ([91m↑26.58%[0m) [0.58% of initial]
[Iter 2700] Gaussian 0 vs 1:
  Original Loss: 0.0017480
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017480 (Pseudo: 0.00%)
[Iter 2700] Gaussian 1 vs 0:
  Original Loss: 0.0017357
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017357 (Pseudo: 0.00%)
[Iter 2710/20000] Loss: 0.0012212 (Best: 0.0009432 @iter2594) ([92m↓15.89%[0m) [0.49% of initial]
[Iter 2710] Gaussian 0 vs 1:
  Original Loss: 0.0012359
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012359 (Pseudo: 0.00%)
[Iter 2710] Gaussian 1 vs 0:
  Original Loss: 0.0013093
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013093 (Pseudo: 0.00%)
[Iter 2720/20000] Loss: 0.0010870 (Best: 0.0009219 @iter2713) ([92m↓10.99%[0m) [0.43% of initial]
[Iter 2720] Gaussian 0 vs 1:
  Original Loss: 0.0010622
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010622 (Pseudo: 0.00%)
[Iter 2720] Gaussian 1 vs 0:
  Original Loss: 0.0010742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010742 (Pseudo: 0.00%)
[Iter 2730/20000] Loss: 0.0009880 (Best: 0.0008396 @iter2725) ([92m↓9.11%[0m) [0.39% of initial]
[Iter 2730] Gaussian 0 vs 1:
  Original Loss: 0.0009129
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009129 (Pseudo: 0.00%)
[Iter 2730] Gaussian 1 vs 0:
  Original Loss: 0.0009658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009658 (Pseudo: 0.00%)
[Iter 2740/20000] Loss: 0.0008605 (Best: 0.0007722 @iter2740) ([92m↓12.90%[0m) [0.34% of initial]
[Iter 2740] Gaussian 0 vs 1:
  Original Loss: 0.0007722
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007722 (Pseudo: 0.00%)
[Iter 2740] Gaussian 1 vs 0:
  Original Loss: 0.0007967
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007967 (Pseudo: 0.00%)
[Iter 2750/20000] Loss: 0.0011328 (Best: 0.0007722 @iter2740) ([91m↑31.64%[0m) [0.45% of initial]
[Iter 2750] Gaussian 0 vs 1:
  Original Loss: 0.0013024
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013024 (Pseudo: 0.00%)
[Iter 2750] Gaussian 1 vs 0:
  Original Loss: 0.0013330
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013330 (Pseudo: 0.00%)
[Iter 2760/20000] Loss: 0.0012262 (Best: 0.0007722 @iter2740) ([91m↑8.24%[0m) [0.49% of initial]
[Iter 2760] Gaussian 0 vs 1:
  Original Loss: 0.0014355
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014355 (Pseudo: 0.00%)
[Iter 2760] Gaussian 1 vs 0:
  Original Loss: 0.0013993
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013993 (Pseudo: 0.00%)
[Iter 2770/20000] Loss: 0.0013790 (Best: 0.0007722 @iter2740) ([91m↑12.46%[0m) [0.55% of initial]
[Iter 2770] Gaussian 0 vs 1:
  Original Loss: 0.0013902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013902 (Pseudo: 0.00%)
[Iter 2770] Gaussian 1 vs 0:
  Original Loss: 0.0012885
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012885 (Pseudo: 0.00%)
[Iter 2780/20000] Loss: 0.0010937 (Best: 0.0007722 @iter2740) ([92m↓20.69%[0m) [0.43% of initial]
[Iter 2780] Gaussian 0 vs 1:
  Original Loss: 0.0012486
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012486 (Pseudo: 0.00%)
[Iter 2780] Gaussian 1 vs 0:
  Original Loss: 0.0012622
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012622 (Pseudo: 0.00%)
[Iter 2790/20000] Loss: 0.0011173 (Best: 0.0007722 @iter2740) ([91m↑2.15%[0m) [0.44% of initial]
[Iter 2790] Gaussian 0 vs 1:
  Original Loss: 0.0011622
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011622 (Pseudo: 0.00%)
[Iter 2790] Gaussian 1 vs 0:
  Original Loss: 0.0012055
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012055 (Pseudo: 0.00%)
Iter:2799, L1 loss=0.001276, Total loss=0.001244, Time:16
[Iter 2800/20000] Loss: 0.0011216 (Best: 0.0007722 @iter2740) ([91m↑0.39%[0m) [0.45% of initial]
[Iter 2800] Gaussian 0 vs 1:
  Original Loss: 0.0010034
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010034 (Pseudo: 0.00%)
[Iter 2800] Gaussian 1 vs 0:
  Original Loss: 0.0010019
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010019 (Pseudo: 0.00%)
[Iter 2810/20000] Loss: 0.0049751 (Best: 0.0007722 @iter2740) ([91m↑343.57%[0m) [1.98% of initial]
[Iter 2810] Gaussian 0 vs 1:
  Original Loss: 0.0040502
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040502 (Pseudo: 0.00%)
[Iter 2810] Gaussian 1 vs 0:
  Original Loss: 0.0041810
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041810 (Pseudo: 0.00%)
[Iter 2820/20000] Loss: 0.0027285 (Best: 0.0007722 @iter2740) ([92m↓45.16%[0m) [1.08% of initial]
[Iter 2820] Gaussian 0 vs 1:
  Original Loss: 0.0025647
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025647 (Pseudo: 0.00%)
[Iter 2820] Gaussian 1 vs 0:
  Original Loss: 0.0025614
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025614 (Pseudo: 0.00%)
[Iter 2830/20000] Loss: 0.0017562 (Best: 0.0007722 @iter2740) ([92m↓35.63%[0m) [0.70% of initial]
[Iter 2830] Gaussian 0 vs 1:
  Original Loss: 0.0015239
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015239 (Pseudo: 0.00%)
[Iter 2830] Gaussian 1 vs 0:
  Original Loss: 0.0015956
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015956 (Pseudo: 0.00%)
[Iter 2840/20000] Loss: 0.0014863 (Best: 0.0007722 @iter2740) ([92m↓15.37%[0m) [0.59% of initial]
[Iter 2840] Gaussian 0 vs 1:
  Original Loss: 0.0015330
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015330 (Pseudo: 0.00%)
[Iter 2840] Gaussian 1 vs 0:
  Original Loss: 0.0015765
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015765 (Pseudo: 0.00%)
[Iter 2850/20000] Loss: 0.0012870 (Best: 0.0007722 @iter2740) ([92m↓13.41%[0m) [0.51% of initial]
[Iter 2850] Gaussian 0 vs 1:
  Original Loss: 0.0013079
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013079 (Pseudo: 0.00%)
[Iter 2850] Gaussian 1 vs 0:
  Original Loss: 0.0013613
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013613 (Pseudo: 0.00%)
[Iter 2860/20000] Loss: 0.0013964 (Best: 0.0007722 @iter2740) ([91m↑8.50%[0m) [0.55% of initial]
[Iter 2860] Gaussian 0 vs 1:
  Original Loss: 0.0014240
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014240 (Pseudo: 0.00%)
[Iter 2860] Gaussian 1 vs 0:
  Original Loss: 0.0014602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014602 (Pseudo: 0.00%)
[Iter 2870/20000] Loss: 0.0011742 (Best: 0.0007722 @iter2740) ([92m↓15.91%[0m) [0.47% of initial]
[Iter 2870] Gaussian 0 vs 1:
  Original Loss: 0.0011198
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011198 (Pseudo: 0.00%)
[Iter 2870] Gaussian 1 vs 0:
  Original Loss: 0.0011681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011681 (Pseudo: 0.00%)
[Iter 2880/20000] Loss: 0.0011453 (Best: 0.0007722 @iter2740) ([92m↓2.46%[0m) [0.45% of initial]
[Iter 2880] Gaussian 0 vs 1:
  Original Loss: 0.0011432
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011432 (Pseudo: 0.00%)
[Iter 2880] Gaussian 1 vs 0:
  Original Loss: 0.0012069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012069 (Pseudo: 0.00%)
[Iter 2890/20000] Loss: 0.0010832 (Best: 0.0007722 @iter2740) ([92m↓5.42%[0m) [0.43% of initial]
[Iter 2890] Gaussian 0 vs 1:
  Original Loss: 0.0010850
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010850 (Pseudo: 0.00%)
[Iter 2890] Gaussian 1 vs 0:
  Original Loss: 0.0011750
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011750 (Pseudo: 0.00%)
Iter:2899, L1 loss=0.0008849, Total loss=0.0008418, Time:17
[Iter 2900/20000] Loss: 0.0010200 (Best: 0.0007722 @iter2740) ([92m↓5.83%[0m) [0.41% of initial]
[Iter 2900] Gaussian 0 vs 1:
  Original Loss: 0.0010767
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010767 (Pseudo: 0.00%)
[Iter 2900] Gaussian 1 vs 0:
  Original Loss: 0.0011505
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011505 (Pseudo: 0.00%)
[Iter 2910/20000] Loss: 0.0011039 (Best: 0.0007722 @iter2740) ([91m↑8.22%[0m) [0.44% of initial]
[Iter 2910] Gaussian 0 vs 1:
  Original Loss: 0.0010608
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010608 (Pseudo: 0.00%)
[Iter 2910] Gaussian 1 vs 0:
  Original Loss: 0.0011112
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011112 (Pseudo: 0.00%)
[Iter 2920/20000] Loss: 0.0012353 (Best: 0.0007722 @iter2740) ([91m↑11.90%[0m) [0.49% of initial]
[Iter 2920] Gaussian 0 vs 1:
  Original Loss: 0.0012004
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012004 (Pseudo: 0.00%)
[Iter 2920] Gaussian 1 vs 0:
  Original Loss: 0.0012262
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012262 (Pseudo: 0.00%)
[Iter 2930/20000] Loss: 0.0011199 (Best: 0.0007722 @iter2740) ([92m↓9.34%[0m) [0.44% of initial]
[Iter 2930] Gaussian 0 vs 1:
  Original Loss: 0.0011639
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011639 (Pseudo: 0.00%)
[Iter 2930] Gaussian 1 vs 0:
  Original Loss: 0.0012480
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012480 (Pseudo: 0.00%)
[Iter 2940/20000] Loss: 0.0009712 (Best: 0.0007722 @iter2740) ([92m↓13.28%[0m) [0.39% of initial]
[Iter 2940] Gaussian 0 vs 1:
  Original Loss: 0.0009994
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009994 (Pseudo: 0.00%)
[Iter 2940] Gaussian 1 vs 0:
  Original Loss: 0.0009678
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009678 (Pseudo: 0.00%)
[Iter 2950/20000] Loss: 0.0009147 (Best: 0.0007722 @iter2740) ([92m↓5.82%[0m) [0.36% of initial]
[Iter 2950] Gaussian 0 vs 1:
  Original Loss: 0.0007887
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007887 (Pseudo: 0.00%)
[Iter 2950] Gaussian 1 vs 0:
  Original Loss: 0.0007735
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007735 (Pseudo: 0.00%)
[Iter 2960/20000] Loss: 0.0009734 (Best: 0.0007722 @iter2740) ([91m↑6.41%[0m) [0.39% of initial]
[Iter 2960] Gaussian 0 vs 1:
  Original Loss: 0.0010943
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010943 (Pseudo: 0.00%)
[Iter 2960] Gaussian 1 vs 0:
  Original Loss: 0.0011494
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011494 (Pseudo: 0.00%)
[Iter 2970/20000] Loss: 0.0008822 (Best: 0.0007206 @iter2969) ([92m↓9.36%[0m) [0.35% of initial]
[Iter 2970] Gaussian 0 vs 1:
  Original Loss: 0.0010197
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010197 (Pseudo: 0.00%)
[Iter 2970] Gaussian 1 vs 0:
  Original Loss: 0.0010784
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010784 (Pseudo: 0.00%)
[Iter 2980/20000] Loss: 0.0008343 (Best: 0.0007159 @iter2977) ([92m↓5.44%[0m) [0.33% of initial]
[Iter 2980] Gaussian 0 vs 1:
  Original Loss: 0.0008194
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008194 (Pseudo: 0.00%)
[Iter 2980] Gaussian 1 vs 0:
  Original Loss: 0.0008404
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008404 (Pseudo: 0.00%)
[Iter 2990/20000] Loss: 0.0008444 (Best: 0.0006816 @iter2983) ([91m↑1.21%[0m) [0.34% of initial]
[Iter 2990] Gaussian 0 vs 1:
  Original Loss: 0.0008154
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008154 (Pseudo: 0.00%)
[Iter 2990] Gaussian 1 vs 0:
  Original Loss: 0.0008080
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008080 (Pseudo: 0.00%)
Iter:2999, L1 loss=0.0006996, Total loss=0.0006523, Time:16
[Iter 3000/20000] Loss: 0.0008215 (Best: 0.0006523 @iter2999) ([92m↓2.71%[0m) [0.33% of initial]
[Iter 3000] Gaussian 0 vs 1:
  Original Loss: 0.0009780
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009780 (Pseudo: 0.00%)
[Iter 3000] Gaussian 1 vs 0:
  Original Loss: 0.0010524
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010524 (Pseudo: 0.00%)
[Iter 3010/20000] Loss: 0.0045499 (Best: 0.0006523 @iter2999) ([91m↑453.84%[0m) [1.81% of initial]
[Iter 3010] Gaussian 0 vs 1:
  Original Loss: 0.0035326
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035326 (Pseudo: 0.00%)
[Iter 3010] Gaussian 1 vs 0:
  Original Loss: 0.0036303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036303 (Pseudo: 0.00%)
[Iter 3020/20000] Loss: 0.0026290 (Best: 0.0006523 @iter2999) ([92m↓42.22%[0m) [1.04% of initial]
[Iter 3020] Gaussian 0 vs 1:
  Original Loss: 0.0027240
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027240 (Pseudo: 0.00%)
[Iter 3020] Gaussian 1 vs 0:
  Original Loss: 0.0027112
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027112 (Pseudo: 0.00%)
[Iter 3030/20000] Loss: 0.0020890 (Best: 0.0006523 @iter2999) ([92m↓20.54%[0m) [0.83% of initial]
[Iter 3030] Gaussian 0 vs 1:
  Original Loss: 0.0024617
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024617 (Pseudo: 0.00%)
[Iter 3030] Gaussian 1 vs 0:
  Original Loss: 0.0024983
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024983 (Pseudo: 0.00%)
[Iter 3040/20000] Loss: 0.0017030 (Best: 0.0006523 @iter2999) ([92m↓18.48%[0m) [0.68% of initial]
[Iter 3040] Gaussian 0 vs 1:
  Original Loss: 0.0014865
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014865 (Pseudo: 0.00%)
[Iter 3040] Gaussian 1 vs 0:
  Original Loss: 0.0014183
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014183 (Pseudo: 0.00%)
[Iter 3050/20000] Loss: 0.0014198 (Best: 0.0006523 @iter2999) ([92m↓16.63%[0m) [0.56% of initial]
[Iter 3050] Gaussian 0 vs 1:
  Original Loss: 0.0015042
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015042 (Pseudo: 0.00%)
[Iter 3050] Gaussian 1 vs 0:
  Original Loss: 0.0015727
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015727 (Pseudo: 0.00%)
[Iter 3060/20000] Loss: 0.0013639 (Best: 0.0006523 @iter2999) ([92m↓3.94%[0m) [0.54% of initial]
[Iter 3060] Gaussian 0 vs 1:
  Original Loss: 0.0011491
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011491 (Pseudo: 0.00%)
[Iter 3060] Gaussian 1 vs 0:
  Original Loss: 0.0011235
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011235 (Pseudo: 0.00%)
[Iter 3070/20000] Loss: 0.0011124 (Best: 0.0006523 @iter2999) ([92m↓18.44%[0m) [0.44% of initial]
[Iter 3070] Gaussian 0 vs 1:
  Original Loss: 0.0010832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010832 (Pseudo: 0.00%)
[Iter 3070] Gaussian 1 vs 0:
  Original Loss: 0.0011705
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011705 (Pseudo: 0.00%)
[Iter 3080/20000] Loss: 0.0011266 (Best: 0.0006523 @iter2999) ([91m↑1.27%[0m) [0.45% of initial]
[Iter 3080] Gaussian 0 vs 1:
  Original Loss: 0.0012836
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012836 (Pseudo: 0.00%)
[Iter 3080] Gaussian 1 vs 0:
  Original Loss: 0.0013310
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013310 (Pseudo: 0.00%)
[Iter 3090/20000] Loss: 0.0010788 (Best: 0.0006523 @iter2999) ([92m↓4.24%[0m) [0.43% of initial]
[Iter 3090] Gaussian 0 vs 1:
  Original Loss: 0.0011962
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011962 (Pseudo: 0.00%)
[Iter 3090] Gaussian 1 vs 0:
  Original Loss: 0.0011747
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011747 (Pseudo: 0.00%)
Iter:3099, L1 loss=0.000894, Total loss=0.0008774, Time:17
[Iter 3100/20000] Loss: 0.0009867 (Best: 0.0006523 @iter2999) ([92m↓8.54%[0m) [0.39% of initial]
[Iter 3100] Gaussian 0 vs 1:
  Original Loss: 0.0009876
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009876 (Pseudo: 0.00%)
[Iter 3100] Gaussian 1 vs 0:
  Original Loss: 0.0010478
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010478 (Pseudo: 0.00%)
[Iter 3110/20000] Loss: 0.0010857 (Best: 0.0006523 @iter2999) ([91m↑10.03%[0m) [0.43% of initial]
[Iter 3110] Gaussian 0 vs 1:
  Original Loss: 0.0012822
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012822 (Pseudo: 0.00%)
[Iter 3110] Gaussian 1 vs 0:
  Original Loss: 0.0013810
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013810 (Pseudo: 0.00%)
[Iter 3120/20000] Loss: 0.0010291 (Best: 0.0006523 @iter2999) ([92m↓5.21%[0m) [0.41% of initial]
[Iter 3120] Gaussian 0 vs 1:
  Original Loss: 0.0011599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011599 (Pseudo: 0.00%)
[Iter 3120] Gaussian 1 vs 0:
  Original Loss: 0.0012107
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012107 (Pseudo: 0.00%)
[Iter 3130/20000] Loss: 0.0008298 (Best: 0.0006523 @iter2999) ([92m↓19.37%[0m) [0.33% of initial]
[Iter 3130] Gaussian 0 vs 1:
  Original Loss: 0.0007245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007245 (Pseudo: 0.00%)
[Iter 3130] Gaussian 1 vs 0:
  Original Loss: 0.0007683
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007683 (Pseudo: 0.00%)
[Iter 3140/20000] Loss: 0.0007993 (Best: 0.0006523 @iter2999) ([92m↓3.67%[0m) [0.32% of initial]
[Iter 3140] Gaussian 0 vs 1:
  Original Loss: 0.0008534
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008534 (Pseudo: 0.00%)
[Iter 3140] Gaussian 1 vs 0:
  Original Loss: 0.0009095
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009095 (Pseudo: 0.00%)
[Iter 3150/20000] Loss: 0.0008259 (Best: 0.0006523 @iter2999) ([91m↑3.32%[0m) [0.33% of initial]
[Iter 3150] Gaussian 0 vs 1:
  Original Loss: 0.0009833
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009833 (Pseudo: 0.00%)
[Iter 3150] Gaussian 1 vs 0:
  Original Loss: 0.0010638
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010638 (Pseudo: 0.00%)
[Iter 3160/20000] Loss: 0.0007774 (Best: 0.0006523 @iter2999) ([92m↓5.87%[0m) [0.31% of initial]
[Iter 3160] Gaussian 0 vs 1:
  Original Loss: 0.0006655
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006655 (Pseudo: 0.00%)
[Iter 3160] Gaussian 1 vs 0:
  Original Loss: 0.0006967
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006967 (Pseudo: 0.00%)
[Iter 3170/20000] Loss: 0.0007989 (Best: 0.0006523 @iter2999) ([91m↑2.77%[0m) [0.32% of initial]
[Iter 3170] Gaussian 0 vs 1:
  Original Loss: 0.0008361
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008361 (Pseudo: 0.00%)
[Iter 3170] Gaussian 1 vs 0:
  Original Loss: 0.0009053
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009053 (Pseudo: 0.00%)
[Iter 3180/20000] Loss: 0.0008501 (Best: 0.0006523 @iter2999) ([91m↑6.41%[0m) [0.34% of initial]
[Iter 3180] Gaussian 0 vs 1:
  Original Loss: 0.0008853
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008853 (Pseudo: 0.00%)
[Iter 3180] Gaussian 1 vs 0:
  Original Loss: 0.0009093
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009093 (Pseudo: 0.00%)
[Iter 3190/20000] Loss: 0.0008299 (Best: 0.0006523 @iter2999) ([92m↓2.38%[0m) [0.33% of initial]
[Iter 3190] Gaussian 0 vs 1:
  Original Loss: 0.0007891
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007891 (Pseudo: 0.00%)
[Iter 3190] Gaussian 1 vs 0:
  Original Loss: 0.0007642
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007642 (Pseudo: 0.00%)
Iter:3199, L1 loss=0.0007921, Total loss=0.0007481, Time:17
[Iter 3200/20000] Loss: 0.0007863 (Best: 0.0006254 @iter3196) ([92m↓5.25%[0m) [0.31% of initial]
[Iter 3200] Gaussian 0 vs 1:
  Original Loss: 0.0008014
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008014 (Pseudo: 0.00%)
[Iter 3200] Gaussian 1 vs 0:
  Original Loss: 0.0008506
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008506 (Pseudo: 0.00%)
[Iter 3210/20000] Loss: 0.0049806 (Best: 0.0006254 @iter3196) ([91m↑533.39%[0m) [1.98% of initial]
[Iter 3210] Gaussian 0 vs 1:
  Original Loss: 0.0046798
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046798 (Pseudo: 0.00%)
[Iter 3210] Gaussian 1 vs 0:
  Original Loss: 0.0051557
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051557 (Pseudo: 0.00%)
[Iter 3220/20000] Loss: 0.0026567 (Best: 0.0006254 @iter3196) ([92m↓46.66%[0m) [1.06% of initial]
[Iter 3220] Gaussian 0 vs 1:
  Original Loss: 0.0023684
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023684 (Pseudo: 0.00%)
[Iter 3220] Gaussian 1 vs 0:
  Original Loss: 0.0025743
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025743 (Pseudo: 0.00%)
[Iter 3230/20000] Loss: 0.0016267 (Best: 0.0006254 @iter3196) ([92m↓38.77%[0m) [0.65% of initial]
[Iter 3230] Gaussian 0 vs 1:
  Original Loss: 0.0016169
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016169 (Pseudo: 0.00%)
[Iter 3230] Gaussian 1 vs 0:
  Original Loss: 0.0016387
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016387 (Pseudo: 0.00%)
[Iter 3240/20000] Loss: 0.0014270 (Best: 0.0006254 @iter3196) ([92m↓12.27%[0m) [0.57% of initial]
[Iter 3240] Gaussian 0 vs 1:
  Original Loss: 0.0014442
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014442 (Pseudo: 0.00%)
[Iter 3240] Gaussian 1 vs 0:
  Original Loss: 0.0015464
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015464 (Pseudo: 0.00%)
[Iter 3250/20000] Loss: 0.0010709 (Best: 0.0006254 @iter3196) ([92m↓24.95%[0m) [0.43% of initial]
[Iter 3250] Gaussian 0 vs 1:
  Original Loss: 0.0009927
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009927 (Pseudo: 0.00%)
[Iter 3250] Gaussian 1 vs 0:
  Original Loss: 0.0010079
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010079 (Pseudo: 0.00%)
[Iter 3260/20000] Loss: 0.0009502 (Best: 0.0006254 @iter3196) ([92m↓11.27%[0m) [0.38% of initial]
[Iter 3260] Gaussian 0 vs 1:
  Original Loss: 0.0008659
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008659 (Pseudo: 0.00%)
[Iter 3260] Gaussian 1 vs 0:
  Original Loss: 0.0008868
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008868 (Pseudo: 0.00%)
[Iter 3270/20000] Loss: 0.0009700 (Best: 0.0006254 @iter3196) ([91m↑2.09%[0m) [0.39% of initial]
[Iter 3270] Gaussian 0 vs 1:
  Original Loss: 0.0011422
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011422 (Pseudo: 0.00%)
[Iter 3270] Gaussian 1 vs 0:
  Original Loss: 0.0012094
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012094 (Pseudo: 0.00%)
[Iter 3280/20000] Loss: 0.0010298 (Best: 0.0006254 @iter3196) ([91m↑6.16%[0m) [0.41% of initial]
[Iter 3280] Gaussian 0 vs 1:
  Original Loss: 0.0009837
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009837 (Pseudo: 0.00%)
[Iter 3280] Gaussian 1 vs 0:
  Original Loss: 0.0009744
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009744 (Pseudo: 0.00%)
[Iter 3290/20000] Loss: 0.0007705 (Best: 0.0006254 @iter3196) ([92m↓25.17%[0m) [0.31% of initial]
[Iter 3290] Gaussian 0 vs 1:
  Original Loss: 0.0007109
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007109 (Pseudo: 0.00%)
[Iter 3290] Gaussian 1 vs 0:
  Original Loss: 0.0007140
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007140 (Pseudo: 0.00%)
Iter:3299, L1 loss=0.00122, Total loss=0.001178, Time:18
[Iter 3300/20000] Loss: 0.0010454 (Best: 0.0006254 @iter3196) ([91m↑35.68%[0m) [0.42% of initial]
[Iter 3300] Gaussian 0 vs 1:
  Original Loss: 0.0010015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010015 (Pseudo: 0.00%)
[Iter 3300] Gaussian 1 vs 0:
  Original Loss: 0.0010017
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010017 (Pseudo: 0.00%)
[Iter 3310/20000] Loss: 0.0008255 (Best: 0.0006254 @iter3196) ([92m↓21.03%[0m) [0.33% of initial]
[Iter 3310] Gaussian 0 vs 1:
  Original Loss: 0.0007516
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007516 (Pseudo: 0.00%)
[Iter 3310] Gaussian 1 vs 0:
  Original Loss: 0.0007175
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007175 (Pseudo: 0.00%)
[Iter 3320/20000] Loss: 0.0009261 (Best: 0.0006254 @iter3196) ([91m↑12.18%[0m) [0.37% of initial]
[Iter 3320] Gaussian 0 vs 1:
  Original Loss: 0.0009551
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009551 (Pseudo: 0.00%)
[Iter 3320] Gaussian 1 vs 0:
  Original Loss: 0.0010159
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010159 (Pseudo: 0.00%)
[Iter 3330/20000] Loss: 0.0009646 (Best: 0.0006254 @iter3196) ([91m↑4.15%[0m) [0.38% of initial]
[Iter 3330] Gaussian 0 vs 1:
  Original Loss: 0.0010594
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010594 (Pseudo: 0.00%)
[Iter 3330] Gaussian 1 vs 0:
  Original Loss: 0.0011511
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011511 (Pseudo: 0.00%)
[Iter 3340/20000] Loss: 0.0010185 (Best: 0.0006254 @iter3196) ([91m↑5.59%[0m) [0.40% of initial]
[Iter 3340] Gaussian 0 vs 1:
  Original Loss: 0.0009773
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009773 (Pseudo: 0.00%)
[Iter 3340] Gaussian 1 vs 0:
  Original Loss: 0.0010661
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010661 (Pseudo: 0.00%)
[Iter 3350/20000] Loss: 0.0008340 (Best: 0.0006254 @iter3196) ([92m↓18.12%[0m) [0.33% of initial]
[Iter 3350] Gaussian 0 vs 1:
  Original Loss: 0.0008964
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008964 (Pseudo: 0.00%)
[Iter 3350] Gaussian 1 vs 0:
  Original Loss: 0.0009398
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009398 (Pseudo: 0.00%)
[Iter 3360/20000] Loss: 0.0010132 (Best: 0.0006254 @iter3196) ([91m↑21.49%[0m) [0.40% of initial]
[Iter 3360] Gaussian 0 vs 1:
  Original Loss: 0.0011661
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011661 (Pseudo: 0.00%)
[Iter 3360] Gaussian 1 vs 0:
  Original Loss: 0.0012574
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012574 (Pseudo: 0.00%)
[Iter 3370/20000] Loss: 0.0007542 (Best: 0.0006254 @iter3196) ([92m↓25.56%[0m) [0.30% of initial]
[Iter 3370] Gaussian 0 vs 1:
  Original Loss: 0.0006464
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006464 (Pseudo: 0.00%)
[Iter 3370] Gaussian 1 vs 0:
  Original Loss: 0.0006811
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006811 (Pseudo: 0.00%)
[Iter 3380/20000] Loss: 0.0007331 (Best: 0.0006254 @iter3196) ([92m↓2.81%[0m) [0.29% of initial]
[Iter 3380] Gaussian 0 vs 1:
  Original Loss: 0.0007587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007587 (Pseudo: 0.00%)
[Iter 3380] Gaussian 1 vs 0:
  Original Loss: 0.0008515
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008515 (Pseudo: 0.00%)
[Iter 3390/20000] Loss: 0.0009832 (Best: 0.0006254 @iter3196) ([91m↑34.12%[0m) [0.39% of initial]
[Iter 3390] Gaussian 0 vs 1:
  Original Loss: 0.0009168
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009168 (Pseudo: 0.00%)
[Iter 3390] Gaussian 1 vs 0:
  Original Loss: 0.0008658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008658 (Pseudo: 0.00%)
Iter:3399, L1 loss=0.001184, Total loss=0.001165, Time:18
[Iter 3400/20000] Loss: 0.0010055 (Best: 0.0006254 @iter3196) ([91m↑2.26%[0m) [0.40% of initial]
[Iter 3400] Gaussian 0 vs 1:
  Original Loss: 0.0008602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008602 (Pseudo: 0.00%)
[Iter 3400] Gaussian 1 vs 0:
  Original Loss: 0.0008400
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008400 (Pseudo: 0.00%)
[Iter 3410/20000] Loss: 0.0045627 (Best: 0.0006254 @iter3196) ([91m↑353.79%[0m) [1.81% of initial]
[Iter 3410] Gaussian 0 vs 1:
  Original Loss: 0.0041822
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041822 (Pseudo: 0.00%)
[Iter 3410] Gaussian 1 vs 0:
  Original Loss: 0.0038520
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038520 (Pseudo: 0.00%)
[Iter 3420/20000] Loss: 0.0023096 (Best: 0.0006254 @iter3196) ([92m↓49.38%[0m) [0.92% of initial]
[Iter 3420] Gaussian 0 vs 1:
  Original Loss: 0.0020035
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020035 (Pseudo: 0.00%)
[Iter 3420] Gaussian 1 vs 0:
  Original Loss: 0.0023234
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023234 (Pseudo: 0.00%)
[Iter 3430/20000] Loss: 0.0014949 (Best: 0.0006254 @iter3196) ([92m↓35.27%[0m) [0.59% of initial]
[Iter 3430] Gaussian 0 vs 1:
  Original Loss: 0.0013054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013054 (Pseudo: 0.00%)
[Iter 3430] Gaussian 1 vs 0:
  Original Loss: 0.0013495
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013495 (Pseudo: 0.00%)
[Iter 3440/20000] Loss: 0.0012414 (Best: 0.0006254 @iter3196) ([92m↓16.96%[0m) [0.49% of initial]
[Iter 3440] Gaussian 0 vs 1:
  Original Loss: 0.0011336
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011336 (Pseudo: 0.00%)
[Iter 3440] Gaussian 1 vs 0:
  Original Loss: 0.0012015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012015 (Pseudo: 0.00%)
[Iter 3450/20000] Loss: 0.0011392 (Best: 0.0006254 @iter3196) ([92m↓8.23%[0m) [0.45% of initial]
[Iter 3450] Gaussian 0 vs 1:
  Original Loss: 0.0012144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012144 (Pseudo: 0.00%)
[Iter 3450] Gaussian 1 vs 0:
  Original Loss: 0.0012491
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012491 (Pseudo: 0.00%)
[Iter 3460/20000] Loss: 0.0010240 (Best: 0.0006254 @iter3196) ([92m↓10.12%[0m) [0.41% of initial]
[Iter 3460] Gaussian 0 vs 1:
  Original Loss: 0.0009443
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009443 (Pseudo: 0.00%)
[Iter 3460] Gaussian 1 vs 0:
  Original Loss: 0.0010317
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010317 (Pseudo: 0.00%)
[Iter 3470/20000] Loss: 0.0009663 (Best: 0.0006254 @iter3196) ([92m↓5.63%[0m) [0.38% of initial]
[Iter 3470] Gaussian 0 vs 1:
  Original Loss: 0.0009094
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009094 (Pseudo: 0.00%)
[Iter 3470] Gaussian 1 vs 0:
  Original Loss: 0.0009271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009271 (Pseudo: 0.00%)
[Iter 3480/20000] Loss: 0.0008994 (Best: 0.0006254 @iter3196) ([92m↓6.92%[0m) [0.36% of initial]
[Iter 3480] Gaussian 0 vs 1:
  Original Loss: 0.0009657
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009657 (Pseudo: 0.00%)
[Iter 3480] Gaussian 1 vs 0:
  Original Loss: 0.0009375
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009375 (Pseudo: 0.00%)
[Iter 3490/20000] Loss: 0.0008619 (Best: 0.0006254 @iter3196) ([92m↓4.17%[0m) [0.34% of initial]
[Iter 3490] Gaussian 0 vs 1:
  Original Loss: 0.0009015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009015 (Pseudo: 0.00%)
[Iter 3490] Gaussian 1 vs 0:
  Original Loss: 0.0008519
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008519 (Pseudo: 0.00%)
Iter:3499, L1 loss=0.0006636, Total loss=0.0006071, Time:18
[Iter 3500/20000] Loss: 0.0006592 (Best: 0.0006071 @iter3499) ([92m↓23.51%[0m) [0.26% of initial]
[Iter 3500] Gaussian 0 vs 1:
  Original Loss: 0.0006228
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006228 (Pseudo: 0.00%)
[Iter 3500] Gaussian 1 vs 0:
  Original Loss: 0.0006255
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006255 (Pseudo: 0.00%)
[Iter 3510/20000] Loss: 0.0007230 (Best: 0.0006071 @iter3499) ([91m↑9.67%[0m) [0.29% of initial]
[Iter 3510] Gaussian 0 vs 1:
  Original Loss: 0.0006634
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006634 (Pseudo: 0.00%)
[Iter 3510] Gaussian 1 vs 0:
  Original Loss: 0.0006789
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006789 (Pseudo: 0.00%)
[Iter 3520/20000] Loss: 0.0007205 (Best: 0.0005927 @iter3517) ([92m↓0.33%[0m) [0.29% of initial]
[Iter 3520] Gaussian 0 vs 1:
  Original Loss: 0.0007404
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007404 (Pseudo: 0.00%)
[Iter 3520] Gaussian 1 vs 0:
  Original Loss: 0.0007957
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007957 (Pseudo: 0.00%)
[Iter 3530/20000] Loss: 0.0007630 (Best: 0.0005927 @iter3517) ([91m↑5.90%[0m) [0.30% of initial]
[Iter 3530] Gaussian 0 vs 1:
  Original Loss: 0.0008405
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008405 (Pseudo: 0.00%)
[Iter 3530] Gaussian 1 vs 0:
  Original Loss: 0.0009009
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009009 (Pseudo: 0.00%)
[Iter 3540/20000] Loss: 0.0010441 (Best: 0.0005927 @iter3517) ([91m↑36.83%[0m) [0.41% of initial]
[Iter 3540] Gaussian 0 vs 1:
  Original Loss: 0.0011651
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011651 (Pseudo: 0.00%)
[Iter 3540] Gaussian 1 vs 0:
  Original Loss: 0.0012267
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012267 (Pseudo: 0.00%)
[Iter 3550/20000] Loss: 0.0010043 (Best: 0.0005927 @iter3517) ([92m↓3.81%[0m) [0.40% of initial]
[Iter 3550] Gaussian 0 vs 1:
  Original Loss: 0.0009668
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009668 (Pseudo: 0.00%)
[Iter 3550] Gaussian 1 vs 0:
  Original Loss: 0.0009232
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009232 (Pseudo: 0.00%)
[Iter 3560/20000] Loss: 0.0009004 (Best: 0.0005927 @iter3517) ([92m↓10.34%[0m) [0.36% of initial]
[Iter 3560] Gaussian 0 vs 1:
  Original Loss: 0.0008940
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008940 (Pseudo: 0.00%)
[Iter 3560] Gaussian 1 vs 0:
  Original Loss: 0.0008804
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008804 (Pseudo: 0.00%)
[Iter 3570/20000] Loss: 0.0009132 (Best: 0.0005927 @iter3517) ([91m↑1.42%[0m) [0.36% of initial]
[Iter 3570] Gaussian 0 vs 1:
  Original Loss: 0.0011207
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011207 (Pseudo: 0.00%)
[Iter 3570] Gaussian 1 vs 0:
  Original Loss: 0.0011686
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011686 (Pseudo: 0.00%)
[Iter 3580/20000] Loss: 0.0007222 (Best: 0.0005927 @iter3517) ([92m↓20.92%[0m) [0.29% of initial]
[Iter 3580] Gaussian 0 vs 1:
  Original Loss: 0.0006439
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006439 (Pseudo: 0.00%)
[Iter 3580] Gaussian 1 vs 0:
  Original Loss: 0.0006277
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006277 (Pseudo: 0.00%)
[Iter 3590/20000] Loss: 0.0007093 (Best: 0.0005927 @iter3517) ([92m↓1.78%[0m) [0.28% of initial]
[Iter 3590] Gaussian 0 vs 1:
  Original Loss: 0.0006760
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006760 (Pseudo: 0.00%)
[Iter 3590] Gaussian 1 vs 0:
  Original Loss: 0.0006701
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006701 (Pseudo: 0.00%)
Iter:3599, L1 loss=0.0006328, Total loss=0.0005842, Time:18
[Iter 3600/20000] Loss: 0.0006901 (Best: 0.0005735 @iter3598) ([92m↓2.70%[0m) [0.27% of initial]
[Iter 3600] Gaussian 0 vs 1:
  Original Loss: 0.0008013
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008013 (Pseudo: 0.00%)
[Iter 3600] Gaussian 1 vs 0:
  Original Loss: 0.0008138
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008138 (Pseudo: 0.00%)
[Iter 3610/20000] Loss: 0.0046911 (Best: 0.0005735 @iter3598) ([91m↑579.72%[0m) [1.86% of initial]
[Iter 3610] Gaussian 0 vs 1:
  Original Loss: 0.0036785
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036785 (Pseudo: 0.00%)
[Iter 3610] Gaussian 1 vs 0:
  Original Loss: 0.0040060
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040060 (Pseudo: 0.00%)
[Iter 3620/20000] Loss: 0.0026481 (Best: 0.0005735 @iter3598) ([92m↓43.55%[0m) [1.05% of initial]
[Iter 3620] Gaussian 0 vs 1:
  Original Loss: 0.0024166
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024166 (Pseudo: 0.00%)
[Iter 3620] Gaussian 1 vs 0:
  Original Loss: 0.0023905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023905 (Pseudo: 0.00%)
[Iter 3630/20000] Loss: 0.0015306 (Best: 0.0005735 @iter3598) ([92m↓42.20%[0m) [0.61% of initial]
[Iter 3630] Gaussian 0 vs 1:
  Original Loss: 0.0014425
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014425 (Pseudo: 0.00%)
[Iter 3630] Gaussian 1 vs 0:
  Original Loss: 0.0015558
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015558 (Pseudo: 0.00%)
[Iter 3640/20000] Loss: 0.0011170 (Best: 0.0005735 @iter3598) ([92m↓27.02%[0m) [0.44% of initial]
[Iter 3640] Gaussian 0 vs 1:
  Original Loss: 0.0010923
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010923 (Pseudo: 0.00%)
[Iter 3640] Gaussian 1 vs 0:
  Original Loss: 0.0011783
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011783 (Pseudo: 0.00%)
[Iter 3650/20000] Loss: 0.0011041 (Best: 0.0005735 @iter3598) ([92m↓1.16%[0m) [0.44% of initial]
[Iter 3650] Gaussian 0 vs 1:
  Original Loss: 0.0011730
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011730 (Pseudo: 0.00%)
[Iter 3650] Gaussian 1 vs 0:
  Original Loss: 0.0012402
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012402 (Pseudo: 0.00%)
[Iter 3660/20000] Loss: 0.0008812 (Best: 0.0005735 @iter3598) ([92m↓20.19%[0m) [0.35% of initial]
[Iter 3660] Gaussian 0 vs 1:
  Original Loss: 0.0009422
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009422 (Pseudo: 0.00%)
[Iter 3660] Gaussian 1 vs 0:
  Original Loss: 0.0009502
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009502 (Pseudo: 0.00%)
[Iter 3670/20000] Loss: 0.0007818 (Best: 0.0005735 @iter3598) ([92m↓11.27%[0m) [0.31% of initial]
[Iter 3670] Gaussian 0 vs 1:
  Original Loss: 0.0007069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007069 (Pseudo: 0.00%)
[Iter 3670] Gaussian 1 vs 0:
  Original Loss: 0.0007167
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007167 (Pseudo: 0.00%)
[Iter 3680/20000] Loss: 0.0009581 (Best: 0.0005735 @iter3598) ([91m↑22.54%[0m) [0.38% of initial]
[Iter 3680] Gaussian 0 vs 1:
  Original Loss: 0.0010227
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010227 (Pseudo: 0.00%)
[Iter 3680] Gaussian 1 vs 0:
  Original Loss: 0.0010757
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010757 (Pseudo: 0.00%)
[Iter 3690/20000] Loss: 0.0012407 (Best: 0.0005735 @iter3598) ([91m↑29.50%[0m) [0.49% of initial]
[Iter 3690] Gaussian 0 vs 1:
  Original Loss: 0.0016362
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016362 (Pseudo: 0.00%)
[Iter 3690] Gaussian 1 vs 0:
  Original Loss: 0.0014205
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014205 (Pseudo: 0.00%)
Iter:3699, L1 loss=0.001052, Total loss=0.000964, Time:19
[Iter 3700/20000] Loss: 0.0010279 (Best: 0.0005735 @iter3598) ([92m↓17.15%[0m) [0.41% of initial]
[Iter 3700] Gaussian 0 vs 1:
  Original Loss: 0.0010231
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010231 (Pseudo: 0.00%)
[Iter 3700] Gaussian 1 vs 0:
  Original Loss: 0.0009627
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009627 (Pseudo: 0.00%)
[Iter 3710/20000] Loss: 0.0008029 (Best: 0.0005735 @iter3598) ([92m↓21.88%[0m) [0.32% of initial]
[Iter 3710] Gaussian 0 vs 1:
  Original Loss: 0.0008168
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008168 (Pseudo: 0.00%)
[Iter 3710] Gaussian 1 vs 0:
  Original Loss: 0.0008466
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008466 (Pseudo: 0.00%)
[Iter 3720/20000] Loss: 0.0008543 (Best: 0.0005735 @iter3598) ([91m↑6.39%[0m) [0.34% of initial]
[Iter 3720] Gaussian 0 vs 1:
  Original Loss: 0.0007890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007890 (Pseudo: 0.00%)
[Iter 3720] Gaussian 1 vs 0:
  Original Loss: 0.0007995
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007995 (Pseudo: 0.00%)
[Iter 3730/20000] Loss: 0.0007381 (Best: 0.0005735 @iter3598) ([92m↓13.59%[0m) [0.29% of initial]
[Iter 3730] Gaussian 0 vs 1:
  Original Loss: 0.0006716
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006716 (Pseudo: 0.00%)
[Iter 3730] Gaussian 1 vs 0:
  Original Loss: 0.0006608
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006608 (Pseudo: 0.00%)
[Iter 3740/20000] Loss: 0.0007469 (Best: 0.0005735 @iter3598) ([91m↑1.19%[0m) [0.30% of initial]
[Iter 3740] Gaussian 0 vs 1:
  Original Loss: 0.0008076
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008076 (Pseudo: 0.00%)
[Iter 3740] Gaussian 1 vs 0:
  Original Loss: 0.0008363
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008363 (Pseudo: 0.00%)
[Iter 3750/20000] Loss: 0.0007782 (Best: 0.0005735 @iter3598) ([91m↑4.18%[0m) [0.31% of initial]
[Iter 3750] Gaussian 0 vs 1:
  Original Loss: 0.0008450
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008450 (Pseudo: 0.00%)
[Iter 3750] Gaussian 1 vs 0:
  Original Loss: 0.0008558
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008558 (Pseudo: 0.00%)
[Iter 3760/20000] Loss: 0.0007585 (Best: 0.0005735 @iter3598) ([92m↓2.53%[0m) [0.30% of initial]
[Iter 3760] Gaussian 0 vs 1:
  Original Loss: 0.0007587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007587 (Pseudo: 0.00%)
[Iter 3760] Gaussian 1 vs 0:
  Original Loss: 0.0007966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007966 (Pseudo: 0.00%)
[Iter 3770/20000] Loss: 0.0007261 (Best: 0.0005735 @iter3598) ([92m↓4.27%[0m) [0.29% of initial]
[Iter 3770] Gaussian 0 vs 1:
  Original Loss: 0.0006828
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006828 (Pseudo: 0.00%)
[Iter 3770] Gaussian 1 vs 0:
  Original Loss: 0.0006987
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006987 (Pseudo: 0.00%)
[Iter 3780/20000] Loss: 0.0006760 (Best: 0.0005296 @iter3775) ([92m↓6.91%[0m) [0.27% of initial]
[Iter 3780] Gaussian 0 vs 1:
  Original Loss: 0.0007353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007353 (Pseudo: 0.00%)
[Iter 3780] Gaussian 1 vs 0:
  Original Loss: 0.0007602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007602 (Pseudo: 0.00%)
[Iter 3790/20000] Loss: 0.0005558 (Best: 0.0004960 @iter3790) ([92m↓17.77%[0m) [0.22% of initial]
[Iter 3790] Gaussian 0 vs 1:
  Original Loss: 0.0004960
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004960 (Pseudo: 0.00%)
[Iter 3790] Gaussian 1 vs 0:
  Original Loss: 0.0005037
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005037 (Pseudo: 0.00%)
Iter:3799, L1 loss=0.0007244, Total loss=0.0006896, Time:19
[Iter 3800/20000] Loss: 0.0006981 (Best: 0.0004960 @iter3790) ([91m↑25.60%[0m) [0.28% of initial]
[Iter 3800] Gaussian 0 vs 1:
  Original Loss: 0.0006585
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006585 (Pseudo: 0.00%)
[Iter 3800] Gaussian 1 vs 0:
  Original Loss: 0.0006596
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006596 (Pseudo: 0.00%)
[Iter 3810/20000] Loss: 0.0050216 (Best: 0.0004960 @iter3790) ([91m↑619.32%[0m) [2.00% of initial]
[Iter 3810] Gaussian 0 vs 1:
  Original Loss: 0.0055907
  Pseudo Loss: 0.0012824 (22.94% of original)
  Total Loss: 0.0068731 (Pseudo: 18.66%)
[Iter 3810] Gaussian 1 vs 0:
  Original Loss: 0.0043491
  Pseudo Loss: 0.0012824 (29.49% of original)
  Total Loss: 0.0056315 (Pseudo: 22.77%)
[Iter 3810] Pseudo Loss: 0.0018661
[Iter 3820/20000] Loss: 0.0024094 (Best: 0.0004960 @iter3790) ([92m↓52.02%[0m) [0.96% of initial]
[Iter 3820] Gaussian 0 vs 1:
  Original Loss: 0.0018961
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018961 (Pseudo: 0.00%)
[Iter 3820] Gaussian 1 vs 0:
  Original Loss: 0.0018700
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018700 (Pseudo: 0.00%)
[Iter 3830/20000] Loss: 0.0013805 (Best: 0.0004960 @iter3790) ([92m↓42.70%[0m) [0.55% of initial]
[Iter 3830] Gaussian 0 vs 1:
  Original Loss: 0.0013333
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013333 (Pseudo: 0.00%)
[Iter 3830] Gaussian 1 vs 0:
  Original Loss: 0.0013359
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013359 (Pseudo: 0.00%)
[Iter 3840/20000] Loss: 0.0013238 (Best: 0.0004960 @iter3790) ([92m↓4.11%[0m) [0.53% of initial]
[Iter 3840] Gaussian 0 vs 1:
  Original Loss: 0.0015472
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015472 (Pseudo: 0.00%)
[Iter 3840] Gaussian 1 vs 0:
  Original Loss: 0.0015910
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015910 (Pseudo: 0.00%)
[Iter 3850/20000] Loss: 0.0009814 (Best: 0.0004960 @iter3790) ([92m↓25.86%[0m) [0.39% of initial]
[Iter 3850] Gaussian 0 vs 1:
  Original Loss: 0.0008981
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008981 (Pseudo: 0.00%)
[Iter 3850] Gaussian 1 vs 0:
  Original Loss: 0.0009928
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009928 (Pseudo: 0.00%)
[Iter 3860/20000] Loss: 0.0009118 (Best: 0.0004960 @iter3790) ([92m↓7.09%[0m) [0.36% of initial]
[Iter 3860] Gaussian 0 vs 1:
  Original Loss: 0.0008216
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008216 (Pseudo: 0.00%)
[Iter 3860] Gaussian 1 vs 0:
  Original Loss: 0.0008363
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008363 (Pseudo: 0.00%)
[Iter 3870/20000] Loss: 0.0007295 (Best: 0.0004960 @iter3790) ([92m↓19.99%[0m) [0.29% of initial]
[Iter 3870] Gaussian 0 vs 1:
  Original Loss: 0.0006749
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006749 (Pseudo: 0.00%)
[Iter 3870] Gaussian 1 vs 0:
  Original Loss: 0.0006944
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006944 (Pseudo: 0.00%)
[Iter 3880/20000] Loss: 0.0007598 (Best: 0.0004960 @iter3790) ([91m↑4.15%[0m) [0.30% of initial]
[Iter 3880] Gaussian 0 vs 1:
  Original Loss: 0.0007800
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007800 (Pseudo: 0.00%)
[Iter 3880] Gaussian 1 vs 0:
  Original Loss: 0.0008151
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008151 (Pseudo: 0.00%)
[Iter 3890/20000] Loss: 0.0006401 (Best: 0.0004960 @iter3790) ([92m↓15.75%[0m) [0.25% of initial]
[Iter 3890] Gaussian 0 vs 1:
  Original Loss: 0.0006211
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006211 (Pseudo: 0.00%)
[Iter 3890] Gaussian 1 vs 0:
  Original Loss: 0.0006304
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006304 (Pseudo: 0.00%)
Iter:3899, L1 loss=0.0007058, Total loss=0.0006656, Time:20
[Iter 3900/20000] Loss: 0.0006498 (Best: 0.0004960 @iter3790) ([91m↑1.51%[0m) [0.26% of initial]
[Iter 3900] Gaussian 0 vs 1:
  Original Loss: 0.0007110
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007110 (Pseudo: 0.00%)
[Iter 3900] Gaussian 1 vs 0:
  Original Loss: 0.0007462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007462 (Pseudo: 0.00%)
[Iter 3910/20000] Loss: 0.0007706 (Best: 0.0004960 @iter3790) ([91m↑18.60%[0m) [0.31% of initial]
[Iter 3910] Gaussian 0 vs 1:
  Original Loss: 0.0007513
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007513 (Pseudo: 0.00%)
[Iter 3910] Gaussian 1 vs 0:
  Original Loss: 0.0007657
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007657 (Pseudo: 0.00%)
[Iter 3920/20000] Loss: 0.0007837 (Best: 0.0004960 @iter3790) ([91m↑1.69%[0m) [0.31% of initial]
[Iter 3920] Gaussian 0 vs 1:
  Original Loss: 0.0007686
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007686 (Pseudo: 0.00%)
[Iter 3920] Gaussian 1 vs 0:
  Original Loss: 0.0008185
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008185 (Pseudo: 0.00%)
[Iter 3930/20000] Loss: 0.0007636 (Best: 0.0004960 @iter3790) ([92m↓2.57%[0m) [0.30% of initial]
[Iter 3930] Gaussian 0 vs 1:
  Original Loss: 0.0008273
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008273 (Pseudo: 0.00%)
[Iter 3930] Gaussian 1 vs 0:
  Original Loss: 0.0008852
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008852 (Pseudo: 0.00%)
[Iter 3940/20000] Loss: 0.0006308 (Best: 0.0004960 @iter3790) ([92m↓17.39%[0m) [0.25% of initial]
[Iter 3940] Gaussian 0 vs 1:
  Original Loss: 0.0005677
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005677 (Pseudo: 0.00%)
[Iter 3940] Gaussian 1 vs 0:
  Original Loss: 0.0005828
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005828 (Pseudo: 0.00%)
[Iter 3950/20000] Loss: 0.0007082 (Best: 0.0004960 @iter3790) ([91m↑12.27%[0m) [0.28% of initial]
[Iter 3950] Gaussian 0 vs 1:
  Original Loss: 0.0007613
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007613 (Pseudo: 0.00%)
[Iter 3950] Gaussian 1 vs 0:
  Original Loss: 0.0007881
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007881 (Pseudo: 0.00%)
[Iter 3960/20000] Loss: 0.0006954 (Best: 0.0004960 @iter3790) ([92m↓1.80%[0m) [0.28% of initial]
[Iter 3960] Gaussian 0 vs 1:
  Original Loss: 0.0006245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006245 (Pseudo: 0.00%)
[Iter 3960] Gaussian 1 vs 0:
  Original Loss: 0.0006529
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006529 (Pseudo: 0.00%)
[Iter 3970/20000] Loss: 0.0006448 (Best: 0.0004960 @iter3790) ([92m↓7.28%[0m) [0.26% of initial]
[Iter 3970] Gaussian 0 vs 1:
  Original Loss: 0.0006091
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006091 (Pseudo: 0.00%)
[Iter 3970] Gaussian 1 vs 0:
  Original Loss: 0.0006261
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006261 (Pseudo: 0.00%)
[Iter 3980/20000] Loss: 0.0008916 (Best: 0.0004960 @iter3790) ([91m↑38.28%[0m) [0.35% of initial]
[Iter 3980] Gaussian 0 vs 1:
  Original Loss: 0.0011151
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011151 (Pseudo: 0.00%)
[Iter 3980] Gaussian 1 vs 0:
  Original Loss: 0.0011227
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011227 (Pseudo: 0.00%)
[Iter 3990/20000] Loss: 0.0006917 (Best: 0.0004960 @iter3790) ([92m↓22.42%[0m) [0.27% of initial]
[Iter 3990] Gaussian 0 vs 1:
  Original Loss: 0.0007158
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007158 (Pseudo: 0.00%)
[Iter 3990] Gaussian 1 vs 0:
  Original Loss: 0.0007824
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007824 (Pseudo: 0.00%)
Iter:3999, L1 loss=0.0008329, Total loss=0.000744, Time:19
[Iter 4000/20000] Loss: 0.0006823 (Best: 0.0004960 @iter3790) ([92m↓1.37%[0m) [0.27% of initial]
[Iter 4000] Gaussian 0 vs 1:
  Original Loss: 0.0006674
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006674 (Pseudo: 0.00%)
[Iter 4000] Gaussian 1 vs 0:
  Original Loss: 0.0007162
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007162 (Pseudo: 0.00%)
[Iter 4010/20000] Loss: 0.0830499 (Best: 0.0004960 @iter3790) ([91m↑12072.75%[0m) [32.99% of initial]
[Iter 4010] Gaussian 0 vs 1:
  Original Loss: 0.0628251
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0628251 (Pseudo: 0.00%)
[Iter 4010] Gaussian 1 vs 0:
  Original Loss: 0.0669051
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0669051 (Pseudo: 0.00%)
[Iter 4020/20000] Loss: 0.0176885 (Best: 0.0004960 @iter3790) ([92m↓78.70%[0m) [7.03% of initial]
[Iter 4020] Gaussian 0 vs 1:
  Original Loss: 0.0171846
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0171846 (Pseudo: 0.00%)
[Iter 4020] Gaussian 1 vs 0:
  Original Loss: 0.0180868
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0180868 (Pseudo: 0.00%)
[Iter 4030/20000] Loss: 0.0079570 (Best: 0.0004960 @iter3790) ([92m↓55.02%[0m) [3.16% of initial]
[Iter 4030] Gaussian 0 vs 1:
  Original Loss: 0.0067906
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067906 (Pseudo: 0.00%)
[Iter 4030] Gaussian 1 vs 0:
  Original Loss: 0.0072487
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0072487 (Pseudo: 0.00%)
[Iter 4040/20000] Loss: 0.0043407 (Best: 0.0004960 @iter3790) ([92m↓45.45%[0m) [1.72% of initial]
[Iter 4040] Gaussian 0 vs 1:
  Original Loss: 0.0042812
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0042812 (Pseudo: 0.00%)
[Iter 4040] Gaussian 1 vs 0:
  Original Loss: 0.0044462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044462 (Pseudo: 0.00%)
[Iter 4050/20000] Loss: 0.0028533 (Best: 0.0004960 @iter3790) ([92m↓34.27%[0m) [1.13% of initial]
[Iter 4050] Gaussian 0 vs 1:
  Original Loss: 0.0032042
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032042 (Pseudo: 0.00%)
[Iter 4050] Gaussian 1 vs 0:
  Original Loss: 0.0033310
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033310 (Pseudo: 0.00%)
[Iter 4060/20000] Loss: 0.0019675 (Best: 0.0004960 @iter3790) ([92m↓31.04%[0m) [0.78% of initial]
[Iter 4060] Gaussian 0 vs 1:
  Original Loss: 0.0016984
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016984 (Pseudo: 0.00%)
[Iter 4060] Gaussian 1 vs 0:
  Original Loss: 0.0017168
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017168 (Pseudo: 0.00%)
[Iter 4070/20000] Loss: 0.0015495 (Best: 0.0004960 @iter3790) ([92m↓21.25%[0m) [0.62% of initial]
[Iter 4070] Gaussian 0 vs 1:
  Original Loss: 0.0013186
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013186 (Pseudo: 0.00%)
[Iter 4070] Gaussian 1 vs 0:
  Original Loss: 0.0013433
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013433 (Pseudo: 0.00%)
[Iter 4080/20000] Loss: 0.0014502 (Best: 0.0004960 @iter3790) ([92m↓6.41%[0m) [0.58% of initial]
[Iter 4080] Gaussian 0 vs 1:
  Original Loss: 0.0014219
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014219 (Pseudo: 0.00%)
[Iter 4080] Gaussian 1 vs 0:
  Original Loss: 0.0014111
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014111 (Pseudo: 0.00%)
[Iter 4090/20000] Loss: 0.0011408 (Best: 0.0004960 @iter3790) ([92m↓21.33%[0m) [0.45% of initial]
[Iter 4090] Gaussian 0 vs 1:
  Original Loss: 0.0009300
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009300 (Pseudo: 0.00%)
[Iter 4090] Gaussian 1 vs 0:
  Original Loss: 0.0009206
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009206 (Pseudo: 0.00%)
Iter:4099, L1 loss=0.0009519, Total loss=0.0009221, Time:26
[Iter 4100/20000] Loss: 0.0009774 (Best: 0.0004960 @iter3790) ([92m↓14.33%[0m) [0.39% of initial]
[Iter 4100] Gaussian 0 vs 1:
  Original Loss: 0.0008976
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008976 (Pseudo: 0.00%)
[Iter 4100] Gaussian 1 vs 0:
  Original Loss: 0.0009014
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009014 (Pseudo: 0.00%)
[Iter 4110/20000] Loss: 0.0010797 (Best: 0.0004960 @iter3790) ([91m↑10.47%[0m) [0.43% of initial]
[Iter 4110] Gaussian 0 vs 1:
  Original Loss: 0.0010649
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010649 (Pseudo: 0.00%)
[Iter 4110] Gaussian 1 vs 0:
  Original Loss: 0.0010803
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010803 (Pseudo: 0.00%)
[Iter 4120/20000] Loss: 0.0009807 (Best: 0.0004960 @iter3790) ([92m↓9.17%[0m) [0.39% of initial]
[Iter 4120] Gaussian 0 vs 1:
  Original Loss: 0.0008971
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008971 (Pseudo: 0.00%)
[Iter 4120] Gaussian 1 vs 0:
  Original Loss: 0.0009273
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009273 (Pseudo: 0.00%)
[Iter 4130/20000] Loss: 0.0011419 (Best: 0.0004960 @iter3790) ([91m↑16.44%[0m) [0.45% of initial]
[Iter 4130] Gaussian 0 vs 1:
  Original Loss: 0.0011315
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011315 (Pseudo: 0.00%)
[Iter 4130] Gaussian 1 vs 0:
  Original Loss: 0.0011722
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011722 (Pseudo: 0.00%)
[Iter 4140/20000] Loss: 0.0010394 (Best: 0.0004960 @iter3790) ([92m↓8.98%[0m) [0.41% of initial]
[Iter 4140] Gaussian 0 vs 1:
  Original Loss: 0.0009517
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009517 (Pseudo: 0.00%)
[Iter 4140] Gaussian 1 vs 0:
  Original Loss: 0.0009529
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009529 (Pseudo: 0.00%)
[Iter 4150/20000] Loss: 0.0008622 (Best: 0.0004960 @iter3790) ([92m↓17.05%[0m) [0.34% of initial]
[Iter 4150] Gaussian 0 vs 1:
  Original Loss: 0.0009051
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009051 (Pseudo: 0.00%)
[Iter 4150] Gaussian 1 vs 0:
  Original Loss: 0.0009587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009587 (Pseudo: 0.00%)
[Iter 4160/20000] Loss: 0.0009796 (Best: 0.0004960 @iter3790) ([91m↑13.61%[0m) [0.39% of initial]
[Iter 4160] Gaussian 0 vs 1:
  Original Loss: 0.0010697
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010697 (Pseudo: 0.00%)
[Iter 4160] Gaussian 1 vs 0:
  Original Loss: 0.0010509
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010509 (Pseudo: 0.00%)
[Iter 4170/20000] Loss: 0.0008635 (Best: 0.0004960 @iter3790) ([92m↓11.85%[0m) [0.34% of initial]
[Iter 4170] Gaussian 0 vs 1:
  Original Loss: 0.0009053
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009053 (Pseudo: 0.00%)
[Iter 4170] Gaussian 1 vs 0:
  Original Loss: 0.0009302
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009302 (Pseudo: 0.00%)
[Iter 4180/20000] Loss: 0.0008697 (Best: 0.0004960 @iter3790) ([91m↑0.72%[0m) [0.35% of initial]
[Iter 4180] Gaussian 0 vs 1:
  Original Loss: 0.0008946
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008946 (Pseudo: 0.00%)
[Iter 4180] Gaussian 1 vs 0:
  Original Loss: 0.0009215
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009215 (Pseudo: 0.00%)
[Iter 4190/20000] Loss: 0.0008247 (Best: 0.0004960 @iter3790) ([92m↓5.18%[0m) [0.33% of initial]
[Iter 4190] Gaussian 0 vs 1:
  Original Loss: 0.0008724
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008724 (Pseudo: 0.00%)
[Iter 4190] Gaussian 1 vs 0:
  Original Loss: 0.0008940
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008940 (Pseudo: 0.00%)
Iter:4199, L1 loss=0.0007909, Total loss=0.0007209, Time:25
[Iter 4200/20000] Loss: 0.0008706 (Best: 0.0004960 @iter3790) ([91m↑5.57%[0m) [0.35% of initial]
[Iter 4200] Gaussian 0 vs 1:
  Original Loss: 0.0010202
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010202 (Pseudo: 0.00%)
[Iter 4200] Gaussian 1 vs 0:
  Original Loss: 0.0009940
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009940 (Pseudo: 0.00%)
[Iter 4210/20000] Loss: 0.0032216 (Best: 0.0004960 @iter3790) ([91m↑270.04%[0m) [1.28% of initial]
[Iter 4210] Gaussian 0 vs 1:
  Original Loss: 0.0029205
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029205 (Pseudo: 0.00%)
[Iter 4210] Gaussian 1 vs 0:
  Original Loss: 0.0026561
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026561 (Pseudo: 0.00%)
[Iter 4220/20000] Loss: 0.0017691 (Best: 0.0004960 @iter3790) ([92m↓45.09%[0m) [0.70% of initial]
[Iter 4220] Gaussian 0 vs 1:
  Original Loss: 0.0017586
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017586 (Pseudo: 0.00%)
[Iter 4220] Gaussian 1 vs 0:
  Original Loss: 0.0018296
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018296 (Pseudo: 0.00%)
[Iter 4230/20000] Loss: 0.0011901 (Best: 0.0004960 @iter3790) ([92m↓32.73%[0m) [0.47% of initial]
[Iter 4230] Gaussian 0 vs 1:
  Original Loss: 0.0010829
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010829 (Pseudo: 0.00%)
[Iter 4230] Gaussian 1 vs 0:
  Original Loss: 0.0010628
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010628 (Pseudo: 0.00%)
[Iter 4240/20000] Loss: 0.0009523 (Best: 0.0004960 @iter3790) ([92m↓19.99%[0m) [0.38% of initial]
[Iter 4240] Gaussian 0 vs 1:
  Original Loss: 0.0008983
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008983 (Pseudo: 0.00%)
[Iter 4240] Gaussian 1 vs 0:
  Original Loss: 0.0009253
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009253 (Pseudo: 0.00%)
[Iter 4250/20000] Loss: 0.0008985 (Best: 0.0004960 @iter3790) ([92m↓5.64%[0m) [0.36% of initial]
[Iter 4250] Gaussian 0 vs 1:
  Original Loss: 0.0008312
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008312 (Pseudo: 0.00%)
[Iter 4250] Gaussian 1 vs 0:
  Original Loss: 0.0008220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008220 (Pseudo: 0.00%)
[Iter 4260/20000] Loss: 0.0009440 (Best: 0.0004960 @iter3790) ([91m↑5.06%[0m) [0.38% of initial]
[Iter 4260] Gaussian 0 vs 1:
  Original Loss: 0.0009777
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009777 (Pseudo: 0.00%)
[Iter 4260] Gaussian 1 vs 0:
  Original Loss: 0.0010602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010602 (Pseudo: 0.00%)
[Iter 4270/20000] Loss: 0.0008684 (Best: 0.0004960 @iter3790) ([92m↓8.00%[0m) [0.35% of initial]
[Iter 4270] Gaussian 0 vs 1:
  Original Loss: 0.0008144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008144 (Pseudo: 0.00%)
[Iter 4270] Gaussian 1 vs 0:
  Original Loss: 0.0008384
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008384 (Pseudo: 0.00%)
[Iter 4280/20000] Loss: 0.0007053 (Best: 0.0004960 @iter3790) ([92m↓18.78%[0m) [0.28% of initial]
[Iter 4280] Gaussian 0 vs 1:
  Original Loss: 0.0006289
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006289 (Pseudo: 0.00%)
[Iter 4280] Gaussian 1 vs 0:
  Original Loss: 0.0006319
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006319 (Pseudo: 0.00%)
[Iter 4290/20000] Loss: 0.0006906 (Best: 0.0004960 @iter3790) ([92m↓2.09%[0m) [0.27% of initial]
[Iter 4290] Gaussian 0 vs 1:
  Original Loss: 0.0007308
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007308 (Pseudo: 0.00%)
[Iter 4290] Gaussian 1 vs 0:
  Original Loss: 0.0007305
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007305 (Pseudo: 0.00%)
Iter:4299, L1 loss=0.0008367, Total loss=0.0008201, Time:26
[Iter 4300/20000] Loss: 0.0006946 (Best: 0.0004960 @iter3790) ([91m↑0.59%[0m) [0.28% of initial]
[Iter 4300] Gaussian 0 vs 1:
  Original Loss: 0.0005996
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005996 (Pseudo: 0.00%)
[Iter 4300] Gaussian 1 vs 0:
  Original Loss: 0.0006044
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006044 (Pseudo: 0.00%)
[Iter 4310/20000] Loss: 0.0006465 (Best: 0.0004960 @iter3790) ([92m↓6.93%[0m) [0.26% of initial]
[Iter 4310] Gaussian 0 vs 1:
  Original Loss: 0.0005864
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005864 (Pseudo: 0.00%)
[Iter 4310] Gaussian 1 vs 0:
  Original Loss: 0.0005957
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005957 (Pseudo: 0.00%)
[Iter 4320/20000] Loss: 0.0007737 (Best: 0.0004960 @iter3790) ([91m↑19.68%[0m) [0.31% of initial]
[Iter 4320] Gaussian 0 vs 1:
  Original Loss: 0.0007814
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007814 (Pseudo: 0.00%)
[Iter 4320] Gaussian 1 vs 0:
  Original Loss: 0.0008116
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008116 (Pseudo: 0.00%)
[Iter 4330/20000] Loss: 0.0006661 (Best: 0.0004960 @iter3790) ([92m↓13.90%[0m) [0.26% of initial]
[Iter 4330] Gaussian 0 vs 1:
  Original Loss: 0.0006113
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006113 (Pseudo: 0.00%)
[Iter 4330] Gaussian 1 vs 0:
  Original Loss: 0.0006419
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006419 (Pseudo: 0.00%)
[Iter 4340/20000] Loss: 0.0006244 (Best: 0.0004960 @iter3790) ([92m↓6.27%[0m) [0.25% of initial]
[Iter 4340] Gaussian 0 vs 1:
  Original Loss: 0.0005908
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005908 (Pseudo: 0.00%)
[Iter 4340] Gaussian 1 vs 0:
  Original Loss: 0.0006147
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006147 (Pseudo: 0.00%)
[Iter 4350/20000] Loss: 0.0006223 (Best: 0.0004960 @iter3790) ([92m↓0.34%[0m) [0.25% of initial]
[Iter 4350] Gaussian 0 vs 1:
  Original Loss: 0.0006552
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006552 (Pseudo: 0.00%)
[Iter 4350] Gaussian 1 vs 0:
  Original Loss: 0.0006864
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006864 (Pseudo: 0.00%)
[Iter 4360/20000] Loss: 0.0006343 (Best: 0.0004960 @iter3790) ([91m↑1.93%[0m) [0.25% of initial]
[Iter 4360] Gaussian 0 vs 1:
  Original Loss: 0.0006256
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006256 (Pseudo: 0.00%)
[Iter 4360] Gaussian 1 vs 0:
  Original Loss: 0.0006072
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006072 (Pseudo: 0.00%)
[Iter 4370/20000] Loss: 0.0006151 (Best: 0.0004960 @iter3790) ([92m↓3.01%[0m) [0.24% of initial]
[Iter 4370] Gaussian 0 vs 1:
  Original Loss: 0.0006500
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006500 (Pseudo: 0.00%)
[Iter 4370] Gaussian 1 vs 0:
  Original Loss: 0.0006691
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006691 (Pseudo: 0.00%)
[Iter 4380/20000] Loss: 0.0006585 (Best: 0.0004960 @iter3790) ([91m↑7.06%[0m) [0.26% of initial]
[Iter 4380] Gaussian 0 vs 1:
  Original Loss: 0.0006323
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006323 (Pseudo: 0.00%)
[Iter 4380] Gaussian 1 vs 0:
  Original Loss: 0.0006524
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006524 (Pseudo: 0.00%)
[Iter 4390/20000] Loss: 0.0006000 (Best: 0.0004960 @iter3790) ([92m↓8.89%[0m) [0.24% of initial]
[Iter 4390] Gaussian 0 vs 1:
  Original Loss: 0.0005894
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005894 (Pseudo: 0.00%)
[Iter 4390] Gaussian 1 vs 0:
  Original Loss: 0.0005939
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005939 (Pseudo: 0.00%)
Iter:4399, L1 loss=0.0005902, Total loss=0.0005228, Time:25
[Iter 4400/20000] Loss: 0.0005862 (Best: 0.0004960 @iter3790) ([92m↓2.29%[0m) [0.23% of initial]
[Iter 4400] Gaussian 0 vs 1:
  Original Loss: 0.0005987
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005987 (Pseudo: 0.00%)
[Iter 4400] Gaussian 1 vs 0:
  Original Loss: 0.0006082
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006082 (Pseudo: 0.00%)
[Iter 4410/20000] Loss: 0.0028615 (Best: 0.0004960 @iter3790) ([91m↑388.11%[0m) [1.14% of initial]
[Iter 4410] Gaussian 0 vs 1:
  Original Loss: 0.0030272
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030272 (Pseudo: 0.00%)
[Iter 4410] Gaussian 1 vs 0:
  Original Loss: 0.0030397
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030397 (Pseudo: 0.00%)
[Iter 4420/20000] Loss: 0.0014503 (Best: 0.0004960 @iter3790) ([92m↓49.31%[0m) [0.58% of initial]
[Iter 4420] Gaussian 0 vs 1:
  Original Loss: 0.0012164
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012164 (Pseudo: 0.00%)
[Iter 4420] Gaussian 1 vs 0:
  Original Loss: 0.0012238
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012238 (Pseudo: 0.00%)
[Iter 4430/20000] Loss: 0.0010519 (Best: 0.0004960 @iter3790) ([92m↓27.48%[0m) [0.42% of initial]
[Iter 4430] Gaussian 0 vs 1:
  Original Loss: 0.0009973
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009973 (Pseudo: 0.00%)
[Iter 4430] Gaussian 1 vs 0:
  Original Loss: 0.0010715
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010715 (Pseudo: 0.00%)
[Iter 4440/20000] Loss: 0.0008089 (Best: 0.0004960 @iter3790) ([92m↓23.10%[0m) [0.32% of initial]
[Iter 4440] Gaussian 0 vs 1:
  Original Loss: 0.0008589
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008589 (Pseudo: 0.00%)
[Iter 4440] Gaussian 1 vs 0:
  Original Loss: 0.0008996
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008996 (Pseudo: 0.00%)
[Iter 4450/20000] Loss: 0.0006922 (Best: 0.0004960 @iter3790) ([92m↓14.43%[0m) [0.28% of initial]
[Iter 4450] Gaussian 0 vs 1:
  Original Loss: 0.0006378
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006378 (Pseudo: 0.00%)
[Iter 4450] Gaussian 1 vs 0:
  Original Loss: 0.0006858
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006858 (Pseudo: 0.00%)
[Iter 4460/20000] Loss: 0.0006666 (Best: 0.0004960 @iter3790) ([92m↓3.70%[0m) [0.26% of initial]
[Iter 4460] Gaussian 0 vs 1:
  Original Loss: 0.0006955
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006955 (Pseudo: 0.00%)
[Iter 4460] Gaussian 1 vs 0:
  Original Loss: 0.0007196
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007196 (Pseudo: 0.00%)
[Iter 4470/20000] Loss: 0.0007264 (Best: 0.0004960 @iter3790) ([91m↑8.97%[0m) [0.29% of initial]
[Iter 4470] Gaussian 0 vs 1:
  Original Loss: 0.0008609
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008609 (Pseudo: 0.00%)
[Iter 4470] Gaussian 1 vs 0:
  Original Loss: 0.0008449
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008449 (Pseudo: 0.00%)
[Iter 4480/20000] Loss: 0.0006834 (Best: 0.0004960 @iter3790) ([92m↓5.92%[0m) [0.27% of initial]
[Iter 4480] Gaussian 0 vs 1:
  Original Loss: 0.0006641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006641 (Pseudo: 0.00%)
[Iter 4480] Gaussian 1 vs 0:
  Original Loss: 0.0006770
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006770 (Pseudo: 0.00%)
[Iter 4490/20000] Loss: 0.0006792 (Best: 0.0004960 @iter3790) ([92m↓0.62%[0m) [0.27% of initial]
[Iter 4490] Gaussian 0 vs 1:
  Original Loss: 0.0006402
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006402 (Pseudo: 0.00%)
[Iter 4490] Gaussian 1 vs 0:
  Original Loss: 0.0006430
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006430 (Pseudo: 0.00%)
Iter:4499, L1 loss=0.0007677, Total loss=0.0007554, Time:25
[Iter 4500/20000] Loss: 0.0007754 (Best: 0.0004960 @iter3790) ([91m↑14.16%[0m) [0.31% of initial]
[Iter 4500] Gaussian 0 vs 1:
  Original Loss: 0.0008015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008015 (Pseudo: 0.00%)
[Iter 4500] Gaussian 1 vs 0:
  Original Loss: 0.0007658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007658 (Pseudo: 0.00%)
[Iter 4510/20000] Loss: 0.0005671 (Best: 0.0004960 @iter3790) ([92m↓26.86%[0m) [0.23% of initial]
[Iter 4510] Gaussian 0 vs 1:
  Original Loss: 0.0004978
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004978 (Pseudo: 0.00%)
[Iter 4510] Gaussian 1 vs 0:
  Original Loss: 0.0005075
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005075 (Pseudo: 0.00%)
[Iter 4520/20000] Loss: 0.0005902 (Best: 0.0004960 @iter3790) ([91m↑4.07%[0m) [0.23% of initial]
[Iter 4520] Gaussian 0 vs 1:
  Original Loss: 0.0005389
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005389 (Pseudo: 0.00%)
[Iter 4520] Gaussian 1 vs 0:
  Original Loss: 0.0005248
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005248 (Pseudo: 0.00%)
[Iter 4530/20000] Loss: 0.0006506 (Best: 0.0004960 @iter3790) ([91m↑10.23%[0m) [0.26% of initial]
[Iter 4530] Gaussian 0 vs 1:
  Original Loss: 0.0007248
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007248 (Pseudo: 0.00%)
[Iter 4530] Gaussian 1 vs 0:
  Original Loss: 0.0007388
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007388 (Pseudo: 0.00%)
[Iter 4540/20000] Loss: 0.0005850 (Best: 0.0004960 @iter3790) ([92m↓10.09%[0m) [0.23% of initial]
[Iter 4540] Gaussian 0 vs 1:
  Original Loss: 0.0005693
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005693 (Pseudo: 0.00%)
[Iter 4540] Gaussian 1 vs 0:
  Original Loss: 0.0005809
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005809 (Pseudo: 0.00%)
[Iter 4550/20000] Loss: 0.0006076 (Best: 0.0004958 @iter4546) ([91m↑3.87%[0m) [0.24% of initial]
[Iter 4550] Gaussian 0 vs 1:
  Original Loss: 0.0006686
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006686 (Pseudo: 0.00%)
[Iter 4550] Gaussian 1 vs 0:
  Original Loss: 0.0006609
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006609 (Pseudo: 0.00%)
[Iter 4560/20000] Loss: 0.0006277 (Best: 0.0004958 @iter4546) ([91m↑3.31%[0m) [0.25% of initial]
[Iter 4560] Gaussian 0 vs 1:
  Original Loss: 0.0006137
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006137 (Pseudo: 0.00%)
[Iter 4560] Gaussian 1 vs 0:
  Original Loss: 0.0006441
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006441 (Pseudo: 0.00%)
[Iter 4570/20000] Loss: 0.0005608 (Best: 0.0004958 @iter4546) ([92m↓10.65%[0m) [0.22% of initial]
[Iter 4570] Gaussian 0 vs 1:
  Original Loss: 0.0005010
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005010 (Pseudo: 0.00%)
[Iter 4570] Gaussian 1 vs 0:
  Original Loss: 0.0005075
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005075 (Pseudo: 0.00%)
[Iter 4580/20000] Loss: 0.0005579 (Best: 0.0004958 @iter4546) ([92m↓0.53%[0m) [0.22% of initial]
[Iter 4580] Gaussian 0 vs 1:
  Original Loss: 0.0005346
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005346 (Pseudo: 0.00%)
[Iter 4580] Gaussian 1 vs 0:
  Original Loss: 0.0005462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005462 (Pseudo: 0.00%)
[Iter 4590/20000] Loss: 0.0006025 (Best: 0.0004958 @iter4546) ([91m↑8.01%[0m) [0.24% of initial]
[Iter 4590] Gaussian 0 vs 1:
  Original Loss: 0.0006562
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006562 (Pseudo: 0.00%)
[Iter 4590] Gaussian 1 vs 0:
  Original Loss: 0.0007002
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007002 (Pseudo: 0.00%)
Iter:4599, L1 loss=0.0006549, Total loss=0.000591, Time:25
[Iter 4600/20000] Loss: 0.0005809 (Best: 0.0004958 @iter4546) ([92m↓3.59%[0m) [0.23% of initial]
[Iter 4600] Gaussian 0 vs 1:
  Original Loss: 0.0005290
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005290 (Pseudo: 0.00%)
[Iter 4600] Gaussian 1 vs 0:
  Original Loss: 0.0005785
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005785 (Pseudo: 0.00%)
[Iter 4610/20000] Loss: 0.0023845 (Best: 0.0004958 @iter4546) ([91m↑310.48%[0m) [0.95% of initial]
[Iter 4610] Gaussian 0 vs 1:
  Original Loss: 0.0021444
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021444 (Pseudo: 0.00%)
[Iter 4610] Gaussian 1 vs 0:
  Original Loss: 0.0021264
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021264 (Pseudo: 0.00%)
[Iter 4620/20000] Loss: 0.0013882 (Best: 0.0004958 @iter4546) ([92m↓41.78%[0m) [0.55% of initial]
[Iter 4620] Gaussian 0 vs 1:
  Original Loss: 0.0013074
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013074 (Pseudo: 0.00%)
[Iter 4620] Gaussian 1 vs 0:
  Original Loss: 0.0013730
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013730 (Pseudo: 0.00%)
[Iter 4630/20000] Loss: 0.0009955 (Best: 0.0004958 @iter4546) ([92m↓28.29%[0m) [0.40% of initial]
[Iter 4630] Gaussian 0 vs 1:
  Original Loss: 0.0008966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008966 (Pseudo: 0.00%)
[Iter 4630] Gaussian 1 vs 0:
  Original Loss: 0.0008770
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008770 (Pseudo: 0.00%)
[Iter 4640/20000] Loss: 0.0007858 (Best: 0.0004958 @iter4546) ([92m↓21.06%[0m) [0.31% of initial]
[Iter 4640] Gaussian 0 vs 1:
  Original Loss: 0.0007518
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007518 (Pseudo: 0.00%)
[Iter 4640] Gaussian 1 vs 0:
  Original Loss: 0.0007265
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007265 (Pseudo: 0.00%)
[Iter 4650/20000] Loss: 0.0006614 (Best: 0.0004958 @iter4546) ([92m↓15.83%[0m) [0.26% of initial]
[Iter 4650] Gaussian 0 vs 1:
  Original Loss: 0.0006522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006522 (Pseudo: 0.00%)
[Iter 4650] Gaussian 1 vs 0:
  Original Loss: 0.0006806
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006806 (Pseudo: 0.00%)
[Iter 4660/20000] Loss: 0.0005725 (Best: 0.0004958 @iter4546) ([92m↓13.45%[0m) [0.23% of initial]
[Iter 4660] Gaussian 0 vs 1:
  Original Loss: 0.0005074
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005074 (Pseudo: 0.00%)
[Iter 4660] Gaussian 1 vs 0:
  Original Loss: 0.0005063
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005063 (Pseudo: 0.00%)
[Iter 4670/20000] Loss: 0.0005406 (Best: 0.0004958 @iter4546) ([92m↓5.56%[0m) [0.21% of initial]
[Iter 4670] Gaussian 0 vs 1:
  Original Loss: 0.0005083
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005083 (Pseudo: 0.00%)
[Iter 4670] Gaussian 1 vs 0:
  Original Loss: 0.0005127
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005127 (Pseudo: 0.00%)
[Iter 4680/20000] Loss: 0.0005401 (Best: 0.0004723 @iter4672) ([92m↓0.11%[0m) [0.21% of initial]
[Iter 4680] Gaussian 0 vs 1:
  Original Loss: 0.0005231
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005231 (Pseudo: 0.00%)
[Iter 4680] Gaussian 1 vs 0:
  Original Loss: 0.0005377
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005377 (Pseudo: 0.00%)
[Iter 4690/20000] Loss: 0.0005031 (Best: 0.0004613 @iter4681) ([92m↓6.85%[0m) [0.20% of initial]
[Iter 4690] Gaussian 0 vs 1:
  Original Loss: 0.0004639
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004639 (Pseudo: 0.00%)
[Iter 4690] Gaussian 1 vs 0:
  Original Loss: 0.0004734
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004734 (Pseudo: 0.00%)
Iter:4699, L1 loss=0.0006205, Total loss=0.0005877, Time:26
[Iter 4700/20000] Loss: 0.0005593 (Best: 0.0004613 @iter4681) ([91m↑11.19%[0m) [0.22% of initial]
[Iter 4700] Gaussian 0 vs 1:
  Original Loss: 0.0005397
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005397 (Pseudo: 0.00%)
[Iter 4700] Gaussian 1 vs 0:
  Original Loss: 0.0005435
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005435 (Pseudo: 0.00%)
[Iter 4710/20000] Loss: 0.0005006 (Best: 0.0004613 @iter4681) ([92m↓10.50%[0m) [0.20% of initial]
[Iter 4710] Gaussian 0 vs 1:
  Original Loss: 0.0004801
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004801 (Pseudo: 0.00%)
[Iter 4710] Gaussian 1 vs 0:
  Original Loss: 0.0004784
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004784 (Pseudo: 0.00%)
[Iter 4720/20000] Loss: 0.0005441 (Best: 0.0004274 @iter4711) ([91m↑8.68%[0m) [0.22% of initial]
[Iter 4720] Gaussian 0 vs 1:
  Original Loss: 0.0005148
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005148 (Pseudo: 0.00%)
[Iter 4720] Gaussian 1 vs 0:
  Original Loss: 0.0005481
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005481 (Pseudo: 0.00%)
[Iter 4730/20000] Loss: 0.0005439 (Best: 0.0004274 @iter4711) ([92m↓0.02%[0m) [0.22% of initial]
[Iter 4730] Gaussian 0 vs 1:
  Original Loss: 0.0005787
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005787 (Pseudo: 0.00%)
[Iter 4730] Gaussian 1 vs 0:
  Original Loss: 0.0005923
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005923 (Pseudo: 0.00%)
[Iter 4740/20000] Loss: 0.0006026 (Best: 0.0004274 @iter4711) ([91m↑10.79%[0m) [0.24% of initial]
[Iter 4740] Gaussian 0 vs 1:
  Original Loss: 0.0006525
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006525 (Pseudo: 0.00%)
[Iter 4740] Gaussian 1 vs 0:
  Original Loss: 0.0006744
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006744 (Pseudo: 0.00%)
[Iter 4750/20000] Loss: 0.0005872 (Best: 0.0004274 @iter4711) ([92m↓2.57%[0m) [0.23% of initial]
[Iter 4750] Gaussian 0 vs 1:
  Original Loss: 0.0005234
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005234 (Pseudo: 0.00%)
[Iter 4750] Gaussian 1 vs 0:
  Original Loss: 0.0005343
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005343 (Pseudo: 0.00%)
[Iter 4760/20000] Loss: 0.0005171 (Best: 0.0004274 @iter4711) ([92m↓11.94%[0m) [0.21% of initial]
[Iter 4760] Gaussian 0 vs 1:
  Original Loss: 0.0005165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005165 (Pseudo: 0.00%)
[Iter 4760] Gaussian 1 vs 0:
  Original Loss: 0.0005232
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005232 (Pseudo: 0.00%)
[Iter 4770/20000] Loss: 0.0005719 (Best: 0.0004274 @iter4711) ([91m↑10.61%[0m) [0.23% of initial]
[Iter 4770] Gaussian 0 vs 1:
  Original Loss: 0.0006342
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006342 (Pseudo: 0.00%)
[Iter 4770] Gaussian 1 vs 0:
  Original Loss: 0.0006249
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006249 (Pseudo: 0.00%)
[Iter 4780/20000] Loss: 0.0005989 (Best: 0.0004274 @iter4711) ([91m↑4.72%[0m) [0.24% of initial]
[Iter 4780] Gaussian 0 vs 1:
  Original Loss: 0.0006204
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006204 (Pseudo: 0.00%)
[Iter 4780] Gaussian 1 vs 0:
  Original Loss: 0.0006187
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006187 (Pseudo: 0.00%)
[Iter 4790/20000] Loss: 0.0005370 (Best: 0.0004274 @iter4711) ([92m↓10.34%[0m) [0.21% of initial]
[Iter 4790] Gaussian 0 vs 1:
  Original Loss: 0.0005410
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005410 (Pseudo: 0.00%)
[Iter 4790] Gaussian 1 vs 0:
  Original Loss: 0.0005353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005353 (Pseudo: 0.00%)
Iter:4799, L1 loss=0.0006151, Total loss=0.0005367, Time:26
[Iter 4800/20000] Loss: 0.0006011 (Best: 0.0004274 @iter4711) ([91m↑11.93%[0m) [0.24% of initial]
[Iter 4800] Gaussian 0 vs 1:
  Original Loss: 0.0005989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005989 (Pseudo: 0.00%)
[Iter 4800] Gaussian 1 vs 0:
  Original Loss: 0.0006200
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006200 (Pseudo: 0.00%)
[Iter 4810/20000] Loss: 0.0022142 (Best: 0.0004274 @iter4711) ([91m↑268.38%[0m) [0.88% of initial]
[Iter 4810] Gaussian 0 vs 1:
  Original Loss: 0.0019742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019742 (Pseudo: 0.00%)
[Iter 4810] Gaussian 1 vs 0:
  Original Loss: 0.0019924
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019924 (Pseudo: 0.00%)
[Iter 4820/20000] Loss: 0.0014381 (Best: 0.0004274 @iter4711) ([92m↓35.05%[0m) [0.57% of initial]
[Iter 4820] Gaussian 0 vs 1:
  Original Loss: 0.0013612
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013612 (Pseudo: 0.00%)
[Iter 4820] Gaussian 1 vs 0:
  Original Loss: 0.0012232
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012232 (Pseudo: 0.00%)
[Iter 4830/20000] Loss: 0.0010098 (Best: 0.0004274 @iter4711) ([92m↓29.78%[0m) [0.40% of initial]
[Iter 4830] Gaussian 0 vs 1:
  Original Loss: 0.0011656
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011656 (Pseudo: 0.00%)
[Iter 4830] Gaussian 1 vs 0:
  Original Loss: 0.0012024
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012024 (Pseudo: 0.00%)
[Iter 4840/20000] Loss: 0.0007297 (Best: 0.0004274 @iter4711) ([92m↓27.74%[0m) [0.29% of initial]
[Iter 4840] Gaussian 0 vs 1:
  Original Loss: 0.0007068
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007068 (Pseudo: 0.00%)
[Iter 4840] Gaussian 1 vs 0:
  Original Loss: 0.0007453
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007453 (Pseudo: 0.00%)
[Iter 4850/20000] Loss: 0.0005775 (Best: 0.0004274 @iter4711) ([92m↓20.86%[0m) [0.23% of initial]
[Iter 4850] Gaussian 0 vs 1:
  Original Loss: 0.0005885
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005885 (Pseudo: 0.00%)
[Iter 4850] Gaussian 1 vs 0:
  Original Loss: 0.0005878
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005878 (Pseudo: 0.00%)
[Iter 4860/20000] Loss: 0.0005751 (Best: 0.0004274 @iter4711) ([92m↓0.42%[0m) [0.23% of initial]
[Iter 4860] Gaussian 0 vs 1:
  Original Loss: 0.0005606
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005606 (Pseudo: 0.00%)
[Iter 4860] Gaussian 1 vs 0:
  Original Loss: 0.0005522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005522 (Pseudo: 0.00%)
[Iter 4870/20000] Loss: 0.0005010 (Best: 0.0004274 @iter4711) ([92m↓12.89%[0m) [0.20% of initial]
[Iter 4870] Gaussian 0 vs 1:
  Original Loss: 0.0004794
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004794 (Pseudo: 0.00%)
[Iter 4870] Gaussian 1 vs 0:
  Original Loss: 0.0004906
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004906 (Pseudo: 0.00%)
[Iter 4880/20000] Loss: 0.0005299 (Best: 0.0004274 @iter4711) ([91m↑5.78%[0m) [0.21% of initial]
[Iter 4880] Gaussian 0 vs 1:
  Original Loss: 0.0005882
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005882 (Pseudo: 0.00%)
[Iter 4880] Gaussian 1 vs 0:
  Original Loss: 0.0006252
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006252 (Pseudo: 0.00%)
[Iter 4890/20000] Loss: 0.0005025 (Best: 0.0004274 @iter4711) ([92m↓5.18%[0m) [0.20% of initial]
[Iter 4890] Gaussian 0 vs 1:
  Original Loss: 0.0004738
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004738 (Pseudo: 0.00%)
[Iter 4890] Gaussian 1 vs 0:
  Original Loss: 0.0004713
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004713 (Pseudo: 0.00%)
Iter:4899, L1 loss=0.0006285, Total loss=0.0006064, Time:26
[Iter 4900/20000] Loss: 0.0005066 (Best: 0.0004274 @iter4711) ([91m↑0.82%[0m) [0.20% of initial]
[Iter 4900] Gaussian 0 vs 1:
  Original Loss: 0.0004588
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004588 (Pseudo: 0.00%)
[Iter 4900] Gaussian 1 vs 0:
  Original Loss: 0.0004574
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004574 (Pseudo: 0.00%)
[Iter 4910/20000] Loss: 0.0006128 (Best: 0.0004274 @iter4711) ([91m↑20.96%[0m) [0.24% of initial]
[Iter 4910] Gaussian 0 vs 1:
  Original Loss: 0.0006989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006989 (Pseudo: 0.00%)
[Iter 4910] Gaussian 1 vs 0:
  Original Loss: 0.0007132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007132 (Pseudo: 0.00%)
[Iter 4920/20000] Loss: 0.0005358 (Best: 0.0004274 @iter4711) ([92m↓12.57%[0m) [0.21% of initial]
[Iter 4920] Gaussian 0 vs 1:
  Original Loss: 0.0005164
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005164 (Pseudo: 0.00%)
[Iter 4920] Gaussian 1 vs 0:
  Original Loss: 0.0005265
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005265 (Pseudo: 0.00%)
[Iter 4930/20000] Loss: 0.0004932 (Best: 0.0004274 @iter4711) ([92m↓7.94%[0m) [0.20% of initial]
[Iter 4930] Gaussian 0 vs 1:
  Original Loss: 0.0004460
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004460 (Pseudo: 0.00%)
[Iter 4930] Gaussian 1 vs 0:
  Original Loss: 0.0004301
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004301 (Pseudo: 0.00%)
[Iter 4940/20000] Loss: 0.0005007 (Best: 0.0004239 @iter4936) ([91m↑1.51%[0m) [0.20% of initial]
[Iter 4940] Gaussian 0 vs 1:
  Original Loss: 0.0004696
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004696 (Pseudo: 0.00%)
[Iter 4940] Gaussian 1 vs 0:
  Original Loss: 0.0004740
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004740 (Pseudo: 0.00%)
[Iter 4950/20000] Loss: 0.0004395 (Best: 0.0003990 @iter4949) ([92m↓12.22%[0m) [0.17% of initial]
[Iter 4950] Gaussian 0 vs 1:
  Original Loss: 0.0004491
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004491 (Pseudo: 0.00%)
[Iter 4950] Gaussian 1 vs 0:
  Original Loss: 0.0004665
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004665 (Pseudo: 0.00%)
[Iter 4960/20000] Loss: 0.0004730 (Best: 0.0003919 @iter4957) ([91m↑7.61%[0m) [0.19% of initial]
[Iter 4960] Gaussian 0 vs 1:
  Original Loss: 0.0004816
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004816 (Pseudo: 0.00%)
[Iter 4960] Gaussian 1 vs 0:
  Original Loss: 0.0004924
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004924 (Pseudo: 0.00%)
[Iter 4970/20000] Loss: 0.0004916 (Best: 0.0003919 @iter4957) ([91m↑3.95%[0m) [0.20% of initial]
[Iter 4970] Gaussian 0 vs 1:
  Original Loss: 0.0005132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005132 (Pseudo: 0.00%)
[Iter 4970] Gaussian 1 vs 0:
  Original Loss: 0.0005291
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005291 (Pseudo: 0.00%)
[Iter 4980/20000] Loss: 0.0005039 (Best: 0.0003919 @iter4957) ([91m↑2.51%[0m) [0.20% of initial]
[Iter 4980] Gaussian 0 vs 1:
  Original Loss: 0.0004982
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004982 (Pseudo: 0.00%)
[Iter 4980] Gaussian 1 vs 0:
  Original Loss: 0.0005025
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005025 (Pseudo: 0.00%)
[Iter 4990/20000] Loss: 0.0004720 (Best: 0.0003919 @iter4957) ([92m↓6.34%[0m) [0.19% of initial]
[Iter 4990] Gaussian 0 vs 1:
  Original Loss: 0.0004472
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004472 (Pseudo: 0.00%)
[Iter 4990] Gaussian 1 vs 0:
  Original Loss: 0.0004742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004742 (Pseudo: 0.00%)
Iter:4999, L1 loss=0.0005039, Total loss=0.0004511, Time:26
[Iter 5000/20000] Loss: 0.0004504 (Best: 0.0003919 @iter4957) ([92m↓4.57%[0m) [0.18% of initial]
[Iter 5000] Gaussian 0 vs 1:
  Original Loss: 0.0004456
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004456 (Pseudo: 0.00%)
[Iter 5000] Gaussian 1 vs 0:
  Original Loss: 0.0004504
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004504 (Pseudo: 0.00%)
[Iter 5010/20000] Loss: 0.0020000 (Best: 0.0003919 @iter4957) ([91m↑344.01%[0m) [0.79% of initial]
[Iter 5010] Gaussian 0 vs 1:
  Original Loss: 0.0017774
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017774 (Pseudo: 0.00%)
[Iter 5010] Gaussian 1 vs 0:
  Original Loss: 0.0018643
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018643 (Pseudo: 0.00%)
[Iter 5020/20000] Loss: 0.0012416 (Best: 0.0003919 @iter4957) ([92m↓37.92%[0m) [0.49% of initial]
[Iter 5020] Gaussian 0 vs 1:
  Original Loss: 0.0010813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010813 (Pseudo: 0.00%)
[Iter 5020] Gaussian 1 vs 0:
  Original Loss: 0.0011327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011327 (Pseudo: 0.00%)
[Iter 5030/20000] Loss: 0.0007899 (Best: 0.0003919 @iter4957) ([92m↓36.38%[0m) [0.31% of initial]
[Iter 5030] Gaussian 0 vs 1:
  Original Loss: 0.0007408
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007408 (Pseudo: 0.00%)
[Iter 5030] Gaussian 1 vs 0:
  Original Loss: 0.0007635
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007635 (Pseudo: 0.00%)
[Iter 5040/20000] Loss: 0.0007624 (Best: 0.0003919 @iter4957) ([92m↓3.49%[0m) [0.30% of initial]
[Iter 5040] Gaussian 0 vs 1:
  Original Loss: 0.0009047
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009047 (Pseudo: 0.00%)
[Iter 5040] Gaussian 1 vs 0:
  Original Loss: 0.0010128
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010128 (Pseudo: 0.00%)
[Iter 5050/20000] Loss: 0.0006661 (Best: 0.0003919 @iter4957) ([92m↓12.62%[0m) [0.26% of initial]
[Iter 5050] Gaussian 0 vs 1:
  Original Loss: 0.0006240
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006240 (Pseudo: 0.00%)
[Iter 5050] Gaussian 1 vs 0:
  Original Loss: 0.0006461
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006461 (Pseudo: 0.00%)
[Iter 5060/20000] Loss: 0.0005100 (Best: 0.0003919 @iter4957) ([92m↓23.43%[0m) [0.20% of initial]
[Iter 5060] Gaussian 0 vs 1:
  Original Loss: 0.0004923
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004923 (Pseudo: 0.00%)
[Iter 5060] Gaussian 1 vs 0:
  Original Loss: 0.0004990
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004990 (Pseudo: 0.00%)
[Iter 5070/20000] Loss: 0.0005726 (Best: 0.0003919 @iter4957) ([91m↑12.28%[0m) [0.23% of initial]
[Iter 5070] Gaussian 0 vs 1:
  Original Loss: 0.0005774
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005774 (Pseudo: 0.00%)
[Iter 5070] Gaussian 1 vs 0:
  Original Loss: 0.0006201
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006201 (Pseudo: 0.00%)
[Iter 5080/20000] Loss: 0.0004795 (Best: 0.0003919 @iter4957) ([92m↓16.27%[0m) [0.19% of initial]
[Iter 5080] Gaussian 0 vs 1:
  Original Loss: 0.0004328
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004328 (Pseudo: 0.00%)
[Iter 5080] Gaussian 1 vs 0:
  Original Loss: 0.0004625
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004625 (Pseudo: 0.00%)
[Iter 5090/20000] Loss: 0.0005054 (Best: 0.0003919 @iter4957) ([91m↑5.39%[0m) [0.20% of initial]
[Iter 5090] Gaussian 0 vs 1:
  Original Loss: 0.0004937
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004937 (Pseudo: 0.00%)
[Iter 5090] Gaussian 1 vs 0:
  Original Loss: 0.0005162
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005162 (Pseudo: 0.00%)
Iter:5099, L1 loss=0.000589, Total loss=0.0005209, Time:26
[Iter 5100/20000] Loss: 0.0005343 (Best: 0.0003919 @iter4957) ([91m↑5.73%[0m) [0.21% of initial]
[Iter 5100] Gaussian 0 vs 1:
  Original Loss: 0.0005605
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005605 (Pseudo: 0.00%)
[Iter 5100] Gaussian 1 vs 0:
  Original Loss: 0.0005813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005813 (Pseudo: 0.00%)
[Iter 5110/20000] Loss: 0.0005233 (Best: 0.0003919 @iter4957) ([92m↓2.05%[0m) [0.21% of initial]
[Iter 5110] Gaussian 0 vs 1:
  Original Loss: 0.0005190
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005190 (Pseudo: 0.00%)
[Iter 5110] Gaussian 1 vs 0:
  Original Loss: 0.0005381
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005381 (Pseudo: 0.00%)
[Iter 5120/20000] Loss: 0.0005067 (Best: 0.0003919 @iter4957) ([92m↓3.18%[0m) [0.20% of initial]
[Iter 5120] Gaussian 0 vs 1:
  Original Loss: 0.0004883
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004883 (Pseudo: 0.00%)
[Iter 5120] Gaussian 1 vs 0:
  Original Loss: 0.0004883
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004883 (Pseudo: 0.00%)
[Iter 5130/20000] Loss: 0.0005346 (Best: 0.0003919 @iter4957) ([91m↑5.52%[0m) [0.21% of initial]
[Iter 5130] Gaussian 0 vs 1:
  Original Loss: 0.0005585
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005585 (Pseudo: 0.00%)
[Iter 5130] Gaussian 1 vs 0:
  Original Loss: 0.0005183
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005183 (Pseudo: 0.00%)
[Iter 5140/20000] Loss: 0.0004594 (Best: 0.0003919 @iter4957) ([92m↓14.07%[0m) [0.18% of initial]
[Iter 5140] Gaussian 0 vs 1:
  Original Loss: 0.0004250
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004250 (Pseudo: 0.00%)
[Iter 5140] Gaussian 1 vs 0:
  Original Loss: 0.0004314
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004314 (Pseudo: 0.00%)
[Iter 5150/20000] Loss: 0.0004578 (Best: 0.0003919 @iter4957) ([92m↓0.37%[0m) [0.18% of initial]
[Iter 5150] Gaussian 0 vs 1:
  Original Loss: 0.0004697
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004697 (Pseudo: 0.00%)
[Iter 5150] Gaussian 1 vs 0:
  Original Loss: 0.0004655
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004655 (Pseudo: 0.00%)
[Iter 5160/20000] Loss: 0.0004514 (Best: 0.0003852 @iter5158) ([92m↓1.39%[0m) [0.18% of initial]
[Iter 5160] Gaussian 0 vs 1:
  Original Loss: 0.0005203
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005203 (Pseudo: 0.00%)
[Iter 5160] Gaussian 1 vs 0:
  Original Loss: 0.0005114
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005114 (Pseudo: 0.00%)
[Iter 5170/20000] Loss: 0.0004985 (Best: 0.0003852 @iter5158) ([91m↑10.44%[0m) [0.20% of initial]
[Iter 5170] Gaussian 0 vs 1:
  Original Loss: 0.0004631
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004631 (Pseudo: 0.00%)
[Iter 5170] Gaussian 1 vs 0:
  Original Loss: 0.0004651
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004651 (Pseudo: 0.00%)
[Iter 5180/20000] Loss: 0.0004599 (Best: 0.0003852 @iter5158) ([92m↓7.74%[0m) [0.18% of initial]
[Iter 5180] Gaussian 0 vs 1:
  Original Loss: 0.0004285
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004285 (Pseudo: 0.00%)
[Iter 5180] Gaussian 1 vs 0:
  Original Loss: 0.0004279
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004279 (Pseudo: 0.00%)
[Iter 5190/20000] Loss: 0.0004641 (Best: 0.0003852 @iter5158) ([91m↑0.91%[0m) [0.18% of initial]
[Iter 5190] Gaussian 0 vs 1:
  Original Loss: 0.0004652
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004652 (Pseudo: 0.00%)
[Iter 5190] Gaussian 1 vs 0:
  Original Loss: 0.0004603
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004603 (Pseudo: 0.00%)
Iter:5199, L1 loss=0.0005453, Total loss=0.0004728, Time:26
[Iter 5200/20000] Loss: 0.0004447 (Best: 0.0003852 @iter5158) ([92m↓4.19%[0m) [0.18% of initial]
[Iter 5200] Gaussian 0 vs 1:
  Original Loss: 0.0004282
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004282 (Pseudo: 0.00%)
[Iter 5200] Gaussian 1 vs 0:
  Original Loss: 0.0004426
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004426 (Pseudo: 0.00%)
[Iter 5210/20000] Loss: 0.0020439 (Best: 0.0003852 @iter5158) ([91m↑359.63%[0m) [0.81% of initial]
[Iter 5210] Gaussian 0 vs 1:
  Original Loss: 0.0019072
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019072 (Pseudo: 0.00%)
[Iter 5210] Gaussian 1 vs 0:
  Original Loss: 0.0017368
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017368 (Pseudo: 0.00%)
[Iter 5220/20000] Loss: 0.0010863 (Best: 0.0003852 @iter5158) ([92m↓46.85%[0m) [0.43% of initial]
[Iter 5220] Gaussian 0 vs 1:
  Original Loss: 0.0009518
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009518 (Pseudo: 0.00%)
[Iter 5220] Gaussian 1 vs 0:
  Original Loss: 0.0009353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009353 (Pseudo: 0.00%)
[Iter 5230/20000] Loss: 0.0007540 (Best: 0.0003852 @iter5158) ([92m↓30.60%[0m) [0.30% of initial]
[Iter 5230] Gaussian 0 vs 1:
  Original Loss: 0.0006424
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006424 (Pseudo: 0.00%)
[Iter 5230] Gaussian 1 vs 0:
  Original Loss: 0.0006366
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006366 (Pseudo: 0.00%)
[Iter 5240/20000] Loss: 0.0005946 (Best: 0.0003852 @iter5158) ([92m↓21.13%[0m) [0.24% of initial]
[Iter 5240] Gaussian 0 vs 1:
  Original Loss: 0.0005735
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005735 (Pseudo: 0.00%)
[Iter 5240] Gaussian 1 vs 0:
  Original Loss: 0.0005707
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005707 (Pseudo: 0.00%)
[Iter 5250/20000] Loss: 0.0007194 (Best: 0.0003852 @iter5158) ([91m↑20.97%[0m) [0.29% of initial]
[Iter 5250] Gaussian 0 vs 1:
  Original Loss: 0.0008054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008054 (Pseudo: 0.00%)
[Iter 5250] Gaussian 1 vs 0:
  Original Loss: 0.0007992
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007992 (Pseudo: 0.00%)
[Iter 5260/20000] Loss: 0.0005719 (Best: 0.0003852 @iter5158) ([92m↓20.50%[0m) [0.23% of initial]
[Iter 5260] Gaussian 0 vs 1:
  Original Loss: 0.0005432
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005432 (Pseudo: 0.00%)
[Iter 5260] Gaussian 1 vs 0:
  Original Loss: 0.0005679
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005679 (Pseudo: 0.00%)
[Iter 5270/20000] Loss: 0.0005244 (Best: 0.0003852 @iter5158) ([92m↓8.30%[0m) [0.21% of initial]
[Iter 5270] Gaussian 0 vs 1:
  Original Loss: 0.0004773
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004773 (Pseudo: 0.00%)
[Iter 5270] Gaussian 1 vs 0:
  Original Loss: 0.0004808
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004808 (Pseudo: 0.00%)
[Iter 5280/20000] Loss: 0.0005607 (Best: 0.0003852 @iter5158) ([91m↑6.91%[0m) [0.22% of initial]
[Iter 5280] Gaussian 0 vs 1:
  Original Loss: 0.0006231
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006231 (Pseudo: 0.00%)
[Iter 5280] Gaussian 1 vs 0:
  Original Loss: 0.0006089
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006089 (Pseudo: 0.00%)
[Iter 5290/20000] Loss: 0.0005058 (Best: 0.0003852 @iter5158) ([92m↓9.79%[0m) [0.20% of initial]
[Iter 5290] Gaussian 0 vs 1:
  Original Loss: 0.0004949
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004949 (Pseudo: 0.00%)
[Iter 5290] Gaussian 1 vs 0:
  Original Loss: 0.0005125
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005125 (Pseudo: 0.00%)
Iter:5299, L1 loss=0.0006141, Total loss=0.000543, Time:27
[Iter 5300/20000] Loss: 0.0005946 (Best: 0.0003852 @iter5158) ([91m↑17.57%[0m) [0.24% of initial]
[Iter 5300] Gaussian 0 vs 1:
  Original Loss: 0.0005704
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005704 (Pseudo: 0.00%)
[Iter 5300] Gaussian 1 vs 0:
  Original Loss: 0.0005799
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005799 (Pseudo: 0.00%)
[Iter 5310/20000] Loss: 0.0005659 (Best: 0.0003852 @iter5158) ([92m↓4.83%[0m) [0.22% of initial]
[Iter 5310] Gaussian 0 vs 1:
  Original Loss: 0.0006307
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006307 (Pseudo: 0.00%)
[Iter 5310] Gaussian 1 vs 0:
  Original Loss: 0.0006211
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006211 (Pseudo: 0.00%)
[Iter 5320/20000] Loss: 0.0005058 (Best: 0.0003852 @iter5158) ([92m↓10.61%[0m) [0.20% of initial]
[Iter 5320] Gaussian 0 vs 1:
  Original Loss: 0.0005329
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005329 (Pseudo: 0.00%)
[Iter 5320] Gaussian 1 vs 0:
  Original Loss: 0.0005365
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005365 (Pseudo: 0.00%)
[Iter 5330/20000] Loss: 0.0004408 (Best: 0.0003852 @iter5158) ([92m↓12.86%[0m) [0.18% of initial]
[Iter 5330] Gaussian 0 vs 1:
  Original Loss: 0.0004347
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004347 (Pseudo: 0.00%)
[Iter 5330] Gaussian 1 vs 0:
  Original Loss: 0.0004311
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004311 (Pseudo: 0.00%)
[Iter 5340/20000] Loss: 0.0004592 (Best: 0.0003852 @iter5158) ([91m↑4.17%[0m) [0.18% of initial]
[Iter 5340] Gaussian 0 vs 1:
  Original Loss: 0.0004720
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004720 (Pseudo: 0.00%)
[Iter 5340] Gaussian 1 vs 0:
  Original Loss: 0.0004675
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004675 (Pseudo: 0.00%)
[Iter 5350/20000] Loss: 0.0005032 (Best: 0.0003743 @iter5344) ([91m↑9.60%[0m) [0.20% of initial]
[Iter 5350] Gaussian 0 vs 1:
  Original Loss: 0.0005089
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005089 (Pseudo: 0.00%)
[Iter 5350] Gaussian 1 vs 0:
  Original Loss: 0.0004905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004905 (Pseudo: 0.00%)
[Iter 5360/20000] Loss: 0.0004787 (Best: 0.0003743 @iter5344) ([92m↓4.88%[0m) [0.19% of initial]
[Iter 5360] Gaussian 0 vs 1:
  Original Loss: 0.0005092
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005092 (Pseudo: 0.00%)
[Iter 5360] Gaussian 1 vs 0:
  Original Loss: 0.0005004
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005004 (Pseudo: 0.00%)
[Iter 5370/20000] Loss: 0.0004925 (Best: 0.0003743 @iter5344) ([91m↑2.89%[0m) [0.20% of initial]
[Iter 5370] Gaussian 0 vs 1:
  Original Loss: 0.0005438
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005438 (Pseudo: 0.00%)
[Iter 5370] Gaussian 1 vs 0:
  Original Loss: 0.0005461
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005461 (Pseudo: 0.00%)
[Iter 5380/20000] Loss: 0.0004930 (Best: 0.0003743 @iter5344) ([91m↑0.10%[0m) [0.20% of initial]
[Iter 5380] Gaussian 0 vs 1:
  Original Loss: 0.0004687
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004687 (Pseudo: 0.00%)
[Iter 5380] Gaussian 1 vs 0:
  Original Loss: 0.0004647
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004647 (Pseudo: 0.00%)
[Iter 5390/20000] Loss: 0.0005183 (Best: 0.0003743 @iter5344) ([91m↑5.13%[0m) [0.21% of initial]
[Iter 5390] Gaussian 0 vs 1:
  Original Loss: 0.0005179
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005179 (Pseudo: 0.00%)
[Iter 5390] Gaussian 1 vs 0:
  Original Loss: 0.0005277
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005277 (Pseudo: 0.00%)
Iter:5399, L1 loss=0.0004904, Total loss=0.0004312, Time:27
[Iter 5400/20000] Loss: 0.0004932 (Best: 0.0003743 @iter5344) ([92m↓4.83%[0m) [0.20% of initial]
[Iter 5400] Gaussian 0 vs 1:
  Original Loss: 0.0005586
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005586 (Pseudo: 0.00%)
[Iter 5400] Gaussian 1 vs 0:
  Original Loss: 0.0005494
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005494 (Pseudo: 0.00%)
[Iter 5410/20000] Loss: 0.0019107 (Best: 0.0003743 @iter5344) ([91m↑287.38%[0m) [0.76% of initial]
[Iter 5410] Gaussian 0 vs 1:
  Original Loss: 0.0017142
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017142 (Pseudo: 0.00%)
[Iter 5410] Gaussian 1 vs 0:
  Original Loss: 0.0016123
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016123 (Pseudo: 0.00%)
[Iter 5420/20000] Loss: 0.0013418 (Best: 0.0003743 @iter5344) ([92m↓29.78%[0m) [0.53% of initial]
[Iter 5420] Gaussian 0 vs 1:
  Original Loss: 0.0012715
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012715 (Pseudo: 0.00%)
[Iter 5420] Gaussian 1 vs 0:
  Original Loss: 0.0012866
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012866 (Pseudo: 0.00%)
[Iter 5430/20000] Loss: 0.0007748 (Best: 0.0003743 @iter5344) ([92m↓42.26%[0m) [0.31% of initial]
[Iter 5430] Gaussian 0 vs 1:
  Original Loss: 0.0007303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007303 (Pseudo: 0.00%)
[Iter 5430] Gaussian 1 vs 0:
  Original Loss: 0.0007303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007303 (Pseudo: 0.00%)
[Iter 5440/20000] Loss: 0.0006721 (Best: 0.0003743 @iter5344) ([92m↓13.26%[0m) [0.27% of initial]
[Iter 5440] Gaussian 0 vs 1:
  Original Loss: 0.0006718
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006718 (Pseudo: 0.00%)
[Iter 5440] Gaussian 1 vs 0:
  Original Loss: 0.0006512
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006512 (Pseudo: 0.00%)
[Iter 5450/20000] Loss: 0.0005434 (Best: 0.0003743 @iter5344) ([92m↓19.14%[0m) [0.22% of initial]
[Iter 5450] Gaussian 0 vs 1:
  Original Loss: 0.0005125
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005125 (Pseudo: 0.00%)
[Iter 5450] Gaussian 1 vs 0:
  Original Loss: 0.0005144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005144 (Pseudo: 0.00%)
[Iter 5460/20000] Loss: 0.0005624 (Best: 0.0003743 @iter5344) ([91m↑3.48%[0m) [0.22% of initial]
[Iter 5460] Gaussian 0 vs 1:
  Original Loss: 0.0006061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006061 (Pseudo: 0.00%)
[Iter 5460] Gaussian 1 vs 0:
  Original Loss: 0.0005823
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005823 (Pseudo: 0.00%)
[Iter 5470/20000] Loss: 0.0004613 (Best: 0.0003743 @iter5344) ([92m↓17.98%[0m) [0.18% of initial]
[Iter 5470] Gaussian 0 vs 1:
  Original Loss: 0.0004414
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004414 (Pseudo: 0.00%)
[Iter 5470] Gaussian 1 vs 0:
  Original Loss: 0.0004537
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004537 (Pseudo: 0.00%)
[Iter 5480/20000] Loss: 0.0004350 (Best: 0.0003685 @iter5476) ([92m↓5.69%[0m) [0.17% of initial]
[Iter 5480] Gaussian 0 vs 1:
  Original Loss: 0.0004090
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004090 (Pseudo: 0.00%)
[Iter 5480] Gaussian 1 vs 0:
  Original Loss: 0.0004115
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004115 (Pseudo: 0.00%)
[Iter 5490/20000] Loss: 0.0004563 (Best: 0.0003685 @iter5476) ([91m↑4.88%[0m) [0.18% of initial]
[Iter 5490] Gaussian 0 vs 1:
  Original Loss: 0.0004577
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004577 (Pseudo: 0.00%)
[Iter 5490] Gaussian 1 vs 0:
  Original Loss: 0.0004633
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004633 (Pseudo: 0.00%)
Iter:5499, L1 loss=0.0005348, Total loss=0.0004745, Time:27
[Iter 5500/20000] Loss: 0.0004167 (Best: 0.0003685 @iter5476) ([92m↓8.67%[0m) [0.17% of initial]
[Iter 5500] Gaussian 0 vs 1:
  Original Loss: 0.0003825
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0003825 (Pseudo: 0.00%)
[Iter 5500] Gaussian 1 vs 0:
  Original Loss: 0.0003892
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0003892 (Pseudo: 0.00%)
[Iter 5510/20000] Loss: 0.0004362 (Best: 0.0003685 @iter5476) ([91m↑4.68%[0m) [0.17% of initial]
[Iter 5510] Gaussian 0 vs 1:
  Original Loss: 0.0004132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004132 (Pseudo: 0.00%)
[Iter 5510] Gaussian 1 vs 0:
  Original Loss: 0.0004299
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004299 (Pseudo: 0.00%)
[Iter 5520/20000] Loss: 0.0004078 (Best: 0.0003685 @iter5476) ([92m↓6.52%[0m) [0.16% of initial]
[Iter 5520] Gaussian 0 vs 1:
  Original Loss: 0.0003905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0003905 (Pseudo: 0.00%)
[Iter 5520] Gaussian 1 vs 0:
  Original Loss: 0.0004030
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004030 (Pseudo: 0.00%)
[Iter 5530/20000] Loss: 0.0004523 (Best: 0.0003577 @iter5521) ([91m↑10.91%[0m) [0.18% of initial]
[Iter 5530] Gaussian 0 vs 1:
  Original Loss: 0.0004165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004165 (Pseudo: 0.00%)
[Iter 5530] Gaussian 1 vs 0:
  Original Loss: 0.0004367
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004367 (Pseudo: 0.00%)
[Iter 5540/20000] Loss: 0.0004664 (Best: 0.0003577 @iter5521) ([91m↑3.11%[0m) [0.19% of initial]
[Iter 5540] Gaussian 0 vs 1:
  Original Loss: 0.0004669
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004669 (Pseudo: 0.00%)
[Iter 5540] Gaussian 1 vs 0:
  Original Loss: 0.0004832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004832 (Pseudo: 0.00%)
[Iter 5550/20000] Loss: 0.0004727 (Best: 0.0003577 @iter5521) ([91m↑1.36%[0m) [0.19% of initial]
[Iter 5550] Gaussian 0 vs 1:
  Original Loss: 0.0004533
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004533 (Pseudo: 0.00%)
[Iter 5550] Gaussian 1 vs 0:
  Original Loss: 0.0004633
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004633 (Pseudo: 0.00%)
[Iter 5560/20000] Loss: 0.0004371 (Best: 0.0003577 @iter5521) ([92m↓7.54%[0m) [0.17% of initial]
[Iter 5560] Gaussian 0 vs 1:
  Original Loss: 0.0004031
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004031 (Pseudo: 0.00%)
[Iter 5560] Gaussian 1 vs 0:
  Original Loss: 0.0004050
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004050 (Pseudo: 0.00%)
[Iter 5570/20000] Loss: 0.0004412 (Best: 0.0003577 @iter5521) ([91m↑0.95%[0m) [0.18% of initial]
[Iter 5570] Gaussian 0 vs 1:
  Original Loss: 0.0004672
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004672 (Pseudo: 0.00%)
[Iter 5570] Gaussian 1 vs 0:
  Original Loss: 0.0004568
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004568 (Pseudo: 0.00%)
[Iter 5580/20000] Loss: 0.0005043 (Best: 0.0003577 @iter5521) ([91m↑14.31%[0m) [0.20% of initial]
[Iter 5580] Gaussian 0 vs 1:
  Original Loss: 0.0004983
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004983 (Pseudo: 0.00%)
[Iter 5580] Gaussian 1 vs 0:
  Original Loss: 0.0005098
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005098 (Pseudo: 0.00%)
[Iter 5590/20000] Loss: 0.0005611 (Best: 0.0003577 @iter5521) ([91m↑11.25%[0m) [0.22% of initial]
[Iter 5590] Gaussian 0 vs 1:
  Original Loss: 0.0005269
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005269 (Pseudo: 0.00%)
[Iter 5590] Gaussian 1 vs 0:
  Original Loss: 0.0005320
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005320 (Pseudo: 0.00%)
Iter:5599, L1 loss=0.0004741, Total loss=0.0004166, Time:27
[Iter 5600/20000] Loss: 0.0004301 (Best: 0.0003577 @iter5521) ([92m↓23.34%[0m) [0.17% of initial]
[Iter 5600] Gaussian 0 vs 1:
  Original Loss: 0.0004087
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004087 (Pseudo: 0.00%)
[Iter 5600] Gaussian 1 vs 0:
  Original Loss: 0.0004172
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004172 (Pseudo: 0.00%)
[Iter 5610/20000] Loss: 0.0022138 (Best: 0.0003577 @iter5521) ([91m↑414.70%[0m) [0.88% of initial]
[Iter 5610] Gaussian 0 vs 1:
  Original Loss: 0.0018313
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018313 (Pseudo: 0.00%)
[Iter 5610] Gaussian 1 vs 0:
  Original Loss: 0.0018145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018145 (Pseudo: 0.00%)
[Iter 5620/20000] Loss: 0.0010737 (Best: 0.0003577 @iter5521) ([92m↓51.50%[0m) [0.43% of initial]
[Iter 5620] Gaussian 0 vs 1:
  Original Loss: 0.0009233
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009233 (Pseudo: 0.00%)
[Iter 5620] Gaussian 1 vs 0:
  Original Loss: 0.0009362
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009362 (Pseudo: 0.00%)
[Iter 5630/20000] Loss: 0.0008146 (Best: 0.0003577 @iter5521) ([92m↓24.13%[0m) [0.32% of initial]
[Iter 5630] Gaussian 0 vs 1:
  Original Loss: 0.0007819
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007819 (Pseudo: 0.00%)
[Iter 5630] Gaussian 1 vs 0:
  Original Loss: 0.0007545
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007545 (Pseudo: 0.00%)
[Iter 5640/20000] Loss: 0.0006714 (Best: 0.0003577 @iter5521) ([92m↓17.58%[0m) [0.27% of initial]
[Iter 5640] Gaussian 0 vs 1:
  Original Loss: 0.0006103
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006103 (Pseudo: 0.00%)
[Iter 5640] Gaussian 1 vs 0:
  Original Loss: 0.0005753
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005753 (Pseudo: 0.00%)
[Iter 5650/20000] Loss: 0.0005509 (Best: 0.0003577 @iter5521) ([92m↓17.96%[0m) [0.22% of initial]
[Iter 5650] Gaussian 0 vs 1:
  Original Loss: 0.0005030
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005030 (Pseudo: 0.00%)
[Iter 5650] Gaussian 1 vs 0:
  Original Loss: 0.0004926
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004926 (Pseudo: 0.00%)
[Iter 5660/20000] Loss: 0.0005126 (Best: 0.0003577 @iter5521) ([92m↓6.95%[0m) [0.20% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 10] Gaussian 0 vs 1:
  Original Loss: 0.2126908
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.020)
  Ratio to Original: 0.00%
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 10] Gaussian 1 vs 0:
  Original Loss: 0.2126908
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.020)
  Ratio to Original: 0.00%
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 20] Gaussian 0 vs 1:
  Original Loss: 0.1693031
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.040)
  Ratio to Original: 0.00%
  Total Loss: 0.1693031 (Pseudo: 0.00%)
[Iter 20] Gaussian 1 vs 0:
  Original Loss: 0.1693034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.040)
  Ratio to Original: 0.00%
  Total Loss: 0.1693034 (Pseudo: 0.00%)
[Iter 30/20000] Loss: 0.1374909 (Best: 0.1327888 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 30] Gaussian 0 vs 1:
  Original Loss: 0.1327888
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.060)
  Ratio to Original: 0.00%
  Total Loss: 0.1327888 (Pseudo: 0.00%)
[Iter 30] Gaussian 1 vs 0:
  Original Loss: 0.1327883
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.060)
  Ratio to Original: 0.00%
  Total Loss: 0.1327883 (Pseudo: 0.00%)
[Iter 40/20000] Loss: 0.1123920 (Best: 0.1098377 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 40] Gaussian 0 vs 1:
  Original Loss: 0.1098377
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.080)
  Ratio to Original: 0.00%
  Total Loss: 0.1098377 (Pseudo: 0.00%)
[Iter 40] Gaussian 1 vs 0:
  Original Loss: 0.1098365
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.080)
  Ratio to Original: 0.00%
  Total Loss: 0.1098365 (Pseudo: 0.00%)
[Iter 50/20000] Loss: 0.0993453 (Best: 0.0965455 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 50] Gaussian 0 vs 1:
  Original Loss: 0.0994871
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.100)
  Ratio to Original: 0.00%
  Total Loss: 0.0994871 (Pseudo: 0.00%)
[Iter 50] Gaussian 1 vs 0:
  Original Loss: 0.0994848
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.100)
  Ratio to Original: 0.00%
  Total Loss: 0.0994848 (Pseudo: 0.00%)
[Iter 60/20000] Loss: 0.0936756 (Best: 0.0908531 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 60] Gaussian 0 vs 1:
  Original Loss: 0.0940257
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.120)
  Ratio to Original: 0.00%
  Total Loss: 0.0940257 (Pseudo: 0.00%)
[Iter 60] Gaussian 1 vs 0:
  Original Loss: 0.0940318
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.120)
  Ratio to Original: 0.00%
  Total Loss: 0.0940318 (Pseudo: 0.00%)
[Iter 70/20000] Loss: 0.0884526 (Best: 0.0869432 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 70] Gaussian 0 vs 1:
  Original Loss: 0.0869432
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.140)
  Ratio to Original: 0.00%
  Total Loss: 0.0869432 (Pseudo: 0.00%)
[Iter 70] Gaussian 1 vs 0:
  Original Loss: 0.0869452
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.140)
  Ratio to Original: 0.00%
  Total Loss: 0.0869452 (Pseudo: 0.00%)
[Iter 80/20000] Loss: 0.0851848 (Best: 0.0830971 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 80] Gaussian 0 vs 1:
  Original Loss: 0.0830971
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.160)
  Ratio to Original: 0.00%
  Total Loss: 0.0830971 (Pseudo: 0.00%)
[Iter 80] Gaussian 1 vs 0:
  Original Loss: 0.0831055
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.160)
  Ratio to Original: 0.00%
  Total Loss: 0.0831055 (Pseudo: 0.00%)
[Iter 90/20000] Loss: 0.0824174 (Best: 0.0801601 @iter88) ([92m↓3.25%[0m) [32.74% of initial]
[Iter 90] Gaussian 0 vs 1:
  Original Loss: 0.0823502
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.180)
  Ratio to Original: 0.00%
  Total Loss: 0.0823502 (Pseudo: 0.00%)
[Iter 90] Gaussian 1 vs 0:
  Original Loss: 0.0823528
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.180)
  Ratio to Original: 0.00%
  Total Loss: 0.0823528 (Pseudo: 0.00%)
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:15
[Iter 100/20000] Loss: 0.0786689 (Best: 0.0766193 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 100] Gaussian 0 vs 1:
  Original Loss: 0.0783040
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.200)
  Ratio to Original: 0.00%
  Total Loss: 0.0783040 (Pseudo: 0.00%)
[Iter 100] Gaussian 1 vs 0:
  Original Loss: 0.0783039
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.200)
  Ratio to Original: 0.00%
  Total Loss: 0.0783039 (Pseudo: 0.00%)
[Iter 110/20000] Loss: 0.0753274 (Best: 0.0731456 @iter106) ([92m↓4.25%[0m) [29.93% of initial]
[Iter 110] Gaussian 0 vs 1:
  Original Loss: 0.0744795
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.220)
  Ratio to Original: 0.00%
  Total Loss: 0.0744795 (Pseudo: 0.00%)
[Iter 110] Gaussian 1 vs 0:
  Original Loss: 0.0744907
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.220)
  Ratio to Original: 0.00%
  Total Loss: 0.0744907 (Pseudo: 0.00%)
[Iter 120/20000] Loss: 0.0714338 (Best: 0.0685779 @iter118) ([92m↓5.17%[0m) [28.38% of initial]
[Iter 120] Gaussian 0 vs 1:
  Original Loss: 0.0722980
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.240)
  Ratio to Original: 0.00%
  Total Loss: 0.0722980 (Pseudo: 0.00%)
[Iter 120] Gaussian 1 vs 0:
  Original Loss: 0.0723168
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.240)
  Ratio to Original: 0.00%
  Total Loss: 0.0723168 (Pseudo: 0.00%)
[Iter 130/20000] Loss: 0.0667094 (Best: 0.0642144 @iter130) ([92m↓6.61%[0m) [26.50% of initial]
[Iter 130] Gaussian 0 vs 1:
  Original Loss: 0.0642144
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.260)
  Ratio to Original: 0.00%
  Total Loss: 0.0642144 (Pseudo: 0.00%)
[Iter 130] Gaussian 1 vs 0:
  Original Loss: 0.0642080
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.260)
  Ratio to Original: 0.00%
  Total Loss: 0.0642080 (Pseudo: 0.00%)
[Iter 140/20000] Loss: 0.0635396 (Best: 0.0612876 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 140] Gaussian 0 vs 1:
  Original Loss: 0.0612876
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.280)
  Ratio to Original: 0.00%
  Total Loss: 0.0612876 (Pseudo: 0.00%)
[Iter 140] Gaussian 1 vs 0:
  Original Loss: 0.0613061
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.280)
  Ratio to Original: 0.00%
  Total Loss: 0.0613061 (Pseudo: 0.00%)
[Iter 150/20000] Loss: 0.0612688 (Best: 0.0583680 @iter148) ([92m↓3.57%[0m) [24.34% of initial]
[Iter 150] Gaussian 0 vs 1:
  Original Loss: 0.0605453
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.300)
  Ratio to Original: 0.00%
  Total Loss: 0.0605453 (Pseudo: 0.00%)
[Iter 150] Gaussian 1 vs 0:
  Original Loss: 0.0605823
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.300)
  Ratio to Original: 0.00%
  Total Loss: 0.0605823 (Pseudo: 0.00%)
[Iter 160/20000] Loss: 0.0590484 (Best: 0.0559286 @iter157) ([92m↓3.62%[0m) [23.46% of initial]
[Iter 160] Gaussian 0 vs 1:
  Original Loss: 0.0599981
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.320)
  Ratio to Original: 0.00%
  Total Loss: 0.0599981 (Pseudo: 0.00%)
[Iter 160] Gaussian 1 vs 0:
  Original Loss: 0.0600279
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.320)
  Ratio to Original: 0.00%
  Total Loss: 0.0600279 (Pseudo: 0.00%)
[Iter 170/20000] Loss: 0.0563500 (Best: 0.0534931 @iter167) ([92m↓4.57%[0m) [22.39% of initial]
[Iter 170] Gaussian 0 vs 1:
  Original Loss: 0.0573921
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.340)
  Ratio to Original: 0.00%
  Total Loss: 0.0573921 (Pseudo: 0.00%)
[Iter 170] Gaussian 1 vs 0:
  Original Loss: 0.0574288
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.340)
  Ratio to Original: 0.00%
  Total Loss: 0.0574288 (Pseudo: 0.00%)
[Iter 180/20000] Loss: 0.0523277 (Best: 0.0500123 @iter179) ([92m↓7.14%[0m) [20.79% of initial]
[Iter 180] Gaussian 0 vs 1:
  Original Loss: 0.0518854
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.360)
  Ratio to Original: 0.00%
  Total Loss: 0.0518854 (Pseudo: 0.00%)
[Iter 180] Gaussian 1 vs 0:
  Original Loss: 0.0518935
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.360)
  Ratio to Original: 0.00%
  Total Loss: 0.0518935 (Pseudo: 0.00%)
[Iter 190/20000] Loss: 0.0494977 (Best: 0.0477921 @iter188) ([92m↓5.41%[0m) [19.66% of initial]
[Iter 190] Gaussian 0 vs 1:
  Original Loss: 0.0489988
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.380)
  Ratio to Original: 0.00%
  Total Loss: 0.0489988 (Pseudo: 0.00%)
[Iter 190] Gaussian 1 vs 0:
  Original Loss: 0.0490586
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.380)
  Ratio to Original: 0.00%
  Total Loss: 0.0490586 (Pseudo: 0.00%)
Iter:199, L1 loss=0.03443, Total loss=0.04979, Time:14
[Iter 200/20000] Loss: 0.0478234 (Best: 0.0456826 @iter198) ([92m↓3.38%[0m) [19.00% of initial]
[Iter 200] Gaussian 0 vs 1:
  Original Loss: 0.0467065
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.400)
  Ratio to Original: 0.00%
  Total Loss: 0.0467065 (Pseudo: 0.00%)
[Iter 200] Gaussian 1 vs 0:
  Original Loss: 0.0467326
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.400)
  Ratio to Original: 0.00%
  Total Loss: 0.0467326 (Pseudo: 0.00%)
[Iter 210/20000] Loss: 0.0450144 (Best: 0.0428364 @iter209) ([92m↓5.87%[0m) [17.88% of initial]
[Iter 210] Gaussian 0 vs 1:
  Original Loss: 0.0447366
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.420)
  Ratio to Original: 0.00%
  Total Loss: 0.0447366 (Pseudo: 0.00%)
[Iter 210] Gaussian 1 vs 0:
  Original Loss: 0.0447613
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.420)
  Ratio to Original: 0.00%
  Total Loss: 0.0447613 (Pseudo: 0.00%)
[Iter 220/20000] Loss: 0.0440382 (Best: 0.0411982 @iter219) ([92m↓2.17%[0m) [17.50% of initial]
[Iter 220] Gaussian 0 vs 1:
  Original Loss: 0.0454602
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.440)
  Ratio to Original: 0.00%
  Total Loss: 0.0454602 (Pseudo: 0.00%)
[Iter 220] Gaussian 1 vs 0:
  Original Loss: 0.0454481
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.440)
  Ratio to Original: 0.00%
  Total Loss: 0.0454481 (Pseudo: 0.00%)
[Iter 230/20000] Loss: 0.0422803 (Best: 0.0398412 @iter227) ([92m↓3.99%[0m) [16.80% of initial]
[Iter 230] Gaussian 0 vs 1:
  Original Loss: 0.0410086
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.460)
  Ratio to Original: 0.00%
  Total Loss: 0.0410086 (Pseudo: 0.00%)
[Iter 230] Gaussian 1 vs 0:
  Original Loss: 0.0410920
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.460)
  Ratio to Original: 0.00%
  Total Loss: 0.0410920 (Pseudo: 0.00%)
[Iter 240/20000] Loss: 0.0402027 (Best: 0.0377617 @iter238) ([92m↓4.91%[0m) [15.97% of initial]
[Iter 240] Gaussian 0 vs 1:
  Original Loss: 0.0393227
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.480)
  Ratio to Original: 0.00%
  Total Loss: 0.0393227 (Pseudo: 0.00%)
[Iter 240] Gaussian 1 vs 0:
  Original Loss: 0.0394214
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.480)
  Ratio to Original: 0.00%
  Total Loss: 0.0394214 (Pseudo: 0.00%)
[Iter 250/20000] Loss: 0.0379483 (Best: 0.0361903 @iter248) ([92m↓5.61%[0m) [15.08% of initial]
[Iter 250] Gaussian 0 vs 1:
  Original Loss: 0.0375778
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.500)
  Ratio to Original: 0.00%
  Total Loss: 0.0375778 (Pseudo: 0.00%)
[Iter 250] Gaussian 1 vs 0:
  Original Loss: 0.0376327
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.500)
  Ratio to Original: 0.00%
  Total Loss: 0.0376327 (Pseudo: 0.00%)
[Iter 260/20000] Loss: 0.0359141 (Best: 0.0343693 @iter260) ([92m↓5.36%[0m) [14.27% of initial]
[Iter 260] Gaussian 0 vs 1:
  Original Loss: 0.0343693
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.520)
  Ratio to Original: 0.00%
  Total Loss: 0.0343693 (Pseudo: 0.00%)
[Iter 260] Gaussian 1 vs 0:
  Original Loss: 0.0343404
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.520)
  Ratio to Original: 0.00%
  Total Loss: 0.0343404 (Pseudo: 0.00%)
[Iter 270/20000] Loss: 0.0349382 (Best: 0.0328604 @iter269) ([92m↓2.72%[0m) [13.88% of initial]
[Iter 270] Gaussian 0 vs 1:
  Original Loss: 0.0346533
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.540)
  Ratio to Original: 0.00%
  Total Loss: 0.0346533 (Pseudo: 0.00%)
[Iter 270] Gaussian 1 vs 0:
  Original Loss: 0.0347309
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.540)
  Ratio to Original: 0.00%
  Total Loss: 0.0347309 (Pseudo: 0.00%)
[Iter 280/20000] Loss: 0.0346945 (Best: 0.0319148 @iter277) ([92m↓0.70%[0m) [13.78% of initial]
[Iter 280] Gaussian 0 vs 1:
  Original Loss: 0.0358568
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.560)
  Ratio to Original: 0.00%
  Total Loss: 0.0358568 (Pseudo: 0.00%)
[Iter 280] Gaussian 1 vs 0:
  Original Loss: 0.0359731
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.560)
  Ratio to Original: 0.00%
  Total Loss: 0.0359731 (Pseudo: 0.00%)
[Iter 290/20000] Loss: 0.0331024 (Best: 0.0303852 @iter287) ([92m↓4.59%[0m) [13.15% of initial]
[Iter 290] Gaussian 0 vs 1:
  Original Loss: 0.0321202
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.580)
  Ratio to Original: 0.00%
  Total Loss: 0.0321202 (Pseudo: 0.00%)
[Iter 290] Gaussian 1 vs 0:
  Original Loss: 0.0321934
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.580)
  Ratio to Original: 0.00%
  Total Loss: 0.0321934 (Pseudo: 0.00%)
Iter:299, L1 loss=0.02221, Total loss=0.03345, Time:14
[Iter 300/20000] Loss: 0.0308937 (Best: 0.0290417 @iter300) ([92m↓6.67%[0m) [12.27% of initial]
[Iter 300] Gaussian 0 vs 1:
  Original Loss: 0.0290417
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.600)
  Ratio to Original: 0.00%
  Total Loss: 0.0290417 (Pseudo: 0.00%)
[Iter 300] Gaussian 1 vs 0:
  Original Loss: 0.0290223
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.600)
  Ratio to Original: 0.00%
  Total Loss: 0.0290223 (Pseudo: 0.00%)
[Iter 310/20000] Loss: 0.0293910 (Best: 0.0274530 @iter310) ([92m↓4.86%[0m) [11.68% of initial]
[Iter 310] Gaussian 0 vs 1:
  Original Loss: 0.0274530
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.620)
  Ratio to Original: 0.00%
  Total Loss: 0.0274530 (Pseudo: 0.00%)
[Iter 310] Gaussian 1 vs 0:
  Original Loss: 0.0274441
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.620)
  Ratio to Original: 0.00%
  Total Loss: 0.0274441 (Pseudo: 0.00%)
[Iter 320/20000] Loss: 0.0278181 (Best: 0.0263720 @iter320) ([92m↓5.35%[0m) [11.05% of initial]
[Iter 320] Gaussian 0 vs 1:
  Original Loss: 0.0263720
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.640)
  Ratio to Original: 0.00%
  Total Loss: 0.0263720 (Pseudo: 0.00%)
[Iter 320] Gaussian 1 vs 0:
  Original Loss: 0.0266206
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.640)
  Ratio to Original: 0.00%
  Total Loss: 0.0266206 (Pseudo: 0.00%)
[Iter 330/20000] Loss: 0.0275578 (Best: 0.0256517 @iter330) ([92m↓0.94%[0m) [10.95% of initial]
[Iter 330] Gaussian 0 vs 1:
  Original Loss: 0.0256517
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.660)
  Ratio to Original: 0.00%
  Total Loss: 0.0256517 (Pseudo: 0.00%)
[Iter 330] Gaussian 1 vs 0:
  Original Loss: 0.0258970
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.660)
  Ratio to Original: 0.00%
  Total Loss: 0.0258970 (Pseudo: 0.00%)
[Iter 340/20000] Loss: 0.0253621 (Best: 0.0242631 @iter340) ([92m↓7.97%[0m) [10.08% of initial]
[Iter 340] Gaussian 0 vs 1:
  Original Loss: 0.0242631
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.680)
  Ratio to Original: 0.00%
  Total Loss: 0.0242631 (Pseudo: 0.00%)
[Iter 340] Gaussian 1 vs 0:
  Original Loss: 0.0244139
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.680)
  Ratio to Original: 0.00%
  Total Loss: 0.0244139 (Pseudo: 0.00%)
[Iter 350/20000] Loss: 0.0260154 (Best: 0.0234693 @iter349) ([91m↑2.58%[0m) [10.34% of initial]
[Iter 350] Gaussian 0 vs 1:
  Original Loss: 0.0273475
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.700)
  Ratio to Original: 0.00%
  Total Loss: 0.0273475 (Pseudo: 0.00%)
[Iter 350] Gaussian 1 vs 0:
  Original Loss: 0.0274214
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.700)
  Ratio to Original: 0.00%
  Total Loss: 0.0274214 (Pseudo: 0.00%)
[Iter 360/20000] Loss: 0.0244330 (Best: 0.0225299 @iter358) ([92m↓6.08%[0m) [9.71% of initial]
[Iter 360] Gaussian 0 vs 1:
  Original Loss: 0.0240026
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.720)
  Ratio to Original: 0.00%
  Total Loss: 0.0240026 (Pseudo: 0.00%)
[Iter 360] Gaussian 1 vs 0:
  Original Loss: 0.0245428
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.720)
  Ratio to Original: 0.00%
  Total Loss: 0.0245428 (Pseudo: 0.00%)
[Iter 370/20000] Loss: 0.0241634 (Best: 0.0219332 @iter368) ([92m↓1.10%[0m) [9.60% of initial]
[Iter 370] Gaussian 0 vs 1:
  Original Loss: 0.0253552
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.740)
  Ratio to Original: 0.00%
  Total Loss: 0.0253552 (Pseudo: 0.00%)
[Iter 370] Gaussian 1 vs 0:
  Original Loss: 0.0255873
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.740)
  Ratio to Original: 0.00%
  Total Loss: 0.0255873 (Pseudo: 0.00%)
[Iter 380/20000] Loss: 0.0219556 (Best: 0.0208685 @iter379) ([92m↓9.14%[0m) [8.72% of initial]
[Iter 380] Gaussian 0 vs 1:
  Original Loss: 0.0222538
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.760)
  Ratio to Original: 0.00%
  Total Loss: 0.0222538 (Pseudo: 0.00%)
[Iter 380] Gaussian 1 vs 0:
  Original Loss: 0.0228190
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.760)
  Ratio to Original: 0.00%
  Total Loss: 0.0228190 (Pseudo: 0.00%)
[Iter 390/20000] Loss: 0.0214535 (Best: 0.0198951 @iter385) ([92m↓2.29%[0m) [8.52% of initial]
[Iter 390] Gaussian 0 vs 1:
  Original Loss: 0.0200861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.780)
  Ratio to Original: 0.00%
  Total Loss: 0.0200861 (Pseudo: 0.00%)
[Iter 390] Gaussian 1 vs 0:
  Original Loss: 0.0203170
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.780)
  Ratio to Original: 0.00%
  Total Loss: 0.0203170 (Pseudo: 0.00%)
Iter:399, L1 loss=0.01372, Total loss=0.02121, Time:14
[Iter 400/20000] Loss: 0.0204162 (Best: 0.0189818 @iter400) ([92m↓4.83%[0m) [8.11% of initial]
[Iter 400] Gaussian 0 vs 1:
  Original Loss: 0.0189818
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.800)
  Ratio to Original: 0.00%
  Total Loss: 0.0189818 (Pseudo: 0.00%)
[Iter 400] Gaussian 1 vs 0:
  Original Loss: 0.0191063
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.800)
  Ratio to Original: 0.00%
  Total Loss: 0.0191063 (Pseudo: 0.00%)
[Iter 410/20000] Loss: 0.0194617 (Best: 0.0183653 @iter410) ([92m↓4.68%[0m) [7.73% of initial]
[Iter 410] Gaussian 0 vs 1:
  Original Loss: 0.0183653
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.820)
  Ratio to Original: 0.00%
  Total Loss: 0.0183653 (Pseudo: 0.00%)
[Iter 410] Gaussian 1 vs 0:
  Original Loss: 0.0185541
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.820)
  Ratio to Original: 0.00%
  Total Loss: 0.0185541 (Pseudo: 0.00%)
[Iter 420/20000] Loss: 0.0199603 (Best: 0.0177621 @iter418) ([91m↑2.56%[0m) [7.93% of initial]
[Iter 420] Gaussian 0 vs 1:
  Original Loss: 0.0212062
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.840)
  Ratio to Original: 0.00%
  Total Loss: 0.0212062 (Pseudo: 0.00%)
[Iter 420] Gaussian 1 vs 0:
  Original Loss: 0.0213478
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.840)
  Ratio to Original: 0.00%
  Total Loss: 0.0213478 (Pseudo: 0.00%)
[Iter 430/20000] Loss: 0.0182680 (Best: 0.0173801 @iter430) ([92m↓8.48%[0m) [7.26% of initial]
[Iter 430] Gaussian 0 vs 1:
  Original Loss: 0.0173801
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.860)
  Ratio to Original: 0.00%
  Total Loss: 0.0173801 (Pseudo: 0.00%)
[Iter 430] Gaussian 1 vs 0:
  Original Loss: 0.0168240
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.860)
  Ratio to Original: 0.00%
  Total Loss: 0.0168240 (Pseudo: 0.00%)
[Iter 440/20000] Loss: 0.0188349 (Best: 0.0170196 @iter438) ([91m↑3.10%[0m) [7.48% of initial]
[Iter 440] Gaussian 0 vs 1:
  Original Loss: 0.0197487
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.880)
  Ratio to Original: 0.00%
  Total Loss: 0.0197487 (Pseudo: 0.00%)
[Iter 440] Gaussian 1 vs 0:
  Original Loss: 0.0190885
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.880)
  Ratio to Original: 0.00%
  Total Loss: 0.0190885 (Pseudo: 0.00%)
[Iter 450/20000] Loss: 0.0180006 (Best: 0.0160581 @iter449) ([92m↓4.43%[0m) [7.15% of initial]
[Iter 450] Gaussian 0 vs 1:
  Original Loss: 0.0192332
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.900)
  Ratio to Original: 0.00%
  Total Loss: 0.0192332 (Pseudo: 0.00%)
[Iter 450] Gaussian 1 vs 0:
  Original Loss: 0.0188306
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.900)
  Ratio to Original: 0.00%
  Total Loss: 0.0188306 (Pseudo: 0.00%)
[Iter 460/20000] Loss: 0.0173075 (Best: 0.0153155 @iter458) ([92m↓3.85%[0m) [6.88% of initial]
[Iter 460] Gaussian 0 vs 1:
  Original Loss: 0.0180222
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.920)
  Ratio to Original: 0.00%
  Total Loss: 0.0180222 (Pseudo: 0.00%)
[Iter 460] Gaussian 1 vs 0:
  Original Loss: 0.0172426
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.920)
  Ratio to Original: 0.00%
  Total Loss: 0.0172426 (Pseudo: 0.00%)
[Iter 470/20000] Loss: 0.0158542 (Best: 0.0148551 @iter463) ([92m↓8.40%[0m) [6.30% of initial]
[Iter 470] Gaussian 0 vs 1:
  Original Loss: 0.0150190
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.940)
  Ratio to Original: 0.00%
  Total Loss: 0.0150190 (Pseudo: 0.00%)
[Iter 470] Gaussian 1 vs 0:
  Original Loss: 0.0138350
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.940)
  Ratio to Original: 0.00%
  Total Loss: 0.0138350 (Pseudo: 0.00%)
[Iter 480/20000] Loss: 0.0158497 (Best: 0.0144849 @iter479) ([92m↓0.03%[0m) [6.30% of initial]
[Iter 480] Gaussian 0 vs 1:
  Original Loss: 0.0160275
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.960)
  Ratio to Original: 0.00%
  Total Loss: 0.0160275 (Pseudo: 0.00%)
[Iter 480] Gaussian 1 vs 0:
  Original Loss: 0.0143497
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.960)
  Ratio to Original: 0.00%
  Total Loss: 0.0143497 (Pseudo: 0.00%)
[Iter 490/20000] Loss: 0.0148425 (Best: 0.0137517 @iter490) ([92m↓6.35%[0m) [5.90% of initial]
[Iter 490] Gaussian 0 vs 1:
  Original Loss: 0.0137517
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.980)
  Ratio to Original: 0.00%
  Total Loss: 0.0137517 (Pseudo: 0.00%)
[Iter 490] Gaussian 1 vs 0:
  Original Loss: 0.0130682
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.980)
  Ratio to Original: 0.00%
  Total Loss: 0.0130682 (Pseudo: 0.00%)
Iter:499, L1 loss=0.008805, Total loss=0.01551, Time:14
[Iter 500/20000] Loss: 0.0146356 (Best: 0.0135424 @iter493) ([92m↓1.39%[0m) [5.81% of initial]
[Iter 500] Gaussian 0 vs 1:
  Original Loss: 0.0142567
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0142567 (Pseudo: 0.00%)
[Iter 500] Gaussian 1 vs 0:
  Original Loss: 0.0137677
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0137677 (Pseudo: 0.00%)
[Iter 510/20000] Loss: 0.0141573 (Best: 0.0129006 @iter508) ([92m↓3.27%[0m) [5.62% of initial]
[Iter 510] Gaussian 0 vs 1:
  Original Loss: 0.0141517
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0141517 (Pseudo: 0.00%)
[Iter 510] Gaussian 1 vs 0:
  Original Loss: 0.0136837
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0136837 (Pseudo: 0.00%)
[Iter 520/20000] Loss: 0.0132030 (Best: 0.0123284 @iter514) ([92m↓6.74%[0m) [5.25% of initial]
[Iter 520] Gaussian 0 vs 1:
  Original Loss: 0.0130815
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0130815 (Pseudo: 0.00%)
[Iter 520] Gaussian 1 vs 0:
  Original Loss: 0.0129185
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0129185 (Pseudo: 0.00%)
[Iter 530/20000] Loss: 0.0125356 (Best: 0.0115212 @iter529) ([92m↓5.05%[0m) [4.98% of initial]
[Iter 530] Gaussian 0 vs 1:
  Original Loss: 0.0125486
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0125486 (Pseudo: 0.00%)
[Iter 530] Gaussian 1 vs 0:
  Original Loss: 0.0127318
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0127318 (Pseudo: 0.00%)
[Iter 540/20000] Loss: 0.0123495 (Best: 0.0110516 @iter538) ([92m↓1.48%[0m) [4.91% of initial]
[Iter 540] Gaussian 0 vs 1:
  Original Loss: 0.0121679
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0121679 (Pseudo: 0.00%)
[Iter 540] Gaussian 1 vs 0:
  Original Loss: 0.0125708
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0125708 (Pseudo: 0.00%)
[Iter 550/20000] Loss: 0.0121470 (Best: 0.0109409 @iter548) ([92m↓1.64%[0m) [4.83% of initial]
[Iter 550] Gaussian 0 vs 1:
  Original Loss: 0.0121311
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0121311 (Pseudo: 0.00%)
[Iter 550] Gaussian 1 vs 0:
  Original Loss: 0.0120861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0120861 (Pseudo: 0.00%)
[Iter 560/20000] Loss: 0.0123161 (Best: 0.0109401 @iter556) ([91m↑1.39%[0m) [4.89% of initial]
[Iter 560] Gaussian 0 vs 1:
  Original Loss: 0.0120802
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0120802 (Pseudo: 0.00%)
[Iter 560] Gaussian 1 vs 0:
  Original Loss: 0.0118709
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0118709 (Pseudo: 0.00%)
[Iter 570/20000] Loss: 0.0117875 (Best: 0.0104893 @iter569) ([92m↓4.29%[0m) [4.68% of initial]
[Iter 570] Gaussian 0 vs 1:
  Original Loss: 0.0127352
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0127352 (Pseudo: 0.00%)
[Iter 570] Gaussian 1 vs 0:
  Original Loss: 0.0125608
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0125608 (Pseudo: 0.00%)
[Iter 580/20000] Loss: 0.0111491 (Best: 0.0101479 @iter578) ([92m↓5.42%[0m) [4.43% of initial]
[Iter 580] Gaussian 0 vs 1:
  Original Loss: 0.0110773
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0110773 (Pseudo: 0.00%)
[Iter 580] Gaussian 1 vs 0:
  Original Loss: 0.0111218
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0111218 (Pseudo: 0.00%)
[Iter 590/20000] Loss: 0.0112763 (Best: 0.0098980 @iter583) ([91m↑1.14%[0m) [4.48% of initial]
[Iter 590] Gaussian 0 vs 1:
  Original Loss: 0.0111352
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0111352 (Pseudo: 0.00%)
[Iter 590] Gaussian 1 vs 0:
  Original Loss: 0.0110003
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0110003 (Pseudo: 0.00%)
Iter:599, L1 loss=0.006812, Total loss=0.01218, Time:13
[Iter 600/20000] Loss: 0.0114872 (Best: 0.0098980 @iter583) ([91m↑1.87%[0m) [4.56% of initial]
[Iter 600] Gaussian 0 vs 1:
  Original Loss: 0.0117089
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0117089 (Pseudo: 0.00%)
[Iter 600] Gaussian 1 vs 0:
  Original Loss: 0.0108206
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0108206 (Pseudo: 0.00%)
[Iter 610/20000] Loss: 0.0197686 (Best: 0.0098980 @iter583) ([91m↑72.09%[0m) [7.85% of initial]
[Iter 610] Gaussian 0 vs 1:
  Original Loss: 0.0173837
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0173837 (Pseudo: 0.00%)
[Iter 610] Gaussian 1 vs 0:
  Original Loss: 0.0179846
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0179846 (Pseudo: 0.00%)
[Iter 620/20000] Loss: 0.0143950 (Best: 0.0098980 @iter583) ([92m↓27.18%[0m) [5.72% of initial]
[Iter 620] Gaussian 0 vs 1:
  Original Loss: 0.0130906
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0130906 (Pseudo: 0.00%)
[Iter 620] Gaussian 1 vs 0:
  Original Loss: 0.0126280
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0126280 (Pseudo: 0.00%)
[Iter 630/20000] Loss: 0.0121635 (Best: 0.0098980 @iter583) ([92m↓15.50%[0m) [4.83% of initial]
[Iter 630] Gaussian 0 vs 1:
  Original Loss: 0.0113021
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0113021 (Pseudo: 0.00%)
[Iter 630] Gaussian 1 vs 0:
  Original Loss: 0.0112670
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0112670 (Pseudo: 0.00%)
[Iter 640/20000] Loss: 0.0105291 (Best: 0.0096385 @iter640) ([92m↓13.44%[0m) [4.18% of initial]
[Iter 640] Gaussian 0 vs 1:
  Original Loss: 0.0096385
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0096385 (Pseudo: 0.00%)
[Iter 640] Gaussian 1 vs 0:
  Original Loss: 0.0091983
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0091983 (Pseudo: 0.00%)
[Iter 650/20000] Loss: 0.0106195 (Best: 0.0093933 @iter646) ([91m↑0.86%[0m) [4.22% of initial]
[Iter 650] Gaussian 0 vs 1:
  Original Loss: 0.0103663
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0103663 (Pseudo: 0.00%)
[Iter 650] Gaussian 1 vs 0:
  Original Loss: 0.0105366
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0105366 (Pseudo: 0.00%)
[Iter 660/20000] Loss: 0.0100114 (Best: 0.0088941 @iter655) ([92m↓5.73%[0m) [3.98% of initial]
[Iter 660] Gaussian 0 vs 1:
  Original Loss: 0.0106640
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0106640 (Pseudo: 0.00%)
[Iter 660] Gaussian 1 vs 0:
  Original Loss: 0.0106458
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0106458 (Pseudo: 0.00%)
[Iter 670/20000] Loss: 0.0095141 (Best: 0.0083938 @iter667) ([92m↓4.97%[0m) [3.78% of initial]
[Iter 670] Gaussian 0 vs 1:
  Original Loss: 0.0093781
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0093781 (Pseudo: 0.00%)
[Iter 670] Gaussian 1 vs 0:
  Original Loss: 0.0093635
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0093635 (Pseudo: 0.00%)
[Iter 680/20000] Loss: 0.0089247 (Best: 0.0083034 @iter680) ([92m↓6.19%[0m) [3.55% of initial]
[Iter 680] Gaussian 0 vs 1:
  Original Loss: 0.0083034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0083034 (Pseudo: 0.00%)
[Iter 680] Gaussian 1 vs 0:
  Original Loss: 0.0081034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0081034 (Pseudo: 0.00%)
[Iter 690/20000] Loss: 0.0092628 (Best: 0.0079286 @iter682) ([91m↑3.79%[0m) [3.68% of initial]
[Iter 690] Gaussian 0 vs 1:
  Original Loss: 0.0087427
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087427 (Pseudo: 0.00%)
[Iter 690] Gaussian 1 vs 0:
  Original Loss: 0.0087921
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087921 (Pseudo: 0.00%)
Iter:699, L1 loss=0.005753, Total loss=0.009746, Time:14
[Iter 700/20000] Loss: 0.0089896 (Best: 0.0079143 @iter695) ([92m↓2.95%[0m) [3.57% of initial]
[Iter 700] Gaussian 0 vs 1:
  Original Loss: 0.0088658
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0088658 (Pseudo: 0.00%)
[Iter 700] Gaussian 1 vs 0:
  Original Loss: 0.0088044
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0088044 (Pseudo: 0.00%)
[Iter 710/20000] Loss: 0.0082676 (Best: 0.0076574 @iter710) ([92m↓8.03%[0m) [3.28% of initial]
[Iter 710] Gaussian 0 vs 1:
  Original Loss: 0.0076574
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0076574 (Pseudo: 0.00%)
[Iter 710] Gaussian 1 vs 0:
  Original Loss: 0.0076096
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0076096 (Pseudo: 0.00%)
[Iter 720/20000] Loss: 0.0084732 (Best: 0.0075350 @iter715) ([91m↑2.49%[0m) [3.37% of initial]
[Iter 720] Gaussian 0 vs 1:
  Original Loss: 0.0079312
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079312 (Pseudo: 0.00%)
[Iter 720] Gaussian 1 vs 0:
  Original Loss: 0.0078905
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0078905 (Pseudo: 0.00%)
[Iter 730/20000] Loss: 0.0084763 (Best: 0.0074474 @iter724) ([91m↑0.04%[0m) [3.37% of initial]
[Iter 730] Gaussian 0 vs 1:
  Original Loss: 0.0083475
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0083475 (Pseudo: 0.00%)
[Iter 730] Gaussian 1 vs 0:
  Original Loss: 0.0083282
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0083282 (Pseudo: 0.00%)
[Iter 740/20000] Loss: 0.0085226 (Best: 0.0074370 @iter733) ([91m↑0.55%[0m) [3.39% of initial]
[Iter 740] Gaussian 0 vs 1:
  Original Loss: 0.0088001
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0088001 (Pseudo: 0.00%)
[Iter 740] Gaussian 1 vs 0:
  Original Loss: 0.0086915
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0086915 (Pseudo: 0.00%)
[Iter 750/20000] Loss: 0.0080038 (Best: 0.0068863 @iter748) ([92m↓6.09%[0m) [3.18% of initial]
[Iter 750] Gaussian 0 vs 1:
  Original Loss: 0.0079391
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079391 (Pseudo: 0.00%)
[Iter 750] Gaussian 1 vs 0:
  Original Loss: 0.0080232
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0080232 (Pseudo: 0.00%)
[Iter 760/20000] Loss: 0.0074151 (Best: 0.0068772 @iter754) ([92m↓7.36%[0m) [2.95% of initial]
[Iter 760] Gaussian 0 vs 1:
  Original Loss: 0.0069822
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069822 (Pseudo: 0.00%)
[Iter 760] Gaussian 1 vs 0:
  Original Loss: 0.0069306
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069306 (Pseudo: 0.00%)
[Iter 770/20000] Loss: 0.0076045 (Best: 0.0068772 @iter754) ([91m↑2.55%[0m) [3.02% of initial]
[Iter 770] Gaussian 0 vs 1:
  Original Loss: 0.0079048
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079048 (Pseudo: 0.00%)
[Iter 770] Gaussian 1 vs 0:
  Original Loss: 0.0079583
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079583 (Pseudo: 0.00%)
[Iter 780/20000] Loss: 0.0078148 (Best: 0.0066673 @iter775) ([91m↑2.77%[0m) [3.10% of initial]
[Iter 780] Gaussian 0 vs 1:
  Original Loss: 0.0084307
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0084307 (Pseudo: 0.00%)
[Iter 780] Gaussian 1 vs 0:
  Original Loss: 0.0084941
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0084941 (Pseudo: 0.00%)
[Iter 790/20000] Loss: 0.0075900 (Best: 0.0065199 @iter787) ([92m↓2.88%[0m) [3.02% of initial]
[Iter 790] Gaussian 0 vs 1:
  Original Loss: 0.0075703
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0075703 (Pseudo: 0.00%)
[Iter 790] Gaussian 1 vs 0:
  Original Loss: 0.0075662
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0075662 (Pseudo: 0.00%)
Iter:799, L1 loss=0.005018, Total loss=0.008075, Time:14
[Iter 800/20000] Loss: 0.0072786 (Best: 0.0064637 @iter796) ([92m↓4.10%[0m) [2.89% of initial]
[Iter 800] Gaussian 0 vs 1:
  Original Loss: 0.0065196
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065196 (Pseudo: 0.00%)
[Iter 800] Gaussian 1 vs 0:
  Original Loss: 0.0066094
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066094 (Pseudo: 0.00%)
[Iter 810/20000] Loss: 0.0152791 (Best: 0.0064637 @iter796) ([91m↑109.92%[0m) [6.07% of initial]
[Iter 810] Gaussian 0 vs 1:
  Original Loss: 0.0137210
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0137210 (Pseudo: 0.00%)
[Iter 810] Gaussian 1 vs 0:
  Original Loss: 0.0142203
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0142203 (Pseudo: 0.00%)
[Iter 820/20000] Loss: 0.0104260 (Best: 0.0064637 @iter796) ([92m↓31.76%[0m) [4.14% of initial]
[Iter 820] Gaussian 0 vs 1:
  Original Loss: 0.0102699
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0102699 (Pseudo: 0.00%)
[Iter 820] Gaussian 1 vs 0:
  Original Loss: 0.0103150
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0103150 (Pseudo: 0.00%)
[Iter 830/20000] Loss: 0.0089167 (Best: 0.0064637 @iter796) ([92m↓14.48%[0m) [3.54% of initial]
[Iter 830] Gaussian 0 vs 1:
  Original Loss: 0.0093644
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0093644 (Pseudo: 0.00%)
[Iter 830] Gaussian 1 vs 0:
  Original Loss: 0.0090817
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0090817 (Pseudo: 0.00%)
[Iter 840/20000] Loss: 0.0080015 (Best: 0.0064637 @iter796) ([92m↓10.26%[0m) [3.18% of initial]
[Iter 840] Gaussian 0 vs 1:
  Original Loss: 0.0087314
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087314 (Pseudo: 0.00%)
[Iter 840] Gaussian 1 vs 0:
  Original Loss: 0.0086397
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0086397 (Pseudo: 0.00%)
[Iter 850/20000] Loss: 0.0076434 (Best: 0.0064637 @iter796) ([92m↓4.47%[0m) [3.04% of initial]
[Iter 850] Gaussian 0 vs 1:
  Original Loss: 0.0076028
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0076028 (Pseudo: 0.00%)
[Iter 850] Gaussian 1 vs 0:
  Original Loss: 0.0073827
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0073827 (Pseudo: 0.00%)
[Iter 860/20000] Loss: 0.0071295 (Best: 0.0064116 @iter856) ([92m↓6.72%[0m) [2.83% of initial]
[Iter 860] Gaussian 0 vs 1:
  Original Loss: 0.0072083
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0072083 (Pseudo: 0.00%)
[Iter 860] Gaussian 1 vs 0:
  Original Loss: 0.0071205
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0071205 (Pseudo: 0.00%)
[Iter 870/20000] Loss: 0.0067272 (Best: 0.0061713 @iter862) ([92m↓5.64%[0m) [2.67% of initial]
[Iter 870] Gaussian 0 vs 1:
  Original Loss: 0.0062396
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062396 (Pseudo: 0.00%)
[Iter 870] Gaussian 1 vs 0:
  Original Loss: 0.0062096
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062096 (Pseudo: 0.00%)
[Iter 880/20000] Loss: 0.0067342 (Best: 0.0058690 @iter875) ([91m↑0.10%[0m) [2.68% of initial]
[Iter 880] Gaussian 0 vs 1:
  Original Loss: 0.0068499
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0068499 (Pseudo: 0.00%)
[Iter 880] Gaussian 1 vs 0:
  Original Loss: 0.0067490
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0067490 (Pseudo: 0.00%)
[Iter 890/20000] Loss: 0.0062803 (Best: 0.0057235 @iter884) ([92m↓6.74%[0m) [2.50% of initial]
[Iter 890] Gaussian 0 vs 1:
  Original Loss: 0.0057370
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057370 (Pseudo: 0.00%)
[Iter 890] Gaussian 1 vs 0:
  Original Loss: 0.0057240
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057240 (Pseudo: 0.00%)
Iter:899, L1 loss=0.003652, Total loss=0.005587, Time:14
[Iter 900/20000] Loss: 0.0064505 (Best: 0.0055866 @iter899) ([91m↑2.71%[0m) [2.56% of initial]
[Iter 900] Gaussian 0 vs 1:
  Original Loss: 0.0066263
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066263 (Pseudo: 0.00%)
[Iter 900] Gaussian 1 vs 0:
  Original Loss: 0.0066667
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066667 (Pseudo: 0.00%)
[Iter 910/20000] Loss: 0.0066189 (Best: 0.0054380 @iter907) ([91m↑2.61%[0m) [2.63% of initial]
[Iter 910] Gaussian 0 vs 1:
  Original Loss: 0.0069898
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069898 (Pseudo: 0.00%)
[Iter 910] Gaussian 1 vs 0:
  Original Loss: 0.0068097
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0068097 (Pseudo: 0.00%)
[Iter 920/20000] Loss: 0.0059797 (Best: 0.0053167 @iter916) ([92m↓9.66%[0m) [2.38% of initial]
[Iter 920] Gaussian 0 vs 1:
  Original Loss: 0.0060827
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060827 (Pseudo: 0.00%)
[Iter 920] Gaussian 1 vs 0:
  Original Loss: 0.0060409
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060409 (Pseudo: 0.00%)
[Iter 930/20000] Loss: 0.0062437 (Best: 0.0052350 @iter925) ([91m↑4.41%[0m) [2.48% of initial]
[Iter 930] Gaussian 0 vs 1:
  Original Loss: 0.0067163
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0067163 (Pseudo: 0.00%)
[Iter 930] Gaussian 1 vs 0:
  Original Loss: 0.0065603
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065603 (Pseudo: 0.00%)
[Iter 940/20000] Loss: 0.0063052 (Best: 0.0052350 @iter925) ([91m↑0.99%[0m) [2.50% of initial]
[Iter 940] Gaussian 0 vs 1:
  Original Loss: 0.0066315
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066315 (Pseudo: 0.00%)
[Iter 940] Gaussian 1 vs 0:
  Original Loss: 0.0065329
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065329 (Pseudo: 0.00%)
[Iter 950/20000] Loss: 0.0059025 (Best: 0.0052204 @iter946) ([92m↓6.39%[0m) [2.35% of initial]
[Iter 950] Gaussian 0 vs 1:
  Original Loss: 0.0056459
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0056459 (Pseudo: 0.00%)
[Iter 950] Gaussian 1 vs 0:
  Original Loss: 0.0054311
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0054311 (Pseudo: 0.00%)
[Iter 960/20000] Loss: 0.0060538 (Best: 0.0052204 @iter946) ([91m↑2.56%[0m) [2.41% of initial]
[Iter 960] Gaussian 0 vs 1:
  Original Loss: 0.0063931
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0063931 (Pseudo: 0.00%)
[Iter 960] Gaussian 1 vs 0:
  Original Loss: 0.0062423
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062423 (Pseudo: 0.00%)
[Iter 970/20000] Loss: 0.0060936 (Best: 0.0052204 @iter946) ([91m↑0.66%[0m) [2.42% of initial]
[Iter 970] Gaussian 0 vs 1:
  Original Loss: 0.0060242
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060242 (Pseudo: 0.00%)
[Iter 970] Gaussian 1 vs 0:
  Original Loss: 0.0058642
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058642 (Pseudo: 0.00%)
[Iter 980/20000] Loss: 0.0062135 (Best: 0.0052204 @iter946) ([91m↑1.97%[0m) [2.47% of initial]
[Iter 980] Gaussian 0 vs 1:
  Original Loss: 0.0066441
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066441 (Pseudo: 0.00%)
[Iter 980] Gaussian 1 vs 0:
  Original Loss: 0.0065955
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065955 (Pseudo: 0.00%)
[Iter 990/20000] Loss: 0.0063943 (Best: 0.0052204 @iter946) ([91m↑2.91%[0m) [2.54% of initial]
[Iter 990] Gaussian 0 vs 1:
  Original Loss: 0.0065431
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065431 (Pseudo: 0.00%)
[Iter 990] Gaussian 1 vs 0:
  Original Loss: 0.0061843
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061843 (Pseudo: 0.00%)
Iter:999, L1 loss=0.004345, Total loss=0.006774, Time:14
[Iter 1000/20000] Loss: 0.0064013 (Best: 0.0052204 @iter946) ([91m↑0.11%[0m) [2.54% of initial]
[Iter 1000] Gaussian 0 vs 1:
  Original Loss: 0.0066241
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066241 (Pseudo: 0.00%)
[Iter 1000] Gaussian 1 vs 0:
  Original Loss: 0.0063582
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0063582 (Pseudo: 0.00%)
[Iter 1010/20000] Loss: 0.0118952 (Best: 0.0052204 @iter946) ([91m↑85.83%[0m) [4.73% of initial]
[Iter 1010] Gaussian 0 vs 1:
  Original Loss: 0.0110860
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0110860 (Pseudo: 0.00%)
[Iter 1010] Gaussian 1 vs 0:
  Original Loss: 0.0111453
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0111453 (Pseudo: 0.00%)
[Iter 1020/20000] Loss: 0.0084708 (Best: 0.0052204 @iter946) ([92m↓28.79%[0m) [3.37% of initial]
[Iter 1020] Gaussian 0 vs 1:
  Original Loss: 0.0080464
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0080464 (Pseudo: 0.00%)
[Iter 1020] Gaussian 1 vs 0:
  Original Loss: 0.0077688
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0077688 (Pseudo: 0.00%)
[Iter 1030/20000] Loss: 0.0068693 (Best: 0.0052204 @iter946) ([92m↓18.91%[0m) [2.73% of initial]
[Iter 1030] Gaussian 0 vs 1:
  Original Loss: 0.0061249
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061249 (Pseudo: 0.00%)
[Iter 1030] Gaussian 1 vs 0:
  Original Loss: 0.0058401
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058401 (Pseudo: 0.00%)
[Iter 1040/20000] Loss: 0.0059400 (Best: 0.0052204 @iter946) ([92m↓13.53%[0m) [2.36% of initial]
[Iter 1040] Gaussian 0 vs 1:
  Original Loss: 0.0058220
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058220 (Pseudo: 0.00%)
[Iter 1040] Gaussian 1 vs 0:
  Original Loss: 0.0059611
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0059611 (Pseudo: 0.00%)
[Iter 1050/20000] Loss: 0.0058424 (Best: 0.0051647 @iter1049) ([92m↓1.64%[0m) [2.32% of initial]
[Iter 1050] Gaussian 0 vs 1:
  Original Loss: 0.0059484
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0059484 (Pseudo: 0.00%)
[Iter 1050] Gaussian 1 vs 0:
  Original Loss: 0.0059871
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0059871 (Pseudo: 0.00%)
[Iter 1060/20000] Loss: 0.0057332 (Best: 0.0049453 @iter1055) ([92m↓1.87%[0m) [2.28% of initial]
[Iter 1060] Gaussian 0 vs 1:
  Original Loss: 0.0058894
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058894 (Pseudo: 0.00%)
[Iter 1060] Gaussian 1 vs 0:
  Original Loss: 0.0057905
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057905 (Pseudo: 0.00%)
[Iter 1070/20000] Loss: 0.0054658 (Best: 0.0045379 @iter1066) ([92m↓4.66%[0m) [2.17% of initial]
[Iter 1070] Gaussian 0 vs 1:
  Original Loss: 0.0060349
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060349 (Pseudo: 0.00%)
[Iter 1070] Gaussian 1 vs 0:
  Original Loss: 0.0058870
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058870 (Pseudo: 0.00%)
[Iter 1080/20000] Loss: 0.0051875 (Best: 0.0045379 @iter1066) ([92m↓5.09%[0m) [2.06% of initial]
[Iter 1080] Gaussian 0 vs 1:
  Original Loss: 0.0048912
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048912 (Pseudo: 0.00%)
[Iter 1080] Gaussian 1 vs 0:
  Original Loss: 0.0048083
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048083 (Pseudo: 0.00%)
[Iter 1090/20000] Loss: 0.0050573 (Best: 0.0044906 @iter1082) ([92m↓2.51%[0m) [2.01% of initial]
[Iter 1090] Gaussian 0 vs 1:
  Original Loss: 0.0049748
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049748 (Pseudo: 0.00%)
[Iter 1090] Gaussian 1 vs 0:
  Original Loss: 0.0049022
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049022 (Pseudo: 0.00%)
Iter:1099, L1 loss=0.003485, Total loss=0.004989, Time:14
[Iter 1100/20000] Loss: 0.0049005 (Best: 0.0042519 @iter1093) ([92m↓3.10%[0m) [1.95% of initial]
[Iter 1100] Gaussian 0 vs 1:
  Original Loss: 0.0045945
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045945 (Pseudo: 0.00%)
[Iter 1100] Gaussian 1 vs 0:
  Original Loss: 0.0046067
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046067 (Pseudo: 0.00%)
[Iter 1110/20000] Loss: 0.0050984 (Best: 0.0042519 @iter1093) ([91m↑4.04%[0m) [2.03% of initial]
[Iter 1110] Gaussian 0 vs 1:
  Original Loss: 0.0048770
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048770 (Pseudo: 0.00%)
[Iter 1110] Gaussian 1 vs 0:
  Original Loss: 0.0047438
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047438 (Pseudo: 0.00%)
[Iter 1120/20000] Loss: 0.0050290 (Best: 0.0041586 @iter1117) ([92m↓1.36%[0m) [2.00% of initial]
[Iter 1120] Gaussian 0 vs 1:
  Original Loss: 0.0049384
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049384 (Pseudo: 0.00%)
[Iter 1120] Gaussian 1 vs 0:
  Original Loss: 0.0049461
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049461 (Pseudo: 0.00%)
[Iter 1130/20000] Loss: 0.0052986 (Best: 0.0041586 @iter1117) ([91m↑5.36%[0m) [2.11% of initial]
[Iter 1130] Gaussian 0 vs 1:
  Original Loss: 0.0056109
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0056109 (Pseudo: 0.00%)
[Iter 1130] Gaussian 1 vs 0:
  Original Loss: 0.0054502
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0054502 (Pseudo: 0.00%)
[Iter 1140/20000] Loss: 0.0047730 (Best: 0.0041325 @iter1135) ([92m↓9.92%[0m) [1.90% of initial]
[Iter 1140] Gaussian 0 vs 1:
  Original Loss: 0.0047845
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047845 (Pseudo: 0.00%)
[Iter 1140] Gaussian 1 vs 0:
  Original Loss: 0.0048541
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048541 (Pseudo: 0.00%)
[Iter 1150/20000] Loss: 0.0045447 (Best: 0.0040237 @iter1145) ([92m↓4.78%[0m) [1.81% of initial]
[Iter 1150] Gaussian 0 vs 1:
  Original Loss: 0.0041806
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0041806 (Pseudo: 0.00%)
[Iter 1150] Gaussian 1 vs 0:
  Original Loss: 0.0040689
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040689 (Pseudo: 0.00%)
[Iter 1160/20000] Loss: 0.0050417 (Best: 0.0040237 @iter1145) ([91m↑10.94%[0m) [2.00% of initial]
[Iter 1160] Gaussian 0 vs 1:
  Original Loss: 0.0048474
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048474 (Pseudo: 0.00%)
[Iter 1160] Gaussian 1 vs 0:
  Original Loss: 0.0050079
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0050079 (Pseudo: 0.00%)
[Iter 1170/20000] Loss: 0.0046799 (Best: 0.0040237 @iter1145) ([92m↓7.18%[0m) [1.86% of initial]
[Iter 1170] Gaussian 0 vs 1:
  Original Loss: 0.0044233
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044233 (Pseudo: 0.00%)
[Iter 1170] Gaussian 1 vs 0:
  Original Loss: 0.0044434
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044434 (Pseudo: 0.00%)
[Iter 1180/20000] Loss: 0.0043715 (Best: 0.0039724 @iter1180) ([92m↓6.59%[0m) [1.74% of initial]
[Iter 1180] Gaussian 0 vs 1:
  Original Loss: 0.0039724
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039724 (Pseudo: 0.00%)
[Iter 1180] Gaussian 1 vs 0:
  Original Loss: 0.0039913
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039913 (Pseudo: 0.00%)
[Iter 1190/20000] Loss: 0.0046370 (Best: 0.0039724 @iter1180) ([91m↑6.07%[0m) [1.84% of initial]
[Iter 1190] Gaussian 0 vs 1:
  Original Loss: 0.0044128
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044128 (Pseudo: 0.00%)
[Iter 1190] Gaussian 1 vs 0:
  Original Loss: 0.0043338
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043338 (Pseudo: 0.00%)
Iter:1199, L1 loss=0.003392, Total loss=0.004931, Time:14
[Iter 1200/20000] Loss: 0.0046300 (Best: 0.0038497 @iter1192) ([92m↓0.15%[0m) [1.84% of initial]
[Iter 1200] Gaussian 0 vs 1:
  Original Loss: 0.0046861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046861 (Pseudo: 0.00%)
[Iter 1200] Gaussian 1 vs 0:
  Original Loss: 0.0044913
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044913 (Pseudo: 0.00%)
[Iter 1210/20000] Loss: 0.0112805 (Best: 0.0038497 @iter1192) ([91m↑143.64%[0m) [4.48% of initial]
[Iter 1210] Gaussian 0 vs 1:
  Original Loss: 0.0102415
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0102415 (Pseudo: 0.00%)
[Iter 1210] Gaussian 1 vs 0:
  Original Loss: 0.0097431
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0097431 (Pseudo: 0.00%)
[Iter 1220/20000] Loss: 0.0069370 (Best: 0.0038497 @iter1192) ([92m↓38.50%[0m) [2.76% of initial]
[Iter 1220] Gaussian 0 vs 1:
  Original Loss: 0.0061284
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061284 (Pseudo: 0.00%)
[Iter 1220] Gaussian 1 vs 0:
  Original Loss: 0.0061501
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061501 (Pseudo: 0.00%)
[Iter 1230/20000] Loss: 0.0060462 (Best: 0.0038497 @iter1192) ([92m↓12.84%[0m) [2.40% of initial]
[Iter 1230] Gaussian 0 vs 1:
  Original Loss: 0.0064972
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0064972 (Pseudo: 0.00%)
[Iter 1230] Gaussian 1 vs 0:
  Original Loss: 0.0061536
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061536 (Pseudo: 0.00%)
[Iter 1240/20000] Loss: 0.0054401 (Best: 0.0038497 @iter1192) ([92m↓10.02%[0m) [2.16% of initial]
[Iter 1240] Gaussian 0 vs 1:
  Original Loss: 0.0055948
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0055948 (Pseudo: 0.00%)
[Iter 1240] Gaussian 1 vs 0:
  Original Loss: 0.0053289
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0053289 (Pseudo: 0.00%)
[Iter 1250/20000] Loss: 0.0047517 (Best: 0.0038497 @iter1192) ([92m↓12.65%[0m) [1.89% of initial]
[Iter 1250] Gaussian 0 vs 1:
  Original Loss: 0.0045857
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045857 (Pseudo: 0.00%)
[Iter 1250] Gaussian 1 vs 0:
  Original Loss: 0.0046398
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046398 (Pseudo: 0.00%)
[Iter 1260/20000] Loss: 0.0046090 (Best: 0.0037383 @iter1258) ([92m↓3.00%[0m) [1.83% of initial]
[Iter 1260] Gaussian 0 vs 1:
  Original Loss: 0.0051981
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0051981 (Pseudo: 0.00%)
[Iter 1260] Gaussian 1 vs 0:
  Original Loss: 0.0050528
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0050528 (Pseudo: 0.00%)
[Iter 1270/20000] Loss: 0.0041134 (Best: 0.0037324 @iter1269) ([92m↓10.75%[0m) [1.63% of initial]
[Iter 1270] Gaussian 0 vs 1:
  Original Loss: 0.0040533
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040533 (Pseudo: 0.00%)
[Iter 1270] Gaussian 1 vs 0:
  Original Loss: 0.0040810
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040810 (Pseudo: 0.00%)
[Iter 1280/20000] Loss: 0.0043556 (Best: 0.0033887 @iter1273) ([91m↑5.89%[0m) [1.73% of initial]
[Iter 1280] Gaussian 0 vs 1:
  Original Loss: 0.0042083
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0042083 (Pseudo: 0.00%)
[Iter 1280] Gaussian 1 vs 0:
  Original Loss: 0.0043291
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043291 (Pseudo: 0.00%)
[Iter 1290/20000] Loss: 0.0042341 (Best: 0.0033288 @iter1288) ([92m↓2.79%[0m) [1.68% of initial]
[Iter 1290] Gaussian 0 vs 1:
  Original Loss: 0.0047543
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047543 (Pseudo: 0.00%)
[Iter 1290] Gaussian 1 vs 0:
  Original Loss: 0.0047068
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047068 (Pseudo: 0.00%)
Iter:1299, L1 loss=0.002782, Total loss=0.003615, Time:13
[Iter 1300/20000] Loss: 0.0039849 (Best: 0.0033288 @iter1288) ([92m↓5.89%[0m) [1.58% of initial]
[Iter 1300] Gaussian 0 vs 1:
  Original Loss: 0.0039749
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039749 (Pseudo: 0.00%)
[Iter 1300] Gaussian 1 vs 0:
  Original Loss: 0.0041416
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0041416 (Pseudo: 0.00%)
[Iter 1310/20000] Loss: 0.0040037 (Best: 0.0033161 @iter1301) ([91m↑0.47%[0m) [1.59% of initial]
[Iter 1310] Gaussian 0 vs 1:
  Original Loss: 0.0037666
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037666 (Pseudo: 0.00%)
[Iter 1310] Gaussian 1 vs 0:
  Original Loss: 0.0038018
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038018 (Pseudo: 0.00%)
[Iter 1320/20000] Loss: 0.0038967 (Best: 0.0031011 @iter1319) ([92m↓2.67%[0m) [1.55% of initial]
[Iter 1320] Gaussian 0 vs 1:
  Original Loss: 0.0045494
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045494 (Pseudo: 0.00%)
[Iter 1320] Gaussian 1 vs 0:
  Original Loss: 0.0044507
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044507 (Pseudo: 0.00%)
[Iter 1330/20000] Loss: 0.0039666 (Best: 0.0030481 @iter1321) ([91m↑1.79%[0m) [1.58% of initial]
[Iter 1330] Gaussian 0 vs 1:
  Original Loss: 0.0041565
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0041565 (Pseudo: 0.00%)
[Iter 1330] Gaussian 1 vs 0:
  Original Loss: 0.0040524
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040524 (Pseudo: 0.00%)
[Iter 1340/20000] Loss: 0.0037236 (Best: 0.0030481 @iter1321) ([92m↓6.13%[0m) [1.48% of initial]
[Iter 1340] Gaussian 0 vs 1:
  Original Loss: 0.0033659
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0033659 (Pseudo: 0.00%)
[Iter 1340] Gaussian 1 vs 0:
  Original Loss: 0.0033322
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0033322 (Pseudo: 0.00%)
[Iter 1350/20000] Loss: 0.0037979 (Best: 0.0030481 @iter1321) ([91m↑2.00%[0m) [1.51% of initial]
[Iter 1350] Gaussian 0 vs 1:
  Original Loss: 0.0033737
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0033737 (Pseudo: 0.00%)
[Iter 1350] Gaussian 1 vs 0:
  Original Loss: 0.0032764
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032764 (Pseudo: 0.00%)
[Iter 1360/20000] Loss: 0.0038875 (Best: 0.0030481 @iter1321) ([91m↑2.36%[0m) [1.54% of initial]
[Iter 1360] Gaussian 0 vs 1:
  Original Loss: 0.0037958
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037958 (Pseudo: 0.00%)
[Iter 1360] Gaussian 1 vs 0:
  Original Loss: 0.0035427
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035427 (Pseudo: 0.00%)
[Iter 1370/20000] Loss: 0.0037024 (Best: 0.0030481 @iter1321) ([92m↓4.76%[0m) [1.47% of initial]
[Iter 1370] Gaussian 0 vs 1:
  Original Loss: 0.0032455
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032455 (Pseudo: 0.00%)
[Iter 1370] Gaussian 1 vs 0:
  Original Loss: 0.0031189
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031189 (Pseudo: 0.00%)
[Iter 1380/20000] Loss: 0.0039643 (Best: 0.0030481 @iter1321) ([91m↑7.07%[0m) [1.57% of initial]
[Iter 1380] Gaussian 0 vs 1:
  Original Loss: 0.0039208
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039208 (Pseudo: 0.00%)
[Iter 1380] Gaussian 1 vs 0:
  Original Loss: 0.0038356
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038356 (Pseudo: 0.00%)
[Iter 1390/20000] Loss: 0.0037643 (Best: 0.0030481 @iter1321) ([92m↓5.05%[0m) [1.50% of initial]
[Iter 1390] Gaussian 0 vs 1:
  Original Loss: 0.0036368
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0036368 (Pseudo: 0.00%)
[Iter 1390] Gaussian 1 vs 0:
  Original Loss: 0.0034566
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034566 (Pseudo: 0.00%)
Iter:1399, L1 loss=0.002266, Total loss=0.002966, Time:13
[Iter 1400/20000] Loss: 0.0034687 (Best: 0.0029658 @iter1399) ([92m↓7.85%[0m) [1.38% of initial]
[Iter 1400] Gaussian 0 vs 1:
  Original Loss: 0.0035717
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035717 (Pseudo: 0.00%)
[Iter 1400] Gaussian 1 vs 0:
  Original Loss: 0.0034101
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034101 (Pseudo: 0.00%)
[Iter 1410/20000] Loss: 0.0090176 (Best: 0.0029658 @iter1399) ([91m↑159.97%[0m) [3.58% of initial]
[Iter 1410] Gaussian 0 vs 1:
  Original Loss: 0.0087644
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087644 (Pseudo: 0.00%)
[Iter 1410] Gaussian 1 vs 0:
  Original Loss: 0.0085339
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0085339 (Pseudo: 0.00%)
[Iter 1420/20000] Loss: 0.0060504 (Best: 0.0029658 @iter1399) ([92m↓32.90%[0m) [2.40% of initial]
[Iter 1420] Gaussian 0 vs 1:
  Original Loss: 0.0057289
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057289 (Pseudo: 0.00%)
[Iter 1420] Gaussian 1 vs 0:
  Original Loss: 0.0056041
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0056041 (Pseudo: 0.00%)
[Iter 1430/20000] Loss: 0.0050223 (Best: 0.0029658 @iter1399) ([92m↓16.99%[0m) [2.00% of initial]
[Iter 1430] Gaussian 0 vs 1:
  Original Loss: 0.0043139
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043139 (Pseudo: 0.00%)
[Iter 1430] Gaussian 1 vs 0:
  Original Loss: 0.0043868
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043868 (Pseudo: 0.00%)
[Iter 1440/20000] Loss: 0.0044881 (Best: 0.0029658 @iter1399) ([92m↓10.64%[0m) [1.78% of initial]
[Iter 1440] Gaussian 0 vs 1:
  Original Loss: 0.0044477
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044477 (Pseudo: 0.00%)
[Iter 1440] Gaussian 1 vs 0:
  Original Loss: 0.0045174
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045174 (Pseudo: 0.00%)
[Iter 1450/20000] Loss: 0.0035636 (Best: 0.0029658 @iter1399) ([92m↓20.60%[0m) [1.42% of initial]
[Iter 1450] Gaussian 0 vs 1:
  Original Loss: 0.0031826
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031826 (Pseudo: 0.00%)
[Iter 1450] Gaussian 1 vs 0:
  Original Loss: 0.0031111
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031111 (Pseudo: 0.00%)
[Iter 1460/20000] Loss: 0.0036491 (Best: 0.0029658 @iter1399) ([91m↑2.40%[0m) [1.45% of initial]
[Iter 1460] Gaussian 0 vs 1:
  Original Loss: 0.0037542
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037542 (Pseudo: 0.00%)
[Iter 1460] Gaussian 1 vs 0:
  Original Loss: 0.0035345
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035345 (Pseudo: 0.00%)
[Iter 1470/20000] Loss: 0.0034877 (Best: 0.0029658 @iter1399) ([92m↓4.42%[0m) [1.39% of initial]
[Iter 1470] Gaussian 0 vs 1:
  Original Loss: 0.0031401
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031401 (Pseudo: 0.00%)
[Iter 1470] Gaussian 1 vs 0:
  Original Loss: 0.0030656
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0030656 (Pseudo: 0.00%)
[Iter 1480/20000] Loss: 0.0033352 (Best: 0.0027651 @iter1480) ([92m↓4.37%[0m) [1.33% of initial]
[Iter 1480] Gaussian 0 vs 1:
  Original Loss: 0.0027651
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027651 (Pseudo: 0.00%)
[Iter 1480] Gaussian 1 vs 0:
  Original Loss: 0.0027461
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027461 (Pseudo: 0.00%)
[Iter 1490/20000] Loss: 0.0032731 (Best: 0.0027651 @iter1480) ([92m↓1.86%[0m) [1.30% of initial]
[Iter 1490] Gaussian 0 vs 1:
  Original Loss: 0.0032476
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032476 (Pseudo: 0.00%)
[Iter 1490] Gaussian 1 vs 0:
  Original Loss: 0.0031494
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031494 (Pseudo: 0.00%)
Iter:1499, L1 loss=0.002505, Total loss=0.003348, Time:13
[Iter 1500/20000] Loss: 0.0032264 (Best: 0.0027651 @iter1480) ([92m↓1.43%[0m) [1.28% of initial]
[Iter 1500] Gaussian 0 vs 1:
  Original Loss: 0.0029305
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029305 (Pseudo: 0.00%)
[Iter 1500] Gaussian 1 vs 0:
  Original Loss: 0.0028685
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028685 (Pseudo: 0.00%)
[Iter 1510/20000] Loss: 0.0030767 (Best: 0.0025984 @iter1504) ([92m↓4.64%[0m) [1.22% of initial]
[Iter 1510] Gaussian 0 vs 1:
  Original Loss: 0.0027949
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027949 (Pseudo: 0.00%)
[Iter 1510] Gaussian 1 vs 0:
  Original Loss: 0.0027258
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027258 (Pseudo: 0.00%)
[Iter 1520/20000] Loss: 0.0030451 (Best: 0.0025810 @iter1520) ([92m↓1.03%[0m) [1.21% of initial]
[Iter 1520] Gaussian 0 vs 1:
  Original Loss: 0.0025810
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025810 (Pseudo: 0.00%)
[Iter 1520] Gaussian 1 vs 0:
  Original Loss: 0.0025351
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025351 (Pseudo: 0.00%)
[Iter 1530/20000] Loss: 0.0032258 (Best: 0.0025554 @iter1526) ([91m↑5.93%[0m) [1.28% of initial]
[Iter 1530] Gaussian 0 vs 1:
  Original Loss: 0.0032819
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032819 (Pseudo: 0.00%)
[Iter 1530] Gaussian 1 vs 0:
  Original Loss: 0.0031134
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031134 (Pseudo: 0.00%)
[Iter 1540/20000] Loss: 0.0031101 (Best: 0.0025554 @iter1526) ([92m↓3.59%[0m) [1.24% of initial]
[Iter 1540] Gaussian 0 vs 1:
  Original Loss: 0.0028985
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028985 (Pseudo: 0.00%)
[Iter 1540] Gaussian 1 vs 0:
  Original Loss: 0.0027851
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027851 (Pseudo: 0.00%)
[Iter 1550/20000] Loss: 0.0031275 (Best: 0.0025554 @iter1526) ([91m↑0.56%[0m) [1.24% of initial]
[Iter 1550] Gaussian 0 vs 1:
  Original Loss: 0.0030683
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0030683 (Pseudo: 0.00%)
[Iter 1550] Gaussian 1 vs 0:
  Original Loss: 0.0028907
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028907 (Pseudo: 0.00%)
[Iter 1560/20000] Loss: 0.0032943 (Best: 0.0025554 @iter1526) ([91m↑5.33%[0m) [1.31% of initial]
[Iter 1560] Gaussian 0 vs 1:
  Original Loss: 0.0038661
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038661 (Pseudo: 0.00%)
[Iter 1560] Gaussian 1 vs 0:
  Original Loss: 0.0038242
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038242 (Pseudo: 0.00%)
[Iter 1570/20000] Loss: 0.0028161 (Best: 0.0025457 @iter1569) ([92m↓14.52%[0m) [1.12% of initial]
[Iter 1570] Gaussian 0 vs 1:
  Original Loss: 0.0026708
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026708 (Pseudo: 0.00%)
[Iter 1570] Gaussian 1 vs 0:
  Original Loss: 0.0026786
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026786 (Pseudo: 0.00%)
[Iter 1580/20000] Loss: 0.0028547 (Best: 0.0023658 @iter1573) ([91m↑1.37%[0m) [1.13% of initial]
[Iter 1580] Gaussian 0 vs 1:
  Original Loss: 0.0029220
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029220 (Pseudo: 0.00%)
[Iter 1580] Gaussian 1 vs 0:
  Original Loss: 0.0029874
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029874 (Pseudo: 0.00%)
[Iter 1590/20000] Loss: 0.0027772 (Best: 0.0023658 @iter1573) ([92m↓2.72%[0m) [1.10% of initial]
[Iter 1590] Gaussian 0 vs 1:
  Original Loss: 0.0025625
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025625 (Pseudo: 0.00%)
[Iter 1590] Gaussian 1 vs 0:
  Original Loss: 0.0024796
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024796 (Pseudo: 0.00%)
Iter:1599, L1 loss=0.002648, Total loss=0.003395, Time:13
[Iter 1600/20000] Loss: 0.0030716 (Best: 0.0023415 @iter1591) ([91m↑10.60%[0m) [1.22% of initial]
[Iter 1600] Gaussian 0 vs 1:
  Original Loss: 0.0032684
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032684 (Pseudo: 0.00%)
[Iter 1600] Gaussian 1 vs 0:
  Original Loss: 0.0032044
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032044 (Pseudo: 0.00%)
[Iter 1610/20000] Loss: 0.0084165 (Best: 0.0023415 @iter1591) ([91m↑174.01%[0m) [3.34% of initial]
[Iter 1610] Gaussian 0 vs 1:
  Original Loss: 0.0072288
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0072288 (Pseudo: 0.00%)
[Iter 1610] Gaussian 1 vs 0:
  Original Loss: 0.0074115
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0074115 (Pseudo: 0.00%)
[Iter 1620/20000] Loss: 0.0054665 (Best: 0.0023415 @iter1591) ([92m↓35.05%[0m) [2.17% of initial]
[Iter 1620] Gaussian 0 vs 1:
  Original Loss: 0.0060430
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060430 (Pseudo: 0.00%)
[Iter 1620] Gaussian 1 vs 0:
  Original Loss: 0.0060418
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060418 (Pseudo: 0.00%)
[Iter 1630/20000] Loss: 0.0040720 (Best: 0.0023415 @iter1591) ([92m↓25.51%[0m) [1.62% of initial]
[Iter 1630] Gaussian 0 vs 1:
  Original Loss: 0.0035955
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035955 (Pseudo: 0.00%)
[Iter 1630] Gaussian 1 vs 0:
  Original Loss: 0.0035838
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035838 (Pseudo: 0.00%)
[Iter 1640/20000] Loss: 0.0038469 (Best: 0.0023415 @iter1591) ([92m↓5.53%[0m) [1.53% of initial]
[Iter 1640] Gaussian 0 vs 1:
  Original Loss: 0.0043440
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043440 (Pseudo: 0.00%)
[Iter 1640] Gaussian 1 vs 0:
  Original Loss: 0.0043648
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043648 (Pseudo: 0.00%)
[Iter 1650/20000] Loss: 0.0034028 (Best: 0.0023415 @iter1591) ([92m↓11.54%[0m) [1.35% of initial]
[Iter 1650] Gaussian 0 vs 1:
  Original Loss: 0.0034259
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034259 (Pseudo: 0.00%)
[Iter 1650] Gaussian 1 vs 0:
  Original Loss: 0.0034279
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034279 (Pseudo: 0.00%)
[Iter 1660/20000] Loss: 0.0029348 (Best: 0.0023415 @iter1591) ([92m↓13.75%[0m) [1.17% of initial]
[Iter 1660] Gaussian 0 vs 1:
  Original Loss: 0.0025539
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025539 (Pseudo: 0.00%)
[Iter 1660] Gaussian 1 vs 0:
  Original Loss: 0.0024665
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024665 (Pseudo: 0.00%)
[Iter 1670/20000] Loss: 0.0027250 (Best: 0.0022377 @iter1669) ([92m↓7.15%[0m) [1.08% of initial]
[Iter 1670] Gaussian 0 vs 1:
  Original Loss: 0.0027261
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027261 (Pseudo: 0.00%)
[Iter 1670] Gaussian 1 vs 0:
  Original Loss: 0.0027722
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027722 (Pseudo: 0.00%)
[Iter 1680/20000] Loss: 0.0029824 (Best: 0.0022377 @iter1669) ([91m↑9.45%[0m) [1.18% of initial]
[Iter 1680] Gaussian 0 vs 1:
  Original Loss: 0.0028817
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028817 (Pseudo: 0.00%)
[Iter 1680] Gaussian 1 vs 0:
  Original Loss: 0.0026041
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026041 (Pseudo: 0.00%)
[Iter 1690/20000] Loss: 0.0031696 (Best: 0.0022377 @iter1669) ([91m↑6.28%[0m) [1.26% of initial]
[Iter 1690] Gaussian 0 vs 1:
  Original Loss: 0.0029565
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029565 (Pseudo: 0.00%)
[Iter 1690] Gaussian 1 vs 0:
  Original Loss: 0.0027443
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027443 (Pseudo: 0.00%)
Iter:1699, L1 loss=0.002619, Total loss=0.003281, Time:13
[Iter 1700/20000] Loss: 0.0028313 (Best: 0.0022377 @iter1669) ([92m↓10.67%[0m) [1.12% of initial]
[Iter 1700] Gaussian 0 vs 1:
  Original Loss: 0.0024241
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024241 (Pseudo: 0.00%)
[Iter 1700] Gaussian 1 vs 0:
  Original Loss: 0.0023661
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023661 (Pseudo: 0.00%)
[Iter 1710/20000] Loss: 0.0030485 (Best: 0.0022377 @iter1669) ([91m↑7.67%[0m) [1.21% of initial]
[Iter 1710] Gaussian 0 vs 1:
  Original Loss: 0.0031695
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031695 (Pseudo: 0.00%)
[Iter 1710] Gaussian 1 vs 0:
  Original Loss: 0.0031918
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031918 (Pseudo: 0.00%)
[Iter 1720/20000] Loss: 0.0025166 (Best: 0.0022377 @iter1669) ([92m↓17.45%[0m) [1.00% of initial]
[Iter 1720] Gaussian 0 vs 1:
  Original Loss: 0.0022935
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022935 (Pseudo: 0.00%)
[Iter 1720] Gaussian 1 vs 0:
  Original Loss: 0.0022894
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022894 (Pseudo: 0.00%)
[Iter 1730/20000] Loss: 0.0025801 (Best: 0.0022285 @iter1726) ([91m↑2.52%[0m) [1.03% of initial]
[Iter 1730] Gaussian 0 vs 1:
  Original Loss: 0.0023047
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023047 (Pseudo: 0.00%)
[Iter 1730] Gaussian 1 vs 0:
  Original Loss: 0.0022506
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022506 (Pseudo: 0.00%)
[Iter 1740/20000] Loss: 0.0024981 (Best: 0.0021822 @iter1738) ([92m↓3.18%[0m) [0.99% of initial]
[Iter 1740] Gaussian 0 vs 1:
  Original Loss: 0.0023131
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023131 (Pseudo: 0.00%)
[Iter 1740] Gaussian 1 vs 0:
  Original Loss: 0.0022769
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022769 (Pseudo: 0.00%)
[Iter 1750/20000] Loss: 0.0023554 (Best: 0.0020337 @iter1742) ([92m↓5.71%[0m) [0.94% of initial]
[Iter 1750] Gaussian 0 vs 1:
  Original Loss: 0.0020960
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020960 (Pseudo: 0.00%)
[Iter 1750] Gaussian 1 vs 0:
  Original Loss: 0.0020044
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020044 (Pseudo: 0.00%)
[Iter 1760/20000] Loss: 0.0027007 (Best: 0.0020337 @iter1742) ([91m↑14.66%[0m) [1.07% of initial]
[Iter 1760] Gaussian 0 vs 1:
  Original Loss: 0.0026516
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026516 (Pseudo: 0.00%)
[Iter 1760] Gaussian 1 vs 0:
  Original Loss: 0.0024420
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024420 (Pseudo: 0.00%)
[Iter 1770/20000] Loss: 0.0024499 (Best: 0.0020337 @iter1742) ([92m↓9.29%[0m) [0.97% of initial]
[Iter 1770] Gaussian 0 vs 1:
  Original Loss: 0.0024179
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024179 (Pseudo: 0.00%)
[Iter 1770] Gaussian 1 vs 0:
  Original Loss: 0.0023375
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023375 (Pseudo: 0.00%)
[Iter 1780/20000] Loss: 0.0024942 (Best: 0.0020337 @iter1742) ([91m↑1.81%[0m) [0.99% of initial]
[Iter 1780] Gaussian 0 vs 1:
  Original Loss: 0.0026557
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026557 (Pseudo: 0.00%)
[Iter 1780] Gaussian 1 vs 0:
  Original Loss: 0.0026901
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026901 (Pseudo: 0.00%)
[Iter 1790/20000] Loss: 0.0021947 (Best: 0.0017947 @iter1789) ([92m↓12.01%[0m) [0.87% of initial]
[Iter 1790] Gaussian 0 vs 1:
  Original Loss: 0.0022580
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022580 (Pseudo: 0.00%)
[Iter 1790] Gaussian 1 vs 0:
  Original Loss: 0.0021683
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021683 (Pseudo: 0.00%)
Iter:1799, L1 loss=0.001658, Total loss=0.001923, Time:13
[Iter 1800/20000] Loss: 0.0022046 (Best: 0.0017947 @iter1789) ([91m↑0.45%[0m) [0.88% of initial]
[Iter 1800] Gaussian 0 vs 1:
  Original Loss: 0.0021755
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021755 (Pseudo: 0.00%)
[Iter 1800] Gaussian 1 vs 0:
  Original Loss: 0.0021331
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021331 (Pseudo: 0.00%)
[Iter 1810/20000] Loss: 0.0074789 (Best: 0.0017947 @iter1789) ([91m↑239.25%[0m) [2.97% of initial]
[Iter 1810] Gaussian 0 vs 1:
  Original Loss: 0.0066157
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066157 (Pseudo: 0.00%)
[Iter 1810] Gaussian 1 vs 0:
  Original Loss: 0.0069806
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069806 (Pseudo: 0.00%)
[Iter 1820/20000] Loss: 0.0043898 (Best: 0.0017947 @iter1789) ([92m↓41.30%[0m) [1.74% of initial]
[Iter 1820] Gaussian 0 vs 1:
  Original Loss: 0.0044454
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044454 (Pseudo: 0.00%)
[Iter 1820] Gaussian 1 vs 0:
  Original Loss: 0.0046795
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046795 (Pseudo: 0.00%)
[Iter 1830/20000] Loss: 0.0039609 (Best: 0.0017947 @iter1789) ([92m↓9.77%[0m) [1.57% of initial]
[Iter 1830] Gaussian 0 vs 1:
  Original Loss: 0.0038922
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038922 (Pseudo: 0.00%)
[Iter 1830] Gaussian 1 vs 0:
  Original Loss: 0.0036706
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0036706 (Pseudo: 0.00%)
[Iter 1840/20000] Loss: 0.0027439 (Best: 0.0017947 @iter1789) ([92m↓30.73%[0m) [1.09% of initial]
[Iter 1840] Gaussian 0 vs 1:
  Original Loss: 0.0023904
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023904 (Pseudo: 0.00%)
[Iter 1840] Gaussian 1 vs 0:
  Original Loss: 0.0023449
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023449 (Pseudo: 0.00%)
[Iter 1850/20000] Loss: 0.0026190 (Best: 0.0017947 @iter1789) ([92m↓4.55%[0m) [1.04% of initial]
[Iter 1850] Gaussian 0 vs 1:
  Original Loss: 0.0023982
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023982 (Pseudo: 0.00%)
[Iter 1850] Gaussian 1 vs 0:
  Original Loss: 0.0023577
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023577 (Pseudo: 0.00%)
[Iter 1860/20000] Loss: 0.0023776 (Best: 0.0017947 @iter1789) ([92m↓9.22%[0m) [0.94% of initial]
[Iter 1860] Gaussian 0 vs 1:
  Original Loss: 0.0021776
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021776 (Pseudo: 0.00%)
[Iter 1860] Gaussian 1 vs 0:
  Original Loss: 0.0021057
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021057 (Pseudo: 0.00%)
[Iter 1870/20000] Loss: 0.0022259 (Best: 0.0017947 @iter1789) ([92m↓6.38%[0m) [0.88% of initial]
[Iter 1870] Gaussian 0 vs 1:
  Original Loss: 0.0020362
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020362 (Pseudo: 0.00%)
[Iter 1870] Gaussian 1 vs 0:
  Original Loss: 0.0019076
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019076 (Pseudo: 0.00%)
[Iter 1880/20000] Loss: 0.0021042 (Best: 0.0017947 @iter1789) ([92m↓5.47%[0m) [0.84% of initial]
[Iter 1880] Gaussian 0 vs 1:
  Original Loss: 0.0018354
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018354 (Pseudo: 0.00%)
[Iter 1880] Gaussian 1 vs 0:
  Original Loss: 0.0017910
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017910 (Pseudo: 0.00%)
[Iter 1890/20000] Loss: 0.0019212 (Best: 0.0017709 @iter1890) ([92m↓8.70%[0m) [0.76% of initial]
[Iter 1890] Gaussian 0 vs 1:
  Original Loss: 0.0017709
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017709 (Pseudo: 0.00%)
[Iter 1890] Gaussian 1 vs 0:
  Original Loss: 0.0016648
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016648 (Pseudo: 0.00%)
Iter:1899, L1 loss=0.001697, Total loss=0.001929, Time:14
[Iter 1900/20000] Loss: 0.0019956 (Best: 0.0016208 @iter1891) ([91m↑3.87%[0m) [0.79% of initial]
[Iter 1900] Gaussian 0 vs 1:
  Original Loss: 0.0018667
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018667 (Pseudo: 0.00%)
[Iter 1900] Gaussian 1 vs 0:
  Original Loss: 0.0017981
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017981 (Pseudo: 0.00%)
[Iter 1910/20000] Loss: 0.0020840 (Best: 0.0016208 @iter1891) ([91m↑4.43%[0m) [0.83% of initial]
[Iter 1910] Gaussian 0 vs 1:
  Original Loss: 0.0018534
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018534 (Pseudo: 0.00%)
[Iter 1910] Gaussian 1 vs 0:
  Original Loss: 0.0017633
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017633 (Pseudo: 0.00%)
[Iter 1920/20000] Loss: 0.0021427 (Best: 0.0016208 @iter1891) ([91m↑2.81%[0m) [0.85% of initial]
[Iter 1920] Gaussian 0 vs 1:
  Original Loss: 0.0021793
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021793 (Pseudo: 0.00%)
[Iter 1920] Gaussian 1 vs 0:
  Original Loss: 0.0020639
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020639 (Pseudo: 0.00%)
[Iter 1930/20000] Loss: 0.0017447 (Best: 0.0015654 @iter1930) ([92m↓18.57%[0m) [0.69% of initial]
[Iter 1930] Gaussian 0 vs 1:
  Original Loss: 0.0015654
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015654 (Pseudo: 0.00%)
[Iter 1930] Gaussian 1 vs 0:
  Original Loss: 0.0015368
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015368 (Pseudo: 0.00%)
[Iter 1940/20000] Loss: 0.0019357 (Best: 0.0015609 @iter1939) ([91m↑10.95%[0m) [0.77% of initial]
[Iter 1940] Gaussian 0 vs 1:
  Original Loss: 0.0020470
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020470 (Pseudo: 0.00%)
[Iter 1940] Gaussian 1 vs 0:
  Original Loss: 0.0019336
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019336 (Pseudo: 0.00%)
[Iter 1950/20000] Loss: 0.0020685 (Best: 0.0015609 @iter1939) ([91m↑6.86%[0m) [0.82% of initial]
[Iter 1950] Gaussian 0 vs 1:
  Original Loss: 0.0019119
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019119 (Pseudo: 0.00%)
[Iter 1950] Gaussian 1 vs 0:
  Original Loss: 0.0018449
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018449 (Pseudo: 0.00%)
[Iter 1960/20000] Loss: 0.0018813 (Best: 0.0015609 @iter1939) ([92m↓9.05%[0m) [0.75% of initial]
[Iter 1960] Gaussian 0 vs 1:
  Original Loss: 0.0017665
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017665 (Pseudo: 0.00%)
[Iter 1960] Gaussian 1 vs 0:
  Original Loss: 0.0017198
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017198 (Pseudo: 0.00%)
[Iter 1970/20000] Loss: 0.0017058 (Best: 0.0015387 @iter1963) ([92m↓9.33%[0m) [0.68% of initial]
[Iter 1970] Gaussian 0 vs 1:
  Original Loss: 0.0016120
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016120 (Pseudo: 0.00%)
[Iter 1970] Gaussian 1 vs 0:
  Original Loss: 0.0015693
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015693 (Pseudo: 0.00%)
[Iter 1980/20000] Loss: 0.0020655 (Best: 0.0015387 @iter1963) ([91m↑21.09%[0m) [0.82% of initial]
[Iter 1980] Gaussian 0 vs 1:
  Original Loss: 0.0024446
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024446 (Pseudo: 0.00%)
[Iter 1980] Gaussian 1 vs 0:
  Original Loss: 0.0024964
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024964 (Pseudo: 0.00%)
[Iter 1990/20000] Loss: 0.0018055 (Best: 0.0015387 @iter1963) ([92m↓12.59%[0m) [0.72% of initial]
[Iter 1990] Gaussian 0 vs 1:
  Original Loss: 0.0016504
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016504 (Pseudo: 0.00%)
[Iter 1990] Gaussian 1 vs 0:
  Original Loss: 0.0016081
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016081 (Pseudo: 0.00%)
Iter:1999, L1 loss=0.001507, Total loss=0.001784, Time:14
[Iter 2000/20000] Loss: 0.0019725 (Best: 0.0014723 @iter1996) ([91m↑9.25%[0m) [0.78% of initial]
Testing Speed: 235.2639207362767 fps
Testing Time: 0.21252727508544922 s

[ITER 2000] Evaluating test: SSIM = 0.851223840713501, PSNR = 17.758567562103273
Testing Speed: 269.97901602763534 fps
Testing Time: 0.011111974716186523 s

[ITER 2000] Evaluating train: SSIM = 0.9999455213546753, PSNR = 48.286462148030594
Iter:2000, total_points:42564
[Iter 2000] Gaussian 0 vs 1:
  Original Loss: 0.0021198
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021198 (Pseudo: 0.00%)
[Iter 2000] Gaussian 1 vs 0:
  Original Loss: 0.0021146
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021146 (Pseudo: 0.00%)
[Iter 2010/20000] Loss: 0.0068103 (Best: 0.0014723 @iter1996) ([91m↑245.26%[0m) [2.71% of initial]
[Iter 2010] Gaussian 0 vs 1:
  Original Loss: 0.0062222
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062222 (Pseudo: 0.00%)
[Iter 2010] Gaussian 1 vs 0:
  Original Loss: 0.0060457
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060457 (Pseudo: 0.00%)
[Iter 2020/20000] Loss: 0.0036691 (Best: 0.0014723 @iter1996) ([92m↓46.12%[0m) [1.46% of initial]
[Iter 2020] Gaussian 0 vs 1:
  Original Loss: 0.0032271
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032271 (Pseudo: 0.00%)
[Iter 2020] Gaussian 1 vs 0:
  Original Loss: 0.0031352
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031352 (Pseudo: 0.00%)
[Iter 2030/20000] Loss: 0.0028172 (Best: 0.0014723 @iter1996) ([92m↓23.22%[0m) [1.12% of initial]
[Iter 2030] Gaussian 0 vs 1:
  Original Loss: 0.0025100
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025100 (Pseudo: 0.00%)
[Iter 2030] Gaussian 1 vs 0:
  Original Loss: 0.0024845
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024845 (Pseudo: 0.00%)
[Iter 2040/20000] Loss: 0.0024673 (Best: 0.0014723 @iter1996) ([92m↓12.42%[0m) [0.98% of initial]
[Iter 2040] Gaussian 0 vs 1:
  Original Loss: 0.0027615
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027615 (Pseudo: 0.00%)
[Iter 2040] Gaussian 1 vs 0:
  Original Loss: 0.0027948
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027948 (Pseudo: 0.00%)
[Iter 2050/20000] Loss: 0.0020627 (Best: 0.0014723 @iter1996) ([92m↓16.40%[0m) [0.82% of initial]
[Iter 2050] Gaussian 0 vs 1:
  Original Loss: 0.0017278
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017278 (Pseudo: 0.00%)
[Iter 2050] Gaussian 1 vs 0:
  Original Loss: 0.0016704
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016704 (Pseudo: 0.00%)
[Iter 2060/20000] Loss: 0.0017035 (Best: 0.0014723 @iter1996) ([92m↓17.42%[0m) [0.68% of initial]
[Iter 2060] Gaussian 0 vs 1:
  Original Loss: 0.0015296
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015296 (Pseudo: 0.00%)
[Iter 2060] Gaussian 1 vs 0:
  Original Loss: 0.0015117
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015117 (Pseudo: 0.00%)
[Iter 2070/20000] Loss: 0.0019892 (Best: 0.0014723 @iter1996) ([91m↑16.77%[0m) [0.79% of initial]
[Iter 2070] Gaussian 0 vs 1:
  Original Loss: 0.0022155
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022155 (Pseudo: 0.00%)
[Iter 2070] Gaussian 1 vs 0:
  Original Loss: 0.0022722
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022722 (Pseudo: 0.00%)
[Iter 2080/20000] Loss: 0.0018927 (Best: 0.0014723 @iter1996) ([92m↓4.85%[0m) [0.75% of initial]
[Iter 2080] Gaussian 0 vs 1:
  Original Loss: 0.0021175
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021175 (Pseudo: 0.00%)
[Iter 2080] Gaussian 1 vs 0:
  Original Loss: 0.0021208
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021208 (Pseudo: 0.00%)
[Iter 2090/20000] Loss: 0.0018186 (Best: 0.0013622 @iter2089) ([92m↓3.91%[0m) [0.72% of initial]
[Iter 2090] Gaussian 0 vs 1:
  Original Loss: 0.0020783
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020783 (Pseudo: 0.00%)
[Iter 2090] Gaussian 1 vs 0:
  Original Loss: 0.0021429
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021429 (Pseudo: 0.00%)
Iter:2099, L1 loss=0.00155, Total loss=0.001656, Time:15
[Iter 2100/20000] Loss: 0.0016712 (Best: 0.0013622 @iter2089) ([92m↓8.10%[0m) [0.66% of initial]
[Iter 2100] Gaussian 0 vs 1:
  Original Loss: 0.0015762
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015762 (Pseudo: 0.00%)
[Iter 2100] Gaussian 1 vs 0:
  Original Loss: 0.0015346
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015346 (Pseudo: 0.00%)
[Iter 2110/20000] Loss: 0.0015717 (Best: 0.0013622 @iter2089) ([92m↓5.96%[0m) [0.62% of initial]
[Iter 2110] Gaussian 0 vs 1:
  Original Loss: 0.0014118
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014118 (Pseudo: 0.00%)
[Iter 2110] Gaussian 1 vs 0:
  Original Loss: 0.0014029
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014029 (Pseudo: 0.00%)
[Iter 2120/20000] Loss: 0.0014321 (Best: 0.0013046 @iter2120) ([92m↓8.88%[0m) [0.57% of initial]
[Iter 2120] Gaussian 0 vs 1:
  Original Loss: 0.0013046
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013046 (Pseudo: 0.00%)
[Iter 2120] Gaussian 1 vs 0:
  Original Loss: 0.0012475
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012475 (Pseudo: 0.00%)
[Iter 2130/20000] Loss: 0.0015624 (Best: 0.0012257 @iter2125) ([91m↑9.09%[0m) [0.62% of initial]
[Iter 2130] Gaussian 0 vs 1:
  Original Loss: 0.0015977
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015977 (Pseudo: 0.00%)
[Iter 2130] Gaussian 1 vs 0:
  Original Loss: 0.0014893
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014893 (Pseudo: 0.00%)
[Iter 2140/20000] Loss: 0.0017188 (Best: 0.0012257 @iter2125) ([91m↑10.01%[0m) [0.68% of initial]
[Iter 2140] Gaussian 0 vs 1:
  Original Loss: 0.0018861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018861 (Pseudo: 0.00%)
[Iter 2140] Gaussian 1 vs 0:
  Original Loss: 0.0018611
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018611 (Pseudo: 0.00%)
[Iter 2150/20000] Loss: 0.0017398 (Best: 0.0012257 @iter2125) ([91m↑1.22%[0m) [0.69% of initial]
[Iter 2150] Gaussian 0 vs 1:
  Original Loss: 0.0014850
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014850 (Pseudo: 0.00%)
[Iter 2150] Gaussian 1 vs 0:
  Original Loss: 0.0014952
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014952 (Pseudo: 0.00%)
[Iter 2160/20000] Loss: 0.0015560 (Best: 0.0012257 @iter2125) ([92m↓10.56%[0m) [0.62% of initial]
[Iter 2160] Gaussian 0 vs 1:
  Original Loss: 0.0013665
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013665 (Pseudo: 0.00%)
[Iter 2160] Gaussian 1 vs 0:
  Original Loss: 0.0013760
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013760 (Pseudo: 0.00%)
[Iter 2170/20000] Loss: 0.0016294 (Best: 0.0012257 @iter2125) ([91m↑4.71%[0m) [0.65% of initial]
[Iter 2170] Gaussian 0 vs 1:
  Original Loss: 0.0017304
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017304 (Pseudo: 0.00%)
[Iter 2170] Gaussian 1 vs 0:
  Original Loss: 0.0017111
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017111 (Pseudo: 0.00%)
[Iter 2180/20000] Loss: 0.0013234 (Best: 0.0012106 @iter2180) ([92m↓18.78%[0m) [0.53% of initial]
[Iter 2180] Gaussian 0 vs 1:
  Original Loss: 0.0012106
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012106 (Pseudo: 0.00%)
[Iter 2180] Gaussian 1 vs 0:
  Original Loss: 0.0011913
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011913 (Pseudo: 0.00%)
[Iter 2190/20000] Loss: 0.0016171 (Best: 0.0012106 @iter2180) ([91m↑22.20%[0m) [0.64% of initial]
[Iter 2190] Gaussian 0 vs 1:
  Original Loss: 0.0019078
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019078 (Pseudo: 0.00%)
[Iter 2190] Gaussian 1 vs 0:
  Original Loss: 0.0019355
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019355 (Pseudo: 0.00%)
Iter:2199, L1 loss=0.001395, Total loss=0.001526, Time:16
[Iter 2200/20000] Loss: 0.0016219 (Best: 0.0012106 @iter2180) ([91m↑0.30%[0m) [0.64% of initial]
[Iter 2200] Gaussian 0 vs 1:
  Original Loss: 0.0017914
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017914 (Pseudo: 0.00%)
[Iter 2200] Gaussian 1 vs 0:
  Original Loss: 0.0018305
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018305 (Pseudo: 0.00%)
[Iter 2210/20000] Loss: 0.0077354 (Best: 0.0012106 @iter2180) ([91m↑376.92%[0m) [3.07% of initial]
[Iter 2210] Gaussian 0 vs 1:
  Original Loss: 0.0075031
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0075031 (Pseudo: 0.00%)
[Iter 2210] Gaussian 1 vs 0:
  Original Loss: 0.0072677
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0072677 (Pseudo: 0.00%)
[Iter 2220/20000] Loss: 0.0042164 (Best: 0.0012106 @iter2180) ([92m↓45.49%[0m) [1.68% of initial]
[Iter 2220] Gaussian 0 vs 1:
  Original Loss: 0.0037695
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037695 (Pseudo: 0.00%)
[Iter 2220] Gaussian 1 vs 0:
  Original Loss: 0.0037385
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037385 (Pseudo: 0.00%)
[Iter 2230/20000] Loss: 0.0026705 (Best: 0.0012106 @iter2180) ([92m↓36.66%[0m) [1.06% of initial]
[Iter 2230] Gaussian 0 vs 1:
  Original Loss: 0.0022750
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022750 (Pseudo: 0.00%)
[Iter 2230] Gaussian 1 vs 0:
  Original Loss: 0.0022484
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022484 (Pseudo: 0.00%)
[Iter 2240/20000] Loss: 0.0023042 (Best: 0.0012106 @iter2180) ([92m↓13.72%[0m) [0.92% of initial]
[Iter 2240] Gaussian 0 vs 1:
  Original Loss: 0.0021141
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021141 (Pseudo: 0.00%)
[Iter 2240] Gaussian 1 vs 0:
  Original Loss: 0.0020571
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020571 (Pseudo: 0.00%)
[Iter 2250/20000] Loss: 0.0021345 (Best: 0.0012106 @iter2180) ([92m↓7.37%[0m) [0.85% of initial]
[Iter 2250] Gaussian 0 vs 1:
  Original Loss: 0.0023109
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023109 (Pseudo: 0.00%)
[Iter 2250] Gaussian 1 vs 0:
  Original Loss: 0.0022848
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022848 (Pseudo: 0.00%)
[Iter 2260/20000] Loss: 0.0016966 (Best: 0.0012106 @iter2180) ([92m↓20.51%[0m) [0.67% of initial]
[Iter 2260] Gaussian 0 vs 1:
  Original Loss: 0.0015034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015034 (Pseudo: 0.00%)
[Iter 2260] Gaussian 1 vs 0:
  Original Loss: 0.0014815
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014815 (Pseudo: 0.00%)
[Iter 2270/20000] Loss: 0.0017942 (Best: 0.0012106 @iter2180) ([91m↑5.75%[0m) [0.71% of initial]
[Iter 2270] Gaussian 0 vs 1:
  Original Loss: 0.0020060
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020060 (Pseudo: 0.00%)
[Iter 2270] Gaussian 1 vs 0:
  Original Loss: 0.0019895
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019895 (Pseudo: 0.00%)
[Iter 2280/20000] Loss: 0.0014482 (Best: 0.0012106 @iter2180) ([92m↓19.28%[0m) [0.58% of initial]
[Iter 2280] Gaussian 0 vs 1:
  Original Loss: 0.0013402
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013402 (Pseudo: 0.00%)
[Iter 2280] Gaussian 1 vs 0:
  Original Loss: 0.0013338
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013338 (Pseudo: 0.00%)
[Iter 2290/20000] Loss: 0.0013923 (Best: 0.0011823 @iter2287) ([92m↓3.86%[0m) [0.55% of initial]
[Iter 2290] Gaussian 0 vs 1:
  Original Loss: 0.0012570
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012570 (Pseudo: 0.00%)
[Iter 2290] Gaussian 1 vs 0:
  Original Loss: 0.0012375
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012375 (Pseudo: 0.00%)
Iter:2299, L1 loss=0.001392, Total loss=0.0014, Time:17
[Iter 2300/20000] Loss: 0.0016849 (Best: 0.0011823 @iter2287) ([91m↑21.02%[0m) [0.67% of initial]
[Iter 2300] Gaussian 0 vs 1:
  Original Loss: 0.0018119
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018119 (Pseudo: 0.00%)
[Iter 2300] Gaussian 1 vs 0:
  Original Loss: 0.0018945
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018945 (Pseudo: 0.00%)
[Iter 2310/20000] Loss: 0.0015445 (Best: 0.0011823 @iter2287) ([92m↓8.34%[0m) [0.61% of initial]
[Iter 2310] Gaussian 0 vs 1:
  Original Loss: 0.0015288
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015288 (Pseudo: 0.00%)
[Iter 2310] Gaussian 1 vs 0:
  Original Loss: 0.0014970
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014970 (Pseudo: 0.00%)
[Iter 2320/20000] Loss: 0.0013208 (Best: 0.0011823 @iter2287) ([92m↓14.48%[0m) [0.52% of initial]
[Iter 2320] Gaussian 0 vs 1:
  Original Loss: 0.0011849
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011849 (Pseudo: 0.00%)
[Iter 2320] Gaussian 1 vs 0:
  Original Loss: 0.0012192
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012192 (Pseudo: 0.00%)
[Iter 2330/20000] Loss: 0.0013487 (Best: 0.0011553 @iter2327) ([91m↑2.11%[0m) [0.54% of initial]
[Iter 2330] Gaussian 0 vs 1:
  Original Loss: 0.0013315
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013315 (Pseudo: 0.00%)
[Iter 2330] Gaussian 1 vs 0:
  Original Loss: 0.0012790
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012790 (Pseudo: 0.00%)
[Iter 2340/20000] Loss: 0.0013611 (Best: 0.0010960 @iter2338) ([91m↑0.92%[0m) [0.54% of initial]
[Iter 2340] Gaussian 0 vs 1:
  Original Loss: 0.0012546
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012546 (Pseudo: 0.00%)
[Iter 2340] Gaussian 1 vs 0:
  Original Loss: 0.0012285
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012285 (Pseudo: 0.00%)
[Iter 2350/20000] Loss: 0.0015030 (Best: 0.0010960 @iter2338) ([91m↑10.42%[0m) [0.60% of initial]
[Iter 2350] Gaussian 0 vs 1:
  Original Loss: 0.0014497
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014497 (Pseudo: 0.00%)
[Iter 2350] Gaussian 1 vs 0:
  Original Loss: 0.0014125
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014125 (Pseudo: 0.00%)
[Iter 2360/20000] Loss: 0.0012858 (Best: 0.0010960 @iter2338) ([92m↓14.45%[0m) [0.51% of initial]
[Iter 2360] Gaussian 0 vs 1:
  Original Loss: 0.0013139
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013139 (Pseudo: 0.00%)
[Iter 2360] Gaussian 1 vs 0:
  Original Loss: 0.0012944
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012944 (Pseudo: 0.00%)
[Iter 2370/20000] Loss: 0.0014347 (Best: 0.0010960 @iter2338) ([91m↑11.58%[0m) [0.57% of initial]
[Iter 2370] Gaussian 0 vs 1:
  Original Loss: 0.0012622
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012622 (Pseudo: 0.00%)
[Iter 2370] Gaussian 1 vs 0:
  Original Loss: 0.0011911
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011911 (Pseudo: 0.00%)
[Iter 2380/20000] Loss: 0.0014792 (Best: 0.0010960 @iter2338) ([91m↑3.10%[0m) [0.59% of initial]
[Iter 2380] Gaussian 0 vs 1:
  Original Loss: 0.0016159
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016159 (Pseudo: 0.00%)
[Iter 2380] Gaussian 1 vs 0:
  Original Loss: 0.0016105
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016105 (Pseudo: 0.00%)
[Iter 2390/20000] Loss: 0.0016021 (Best: 0.0010960 @iter2338) ([91m↑8.30%[0m) [0.64% of initial]
[Iter 2390] Gaussian 0 vs 1:
  Original Loss: 0.0018050
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018050 (Pseudo: 0.00%)
[Iter 2390] Gaussian 1 vs 0:
  Original Loss: 0.0017708
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017708 (Pseudo: 0.00%)
Iter:2399, L1 loss=0.001198, Total loss=0.001263, Time:17
[Iter 2400/20000] Loss: 0.0013135 (Best: 0.0010960 @iter2338) ([92m↓18.01%[0m) [0.52% of initial]
[Iter 2400] Gaussian 0 vs 1:
  Original Loss: 0.0011973
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011973 (Pseudo: 0.00%)
[Iter 2400] Gaussian 1 vs 0:
  Original Loss: 0.0013144
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013144 (Pseudo: 0.00%)
[Iter 2410/20000] Loss: 0.0061524 (Best: 0.0010960 @iter2338) ([91m↑368.39%[0m) [2.44% of initial]
[Iter 2410] Gaussian 0 vs 1:
  Original Loss: 0.0052609
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0052609 (Pseudo: 0.00%)
[Iter 2410] Gaussian 1 vs 0:
  Original Loss: 0.0049266
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049266 (Pseudo: 0.00%)
[Iter 2420/20000] Loss: 0.0035401 (Best: 0.0010960 @iter2338) ([92m↓42.46%[0m) [1.41% of initial]
[Iter 2420] Gaussian 0 vs 1:
  Original Loss: 0.0029951
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029951 (Pseudo: 0.00%)
[Iter 2420] Gaussian 1 vs 0:
  Original Loss: 0.0028760
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028760 (Pseudo: 0.00%)
[Iter 2430/20000] Loss: 0.0025813 (Best: 0.0010960 @iter2338) ([92m↓27.08%[0m) [1.03% of initial]
[Iter 2430] Gaussian 0 vs 1:
  Original Loss: 0.0026477
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026477 (Pseudo: 0.00%)
[Iter 2430] Gaussian 1 vs 0:
  Original Loss: 0.0028132
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028132 (Pseudo: 0.00%)
[Iter 2440/20000] Loss: 0.0020488 (Best: 0.0010960 @iter2338) ([92m↓20.63%[0m) [0.81% of initial]
[Iter 2440] Gaussian 0 vs 1:
  Original Loss: 0.0017777
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017777 (Pseudo: 0.00%)
[Iter 2440] Gaussian 1 vs 0:
  Original Loss: 0.0017036
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017036 (Pseudo: 0.00%)
[Iter 2450/20000] Loss: 0.0019562 (Best: 0.0010960 @iter2338) ([92m↓4.52%[0m) [0.78% of initial]
[Iter 2450] Gaussian 0 vs 1:
  Original Loss: 0.0020311
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020311 (Pseudo: 0.00%)
[Iter 2450] Gaussian 1 vs 0:
  Original Loss: 0.0021307
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021307 (Pseudo: 0.00%)
[Iter 2460/20000] Loss: 0.0016487 (Best: 0.0010960 @iter2338) ([92m↓15.72%[0m) [0.66% of initial]
[Iter 2460] Gaussian 0 vs 1:
  Original Loss: 0.0014915
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014915 (Pseudo: 0.00%)
[Iter 2460] Gaussian 1 vs 0:
  Original Loss: 0.0015004
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015004 (Pseudo: 0.00%)
[Iter 2470/20000] Loss: 0.0016327 (Best: 0.0010960 @iter2338) ([92m↓0.97%[0m) [0.65% of initial]
[Iter 2470] Gaussian 0 vs 1:
  Original Loss: 0.0016538
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016538 (Pseudo: 0.00%)
[Iter 2470] Gaussian 1 vs 0:
  Original Loss: 0.0017107
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017107 (Pseudo: 0.00%)
[Iter 2480/20000] Loss: 0.0016395 (Best: 0.0010960 @iter2338) ([91m↑0.41%[0m) [0.65% of initial]
[Iter 2480] Gaussian 0 vs 1:
  Original Loss: 0.0014431
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014431 (Pseudo: 0.00%)
[Iter 2480] Gaussian 1 vs 0:
  Original Loss: 0.0014340
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014340 (Pseudo: 0.00%)
[Iter 2490/20000] Loss: 0.0014592 (Best: 0.0010960 @iter2338) ([92m↓10.99%[0m) [0.58% of initial]
[Iter 2490] Gaussian 0 vs 1:
  Original Loss: 0.0014358
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014358 (Pseudo: 0.00%)
[Iter 2490] Gaussian 1 vs 0:
  Original Loss: 0.0014134
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014134 (Pseudo: 0.00%)
Iter:2499, L1 loss=0.001231, Total loss=0.001227, Time:17
[Iter 2500/20000] Loss: 0.0013106 (Best: 0.0010960 @iter2338) ([92m↓10.19%[0m) [0.52% of initial]
[Iter 2500] Gaussian 0 vs 1:
  Original Loss: 0.0012209
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012209 (Pseudo: 0.00%)
[Iter 2500] Gaussian 1 vs 0:
  Original Loss: 0.0012528
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012528 (Pseudo: 0.00%)
[Iter 2510/20000] Loss: 0.0013585 (Best: 0.0010301 @iter2504) ([91m↑3.66%[0m) [0.54% of initial]
[Iter 2510] Gaussian 0 vs 1:
  Original Loss: 0.0015743
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015743 (Pseudo: 0.00%)
[Iter 2510] Gaussian 1 vs 0:
  Original Loss: 0.0016330
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016330 (Pseudo: 0.00%)
[Iter 2520/20000] Loss: 0.0012036 (Best: 0.0010111 @iter2519) ([92m↓11.40%[0m) [0.48% of initial]
[Iter 2520] Gaussian 0 vs 1:
  Original Loss: 0.0012162
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012162 (Pseudo: 0.00%)
[Iter 2520] Gaussian 1 vs 0:
  Original Loss: 0.0012883
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012883 (Pseudo: 0.00%)
[Iter 2530/20000] Loss: 0.0010594 (Best: 0.0009340 @iter2528) ([92m↓11.98%[0m) [0.42% of initial]
[Iter 2530] Gaussian 0 vs 1:
  Original Loss: 0.0009551
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009551 (Pseudo: 0.00%)
[Iter 2530] Gaussian 1 vs 0:
  Original Loss: 0.0009538
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009538 (Pseudo: 0.00%)
[Iter 2540/20000] Loss: 0.0011869 (Best: 0.0009340 @iter2528) ([91m↑12.03%[0m) [0.47% of initial]
[Iter 2540] Gaussian 0 vs 1:
  Original Loss: 0.0011876
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011876 (Pseudo: 0.00%)
[Iter 2540] Gaussian 1 vs 0:
  Original Loss: 0.0011839
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011839 (Pseudo: 0.00%)
[Iter 2550/20000] Loss: 0.0013671 (Best: 0.0009340 @iter2528) ([91m↑15.19%[0m) [0.54% of initial]
[Iter 2550] Gaussian 0 vs 1:
  Original Loss: 0.0014048
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014048 (Pseudo: 0.00%)
[Iter 2550] Gaussian 1 vs 0:
  Original Loss: 0.0014457
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014457 (Pseudo: 0.00%)
[Iter 2560/20000] Loss: 0.0011793 (Best: 0.0009340 @iter2528) ([92m↓13.74%[0m) [0.47% of initial]
[Iter 2560] Gaussian 0 vs 1:
  Original Loss: 0.0010764
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010764 (Pseudo: 0.00%)
[Iter 2560] Gaussian 1 vs 0:
  Original Loss: 0.0010463
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010463 (Pseudo: 0.00%)
[Iter 2570/20000] Loss: 0.0013915 (Best: 0.0009340 @iter2528) ([91m↑17.99%[0m) [0.55% of initial]
[Iter 2570] Gaussian 0 vs 1:
  Original Loss: 0.0013948
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013948 (Pseudo: 0.00%)
[Iter 2570] Gaussian 1 vs 0:
  Original Loss: 0.0013855
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013855 (Pseudo: 0.00%)
[Iter 2580/20000] Loss: 0.0012150 (Best: 0.0009128 @iter2578) ([92m↓12.69%[0m) [0.48% of initial]
[Iter 2580] Gaussian 0 vs 1:
  Original Loss: 0.0012350
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012350 (Pseudo: 0.00%)
[Iter 2580] Gaussian 1 vs 0:
  Original Loss: 0.0012421
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012421 (Pseudo: 0.00%)
[Iter 2590/20000] Loss: 0.0012754 (Best: 0.0009102 @iter2584) ([91m↑4.97%[0m) [0.51% of initial]
[Iter 2590] Gaussian 0 vs 1:
  Original Loss: 0.0013607
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013607 (Pseudo: 0.00%)
[Iter 2590] Gaussian 1 vs 0:
  Original Loss: 0.0014092
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014092 (Pseudo: 0.00%)
Iter:2599, L1 loss=0.001014, Total loss=0.001012, Time:17
[Iter 2600/20000] Loss: 0.0011904 (Best: 0.0009102 @iter2584) ([92m↓6.67%[0m) [0.47% of initial]
[Iter 2600] Gaussian 0 vs 1:
  Original Loss: 0.0013056
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013056 (Pseudo: 0.00%)
[Iter 2600] Gaussian 1 vs 0:
  Original Loss: 0.0013334
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013334 (Pseudo: 0.00%)
[Iter 2610/20000] Loss: 0.0060108 (Best: 0.0009102 @iter2584) ([91m↑404.96%[0m) [2.39% of initial]
[Iter 2610] Gaussian 0 vs 1:
  Original Loss: 0.0054474
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0054474 (Pseudo: 0.00%)
[Iter 2610] Gaussian 1 vs 0:
  Original Loss: 0.0052212
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0052212 (Pseudo: 0.00%)
[Iter 2620/20000] Loss: 0.0032401 (Best: 0.0009102 @iter2584) ([92m↓46.10%[0m) [1.29% of initial]
[Iter 2620] Gaussian 0 vs 1:
  Original Loss: 0.0028164
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028164 (Pseudo: 0.00%)
[Iter 2620] Gaussian 1 vs 0:
  Original Loss: 0.0027265
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027265 (Pseudo: 0.00%)
[Iter 2630/20000] Loss: 0.0021727 (Best: 0.0009102 @iter2584) ([92m↓32.94%[0m) [0.86% of initial]
[Iter 2630] Gaussian 0 vs 1:
  Original Loss: 0.0021922
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021922 (Pseudo: 0.00%)
[Iter 2630] Gaussian 1 vs 0:
  Original Loss: 0.0021198
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021198 (Pseudo: 0.00%)
[Iter 2640/20000] Loss: 0.0017086 (Best: 0.0009102 @iter2584) ([92m↓21.36%[0m) [0.68% of initial]
[Iter 2640] Gaussian 0 vs 1:
  Original Loss: 0.0015578
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015578 (Pseudo: 0.00%)
[Iter 2640] Gaussian 1 vs 0:
  Original Loss: 0.0015522
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015522 (Pseudo: 0.00%)
[Iter 2650/20000] Loss: 0.0014132 (Best: 0.0009102 @iter2584) ([92m↓17.29%[0m) [0.56% of initial]
[Iter 2650] Gaussian 0 vs 1:
  Original Loss: 0.0011457
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011457 (Pseudo: 0.00%)
[Iter 2650] Gaussian 1 vs 0:
  Original Loss: 0.0011131
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011131 (Pseudo: 0.00%)
[Iter 2660/20000] Loss: 0.0016634 (Best: 0.0009102 @iter2584) ([91m↑17.70%[0m) [0.66% of initial]
[Iter 2660] Gaussian 0 vs 1:
  Original Loss: 0.0014413
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014413 (Pseudo: 0.00%)
[Iter 2660] Gaussian 1 vs 0:
  Original Loss: 0.0014032
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014032 (Pseudo: 0.00%)
[Iter 2670/20000] Loss: 0.0016491 (Best: 0.0009102 @iter2584) ([92m↓0.86%[0m) [0.66% of initial]
[Iter 2670] Gaussian 0 vs 1:
  Original Loss: 0.0017100
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017100 (Pseudo: 0.00%)
[Iter 2670] Gaussian 1 vs 0:
  Original Loss: 0.0016796
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016796 (Pseudo: 0.00%)
[Iter 2680/20000] Loss: 0.0012779 (Best: 0.0009102 @iter2584) ([92m↓22.51%[0m) [0.51% of initial]
[Iter 2680] Gaussian 0 vs 1:
  Original Loss: 0.0010734
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010734 (Pseudo: 0.00%)
[Iter 2680] Gaussian 1 vs 0:
  Original Loss: 0.0010524
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010524 (Pseudo: 0.00%)
[Iter 2690/20000] Loss: 0.0012013 (Best: 0.0009102 @iter2584) ([92m↓5.99%[0m) [0.48% of initial]
[Iter 2690] Gaussian 0 vs 1:
  Original Loss: 0.0010383
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010383 (Pseudo: 0.00%)
[Iter 2690] Gaussian 1 vs 0:
  Original Loss: 0.0009678
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009678 (Pseudo: 0.00%)
Iter:2699, L1 loss=0.001111, Total loss=0.001177, Time:18
[Iter 2700/20000] Loss: 0.0014546 (Best: 0.0009102 @iter2584) ([91m↑21.09%[0m) [0.58% of initial]
[Iter 2700] Gaussian 0 vs 1:
  Original Loss: 0.0017281
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017281 (Pseudo: 0.00%)
[Iter 2700] Gaussian 1 vs 0:
  Original Loss: 0.0017053
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017053 (Pseudo: 0.00%)
[Iter 2710/20000] Loss: 0.0012435 (Best: 0.0009102 @iter2584) ([92m↓14.51%[0m) [0.49% of initial]
[Iter 2710] Gaussian 0 vs 1:
  Original Loss: 0.0012896
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012896 (Pseudo: 0.00%)
[Iter 2710] Gaussian 1 vs 0:
  Original Loss: 0.0012699
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012699 (Pseudo: 0.00%)
[Iter 2720/20000] Loss: 0.0010938 (Best: 0.0009102 @iter2584) ([92m↓12.04%[0m) [0.43% of initial]
[Iter 2720] Gaussian 0 vs 1:
  Original Loss: 0.0010369
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010369 (Pseudo: 0.00%)
[Iter 2720] Gaussian 1 vs 0:
  Original Loss: 0.0010570
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010570 (Pseudo: 0.00%)
[Iter 2730/20000] Loss: 0.0009833 (Best: 0.0008248 @iter2725) ([92m↓10.11%[0m) [0.39% of initial]
[Iter 2730] Gaussian 0 vs 1:
  Original Loss: 0.0009075
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009075 (Pseudo: 0.00%)
[Iter 2730] Gaussian 1 vs 0:
  Original Loss: 0.0009161
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009161 (Pseudo: 0.00%)
[Iter 2740/20000] Loss: 0.0008567 (Best: 0.0007618 @iter2740) ([92m↓12.87%[0m) [0.34% of initial]
[Iter 2740] Gaussian 0 vs 1:
  Original Loss: 0.0007618
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0007618 (Pseudo: 0.00%)
[Iter 2740] Gaussian 1 vs 0:
  Original Loss: 0.0007701
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0007701 (Pseudo: 0.00%)
[Iter 2750/20000] Loss: 0.0011315 (Best: 0.0007618 @iter2740) ([91m↑32.07%[0m) [0.45% of initial]
[Iter 2750] Gaussian 0 vs 1:
  Original Loss: 0.0013268
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013268 (Pseudo: 0.00%)
[Iter 2750] Gaussian 1 vs 0:
  Original Loss: 0.0013694
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013694 (Pseudo: 0.00%)
[Iter 2760/20000] Loss: 0.0011649 (Best: 0.0007618 @iter2740) ([91m↑2.96%[0m) [0.46% of initial]
[Iter 2760] Gaussian 0 vs 1:
  Original Loss: 0.0012803
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012803 (Pseudo: 0.00%)
[Iter 2760] Gaussian 1 vs 0:
  Original Loss: 0.0014127
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014127 (Pseudo: 0.00%)
[Iter 2770/20000] Loss: 0.0013065 (Best: 0.0007618 @iter2740) ([91m↑12.15%[0m) [0.52% of initial]
[Iter 2770] Gaussian 0 vs 1:
  Original Loss: 0.0012820
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012820 (Pseudo: 0.00%)
[Iter 2770] Gaussian 1 vs 0:
  Original Loss: 0.0013043
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013043 (Pseudo: 0.00%)
[Iter 2780/20000] Loss: 0.0010920 (Best: 0.0007618 @iter2740) ([92m↓16.41%[0m) [0.43% of initial]
[Iter 2780] Gaussian 0 vs 1:
  Original Loss: 0.0012728
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012728 (Pseudo: 0.00%)
[Iter 2780] Gaussian 1 vs 0:
  Original Loss: 0.0012630
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012630 (Pseudo: 0.00%)
[Iter 2790/20000] Loss: 0.0011261 (Best: 0.0007618 @iter2740) ([91m↑3.12%[0m) [0.45% of initial]
[Iter 2790] Gaussian 0 vs 1:
  Original Loss: 0.0011587
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011587 (Pseudo: 0.00%)
[Iter 2790] Gaussian 1 vs 0:
  Original Loss: 0.0011701
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011701 (Pseudo: 0.00%)
Iter:2799, L1 loss=0.001261, Total loss=0.001296, Time:17
[Iter 2800/20000] Loss: 0.0011152 (Best: 0.0007618 @iter2740) ([92m↓0.97%[0m) [0.44% of initial]
[Iter 2800] Gaussian 0 vs 1:
  Original Loss: 0.0009635
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009635 (Pseudo: 0.00%)
[Iter 2800] Gaussian 1 vs 0:
  Original Loss: 0.0009860
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009860 (Pseudo: 0.00%)
[Iter 2810/20000] Loss: 0.0049535 (Best: 0.0007618 @iter2740) ([91m↑344.18%[0m) [1.97% of initial]
[Iter 2810] Gaussian 0 vs 1:
  Original Loss: 0.0040058
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040058 (Pseudo: 0.00%)
[Iter 2810] Gaussian 1 vs 0:
  Original Loss: 0.0039270
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039270 (Pseudo: 0.00%)
[Iter 2820/20000] Loss: 0.0026826 (Best: 0.0007618 @iter2740) ([92m↓45.84%[0m) [1.07% of initial]
[Iter 2820] Gaussian 0 vs 1:
  Original Loss: 0.0024844
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024844 (Pseudo: 0.00%)
[Iter 2820] Gaussian 1 vs 0:
  Original Loss: 0.0024523
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024523 (Pseudo: 0.00%)
[Iter 2830/20000] Loss: 0.0017814 (Best: 0.0007618 @iter2740) ([92m↓33.59%[0m) [0.71% of initial]
[Iter 2830] Gaussian 0 vs 1:
  Original Loss: 0.0015890
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015890 (Pseudo: 0.00%)
[Iter 2830] Gaussian 1 vs 0:
  Original Loss: 0.0015108
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015108 (Pseudo: 0.00%)
[Iter 2840/20000] Loss: 0.0015067 (Best: 0.0007618 @iter2740) ([92m↓15.42%[0m) [0.60% of initial]
[Iter 2840] Gaussian 0 vs 1:
  Original Loss: 0.0015821
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015821 (Pseudo: 0.00%)
[Iter 2840] Gaussian 1 vs 0:
  Original Loss: 0.0015879
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015879 (Pseudo: 0.00%)
[Iter 2850/20000] Loss: 0.0013013 (Best: 0.0007618 @iter2740) ([92m↓13.63%[0m) [0.52% of initial]
[Iter 2850] Gaussian 0 vs 1:
  Original Loss: 0.0012960
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012960 (Pseudo: 0.00%)
[Iter 2850] Gaussian 1 vs 0:
  Original Loss: 0.0012764
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012764 (Pseudo: 0.00%)
[Iter 2860/20000] Loss: 0.0014410 (Best: 0.0007618 @iter2740) ([91m↑10.73%[0m) [0.57% of initial]
[Iter 2860] Gaussian 0 vs 1:
  Original Loss: 0.0014827
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014827 (Pseudo: 0.00%)
[Iter 2860] Gaussian 1 vs 0:
  Original Loss: 0.0014960
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014960 (Pseudo: 0.00%)
[Iter 2870/20000] Loss: 0.0012020 (Best: 0.0007618 @iter2740) ([92m↓16.59%[0m) [0.48% of initial]
[Iter 2870] Gaussian 0 vs 1:
  Original Loss: 0.0011101
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011101 (Pseudo: 0.00%)
[Iter 2870] Gaussian 1 vs 0:
  Original Loss: 0.0011716
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011716 (Pseudo: 0.00%)
[Iter 2880/20000] Loss: 0.0011502 (Best: 0.0007618 @iter2740) ([92m↓4.31%[0m) [0.46% of initial]
[Iter 2880] Gaussian 0 vs 1:
  Original Loss: 0.0011625
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011625 (Pseudo: 0.00%)
[Iter 2880] Gaussian 1 vs 0:
  Original Loss: 0.0011148
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011148 (Pseudo: 0.00%)
[Iter 2890/20000] Loss: 0.0011142 (Best: 0.0007618 @iter2740) ([92m↓3.13%[0m) [0.44% of initial]
[Iter 2890] Gaussian 0 vs 1:
  Original Loss: 0.0011306
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011306 (Pseudo: 0.00%)
[Iter 2890] Gaussian 1 vs 0:
  Original Loss: 0.0011609
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011609 (Pseudo: 0.00%)
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693033 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374909 (Best: 0.1327883 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123912 (Best: 0.1098365 @iter40) ([92m↓18.26%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993451 (Best: 0.0965456 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936794 (Best: 0.0908578 @iter59) ([92m↓5.70%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884512 (Best: 0.0869382 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851907 (Best: 0.0831084 @iter80) ([92m↓3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824118 (Best: 0.0801456 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:21
[Iter 100/20000] Loss: 0.0786623 (Best: 0.0766275 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753225 (Best: 0.0731347 @iter106) ([92m↓4.25%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714331 (Best: 0.0685495 @iter118) ([92m↓5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0666932 (Best: 0.0641878 @iter130) ([92m↓6.64%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635410 (Best: 0.0613000 @iter140) ([92m↓4.73%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612668 (Best: 0.0583680 @iter148) ([92m↓3.58%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590264 (Best: 0.0559365 @iter157) ([92m↓3.66%[0m) [23.45% of initial]
[Iter 170/20000] Loss: 0.0563525 (Best: 0.0535271 @iter167) ([92m↓4.53%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0522929 (Best: 0.0499450 @iter179) ([92m↓7.20%[0m) [20.78% of initial]
[Iter 190/20000] Loss: 0.0495094 (Best: 0.0477999 @iter188) ([92m↓5.32%[0m) [19.67% of initial]
Iter:199, L1 loss=0.03443, Total loss=0.04965, Time:16
[Iter 200/20000] Loss: 0.0477494 (Best: 0.0455610 @iter198) ([92m↓3.55%[0m) [18.97% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693030 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374909 (Best: 0.1327888 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123924 (Best: 0.1098380 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993465 (Best: 0.0965469 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936745 (Best: 0.0908466 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884501 (Best: 0.0869346 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851832 (Best: 0.0830954 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824056 (Best: 0.0801445 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05724, Total loss=0.07876, Time:21
[Iter 100/20000] Loss: 0.0786614 (Best: 0.0766117 @iter97) ([92m↓4.54%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753191 (Best: 0.0731338 @iter106) ([92m↓4.25%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714308 (Best: 0.0685448 @iter118) ([92m↓5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0667027 (Best: 0.0641905 @iter130) ([92m↓6.62%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635355 (Best: 0.0612855 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612953 (Best: 0.0584232 @iter148) ([92m↓3.53%[0m) [24.35% of initial]
[Iter 160/20000] Loss: 0.0590676 (Best: 0.0559612 @iter157) ([92m↓3.63%[0m) [23.47% of initial]
[Iter 170/20000] Loss: 0.0563757 (Best: 0.0535411 @iter167) ([92m↓4.56%[0m) [22.40% of initial]
[Iter 180/20000] Loss: 0.0523700 (Best: 0.0500822 @iter179) ([92m↓7.11%[0m) [20.81% of initial]
[Iter 190/20000] Loss: 0.0495711 (Best: 0.0478573 @iter188) ([92m↓5.34%[0m) [19.69% of initial]
Iter:199, L1 loss=0.03448, Total loss=0.04979, Time:18
[Iter 200/20000] Loss: 0.0477961 (Best: 0.0457590 @iter198) ([92m↓3.58%[0m) [18.99% of initial]
[Iter 210/20000] Loss: 0.0450427 (Best: 0.0427748 @iter209) ([92m↓5.76%[0m) [17.90% of initial]
[Iter 220/20000] Loss: 0.0440523 (Best: 0.0411728 @iter219) ([92m↓2.20%[0m) [17.50% of initial]
[Iter 230/20000] Loss: 0.0423533 (Best: 0.0398691 @iter227) ([92m↓3.86%[0m) [16.83% of initial]
[Iter 240/20000] Loss: 0.0402689 (Best: 0.0379520 @iter238) ([92m↓4.92%[0m) [16.00% of initial]
[Iter 250/20000] Loss: 0.0380066 (Best: 0.0362114 @iter248) ([92m↓5.62%[0m) [15.10% of initial]
[Iter 260/20000] Loss: 0.0358424 (Best: 0.0342580 @iter260) ([92m↓5.69%[0m) [14.24% of initial]
[Iter 270/20000] Loss: 0.0349260 (Best: 0.0328095 @iter269) ([92m↓2.56%[0m) [13.88% of initial]
[Iter 280/20000] Loss: 0.0347145 (Best: 0.0317726 @iter277) ([92m↓0.61%[0m) [13.79% of initial]
[Iter 290/20000] Loss: 0.0330622 (Best: 0.0304665 @iter287) ([92m↓4.76%[0m) [13.14% of initial]
Iter:299, L1 loss=0.02216, Total loss=0.03338, Time:17
[Iter 300/20000] Loss: 0.0308207 (Best: 0.0289778 @iter300) ([92m↓6.78%[0m) [12.24% of initial]
[Iter 310/20000] Loss: 0.0293137 (Best: 0.0273058 @iter310) ([92m↓4.89%[0m) [11.65% of initial]
[Iter 320/20000] Loss: 0.0278540 (Best: 0.0263919 @iter320) ([92m↓4.98%[0m) [11.07% of initial]
[Iter 330/20000] Loss: 0.0275400 (Best: 0.0256397 @iter330) ([92m↓1.13%[0m) [10.94% of initial]
[Iter 340/20000] Loss: 0.0253861 (Best: 0.0242630 @iter340) ([92m↓7.82%[0m) [10.09% of initial]
[Iter 350/20000] Loss: 0.0261197 (Best: 0.0234571 @iter349) ([91m↑2.89%[0m) [10.38% of initial]
[Iter 360/20000] Loss: 0.0247774 (Best: 0.0228342 @iter358) ([92m↓5.14%[0m) [9.84% of initial]
[Iter 370/20000] Loss: 0.0245670 (Best: 0.0222024 @iter368) ([92m↓0.85%[0m) [9.76% of initial]
[Iter 380/20000] Loss: 0.0222958 (Best: 0.0211353 @iter379) ([92m↓9.24%[0m) [8.86% of initial]
[Iter 390/20000] Loss: 0.0217796 (Best: 0.0203159 @iter385) ([92m↓2.32%[0m) [8.65% of initial]
Iter:399, L1 loss=0.01353, Total loss=0.02133, Time:18
[Iter 400/20000] Loss: 0.0206350 (Best: 0.0192143 @iter400) ([92m↓5.26%[0m) [8.20% of initial]
[Iter 410/20000] Loss: 0.0194687 (Best: 0.0183569 @iter410) ([92m↓5.65%[0m) [7.73% of initial]
[Iter 420/20000] Loss: 0.0197469 (Best: 0.0177098 @iter418) ([91m↑1.43%[0m) [7.85% of initial]
[Iter 430/20000] Loss: 0.0179078 (Best: 0.0172186 @iter430) ([92m↓9.31%[0m) [7.11% of initial]
[Iter 440/20000] Loss: 0.0184554 (Best: 0.0167350 @iter438) ([91m↑3.06%[0m) [7.33% of initial]
[Iter 450/20000] Loss: 0.0174292 (Best: 0.0156436 @iter449) ([92m↓5.56%[0m) [6.92% of initial]
[Iter 460/20000] Loss: 0.0166013 (Best: 0.0149313 @iter458) ([92m↓4.75%[0m) [6.60% of initial]
[Iter 470/20000] Loss: 0.0151157 (Best: 0.0141822 @iter470) ([92m↓8.95%[0m) [6.01% of initial]
[Iter 480/20000] Loss: 0.0147565 (Best: 0.0132992 @iter479) ([92m↓2.38%[0m) [5.86% of initial]
[Iter 490/20000] Loss: 0.0137483 (Best: 0.0127463 @iter490) ([92m↓6.83%[0m) [5.46% of initial]
Iter:499, L1 loss=0.008123, Total loss=0.01425, Time:18
[Iter 500/20000] Loss: 0.0135548 (Best: 0.0126694 @iter493) ([92m↓1.41%[0m) [5.39% of initial]
[Iter 510/20000] Loss: 0.0135199 (Best: 0.0120787 @iter508) ([92m↓0.26%[0m) [5.37% of initial]
[Iter 520/20000] Loss: 0.0127953 (Best: 0.0117691 @iter511) ([92m↓5.36%[0m) [5.08% of initial]
[Iter 530/20000] Loss: 0.0123573 (Best: 0.0111778 @iter529) ([92m↓3.42%[0m) [4.91% of initial]
[Iter 540/20000] Loss: 0.0125711 (Best: 0.0111778 @iter529) ([91m↑1.73%[0m) [4.99% of initial]
[Iter 550/20000] Loss: 0.0120336 (Best: 0.0110438 @iter545) ([92m↓4.28%[0m) [4.78% of initial]
[Iter 560/20000] Loss: 0.0122784 (Best: 0.0106725 @iter556) ([91m↑2.03%[0m) [4.88% of initial]
[Iter 570/20000] Loss: 0.0118497 (Best: 0.0104502 @iter569) ([92m↓3.49%[0m) [4.71% of initial]
[Iter 580/20000] Loss: 0.0114676 (Best: 0.0104502 @iter569) ([92m↓3.22%[0m) [4.56% of initial]
[Iter 590/20000] Loss: 0.0113879 (Best: 0.0102013 @iter583) ([92m↓0.69%[0m) [4.52% of initial]
Iter:599, L1 loss=0.007168, Total loss=0.01179, Time:18
[Iter 600/20000] Loss: 0.0110137 (Best: 0.0101286 @iter591) ([92m↓3.29%[0m) [4.38% of initial]
[Iter 610/20000] Loss: 0.0213721 (Best: 0.0101286 @iter591) ([91m↑94.05%[0m) [8.49% of initial]
[Iter 620/20000] Loss: 0.0139540 (Best: 0.0101286 @iter591) ([92m↓34.71%[0m) [5.54% of initial]
[Iter 630/20000] Loss: 0.0117599 (Best: 0.0101286 @iter591) ([92m↓15.72%[0m) [4.67% of initial]
[Iter 640/20000] Loss: 0.0100886 (Best: 0.0090897 @iter640) ([92m↓14.21%[0m) [4.01% of initial]
[Iter 650/20000] Loss: 0.0105900 (Best: 0.0090224 @iter646) ([91m↑4.97%[0m) [4.21% of initial]
[Iter 660/20000] Loss: 0.0099560 (Best: 0.0086686 @iter655) ([92m↓5.99%[0m) [3.96% of initial]
[Iter 670/20000] Loss: 0.0095573 (Best: 0.0082746 @iter667) ([92m↓4.00%[0m) [3.80% of initial]
[Iter 680/20000] Loss: 0.0088036 (Best: 0.0081489 @iter680) ([92m↓7.89%[0m) [3.50% of initial]
[Iter 690/20000] Loss: 0.0090871 (Best: 0.0077659 @iter685) ([91m↑3.22%[0m) [3.61% of initial]
Iter:699, L1 loss=0.005697, Total loss=0.009633, Time:18
[Iter 700/20000] Loss: 0.0089681 (Best: 0.0077659 @iter685) ([92m↓1.31%[0m) [3.56% of initial]
[Iter 710/20000] Loss: 0.0083568 (Best: 0.0075818 @iter703) ([92m↓6.82%[0m) [3.32% of initial]
[Iter 720/20000] Loss: 0.0084263 (Best: 0.0075750 @iter715) ([91m↑0.83%[0m) [3.35% of initial]
[Iter 730/20000] Loss: 0.0084545 (Best: 0.0072810 @iter727) ([91m↑0.33%[0m) [3.36% of initial]
[Iter 740/20000] Loss: 0.0085990 (Best: 0.0071907 @iter733) ([91m↑1.71%[0m) [3.42% of initial]
[Iter 750/20000] Loss: 0.0081885 (Best: 0.0071907 @iter733) ([92m↓4.77%[0m) [3.25% of initial]
[Iter 760/20000] Loss: 0.0074114 (Best: 0.0069256 @iter754) ([92m↓9.49%[0m) [2.94% of initial]
[Iter 770/20000] Loss: 0.0075560 (Best: 0.0069256 @iter754) ([91m↑1.95%[0m) [3.00% of initial]
[Iter 780/20000] Loss: 0.0078130 (Best: 0.0067757 @iter778) ([91m↑3.40%[0m) [3.10% of initial]
[Iter 790/20000] Loss: 0.0075804 (Best: 0.0065905 @iter787) ([92m↓2.98%[0m) [3.01% of initial]
Iter:799, L1 loss=0.005006, Total loss=0.008092, Time:18
[Iter 800/20000] Loss: 0.0073647 (Best: 0.0065699 @iter794) ([92m↓2.85%[0m) [2.93% of initial]
[Iter 810/20000] Loss: 0.0154988 (Best: 0.0065699 @iter794) ([91m↑110.45%[0m) [6.16% of initial]
[Iter 820/20000] Loss: 0.0109214 (Best: 0.0065699 @iter794) ([92m↓29.53%[0m) [4.34% of initial]
[Iter 830/20000] Loss: 0.0090186 (Best: 0.0065699 @iter794) ([92m↓17.42%[0m) [3.58% of initial]
[Iter 840/20000] Loss: 0.0082094 (Best: 0.0065699 @iter794) ([92m↓8.97%[0m) [3.26% of initial]
[Iter 850/20000] Loss: 0.0074978 (Best: 0.0065699 @iter794) ([92m↓8.67%[0m) [2.98% of initial]
[Iter 860/20000] Loss: 0.0070423 (Best: 0.0062987 @iter859) ([92m↓6.07%[0m) [2.80% of initial]
[Iter 870/20000] Loss: 0.0066952 (Best: 0.0061127 @iter862) ([92m↓4.93%[0m) [2.66% of initial]
[Iter 880/20000] Loss: 0.0066766 (Best: 0.0059547 @iter875) ([92m↓0.28%[0m) [2.65% of initial]
[Iter 890/20000] Loss: 0.0062916 (Best: 0.0057352 @iter884) ([92m↓5.77%[0m) [2.50% of initial]
Iter:899, L1 loss=0.003697, Total loss=0.005645, Time:14
[Iter 900/20000] Loss: 0.0064825 (Best: 0.0056453 @iter899) ([91m↑3.03%[0m) [2.58% of initial]
[Iter 910/20000] Loss: 0.0066310 (Best: 0.0055385 @iter907) ([91m↑2.29%[0m) [2.63% of initial]
[Iter 920/20000] Loss: 0.0060062 (Best: 0.0054099 @iter913) ([92m↓9.42%[0m) [2.39% of initial]
[Iter 930/20000] Loss: 0.0062460 (Best: 0.0053537 @iter925) ([91m↑3.99%[0m) [2.48% of initial]
[Iter 940/20000] Loss: 0.0062910 (Best: 0.0052154 @iter938) ([91m↑0.72%[0m) [2.50% of initial]
[Iter 950/20000] Loss: 0.0058857 (Best: 0.0052154 @iter938) ([92m↓6.44%[0m) [2.34% of initial]
[Iter 960/20000] Loss: 0.0060818 (Best: 0.0052154 @iter938) ([91m↑3.33%[0m) [2.42% of initial]
[Iter 970/20000] Loss: 0.0059414 (Best: 0.0052101 @iter964) ([92m↓2.31%[0m) [2.36% of initial]
[Iter 980/20000] Loss: 0.0063186 (Best: 0.0052101 @iter964) ([91m↑6.35%[0m) [2.51% of initial]
[Iter 990/20000] Loss: 0.0061374 (Best: 0.0052078 @iter988) ([92m↓2.87%[0m) [2.44% of initial]
Iter:999, L1 loss=0.004446, Total loss=0.006789, Time:17
[Iter 1000/20000] Loss: 0.0064049 (Best: 0.0052078 @iter988) ([91m↑4.36%[0m) [2.54% of initial]
Pruning 997 points (7.2%) from gaussian0 at iteration 1000
Pruning 1024 points (7.5%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0136676 (Best: 0.0052078 @iter988) ([91m↑113.39%[0m) [5.43% of initial]
[Iter 1020/20000] Loss: 0.0097405 (Best: 0.0052078 @iter988) ([92m↓28.73%[0m) [3.87% of initial]
[Iter 1030/20000] Loss: 0.0078874 (Best: 0.0052078 @iter988) ([92m↓19.02%[0m) [3.13% of initial]
[Iter 1040/20000] Loss: 0.0071045 (Best: 0.0052078 @iter988) ([92m↓9.93%[0m) [2.82% of initial]
[Iter 1050/20000] Loss: 0.0067992 (Best: 0.0052078 @iter988) ([92m↓4.30%[0m) [2.70% of initial]
[Iter 1060/20000] Loss: 0.0065283 (Best: 0.0052078 @iter988) ([92m↓3.98%[0m) [2.59% of initial]
[Iter 1070/20000] Loss: 0.0063595 (Best: 0.0052078 @iter988) ([92m↓2.59%[0m) [2.53% of initial]
[Iter 1080/20000] Loss: 0.0060951 (Best: 0.0052078 @iter988) ([92m↓4.16%[0m) [2.42% of initial]
[Iter 1090/20000] Loss: 0.0059933 (Best: 0.0052078 @iter988) ([92m↓1.67%[0m) [2.38% of initial]
Iter:1099, L1 loss=0.003805, Total loss=0.005927, Time:18
[Iter 1100/20000] Loss: 0.0057804 (Best: 0.0052078 @iter988) ([92m↓3.55%[0m) [2.30% of initial]
[Iter 1110/20000] Loss: 0.0058143 (Best: 0.0052078 @iter988) ([91m↑0.59%[0m) [2.31% of initial]
[Iter 1120/20000] Loss: 0.0057839 (Best: 0.0050055 @iter1117) ([92m↓0.52%[0m) [2.30% of initial]
[Iter 1130/20000] Loss: 0.0058946 (Best: 0.0050055 @iter1117) ([91m↑1.92%[0m) [2.34% of initial]
[Iter 1140/20000] Loss: 0.0055643 (Best: 0.0049841 @iter1135) ([92m↓5.60%[0m) [2.21% of initial]
[Iter 1150/20000] Loss: 0.0052458 (Best: 0.0048780 @iter1145) ([92m↓5.72%[0m) [2.08% of initial]
[Iter 1160/20000] Loss: 0.0057627 (Best: 0.0048325 @iter1156) ([91m↑9.85%[0m) [2.29% of initial]
[Iter 1170/20000] Loss: 0.0054423 (Best: 0.0048231 @iter1166) ([92m↓5.56%[0m) [2.16% of initial]
[Iter 1180/20000] Loss: 0.0050938 (Best: 0.0047607 @iter1180) ([92m↓6.40%[0m) [2.02% of initial]
[Iter 1190/20000] Loss: 0.0053946 (Best: 0.0047381 @iter1186) ([91m↑5.91%[0m) [2.14% of initial]
Iter:1199, L1 loss=0.00373, Total loss=0.005736, Time:17
[Iter 1200/20000] Loss: 0.0054311 (Best: 0.0047089 @iter1195) ([91m↑0.68%[0m) [2.16% of initial]
[Iter 1210/20000] Loss: 0.0123840 (Best: 0.0047089 @iter1195) ([91m↑128.02%[0m) [4.92% of initial]
[Iter 1220/20000] Loss: 0.0081281 (Best: 0.0047089 @iter1195) ([92m↓34.37%[0m) [3.23% of initial]
[Iter 1230/20000] Loss: 0.0067012 (Best: 0.0047089 @iter1195) ([92m↓17.56%[0m) [2.66% of initial]
[Iter 1240/20000] Loss: 0.0061042 (Best: 0.0047089 @iter1195) ([92m↓8.91%[0m) [2.43% of initial]
[Iter 1250/20000] Loss: 0.0054067 (Best: 0.0047089 @iter1195) ([92m↓11.43%[0m) [2.15% of initial]
[Iter 1260/20000] Loss: 0.0051951 (Best: 0.0044716 @iter1258) ([92m↓3.91%[0m) [2.06% of initial]
[Iter 1270/20000] Loss: 0.0047987 (Best: 0.0044625 @iter1269) ([92m↓7.63%[0m) [1.91% of initial]
[Iter 1280/20000] Loss: 0.0049754 (Best: 0.0041316 @iter1273) ([91m↑3.68%[0m) [1.98% of initial]
[Iter 1290/20000] Loss: 0.0049100 (Best: 0.0040692 @iter1288) ([92m↓1.32%[0m) [1.95% of initial]
Iter:1299, L1 loss=0.002991, Total loss=0.004384, Time:19
[Iter 1300/20000] Loss: 0.0047313 (Best: 0.0040692 @iter1288) ([92m↓3.64%[0m) [1.88% of initial]
[Iter 1310/20000] Loss: 0.0048043 (Best: 0.0040692 @iter1288) ([91m↑1.54%[0m) [1.91% of initial]
[Iter 1320/20000] Loss: 0.0045331 (Best: 0.0038643 @iter1319) ([92m↓5.65%[0m) [1.80% of initial]
[Iter 1330/20000] Loss: 0.0044820 (Best: 0.0037796 @iter1321) ([92m↓1.13%[0m) [1.78% of initial]
[Iter 1340/20000] Loss: 0.0043336 (Best: 0.0037796 @iter1321) ([92m↓3.31%[0m) [1.72% of initial]
[Iter 1350/20000] Loss: 0.0043177 (Best: 0.0037796 @iter1321) ([92m↓0.37%[0m) [1.72% of initial]
[Iter 1360/20000] Loss: 0.0043546 (Best: 0.0037796 @iter1321) ([91m↑0.85%[0m) [1.73% of initial]
[Iter 1370/20000] Loss: 0.0042020 (Best: 0.0037796 @iter1321) ([92m↓3.50%[0m) [1.67% of initial]
[Iter 1380/20000] Loss: 0.0043393 (Best: 0.0036630 @iter1375) ([91m↑3.27%[0m) [1.72% of initial]
[Iter 1390/20000] Loss: 0.0041833 (Best: 0.0036630 @iter1375) ([92m↓3.59%[0m) [1.66% of initial]
Iter:1399, L1 loss=0.002531, Total loss=0.00347, Time:14
[Iter 1400/20000] Loss: 0.0039262 (Best: 0.0034698 @iter1399) ([92m↓6.15%[0m) [1.56% of initial]
[Iter 1410/20000] Loss: 0.0098935 (Best: 0.0034698 @iter1399) ([91m↑151.99%[0m) [3.93% of initial]
[Iter 1420/20000] Loss: 0.0068206 (Best: 0.0034698 @iter1399) ([92m↓31.06%[0m) [2.71% of initial]
[Iter 1430/20000] Loss: 0.0054939 (Best: 0.0034698 @iter1399) ([92m↓19.45%[0m) [2.18% of initial]
[Iter 1440/20000] Loss: 0.0049253 (Best: 0.0034698 @iter1399) ([92m↓10.35%[0m) [1.96% of initial]
[Iter 1450/20000] Loss: 0.0040622 (Best: 0.0034698 @iter1399) ([92m↓17.52%[0m) [1.61% of initial]
[Iter 1460/20000] Loss: 0.0041290 (Best: 0.0034698 @iter1399) ([91m↑1.64%[0m) [1.64% of initial]
[Iter 1470/20000] Loss: 0.0039509 (Best: 0.0034698 @iter1399) ([92m↓4.31%[0m) [1.57% of initial]
[Iter 1480/20000] Loss: 0.0037362 (Best: 0.0032498 @iter1480) ([92m↓5.43%[0m) [1.48% of initial]
[Iter 1490/20000] Loss: 0.0037250 (Best: 0.0032498 @iter1480) ([92m↓0.30%[0m) [1.48% of initial]
Iter:1499, L1 loss=0.002868, Total loss=0.003854, Time:19
[Iter 1500/20000] Loss: 0.0036762 (Best: 0.0032498 @iter1480) ([92m↓1.31%[0m) [1.46% of initial]
Pruning 659 points (2.7%) from gaussian0 at iteration 1500
Pruning 737 points (3.0%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0048843 (Best: 0.0032498 @iter1480) ([91m↑32.86%[0m) [1.94% of initial]
[Iter 1520/20000] Loss: 0.0042176 (Best: 0.0032498 @iter1480) ([92m↓13.65%[0m) [1.68% of initial]
[Iter 1530/20000] Loss: 0.0039439 (Best: 0.0032498 @iter1480) ([92m↓6.49%[0m) [1.57% of initial]
[Iter 1540/20000] Loss: 0.0037935 (Best: 0.0032498 @iter1480) ([92m↓3.81%[0m) [1.51% of initial]
[Iter 1550/20000] Loss: 0.0034878 (Best: 0.0032249 @iter1543) ([92m↓8.06%[0m) [1.39% of initial]
[Iter 1560/20000] Loss: 0.0036592 (Best: 0.0030060 @iter1558) ([91m↑4.92%[0m) [1.45% of initial]
[Iter 1570/20000] Loss: 0.0032923 (Best: 0.0029810 @iter1569) ([92m↓10.03%[0m) [1.31% of initial]
[Iter 1580/20000] Loss: 0.0032870 (Best: 0.0028057 @iter1573) ([92m↓0.16%[0m) [1.31% of initial]
[Iter 1590/20000] Loss: 0.0032354 (Best: 0.0028057 @iter1573) ([92m↓1.57%[0m) [1.29% of initial]
Iter:1599, L1 loss=0.002943, Total loss=0.00381, Time:22
[Iter 1600/20000] Loss: 0.0035155 (Best: 0.0028057 @iter1573) ([91m↑8.66%[0m) [1.40% of initial]
[Iter 1610/20000] Loss: 0.0098386 (Best: 0.0028057 @iter1573) ([91m↑179.87%[0m) [3.91% of initial]
[Iter 1620/20000] Loss: 0.0066054 (Best: 0.0028057 @iter1573) ([92m↓32.86%[0m) [2.62% of initial]
[Iter 1630/20000] Loss: 0.0048198 (Best: 0.0028057 @iter1573) ([92m↓27.03%[0m) [1.91% of initial]
[Iter 1640/20000] Loss: 0.0043656 (Best: 0.0028057 @iter1573) ([92m↓9.42%[0m) [1.73% of initial]
[Iter 1650/20000] Loss: 0.0040435 (Best: 0.0028057 @iter1573) ([92m↓7.38%[0m) [1.61% of initial]
[Iter 1660/20000] Loss: 0.0035095 (Best: 0.0028057 @iter1573) ([92m↓13.21%[0m) [1.39% of initial]
[Iter 1670/20000] Loss: 0.0033057 (Best: 0.0028057 @iter1573) ([92m↓5.81%[0m) [1.31% of initial]
[Iter 1680/20000] Loss: 0.0034018 (Best: 0.0028057 @iter1573) ([91m↑2.91%[0m) [1.35% of initial]
[Iter 1690/20000] Loss: 0.0034474 (Best: 0.0028057 @iter1573) ([91m↑1.34%[0m) [1.37% of initial]
Iter:1699, L1 loss=0.002662, Total loss=0.003404, Time:20
[Iter 1700/20000] Loss: 0.0031770 (Best: 0.0028057 @iter1573) ([92m↓7.84%[0m) [1.26% of initial]
[Iter 1710/20000] Loss: 0.0034265 (Best: 0.0028031 @iter1705) ([91m↑7.85%[0m) [1.36% of initial]
[Iter 1720/20000] Loss: 0.0029587 (Best: 0.0027939 @iter1720) ([92m↓13.65%[0m) [1.18% of initial]
[Iter 1730/20000] Loss: 0.0029716 (Best: 0.0027350 @iter1730) ([91m↑0.44%[0m) [1.18% of initial]
[Iter 1740/20000] Loss: 0.0030054 (Best: 0.0027014 @iter1738) ([91m↑1.14%[0m) [1.19% of initial]
[Iter 1750/20000] Loss: 0.0026987 (Best: 0.0024756 @iter1750) ([92m↓10.20%[0m) [1.07% of initial]
[Iter 1760/20000] Loss: 0.0029375 (Best: 0.0024756 @iter1750) ([91m↑8.85%[0m) [1.17% of initial]
[Iter 1770/20000] Loss: 0.0027859 (Best: 0.0024756 @iter1750) ([92m↓5.16%[0m) [1.11% of initial]
[Iter 1780/20000] Loss: 0.0028084 (Best: 0.0024675 @iter1771) ([91m↑0.81%[0m) [1.12% of initial]
[Iter 1790/20000] Loss: 0.0025347 (Best: 0.0021930 @iter1789) ([92m↓9.74%[0m) [1.01% of initial]
Iter:1799, L1 loss=0.001906, Total loss=0.002381, Time:18
[Iter 1800/20000] Loss: 0.0026024 (Best: 0.0021930 @iter1789) ([91m↑2.67%[0m) [1.03% of initial]
[Iter 1810/20000] Loss: 0.0091911 (Best: 0.0021930 @iter1789) ([91m↑253.17%[0m) [3.65% of initial]
[Iter 1820/20000] Loss: 0.0053204 (Best: 0.0021930 @iter1789) ([92m↓42.11%[0m) [2.11% of initial]
[Iter 1830/20000] Loss: 0.0044098 (Best: 0.0021930 @iter1789) ([92m↓17.12%[0m) [1.75% of initial]
[Iter 1840/20000] Loss: 0.0032407 (Best: 0.0021930 @iter1789) ([92m↓26.51%[0m) [1.29% of initial]
[Iter 1850/20000] Loss: 0.0030095 (Best: 0.0021930 @iter1789) ([92m↓7.13%[0m) [1.20% of initial]
[Iter 1860/20000] Loss: 0.0027869 (Best: 0.0021930 @iter1789) ([92m↓7.40%[0m) [1.11% of initial]
[Iter 1870/20000] Loss: 0.0025866 (Best: 0.0021930 @iter1789) ([92m↓7.19%[0m) [1.03% of initial]
[Iter 1880/20000] Loss: 0.0024574 (Best: 0.0021930 @iter1789) ([92m↓5.00%[0m) [0.98% of initial]
[Iter 1890/20000] Loss: 0.0022584 (Best: 0.0020950 @iter1890) ([92m↓8.10%[0m) [0.90% of initial]
Iter:1899, L1 loss=0.001931, Total loss=0.002243, Time:23
[Iter 1900/20000] Loss: 0.0023464 (Best: 0.0019723 @iter1891) ([91m↑3.90%[0m) [0.93% of initial]
[Iter 1910/20000] Loss: 0.0023694 (Best: 0.0019329 @iter1903) ([91m↑0.98%[0m) [0.94% of initial]
[Iter 1920/20000] Loss: 0.0024219 (Best: 0.0019329 @iter1903) ([91m↑2.22%[0m) [0.96% of initial]
[Iter 1930/20000] Loss: 0.0020688 (Best: 0.0018956 @iter1930) ([92m↓14.58%[0m) [0.82% of initial]
[Iter 1940/20000] Loss: 0.0021894 (Best: 0.0018865 @iter1939) ([91m↑5.83%[0m) [0.87% of initial]
[Iter 1950/20000] Loss: 0.0024752 (Best: 0.0018865 @iter1939) ([91m↑13.05%[0m) [0.98% of initial]
[Iter 1960/20000] Loss: 0.0022177 (Best: 0.0018865 @iter1939) ([92m↓10.40%[0m) [0.88% of initial]
[Iter 1970/20000] Loss: 0.0020408 (Best: 0.0018785 @iter1963) ([92m↓7.98%[0m) [0.81% of initial]
[Iter 1980/20000] Loss: 0.0023498 (Best: 0.0018785 @iter1963) ([91m↑15.14%[0m) [0.93% of initial]
[Iter 1990/20000] Loss: 0.0021064 (Best: 0.0018785 @iter1963) ([92m↓10.36%[0m) [0.84% of initial]
Iter:1999, L1 loss=0.001655, Total loss=0.00194, Time:22
[Iter 2000/20000] Loss: 0.0021905 (Best: 0.0017209 @iter1996) ([91m↑3.99%[0m) [0.87% of initial]
Testing Speed: 119.6850861048096 fps
Testing Time: 0.41776299476623535 s

[ITER 2000] Evaluating test: SSIM = 0.8639336740970611, PSNR = 17.609300174713134
Testing Speed: 130.96150123333436 fps
Testing Time: 0.022907495498657227 s

[ITER 2000] Evaluating train: SSIM = 0.9999516407648722, PSNR = 48.570456186930336
Iter:2000, total_points:42623
Pruning 665 points (1.2%) from gaussian0 at iteration 2000
Pruning 730 points (1.3%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.0080007 (Best: 0.0017209 @iter1996) ([91m↑265.25%[0m) [3.18% of initial]
[Iter 2020/20000] Loss: 0.0050709 (Best: 0.0017209 @iter1996) ([92m↓36.62%[0m) [2.01% of initial]
[Iter 2030/20000] Loss: 0.0037194 (Best: 0.0017209 @iter1996) ([92m↓26.65%[0m) [1.48% of initial]
[Iter 2040/20000] Loss: 0.0031932 (Best: 0.0017209 @iter1996) ([92m↓14.15%[0m) [1.27% of initial]
[Iter 2050/20000] Loss: 0.0027622 (Best: 0.0017209 @iter1996) ([92m↓13.50%[0m) [1.10% of initial]
[Iter 2060/20000] Loss: 0.0023987 (Best: 0.0017209 @iter1996) ([92m↓13.16%[0m) [0.95% of initial]
[Iter 2070/20000] Loss: 0.0025588 (Best: 0.0017209 @iter1996) ([91m↑6.67%[0m) [1.02% of initial]
[Iter 2080/20000] Loss: 0.0024370 (Best: 0.0017209 @iter1996) ([92m↓4.76%[0m) [0.97% of initial]
[Iter 2090/20000] Loss: 0.0023824 (Best: 0.0017209 @iter1996) ([92m↓2.24%[0m) [0.95% of initial]
Iter:2099, L1 loss=0.001964, Total loss=0.002275, Time:22
[Iter 2100/20000] Loss: 0.0022520 (Best: 0.0017209 @iter1996) ([92m↓5.47%[0m) [0.89% of initial]
[Iter 2110/20000] Loss: 0.0021570 (Best: 0.0017209 @iter1996) ([92m↓4.22%[0m) [0.86% of initial]
[Iter 2120/20000] Loss: 0.0019419 (Best: 0.0017209 @iter1996) ([92m↓9.97%[0m) [0.77% of initial]
[Iter 2130/20000] Loss: 0.0021159 (Best: 0.0017209 @iter1996) ([91m↑8.96%[0m) [0.84% of initial]
[Iter 2140/20000] Loss: 0.0022173 (Best: 0.0017209 @iter1996) ([91m↑4.79%[0m) [0.88% of initial]
[Iter 2150/20000] Loss: 0.0022493 (Best: 0.0017209 @iter1996) ([91m↑1.44%[0m) [0.89% of initial]
[Iter 2160/20000] Loss: 0.0021010 (Best: 0.0017209 @iter1996) ([92m↓6.59%[0m) [0.83% of initial]
[Iter 2170/20000] Loss: 0.0021218 (Best: 0.0017209 @iter1996) ([91m↑0.99%[0m) [0.84% of initial]
[Iter 2180/20000] Loss: 0.0018205 (Best: 0.0016963 @iter2180) ([92m↓14.20%[0m) [0.72% of initial]
[Iter 2190/20000] Loss: 0.0021048 (Best: 0.0016963 @iter2180) ([91m↑15.62%[0m) [0.84% of initial]
Iter:2199, L1 loss=0.001813, Total loss=0.002014, Time:26
[Iter 2200/20000] Loss: 0.0020828 (Best: 0.0016766 @iter2191) ([92m↓1.05%[0m) [0.83% of initial]
[Iter 2210/20000] Loss: 0.0087117 (Best: 0.0016766 @iter2191) ([91m↑318.27%[0m) [3.46% of initial]
[Iter 2220/20000] Loss: 0.0049476 (Best: 0.0016766 @iter2191) ([92m↓43.21%[0m) [1.97% of initial]
[Iter 2230/20000] Loss: 0.0031843 (Best: 0.0016766 @iter2191) ([92m↓35.64%[0m) [1.27% of initial]
[Iter 2240/20000] Loss: 0.0027000 (Best: 0.0016766 @iter2191) ([92m↓15.21%[0m) [1.07% of initial]
[Iter 2250/20000] Loss: 0.0025452 (Best: 0.0016766 @iter2191) ([92m↓5.73%[0m) [1.01% of initial]
[Iter 2260/20000] Loss: 0.0021475 (Best: 0.0016766 @iter2191) ([92m↓15.63%[0m) [0.85% of initial]
[Iter 2270/20000] Loss: 0.0021857 (Best: 0.0016766 @iter2191) ([91m↑1.78%[0m) [0.87% of initial]
[Iter 2280/20000] Loss: 0.0018488 (Best: 0.0016766 @iter2191) ([92m↓15.41%[0m) [0.73% of initial]
[Iter 2290/20000] Loss: 0.0017884 (Best: 0.0015869 @iter2287) ([92m↓3.27%[0m) [0.71% of initial]
Iter:2299, L1 loss=0.001587, Total loss=0.001715, Time:24
[Iter 2300/20000] Loss: 0.0020434 (Best: 0.0015869 @iter2287) ([91m↑14.26%[0m) [0.81% of initial]
[Iter 2310/20000] Loss: 0.0019283 (Best: 0.0015869 @iter2287) ([92m↓5.64%[0m) [0.77% of initial]
[Iter 2320/20000] Loss: 0.0017015 (Best: 0.0015595 @iter2320) ([92m↓11.76%[0m) [0.68% of initial]
[Iter 2330/20000] Loss: 0.0016928 (Best: 0.0015242 @iter2324) ([92m↓0.51%[0m) [0.67% of initial]
[Iter 2340/20000] Loss: 0.0017468 (Best: 0.0014926 @iter2338) ([91m↑3.19%[0m) [0.69% of initial]
[Iter 2350/20000] Loss: 0.0018307 (Best: 0.0014809 @iter2342) ([91m↑4.80%[0m) [0.73% of initial]
[Iter 2360/20000] Loss: 0.0016343 (Best: 0.0014269 @iter2359) ([92m↓10.73%[0m) [0.65% of initial]
[Iter 2370/20000] Loss: 0.0017584 (Best: 0.0014269 @iter2359) ([91m↑7.59%[0m) [0.70% of initial]
[Iter 2380/20000] Loss: 0.0018236 (Best: 0.0014269 @iter2359) ([91m↑3.70%[0m) [0.72% of initial]
[Iter 2390/20000] Loss: 0.0019783 (Best: 0.0014269 @iter2359) ([91m↑8.48%[0m) [0.79% of initial]
Iter:2399, L1 loss=0.001468, Total loss=0.001522, Time:26
[Iter 2400/20000] Loss: 0.0016624 (Best: 0.0014269 @iter2359) ([92m↓15.97%[0m) [0.66% of initial]
[Iter 2410/20000] Loss: 0.0067322 (Best: 0.0014269 @iter2359) ([91m↑304.96%[0m) [2.67% of initial]
[Iter 2420/20000] Loss: 0.0039196 (Best: 0.0014269 @iter2359) ([92m↓41.78%[0m) [1.56% of initial]
[Iter 2430/20000] Loss: 0.0028883 (Best: 0.0014269 @iter2359) ([92m↓26.31%[0m) [1.15% of initial]
[Iter 2440/20000] Loss: 0.0023718 (Best: 0.0014269 @iter2359) ([92m↓17.88%[0m) [0.94% of initial]
[Iter 2450/20000] Loss: 0.0022596 (Best: 0.0014269 @iter2359) ([92m↓4.73%[0m) [0.90% of initial]
[Iter 2460/20000] Loss: 0.0019537 (Best: 0.0014269 @iter2359) ([92m↓13.54%[0m) [0.78% of initial]
[Iter 2470/20000] Loss: 0.0018921 (Best: 0.0014269 @iter2359) ([92m↓3.15%[0m) [0.75% of initial]
[Iter 2480/20000] Loss: 0.0018869 (Best: 0.0014269 @iter2359) ([92m↓0.27%[0m) [0.75% of initial]
[Iter 2490/20000] Loss: 0.0017019 (Best: 0.0014269 @iter2359) ([92m↓9.81%[0m) [0.68% of initial]
Iter:2499, L1 loss=0.001391, Total loss=0.00148, Time:25
[Iter 2500/20000] Loss: 0.0015505 (Best: 0.0014269 @iter2359) ([92m↓8.89%[0m) [0.62% of initial]
Pruning 497 points (0.6%) from gaussian0 at iteration 2500
Pruning 537 points (0.7%) from gaussian1 at iteration 2500
[Iter 2510/20000] Loss: 0.0033516 (Best: 0.0014269 @iter2359) ([91m↑116.16%[0m) [1.33% of initial]
[Iter 2520/20000] Loss: 0.0022367 (Best: 0.0014269 @iter2359) ([92m↓33.26%[0m) [0.89% of initial]
[Iter 2530/20000] Loss: 0.0016884 (Best: 0.0014269 @iter2359) ([92m↓24.51%[0m) [0.67% of initial]
[Iter 2540/20000] Loss: 0.0015706 (Best: 0.0014116 @iter2533) ([92m↓6.98%[0m) [0.62% of initial]
[Iter 2550/20000] Loss: 0.0017020 (Best: 0.0013079 @iter2548) ([91m↑8.36%[0m) [0.68% of initial]
[Iter 2560/20000] Loss: 0.0014533 (Best: 0.0012437 @iter2557) ([92m↓14.61%[0m) [0.58% of initial]
[Iter 2570/20000] Loss: 0.0016381 (Best: 0.0012437 @iter2557) ([91m↑12.72%[0m) [0.65% of initial]
[Iter 2580/20000] Loss: 0.0014639 (Best: 0.0011622 @iter2578) ([92m↓10.63%[0m) [0.58% of initial]
[Iter 2590/20000] Loss: 0.0015619 (Best: 0.0011509 @iter2584) ([91m↑6.69%[0m) [0.62% of initial]
Iter:2599, L1 loss=0.001216, Total loss=0.001253, Time:26
[Iter 2600/20000] Loss: 0.0014667 (Best: 0.0011509 @iter2584) ([92m↓6.09%[0m) [0.58% of initial]
[Iter 2610/20000] Loss: 0.0067031 (Best: 0.0011509 @iter2584) ([91m↑357.01%[0m) [2.66% of initial]
[Iter 2620/20000] Loss: 0.0038604 (Best: 0.0011509 @iter2584) ([92m↓42.41%[0m) [1.53% of initial]
[Iter 2630/20000] Loss: 0.0025211 (Best: 0.0011509 @iter2584) ([92m↓34.69%[0m) [1.00% of initial]
[Iter 2640/20000] Loss: 0.0020215 (Best: 0.0011509 @iter2584) ([92m↓19.82%[0m) [0.80% of initial]
[Iter 2650/20000] Loss: 0.0016893 (Best: 0.0011509 @iter2584) ([92m↓16.44%[0m) [0.67% of initial]
[Iter 2660/20000] Loss: 0.0018997 (Best: 0.0011509 @iter2584) ([91m↑12.46%[0m) [0.75% of initial]
[Iter 2670/20000] Loss: 0.0017992 (Best: 0.0011509 @iter2584) ([92m↓5.29%[0m) [0.71% of initial]
[Iter 2680/20000] Loss: 0.0014482 (Best: 0.0011509 @iter2584) ([92m↓19.51%[0m) [0.58% of initial]
[Iter 2690/20000] Loss: 0.0014088 (Best: 0.0011509 @iter2584) ([92m↓2.72%[0m) [0.56% of initial]
Iter:2699, L1 loss=0.001363, Total loss=0.001393, Time:26
[Iter 2700/20000] Loss: 0.0017159 (Best: 0.0011509 @iter2584) ([91m↑21.80%[0m) [0.68% of initial]
[Iter 2710/20000] Loss: 0.0014514 (Best: 0.0011509 @iter2584) ([92m↓15.42%[0m) [0.58% of initial]
[Iter 2720/20000] Loss: 0.0013113 (Best: 0.0011509 @iter2584) ([92m↓9.66%[0m) [0.52% of initial]
[Iter 2730/20000] Loss: 0.0012070 (Best: 0.0010613 @iter2725) ([92m↓7.95%[0m) [0.48% of initial]
[Iter 2740/20000] Loss: 0.0010728 (Best: 0.0009589 @iter2740) ([92m↓11.12%[0m) [0.43% of initial]
[Iter 2750/20000] Loss: 0.0013804 (Best: 0.0009589 @iter2740) ([91m↑28.67%[0m) [0.55% of initial]
[Iter 2760/20000] Loss: 0.0015101 (Best: 0.0009589 @iter2740) ([91m↑9.39%[0m) [0.60% of initial]
[Iter 2770/20000] Loss: 0.0016229 (Best: 0.0009589 @iter2740) ([91m↑7.48%[0m) [0.64% of initial]
[Iter 2780/20000] Loss: 0.0013307 (Best: 0.0009589 @iter2740) ([92m↓18.00%[0m) [0.53% of initial]
[Iter 2790/20000] Loss: 0.0013819 (Best: 0.0009589 @iter2740) ([91m↑3.84%[0m) [0.55% of initial]
Iter:2799, L1 loss=0.001414, Total loss=0.001547, Time:27
[Iter 2800/20000] Loss: 0.0013924 (Best: 0.0009589 @iter2740) ([91m↑0.76%[0m) [0.55% of initial]
[Iter 2810/20000] Loss: 0.0056787 (Best: 0.0009589 @iter2740) ([91m↑307.83%[0m) [2.26% of initial]
[Iter 2820/20000] Loss: 0.0030386 (Best: 0.0009589 @iter2740) ([92m↓46.49%[0m) [1.21% of initial]
[Iter 2830/20000] Loss: 0.0019869 (Best: 0.0009589 @iter2740) ([92m↓34.61%[0m) [0.79% of initial]
[Iter 2840/20000] Loss: 0.0017137 (Best: 0.0009589 @iter2740) ([92m↓13.75%[0m) [0.68% of initial]
[Iter 2850/20000] Loss: 0.0015058 (Best: 0.0009589 @iter2740) ([92m↓12.13%[0m) [0.60% of initial]
[Iter 2860/20000] Loss: 0.0016210 (Best: 0.0009589 @iter2740) ([91m↑7.65%[0m) [0.64% of initial]
[Iter 2870/20000] Loss: 0.0013906 (Best: 0.0009589 @iter2740) ([92m↓14.21%[0m) [0.55% of initial]
[Iter 2880/20000] Loss: 0.0013447 (Best: 0.0009589 @iter2740) ([92m↓3.30%[0m) [0.53% of initial]
[Iter 2890/20000] Loss: 0.0012779 (Best: 0.0009589 @iter2740) ([92m↓4.97%[0m) [0.51% of initial]
Iter:2899, L1 loss=0.001008, Total loss=0.001024, Time:25
[Iter 2900/20000] Loss: 0.0012220 (Best: 0.0009589 @iter2740) ([92m↓4.38%[0m) [0.49% of initial]
[Iter 2910/20000] Loss: 0.0013570 (Best: 0.0009589 @iter2740) ([91m↑11.05%[0m) [0.54% of initial]
[Iter 2920/20000] Loss: 0.0014170 (Best: 0.0009589 @iter2740) ([91m↑4.43%[0m) [0.56% of initial]
[Iter 2930/20000] Loss: 0.0013201 (Best: 0.0009589 @iter2740) ([92m↓6.84%[0m) [0.52% of initial]
[Iter 2940/20000] Loss: 0.0011453 (Best: 0.0009589 @iter2740) ([92m↓13.24%[0m) [0.46% of initial]
[Iter 2950/20000] Loss: 0.0010667 (Best: 0.0009117 @iter2950) ([92m↓6.87%[0m) [0.42% of initial]
[Iter 2960/20000] Loss: 0.0011750 (Best: 0.0009117 @iter2950) ([91m↑10.16%[0m) [0.47% of initial]
[Iter 2970/20000] Loss: 0.0010597 (Best: 0.0008533 @iter2969) ([92m↓9.81%[0m) [0.42% of initial]
[Iter 2980/20000] Loss: 0.0010040 (Best: 0.0008533 @iter2969) ([92m↓5.26%[0m) [0.40% of initial]
[Iter 2990/20000] Loss: 0.0010378 (Best: 0.0007953 @iter2983) ([91m↑3.36%[0m) [0.41% of initial]
Iter:2999, L1 loss=0.0008053, Total loss=0.0007963, Time:27
[Iter 3000/20000] Loss: 0.0010182 (Best: 0.0007953 @iter2983) ([92m↓1.88%[0m) [0.40% of initial]
Pruning 380 points (0.3%) from gaussian0 at iteration 3000
Pruning 368 points (0.3%) from gaussian1 at iteration 3000
[Iter 3010/20000] Loss: 0.0056973 (Best: 0.0007953 @iter2983) ([91m↑459.53%[0m) [2.26% of initial]
[Iter 3020/20000] Loss: 0.0034144 (Best: 0.0007953 @iter2983) ([92m↓40.07%[0m) [1.36% of initial]
[Iter 3030/20000] Loss: 0.0024079 (Best: 0.0007953 @iter2983) ([92m↓29.48%[0m) [0.96% of initial]
[Iter 3040/20000] Loss: 0.0018695 (Best: 0.0007953 @iter2983) ([92m↓22.36%[0m) [0.74% of initial]
[Iter 3050/20000] Loss: 0.0016989 (Best: 0.0007953 @iter2983) ([92m↓9.12%[0m) [0.67% of initial]
[Iter 3060/20000] Loss: 0.0015909 (Best: 0.0007953 @iter2983) ([92m↓6.36%[0m) [0.63% of initial]
[Iter 3070/20000] Loss: 0.0014103 (Best: 0.0007953 @iter2983) ([92m↓11.35%[0m) [0.56% of initial]
[Iter 3080/20000] Loss: 0.0014145 (Best: 0.0007953 @iter2983) ([91m↑0.29%[0m) [0.56% of initial]
[Iter 3090/20000] Loss: 0.0013549 (Best: 0.0007953 @iter2983) ([92m↓4.21%[0m) [0.54% of initial]
Iter:3099, L1 loss=0.001102, Total loss=0.001145, Time:30
[Iter 3100/20000] Loss: 0.0012914 (Best: 0.0007953 @iter2983) ([92m↓4.69%[0m) [0.51% of initial]
[Iter 3110/20000] Loss: 0.0014303 (Best: 0.0007953 @iter2983) ([91m↑10.76%[0m) [0.57% of initial]
[Iter 3120/20000] Loss: 0.0013664 (Best: 0.0007953 @iter2983) ([92m↓4.47%[0m) [0.54% of initial]
[Iter 3130/20000] Loss: 0.0011487 (Best: 0.0007953 @iter2983) ([92m↓15.94%[0m) [0.46% of initial]
[Iter 3140/20000] Loss: 0.0010810 (Best: 0.0007953 @iter2983) ([92m↓5.89%[0m) [0.43% of initial]
[Iter 3150/20000] Loss: 0.0011638 (Best: 0.0007953 @iter2983) ([91m↑7.66%[0m) [0.46% of initial]
[Iter 3160/20000] Loss: 0.0010790 (Best: 0.0007953 @iter2983) ([92m↓7.29%[0m) [0.43% of initial]
[Iter 3170/20000] Loss: 0.0010831 (Best: 0.0007953 @iter2983) ([91m↑0.38%[0m) [0.43% of initial]
[Iter 3180/20000] Loss: 0.0011463 (Best: 0.0007953 @iter2983) ([91m↑5.84%[0m) [0.46% of initial]
[Iter 3190/20000] Loss: 0.0011184 (Best: 0.0007953 @iter2983) ([92m↓2.44%[0m) [0.44% of initial]
Iter:3199, L1 loss=0.001017, Total loss=0.001013, Time:32
[Iter 3200/20000] Loss: 0.0010731 (Best: 0.0007953 @iter2983) ([92m↓4.06%[0m) [0.43% of initial]
[Iter 3210/20000] Loss: 0.0056278 (Best: 0.0007953 @iter2983) ([91m↑424.46%[0m) [2.24% of initial]
[Iter 3220/20000] Loss: 0.0032222 (Best: 0.0007953 @iter2983) ([92m↓42.75%[0m) [1.28% of initial]
[Iter 3230/20000] Loss: 0.0020420 (Best: 0.0007953 @iter2983) ([92m↓36.62%[0m) [0.81% of initial]
[Iter 3240/20000] Loss: 0.0017980 (Best: 0.0007953 @iter2983) ([92m↓11.95%[0m) [0.71% of initial]
[Iter 3250/20000] Loss: 0.0013573 (Best: 0.0007953 @iter2983) ([92m↓24.51%[0m) [0.54% of initial]
[Iter 3260/20000] Loss: 0.0012147 (Best: 0.0007953 @iter2983) ([92m↓10.50%[0m) [0.48% of initial]
[Iter 3270/20000] Loss: 0.0012604 (Best: 0.0007953 @iter2983) ([91m↑3.76%[0m) [0.50% of initial]
[Iter 3280/20000] Loss: 0.0013297 (Best: 0.0007953 @iter2983) ([91m↑5.49%[0m) [0.53% of initial]
[Iter 3290/20000] Loss: 0.0010059 (Best: 0.0007953 @iter2983) ([92m↓24.35%[0m) [0.40% of initial]
Iter:3299, L1 loss=0.001448, Total loss=0.001618, Time:32
[Iter 3300/20000] Loss: 0.0013588 (Best: 0.0007953 @iter2983) ([91m↑35.09%[0m) [0.54% of initial]
[Iter 3310/20000] Loss: 0.0010207 (Best: 0.0007953 @iter2983) ([92m↓24.88%[0m) [0.41% of initial]
[Iter 3320/20000] Loss: 0.0011656 (Best: 0.0007953 @iter2983) ([91m↑14.20%[0m) [0.46% of initial]
[Iter 3330/20000] Loss: 0.0012299 (Best: 0.0007953 @iter2983) ([91m↑5.51%[0m) [0.49% of initial]
[Iter 3340/20000] Loss: 0.0013256 (Best: 0.0007953 @iter2983) ([91m↑7.79%[0m) [0.53% of initial]
[Iter 3350/20000] Loss: 0.0010960 (Best: 0.0007953 @iter2983) ([92m↓17.32%[0m) [0.44% of initial]
[Iter 3360/20000] Loss: 0.0013563 (Best: 0.0007953 @iter2983) ([91m↑23.74%[0m) [0.54% of initial]
[Iter 3370/20000] Loss: 0.0009855 (Best: 0.0007953 @iter2983) ([92m↓27.34%[0m) [0.39% of initial]
[Iter 3380/20000] Loss: 0.0009665 (Best: 0.0007933 @iter3379) ([92m↓1.93%[0m) [0.38% of initial]
[Iter 3390/20000] Loss: 0.0012471 (Best: 0.0007933 @iter3379) ([91m↑29.03%[0m) [0.50% of initial]
Iter:3399, L1 loss=0.001536, Total loss=0.001564, Time:33
[Iter 3400/20000] Loss: 0.0012967 (Best: 0.0007933 @iter3379) ([91m↑3.98%[0m) [0.52% of initial]
[Iter 3410/20000] Loss: 0.0051829 (Best: 0.0007933 @iter3379) ([91m↑299.70%[0m) [2.06% of initial]
[Iter 3420/20000] Loss: 0.0025602 (Best: 0.0007933 @iter3379) ([92m↓50.60%[0m) [1.02% of initial]
[Iter 3430/20000] Loss: 0.0016643 (Best: 0.0007933 @iter3379) ([92m↓34.99%[0m) [0.66% of initial]
[Iter 3440/20000] Loss: 0.0014805 (Best: 0.0007933 @iter3379) ([92m↓11.05%[0m) [0.59% of initial]
[Iter 3450/20000] Loss: 0.0014251 (Best: 0.0007933 @iter3379) ([92m↓3.74%[0m) [0.57% of initial]
[Iter 3460/20000] Loss: 0.0012874 (Best: 0.0007933 @iter3379) ([92m↓9.67%[0m) [0.51% of initial]
[Iter 3470/20000] Loss: 0.0012022 (Best: 0.0007933 @iter3379) ([92m↓6.62%[0m) [0.48% of initial]
[Iter 3480/20000] Loss: 0.0010966 (Best: 0.0007933 @iter3379) ([92m↓8.78%[0m) [0.44% of initial]
[Iter 3490/20000] Loss: 0.0010460 (Best: 0.0007933 @iter3379) ([92m↓4.62%[0m) [0.42% of initial]
Iter:3499, L1 loss=0.0007809, Total loss=0.0007549, Time:36
[Iter 3500/20000] Loss: 0.0008266 (Best: 0.0007549 @iter3499) ([92m↓20.97%[0m) [0.33% of initial]
Pruning 307 points (0.2%) from gaussian0 at iteration 3500
Pruning 317 points (0.2%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0025120 (Best: 0.0007549 @iter3499) ([91m↑203.88%[0m) [1.00% of initial]
[Iter 3520/20000] Loss: 0.0016366 (Best: 0.0007549 @iter3499) ([92m↓34.85%[0m) [0.65% of initial]
[Iter 3530/20000] Loss: 0.0012273 (Best: 0.0007549 @iter3499) ([92m↓25.01%[0m) [0.49% of initial]
[Iter 3540/20000] Loss: 0.0013741 (Best: 0.0007549 @iter3499) ([91m↑11.96%[0m) [0.55% of initial]
[Iter 3550/20000] Loss: 0.0012333 (Best: 0.0007549 @iter3499) ([92m↓10.24%[0m) [0.49% of initial]
[Iter 3560/20000] Loss: 0.0010850 (Best: 0.0007549 @iter3499) ([92m↓12.02%[0m) [0.43% of initial]
[Iter 3570/20000] Loss: 0.0011408 (Best: 0.0007549 @iter3499) ([91m↑5.14%[0m) [0.45% of initial]
[Iter 3580/20000] Loss: 0.0008809 (Best: 0.0007549 @iter3499) ([92m↓22.78%[0m) [0.35% of initial]
[Iter 3590/20000] Loss: 0.0008914 (Best: 0.0007549 @iter3499) ([91m↑1.19%[0m) [0.35% of initial]
Iter:3599, L1 loss=0.000775, Total loss=0.0007452, Time:33
[Iter 3600/20000] Loss: 0.0008637 (Best: 0.0007077 @iter3598) ([92m↓3.10%[0m) [0.34% of initial]
[Iter 3610/20000] Loss: 0.0045684 (Best: 0.0007077 @iter3598) ([91m↑428.91%[0m) [1.81% of initial]
[Iter 3620/20000] Loss: 0.0028420 (Best: 0.0007077 @iter3598) ([92m↓37.79%[0m) [1.13% of initial]
[Iter 3630/20000] Loss: 0.0017420 (Best: 0.0007077 @iter3598) ([92m↓38.70%[0m) [0.69% of initial]
[Iter 3640/20000] Loss: 0.0013530 (Best: 0.0007077 @iter3598) ([92m↓22.33%[0m) [0.54% of initial]
[Iter 3650/20000] Loss: 0.0013367 (Best: 0.0007077 @iter3598) ([92m↓1.20%[0m) [0.53% of initial]
[Iter 3660/20000] Loss: 0.0011080 (Best: 0.0007077 @iter3598) ([92m↓17.11%[0m) [0.44% of initial]
[Iter 3670/20000] Loss: 0.0009545 (Best: 0.0007077 @iter3598) ([92m↓13.86%[0m) [0.38% of initial]
[Iter 3680/20000] Loss: 0.0012083 (Best: 0.0007077 @iter3598) ([91m↑26.60%[0m) [0.48% of initial]
[Iter 3690/20000] Loss: 0.0014083 (Best: 0.0007077 @iter3598) ([91m↑16.55%[0m) [0.56% of initial]
Iter:3699, L1 loss=0.001215, Total loss=0.001219, Time:35
[Iter 3700/20000] Loss: 0.0012080 (Best: 0.0007077 @iter3598) ([92m↓14.22%[0m) [0.48% of initial]
[Iter 3710/20000] Loss: 0.0009975 (Best: 0.0007077 @iter3598) ([92m↓17.43%[0m) [0.40% of initial]
[Iter 3720/20000] Loss: 0.0010551 (Best: 0.0007077 @iter3598) ([91m↑5.78%[0m) [0.42% of initial]
[Iter 3730/20000] Loss: 0.0009057 (Best: 0.0007077 @iter3598) ([92m↓14.16%[0m) [0.36% of initial]
[Iter 3740/20000] Loss: 0.0009345 (Best: 0.0007077 @iter3598) ([91m↑3.18%[0m) [0.37% of initial]
[Iter 3750/20000] Loss: 0.0009682 (Best: 0.0007077 @iter3598) ([91m↑3.61%[0m) [0.38% of initial]
[Iter 3760/20000] Loss: 0.0009446 (Best: 0.0007077 @iter3598) ([92m↓2.44%[0m) [0.38% of initial]
[Iter 3770/20000] Loss: 0.0008982 (Best: 0.0007077 @iter3598) ([92m↓4.91%[0m) [0.36% of initial]
[Iter 3780/20000] Loss: 0.0008435 (Best: 0.0006579 @iter3775) ([92m↓6.09%[0m) [0.34% of initial]
[Iter 3790/20000] Loss: 0.0006933 (Best: 0.0006098 @iter3790) ([92m↓17.81%[0m) [0.28% of initial]
Iter:3799, L1 loss=0.0008631, Total loss=0.0008777, Time:28
[Iter 3800/20000] Loss: 0.0008611 (Best: 0.0006098 @iter3790) ([91m↑24.20%[0m) [0.34% of initial]
[Iter 3810/20000] Loss: 0.0042488 (Best: 0.0006098 @iter3790) ([91m↑393.41%[0m) [1.69% of initial]
[Iter 3820/20000] Loss: 0.0023342 (Best: 0.0006098 @iter3790) ([92m↓45.06%[0m) [0.93% of initial]
[Iter 3830/20000] Loss: 0.0014282 (Best: 0.0006098 @iter3790) ([92m↓38.81%[0m) [0.57% of initial]
[Iter 3840/20000] Loss: 0.0015191 (Best: 0.0006098 @iter3790) ([91m↑6.37%[0m) [0.60% of initial]
[Iter 3850/20000] Loss: 0.0011519 (Best: 0.0006098 @iter3790) ([92m↓24.17%[0m) [0.46% of initial]
[Iter 3860/20000] Loss: 0.0011215 (Best: 0.0006098 @iter3790) ([92m↓2.64%[0m) [0.45% of initial]
[Iter 3870/20000] Loss: 0.0009037 (Best: 0.0006098 @iter3790) ([92m↓19.42%[0m) [0.36% of initial]
[Iter 3880/20000] Loss: 0.0009424 (Best: 0.0006098 @iter3790) ([91m↑4.28%[0m) [0.37% of initial]
[Iter 3890/20000] Loss: 0.0007566 (Best: 0.0006098 @iter3790) ([92m↓19.71%[0m) [0.30% of initial]
Iter:3899, L1 loss=0.0008442, Total loss=0.0008249, Time:37
[Iter 3900/20000] Loss: 0.0007970 (Best: 0.0005893 @iter3898) ([91m↑5.33%[0m) [0.32% of initial]
[Iter 3910/20000] Loss: 0.0009577 (Best: 0.0005893 @iter3898) ([91m↑20.16%[0m) [0.38% of initial]
[Iter 3920/20000] Loss: 0.0009955 (Best: 0.0005893 @iter3898) ([91m↑3.95%[0m) [0.40% of initial]
[Iter 3930/20000] Loss: 0.0009716 (Best: 0.0005893 @iter3898) ([92m↓2.40%[0m) [0.39% of initial]
[Iter 3940/20000] Loss: 0.0007991 (Best: 0.0005893 @iter3898) ([92m↓17.76%[0m) [0.32% of initial]
[Iter 3950/20000] Loss: 0.0008867 (Best: 0.0005893 @iter3898) ([91m↑10.96%[0m) [0.35% of initial]
[Iter 3960/20000] Loss: 0.0008975 (Best: 0.0005893 @iter3898) ([91m↑1.22%[0m) [0.36% of initial]
[Iter 3970/20000] Loss: 0.0008014 (Best: 0.0005893 @iter3898) ([92m↓10.71%[0m) [0.32% of initial]
[Iter 3980/20000] Loss: 0.0011550 (Best: 0.0005893 @iter3898) ([91m↑44.11%[0m) [0.46% of initial]
[Iter 3990/20000] Loss: 0.0008777 (Best: 0.0005893 @iter3898) ([92m↓24.01%[0m) [0.35% of initial]
Iter:3999, L1 loss=0.0009605, Total loss=0.0009579, Time:36
[Iter 4000/20000] Loss: 0.0008713 (Best: 0.0005893 @iter3898) ([92m↓0.72%[0m) [0.35% of initial]
Pruning 293 points (0.2%) from gaussian0 at iteration 4000
Pruning 257 points (0.2%) from gaussian1 at iteration 4000
[Iter 4010/20000] Loss: 0.1509534 (Best: 0.0005893 @iter3898) ([91m↑17224.50%[0m) [59.97% of initial]
[Iter 4020/20000] Loss: 0.1042555 (Best: 0.0005893 @iter3898) ([92m↓30.94%[0m) [41.42% of initial]
[Iter 4030/20000] Loss: 0.0666630 (Best: 0.0005893 @iter3898) ([92m↓36.06%[0m) [26.48% of initial]
[Iter 4040/20000] Loss: 0.0372397 (Best: 0.0005893 @iter3898) ([92m↓44.14%[0m) [14.79% of initial]
[Iter 4050/20000] Loss: 0.0171762 (Best: 0.0005893 @iter3898) ([92m↓53.88%[0m) [6.82% of initial]
[Iter 4060/20000] Loss: 0.0080140 (Best: 0.0005893 @iter3898) ([92m↓53.34%[0m) [3.18% of initial]
[Iter 4070/20000] Loss: 0.0049723 (Best: 0.0005893 @iter3898) ([92m↓37.95%[0m) [1.98% of initial]
[Iter 4080/20000] Loss: 0.0037523 (Best: 0.0005893 @iter3898) ([92m↓24.54%[0m) [1.49% of initial]
[Iter 4090/20000] Loss: 0.0027871 (Best: 0.0005893 @iter3898) ([92m↓25.72%[0m) [1.11% of initial]
Iter:4099, L1 loss=0.002193, Total loss=0.002335, Time:47
[Iter 4100/20000] Loss: 0.0023528 (Best: 0.0005893 @iter3898) ([92m↓15.58%[0m) [0.93% of initial]
[Iter 4110/20000] Loss: 0.0020927 (Best: 0.0005893 @iter3898) ([92m↓11.05%[0m) [0.83% of initial]
[Iter 4120/20000] Loss: 0.0018296 (Best: 0.0005893 @iter3898) ([92m↓12.57%[0m) [0.73% of initial]
[Iter 4130/20000] Loss: 0.0018131 (Best: 0.0005893 @iter3898) ([92m↓0.90%[0m) [0.72% of initial]
[Iter 4140/20000] Loss: 0.0016524 (Best: 0.0005893 @iter3898) ([92m↓8.86%[0m) [0.66% of initial]
[Iter 4150/20000] Loss: 0.0014847 (Best: 0.0005893 @iter3898) ([92m↓10.15%[0m) [0.59% of initial]
[Iter 4160/20000] Loss: 0.0015548 (Best: 0.0005893 @iter3898) ([91m↑4.72%[0m) [0.62% of initial]
[Iter 4170/20000] Loss: 0.0014670 (Best: 0.0005893 @iter3898) ([92m↓5.65%[0m) [0.58% of initial]
[Iter 4180/20000] Loss: 0.0014532 (Best: 0.0005893 @iter3898) ([92m↓0.94%[0m) [0.58% of initial]
[Iter 4190/20000] Loss: 0.0012832 (Best: 0.0005893 @iter3898) ([92m↓11.70%[0m) [0.51% of initial]
Iter:4199, L1 loss=0.001243, Total loss=0.001257, Time:45
[Iter 4200/20000] Loss: 0.0013494 (Best: 0.0005893 @iter3898) ([91m↑5.16%[0m) [0.54% of initial]
[Iter 4210/20000] Loss: 0.0034420 (Best: 0.0005893 @iter3898) ([91m↑155.08%[0m) [1.37% of initial]
[Iter 4220/20000] Loss: 0.0022966 (Best: 0.0005893 @iter3898) ([92m↓33.28%[0m) [0.91% of initial]
[Iter 4230/20000] Loss: 0.0015670 (Best: 0.0005893 @iter3898) ([92m↓31.77%[0m) [0.62% of initial]
[Iter 4240/20000] Loss: 0.0013685 (Best: 0.0005893 @iter3898) ([92m↓12.67%[0m) [0.54% of initial]
[Iter 4250/20000] Loss: 0.0013491 (Best: 0.0005893 @iter3898) ([92m↓1.42%[0m) [0.54% of initial]
[Iter 4260/20000] Loss: 0.0013991 (Best: 0.0005893 @iter3898) ([91m↑3.71%[0m) [0.56% of initial]
[Iter 4270/20000] Loss: 0.0013169 (Best: 0.0005893 @iter3898) ([92m↓5.88%[0m) [0.52% of initial]
[Iter 4280/20000] Loss: 0.0010863 (Best: 0.0005893 @iter3898) ([92m↓17.51%[0m) [0.43% of initial]
[Iter 4290/20000] Loss: 0.0010954 (Best: 0.0005893 @iter3898) ([91m↑0.84%[0m) [0.44% of initial]
Iter:4299, L1 loss=0.001303, Total loss=0.001249, Time:47
[Iter 4300/20000] Loss: 0.0010554 (Best: 0.0005893 @iter3898) ([92m↓3.65%[0m) [0.42% of initial]
[Iter 4310/20000] Loss: 0.0010129 (Best: 0.0005893 @iter3898) ([92m↓4.03%[0m) [0.40% of initial]
[Iter 4320/20000] Loss: 0.0011667 (Best: 0.0005893 @iter3898) ([91m↑15.18%[0m) [0.46% of initial]
[Iter 4330/20000] Loss: 0.0010109 (Best: 0.0005893 @iter3898) ([92m↓13.35%[0m) [0.40% of initial]
[Iter 4340/20000] Loss: 0.0010034 (Best: 0.0005893 @iter3898) ([92m↓0.74%[0m) [0.40% of initial]
[Iter 4350/20000] Loss: 0.0009884 (Best: 0.0005893 @iter3898) ([92m↓1.49%[0m) [0.39% of initial]
[Iter 4360/20000] Loss: 0.0009497 (Best: 0.0005893 @iter3898) ([92m↓3.92%[0m) [0.38% of initial]
[Iter 4370/20000] Loss: 0.0009979 (Best: 0.0005893 @iter3898) ([91m↑5.07%[0m) [0.40% of initial]
[Iter 4380/20000] Loss: 0.0010230 (Best: 0.0005893 @iter3898) ([91m↑2.52%[0m) [0.41% of initial]
[Iter 4390/20000] Loss: 0.0009515 (Best: 0.0005893 @iter3898) ([92m↓6.99%[0m) [0.38% of initial]
Iter:4399, L1 loss=0.0008477, Total loss=0.0008333, Time:45
[Iter 4400/20000] Loss: 0.0009355 (Best: 0.0005893 @iter3898) ([92m↓1.68%[0m) [0.37% of initial]
[Iter 4410/20000] Loss: 0.0022363 (Best: 0.0005893 @iter3898) ([91m↑139.04%[0m) [0.89% of initial]
[Iter 4420/20000] Loss: 0.0014923 (Best: 0.0005893 @iter3898) ([92m↓33.27%[0m) [0.59% of initial]
[Iter 4430/20000] Loss: 0.0012770 (Best: 0.0005893 @iter3898) ([92m↓14.42%[0m) [0.51% of initial]
[Iter 4440/20000] Loss: 0.0010866 (Best: 0.0005893 @iter3898) ([92m↓14.91%[0m) [0.43% of initial]
[Iter 4450/20000] Loss: 0.0009849 (Best: 0.0005893 @iter3898) ([92m↓9.35%[0m) [0.39% of initial]
[Iter 4460/20000] Loss: 0.0009724 (Best: 0.0005893 @iter3898) ([92m↓1.27%[0m) [0.39% of initial]
[Iter 4470/20000] Loss: 0.0010854 (Best: 0.0005893 @iter3898) ([91m↑11.62%[0m) [0.43% of initial]
[Iter 4480/20000] Loss: 0.0010389 (Best: 0.0005893 @iter3898) ([92m↓4.29%[0m) [0.41% of initial]
[Iter 4490/20000] Loss: 0.0010052 (Best: 0.0005893 @iter3898) ([92m↓3.24%[0m) [0.40% of initial]
Iter:4499, L1 loss=0.001083, Total loss=0.001031, Time:47
[Iter 4500/20000] Loss: 0.0011270 (Best: 0.0005893 @iter3898) ([91m↑12.12%[0m) [0.45% of initial]
Pruning 305 points (0.2%) from gaussian0 at iteration 4500
Pruning 340 points (0.2%) from gaussian1 at iteration 4500
[Iter 4510/20000] Loss: 0.0018741 (Best: 0.0005893 @iter3898) ([91m↑66.29%[0m) [0.74% of initial]
[Iter 4520/20000] Loss: 0.0015112 (Best: 0.0005893 @iter3898) ([92m↓19.36%[0m) [0.60% of initial]
[Iter 4530/20000] Loss: 0.0014454 (Best: 0.0005893 @iter3898) ([92m↓4.35%[0m) [0.57% of initial]
[Iter 4540/20000] Loss: 0.0011763 (Best: 0.0005893 @iter3898) ([92m↓18.62%[0m) [0.47% of initial]
[Iter 4550/20000] Loss: 0.0010320 (Best: 0.0005893 @iter3898) ([92m↓12.26%[0m) [0.41% of initial]
[Iter 4560/20000] Loss: 0.0010342 (Best: 0.0005893 @iter3898) ([91m↑0.21%[0m) [0.41% of initial]
[Iter 4570/20000] Loss: 0.0009000 (Best: 0.0005893 @iter3898) ([92m↓12.98%[0m) [0.36% of initial]
[Iter 4580/20000] Loss: 0.0008892 (Best: 0.0005893 @iter3898) ([92m↓1.19%[0m) [0.35% of initial]
[Iter 4590/20000] Loss: 0.0009775 (Best: 0.0005893 @iter3898) ([91m↑9.92%[0m) [0.39% of initial]
Iter:4599, L1 loss=0.0009708, Total loss=0.0009429, Time:45
[Iter 4600/20000] Loss: 0.0009146 (Best: 0.0005893 @iter3898) ([92m↓6.43%[0m) [0.36% of initial]
[Iter 4610/20000] Loss: 0.0024649 (Best: 0.0005893 @iter3898) ([91m↑169.51%[0m) [0.98% of initial]
[Iter 4620/20000] Loss: 0.0017129 (Best: 0.0005893 @iter3898) ([92m↓30.51%[0m) [0.68% of initial]
[Iter 4630/20000] Loss: 0.0012168 (Best: 0.0005893 @iter3898) ([92m↓28.96%[0m) [0.48% of initial]
[Iter 4640/20000] Loss: 0.0010630 (Best: 0.0005893 @iter3898) ([92m↓12.65%[0m) [0.42% of initial]
[Iter 4650/20000] Loss: 0.0009742 (Best: 0.0005893 @iter3898) ([92m↓8.35%[0m) [0.39% of initial]
[Iter 4660/20000] Loss: 0.0008604 (Best: 0.0005893 @iter3898) ([92m↓11.68%[0m) [0.34% of initial]
[Iter 4670/20000] Loss: 0.0008477 (Best: 0.0005893 @iter3898) ([92m↓1.48%[0m) [0.34% of initial]
[Iter 4680/20000] Loss: 0.0008326 (Best: 0.0005893 @iter3898) ([92m↓1.78%[0m) [0.33% of initial]
[Iter 4690/20000] Loss: 0.0008157 (Best: 0.0005893 @iter3898) ([92m↓2.03%[0m) [0.32% of initial]
Iter:4699, L1 loss=0.0009038, Total loss=0.0008452, Time:48
[Iter 4700/20000] Loss: 0.0008767 (Best: 0.0005893 @iter3898) ([91m↑7.48%[0m) [0.35% of initial]
[Iter 4710/20000] Loss: 0.0007878 (Best: 0.0005893 @iter3898) ([92m↓10.13%[0m) [0.31% of initial]
[Iter 4720/20000] Loss: 0.0008575 (Best: 0.0005893 @iter3898) ([91m↑8.84%[0m) [0.34% of initial]
[Iter 4730/20000] Loss: 0.0008398 (Best: 0.0005893 @iter3898) ([92m↓2.06%[0m) [0.33% of initial]
[Iter 4740/20000] Loss: 0.0009479 (Best: 0.0005893 @iter3898) ([91m↑12.87%[0m) [0.38% of initial]
[Iter 4750/20000] Loss: 0.0009089 (Best: 0.0005893 @iter3898) ([92m↓4.12%[0m) [0.36% of initial]
[Iter 4760/20000] Loss: 0.0008425 (Best: 0.0005893 @iter3898) ([92m↓7.30%[0m) [0.33% of initial]
[Iter 4770/20000] Loss: 0.0008905 (Best: 0.0005893 @iter3898) ([91m↑5.69%[0m) [0.35% of initial]
[Iter 4780/20000] Loss: 0.0009489 (Best: 0.0005893 @iter3898) ([91m↑6.56%[0m) [0.38% of initial]
[Iter 4790/20000] Loss: 0.0008507 (Best: 0.0005893 @iter3898) ([92m↓10.34%[0m) [0.34% of initial]
Iter:4799, L1 loss=0.0008695, Total loss=0.0008421, Time:45
[Iter 4800/20000] Loss: 0.0009692 (Best: 0.0005893 @iter3898) ([91m↑13.93%[0m) [0.39% of initial]
[Iter 4810/20000] Loss: 0.0019592 (Best: 0.0005893 @iter3898) ([91m↑102.14%[0m) [0.78% of initial]
[Iter 4820/20000] Loss: 0.0015034 (Best: 0.0005893 @iter3898) ([92m↓23.27%[0m) [0.60% of initial]
[Iter 4830/20000] Loss: 0.0012207 (Best: 0.0005893 @iter3898) ([92m↓18.80%[0m) [0.48% of initial]
[Iter 4840/20000] Loss: 0.0009605 (Best: 0.0005893 @iter3898) ([92m↓21.32%[0m) [0.38% of initial]
[Iter 4850/20000] Loss: 0.0008235 (Best: 0.0005893 @iter3898) ([92m↓14.27%[0m) [0.33% of initial]
[Iter 4860/20000] Loss: 0.0008835 (Best: 0.0005893 @iter3898) ([91m↑7.29%[0m) [0.35% of initial]
[Iter 4870/20000] Loss: 0.0007905 (Best: 0.0005893 @iter3898) ([92m↓10.52%[0m) [0.31% of initial]
[Iter 4880/20000] Loss: 0.0008480 (Best: 0.0005893 @iter3898) ([91m↑7.27%[0m) [0.34% of initial]
[Iter 4890/20000] Loss: 0.0007971 (Best: 0.0005893 @iter3898) ([92m↓6.01%[0m) [0.32% of initial]
Iter:4899, L1 loss=0.0008861, Total loss=0.0008623, Time:45
[Iter 4900/20000] Loss: 0.0007813 (Best: 0.0005893 @iter3898) ([92m↓1.98%[0m) [0.31% of initial]
[Iter 4910/20000] Loss: 0.0009760 (Best: 0.0005893 @iter3898) ([91m↑24.93%[0m) [0.39% of initial]
[Iter 4920/20000] Loss: 0.0008369 (Best: 0.0005893 @iter3898) ([92m↓14.25%[0m) [0.33% of initial]
[Iter 4930/20000] Loss: 0.0007474 (Best: 0.0005893 @iter3898) ([92m↓10.69%[0m) [0.30% of initial]
[Iter 4940/20000] Loss: 0.0007870 (Best: 0.0005893 @iter3898) ([91m↑5.30%[0m) [0.31% of initial]
[Iter 4950/20000] Loss: 0.0006894 (Best: 0.0005893 @iter3898) ([92m↓12.40%[0m) [0.27% of initial]
[Iter 4960/20000] Loss: 0.0007212 (Best: 0.0005893 @iter3898) ([91m↑4.62%[0m) [0.29% of initial]
[Iter 4970/20000] Loss: 0.0007611 (Best: 0.0005893 @iter3898) ([91m↑5.53%[0m) [0.30% of initial]
[Iter 4980/20000] Loss: 0.0007873 (Best: 0.0005893 @iter3898) ([91m↑3.44%[0m) [0.31% of initial]
[Iter 4990/20000] Loss: 0.0007197 (Best: 0.0005893 @iter3898) ([92m↓8.59%[0m) [0.29% of initial]
Iter:4999, L1 loss=0.0007129, Total loss=0.00068, Time:47
[Iter 5000/20000] Loss: 0.0006755 (Best: 0.0005893 @iter3898) ([92m↓6.14%[0m) [0.27% of initial]
Pruning 169 points (0.1%) from gaussian0 at iteration 5000
Pruning 173 points (0.1%) from gaussian1 at iteration 5000
[Iter 5010/20000] Loss: 0.0022434 (Best: 0.0005893 @iter3898) ([91m↑232.11%[0m) [0.89% of initial]
[Iter 5020/20000] Loss: 0.0015752 (Best: 0.0005893 @iter3898) ([92m↓29.79%[0m) [0.63% of initial]
[Iter 5030/20000] Loss: 0.0011085 (Best: 0.0005893 @iter3898) ([92m↓29.63%[0m) [0.44% of initial]
[Iter 5040/20000] Loss: 0.0010944 (Best: 0.0005893 @iter3898) ([92m↓1.27%[0m) [0.43% of initial]
[Iter 5050/20000] Loss: 0.0009482 (Best: 0.0005893 @iter3898) ([92m↓13.35%[0m) [0.38% of initial]
[Iter 5060/20000] Loss: 0.0007753 (Best: 0.0005893 @iter3898) ([92m↓18.24%[0m) [0.31% of initial]
[Iter 5070/20000] Loss: 0.0008414 (Best: 0.0005893 @iter3898) ([91m↑8.53%[0m) [0.33% of initial]
[Iter 5080/20000] Loss: 0.0007346 (Best: 0.0005893 @iter3898) ([92m↓12.69%[0m) [0.29% of initial]
[Iter 5090/20000] Loss: 0.0007773 (Best: 0.0005893 @iter3898) ([91m↑5.81%[0m) [0.31% of initial]
Iter:5099, L1 loss=0.0008231, Total loss=0.0007675, Time:53
[Iter 5100/20000] Loss: 0.0008280 (Best: 0.0005893 @iter3898) ([91m↑6.52%[0m) [0.33% of initial]
[Iter 5110/20000] Loss: 0.0008013 (Best: 0.0005893 @iter3898) ([92m↓3.23%[0m) [0.32% of initial]
[Iter 5120/20000] Loss: 0.0008036 (Best: 0.0005893 @iter3898) ([91m↑0.29%[0m) [0.32% of initial]
[Iter 5130/20000] Loss: 0.0008183 (Best: 0.0005893 @iter3898) ([91m↑1.83%[0m) [0.33% of initial]
[Iter 5140/20000] Loss: 0.0007095 (Best: 0.0005893 @iter3898) ([92m↓13.29%[0m) [0.28% of initial]
[Iter 5150/20000] Loss: 0.0007272 (Best: 0.0005893 @iter3898) ([91m↑2.49%[0m) [0.29% of initial]
[Iter 5160/20000] Loss: 0.0007218 (Best: 0.0005893 @iter3898) ([92m↓0.74%[0m) [0.29% of initial]
[Iter 5170/20000] Loss: 0.0007717 (Best: 0.0005893 @iter3898) ([91m↑6.91%[0m) [0.31% of initial]
[Iter 5180/20000] Loss: 0.0007168 (Best: 0.0005893 @iter3898) ([92m↓7.12%[0m) [0.28% of initial]
[Iter 5190/20000] Loss: 0.0007328 (Best: 0.0005893 @iter3898) ([91m↑2.24%[0m) [0.29% of initial]
Iter:5199, L1 loss=0.0007879, Total loss=0.0007599, Time:50
[Iter 5200/20000] Loss: 0.0007058 (Best: 0.0005893 @iter3898) ([92m↓3.70%[0m) [0.28% of initial]
[Iter 5210/20000] Loss: 0.0019077 (Best: 0.0005893 @iter3898) ([91m↑170.30%[0m) [0.76% of initial]
[Iter 5220/20000] Loss: 0.0013919 (Best: 0.0005893 @iter3898) ([92m↓27.04%[0m) [0.55% of initial]
[Iter 5230/20000] Loss: 0.0010224 (Best: 0.0005893 @iter3898) ([92m↓26.55%[0m) [0.41% of initial]
[Iter 5240/20000] Loss: 0.0008042 (Best: 0.0005893 @iter3898) ([92m↓21.34%[0m) [0.32% of initial]
[Iter 5250/20000] Loss: 0.0011098 (Best: 0.0005893 @iter3898) ([91m↑38.01%[0m) [0.44% of initial]
[Iter 5260/20000] Loss: 0.0008808 (Best: 0.0005893 @iter3898) ([92m↓20.63%[0m) [0.35% of initial]
[Iter 5270/20000] Loss: 0.0008038 (Best: 0.0005893 @iter3898) ([92m↓8.74%[0m) [0.32% of initial]
[Iter 5280/20000] Loss: 0.0008816 (Best: 0.0005893 @iter3898) ([91m↑9.67%[0m) [0.35% of initial]
[Iter 5290/20000] Loss: 0.0008300 (Best: 0.0005893 @iter3898) ([92m↓5.84%[0m) [0.33% of initial]
Iter:5299, L1 loss=0.0008955, Total loss=0.0008469, Time:46
[Iter 5300/20000] Loss: 0.0009130 (Best: 0.0005893 @iter3898) ([91m↑10.00%[0m) [0.36% of initial]
[Iter 5310/20000] Loss: 0.0009025 (Best: 0.0005893 @iter3898) ([92m↓1.15%[0m) [0.36% of initial]
[Iter 5320/20000] Loss: 0.0007976 (Best: 0.0005893 @iter3898) ([92m↓11.63%[0m) [0.32% of initial]
[Iter 5330/20000] Loss: 0.0006619 (Best: 0.0005893 @iter3898) ([92m↓17.01%[0m) [0.26% of initial]
[Iter 5340/20000] Loss: 0.0007039 (Best: 0.0005893 @iter3898) ([91m↑6.35%[0m) [0.28% of initial]
[Iter 5350/20000] Loss: 0.0007277 (Best: 0.0005669 @iter5344) ([91m↑3.37%[0m) [0.29% of initial]
[Iter 5360/20000] Loss: 0.0007229 (Best: 0.0005669 @iter5344) ([92m↓0.66%[0m) [0.29% of initial]
[Iter 5370/20000] Loss: 0.0007575 (Best: 0.0005669 @iter5344) ([91m↑4.80%[0m) [0.30% of initial]
[Iter 5380/20000] Loss: 0.0007367 (Best: 0.0005669 @iter5344) ([92m↓2.75%[0m) [0.29% of initial]
[Iter 5390/20000] Loss: 0.0007408 (Best: 0.0005669 @iter5344) ([91m↑0.56%[0m) [0.29% of initial]
Iter:5399, L1 loss=0.0006828, Total loss=0.0006596, Time:44
[Iter 5400/20000] Loss: 0.0007412 (Best: 0.0005669 @iter5344) ([91m↑0.05%[0m) [0.29% of initial]
[Iter 5410/20000] Loss: 0.0015317 (Best: 0.0005669 @iter5344) ([91m↑106.66%[0m) [0.61% of initial]
[Iter 5420/20000] Loss: 0.0012944 (Best: 0.0005669 @iter5344) ([92m↓15.49%[0m) [0.51% of initial]
[Iter 5430/20000] Loss: 0.0008874 (Best: 0.0005669 @iter5344) ([92m↓31.44%[0m) [0.35% of initial]
[Iter 5440/20000] Loss: 0.0008234 (Best: 0.0005669 @iter5344) ([92m↓7.21%[0m) [0.33% of initial]
[Iter 5450/20000] Loss: 0.0007029 (Best: 0.0005669 @iter5344) ([92m↓14.63%[0m) [0.28% of initial]
[Iter 5460/20000] Loss: 0.0007784 (Best: 0.0005669 @iter5344) ([91m↑10.73%[0m) [0.31% of initial]
[Iter 5470/20000] Loss: 0.0006740 (Best: 0.0005669 @iter5344) ([92m↓13.41%[0m) [0.27% of initial]
[Iter 5480/20000] Loss: 0.0006394 (Best: 0.0005411 @iter5476) ([92m↓5.14%[0m) [0.25% of initial]
[Iter 5490/20000] Loss: 0.0006649 (Best: 0.0005411 @iter5476) ([91m↑3.99%[0m) [0.26% of initial]
Iter:5499, L1 loss=0.000712, Total loss=0.0006783, Time:49
[Iter 5500/20000] Loss: 0.0006256 (Best: 0.0005411 @iter5476) ([92m↓5.91%[0m) [0.25% of initial]
Pruning 90 points (0.0%) from gaussian0 at iteration 5500
Pruning 111 points (0.1%) from gaussian1 at iteration 5500
[Iter 5510/20000] Loss: 0.0011625 (Best: 0.0005411 @iter5476) ([91m↑85.83%[0m) [0.46% of initial]
[Iter 5520/20000] Loss: 0.0008885 (Best: 0.0005411 @iter5476) ([92m↓23.57%[0m) [0.35% of initial]
[Iter 5530/20000] Loss: 0.0008250 (Best: 0.0005411 @iter5476) ([92m↓7.15%[0m) [0.33% of initial]
[Iter 5540/20000] Loss: 0.0007630 (Best: 0.0005411 @iter5476) ([92m↓7.52%[0m) [0.30% of initial]
[Iter 5550/20000] Loss: 0.0007237 (Best: 0.0005411 @iter5476) ([92m↓5.15%[0m) [0.29% of initial]
[Iter 5560/20000] Loss: 0.0006744 (Best: 0.0005411 @iter5476) ([92m↓6.81%[0m) [0.27% of initial]
[Iter 5570/20000] Loss: 0.0006707 (Best: 0.0005411 @iter5476) ([92m↓0.56%[0m) [0.27% of initial]
[Iter 5580/20000] Loss: 0.0007783 (Best: 0.0005411 @iter5476) ([91m↑16.04%[0m) [0.31% of initial]
[Iter 5590/20000] Loss: 0.0008205 (Best: 0.0005411 @iter5476) ([91m↑5.42%[0m) [0.33% of initial]
Iter:5599, L1 loss=0.0006535, Total loss=0.0006218, Time:45
[Iter 5600/20000] Loss: 0.0006420 (Best: 0.0005411 @iter5476) ([92m↓21.76%[0m) [0.26% of initial]
[Iter 5610/20000] Loss: 0.0017242 (Best: 0.0005411 @iter5476) ([91m↑168.59%[0m) [0.69% of initial]
[Iter 5620/20000] Loss: 0.0010798 (Best: 0.0005411 @iter5476) ([92m↓37.37%[0m) [0.43% of initial]
[Iter 5630/20000] Loss: 0.0008919 (Best: 0.0005411 @iter5476) ([92m↓17.40%[0m) [0.35% of initial]
[Iter 5640/20000] Loss: 0.0008263 (Best: 0.0005411 @iter5476) ([92m↓7.35%[0m) [0.33% of initial]
[Iter 5650/20000] Loss: 0.0007010 (Best: 0.0005411 @iter5476) ([92m↓15.17%[0m) [0.28% of initial]
[Iter 5660/20000] Loss: 0.0006971 (Best: 0.0005411 @iter5476) ([92m↓0.55%[0m) [0.28% of initial]
[Iter 5670/20000] Loss: 0.0007007 (Best: 0.0005411 @iter5476) ([91m↑0.51%[0m) [0.28% of initial]
[Iter 5680/20000] Loss: 0.0006421 (Best: 0.0005411 @iter5476) ([92m↓8.37%[0m) [0.26% of initial]
[Iter 5690/20000] Loss: 0.0006927 (Best: 0.0005411 @iter5476) ([91m↑7.89%[0m) [0.28% of initial]
Iter:5699, L1 loss=0.0006601, Total loss=0.0006109, Time:49
[Iter 5700/20000] Loss: 0.0005998 (Best: 0.0005411 @iter5476) ([92m↓13.42%[0m) [0.24% of initial]
[Iter 5710/20000] Loss: 0.0007573 (Best: 0.0005273 @iter5701) ([91m↑26.27%[0m) [0.30% of initial]
[Iter 5720/20000] Loss: 0.0006786 (Best: 0.0005273 @iter5701) ([92m↓10.39%[0m) [0.27% of initial]
[Iter 5730/20000] Loss: 0.0006995 (Best: 0.0005273 @iter5701) ([91m↑3.08%[0m) [0.28% of initial]
[Iter 5740/20000] Loss: 0.0005895 (Best: 0.0005273 @iter5701) ([92m↓15.73%[0m) [0.23% of initial]
[Iter 5750/20000] Loss: 0.0006043 (Best: 0.0005273 @iter5701) ([91m↑2.50%[0m) [0.24% of initial]
[Iter 5760/20000] Loss: 0.0006093 (Best: 0.0005273 @iter5701) ([91m↑0.83%[0m) [0.24% of initial]
[Iter 5770/20000] Loss: 0.0005415 (Best: 0.0004907 @iter5770) ([92m↓11.13%[0m) [0.22% of initial]
[Iter 5780/20000] Loss: 0.0005630 (Best: 0.0004907 @iter5770) ([91m↑3.97%[0m) [0.22% of initial]
[Iter 5790/20000] Loss: 0.0006044 (Best: 0.0004907 @iter5770) ([91m↑7.36%[0m) [0.24% of initial]
Iter:5799, L1 loss=0.0006049, Total loss=0.0005769, Time:46
[Iter 5800/20000] Loss: 0.0005710 (Best: 0.0004636 @iter5797) ([92m↓5.53%[0m) [0.23% of initial]
[Iter 5810/20000] Loss: 0.0012870 (Best: 0.0004636 @iter5797) ([91m↑125.41%[0m) [0.51% of initial]
[Iter 5820/20000] Loss: 0.0010322 (Best: 0.0004636 @iter5797) ([92m↓19.80%[0m) [0.41% of initial]
[Iter 5830/20000] Loss: 0.0008007 (Best: 0.0004636 @iter5797) ([92m↓22.43%[0m) [0.32% of initial]
[Iter 5840/20000] Loss: 0.0007060 (Best: 0.0004636 @iter5797) ([92m↓11.82%[0m) [0.28% of initial]
[Iter 5850/20000] Loss: 0.0007289 (Best: 0.0004636 @iter5797) ([91m↑3.24%[0m) [0.29% of initial]
[Iter 5860/20000] Loss: 0.0006050 (Best: 0.0004636 @iter5797) ([92m↓17.01%[0m) [0.24% of initial]
[Iter 5870/20000] Loss: 0.0006936 (Best: 0.0004636 @iter5797) ([91m↑14.66%[0m) [0.28% of initial]
[Iter 5880/20000] Loss: 0.0006495 (Best: 0.0004636 @iter5797) ([92m↓6.36%[0m) [0.26% of initial]
[Iter 5890/20000] Loss: 0.0006081 (Best: 0.0004636 @iter5797) ([92m↓6.38%[0m) [0.24% of initial]
Iter:5899, L1 loss=0.000615, Total loss=0.0005772, Time:63
[Iter 5900/20000] Loss: 0.0005901 (Best: 0.0004636 @iter5797) ([92m↓2.96%[0m) [0.23% of initial]
[Iter 5910/20000] Loss: 0.0006280 (Best: 0.0004636 @iter5797) ([91m↑6.43%[0m) [0.25% of initial]
[Iter 5920/20000] Loss: 0.0005960 (Best: 0.0004636 @iter5797) ([92m↓5.10%[0m) [0.24% of initial]
[Iter 5930/20000] Loss: 0.0005069 (Best: 0.0004636 @iter5797) ([92m↓14.94%[0m) [0.20% of initial]
[Iter 5940/20000] Loss: 0.0006668 (Best: 0.0004636 @iter5797) ([91m↑31.54%[0m) [0.26% of initial]
[Iter 5950/20000] Loss: 0.0005495 (Best: 0.0004636 @iter5797) ([92m↓17.59%[0m) [0.22% of initial]
[Iter 5960/20000] Loss: 0.0005904 (Best: 0.0004636 @iter5797) ([91m↑7.45%[0m) [0.23% of initial]
[Iter 5970/20000] Loss: 0.0006967 (Best: 0.0004636 @iter5797) ([91m↑17.99%[0m) [0.28% of initial]
[Iter 5980/20000] Loss: 0.0006166 (Best: 0.0004636 @iter5797) ([92m↓11.50%[0m) [0.24% of initial]
[Iter 5990/20000] Loss: 0.0006217 (Best: 0.0004636 @iter5797) ([91m↑0.83%[0m) [0.25% of initial]
Iter:5999, L1 loss=0.0006657, Total loss=0.0006314, Time:45
[Iter 6000/20000] Loss: 0.0006280 (Best: 0.0004636 @iter5797) ([91m↑1.01%[0m) [0.25% of initial]
Pruning 87 points (0.0%) from gaussian0 at iteration 6000
Pruning 75 points (0.0%) from gaussian1 at iteration 6000
[Iter 6010/20000] Loss: 0.0019937 (Best: 0.0004636 @iter5797) ([91m↑217.46%[0m) [0.79% of initial]
[Iter 6020/20000] Loss: 0.0012910 (Best: 0.0004636 @iter5797) ([92m↓35.25%[0m) [0.51% of initial]
[Iter 6030/20000] Loss: 0.0008820 (Best: 0.0004636 @iter5797) ([92m↓31.69%[0m) [0.35% of initial]
[Iter 6040/20000] Loss: 0.0006916 (Best: 0.0004636 @iter5797) ([92m↓21.58%[0m) [0.27% of initial]
[Iter 6050/20000] Loss: 0.0006242 (Best: 0.0004636 @iter5797) ([92m↓9.74%[0m) [0.25% of initial]
[Iter 6060/20000] Loss: 0.0006624 (Best: 0.0004636 @iter5797) ([91m↑6.11%[0m) [0.26% of initial]
[Iter 6070/20000] Loss: 0.0006450 (Best: 0.0004636 @iter5797) ([92m↓2.63%[0m) [0.26% of initial]
[Iter 6080/20000] Loss: 0.0006430 (Best: 0.0004636 @iter5797) ([92m↓0.30%[0m) [0.26% of initial]
[Iter 6090/20000] Loss: 0.0005856 (Best: 0.0004636 @iter5797) ([92m↓8.93%[0m) [0.23% of initial]
Iter:6099, L1 loss=0.0005932, Total loss=0.0005514, Time:47
[Iter 6100/20000] Loss: 0.0005850 (Best: 0.0004636 @iter5797) ([92m↓0.09%[0m) [0.23% of initial]
[Iter 6110/20000] Loss: 0.0005718 (Best: 0.0004636 @iter5797) ([92m↓2.26%[0m) [0.23% of initial]
[Iter 6120/20000] Loss: 0.0006419 (Best: 0.0004636 @iter5797) ([91m↑12.26%[0m) [0.26% of initial]
[Iter 6130/20000] Loss: 0.0006138 (Best: 0.0004636 @iter5797) ([92m↓4.37%[0m) [0.24% of initial]
[Iter 6140/20000] Loss: 0.0005259 (Best: 0.0004636 @iter5797) ([92m↓14.33%[0m) [0.21% of initial]
[Iter 6150/20000] Loss: 0.0005527 (Best: 0.0004636 @iter5797) ([91m↑5.11%[0m) [0.22% of initial]
[Iter 6160/20000] Loss: 0.0005346 (Best: 0.0004636 @iter5797) ([92m↓3.27%[0m) [0.21% of initial]
[Iter 6170/20000] Loss: 0.0005613 (Best: 0.0004636 @iter5797) ([91m↑4.99%[0m) [0.22% of initial]
[Iter 6180/20000] Loss: 0.0006293 (Best: 0.0004636 @iter5797) ([91m↑12.11%[0m) [0.25% of initial]
[Iter 6190/20000] Loss: 0.0005344 (Best: 0.0004636 @iter5797) ([92m↓15.08%[0m) [0.21% of initial]
Iter:6199, L1 loss=0.0005271, Total loss=0.0004854, Time:48
[Iter 6200/20000] Loss: 0.0005400 (Best: 0.0004636 @iter5797) ([91m↑1.05%[0m) [0.21% of initial]
[Iter 6210/20000] Loss: 0.0012952 (Best: 0.0004636 @iter5797) ([91m↑139.86%[0m) [0.51% of initial]
[Iter 6220/20000] Loss: 0.0009411 (Best: 0.0004636 @iter5797) ([92m↓27.34%[0m) [0.37% of initial]
[Iter 6230/20000] Loss: 0.0008393 (Best: 0.0004636 @iter5797) ([92m↓10.81%[0m) [0.33% of initial]
[Iter 6240/20000] Loss: 0.0006827 (Best: 0.0004636 @iter5797) ([92m↓18.66%[0m) [0.27% of initial]
[Iter 6250/20000] Loss: 0.0006082 (Best: 0.0004636 @iter5797) ([92m↓10.90%[0m) [0.24% of initial]
[Iter 6260/20000] Loss: 0.0007019 (Best: 0.0004636 @iter5797) ([91m↑15.40%[0m) [0.28% of initial]
[Iter 6270/20000] Loss: 0.0006226 (Best: 0.0004636 @iter5797) ([92m↓11.30%[0m) [0.25% of initial]
[Iter 6280/20000] Loss: 0.0006626 (Best: 0.0004636 @iter5797) ([91m↑6.42%[0m) [0.26% of initial]
[Iter 6290/20000] Loss: 0.0005930 (Best: 0.0004636 @iter5797) ([92m↓10.50%[0m) [0.24% of initial]
Iter:6299, L1 loss=0.0007357, Total loss=0.0006753, Time:47
[Iter 6300/20000] Loss: 0.0007885 (Best: 0.0004636 @iter5797) ([91m↑32.97%[0m) [0.31% of initial]
[Iter 6310/20000] Loss: 0.0006745 (Best: 0.0004636 @iter5797) ([92m↓14.46%[0m) [0.27% of initial]
[Iter 6320/20000] Loss: 0.0006674 (Best: 0.0004636 @iter5797) ([92m↓1.05%[0m) [0.27% of initial]
[Iter 6330/20000] Loss: 0.0006346 (Best: 0.0004636 @iter5797) ([92m↓4.92%[0m) [0.25% of initial]
[Iter 6340/20000] Loss: 0.0005132 (Best: 0.0004580 @iter6340) ([92m↓19.13%[0m) [0.20% of initial]
[Iter 6350/20000] Loss: 0.0005234 (Best: 0.0004580 @iter6340) ([91m↑1.99%[0m) [0.21% of initial]
[Iter 6360/20000] Loss: 0.0005989 (Best: 0.0004580 @iter6340) ([91m↑14.43%[0m) [0.24% of initial]
[Iter 6370/20000] Loss: 0.0005790 (Best: 0.0004571 @iter6364) ([92m↓3.33%[0m) [0.23% of initial]
[Iter 6380/20000] Loss: 0.0005245 (Best: 0.0004571 @iter6364) ([92m↓9.40%[0m) [0.21% of initial]
[Iter 6390/20000] Loss: 0.0005524 (Best: 0.0004525 @iter6382) ([91m↑5.32%[0m) [0.22% of initial]
Iter:6399, L1 loss=0.0005685, Total loss=0.000524, Time:50
[Iter 6400/20000] Loss: 0.0005780 (Best: 0.0004525 @iter6382) ([91m↑4.63%[0m) [0.23% of initial]
[Iter 6410/20000] Loss: 0.0012825 (Best: 0.0004525 @iter6382) ([91m↑121.89%[0m) [0.51% of initial]
[Iter 6420/20000] Loss: 0.0010541 (Best: 0.0004525 @iter6382) ([92m↓17.81%[0m) [0.42% of initial]
[Iter 6430/20000] Loss: 0.0009096 (Best: 0.0004525 @iter6382) ([92m↓13.71%[0m) [0.36% of initial]
[Iter 6440/20000] Loss: 0.0007543 (Best: 0.0004525 @iter6382) ([92m↓17.08%[0m) [0.30% of initial]
[Iter 6450/20000] Loss: 0.0006857 (Best: 0.0004525 @iter6382) ([92m↓9.09%[0m) [0.27% of initial]
[Iter 6460/20000] Loss: 0.0005871 (Best: 0.0004525 @iter6382) ([92m↓14.38%[0m) [0.23% of initial]
[Iter 6470/20000] Loss: 0.0005759 (Best: 0.0004525 @iter6382) ([92m↓1.91%[0m) [0.23% of initial]
[Iter 6480/20000] Loss: 0.0005767 (Best: 0.0004525 @iter6382) ([91m↑0.13%[0m) [0.23% of initial]
[Iter 6490/20000] Loss: 0.0005271 (Best: 0.0004525 @iter6382) ([92m↓8.59%[0m) [0.21% of initial]
Iter:6499, L1 loss=0.0006453, Total loss=0.0006404, Time:47
[Iter 6500/20000] Loss: 0.0006148 (Best: 0.0004525 @iter6382) ([91m↑16.63%[0m) [0.24% of initial]
Pruning 65 points (0.0%) from gaussian0 at iteration 6500
Pruning 77 points (0.0%) from gaussian1 at iteration 6500
[Iter 6510/20000] Loss: 0.0013307 (Best: 0.0004525 @iter6382) ([91m↑116.45%[0m) [0.53% of initial]
[Iter 6520/20000] Loss: 0.0008475 (Best: 0.0004525 @iter6382) ([92m↓36.31%[0m) [0.34% of initial]
[Iter 6530/20000] Loss: 0.0007727 (Best: 0.0004525 @iter6382) ([92m↓8.83%[0m) [0.31% of initial]
[Iter 6540/20000] Loss: 0.0006198 (Best: 0.0004525 @iter6382) ([92m↓19.79%[0m) [0.25% of initial]
[Iter 6550/20000] Loss: 0.0005630 (Best: 0.0004525 @iter6382) ([92m↓9.16%[0m) [0.22% of initial]
[Iter 6560/20000] Loss: 0.0004760 (Best: 0.0004479 @iter6559) ([92m↓15.45%[0m) [0.19% of initial]
[Iter 6570/20000] Loss: 0.0005741 (Best: 0.0004291 @iter6568) ([91m↑20.60%[0m) [0.23% of initial]
[Iter 6580/20000] Loss: 0.0005719 (Best: 0.0004291 @iter6568) ([92m↓0.37%[0m) [0.23% of initial]
[Iter 6590/20000] Loss: 0.0004833 (Best: 0.0004291 @iter6568) ([92m↓15.50%[0m) [0.19% of initial]
Iter:6599, L1 loss=0.0005443, Total loss=0.0004968, Time:48
[Iter 6600/20000] Loss: 0.0005183 (Best: 0.0004291 @iter6568) ([91m↑7.25%[0m) [0.21% of initial]
[Iter 6610/20000] Loss: 0.0012198 (Best: 0.0004291 @iter6568) ([91m↑135.32%[0m) [0.48% of initial]
[Iter 6620/20000] Loss: 0.0008631 (Best: 0.0004291 @iter6568) ([92m↓29.24%[0m) [0.34% of initial]
[Iter 6630/20000] Loss: 0.0006561 (Best: 0.0004291 @iter6568) ([92m↓23.99%[0m) [0.26% of initial]
[Iter 6640/20000] Loss: 0.0005486 (Best: 0.0004291 @iter6568) ([92m↓16.38%[0m) [0.22% of initial]
[Iter 6650/20000] Loss: 0.0005326 (Best: 0.0004291 @iter6568) ([92m↓2.92%[0m) [0.21% of initial]
[Iter 6660/20000] Loss: 0.0005998 (Best: 0.0004291 @iter6568) ([91m↑12.63%[0m) [0.24% of initial]
[Iter 6670/20000] Loss: 0.0005783 (Best: 0.0004291 @iter6568) ([92m↓3.59%[0m) [0.23% of initial]
[Iter 6680/20000] Loss: 0.0006007 (Best: 0.0004291 @iter6568) ([91m↑3.88%[0m) [0.24% of initial]
[Iter 6690/20000] Loss: 0.0005541 (Best: 0.0004291 @iter6568) ([92m↓7.76%[0m) [0.22% of initial]
Iter:6699, L1 loss=0.0006127, Total loss=0.0005619, Time:50
[Iter 6700/20000] Loss: 0.0005268 (Best: 0.0004291 @iter6568) ([92m↓4.93%[0m) [0.21% of initial]
[Iter 6710/20000] Loss: 0.0005757 (Best: 0.0004291 @iter6568) ([91m↑9.28%[0m) [0.23% of initial]
[Iter 6720/20000] Loss: 0.0005211 (Best: 0.0004291 @iter6568) ([92m↓9.48%[0m) [0.21% of initial]
[Iter 6730/20000] Loss: 0.0004686 (Best: 0.0004281 @iter6724) ([92m↓10.07%[0m) [0.19% of initial]
[Iter 6740/20000] Loss: 0.0004995 (Best: 0.0004267 @iter6731) ([91m↑6.58%[0m) [0.20% of initial]
[Iter 6750/20000] Loss: 0.0005180 (Best: 0.0004267 @iter6731) ([91m↑3.72%[0m) [0.21% of initial]
[Iter 6760/20000] Loss: 0.0004921 (Best: 0.0004267 @iter6731) ([92m↓5.01%[0m) [0.20% of initial]
[Iter 6770/20000] Loss: 0.0004797 (Best: 0.0004267 @iter6731) ([92m↓2.52%[0m) [0.19% of initial]
[Iter 6780/20000] Loss: 0.0004461 (Best: 0.0004217 @iter6778) ([92m↓7.00%[0m) [0.18% of initial]
[Iter 6790/20000] Loss: 0.0005169 (Best: 0.0003938 @iter6781) ([91m↑15.89%[0m) [0.21% of initial]
Iter:6799, L1 loss=0.000459, Total loss=0.0004292, Time:50
[Iter 6800/20000] Loss: 0.0004511 (Best: 0.0003938 @iter6781) ([92m↓12.75%[0m) [0.18% of initial]
[Iter 6810/20000] Loss: 0.0010815 (Best: 0.0003938 @iter6781) ([91m↑139.77%[0m) [0.43% of initial]
[Iter 6820/20000] Loss: 0.0008902 (Best: 0.0003938 @iter6781) ([92m↓17.69%[0m) [0.35% of initial]
[Iter 6830/20000] Loss: 0.0006628 (Best: 0.0003938 @iter6781) ([92m↓25.54%[0m) [0.26% of initial]
[Iter 6840/20000] Loss: 0.0005799 (Best: 0.0003938 @iter6781) ([92m↓12.52%[0m) [0.23% of initial]
[Iter 6850/20000] Loss: 0.0005601 (Best: 0.0003938 @iter6781) ([92m↓3.41%[0m) [0.22% of initial]
[Iter 6860/20000] Loss: 0.0005178 (Best: 0.0003938 @iter6781) ([92m↓7.56%[0m) [0.21% of initial]
[Iter 6870/20000] Loss: 0.0005035 (Best: 0.0003938 @iter6781) ([92m↓2.76%[0m) [0.20% of initial]
[Iter 6880/20000] Loss: 0.0004751 (Best: 0.0003938 @iter6781) ([92m↓5.64%[0m) [0.19% of initial]
[Iter 6890/20000] Loss: 0.0005606 (Best: 0.0003938 @iter6781) ([91m↑18.00%[0m) [0.22% of initial]
Iter:6899, L1 loss=0.0006201, Total loss=0.0005535, Time:53
[Iter 6900/20000] Loss: 0.0005544 (Best: 0.0003938 @iter6781) ([92m↓1.11%[0m) [0.22% of initial]
[Iter 6910/20000] Loss: 0.0005599 (Best: 0.0003938 @iter6781) ([91m↑1.00%[0m) [0.22% of initial]
[Iter 6920/20000] Loss: 0.0005061 (Best: 0.0003938 @iter6781) ([92m↓9.62%[0m) [0.20% of initial]
[Iter 6930/20000] Loss: 0.0005178 (Best: 0.0003938 @iter6781) ([91m↑2.32%[0m) [0.21% of initial]
[Iter 6940/20000] Loss: 0.0004580 (Best: 0.0003938 @iter6781) ([92m↓11.56%[0m) [0.18% of initial]
[Iter 6950/20000] Loss: 0.0004607 (Best: 0.0003938 @iter6781) ([91m↑0.59%[0m) [0.18% of initial]
[Iter 6960/20000] Loss: 0.0004383 (Best: 0.0003938 @iter6781) ([92m↓4.86%[0m) [0.17% of initial]
[Iter 6970/20000] Loss: 0.0005168 (Best: 0.0003869 @iter6961) ([91m↑17.89%[0m) [0.21% of initial]
[Iter 6980/20000] Loss: 0.0005227 (Best: 0.0003869 @iter6961) ([91m↑1.15%[0m) [0.21% of initial]
[Iter 6990/20000] Loss: 0.0004772 (Best: 0.0003869 @iter6961) ([92m↓8.70%[0m) [0.19% of initial]
Iter:6999, L1 loss=0.0005963, Total loss=0.0005725, Time:46
[Iter 7000/20000] Loss: 0.0004809 (Best: 0.0003869 @iter6961) ([91m↑0.78%[0m) [0.19% of initial]
Pruning 50 points (0.0%) from gaussian0 at iteration 7000
Pruning 71 points (0.0%) from gaussian1 at iteration 7000
[Iter 7010/20000] Loss: 0.0013936 (Best: 0.0003869 @iter6961) ([91m↑189.78%[0m) [0.55% of initial]
[Iter 7020/20000] Loss: 0.0009466 (Best: 0.0003869 @iter6961) ([92m↓32.08%[0m) [0.38% of initial]
[Iter 7030/20000] Loss: 0.0006798 (Best: 0.0003869 @iter6961) ([92m↓28.18%[0m) [0.27% of initial]
[Iter 7040/20000] Loss: 0.0005720 (Best: 0.0003869 @iter6961) ([92m↓15.86%[0m) [0.23% of initial]
[Iter 7050/20000] Loss: 0.0005390 (Best: 0.0003869 @iter6961) ([92m↓5.77%[0m) [0.21% of initial]
[Iter 7060/20000] Loss: 0.0005704 (Best: 0.0003869 @iter6961) ([91m↑5.82%[0m) [0.23% of initial]
[Iter 7070/20000] Loss: 0.0005135 (Best: 0.0003869 @iter6961) ([92m↓9.97%[0m) [0.20% of initial]
[Iter 7080/20000] Loss: 0.0005249 (Best: 0.0003869 @iter6961) ([91m↑2.22%[0m) [0.21% of initial]
[Iter 7090/20000] Loss: 0.0005500 (Best: 0.0003869 @iter6961) ([91m↑4.77%[0m) [0.22% of initial]
Iter:7099, L1 loss=0.0005262, Total loss=0.0004664, Time:46
[Iter 7100/20000] Loss: 0.0005001 (Best: 0.0003869 @iter6961) ([92m↓9.06%[0m) [0.20% of initial]
[Iter 7110/20000] Loss: 0.0005138 (Best: 0.0003869 @iter6961) ([91m↑2.72%[0m) [0.20% of initial]
[Iter 7120/20000] Loss: 0.0004745 (Best: 0.0003869 @iter6961) ([92m↓7.65%[0m) [0.19% of initial]
[Iter 7130/20000] Loss: 0.0004574 (Best: 0.0003869 @iter6961) ([92m↓3.59%[0m) [0.18% of initial]
[Iter 7140/20000] Loss: 0.0005380 (Best: 0.0003869 @iter6961) ([91m↑17.62%[0m) [0.21% of initial]
[Iter 7150/20000] Loss: 0.0004866 (Best: 0.0003869 @iter6961) ([92m↓9.56%[0m) [0.19% of initial]
[Iter 7160/20000] Loss: 0.0004872 (Best: 0.0003869 @iter6961) ([91m↑0.14%[0m) [0.19% of initial]
[Iter 7170/20000] Loss: 0.0005008 (Best: 0.0003869 @iter6961) ([91m↑2.78%[0m) [0.20% of initial]
[Iter 7180/20000] Loss: 0.0005095 (Best: 0.0003869 @iter6961) ([91m↑1.75%[0m) [0.20% of initial]
[Iter 7190/20000] Loss: 0.0004401 (Best: 0.0003869 @iter6961) ([92m↓13.62%[0m) [0.17% of initial]
Iter:7199, L1 loss=0.0004851, Total loss=0.0004594, Time:46
[Iter 7200/20000] Loss: 0.0004657 (Best: 0.0003869 @iter6961) ([91m↑5.82%[0m) [0.19% of initial]
[Iter 7210/20000] Loss: 0.0011658 (Best: 0.0003869 @iter6961) ([91m↑150.32%[0m) [0.46% of initial]
[Iter 7220/20000] Loss: 0.0009502 (Best: 0.0003869 @iter6961) ([92m↓18.50%[0m) [0.38% of initial]
[Iter 7230/20000] Loss: 0.0007286 (Best: 0.0003869 @iter6961) ([92m↓23.31%[0m) [0.29% of initial]
[Iter 7240/20000] Loss: 0.0006093 (Best: 0.0003869 @iter6961) ([92m↓16.37%[0m) [0.24% of initial]
[Iter 7250/20000] Loss: 0.0005233 (Best: 0.0003869 @iter6961) ([92m↓14.13%[0m) [0.21% of initial]
[Iter 7260/20000] Loss: 0.0004909 (Best: 0.0003869 @iter6961) ([92m↓6.18%[0m) [0.20% of initial]
[Iter 7270/20000] Loss: 0.0004530 (Best: 0.0003869 @iter6961) ([92m↓7.72%[0m) [0.18% of initial]
[Iter 7280/20000] Loss: 0.0004391 (Best: 0.0003838 @iter7276) ([92m↓3.07%[0m) [0.17% of initial]
[Iter 7290/20000] Loss: 0.0004642 (Best: 0.0003838 @iter7276) ([91m↑5.71%[0m) [0.18% of initial]
Iter:7299, L1 loss=0.000556, Total loss=0.0005305, Time:46
[Iter 7300/20000] Loss: 0.0004824 (Best: 0.0003838 @iter7276) ([91m↑3.92%[0m) [0.19% of initial]
[Iter 7310/20000] Loss: 0.0004689 (Best: 0.0003838 @iter7276) ([92m↓2.80%[0m) [0.19% of initial]
[Iter 7320/20000] Loss: 0.0005472 (Best: 0.0003838 @iter7276) ([91m↑16.70%[0m) [0.22% of initial]
[Iter 7330/20000] Loss: 0.0005120 (Best: 0.0003838 @iter7276) ([92m↓6.43%[0m) [0.20% of initial]
[Iter 7340/20000] Loss: 0.0004697 (Best: 0.0003838 @iter7276) ([92m↓8.26%[0m) [0.19% of initial]
[Iter 7350/20000] Loss: 0.0005179 (Best: 0.0003838 @iter7276) ([91m↑10.24%[0m) [0.21% of initial]
[Iter 7360/20000] Loss: 0.0005206 (Best: 0.0003838 @iter7276) ([91m↑0.53%[0m) [0.21% of initial]
[Iter 7370/20000] Loss: 0.0004584 (Best: 0.0003838 @iter7276) ([92m↓11.96%[0m) [0.18% of initial]
[Iter 7380/20000] Loss: 0.0005869 (Best: 0.0003838 @iter7276) ([91m↑28.05%[0m) [0.23% of initial]
[Iter 7390/20000] Loss: 0.0006195 (Best: 0.0003838 @iter7276) ([91m↑5.54%[0m) [0.25% of initial]
Iter:7399, L1 loss=0.0006252, Total loss=0.0005755, Time:48
[Iter 7400/20000] Loss: 0.0006135 (Best: 0.0003838 @iter7276) ([92m↓0.97%[0m) [0.24% of initial]
[Iter 7410/20000] Loss: 0.0012206 (Best: 0.0003838 @iter7276) ([91m↑98.95%[0m) [0.48% of initial]
[Iter 7420/20000] Loss: 0.0008264 (Best: 0.0003838 @iter7276) ([92m↓32.30%[0m) [0.33% of initial]
[Iter 7430/20000] Loss: 0.0006898 (Best: 0.0003838 @iter7276) ([92m↓16.52%[0m) [0.27% of initial]
[Iter 7440/20000] Loss: 0.0006338 (Best: 0.0003838 @iter7276) ([92m↓8.12%[0m) [0.25% of initial]
[Iter 7450/20000] Loss: 0.0005729 (Best: 0.0003838 @iter7276) ([92m↓9.62%[0m) [0.23% of initial]
[Iter 7460/20000] Loss: 0.0005401 (Best: 0.0003838 @iter7276) ([92m↓5.72%[0m) [0.21% of initial]
[Iter 7470/20000] Loss: 0.0004990 (Best: 0.0003838 @iter7276) ([92m↓7.61%[0m) [0.20% of initial]
[Iter 7480/20000] Loss: 0.0005019 (Best: 0.0003838 @iter7276) ([91m↑0.57%[0m) [0.20% of initial]
[Iter 7490/20000] Loss: 0.0004336 (Best: 0.0003838 @iter7276) ([92m↓13.60%[0m) [0.17% of initial]
Iter:7499, L1 loss=0.0004853, Total loss=0.0004622, Time:51
[Iter 7500/20000] Loss: 0.0004835 (Best: 0.0003838 @iter7276) ([91m↑11.51%[0m) [0.19% of initial]
Pruning 45 points (0.0%) from gaussian0 at iteration 7500
Pruning 75 points (0.0%) from gaussian1 at iteration 7500
[Iter 7510/20000] Loss: 0.0011664 (Best: 0.0003838 @iter7276) ([91m↑141.21%[0m) [0.46% of initial]
[Iter 7520/20000] Loss: 0.0007618 (Best: 0.0003838 @iter7276) ([92m↓34.68%[0m) [0.30% of initial]
[Iter 7530/20000] Loss: 0.0005886 (Best: 0.0003838 @iter7276) ([92m↓22.74%[0m) [0.23% of initial]
[Iter 7540/20000] Loss: 0.0004357 (Best: 0.0003838 @iter7276) ([92m↓25.99%[0m) [0.17% of initial]
[Iter 7550/20000] Loss: 0.0004381 (Best: 0.0003838 @iter7276) ([91m↑0.57%[0m) [0.17% of initial]
[Iter 7560/20000] Loss: 0.0004262 (Best: 0.0003704 @iter7555) ([92m↓2.73%[0m) [0.17% of initial]
[Iter 7570/20000] Loss: 0.0004453 (Best: 0.0003704 @iter7555) ([91m↑4.48%[0m) [0.18% of initial]
[Iter 7580/20000] Loss: 0.0004769 (Best: 0.0003704 @iter7555) ([91m↑7.10%[0m) [0.19% of initial]
[Iter 7590/20000] Loss: 0.0004823 (Best: 0.0003704 @iter7555) ([91m↑1.13%[0m) [0.19% of initial]
Iter:7599, L1 loss=0.0004666, Total loss=0.0004223, Time:49
[Iter 7600/20000] Loss: 0.0004311 (Best: 0.0003704 @iter7555) ([92m↓10.61%[0m) [0.17% of initial]
[Iter 7610/20000] Loss: 0.0014313 (Best: 0.0003704 @iter7555) ([91m↑232.00%[0m) [0.57% of initial]
[Iter 7620/20000] Loss: 0.0009060 (Best: 0.0003704 @iter7555) ([92m↓36.71%[0m) [0.36% of initial]
[Iter 7630/20000] Loss: 0.0007027 (Best: 0.0003704 @iter7555) ([92m↓22.43%[0m) [0.28% of initial]
[Iter 7640/20000] Loss: 0.0005748 (Best: 0.0003704 @iter7555) ([92m↓18.20%[0m) [0.23% of initial]
[Iter 7650/20000] Loss: 0.0005068 (Best: 0.0003704 @iter7555) ([92m↓11.83%[0m) [0.20% of initial]
[Iter 7660/20000] Loss: 0.0004232 (Best: 0.0003704 @iter7555) ([92m↓16.49%[0m) [0.17% of initial]
[Iter 7670/20000] Loss: 0.0003929 (Best: 0.0003704 @iter7555) ([92m↓7.17%[0m) [0.16% of initial]
[Iter 7680/20000] Loss: 0.0004299 (Best: 0.0003704 @iter7555) ([91m↑9.43%[0m) [0.17% of initial]
[Iter 7690/20000] Loss: 0.0004022 (Best: 0.0003643 @iter7690) ([92m↓6.44%[0m) [0.16% of initial]
Iter:7699, L1 loss=0.0004246, Total loss=0.0003872, Time:50
[Iter 7700/20000] Loss: 0.0003947 (Best: 0.0003643 @iter7690) ([92m↓1.87%[0m) [0.16% of initial]
[Iter 7710/20000] Loss: 0.0003857 (Best: 0.0003643 @iter7690) ([92m↓2.30%[0m) [0.15% of initial]
[Iter 7720/20000] Loss: 0.0003821 (Best: 0.0003385 @iter7714) ([92m↓0.93%[0m) [0.15% of initial]
[Iter 7730/20000] Loss: 0.0003823 (Best: 0.0003369 @iter7729) ([91m↑0.06%[0m) [0.15% of initial]
[Iter 7740/20000] Loss: 0.0003895 (Best: 0.0003369 @iter7729) ([91m↑1.88%[0m) [0.15% of initial]
[Iter 7750/20000] Loss: 0.0004223 (Best: 0.0003369 @iter7729) ([91m↑8.42%[0m) [0.17% of initial]
[Iter 7760/20000] Loss: 0.0004638 (Best: 0.0003369 @iter7729) ([91m↑9.83%[0m) [0.18% of initial]
[Iter 7770/20000] Loss: 0.0004515 (Best: 0.0003369 @iter7729) ([92m↓2.66%[0m) [0.18% of initial]
[Iter 7780/20000] Loss: 0.0004377 (Best: 0.0003369 @iter7729) ([92m↓3.05%[0m) [0.17% of initial]
[Iter 7790/20000] Loss: 0.0004517 (Best: 0.0003369 @iter7729) ([91m↑3.19%[0m) [0.18% of initial]
Iter:7799, L1 loss=0.0004463, Total loss=0.0003852, Time:45
[Iter 7800/20000] Loss: 0.0004465 (Best: 0.0003369 @iter7729) ([92m↓1.15%[0m) [0.18% of initial]
[Iter 7810/20000] Loss: 0.0009706 (Best: 0.0003369 @iter7729) ([91m↑117.40%[0m) [0.39% of initial]
[Iter 7820/20000] Loss: 0.0007290 (Best: 0.0003369 @iter7729) ([92m↓24.89%[0m) [0.29% of initial]
[Iter 7830/20000] Loss: 0.0006404 (Best: 0.0003369 @iter7729) ([92m↓12.15%[0m) [0.25% of initial]
[Iter 7840/20000] Loss: 0.0005472 (Best: 0.0003369 @iter7729) ([92m↓14.55%[0m) [0.22% of initial]
[Iter 7850/20000] Loss: 0.0005384 (Best: 0.0003369 @iter7729) ([92m↓1.61%[0m) [0.21% of initial]
[Iter 7860/20000] Loss: 0.0005445 (Best: 0.0003369 @iter7729) ([91m↑1.13%[0m) [0.22% of initial]
[Iter 7870/20000] Loss: 0.0005006 (Best: 0.0003369 @iter7729) ([92m↓8.06%[0m) [0.20% of initial]
[Iter 7880/20000] Loss: 0.0004410 (Best: 0.0003369 @iter7729) ([92m↓11.90%[0m) [0.18% of initial]
[Iter 7890/20000] Loss: 0.0005398 (Best: 0.0003369 @iter7729) ([91m↑22.40%[0m) [0.21% of initial]
Iter:7899, L1 loss=0.0004942, Total loss=0.0004555, Time:49
[Iter 7900/20000] Loss: 0.0004654 (Best: 0.0003369 @iter7729) ([92m↓13.79%[0m) [0.18% of initial]
[Iter 7910/20000] Loss: 0.0004650 (Best: 0.0003369 @iter7729) ([92m↓0.07%[0m) [0.18% of initial]
[Iter 7920/20000] Loss: 0.0005602 (Best: 0.0003369 @iter7729) ([91m↑20.47%[0m) [0.22% of initial]
[Iter 7930/20000] Loss: 0.0004661 (Best: 0.0003369 @iter7729) ([92m↓16.80%[0m) [0.19% of initial]
[Iter 7940/20000] Loss: 0.0004182 (Best: 0.0003369 @iter7729) ([92m↓10.27%[0m) [0.17% of initial]
[Iter 7950/20000] Loss: 0.0004031 (Best: 0.0003369 @iter7729) ([92m↓3.62%[0m) [0.16% of initial]
[Iter 7960/20000] Loss: 0.0004773 (Best: 0.0003369 @iter7729) ([91m↑18.40%[0m) [0.19% of initial]
[Iter 7970/20000] Loss: 0.0004626 (Best: 0.0003369 @iter7729) ([92m↓3.07%[0m) [0.18% of initial]
[Iter 7980/20000] Loss: 0.0004631 (Best: 0.0003369 @iter7729) ([91m↑0.11%[0m) [0.18% of initial]
[Iter 7990/20000] Loss: 0.0004134 (Best: 0.0003369 @iter7729) ([92m↓10.74%[0m) [0.16% of initial]
Iter:7999, L1 loss=0.0004691, Total loss=0.0004044, Time:47
[Iter 8000/20000] Loss: 0.0004103 (Best: 0.0003369 @iter7729) ([92m↓0.73%[0m) [0.16% of initial]
Pruning 30 points (0.0%) from gaussian0 at iteration 8000
Pruning 42 points (0.0%) from gaussian1 at iteration 8000
[Iter 8010/20000] Loss: 0.0414877 (Best: 0.0003369 @iter7729) ([91m↑10010.91%[0m) [16.48% of initial]
[Iter 8020/20000] Loss: 0.0167771 (Best: 0.0003369 @iter7729) ([92m↓59.56%[0m) [6.67% of initial]
[Iter 8030/20000] Loss: 0.0053012 (Best: 0.0003369 @iter7729) ([92m↓68.40%[0m) [2.11% of initial]
[Iter 8040/20000] Loss: 0.0039965 (Best: 0.0003369 @iter7729) ([92m↓24.61%[0m) [1.59% of initial]
[Iter 8050/20000] Loss: 0.0022967 (Best: 0.0003369 @iter7729) ([92m↓42.53%[0m) [0.91% of initial]
[Iter 8060/20000] Loss: 0.0015482 (Best: 0.0003369 @iter7729) ([92m↓32.59%[0m) [0.62% of initial]
[Iter 8070/20000] Loss: 0.0012269 (Best: 0.0003369 @iter7729) ([92m↓20.75%[0m) [0.49% of initial]
[Iter 8080/20000] Loss: 0.0009606 (Best: 0.0003369 @iter7729) ([92m↓21.71%[0m) [0.38% of initial]
[Iter 8090/20000] Loss: 0.0008050 (Best: 0.0003369 @iter7729) ([92m↓16.20%[0m) [0.32% of initial]
Iter:8099, L1 loss=0.0007337, Total loss=0.000715, Time:52
[Iter 8100/20000] Loss: 0.0007718 (Best: 0.0003369 @iter7729) ([92m↓4.12%[0m) [0.31% of initial]
[Iter 8110/20000] Loss: 0.0006750 (Best: 0.0003369 @iter7729) ([92m↓12.54%[0m) [0.27% of initial]
[Iter 8120/20000] Loss: 0.0006090 (Best: 0.0003369 @iter7729) ([92m↓9.78%[0m) [0.24% of initial]
[Iter 8130/20000] Loss: 0.0006347 (Best: 0.0003369 @iter7729) ([91m↑4.21%[0m) [0.25% of initial]
[Iter 8140/20000] Loss: 0.0005993 (Best: 0.0003369 @iter7729) ([92m↓5.57%[0m) [0.24% of initial]
[Iter 8150/20000] Loss: 0.0005877 (Best: 0.0003369 @iter7729) ([92m↓1.94%[0m) [0.23% of initial]
[Iter 8160/20000] Loss: 0.0005901 (Best: 0.0003369 @iter7729) ([91m↑0.40%[0m) [0.23% of initial]
[Iter 8170/20000] Loss: 0.0005682 (Best: 0.0003369 @iter7729) ([92m↓3.70%[0m) [0.23% of initial]
[Iter 8180/20000] Loss: 0.0005749 (Best: 0.0003369 @iter7729) ([91m↑1.17%[0m) [0.23% of initial]
[Iter 8190/20000] Loss: 0.0005507 (Best: 0.0003369 @iter7729) ([92m↓4.20%[0m) [0.22% of initial]
Iter:8199, L1 loss=0.0005961, Total loss=0.0005534, Time:51
[Iter 8200/20000] Loss: 0.0005335 (Best: 0.0003369 @iter7729) ([92m↓3.12%[0m) [0.21% of initial]
[Iter 8210/20000] Loss: 0.0005019 (Best: 0.0003369 @iter7729) ([92m↓5.93%[0m) [0.20% of initial]
[Iter 8220/20000] Loss: 0.0005190 (Best: 0.0003369 @iter7729) ([91m↑3.40%[0m) [0.21% of initial]
[Iter 8230/20000] Loss: 0.0005274 (Best: 0.0003369 @iter7729) ([91m↑1.61%[0m) [0.21% of initial]
[Iter 8240/20000] Loss: 0.0005199 (Best: 0.0003369 @iter7729) ([92m↓1.42%[0m) [0.21% of initial]
[Iter 8250/20000] Loss: 0.0005618 (Best: 0.0003369 @iter7729) ([91m↑8.07%[0m) [0.22% of initial]
[Iter 8260/20000] Loss: 0.0005497 (Best: 0.0003369 @iter7729) ([92m↓2.15%[0m) [0.22% of initial]
[Iter 8270/20000] Loss: 0.0005540 (Best: 0.0003369 @iter7729) ([91m↑0.78%[0m) [0.22% of initial]
[Iter 8280/20000] Loss: 0.0005327 (Best: 0.0003369 @iter7729) ([92m↓3.85%[0m) [0.21% of initial]
[Iter 8290/20000] Loss: 0.0005622 (Best: 0.0003369 @iter7729) ([91m↑5.52%[0m) [0.22% of initial]
Iter:8299, L1 loss=0.0005179, Total loss=0.0004607, Time:55
[Iter 8300/20000] Loss: 0.0005112 (Best: 0.0003369 @iter7729) ([92m↓9.07%[0m) [0.20% of initial]
[Iter 8310/20000] Loss: 0.0005019 (Best: 0.0003369 @iter7729) ([92m↓1.81%[0m) [0.20% of initial]
[Iter 8320/20000] Loss: 0.0004797 (Best: 0.0003369 @iter7729) ([92m↓4.43%[0m) [0.19% of initial]
[Iter 8330/20000] Loss: 0.0004841 (Best: 0.0003369 @iter7729) ([91m↑0.92%[0m) [0.19% of initial]
[Iter 8340/20000] Loss: 0.0005028 (Best: 0.0003369 @iter7729) ([91m↑3.86%[0m) [0.20% of initial]
[Iter 8350/20000] Loss: 0.0004602 (Best: 0.0003369 @iter7729) ([92m↓8.48%[0m) [0.18% of initial]
[Iter 8360/20000] Loss: 0.0004704 (Best: 0.0003369 @iter7729) ([91m↑2.22%[0m) [0.19% of initial]
[Iter 8370/20000] Loss: 0.0004648 (Best: 0.0003369 @iter7729) ([92m↓1.18%[0m) [0.18% of initial]
[Iter 8380/20000] Loss: 0.0004734 (Best: 0.0003369 @iter7729) ([91m↑1.84%[0m) [0.19% of initial]
[Iter 8390/20000] Loss: 0.0004370 (Best: 0.0003369 @iter7729) ([92m↓7.68%[0m) [0.17% of initial]
Iter:8399, L1 loss=0.0004929, Total loss=0.0004543, Time:51
[Iter 8400/20000] Loss: 0.0004879 (Best: 0.0003369 @iter7729) ([91m↑11.64%[0m) [0.19% of initial]
[Iter 8410/20000] Loss: 0.0004667 (Best: 0.0003369 @iter7729) ([92m↓4.34%[0m) [0.19% of initial]
[Iter 8420/20000] Loss: 0.0004577 (Best: 0.0003369 @iter7729) ([92m↓1.93%[0m) [0.18% of initial]
[Iter 8430/20000] Loss: 0.0004774 (Best: 0.0003369 @iter7729) ([91m↑4.31%[0m) [0.19% of initial]
[Iter 8440/20000] Loss: 0.0004618 (Best: 0.0003369 @iter7729) ([92m↓3.27%[0m) [0.18% of initial]
[Iter 8450/20000] Loss: 0.0004917 (Best: 0.0003369 @iter7729) ([91m↑6.47%[0m) [0.20% of initial]
[Iter 8460/20000] Loss: 0.0004746 (Best: 0.0003369 @iter7729) ([92m↓3.47%[0m) [0.19% of initial]
[Iter 8470/20000] Loss: 0.0004841 (Best: 0.0003369 @iter7729) ([91m↑2.01%[0m) [0.19% of initial]
[Iter 8480/20000] Loss: 0.0004691 (Best: 0.0003369 @iter7729) ([92m↓3.11%[0m) [0.19% of initial]
[Iter 8490/20000] Loss: 0.0004891 (Best: 0.0003369 @iter7729) ([91m↑4.26%[0m) [0.19% of initial]
Iter:8499, L1 loss=0.0005655, Total loss=0.0005052, Time:56
[Iter 8500/20000] Loss: 0.0005093 (Best: 0.0003369 @iter7729) ([91m↑4.12%[0m) [0.20% of initial]
Pruning 55 points (0.0%) from gaussian0 at iteration 8500
Pruning 70 points (0.0%) from gaussian1 at iteration 8500
[Iter 8510/20000] Loss: 0.0010629 (Best: 0.0003369 @iter7729) ([91m↑108.71%[0m) [0.42% of initial]
[Iter 8520/20000] Loss: 0.0007686 (Best: 0.0003369 @iter7729) ([92m↓27.69%[0m) [0.31% of initial]
[Iter 8530/20000] Loss: 0.0006062 (Best: 0.0003369 @iter7729) ([92m↓21.12%[0m) [0.24% of initial]
[Iter 8540/20000] Loss: 0.0005482 (Best: 0.0003369 @iter7729) ([92m↓9.58%[0m) [0.22% of initial]
[Iter 8550/20000] Loss: 0.0005209 (Best: 0.0003369 @iter7729) ([92m↓4.97%[0m) [0.21% of initial]
[Iter 8560/20000] Loss: 0.0005042 (Best: 0.0003369 @iter7729) ([92m↓3.20%[0m) [0.20% of initial]
[Iter 8570/20000] Loss: 0.0004960 (Best: 0.0003369 @iter7729) ([92m↓1.64%[0m) [0.20% of initial]
[Iter 8580/20000] Loss: 0.0004933 (Best: 0.0003369 @iter7729) ([92m↓0.54%[0m) [0.20% of initial]
[Iter 8590/20000] Loss: 0.0004787 (Best: 0.0003369 @iter7729) ([92m↓2.94%[0m) [0.19% of initial]
Iter:8599, L1 loss=0.0004769, Total loss=0.0004286, Time:52
[Iter 8600/20000] Loss: 0.0004693 (Best: 0.0003369 @iter7729) ([92m↓1.97%[0m) [0.19% of initial]
[Iter 8610/20000] Loss: 0.0004886 (Best: 0.0003369 @iter7729) ([91m↑4.10%[0m) [0.19% of initial]
[Iter 8620/20000] Loss: 0.0004783 (Best: 0.0003369 @iter7729) ([92m↓2.09%[0m) [0.19% of initial]
[Iter 8630/20000] Loss: 0.0004715 (Best: 0.0003369 @iter7729) ([92m↓1.43%[0m) [0.19% of initial]
[Iter 8640/20000] Loss: 0.0004535 (Best: 0.0003369 @iter7729) ([92m↓3.82%[0m) [0.18% of initial]
[Iter 8650/20000] Loss: 0.0004711 (Best: 0.0003369 @iter7729) ([91m↑3.90%[0m) [0.19% of initial]
[Iter 8660/20000] Loss: 0.0005133 (Best: 0.0003369 @iter7729) ([91m↑8.94%[0m) [0.20% of initial]
[Iter 8670/20000] Loss: 0.0005125 (Best: 0.0003369 @iter7729) ([92m↓0.16%[0m) [0.20% of initial]
[Iter 8680/20000] Loss: 0.0004909 (Best: 0.0003369 @iter7729) ([92m↓4.20%[0m) [0.20% of initial]
[Iter 8690/20000] Loss: 0.0005903 (Best: 0.0003369 @iter7729) ([91m↑20.23%[0m) [0.23% of initial]
Iter:8699, L1 loss=0.0005364, Total loss=0.0004959, Time:61
[Iter 8700/20000] Loss: 0.0005236 (Best: 0.0003369 @iter7729) ([92m↓11.30%[0m) [0.21% of initial]
[Iter 8710/20000] Loss: 0.0005063 (Best: 0.0003369 @iter7729) ([92m↓3.30%[0m) [0.20% of initial]
[Iter 8720/20000] Loss: 0.0004824 (Best: 0.0003369 @iter7729) ([92m↓4.73%[0m) [0.19% of initial]
[Iter 8730/20000] Loss: 0.0005204 (Best: 0.0003369 @iter7729) ([91m↑7.87%[0m) [0.21% of initial]
[Iter 8740/20000] Loss: 0.0004862 (Best: 0.0003369 @iter7729) ([92m↓6.56%[0m) [0.19% of initial]
[Iter 8750/20000] Loss: 0.0005446 (Best: 0.0003369 @iter7729) ([91m↑12.00%[0m) [0.22% of initial]
[Iter 8760/20000] Loss: 0.0005098 (Best: 0.0003369 @iter7729) ([92m↓6.38%[0m) [0.20% of initial]
[Iter 8770/20000] Loss: 0.0005301 (Best: 0.0003369 @iter7729) ([91m↑3.98%[0m) [0.21% of initial]
[Iter 8780/20000] Loss: 0.0005182 (Best: 0.0003369 @iter7729) ([92m↓2.25%[0m) [0.21% of initial]
[Iter 8790/20000] Loss: 0.0005228 (Best: 0.0003369 @iter7729) ([91m↑0.89%[0m) [0.21% of initial]
Iter:8799, L1 loss=0.0005895, Total loss=0.0005658, Time:51
[Iter 8800/20000] Loss: 0.0005015 (Best: 0.0003369 @iter7729) ([92m↓4.08%[0m) [0.20% of initial]
[Iter 8810/20000] Loss: 0.0004533 (Best: 0.0003369 @iter7729) ([92m↓9.60%[0m) [0.18% of initial]
[Iter 8820/20000] Loss: 0.0005183 (Best: 0.0003369 @iter7729) ([91m↑14.32%[0m) [0.21% of initial]
[Iter 8830/20000] Loss: 0.0006222 (Best: 0.0003369 @iter7729) ([91m↑20.06%[0m) [0.25% of initial]
[Iter 8840/20000] Loss: 0.0005779 (Best: 0.0003369 @iter7729) ([92m↓7.12%[0m) [0.23% of initial]
[Iter 8850/20000] Loss: 0.0005972 (Best: 0.0003369 @iter7729) ([91m↑3.34%[0m) [0.24% of initial]
[Iter 8860/20000] Loss: 0.0005029 (Best: 0.0003369 @iter7729) ([92m↓15.79%[0m) [0.20% of initial]
[Iter 8870/20000] Loss: 0.0004712 (Best: 0.0003369 @iter7729) ([92m↓6.30%[0m) [0.19% of initial]
[Iter 8880/20000] Loss: 0.0004658 (Best: 0.0003369 @iter7729) ([92m↓1.14%[0m) [0.19% of initial]
[Iter 8890/20000] Loss: 0.0004472 (Best: 0.0003369 @iter7729) ([92m↓4.00%[0m) [0.18% of initial]
Iter:8899, L1 loss=0.0004799, Total loss=0.0004553, Time:51
[Iter 8900/20000] Loss: 0.0004892 (Best: 0.0003369 @iter7729) ([91m↑9.39%[0m) [0.19% of initial]
[Iter 8910/20000] Loss: 0.0004858 (Best: 0.0003369 @iter7729) ([92m↓0.68%[0m) [0.19% of initial]
[Iter 8920/20000] Loss: 0.0004657 (Best: 0.0003369 @iter7729) ([92m↓4.14%[0m) [0.19% of initial]
[Iter 8930/20000] Loss: 0.0004665 (Best: 0.0003369 @iter7729) ([91m↑0.17%[0m) [0.19% of initial]
[Iter 8940/20000] Loss: 0.0004572 (Best: 0.0003369 @iter7729) ([92m↓1.99%[0m) [0.18% of initial]
[Iter 8950/20000] Loss: 0.0004903 (Best: 0.0003369 @iter7729) ([91m↑7.23%[0m) [0.19% of initial]
[Iter 8960/20000] Loss: 0.0004903 (Best: 0.0003369 @iter7729) ([91m↑0.01%[0m) [0.19% of initial]
[Iter 8970/20000] Loss: 0.0005635 (Best: 0.0003369 @iter7729) ([91m↑14.93%[0m) [0.22% of initial]
[Iter 8980/20000] Loss: 0.0005386 (Best: 0.0003369 @iter7729) ([92m↓4.42%[0m) [0.21% of initial]
[Iter 8990/20000] Loss: 0.0005008 (Best: 0.0003369 @iter7729) ([92m↓7.01%[0m) [0.20% of initial]
Iter:8999, L1 loss=0.0004685, Total loss=0.0004271, Time:55
[Iter 9000/20000] Loss: 0.0004704 (Best: 0.0003369 @iter7729) ([92m↓6.08%[0m) [0.19% of initial]
Pruning 38 points (0.0%) from gaussian0 at iteration 9000
Pruning 35 points (0.0%) from gaussian1 at iteration 9000
[Iter 9010/20000] Loss: 0.0008847 (Best: 0.0003369 @iter7729) ([91m↑88.07%[0m) [0.35% of initial]
[Iter 9020/20000] Loss: 0.0006625 (Best: 0.0003369 @iter7729) ([92m↓25.12%[0m) [0.26% of initial]
[Iter 9030/20000] Loss: 0.0005421 (Best: 0.0003369 @iter7729) ([92m↓18.18%[0m) [0.22% of initial]
[Iter 9040/20000] Loss: 0.0004983 (Best: 0.0003369 @iter7729) ([92m↓8.07%[0m) [0.20% of initial]
[Iter 9050/20000] Loss: 0.0004628 (Best: 0.0003369 @iter7729) ([92m↓7.12%[0m) [0.18% of initial]
[Iter 9060/20000] Loss: 0.0004803 (Best: 0.0003369 @iter7729) ([91m↑3.78%[0m) [0.19% of initial]
[Iter 9070/20000] Loss: 0.0004950 (Best: 0.0003369 @iter7729) ([91m↑3.06%[0m) [0.20% of initial]
[Iter 9080/20000] Loss: 0.0005207 (Best: 0.0003369 @iter7729) ([91m↑5.19%[0m) [0.21% of initial]
[Iter 9090/20000] Loss: 0.0004908 (Best: 0.0003369 @iter7729) ([92m↓5.74%[0m) [0.19% of initial]
Iter:9099, L1 loss=0.0005775, Total loss=0.000541, Time:55
[Iter 9100/20000] Loss: 0.0004881 (Best: 0.0003369 @iter7729) ([92m↓0.55%[0m) [0.19% of initial]
[Iter 9110/20000] Loss: 0.0005164 (Best: 0.0003369 @iter7729) ([91m↑5.79%[0m) [0.21% of initial]
[Iter 9120/20000] Loss: 0.0004611 (Best: 0.0003369 @iter7729) ([92m↓10.70%[0m) [0.18% of initial]
[Iter 9130/20000] Loss: 0.0004648 (Best: 0.0003369 @iter7729) ([91m↑0.79%[0m) [0.18% of initial]
[Iter 9140/20000] Loss: 0.0004561 (Best: 0.0003369 @iter7729) ([92m↓1.86%[0m) [0.18% of initial]
[Iter 9150/20000] Loss: 0.0004299 (Best: 0.0003369 @iter7729) ([92m↓5.75%[0m) [0.17% of initial]
[Iter 9160/20000] Loss: 0.0004630 (Best: 0.0003369 @iter7729) ([91m↑7.68%[0m) [0.18% of initial]
[Iter 9170/20000] Loss: 0.0004341 (Best: 0.0003369 @iter7729) ([92m↓6.24%[0m) [0.17% of initial]
[Iter 9180/20000] Loss: 0.0004488 (Best: 0.0003369 @iter7729) ([91m↑3.39%[0m) [0.18% of initial]
[Iter 9190/20000] Loss: 0.0004046 (Best: 0.0003369 @iter7729) ([92m↓9.84%[0m) [0.16% of initial]
Iter:9199, L1 loss=0.0004736, Total loss=0.0004307, Time:50
[Iter 9200/20000] Loss: 0.0004283 (Best: 0.0003369 @iter7729) ([91m↑5.85%[0m) [0.17% of initial]
[Iter 9210/20000] Loss: 0.0004427 (Best: 0.0003369 @iter7729) ([91m↑3.38%[0m) [0.18% of initial]
[Iter 9220/20000] Loss: 0.0004452 (Best: 0.0003369 @iter7729) ([91m↑0.55%[0m) [0.18% of initial]
[Iter 9230/20000] Loss: 0.0004359 (Best: 0.0003369 @iter7729) ([92m↓2.09%[0m) [0.17% of initial]
[Iter 9240/20000] Loss: 0.0004596 (Best: 0.0003369 @iter7729) ([91m↑5.44%[0m) [0.18% of initial]
[Iter 9250/20000] Loss: 0.0004388 (Best: 0.0003369 @iter7729) ([92m↓4.52%[0m) [0.17% of initial]
[Iter 9260/20000] Loss: 0.0004415 (Best: 0.0003369 @iter7729) ([91m↑0.61%[0m) [0.18% of initial]
[Iter 9270/20000] Loss: 0.0004337 (Best: 0.0003369 @iter7729) ([92m↓1.77%[0m) [0.17% of initial]
[Iter 9280/20000] Loss: 0.0004077 (Best: 0.0003369 @iter7729) ([92m↓5.99%[0m) [0.16% of initial]
[Iter 9290/20000] Loss: 0.0004036 (Best: 0.0003369 @iter7729) ([92m↓1.01%[0m) [0.16% of initial]
Iter:9299, L1 loss=0.0004281, Total loss=0.0003889, Time:55
[Iter 9300/20000] Loss: 0.0004409 (Best: 0.0003369 @iter7729) ([91m↑9.23%[0m) [0.18% of initial]
[Iter 9310/20000] Loss: 0.0004530 (Best: 0.0003369 @iter7729) ([91m↑2.76%[0m) [0.18% of initial]
[Iter 9320/20000] Loss: 0.0004623 (Best: 0.0003369 @iter7729) ([91m↑2.05%[0m) [0.18% of initial]
[Iter 9330/20000] Loss: 0.0005002 (Best: 0.0003369 @iter7729) ([91m↑8.19%[0m) [0.20% of initial]
[Iter 9340/20000] Loss: 0.0004886 (Best: 0.0003369 @iter7729) ([92m↓2.31%[0m) [0.19% of initial]
[Iter 9350/20000] Loss: 0.0004444 (Best: 0.0003369 @iter7729) ([92m↓9.05%[0m) [0.18% of initial]
[Iter 9360/20000] Loss: 0.0004913 (Best: 0.0003369 @iter7729) ([91m↑10.55%[0m) [0.20% of initial]
[Iter 9370/20000] Loss: 0.0004290 (Best: 0.0003369 @iter7729) ([92m↓12.67%[0m) [0.17% of initial]
[Iter 9380/20000] Loss: 0.0004580 (Best: 0.0003369 @iter7729) ([91m↑6.74%[0m) [0.18% of initial]
[Iter 9390/20000] Loss: 0.0004563 (Best: 0.0003369 @iter7729) ([92m↓0.36%[0m) [0.18% of initial]
Iter:9399, L1 loss=0.0005855, Total loss=0.0005371, Time:55
[Iter 9400/20000] Loss: 0.0004375 (Best: 0.0003369 @iter7729) ([92m↓4.13%[0m) [0.17% of initial]
[Iter 9410/20000] Loss: 0.0004376 (Best: 0.0003369 @iter7729) ([91m↑0.04%[0m) [0.17% of initial]
[Iter 9420/20000] Loss: 0.0004466 (Best: 0.0003369 @iter7729) ([91m↑2.05%[0m) [0.18% of initial]
[Iter 9430/20000] Loss: 0.0004134 (Best: 0.0003369 @iter7729) ([92m↓7.44%[0m) [0.16% of initial]
[Iter 9440/20000] Loss: 0.0004642 (Best: 0.0003369 @iter7729) ([91m↑12.31%[0m) [0.18% of initial]
[Iter 9450/20000] Loss: 0.0004406 (Best: 0.0003369 @iter7729) ([92m↓5.09%[0m) [0.18% of initial]
[Iter 9460/20000] Loss: 0.0003863 (Best: 0.0003369 @iter7729) ([92m↓12.32%[0m) [0.15% of initial]
[Iter 9470/20000] Loss: 0.0003736 (Best: 0.0003369 @iter7729) ([92m↓3.31%[0m) [0.15% of initial]
[Iter 9480/20000] Loss: 0.0004483 (Best: 0.0003369 @iter7729) ([91m↑20.01%[0m) [0.18% of initial]
[Iter 9490/20000] Loss: 0.0004076 (Best: 0.0003369 @iter7729) ([92m↓9.09%[0m) [0.16% of initial]
Iter:9499, L1 loss=0.0004406, Total loss=0.0004212, Time:50
[Iter 9500/20000] Loss: 0.0004235 (Best: 0.0003369 @iter7729) ([91m↑3.91%[0m) [0.17% of initial]
Pruning 19 points (0.0%) from gaussian0 at iteration 9500
Pruning 24 points (0.0%) from gaussian1 at iteration 9500
[Iter 9510/20000] Loss: 0.0007228 (Best: 0.0003369 @iter7729) ([91m↑70.69%[0m) [0.29% of initial]
[Iter 9520/20000] Loss: 0.0005496 (Best: 0.0003369 @iter7729) ([92m↓23.97%[0m) [0.22% of initial]
[Iter 9530/20000] Loss: 0.0005880 (Best: 0.0003369 @iter7729) ([91m↑6.99%[0m) [0.23% of initial]
[Iter 9540/20000] Loss: 0.0004660 (Best: 0.0003369 @iter7729) ([92m↓20.75%[0m) [0.19% of initial]
[Iter 9550/20000] Loss: 0.0004077 (Best: 0.0003369 @iter7729) ([92m↓12.51%[0m) [0.16% of initial]
[Iter 9560/20000] Loss: 0.0003920 (Best: 0.0003369 @iter7729) ([92m↓3.84%[0m) [0.16% of initial]
[Iter 9570/20000] Loss: 0.0003853 (Best: 0.0003369 @iter7729) ([92m↓1.71%[0m) [0.15% of initial]
[Iter 9580/20000] Loss: 0.0003701 (Best: 0.0003369 @iter7729) ([92m↓3.94%[0m) [0.15% of initial]
[Iter 9590/20000] Loss: 0.0003750 (Best: 0.0003369 @iter7729) ([91m↑1.32%[0m) [0.15% of initial]
Iter:9599, L1 loss=0.0005031, Total loss=0.0004572, Time:57
[Iter 9600/20000] Loss: 0.0004052 (Best: 0.0003369 @iter7729) ([91m↑8.04%[0m) [0.16% of initial]
[Iter 9610/20000] Loss: 0.0003915 (Best: 0.0003369 @iter7729) ([92m↓3.39%[0m) [0.16% of initial]
[Iter 9620/20000] Loss: 0.0004074 (Best: 0.0003369 @iter7729) ([91m↑4.08%[0m) [0.16% of initial]
[Iter 9630/20000] Loss: 0.0003837 (Best: 0.0003369 @iter7729) ([92m↓5.82%[0m) [0.15% of initial]
[Iter 9640/20000] Loss: 0.0003746 (Best: 0.0003344 @iter9638) ([92m↓2.39%[0m) [0.15% of initial]
[Iter 9650/20000] Loss: 0.0004283 (Best: 0.0003344 @iter9638) ([91m↑14.34%[0m) [0.17% of initial]
[Iter 9660/20000] Loss: 0.0004002 (Best: 0.0003344 @iter9638) ([92m↓6.56%[0m) [0.16% of initial]
[Iter 9670/20000] Loss: 0.0004413 (Best: 0.0003344 @iter9638) ([91m↑10.27%[0m) [0.18% of initial]
[Iter 9680/20000] Loss: 0.0004533 (Best: 0.0003344 @iter9638) ([91m↑2.72%[0m) [0.18% of initial]
[Iter 9690/20000] Loss: 0.0005206 (Best: 0.0003344 @iter9638) ([91m↑14.86%[0m) [0.21% of initial]
Iter:9699, L1 loss=0.0006151, Total loss=0.0005896, Time:51
[Iter 9700/20000] Loss: 0.0004847 (Best: 0.0003344 @iter9638) ([92m↓6.91%[0m) [0.19% of initial]
[Iter 9710/20000] Loss: 0.0004636 (Best: 0.0003344 @iter9638) ([92m↓4.35%[0m) [0.18% of initial]
[Iter 9720/20000] Loss: 0.0004326 (Best: 0.0003344 @iter9638) ([92m↓6.69%[0m) [0.17% of initial]
[Iter 9730/20000] Loss: 0.0003984 (Best: 0.0003344 @iter9638) ([92m↓7.89%[0m) [0.16% of initial]
[Iter 9740/20000] Loss: 0.0004230 (Best: 0.0003344 @iter9638) ([91m↑6.16%[0m) [0.17% of initial]
[Iter 9750/20000] Loss: 0.0004162 (Best: 0.0003344 @iter9638) ([92m↓1.61%[0m) [0.17% of initial]
[Iter 9760/20000] Loss: 0.0003854 (Best: 0.0003344 @iter9638) ([92m↓7.40%[0m) [0.15% of initial]
[Iter 9770/20000] Loss: 0.0003944 (Best: 0.0003344 @iter9638) ([91m↑2.34%[0m) [0.16% of initial]
[Iter 9780/20000] Loss: 0.0003752 (Best: 0.0003344 @iter9638) ([92m↓4.87%[0m) [0.15% of initial]
[Iter 9790/20000] Loss: 0.0003709 (Best: 0.0003240 @iter9784) ([92m↓1.15%[0m) [0.15% of initial]
Iter:9799, L1 loss=0.00043, Total loss=0.0003805, Time:34
[Iter 9800/20000] Loss: 0.0003951 (Best: 0.0003240 @iter9784) ([91m↑6.53%[0m) [0.16% of initial]
[Iter 9810/20000] Loss: 0.0003834 (Best: 0.0003240 @iter9784) ([92m↓2.97%[0m) [0.15% of initial]
[Iter 9820/20000] Loss: 0.0003609 (Best: 0.0003240 @iter9784) ([92m↓5.86%[0m) [0.14% of initial]
[Iter 9830/20000] Loss: 0.0003781 (Best: 0.0003240 @iter9784) ([91m↑4.75%[0m) [0.15% of initial]
[Iter 9840/20000] Loss: 0.0003944 (Best: 0.0003240 @iter9784) ([91m↑4.33%[0m) [0.16% of initial]
[Iter 9850/20000] Loss: 0.0003670 (Best: 0.0003240 @iter9784) ([92m↓6.95%[0m) [0.15% of initial]
[Iter 9860/20000] Loss: 0.0003691 (Best: 0.0003240 @iter9784) ([91m↑0.57%[0m) [0.15% of initial]
[Iter 9870/20000] Loss: 0.0003933 (Best: 0.0003240 @iter9784) ([91m↑6.55%[0m) [0.16% of initial]
[Iter 9880/20000] Loss: 0.0004117 (Best: 0.0003240 @iter9784) ([91m↑4.69%[0m) [0.16% of initial]
[Iter 9890/20000] Loss: 0.0005077 (Best: 0.0003240 @iter9784) ([91m↑23.31%[0m) [0.20% of initial]
Iter:9899, L1 loss=0.0005777, Total loss=0.0005037, Time:55
[Iter 9900/20000] Loss: 0.0004611 (Best: 0.0003240 @iter9784) ([92m↓9.19%[0m) [0.18% of initial]
[Iter 9910/20000] Loss: 0.0003856 (Best: 0.0003240 @iter9784) ([92m↓16.36%[0m) [0.15% of initial]
[Iter 9920/20000] Loss: 0.0003770 (Best: 0.0003240 @iter9784) ([92m↓2.25%[0m) [0.15% of initial]
[Iter 9930/20000] Loss: 0.0003986 (Best: 0.0003240 @iter9784) ([91m↑5.74%[0m) [0.16% of initial]
[Iter 9940/20000] Loss: 0.0003920 (Best: 0.0003240 @iter9784) ([92m↓1.67%[0m) [0.16% of initial]
[Iter 9950/20000] Loss: 0.0004331 (Best: 0.0003240 @iter9784) ([91m↑10.50%[0m) [0.17% of initial]
[Iter 9960/20000] Loss: 0.0004330 (Best: 0.0003240 @iter9784) ([92m↓0.02%[0m) [0.17% of initial]
[Iter 9970/20000] Loss: 0.0004127 (Best: 0.0003240 @iter9784) ([92m↓4.70%[0m) [0.16% of initial]
[Iter 9980/20000] Loss: 0.0004080 (Best: 0.0003240 @iter9784) ([92m↓1.12%[0m) [0.16% of initial]
[Iter 9990/20000] Loss: 0.0004276 (Best: 0.0003240 @iter9784) ([91m↑4.80%[0m) [0.17% of initial]
Iter:9999, L1 loss=0.0006446, Total loss=0.0005581, Time:55
[Iter 10000/20000] Loss: 0.0004964 (Best: 0.0003240 @iter9784) ([91m↑16.08%[0m) [0.20% of initial]
Pruning 19 points (0.0%) from gaussian0 at iteration 10000
Pruning 21 points (0.0%) from gaussian1 at iteration 10000
[Iter 10010/20000] Loss: 0.0007291 (Best: 0.0003240 @iter9784) ([91m↑46.88%[0m) [0.29% of initial]
[Iter 10020/20000] Loss: 0.0005973 (Best: 0.0003240 @iter9784) ([92m↓18.08%[0m) [0.24% of initial]
[Iter 10030/20000] Loss: 0.0004440 (Best: 0.0003240 @iter9784) ([92m↓25.66%[0m) [0.18% of initial]
[Iter 10040/20000] Loss: 0.0004054 (Best: 0.0003240 @iter9784) ([92m↓8.69%[0m) [0.16% of initial]
[Iter 10050/20000] Loss: 0.0003786 (Best: 0.0003240 @iter9784) ([92m↓6.61%[0m) [0.15% of initial]
[Iter 10060/20000] Loss: 0.0003414 (Best: 0.0003235 @iter10060) ([92m↓9.82%[0m) [0.14% of initial]
[Iter 10070/20000] Loss: 0.0003452 (Best: 0.0003235 @iter10060) ([91m↑1.12%[0m) [0.14% of initial]
[Iter 10080/20000] Loss: 0.0003507 (Best: 0.0003201 @iter10072) ([91m↑1.59%[0m) [0.14% of initial]
[Iter 10090/20000] Loss: 0.0003454 (Best: 0.0003163 @iter10084) ([92m↓1.51%[0m) [0.14% of initial]
Iter:10099, L1 loss=0.000378, Total loss=0.0003592, Time:55
[Iter 10100/20000] Loss: 0.0003674 (Best: 0.0003163 @iter10084) ([91m↑6.35%[0m) [0.15% of initial]
[Iter 10110/20000] Loss: 0.0003623 (Best: 0.0003163 @iter10084) ([92m↓1.38%[0m) [0.14% of initial]
[Iter 10120/20000] Loss: 0.0003589 (Best: 0.0003163 @iter10084) ([92m↓0.92%[0m) [0.14% of initial]
[Iter 10130/20000] Loss: 0.0003637 (Best: 0.0003163 @iter10084) ([91m↑1.33%[0m) [0.14% of initial]
[Iter 10140/20000] Loss: 0.0004160 (Best: 0.0003163 @iter10084) ([91m↑14.38%[0m) [0.17% of initial]
[Iter 10150/20000] Loss: 0.0004179 (Best: 0.0003163 @iter10084) ([91m↑0.46%[0m) [0.17% of initial]
[Iter 10160/20000] Loss: 0.0004021 (Best: 0.0003163 @iter10084) ([92m↓3.78%[0m) [0.16% of initial]
[Iter 10170/20000] Loss: 0.0003789 (Best: 0.0003163 @iter10084) ([92m↓5.79%[0m) [0.15% of initial]
[Iter 10180/20000] Loss: 0.0003393 (Best: 0.0003163 @iter10084) ([92m↓10.45%[0m) [0.13% of initial]
[Iter 10190/20000] Loss: 0.0003256 (Best: 0.0003074 @iter10183) ([92m↓4.02%[0m) [0.13% of initial]
Iter:10199, L1 loss=0.0004303, Total loss=0.0003925, Time:58
[Iter 10200/20000] Loss: 0.0003680 (Best: 0.0003074 @iter10183) ([91m↑13.02%[0m) [0.15% of initial]
[Iter 10210/20000] Loss: 0.0003522 (Best: 0.0003074 @iter10183) ([92m↓4.29%[0m) [0.14% of initial]
[Iter 10220/20000] Loss: 0.0003636 (Best: 0.0003074 @iter10183) ([91m↑3.23%[0m) [0.14% of initial]
[Iter 10230/20000] Loss: 0.0003633 (Best: 0.0003074 @iter10183) ([92m↓0.09%[0m) [0.14% of initial]
[Iter 10240/20000] Loss: 0.0003500 (Best: 0.0003064 @iter10237) ([92m↓3.67%[0m) [0.14% of initial]
[Iter 10250/20000] Loss: 0.0003567 (Best: 0.0003064 @iter10237) ([91m↑1.93%[0m) [0.14% of initial]
[Iter 10260/20000] Loss: 0.0003849 (Best: 0.0003064 @iter10237) ([91m↑7.90%[0m) [0.15% of initial]
[Iter 10270/20000] Loss: 0.0003611 (Best: 0.0003064 @iter10237) ([92m↓6.18%[0m) [0.14% of initial]
[Iter 10280/20000] Loss: 0.0003632 (Best: 0.0003064 @iter10237) ([91m↑0.58%[0m) [0.14% of initial]
[Iter 10290/20000] Loss: 0.0003991 (Best: 0.0003064 @iter10237) ([91m↑9.88%[0m) [0.16% of initial]
Iter:10299, L1 loss=0.0004022, Total loss=0.0003547, Time:55
[Iter 10300/20000] Loss: 0.0003648 (Best: 0.0003064 @iter10237) ([92m↓8.61%[0m) [0.14% of initial]
[Iter 10310/20000] Loss: 0.0003827 (Best: 0.0003064 @iter10237) ([91m↑4.92%[0m) [0.15% of initial]
[Iter 10320/20000] Loss: 0.0003870 (Best: 0.0003064 @iter10237) ([91m↑1.13%[0m) [0.15% of initial]
[Iter 10330/20000] Loss: 0.0003674 (Best: 0.0003064 @iter10237) ([92m↓5.06%[0m) [0.15% of initial]
[Iter 10340/20000] Loss: 0.0003949 (Best: 0.0003064 @iter10237) ([91m↑7.47%[0m) [0.16% of initial]
[Iter 10350/20000] Loss: 0.0003722 (Best: 0.0003064 @iter10237) ([92m↓5.74%[0m) [0.15% of initial]
[Iter 10360/20000] Loss: 0.0003990 (Best: 0.0003064 @iter10237) ([91m↑7.19%[0m) [0.16% of initial]
[Iter 10370/20000] Loss: 0.0004175 (Best: 0.0003064 @iter10237) ([91m↑4.63%[0m) [0.17% of initial]
[Iter 10380/20000] Loss: 0.0003716 (Best: 0.0003064 @iter10237) ([92m↓10.98%[0m) [0.15% of initial]
[Iter 10390/20000] Loss: 0.0003959 (Best: 0.0003064 @iter10237) ([91m↑6.54%[0m) [0.16% of initial]
Iter:10399, L1 loss=0.0004162, Total loss=0.0003524, Time:56
[Iter 10400/20000] Loss: 0.0003789 (Best: 0.0003064 @iter10237) ([92m↓4.31%[0m) [0.15% of initial]
[Iter 10410/20000] Loss: 0.0003516 (Best: 0.0003064 @iter10237) ([92m↓7.21%[0m) [0.14% of initial]
[Iter 10420/20000] Loss: 0.0003633 (Best: 0.0003064 @iter10237) ([91m↑3.34%[0m) [0.14% of initial]
[Iter 10430/20000] Loss: 0.0004092 (Best: 0.0003064 @iter10237) ([91m↑12.63%[0m) [0.16% of initial]
[Iter 10440/20000] Loss: 0.0003799 (Best: 0.0003064 @iter10237) ([92m↓7.16%[0m) [0.15% of initial]
[Iter 10450/20000] Loss: 0.0003953 (Best: 0.0003064 @iter10237) ([91m↑4.06%[0m) [0.16% of initial]
[Iter 10460/20000] Loss: 0.0003343 (Best: 0.0003064 @iter10237) ([92m↓15.42%[0m) [0.13% of initial]
[Iter 10470/20000] Loss: 0.0004002 (Best: 0.0003064 @iter10237) ([91m↑19.69%[0m) [0.16% of initial]
[Iter 10480/20000] Loss: 0.0003625 (Best: 0.0003064 @iter10237) ([92m↓9.42%[0m) [0.14% of initial]
[Iter 10490/20000] Loss: 0.0003407 (Best: 0.0003064 @iter10237) ([92m↓6.01%[0m) [0.14% of initial]
Iter:10499, L1 loss=0.0003905, Total loss=0.0003314, Time:50
[Iter 10500/20000] Loss: 0.0003410 (Best: 0.0003064 @iter10237) ([91m↑0.08%[0m) [0.14% of initial]
Pruning 20 points (0.0%) from gaussian0 at iteration 10500
Pruning 20 points (0.0%) from gaussian1 at iteration 10500
[Iter 10510/20000] Loss: 0.0006188 (Best: 0.0003064 @iter10237) ([91m↑81.50%[0m) [0.25% of initial]
[Iter 10520/20000] Loss: 0.0004944 (Best: 0.0003064 @iter10237) ([92m↓20.12%[0m) [0.20% of initial]
[Iter 10530/20000] Loss: 0.0004555 (Best: 0.0003064 @iter10237) ([92m↓7.86%[0m) [0.18% of initial]
[Iter 10540/20000] Loss: 0.0004095 (Best: 0.0003064 @iter10237) ([92m↓10.09%[0m) [0.16% of initial]
[Iter 10550/20000] Loss: 0.0003548 (Best: 0.0003064 @iter10237) ([92m↓13.36%[0m) [0.14% of initial]
[Iter 10560/20000] Loss: 0.0003405 (Best: 0.0003064 @iter10237) ([92m↓4.04%[0m) [0.14% of initial]
[Iter 10570/20000] Loss: 0.0003356 (Best: 0.0003054 @iter10561) ([92m↓1.45%[0m) [0.13% of initial]
[Iter 10580/20000] Loss: 0.0003428 (Best: 0.0003054 @iter10561) ([91m↑2.15%[0m) [0.14% of initial]
[Iter 10590/20000] Loss: 0.0003423 (Best: 0.0003018 @iter10583) ([92m↓0.15%[0m) [0.14% of initial]
Iter:10599, L1 loss=0.0003717, Total loss=0.0003268, Time:50
[Iter 10600/20000] Loss: 0.0003357 (Best: 0.0003018 @iter10583) ([92m↓1.91%[0m) [0.13% of initial]
[Iter 10610/20000] Loss: 0.0003322 (Best: 0.0002961 @iter10603) ([92m↓1.04%[0m) [0.13% of initial]
[Iter 10620/20000] Loss: 0.0003280 (Best: 0.0002961 @iter10603) ([92m↓1.26%[0m) [0.13% of initial]
[Iter 10630/20000] Loss: 0.0003450 (Best: 0.0002961 @iter10603) ([91m↑5.16%[0m) [0.14% of initial]
[Iter 10640/20000] Loss: 0.0003866 (Best: 0.0002961 @iter10603) ([91m↑12.06%[0m) [0.15% of initial]
[Iter 10650/20000] Loss: 0.0003840 (Best: 0.0002961 @iter10603) ([92m↓0.66%[0m) [0.15% of initial]
[Iter 10660/20000] Loss: 0.0003591 (Best: 0.0002961 @iter10603) ([92m↓6.48%[0m) [0.14% of initial]
[Iter 10670/20000] Loss: 0.0003488 (Best: 0.0002961 @iter10603) ([92m↓2.87%[0m) [0.14% of initial]
[Iter 10680/20000] Loss: 0.0003291 (Best: 0.0002961 @iter10603) ([92m↓5.66%[0m) [0.13% of initial]
[Iter 10690/20000] Loss: 0.0003373 (Best: 0.0002961 @iter10603) ([91m↑2.51%[0m) [0.13% of initial]
Iter:10699, L1 loss=0.000413, Total loss=0.0003684, Time:49
[Iter 10700/20000] Loss: 0.0003792 (Best: 0.0002961 @iter10603) ([91m↑12.40%[0m) [0.15% of initial]
[Iter 10710/20000] Loss: 0.0003888 (Best: 0.0002961 @iter10603) ([91m↑2.54%[0m) [0.15% of initial]
[Iter 10720/20000] Loss: 0.0004384 (Best: 0.0002961 @iter10603) ([91m↑12.77%[0m) [0.17% of initial]
[Iter 10730/20000] Loss: 0.0004377 (Best: 0.0002961 @iter10603) ([92m↓0.17%[0m) [0.17% of initial]
[Iter 10740/20000] Loss: 0.0003729 (Best: 0.0002961 @iter10603) ([92m↓14.81%[0m) [0.15% of initial]
[Iter 10750/20000] Loss: 0.0003702 (Best: 0.0002961 @iter10603) ([92m↓0.71%[0m) [0.15% of initial]
[Iter 10760/20000] Loss: 0.0003398 (Best: 0.0002961 @iter10603) ([92m↓8.21%[0m) [0.14% of initial]
[Iter 10770/20000] Loss: 0.0003260 (Best: 0.0002961 @iter10603) ([92m↓4.09%[0m) [0.13% of initial]
[Iter 10780/20000] Loss: 0.0003231 (Best: 0.0002961 @iter10603) ([92m↓0.88%[0m) [0.13% of initial]
[Iter 10790/20000] Loss: 0.0003358 (Best: 0.0002850 @iter10784) ([91m↑3.92%[0m) [0.13% of initial]
Iter:10799, L1 loss=0.0003668, Total loss=0.0003312, Time:50
[Iter 10800/20000] Loss: 0.0003643 (Best: 0.0002850 @iter10784) ([91m↑8.50%[0m) [0.14% of initial]
[Iter 10810/20000] Loss: 0.0004076 (Best: 0.0002850 @iter10784) ([91m↑11.88%[0m) [0.16% of initial]
[Iter 10820/20000] Loss: 0.0003876 (Best: 0.0002850 @iter10784) ([92m↓4.90%[0m) [0.15% of initial]
[Iter 10830/20000] Loss: 0.0003834 (Best: 0.0002850 @iter10784) ([92m↓1.07%[0m) [0.15% of initial]
[Iter 10840/20000] Loss: 0.0003423 (Best: 0.0002850 @iter10784) ([92m↓10.72%[0m) [0.14% of initial]
[Iter 10850/20000] Loss: 0.0003666 (Best: 0.0002850 @iter10784) ([91m↑7.10%[0m) [0.15% of initial]
[Iter 10860/20000] Loss: 0.0003375 (Best: 0.0002850 @iter10784) ([92m↓7.96%[0m) [0.13% of initial]
[Iter 10870/20000] Loss: 0.0003331 (Best: 0.0002850 @iter10784) ([92m↓1.28%[0m) [0.13% of initial]
[Iter 10880/20000] Loss: 0.0003328 (Best: 0.0002850 @iter10784) ([92m↓0.11%[0m) [0.13% of initial]
[Iter 10890/20000] Loss: 0.0003477 (Best: 0.0002850 @iter10784) ([91m↑4.48%[0m) [0.14% of initial]
Iter:10899, L1 loss=0.0004616, Total loss=0.00041, Time:55
[Iter 10900/20000] Loss: 0.0003673 (Best: 0.0002850 @iter10784) ([91m↑5.64%[0m) [0.15% of initial]
[Iter 10910/20000] Loss: 0.0003631 (Best: 0.0002850 @iter10784) ([92m↓1.12%[0m) [0.14% of initial]
[Iter 10920/20000] Loss: 0.0003448 (Best: 0.0002850 @iter10784) ([92m↓5.06%[0m) [0.14% of initial]
[Iter 10930/20000] Loss: 0.0003312 (Best: 0.0002850 @iter10784) ([92m↓3.95%[0m) [0.13% of initial]
[Iter 10940/20000] Loss: 0.0003484 (Best: 0.0002850 @iter10784) ([91m↑5.20%[0m) [0.14% of initial]
[Iter 10950/20000] Loss: 0.0003320 (Best: 0.0002850 @iter10784) ([92m↓4.71%[0m) [0.13% of initial]
[Iter 10960/20000] Loss: 0.0003274 (Best: 0.0002850 @iter10784) ([92m↓1.38%[0m) [0.13% of initial]
[Iter 10970/20000] Loss: 0.0003118 (Best: 0.0002850 @iter10784) ([92m↓4.76%[0m) [0.12% of initial]
[Iter 10980/20000] Loss: 0.0003021 (Best: 0.0002850 @iter10784) ([92m↓3.11%[0m) [0.12% of initial]
[Iter 10990/20000] Loss: 0.0003148 (Best: 0.0002841 @iter10981) ([91m↑4.21%[0m) [0.13% of initial]
Iter:10999, L1 loss=0.0003685, Total loss=0.0003307, Time:53
[Iter 11000/20000] Loss: 0.0003062 (Best: 0.0002841 @iter10981) ([92m↓2.73%[0m) [0.12% of initial]
Pruning 10 points (0.0%) from gaussian0 at iteration 11000
Pruning 26 points (0.0%) from gaussian1 at iteration 11000
[Iter 11010/20000] Loss: 0.0006979 (Best: 0.0002841 @iter10981) ([91m↑127.91%[0m) [0.28% of initial]
[Iter 11020/20000] Loss: 0.0005304 (Best: 0.0002841 @iter10981) ([92m↓24.00%[0m) [0.21% of initial]
[Iter 11030/20000] Loss: 0.0004006 (Best: 0.0002841 @iter10981) ([92m↓24.46%[0m) [0.16% of initial]
[Iter 11040/20000] Loss: 0.0003502 (Best: 0.0002841 @iter10981) ([92m↓12.60%[0m) [0.14% of initial]
[Iter 11050/20000] Loss: 0.0003428 (Best: 0.0002841 @iter10981) ([92m↓2.11%[0m) [0.14% of initial]
[Iter 11060/20000] Loss: 0.0003057 (Best: 0.0002779 @iter11056) ([92m↓10.82%[0m) [0.12% of initial]
[Iter 11070/20000] Loss: 0.0003234 (Best: 0.0002779 @iter11056) ([91m↑5.80%[0m) [0.13% of initial]
[Iter 11080/20000] Loss: 0.0003073 (Best: 0.0002779 @iter11056) ([92m↓5.00%[0m) [0.12% of initial]
[Iter 11090/20000] Loss: 0.0003302 (Best: 0.0002779 @iter11056) ([91m↑7.47%[0m) [0.13% of initial]
Iter:11099, L1 loss=0.0003536, Total loss=0.0002995, Time:53
[Iter 11100/20000] Loss: 0.0003379 (Best: 0.0002779 @iter11056) ([91m↑2.32%[0m) [0.13% of initial]
[Iter 11110/20000] Loss: 0.0003815 (Best: 0.0002779 @iter11056) ([91m↑12.92%[0m) [0.15% of initial]
[Iter 11120/20000] Loss: 0.0003291 (Best: 0.0002779 @iter11056) ([92m↓13.73%[0m) [0.13% of initial]
[Iter 11130/20000] Loss: 0.0003841 (Best: 0.0002779 @iter11056) ([91m↑16.71%[0m) [0.15% of initial]
[Iter 11140/20000] Loss: 0.0003376 (Best: 0.0002779 @iter11056) ([92m↓12.12%[0m) [0.13% of initial]
[Iter 11150/20000] Loss: 0.0003283 (Best: 0.0002779 @iter11056) ([92m↓2.75%[0m) [0.13% of initial]
[Iter 11160/20000] Loss: 0.0003444 (Best: 0.0002779 @iter11056) ([91m↑4.91%[0m) [0.14% of initial]
[Iter 11170/20000] Loss: 0.0003418 (Best: 0.0002779 @iter11056) ([92m↓0.76%[0m) [0.14% of initial]
[Iter 11180/20000] Loss: 0.0003291 (Best: 0.0002779 @iter11056) ([92m↓3.71%[0m) [0.13% of initial]
[Iter 11190/20000] Loss: 0.0003429 (Best: 0.0002779 @iter11056) ([91m↑4.17%[0m) [0.14% of initial]
Iter:11199, L1 loss=0.000362, Total loss=0.0003169, Time:53
[Iter 11200/20000] Loss: 0.0003175 (Best: 0.0002779 @iter11056) ([92m↓7.40%[0m) [0.13% of initial]
[Iter 11210/20000] Loss: 0.0003035 (Best: 0.0002779 @iter11056) ([92m↓4.41%[0m) [0.12% of initial]
[Iter 11220/20000] Loss: 0.0003233 (Best: 0.0002779 @iter11056) ([91m↑6.52%[0m) [0.13% of initial]
[Iter 11230/20000] Loss: 0.0003192 (Best: 0.0002779 @iter11056) ([92m↓1.28%[0m) [0.13% of initial]
[Iter 11240/20000] Loss: 0.0003206 (Best: 0.0002779 @iter11056) ([91m↑0.46%[0m) [0.13% of initial]
[Iter 11250/20000] Loss: 0.0003203 (Best: 0.0002779 @iter11056) ([92m↓0.11%[0m) [0.13% of initial]
[Iter 11260/20000] Loss: 0.0002976 (Best: 0.0002779 @iter11056) ([92m↓7.09%[0m) [0.12% of initial]
[Iter 11270/20000] Loss: 0.0002906 (Best: 0.0002720 @iter11270) ([92m↓2.34%[0m) [0.12% of initial]
[Iter 11280/20000] Loss: 0.0003112 (Best: 0.0002720 @iter11270) ([91m↑7.08%[0m) [0.12% of initial]
[Iter 11290/20000] Loss: 0.0003067 (Best: 0.0002720 @iter11270) ([92m↓1.44%[0m) [0.12% of initial]
Iter:11299, L1 loss=0.0003207, Total loss=0.0002841, Time:52
[Iter 11300/20000] Loss: 0.0003138 (Best: 0.0002720 @iter11270) ([91m↑2.30%[0m) [0.12% of initial]
[Iter 11310/20000] Loss: 0.0002850 (Best: 0.0002720 @iter11270) ([92m↓9.16%[0m) [0.11% of initial]
[Iter 11320/20000] Loss: 0.0002969 (Best: 0.0002655 @iter11315) ([91m↑4.19%[0m) [0.12% of initial]
[Iter 11330/20000] Loss: 0.0003062 (Best: 0.0002655 @iter11315) ([91m↑3.11%[0m) [0.12% of initial]
[Iter 11340/20000] Loss: 0.0003261 (Best: 0.0002655 @iter11315) ([91m↑6.50%[0m) [0.13% of initial]
[Iter 11350/20000] Loss: 0.0003926 (Best: 0.0002655 @iter11315) ([91m↑20.40%[0m) [0.16% of initial]
[Iter 11360/20000] Loss: 0.0003178 (Best: 0.0002655 @iter11315) ([92m↓19.04%[0m) [0.13% of initial]
[Iter 11370/20000] Loss: 0.0003524 (Best: 0.0002655 @iter11315) ([91m↑10.87%[0m) [0.14% of initial]
[Iter 11380/20000] Loss: 0.0003604 (Best: 0.0002655 @iter11315) ([91m↑2.28%[0m) [0.14% of initial]
[Iter 11390/20000] Loss: 0.0003603 (Best: 0.0002655 @iter11315) ([92m↓0.03%[0m) [0.14% of initial]
Iter:11399, L1 loss=0.0004158, Total loss=0.0003581, Time:50
[Iter 11400/20000] Loss: 0.0003628 (Best: 0.0002655 @iter11315) ([91m↑0.71%[0m) [0.14% of initial]
[Iter 11410/20000] Loss: 0.0003336 (Best: 0.0002655 @iter11315) ([92m↓8.06%[0m) [0.13% of initial]
[Iter 11420/20000] Loss: 0.0003104 (Best: 0.0002655 @iter11315) ([92m↓6.96%[0m) [0.12% of initial]
[Iter 11430/20000] Loss: 0.0003410 (Best: 0.0002655 @iter11315) ([91m↑9.87%[0m) [0.14% of initial]
[Iter 11440/20000] Loss: 0.0003503 (Best: 0.0002655 @iter11315) ([91m↑2.72%[0m) [0.14% of initial]
[Iter 11450/20000] Loss: 0.0003652 (Best: 0.0002655 @iter11315) ([91m↑4.26%[0m) [0.15% of initial]
[Iter 11460/20000] Loss: 0.0003296 (Best: 0.0002655 @iter11315) ([92m↓9.75%[0m) [0.13% of initial]
[Iter 11470/20000] Loss: 0.0003251 (Best: 0.0002655 @iter11315) ([92m↓1.36%[0m) [0.13% of initial]
[Iter 11480/20000] Loss: 0.0003095 (Best: 0.0002655 @iter11315) ([92m↓4.79%[0m) [0.12% of initial]
[Iter 11490/20000] Loss: 0.0003160 (Best: 0.0002655 @iter11315) ([91m↑2.08%[0m) [0.13% of initial]
Iter:11499, L1 loss=0.0004346, Total loss=0.000383, Time:46
[Iter 11500/20000] Loss: 0.0003364 (Best: 0.0002655 @iter11315) ([91m↑6.45%[0m) [0.13% of initial]
Pruning 13 points (0.0%) from gaussian0 at iteration 11500
Pruning 18 points (0.0%) from gaussian1 at iteration 11500
[Iter 11510/20000] Loss: 0.0005936 (Best: 0.0002655 @iter11315) ([91m↑76.47%[0m) [0.24% of initial]
[Iter 11520/20000] Loss: 0.0004291 (Best: 0.0002655 @iter11315) ([92m↓27.71%[0m) [0.17% of initial]
[Iter 11530/20000] Loss: 0.0003676 (Best: 0.0002655 @iter11315) ([92m↓14.34%[0m) [0.15% of initial]
[Iter 11540/20000] Loss: 0.0003310 (Best: 0.0002655 @iter11315) ([92m↓9.97%[0m) [0.13% of initial]
[Iter 11550/20000] Loss: 0.0003301 (Best: 0.0002655 @iter11315) ([92m↓0.27%[0m) [0.13% of initial]
[Iter 11560/20000] Loss: 0.0003301 (Best: 0.0002655 @iter11315) ([91m↑0.02%[0m) [0.13% of initial]
[Iter 11570/20000] Loss: 0.0003176 (Best: 0.0002655 @iter11315) ([92m↓3.79%[0m) [0.13% of initial]
[Iter 11580/20000] Loss: 0.0003417 (Best: 0.0002655 @iter11315) ([91m↑7.57%[0m) [0.14% of initial]
[Iter 11590/20000] Loss: 0.0003399 (Best: 0.0002655 @iter11315) ([92m↓0.53%[0m) [0.14% of initial]
Iter:11599, L1 loss=0.0003369, Total loss=0.0003464, Time:51
[Iter 11600/20000] Loss: 0.0003377 (Best: 0.0002655 @iter11315) ([92m↓0.63%[0m) [0.13% of initial]
[Iter 11610/20000] Loss: 0.0003299 (Best: 0.0002655 @iter11315) ([92m↓2.32%[0m) [0.13% of initial]
[Iter 11620/20000] Loss: 0.0003242 (Best: 0.0002655 @iter11315) ([92m↓1.74%[0m) [0.13% of initial]
[Iter 11630/20000] Loss: 0.0002812 (Best: 0.0002655 @iter11315) ([92m↓13.24%[0m) [0.11% of initial]
[Iter 11640/20000] Loss: 0.0003263 (Best: 0.0002655 @iter11315) ([91m↑16.01%[0m) [0.13% of initial]
[Iter 11650/20000] Loss: 0.0003286 (Best: 0.0002655 @iter11315) ([91m↑0.71%[0m) [0.13% of initial]
[Iter 11660/20000] Loss: 0.0003317 (Best: 0.0002655 @iter11315) ([91m↑0.93%[0m) [0.13% of initial]
[Iter 11670/20000] Loss: 0.0003098 (Best: 0.0002655 @iter11315) ([92m↓6.59%[0m) [0.12% of initial]
[Iter 11680/20000] Loss: 0.0003173 (Best: 0.0002655 @iter11315) ([91m↑2.41%[0m) [0.13% of initial]
[Iter 11690/20000] Loss: 0.0003017 (Best: 0.0002655 @iter11315) ([92m↓4.92%[0m) [0.12% of initial]
Iter:11699, L1 loss=0.000319, Total loss=0.0002772, Time:50
[Iter 11700/20000] Loss: 0.0002813 (Best: 0.0002655 @iter11315) ([92m↓6.75%[0m) [0.11% of initial]
[Iter 11710/20000] Loss: 0.0002790 (Best: 0.0002556 @iter11707) ([92m↓0.83%[0m) [0.11% of initial]
[Iter 11720/20000] Loss: 0.0002741 (Best: 0.0002512 @iter11719) ([92m↓1.75%[0m) [0.11% of initial]
[Iter 11730/20000] Loss: 0.0002963 (Best: 0.0002512 @iter11719) ([91m↑8.11%[0m) [0.12% of initial]
[Iter 11740/20000] Loss: 0.0003132 (Best: 0.0002512 @iter11719) ([91m↑5.70%[0m) [0.12% of initial]
[Iter 11750/20000] Loss: 0.0003246 (Best: 0.0002512 @iter11719) ([91m↑3.64%[0m) [0.13% of initial]
[Iter 11760/20000] Loss: 0.0003406 (Best: 0.0002512 @iter11719) ([91m↑4.90%[0m) [0.14% of initial]
[Iter 11770/20000] Loss: 0.0002983 (Best: 0.0002512 @iter11719) ([92m↓12.42%[0m) [0.12% of initial]
[Iter 11780/20000] Loss: 0.0003034 (Best: 0.0002512 @iter11719) ([91m↑1.71%[0m) [0.12% of initial]
[Iter 11790/20000] Loss: 0.0002876 (Best: 0.0002512 @iter11719) ([92m↓5.21%[0m) [0.11% of initial]
Iter:11799, L1 loss=0.0003444, Total loss=0.0003007, Time:46
[Iter 11800/20000] Loss: 0.0002809 (Best: 0.0002512 @iter11719) ([92m↓2.32%[0m) [0.11% of initial]
[Iter 11810/20000] Loss: 0.0002648 (Best: 0.0002512 @iter11719) ([92m↓5.75%[0m) [0.11% of initial]
[Iter 11820/20000] Loss: 0.0002924 (Best: 0.0002512 @iter11719) ([91m↑10.44%[0m) [0.12% of initial]
[Iter 11830/20000] Loss: 0.0003237 (Best: 0.0002512 @iter11719) ([91m↑10.69%[0m) [0.13% of initial]
[Iter 11840/20000] Loss: 0.0003233 (Best: 0.0002512 @iter11719) ([92m↓0.11%[0m) [0.13% of initial]
[Iter 11850/20000] Loss: 0.0003092 (Best: 0.0002512 @iter11719) ([92m↓4.37%[0m) [0.12% of initial]
[Iter 11860/20000] Loss: 0.0002992 (Best: 0.0002512 @iter11719) ([92m↓3.24%[0m) [0.12% of initial]
[Iter 11870/20000] Loss: 0.0002943 (Best: 0.0002512 @iter11719) ([92m↓1.62%[0m) [0.12% of initial]
[Iter 11880/20000] Loss: 0.0002974 (Best: 0.0002512 @iter11719) ([91m↑1.05%[0m) [0.12% of initial]
[Iter 11890/20000] Loss: 0.0003610 (Best: 0.0002512 @iter11719) ([91m↑21.37%[0m) [0.14% of initial]
Iter:11899, L1 loss=0.0003594, Total loss=0.0003372, Time:49
[Iter 11900/20000] Loss: 0.0003327 (Best: 0.0002512 @iter11719) ([92m↓7.84%[0m) [0.13% of initial]
[Iter 11910/20000] Loss: 0.0003429 (Best: 0.0002512 @iter11719) ([91m↑3.07%[0m) [0.14% of initial]
[Iter 11920/20000] Loss: 0.0003818 (Best: 0.0002512 @iter11719) ([91m↑11.34%[0m) [0.15% of initial]
[Iter 11930/20000] Loss: 0.0003416 (Best: 0.0002512 @iter11719) ([92m↓10.54%[0m) [0.14% of initial]
[Iter 11940/20000] Loss: 0.0003106 (Best: 0.0002512 @iter11719) ([92m↓9.07%[0m) [0.12% of initial]
[Iter 11950/20000] Loss: 0.0003148 (Best: 0.0002512 @iter11719) ([91m↑1.37%[0m) [0.13% of initial]
[Iter 11960/20000] Loss: 0.0002715 (Best: 0.0002512 @iter11719) ([92m↓13.78%[0m) [0.11% of initial]
[Iter 11970/20000] Loss: 0.0002977 (Best: 0.0002512 @iter11719) ([91m↑9.66%[0m) [0.12% of initial]
[Iter 11980/20000] Loss: 0.0002754 (Best: 0.0002512 @iter11719) ([92m↓7.48%[0m) [0.11% of initial]
[Iter 11990/20000] Loss: 0.0002914 (Best: 0.0002512 @iter11719) ([91m↑5.81%[0m) [0.12% of initial]
Iter:11999, L1 loss=0.0003212, Total loss=0.0002881, Time:53
[Iter 12000/20000] Loss: 0.0003265 (Best: 0.0002512 @iter11719) ([91m↑12.04%[0m) [0.13% of initial]
Pruning 10 points (0.0%) from gaussian0 at iteration 12000
Pruning 11 points (0.0%) from gaussian1 at iteration 12000
[Iter 12010/20000] Loss: 0.0212707 (Best: 0.0002512 @iter11719) ([91m↑6414.70%[0m) [8.45% of initial]
[Iter 12020/20000] Loss: 0.0058984 (Best: 0.0002512 @iter11719) ([92m↓72.27%[0m) [2.34% of initial]
[Iter 12030/20000] Loss: 0.0040671 (Best: 0.0002512 @iter11719) ([92m↓31.05%[0m) [1.62% of initial]
[Iter 12040/20000] Loss: 0.0022118 (Best: 0.0002512 @iter11719) ([92m↓45.62%[0m) [0.88% of initial]
[Iter 12050/20000] Loss: 0.0014724 (Best: 0.0002512 @iter11719) ([92m↓33.43%[0m) [0.58% of initial]
[Iter 12060/20000] Loss: 0.0010354 (Best: 0.0002512 @iter11719) ([92m↓29.68%[0m) [0.41% of initial]
[Iter 12070/20000] Loss: 0.0007856 (Best: 0.0002512 @iter11719) ([92m↓24.13%[0m) [0.31% of initial]
[Iter 12080/20000] Loss: 0.0006639 (Best: 0.0002512 @iter11719) ([92m↓15.49%[0m) [0.26% of initial]
[Iter 12090/20000] Loss: 0.0005797 (Best: 0.0002512 @iter11719) ([92m↓12.69%[0m) [0.23% of initial]
Iter:12099, L1 loss=0.0006134, Total loss=0.0005614, Time:54
[Iter 12100/20000] Loss: 0.0005358 (Best: 0.0002512 @iter11719) ([92m↓7.56%[0m) [0.21% of initial]
[Iter 12110/20000] Loss: 0.0004911 (Best: 0.0002512 @iter11719) ([92m↓8.35%[0m) [0.20% of initial]
[Iter 12120/20000] Loss: 0.0004632 (Best: 0.0002512 @iter11719) ([92m↓5.67%[0m) [0.18% of initial]
[Iter 12130/20000] Loss: 0.0004371 (Best: 0.0002512 @iter11719) ([92m↓5.63%[0m) [0.17% of initial]
[Iter 12140/20000] Loss: 0.0004161 (Best: 0.0002512 @iter11719) ([92m↓4.82%[0m) [0.17% of initial]
[Iter 12150/20000] Loss: 0.0004198 (Best: 0.0002512 @iter11719) ([91m↑0.89%[0m) [0.17% of initial]
[Iter 12160/20000] Loss: 0.0003979 (Best: 0.0002512 @iter11719) ([92m↓5.21%[0m) [0.16% of initial]
[Iter 12170/20000] Loss: 0.0003804 (Best: 0.0002512 @iter11719) ([92m↓4.40%[0m) [0.15% of initial]
[Iter 12180/20000] Loss: 0.0003744 (Best: 0.0002512 @iter11719) ([92m↓1.58%[0m) [0.15% of initial]
[Iter 12190/20000] Loss: 0.0003734 (Best: 0.0002512 @iter11719) ([92m↓0.25%[0m) [0.15% of initial]
Iter:12199, L1 loss=0.0004077, Total loss=0.0003718, Time:52
[Iter 12200/20000] Loss: 0.0003595 (Best: 0.0002512 @iter11719) ([92m↓3.73%[0m) [0.14% of initial]
[Iter 12210/20000] Loss: 0.0003699 (Best: 0.0002512 @iter11719) ([91m↑2.90%[0m) [0.15% of initial]
[Iter 12220/20000] Loss: 0.0003571 (Best: 0.0002512 @iter11719) ([92m↓3.48%[0m) [0.14% of initial]
[Iter 12230/20000] Loss: 0.0003584 (Best: 0.0002512 @iter11719) ([91m↑0.37%[0m) [0.14% of initial]
[Iter 12240/20000] Loss: 0.0003690 (Best: 0.0002512 @iter11719) ([91m↑2.97%[0m) [0.15% of initial]
[Iter 12250/20000] Loss: 0.0003518 (Best: 0.0002512 @iter11719) ([92m↓4.68%[0m) [0.14% of initial]
[Iter 12260/20000] Loss: 0.0003478 (Best: 0.0002512 @iter11719) ([92m↓1.12%[0m) [0.14% of initial]
[Iter 12270/20000] Loss: 0.0003456 (Best: 0.0002512 @iter11719) ([92m↓0.65%[0m) [0.14% of initial]
[Iter 12280/20000] Loss: 0.0003544 (Best: 0.0002512 @iter11719) ([91m↑2.56%[0m) [0.14% of initial]
[Iter 12290/20000] Loss: 0.0003807 (Best: 0.0002512 @iter11719) ([91m↑7.43%[0m) [0.15% of initial]
Iter:12299, L1 loss=0.000405, Total loss=0.0003461, Time:50
[Iter 12300/20000] Loss: 0.0003496 (Best: 0.0002512 @iter11719) ([92m↓8.18%[0m) [0.14% of initial]
[Iter 12310/20000] Loss: 0.0003398 (Best: 0.0002512 @iter11719) ([92m↓2.79%[0m) [0.14% of initial]
[Iter 12320/20000] Loss: 0.0003402 (Best: 0.0002512 @iter11719) ([91m↑0.10%[0m) [0.14% of initial]
[Iter 12330/20000] Loss: 0.0003565 (Best: 0.0002512 @iter11719) ([91m↑4.79%[0m) [0.14% of initial]
[Iter 12340/20000] Loss: 0.0003497 (Best: 0.0002512 @iter11719) ([92m↓1.91%[0m) [0.14% of initial]
[Iter 12350/20000] Loss: 0.0003479 (Best: 0.0002512 @iter11719) ([92m↓0.52%[0m) [0.14% of initial]
[Iter 12360/20000] Loss: 0.0003437 (Best: 0.0002512 @iter11719) ([92m↓1.19%[0m) [0.14% of initial]
[Iter 12370/20000] Loss: 0.0003330 (Best: 0.0002512 @iter11719) ([92m↓3.12%[0m) [0.13% of initial]
[Iter 12380/20000] Loss: 0.0003365 (Best: 0.0002512 @iter11719) ([91m↑1.04%[0m) [0.13% of initial]
[Iter 12390/20000] Loss: 0.0003397 (Best: 0.0002512 @iter11719) ([91m↑0.96%[0m) [0.13% of initial]
Iter:12399, L1 loss=0.0003642, Total loss=0.0003278, Time:54
[Iter 12400/20000] Loss: 0.0003363 (Best: 0.0002512 @iter11719) ([92m↓1.01%[0m) [0.13% of initial]
[Iter 12410/20000] Loss: 0.0003511 (Best: 0.0002512 @iter11719) ([91m↑4.42%[0m) [0.14% of initial]
[Iter 12420/20000] Loss: 0.0003427 (Best: 0.0002512 @iter11719) ([92m↓2.41%[0m) [0.14% of initial]
[Iter 12430/20000] Loss: 0.0003407 (Best: 0.0002512 @iter11719) ([92m↓0.58%[0m) [0.14% of initial]
[Iter 12440/20000] Loss: 0.0003471 (Best: 0.0002512 @iter11719) ([91m↑1.88%[0m) [0.14% of initial]
[Iter 12450/20000] Loss: 0.0003495 (Best: 0.0002512 @iter11719) ([91m↑0.69%[0m) [0.14% of initial]
[Iter 12460/20000] Loss: 0.0003324 (Best: 0.0002512 @iter11719) ([92m↓4.88%[0m) [0.13% of initial]
[Iter 12470/20000] Loss: 0.0003470 (Best: 0.0002512 @iter11719) ([91m↑4.40%[0m) [0.14% of initial]
[Iter 12480/20000] Loss: 0.0003447 (Best: 0.0002512 @iter11719) ([92m↓0.68%[0m) [0.14% of initial]
[Iter 12490/20000] Loss: 0.0003414 (Best: 0.0002512 @iter11719) ([92m↓0.95%[0m) [0.14% of initial]
Iter:12499, L1 loss=0.0003831, Total loss=0.0003763, Time:56
[Iter 12500/20000] Loss: 0.0003674 (Best: 0.0002512 @iter11719) ([91m↑7.61%[0m) [0.15% of initial]
Pruning 20 points (0.0%) from gaussian0 at iteration 12500
Pruning 18 points (0.0%) from gaussian1 at iteration 12500
[Iter 12510/20000] Loss: 0.0007595 (Best: 0.0002512 @iter11719) ([91m↑106.72%[0m) [0.30% of initial]
[Iter 12520/20000] Loss: 0.0005669 (Best: 0.0002512 @iter11719) ([92m↓25.36%[0m) [0.23% of initial]
[Iter 12530/20000] Loss: 0.0004234 (Best: 0.0002512 @iter11719) ([92m↓25.31%[0m) [0.17% of initial]
[Iter 12540/20000] Loss: 0.0003804 (Best: 0.0002512 @iter11719) ([92m↓10.15%[0m) [0.15% of initial]
[Iter 12550/20000] Loss: 0.0003431 (Best: 0.0002512 @iter11719) ([92m↓9.81%[0m) [0.14% of initial]
[Iter 12560/20000] Loss: 0.0003292 (Best: 0.0002512 @iter11719) ([92m↓4.04%[0m) [0.13% of initial]
[Iter 12570/20000] Loss: 0.0003419 (Best: 0.0002512 @iter11719) ([91m↑3.86%[0m) [0.14% of initial]
[Iter 12580/20000] Loss: 0.0003540 (Best: 0.0002512 @iter11719) ([91m↑3.52%[0m) [0.14% of initial]
[Iter 12590/20000] Loss: 0.0003404 (Best: 0.0002512 @iter11719) ([92m↓3.85%[0m) [0.14% of initial]
Iter:12599, L1 loss=0.0004725, Total loss=0.0003984, Time:59
[Iter 12600/20000] Loss: 0.0003599 (Best: 0.0002512 @iter11719) ([91m↑5.74%[0m) [0.14% of initial]
[Iter 12610/20000] Loss: 0.0003524 (Best: 0.0002512 @iter11719) ([92m↓2.08%[0m) [0.14% of initial]
[Iter 12620/20000] Loss: 0.0003421 (Best: 0.0002512 @iter11719) ([92m↓2.92%[0m) [0.14% of initial]
[Iter 12630/20000] Loss: 0.0003544 (Best: 0.0002512 @iter11719) ([91m↑3.58%[0m) [0.14% of initial]
[Iter 12640/20000] Loss: 0.0003528 (Best: 0.0002512 @iter11719) ([92m↓0.44%[0m) [0.14% of initial]
[Iter 12650/20000] Loss: 0.0003401 (Best: 0.0002512 @iter11719) ([92m↓3.60%[0m) [0.14% of initial]
[Iter 12660/20000] Loss: 0.0003517 (Best: 0.0002512 @iter11719) ([91m↑3.39%[0m) [0.14% of initial]
[Iter 12670/20000] Loss: 0.0003542 (Best: 0.0002512 @iter11719) ([91m↑0.72%[0m) [0.14% of initial]
[Iter 12680/20000] Loss: 0.0003750 (Best: 0.0002512 @iter11719) ([91m↑5.86%[0m) [0.15% of initial]
[Iter 12690/20000] Loss: 0.0003546 (Best: 0.0002512 @iter11719) ([92m↓5.43%[0m) [0.14% of initial]
Iter:12699, L1 loss=0.0004588, Total loss=0.0003713, Time:53
[Iter 12700/20000] Loss: 0.0003581 (Best: 0.0002512 @iter11719) ([91m↑0.98%[0m) [0.14% of initial]
[Iter 12710/20000] Loss: 0.0003567 (Best: 0.0002512 @iter11719) ([92m↓0.39%[0m) [0.14% of initial]
[Iter 12720/20000] Loss: 0.0003468 (Best: 0.0002512 @iter11719) ([92m↓2.76%[0m) [0.14% of initial]
[Iter 12730/20000] Loss: 0.0003659 (Best: 0.0002512 @iter11719) ([91m↑5.51%[0m) [0.15% of initial]
[Iter 12740/20000] Loss: 0.0003508 (Best: 0.0002512 @iter11719) ([92m↓4.15%[0m) [0.14% of initial]
[Iter 12750/20000] Loss: 0.0003299 (Best: 0.0002512 @iter11719) ([92m↓5.94%[0m) [0.13% of initial]
[Iter 12760/20000] Loss: 0.0003337 (Best: 0.0002512 @iter11719) ([91m↑1.16%[0m) [0.13% of initial]
[Iter 12770/20000] Loss: 0.0003584 (Best: 0.0002512 @iter11719) ([91m↑7.37%[0m) [0.14% of initial]
[Iter 12780/20000] Loss: 0.0003751 (Best: 0.0002512 @iter11719) ([91m↑4.68%[0m) [0.15% of initial]
[Iter 12790/20000] Loss: 0.0003569 (Best: 0.0002512 @iter11719) ([92m↓4.87%[0m) [0.14% of initial]
Iter:12799, L1 loss=0.0003686, Total loss=0.0003517, Time:51
[Iter 12800/20000] Loss: 0.0003588 (Best: 0.0002512 @iter11719) ([91m↑0.53%[0m) [0.14% of initial]
[Iter 12810/20000] Loss: 0.0003821 (Best: 0.0002512 @iter11719) ([91m↑6.51%[0m) [0.15% of initial]
[Iter 12820/20000] Loss: 0.0003572 (Best: 0.0002512 @iter11719) ([92m↓6.52%[0m) [0.14% of initial]
[Iter 12830/20000] Loss: 0.0003467 (Best: 0.0002512 @iter11719) ([92m↓2.92%[0m) [0.14% of initial]
[Iter 12840/20000] Loss: 0.0003556 (Best: 0.0002512 @iter11719) ([91m↑2.56%[0m) [0.14% of initial]
[Iter 12850/20000] Loss: 0.0003364 (Best: 0.0002512 @iter11719) ([92m↓5.39%[0m) [0.13% of initial]
[Iter 12860/20000] Loss: 0.0003235 (Best: 0.0002512 @iter11719) ([92m↓3.86%[0m) [0.13% of initial]
[Iter 12870/20000] Loss: 0.0003189 (Best: 0.0002512 @iter11719) ([92m↓1.42%[0m) [0.13% of initial]
[Iter 12880/20000] Loss: 0.0003139 (Best: 0.0002512 @iter11719) ([92m↓1.57%[0m) [0.12% of initial]
[Iter 12890/20000] Loss: 0.0003171 (Best: 0.0002512 @iter11719) ([91m↑1.01%[0m) [0.13% of initial]
Iter:12899, L1 loss=0.0003607, Total loss=0.0003259, Time:53
[Iter 12900/20000] Loss: 0.0003139 (Best: 0.0002512 @iter11719) ([92m↓1.00%[0m) [0.12% of initial]
[Iter 12910/20000] Loss: 0.0003176 (Best: 0.0002512 @iter11719) ([91m↑1.18%[0m) [0.13% of initial]
[Iter 12920/20000] Loss: 0.0003300 (Best: 0.0002512 @iter11719) ([91m↑3.92%[0m) [0.13% of initial]
[Iter 12930/20000] Loss: 0.0003524 (Best: 0.0002512 @iter11719) ([91m↑6.77%[0m) [0.14% of initial]
[Iter 12940/20000] Loss: 0.0003745 (Best: 0.0002512 @iter11719) ([91m↑6.28%[0m) [0.15% of initial]
[Iter 12950/20000] Loss: 0.0003806 (Best: 0.0002512 @iter11719) ([91m↑1.63%[0m) [0.15% of initial]
[Iter 12960/20000] Loss: 0.0004019 (Best: 0.0002512 @iter11719) ([91m↑5.58%[0m) [0.16% of initial]
[Iter 12970/20000] Loss: 0.0003322 (Best: 0.0002512 @iter11719) ([92m↓17.32%[0m) [0.13% of initial]
[Iter 12980/20000] Loss: 0.0003639 (Best: 0.0002512 @iter11719) ([91m↑9.53%[0m) [0.14% of initial]
[Iter 12990/20000] Loss: 0.0003614 (Best: 0.0002512 @iter11719) ([92m↓0.70%[0m) [0.14% of initial]
Iter:12999, L1 loss=0.0003632, Total loss=0.0003274, Time:51
[Iter 13000/20000] Loss: 0.0003325 (Best: 0.0002512 @iter11719) ([92m↓7.98%[0m) [0.13% of initial]
Pruning 10 points (0.0%) from gaussian0 at iteration 13000
Pruning 13 points (0.0%) from gaussian1 at iteration 13000
[Iter 13010/20000] Loss: 0.0008516 (Best: 0.0002512 @iter11719) ([91m↑156.11%[0m) [0.34% of initial]
[Iter 13020/20000] Loss: 0.0005368 (Best: 0.0002512 @iter11719) ([92m↓36.97%[0m) [0.21% of initial]
[Iter 13030/20000] Loss: 0.0004252 (Best: 0.0002512 @iter11719) ([92m↓20.79%[0m) [0.17% of initial]
[Iter 13040/20000] Loss: 0.0003767 (Best: 0.0002512 @iter11719) ([92m↓11.40%[0m) [0.15% of initial]
[Iter 13050/20000] Loss: 0.0003378 (Best: 0.0002512 @iter11719) ([92m↓10.33%[0m) [0.13% of initial]
[Iter 13060/20000] Loss: 0.0003296 (Best: 0.0002512 @iter11719) ([92m↓2.42%[0m) [0.13% of initial]
[Iter 13070/20000] Loss: 0.0003283 (Best: 0.0002512 @iter11719) ([92m↓0.39%[0m) [0.13% of initial]
[Iter 13080/20000] Loss: 0.0003200 (Best: 0.0002512 @iter11719) ([92m↓2.52%[0m) [0.13% of initial]
[Iter 13090/20000] Loss: 0.0003366 (Best: 0.0002512 @iter11719) ([91m↑5.17%[0m) [0.13% of initial]
Iter:13099, L1 loss=0.000384, Total loss=0.0003333, Time:54
[Iter 13100/20000] Loss: 0.0003389 (Best: 0.0002512 @iter11719) ([91m↑0.69%[0m) [0.13% of initial]
[Iter 13110/20000] Loss: 0.0003439 (Best: 0.0002512 @iter11719) ([91m↑1.49%[0m) [0.14% of initial]
[Iter 13120/20000] Loss: 0.0003348 (Best: 0.0002512 @iter11719) ([92m↓2.65%[0m) [0.13% of initial]
[Iter 13130/20000] Loss: 0.0003407 (Best: 0.0002512 @iter11719) ([91m↑1.75%[0m) [0.14% of initial]
[Iter 13140/20000] Loss: 0.0003338 (Best: 0.0002512 @iter11719) ([92m↓2.01%[0m) [0.13% of initial]
[Iter 13150/20000] Loss: 0.0003124 (Best: 0.0002512 @iter11719) ([92m↓6.41%[0m) [0.12% of initial]
[Iter 13160/20000] Loss: 0.0003310 (Best: 0.0002512 @iter11719) ([91m↑5.94%[0m) [0.13% of initial]
[Iter 13170/20000] Loss: 0.0003227 (Best: 0.0002512 @iter11719) ([92m↓2.51%[0m) [0.13% of initial]
[Iter 13180/20000] Loss: 0.0003472 (Best: 0.0002512 @iter11719) ([91m↑7.61%[0m) [0.14% of initial]
[Iter 13190/20000] Loss: 0.0003346 (Best: 0.0002512 @iter11719) ([92m↓3.65%[0m) [0.13% of initial]
Iter:13199, L1 loss=0.0003925, Total loss=0.0003292, Time:61
[Iter 13200/20000] Loss: 0.0003433 (Best: 0.0002512 @iter11719) ([91m↑2.61%[0m) [0.14% of initial]
[Iter 13210/20000] Loss: 0.0003545 (Best: 0.0002512 @iter11719) ([91m↑3.24%[0m) [0.14% of initial]
[Iter 13220/20000] Loss: 0.0003120 (Best: 0.0002512 @iter11719) ([92m↓11.97%[0m) [0.12% of initial]
[Iter 13230/20000] Loss: 0.0003533 (Best: 0.0002512 @iter11719) ([91m↑13.22%[0m) [0.14% of initial]
[Iter 13240/20000] Loss: 0.0003316 (Best: 0.0002512 @iter11719) ([92m↓6.13%[0m) [0.13% of initial]
[Iter 13250/20000] Loss: 0.0003236 (Best: 0.0002512 @iter11719) ([92m↓2.40%[0m) [0.13% of initial]
[Iter 13260/20000] Loss: 0.0003182 (Best: 0.0002512 @iter11719) ([92m↓1.68%[0m) [0.13% of initial]
[Iter 13270/20000] Loss: 0.0003276 (Best: 0.0002512 @iter11719) ([91m↑2.96%[0m) [0.13% of initial]
[Iter 13280/20000] Loss: 0.0003330 (Best: 0.0002512 @iter11719) ([91m↑1.64%[0m) [0.13% of initial]
[Iter 13290/20000] Loss: 0.0003075 (Best: 0.0002512 @iter11719) ([92m↓7.66%[0m) [0.12% of initial]
Iter:13299, L1 loss=0.0003349, Total loss=0.0003066, Time:54
[Iter 13300/20000] Loss: 0.0003072 (Best: 0.0002512 @iter11719) ([92m↓0.10%[0m) [0.12% of initial]
[Iter 13310/20000] Loss: 0.0003030 (Best: 0.0002512 @iter11719) ([92m↓1.37%[0m) [0.12% of initial]
[Iter 13320/20000] Loss: 0.0003073 (Best: 0.0002512 @iter11719) ([91m↑1.43%[0m) [0.12% of initial]
[Iter 13330/20000] Loss: 0.0003152 (Best: 0.0002512 @iter11719) ([91m↑2.58%[0m) [0.13% of initial]
[Iter 13340/20000] Loss: 0.0003152 (Best: 0.0002512 @iter11719) ([91m↑0.01%[0m) [0.13% of initial]
[Iter 13350/20000] Loss: 0.0003043 (Best: 0.0002512 @iter11719) ([92m↓3.47%[0m) [0.12% of initial]
[Iter 13360/20000] Loss: 0.0003189 (Best: 0.0002512 @iter11719) ([91m↑4.81%[0m) [0.13% of initial]
[Iter 13370/20000] Loss: 0.0002993 (Best: 0.0002512 @iter11719) ([92m↓6.14%[0m) [0.12% of initial]
[Iter 13380/20000] Loss: 0.0003377 (Best: 0.0002512 @iter11719) ([91m↑12.81%[0m) [0.13% of initial]
[Iter 13390/20000] Loss: 0.0003655 (Best: 0.0002512 @iter11719) ([91m↑8.22%[0m) [0.15% of initial]
Iter:13399, L1 loss=0.0003427, Total loss=0.0003067, Time:52
[Iter 13400/20000] Loss: 0.0003381 (Best: 0.0002512 @iter11719) ([92m↓7.47%[0m) [0.13% of initial]
[Iter 13410/20000] Loss: 0.0003184 (Best: 0.0002512 @iter11719) ([92m↓5.84%[0m) [0.13% of initial]
[Iter 13420/20000] Loss: 0.0003176 (Best: 0.0002512 @iter11719) ([92m↓0.25%[0m) [0.13% of initial]
[Iter 13430/20000] Loss: 0.0002990 (Best: 0.0002512 @iter11719) ([92m↓5.85%[0m) [0.12% of initial]
[Iter 13440/20000] Loss: 0.0003108 (Best: 0.0002512 @iter11719) ([91m↑3.92%[0m) [0.12% of initial]
[Iter 13450/20000] Loss: 0.0003012 (Best: 0.0002512 @iter11719) ([92m↓3.08%[0m) [0.12% of initial]
[Iter 13460/20000] Loss: 0.0002983 (Best: 0.0002512 @iter11719) ([92m↓0.96%[0m) [0.12% of initial]
[Iter 13470/20000] Loss: 0.0003240 (Best: 0.0002512 @iter11719) ([91m↑8.63%[0m) [0.13% of initial]
[Iter 13480/20000] Loss: 0.0003163 (Best: 0.0002512 @iter11719) ([92m↓2.40%[0m) [0.13% of initial]
[Iter 13490/20000] Loss: 0.0003914 (Best: 0.0002512 @iter11719) ([91m↑23.76%[0m) [0.16% of initial]
Iter:13499, L1 loss=0.0003673, Total loss=0.0003408, Time:56
[Iter 13500/20000] Loss: 0.0003521 (Best: 0.0002512 @iter11719) ([92m↓10.06%[0m) [0.14% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 13500
Pruning 14 points (0.0%) from gaussian1 at iteration 13500
[Iter 13510/20000] Loss: 0.0006619 (Best: 0.0002512 @iter11719) ([91m↑88.01%[0m) [0.26% of initial]
[Iter 13520/20000] Loss: 0.0004606 (Best: 0.0002512 @iter11719) ([92m↓30.41%[0m) [0.18% of initial]
[Iter 13530/20000] Loss: 0.0003988 (Best: 0.0002512 @iter11719) ([92m↓13.41%[0m) [0.16% of initial]
[Iter 13540/20000] Loss: 0.0003431 (Best: 0.0002512 @iter11719) ([92m↓13.98%[0m) [0.14% of initial]
[Iter 13550/20000] Loss: 0.0003171 (Best: 0.0002512 @iter11719) ([92m↓7.57%[0m) [0.13% of initial]
[Iter 13560/20000] Loss: 0.0002985 (Best: 0.0002512 @iter11719) ([92m↓5.86%[0m) [0.12% of initial]
[Iter 13570/20000] Loss: 0.0002841 (Best: 0.0002512 @iter11719) ([92m↓4.81%[0m) [0.11% of initial]
[Iter 13580/20000] Loss: 0.0003077 (Best: 0.0002512 @iter11719) ([91m↑8.29%[0m) [0.12% of initial]
[Iter 13590/20000] Loss: 0.0003117 (Best: 0.0002512 @iter11719) ([91m↑1.31%[0m) [0.12% of initial]
Iter:13599, L1 loss=0.0003252, Total loss=0.0002896, Time:50
[Iter 13600/20000] Loss: 0.0002862 (Best: 0.0002512 @iter11719) ([92m↓8.19%[0m) [0.11% of initial]
[Iter 13610/20000] Loss: 0.0002998 (Best: 0.0002512 @iter11719) ([91m↑4.75%[0m) [0.12% of initial]
[Iter 13620/20000] Loss: 0.0002900 (Best: 0.0002512 @iter11719) ([92m↓3.28%[0m) [0.12% of initial]
[Iter 13630/20000] Loss: 0.0002806 (Best: 0.0002512 @iter11719) ([92m↓3.21%[0m) [0.11% of initial]
[Iter 13640/20000] Loss: 0.0003253 (Best: 0.0002512 @iter11719) ([91m↑15.91%[0m) [0.13% of initial]
[Iter 13650/20000] Loss: 0.0003283 (Best: 0.0002512 @iter11719) ([91m↑0.92%[0m) [0.13% of initial]
[Iter 13660/20000] Loss: 0.0003144 (Best: 0.0002512 @iter11719) ([92m↓4.22%[0m) [0.12% of initial]
[Iter 13670/20000] Loss: 0.0003381 (Best: 0.0002512 @iter11719) ([91m↑7.54%[0m) [0.13% of initial]
[Iter 13680/20000] Loss: 0.0003299 (Best: 0.0002512 @iter11719) ([92m↓2.42%[0m) [0.13% of initial]
[Iter 13690/20000] Loss: 0.0003458 (Best: 0.0002512 @iter11719) ([91m↑4.82%[0m) [0.14% of initial]
Iter:13699, L1 loss=0.0004009, Total loss=0.0003557, Time:53
[Iter 13700/20000] Loss: 0.0003348 (Best: 0.0002512 @iter11719) ([92m↓3.19%[0m) [0.13% of initial]
[Iter 13710/20000] Loss: 0.0003067 (Best: 0.0002512 @iter11719) ([92m↓8.41%[0m) [0.12% of initial]
[Iter 13720/20000] Loss: 0.0003132 (Best: 0.0002512 @iter11719) ([91m↑2.12%[0m) [0.12% of initial]
[Iter 13730/20000] Loss: 0.0003237 (Best: 0.0002512 @iter11719) ([91m↑3.35%[0m) [0.13% of initial]
[Iter 13740/20000] Loss: 0.0003278 (Best: 0.0002512 @iter11719) ([91m↑1.28%[0m) [0.13% of initial]
[Iter 13750/20000] Loss: 0.0003037 (Best: 0.0002512 @iter11719) ([92m↓7.35%[0m) [0.12% of initial]
[Iter 13760/20000] Loss: 0.0003101 (Best: 0.0002512 @iter11719) ([91m↑2.10%[0m) [0.12% of initial]
[Iter 13770/20000] Loss: 0.0003239 (Best: 0.0002512 @iter11719) ([91m↑4.45%[0m) [0.13% of initial]
[Iter 13780/20000] Loss: 0.0003272 (Best: 0.0002512 @iter11719) ([91m↑1.04%[0m) [0.13% of initial]
[Iter 13790/20000] Loss: 0.0003896 (Best: 0.0002512 @iter11719) ([91m↑19.06%[0m) [0.15% of initial]
Iter:13799, L1 loss=0.0003949, Total loss=0.0003305, Time:51
[Iter 13800/20000] Loss: 0.0003249 (Best: 0.0002512 @iter11719) ([92m↓16.62%[0m) [0.13% of initial]
[Iter 13810/20000] Loss: 0.0003271 (Best: 0.0002512 @iter11719) ([91m↑0.70%[0m) [0.13% of initial]
[Iter 13820/20000] Loss: 0.0003192 (Best: 0.0002512 @iter11719) ([92m↓2.43%[0m) [0.13% of initial]
[Iter 13830/20000] Loss: 0.0003326 (Best: 0.0002512 @iter11719) ([91m↑4.20%[0m) [0.13% of initial]
[Iter 13840/20000] Loss: 0.0003183 (Best: 0.0002512 @iter11719) ([92m↓4.31%[0m) [0.13% of initial]
[Iter 13850/20000] Loss: 0.0002948 (Best: 0.0002512 @iter11719) ([92m↓7.37%[0m) [0.12% of initial]
[Iter 13860/20000] Loss: 0.0002932 (Best: 0.0002512 @iter11719) ([92m↓0.54%[0m) [0.12% of initial]
[Iter 13870/20000] Loss: 0.0002849 (Best: 0.0002512 @iter11719) ([92m↓2.82%[0m) [0.11% of initial]
[Iter 13880/20000] Loss: 0.0002930 (Best: 0.0002512 @iter11719) ([91m↑2.85%[0m) [0.12% of initial]
[Iter 13890/20000] Loss: 0.0002985 (Best: 0.0002512 @iter11719) ([91m↑1.86%[0m) [0.12% of initial]
Iter:13899, L1 loss=0.0003926, Total loss=0.0003381, Time:30
[Iter 13900/20000] Loss: 0.0003184 (Best: 0.0002512 @iter11719) ([91m↑6.67%[0m) [0.13% of initial]
[Iter 13910/20000] Loss: 0.0003010 (Best: 0.0002512 @iter11719) ([92m↓5.48%[0m) [0.12% of initial]
[Iter 13920/20000] Loss: 0.0003194 (Best: 0.0002512 @iter11719) ([91m↑6.11%[0m) [0.13% of initial]
[Iter 13930/20000] Loss: 0.0002881 (Best: 0.0002512 @iter11719) ([92m↓9.80%[0m) [0.11% of initial]
[Iter 13940/20000] Loss: 0.0002996 (Best: 0.0002512 @iter11719) ([91m↑4.01%[0m) [0.12% of initial]
[Iter 13950/20000] Loss: 0.0003137 (Best: 0.0002512 @iter11719) ([91m↑4.70%[0m) [0.12% of initial]
[Iter 13960/20000] Loss: 0.0002905 (Best: 0.0002512 @iter11719) ([92m↓7.37%[0m) [0.12% of initial]
[Iter 13970/20000] Loss: 0.0003077 (Best: 0.0002512 @iter11719) ([91m↑5.90%[0m) [0.12% of initial]
[Iter 13980/20000] Loss: 0.0003164 (Best: 0.0002512 @iter11719) ([91m↑2.83%[0m) [0.13% of initial]
[Iter 13990/20000] Loss: 0.0003696 (Best: 0.0002512 @iter11719) ([91m↑16.80%[0m) [0.15% of initial]
Iter:13999, L1 loss=0.0003163, Total loss=0.0002825, Time:40
[Iter 14000/20000] Loss: 0.0003215 (Best: 0.0002512 @iter11719) ([92m↓13.01%[0m) [0.13% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 14000
Pruning 8 points (0.0%) from gaussian1 at iteration 14000
[Iter 14010/20000] Loss: 0.0006089 (Best: 0.0002512 @iter11719) ([91m↑89.40%[0m) [0.24% of initial]
[Iter 14020/20000] Loss: 0.0004848 (Best: 0.0002512 @iter11719) ([92m↓20.37%[0m) [0.19% of initial]
[Iter 14030/20000] Loss: 0.0003864 (Best: 0.0002512 @iter11719) ([92m↓20.30%[0m) [0.15% of initial]
[Iter 14040/20000] Loss: 0.0003247 (Best: 0.0002512 @iter11719) ([92m↓15.99%[0m) [0.13% of initial]
[Iter 14050/20000] Loss: 0.0003222 (Best: 0.0002512 @iter11719) ([92m↓0.75%[0m) [0.13% of initial]
[Iter 14060/20000] Loss: 0.0003203 (Best: 0.0002512 @iter11719) ([92m↓0.59%[0m) [0.13% of initial]
[Iter 14070/20000] Loss: 0.0003057 (Best: 0.0002512 @iter11719) ([92m↓4.57%[0m) [0.12% of initial]
[Iter 14080/20000] Loss: 0.0002854 (Best: 0.0002512 @iter11719) ([92m↓6.64%[0m) [0.11% of initial]
[Iter 14090/20000] Loss: 0.0002857 (Best: 0.0002512 @iter11719) ([91m↑0.09%[0m) [0.11% of initial]
Iter:14099, L1 loss=0.0003292, Total loss=0.0002767, Time:50
[Iter 14100/20000] Loss: 0.0002816 (Best: 0.0002512 @iter11719) ([92m↓1.43%[0m) [0.11% of initial]
[Iter 14110/20000] Loss: 0.0003082 (Best: 0.0002512 @iter11719) ([91m↑9.45%[0m) [0.12% of initial]
[Iter 14120/20000] Loss: 0.0002998 (Best: 0.0002512 @iter11719) ([92m↓2.70%[0m) [0.12% of initial]
[Iter 14130/20000] Loss: 0.0003212 (Best: 0.0002512 @iter11719) ([91m↑7.14%[0m) [0.13% of initial]
[Iter 14140/20000] Loss: 0.0002921 (Best: 0.0002512 @iter11719) ([92m↓9.08%[0m) [0.12% of initial]
[Iter 14150/20000] Loss: 0.0002919 (Best: 0.0002512 @iter11719) ([92m↓0.04%[0m) [0.12% of initial]
[Iter 14160/20000] Loss: 0.0002782 (Best: 0.0002512 @iter11719) ([92m↓4.72%[0m) [0.11% of initial]
[Iter 14170/20000] Loss: 0.0003173 (Best: 0.0002512 @iter11719) ([91m↑14.06%[0m) [0.13% of initial]
[Iter 14180/20000] Loss: 0.0002887 (Best: 0.0002512 @iter11719) ([92m↓9.01%[0m) [0.11% of initial]
[Iter 14190/20000] Loss: 0.0002855 (Best: 0.0002512 @iter11719) ([92m↓1.12%[0m) [0.11% of initial]
Iter:14199, L1 loss=0.0003189, Total loss=0.0002693, Time:54
[Iter 14200/20000] Loss: 0.0002809 (Best: 0.0002512 @iter11719) ([92m↓1.60%[0m) [0.11% of initial]
[Iter 14210/20000] Loss: 0.0002699 (Best: 0.0002493 @iter14206) ([92m↓3.93%[0m) [0.11% of initial]
[Iter 14220/20000] Loss: 0.0002708 (Best: 0.0002493 @iter14206) ([91m↑0.34%[0m) [0.11% of initial]
[Iter 14230/20000] Loss: 0.0003365 (Best: 0.0002493 @iter14206) ([91m↑24.27%[0m) [0.13% of initial]
[Iter 14240/20000] Loss: 0.0002929 (Best: 0.0002493 @iter14206) ([92m↓12.95%[0m) [0.12% of initial]
[Iter 14250/20000] Loss: 0.0003068 (Best: 0.0002493 @iter14206) ([91m↑4.71%[0m) [0.12% of initial]
[Iter 14260/20000] Loss: 0.0002907 (Best: 0.0002493 @iter14206) ([92m↓5.23%[0m) [0.12% of initial]
[Iter 14270/20000] Loss: 0.0003061 (Best: 0.0002493 @iter14206) ([91m↑5.28%[0m) [0.12% of initial]
[Iter 14280/20000] Loss: 0.0002974 (Best: 0.0002493 @iter14206) ([92m↓2.82%[0m) [0.12% of initial]
[Iter 14290/20000] Loss: 0.0002769 (Best: 0.0002493 @iter14206) ([92m↓6.89%[0m) [0.11% of initial]
Iter:14299, L1 loss=0.0003206, Total loss=0.0002888, Time:51
[Iter 14300/20000] Loss: 0.0002851 (Best: 0.0002493 @iter14206) ([91m↑2.96%[0m) [0.11% of initial]
[Iter 14310/20000] Loss: 0.0003077 (Best: 0.0002493 @iter14206) ([91m↑7.94%[0m) [0.12% of initial]
[Iter 14320/20000] Loss: 0.0002877 (Best: 0.0002493 @iter14206) ([92m↓6.52%[0m) [0.11% of initial]
[Iter 14330/20000] Loss: 0.0002952 (Best: 0.0002493 @iter14206) ([91m↑2.64%[0m) [0.12% of initial]
[Iter 14340/20000] Loss: 0.0003350 (Best: 0.0002493 @iter14206) ([91m↑13.46%[0m) [0.13% of initial]
[Iter 14350/20000] Loss: 0.0003305 (Best: 0.0002493 @iter14206) ([92m↓1.33%[0m) [0.13% of initial]
[Iter 14360/20000] Loss: 0.0003145 (Best: 0.0002493 @iter14206) ([92m↓4.86%[0m) [0.12% of initial]
[Iter 14370/20000] Loss: 0.0002967 (Best: 0.0002493 @iter14206) ([92m↓5.63%[0m) [0.12% of initial]
[Iter 14380/20000] Loss: 0.0003028 (Best: 0.0002493 @iter14206) ([91m↑2.05%[0m) [0.12% of initial]
[Iter 14390/20000] Loss: 0.0003269 (Best: 0.0002493 @iter14206) ([91m↑7.95%[0m) [0.13% of initial]
Iter:14399, L1 loss=0.0003174, Total loss=0.0002769, Time:48
[Iter 14400/20000] Loss: 0.0003023 (Best: 0.0002493 @iter14206) ([92m↓7.52%[0m) [0.12% of initial]
[Iter 14410/20000] Loss: 0.0003104 (Best: 0.0002493 @iter14206) ([91m↑2.68%[0m) [0.12% of initial]
[Iter 14420/20000] Loss: 0.0004075 (Best: 0.0002493 @iter14206) ([91m↑31.27%[0m) [0.16% of initial]
[Iter 14430/20000] Loss: 0.0004108 (Best: 0.0002493 @iter14206) ([91m↑0.82%[0m) [0.16% of initial]
[Iter 14440/20000] Loss: 0.0003810 (Best: 0.0002493 @iter14206) ([92m↓7.24%[0m) [0.15% of initial]
[Iter 14450/20000] Loss: 0.0003557 (Best: 0.0002493 @iter14206) ([92m↓6.65%[0m) [0.14% of initial]
[Iter 14460/20000] Loss: 0.0003477 (Best: 0.0002493 @iter14206) ([92m↓2.25%[0m) [0.14% of initial]
[Iter 14470/20000] Loss: 0.0003323 (Best: 0.0002493 @iter14206) ([92m↓4.41%[0m) [0.13% of initial]
[Iter 14480/20000] Loss: 0.0003135 (Best: 0.0002493 @iter14206) ([92m↓5.68%[0m) [0.12% of initial]
[Iter 14490/20000] Loss: 0.0003179 (Best: 0.0002493 @iter14206) ([91m↑1.40%[0m) [0.13% of initial]
Iter:14499, L1 loss=0.0003442, Total loss=0.000325, Time:54
[Iter 14500/20000] Loss: 0.0003108 (Best: 0.0002493 @iter14206) ([92m↓2.21%[0m) [0.12% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 14500
Pruning 10 points (0.0%) from gaussian1 at iteration 14500
[Iter 14510/20000] Loss: 0.0006681 (Best: 0.0002493 @iter14206) ([91m↑114.96%[0m) [0.27% of initial]
[Iter 14520/20000] Loss: 0.0005674 (Best: 0.0002493 @iter14206) ([92m↓15.09%[0m) [0.23% of initial]
[Iter 14530/20000] Loss: 0.0004527 (Best: 0.0002493 @iter14206) ([92m↓20.20%[0m) [0.18% of initial]
[Iter 14540/20000] Loss: 0.0003678 (Best: 0.0002493 @iter14206) ([92m↓18.77%[0m) [0.15% of initial]
[Iter 14550/20000] Loss: 0.0003291 (Best: 0.0002493 @iter14206) ([92m↓10.52%[0m) [0.13% of initial]
[Iter 14560/20000] Loss: 0.0002890 (Best: 0.0002493 @iter14206) ([92m↓12.17%[0m) [0.11% of initial]
[Iter 14570/20000] Loss: 0.0002786 (Best: 0.0002493 @iter14206) ([92m↓3.62%[0m) [0.11% of initial]
[Iter 14580/20000] Loss: 0.0002655 (Best: 0.0002467 @iter14578) ([92m↓4.69%[0m) [0.11% of initial]
[Iter 14590/20000] Loss: 0.0002691 (Best: 0.0002467 @iter14578) ([91m↑1.36%[0m) [0.11% of initial]
Iter:14599, L1 loss=0.0003175, Total loss=0.0002986, Time:50
[Iter 14600/20000] Loss: 0.0002917 (Best: 0.0002467 @iter14578) ([91m↑8.40%[0m) [0.12% of initial]
[Iter 14610/20000] Loss: 0.0003375 (Best: 0.0002467 @iter14578) ([91m↑15.69%[0m) [0.13% of initial]
[Iter 14620/20000] Loss: 0.0002971 (Best: 0.0002467 @iter14578) ([92m↓11.95%[0m) [0.12% of initial]
[Iter 14630/20000] Loss: 0.0002685 (Best: 0.0002467 @iter14578) ([92m↓9.62%[0m) [0.11% of initial]
[Iter 14640/20000] Loss: 0.0002805 (Best: 0.0002467 @iter14578) ([91m↑4.45%[0m) [0.11% of initial]
[Iter 14650/20000] Loss: 0.0002886 (Best: 0.0002467 @iter14578) ([91m↑2.87%[0m) [0.11% of initial]
[Iter 14660/20000] Loss: 0.0002774 (Best: 0.0002467 @iter14578) ([92m↓3.88%[0m) [0.11% of initial]
[Iter 14670/20000] Loss: 0.0002715 (Best: 0.0002467 @iter14578) ([92m↓2.12%[0m) [0.11% of initial]
[Iter 14680/20000] Loss: 0.0002675 (Best: 0.0002467 @iter14578) ([92m↓1.47%[0m) [0.11% of initial]
[Iter 14690/20000] Loss: 0.0002575 (Best: 0.0002454 @iter14689) ([92m↓3.74%[0m) [0.10% of initial]
Iter:14699, L1 loss=0.0003144, Total loss=0.0002788, Time:53
[Iter 14700/20000] Loss: 0.0002735 (Best: 0.0002454 @iter14689) ([91m↑6.22%[0m) [0.11% of initial]
[Iter 14710/20000] Loss: 0.0002639 (Best: 0.0002454 @iter14689) ([92m↓3.51%[0m) [0.10% of initial]
[Iter 14720/20000] Loss: 0.0002746 (Best: 0.0002454 @iter14689) ([91m↑4.05%[0m) [0.11% of initial]
[Iter 14730/20000] Loss: 0.0002813 (Best: 0.0002454 @iter14689) ([91m↑2.44%[0m) [0.11% of initial]
[Iter 14740/20000] Loss: 0.0002608 (Best: 0.0002454 @iter14689) ([92m↓7.29%[0m) [0.10% of initial]
[Iter 14750/20000] Loss: 0.0002613 (Best: 0.0002454 @iter14689) ([91m↑0.17%[0m) [0.10% of initial]
[Iter 14760/20000] Loss: 0.0002760 (Best: 0.0002419 @iter14752) ([91m↑5.62%[0m) [0.11% of initial]
[Iter 14770/20000] Loss: 0.0003300 (Best: 0.0002419 @iter14752) ([91m↑19.59%[0m) [0.13% of initial]
[Iter 14780/20000] Loss: 0.0003506 (Best: 0.0002419 @iter14752) ([91m↑6.23%[0m) [0.14% of initial]
[Iter 14790/20000] Loss: 0.0003382 (Best: 0.0002419 @iter14752) ([92m↓3.54%[0m) [0.13% of initial]
Iter:14799, L1 loss=0.0004117, Total loss=0.0003554, Time:53
[Iter 14800/20000] Loss: 0.0003166 (Best: 0.0002419 @iter14752) ([92m↓6.38%[0m) [0.13% of initial]
[Iter 14810/20000] Loss: 0.0002947 (Best: 0.0002419 @iter14752) ([92m↓6.94%[0m) [0.12% of initial]
[Iter 14820/20000] Loss: 0.0002860 (Best: 0.0002419 @iter14752) ([92m↓2.96%[0m) [0.11% of initial]
[Iter 14830/20000] Loss: 0.0002825 (Best: 0.0002419 @iter14752) ([92m↓1.20%[0m) [0.11% of initial]
[Iter 14840/20000] Loss: 0.0002923 (Best: 0.0002419 @iter14752) ([91m↑3.45%[0m) [0.12% of initial]
[Iter 14850/20000] Loss: 0.0002985 (Best: 0.0002419 @iter14752) ([91m↑2.13%[0m) [0.12% of initial]
[Iter 14860/20000] Loss: 0.0003015 (Best: 0.0002419 @iter14752) ([91m↑1.01%[0m) [0.12% of initial]
[Iter 14870/20000] Loss: 0.0002987 (Best: 0.0002419 @iter14752) ([92m↓0.92%[0m) [0.12% of initial]
[Iter 14880/20000] Loss: 0.0002908 (Best: 0.0002419 @iter14752) ([92m↓2.67%[0m) [0.12% of initial]
[Iter 14890/20000] Loss: 0.0002781 (Best: 0.0002419 @iter14752) ([92m↓4.35%[0m) [0.11% of initial]
Iter:14899, L1 loss=0.0003029, Total loss=0.0002729, Time:51
[Iter 14900/20000] Loss: 0.0002713 (Best: 0.0002419 @iter14752) ([92m↓2.45%[0m) [0.11% of initial]
[Iter 14910/20000] Loss: 0.0002699 (Best: 0.0002419 @iter14752) ([92m↓0.50%[0m) [0.11% of initial]
[Iter 14920/20000] Loss: 0.0002740 (Best: 0.0002419 @iter14752) ([91m↑1.49%[0m) [0.11% of initial]
[Iter 14930/20000] Loss: 0.0002713 (Best: 0.0002419 @iter14752) ([92m↓0.98%[0m) [0.11% of initial]
[Iter 14940/20000] Loss: 0.0002586 (Best: 0.0002419 @iter14752) ([92m↓4.67%[0m) [0.10% of initial]
[Iter 14950/20000] Loss: 0.0002761 (Best: 0.0002419 @iter14752) ([91m↑6.77%[0m) [0.11% of initial]
[Iter 14960/20000] Loss: 0.0002597 (Best: 0.0002419 @iter14752) ([92m↓5.95%[0m) [0.10% of initial]
[Iter 14970/20000] Loss: 0.0003102 (Best: 0.0002419 @iter14752) ([91m↑19.45%[0m) [0.12% of initial]
[Iter 14980/20000] Loss: 0.0002870 (Best: 0.0002419 @iter14752) ([92m↓7.47%[0m) [0.11% of initial]
[Iter 14990/20000] Loss: 0.0003420 (Best: 0.0002419 @iter14752) ([91m↑19.16%[0m) [0.14% of initial]
Iter:14999, L1 loss=0.0004155, Total loss=0.0003421, Time:50
[Iter 15000/20000] Loss: 0.0004061 (Best: 0.0002419 @iter14752) ([91m↑18.73%[0m) [0.16% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 15000
Pruning 4 points (0.0%) from gaussian1 at iteration 15000
[Iter 15010/20000] Loss: 0.0004689 (Best: 0.0002419 @iter14752) ([91m↑15.47%[0m) [0.19% of initial]
[Iter 15020/20000] Loss: 0.0003985 (Best: 0.0002419 @iter14752) ([92m↓15.01%[0m) [0.16% of initial]
[Iter 15030/20000] Loss: 0.0003182 (Best: 0.0002419 @iter14752) ([92m↓20.16%[0m) [0.13% of initial]
[Iter 15040/20000] Loss: 0.0002886 (Best: 0.0002419 @iter14752) ([92m↓9.29%[0m) [0.11% of initial]
[Iter 15050/20000] Loss: 0.0002699 (Best: 0.0002419 @iter14752) ([92m↓6.49%[0m) [0.11% of initial]
[Iter 15060/20000] Loss: 0.0002908 (Best: 0.0002419 @iter14752) ([91m↑7.74%[0m) [0.12% of initial]
[Iter 15070/20000] Loss: 0.0002740 (Best: 0.0002419 @iter14752) ([92m↓5.76%[0m) [0.11% of initial]
[Iter 15080/20000] Loss: 0.0002679 (Best: 0.0002419 @iter14752) ([92m↓2.24%[0m) [0.11% of initial]
[Iter 15090/20000] Loss: 0.0002582 (Best: 0.0002419 @iter14752) ([92m↓3.62%[0m) [0.10% of initial]
Iter:15099, L1 loss=0.0002794, Total loss=0.0002425, Time:50
[Iter 15100/20000] Loss: 0.0002441 (Best: 0.0002382 @iter15092) ([92m↓5.46%[0m) [0.10% of initial]
[Iter 15110/20000] Loss: 0.0002668 (Best: 0.0002331 @iter15101) ([91m↑9.28%[0m) [0.11% of initial]
[Iter 15120/20000] Loss: 0.0002816 (Best: 0.0002331 @iter15101) ([91m↑5.58%[0m) [0.11% of initial]
[Iter 15130/20000] Loss: 0.0002914 (Best: 0.0002331 @iter15101) ([91m↑3.48%[0m) [0.12% of initial]
[Iter 15140/20000] Loss: 0.0002596 (Best: 0.0002331 @iter15101) ([92m↓10.93%[0m) [0.10% of initial]
[Iter 15150/20000] Loss: 0.0003014 (Best: 0.0002331 @iter15101) ([91m↑16.12%[0m) [0.12% of initial]
[Iter 15160/20000] Loss: 0.0002660 (Best: 0.0002331 @iter15101) ([92m↓11.76%[0m) [0.11% of initial]
[Iter 15170/20000] Loss: 0.0002660 (Best: 0.0002331 @iter15101) ([91m↑0.00%[0m) [0.11% of initial]
[Iter 15180/20000] Loss: 0.0002789 (Best: 0.0002331 @iter15101) ([91m↑4.87%[0m) [0.11% of initial]
[Iter 15190/20000] Loss: 0.0002751 (Best: 0.0002331 @iter15101) ([92m↓1.39%[0m) [0.11% of initial]
Iter:15199, L1 loss=0.00031, Total loss=0.0002789, Time:47
[Iter 15200/20000] Loss: 0.0002787 (Best: 0.0002331 @iter15101) ([91m↑1.32%[0m) [0.11% of initial]
[Iter 15210/20000] Loss: 0.0003440 (Best: 0.0002331 @iter15101) ([91m↑23.42%[0m) [0.14% of initial]
[Iter 15220/20000] Loss: 0.0003409 (Best: 0.0002331 @iter15101) ([92m↓0.88%[0m) [0.14% of initial]
[Iter 15230/20000] Loss: 0.0002950 (Best: 0.0002331 @iter15101) ([92m↓13.48%[0m) [0.12% of initial]
[Iter 15240/20000] Loss: 0.0002738 (Best: 0.0002331 @iter15101) ([92m↓7.17%[0m) [0.11% of initial]
[Iter 15250/20000] Loss: 0.0002551 (Best: 0.0002331 @iter15101) ([92m↓6.83%[0m) [0.10% of initial]
[Iter 15260/20000] Loss: 0.0002723 (Best: 0.0002331 @iter15101) ([91m↑6.75%[0m) [0.11% of initial]
[Iter 15270/20000] Loss: 0.0002712 (Best: 0.0002331 @iter15101) ([92m↓0.41%[0m) [0.11% of initial]
[Iter 15280/20000] Loss: 0.0002692 (Best: 0.0002331 @iter15101) ([92m↓0.74%[0m) [0.11% of initial]
[Iter 15290/20000] Loss: 0.0002732 (Best: 0.0002331 @iter15101) ([91m↑1.49%[0m) [0.11% of initial]
Iter:15299, L1 loss=0.0003542, Total loss=0.0002882, Time:48
[Iter 15300/20000] Loss: 0.0002876 (Best: 0.0002331 @iter15101) ([91m↑5.25%[0m) [0.11% of initial]
[Iter 15310/20000] Loss: 0.0002932 (Best: 0.0002331 @iter15101) ([91m↑1.97%[0m) [0.12% of initial]
[Iter 15320/20000] Loss: 0.0002862 (Best: 0.0002331 @iter15101) ([92m↓2.40%[0m) [0.11% of initial]
[Iter 15330/20000] Loss: 0.0002798 (Best: 0.0002331 @iter15101) ([92m↓2.22%[0m) [0.11% of initial]
[Iter 15340/20000] Loss: 0.0002699 (Best: 0.0002331 @iter15101) ([92m↓3.56%[0m) [0.11% of initial]
[Iter 15350/20000] Loss: 0.0002769 (Best: 0.0002331 @iter15101) ([91m↑2.59%[0m) [0.11% of initial]
[Iter 15360/20000] Loss: 0.0002894 (Best: 0.0002331 @iter15101) ([91m↑4.54%[0m) [0.11% of initial]
[Iter 15370/20000] Loss: 0.0002859 (Best: 0.0002331 @iter15101) ([92m↓1.23%[0m) [0.11% of initial]
[Iter 15380/20000] Loss: 0.0002786 (Best: 0.0002331 @iter15101) ([92m↓2.53%[0m) [0.11% of initial]
[Iter 15390/20000] Loss: 0.0002739 (Best: 0.0002331 @iter15101) ([92m↓1.70%[0m) [0.11% of initial]
Iter:15399, L1 loss=0.0002861, Total loss=0.0002467, Time:51
[Iter 15400/20000] Loss: 0.0002455 (Best: 0.0002331 @iter15101) ([92m↓10.35%[0m) [0.10% of initial]
[Iter 15410/20000] Loss: 0.0002472 (Best: 0.0002292 @iter15409) ([91m↑0.66%[0m) [0.10% of initial]
[Iter 15420/20000] Loss: 0.0002490 (Best: 0.0002292 @iter15409) ([91m↑0.75%[0m) [0.10% of initial]
[Iter 15430/20000] Loss: 0.0002451 (Best: 0.0002292 @iter15409) ([92m↓1.57%[0m) [0.10% of initial]
[Iter 15440/20000] Loss: 0.0002469 (Best: 0.0002292 @iter15409) ([91m↑0.73%[0m) [0.10% of initial]
[Iter 15450/20000] Loss: 0.0002655 (Best: 0.0002292 @iter15409) ([91m↑7.52%[0m) [0.11% of initial]
[Iter 15460/20000] Loss: 0.0002912 (Best: 0.0002292 @iter15409) ([91m↑9.70%[0m) [0.12% of initial]
[Iter 15470/20000] Loss: 0.0003199 (Best: 0.0002292 @iter15409) ([91m↑9.84%[0m) [0.13% of initial]
[Iter 15480/20000] Loss: 0.0003053 (Best: 0.0002292 @iter15409) ([92m↓4.56%[0m) [0.12% of initial]
[Iter 15490/20000] Loss: 0.0002655 (Best: 0.0002292 @iter15409) ([92m↓13.03%[0m) [0.11% of initial]
Iter:15499, L1 loss=0.0002982, Total loss=0.0002667, Time:54
[Iter 15500/20000] Loss: 0.0002753 (Best: 0.0002292 @iter15409) ([91m↑3.69%[0m) [0.11% of initial]
Pruning 6 points (0.0%) from gaussian0 at iteration 15500
Pruning 7 points (0.0%) from gaussian1 at iteration 15500
[Iter 15510/20000] Loss: 0.0006046 (Best: 0.0002292 @iter15409) ([91m↑119.60%[0m) [0.24% of initial]
[Iter 15520/20000] Loss: 0.0004058 (Best: 0.0002292 @iter15409) ([92m↓32.88%[0m) [0.16% of initial]
[Iter 15530/20000] Loss: 0.0003282 (Best: 0.0002292 @iter15409) ([92m↓19.11%[0m) [0.13% of initial]
[Iter 15540/20000] Loss: 0.0002768 (Best: 0.0002292 @iter15409) ([92m↓15.66%[0m) [0.11% of initial]
[Iter 15550/20000] Loss: 0.0002646 (Best: 0.0002292 @iter15409) ([92m↓4.41%[0m) [0.11% of initial]
[Iter 15560/20000] Loss: 0.0002817 (Best: 0.0002292 @iter15409) ([91m↑6.45%[0m) [0.11% of initial]
[Iter 15570/20000] Loss: 0.0003477 (Best: 0.0002292 @iter15409) ([91m↑23.43%[0m) [0.14% of initial]
[Iter 15580/20000] Loss: 0.0002804 (Best: 0.0002292 @iter15409) ([92m↓19.34%[0m) [0.11% of initial]
[Iter 15590/20000] Loss: 0.0002645 (Best: 0.0002292 @iter15409) ([92m↓5.68%[0m) [0.11% of initial]
Iter:15599, L1 loss=0.00028, Total loss=0.0002575, Time:47
[Iter 15600/20000] Loss: 0.0002588 (Best: 0.0002292 @iter15409) ([92m↓2.16%[0m) [0.10% of initial]
[Iter 15610/20000] Loss: 0.0002685 (Best: 0.0002292 @iter15409) ([91m↑3.74%[0m) [0.11% of initial]
[Iter 15620/20000] Loss: 0.0002456 (Best: 0.0002292 @iter15409) ([92m↓8.53%[0m) [0.10% of initial]
[Iter 15630/20000] Loss: 0.0002714 (Best: 0.0002292 @iter15409) ([91m↑10.50%[0m) [0.11% of initial]
[Iter 15640/20000] Loss: 0.0002555 (Best: 0.0002292 @iter15409) ([92m↓5.87%[0m) [0.10% of initial]
[Iter 15650/20000] Loss: 0.0002888 (Best: 0.0002292 @iter15409) ([91m↑13.04%[0m) [0.11% of initial]
[Iter 15660/20000] Loss: 0.0002630 (Best: 0.0002292 @iter15409) ([92m↓8.94%[0m) [0.10% of initial]
[Iter 15670/20000] Loss: 0.0002708 (Best: 0.0002292 @iter15409) ([91m↑2.99%[0m) [0.11% of initial]
[Iter 15680/20000] Loss: 0.0003601 (Best: 0.0002292 @iter15409) ([91m↑32.98%[0m) [0.14% of initial]
[Iter 15690/20000] Loss: 0.0003207 (Best: 0.0002292 @iter15409) ([92m↓10.96%[0m) [0.13% of initial]
Iter:15699, L1 loss=0.0003277, Total loss=0.0002618, Time:55
[Iter 15700/20000] Loss: 0.0002709 (Best: 0.0002292 @iter15409) ([92m↓15.51%[0m) [0.11% of initial]
[Iter 15710/20000] Loss: 0.0002491 (Best: 0.0002292 @iter15409) ([92m↓8.06%[0m) [0.10% of initial]
[Iter 15720/20000] Loss: 0.0002615 (Best: 0.0002292 @iter15409) ([91m↑4.97%[0m) [0.10% of initial]
[Iter 15730/20000] Loss: 0.0002716 (Best: 0.0002292 @iter15409) ([91m↑3.86%[0m) [0.11% of initial]
[Iter 15740/20000] Loss: 0.0002623 (Best: 0.0002292 @iter15409) ([92m↓3.42%[0m) [0.10% of initial]
[Iter 15750/20000] Loss: 0.0002710 (Best: 0.0002292 @iter15409) ([91m↑3.31%[0m) [0.11% of initial]
[Iter 15760/20000] Loss: 0.0002807 (Best: 0.0002292 @iter15409) ([91m↑3.60%[0m) [0.11% of initial]
[Iter 15770/20000] Loss: 0.0003014 (Best: 0.0002292 @iter15409) ([91m↑7.37%[0m) [0.12% of initial]
[Iter 15780/20000] Loss: 0.0002662 (Best: 0.0002292 @iter15409) ([92m↓11.70%[0m) [0.11% of initial]
[Iter 15790/20000] Loss: 0.0002569 (Best: 0.0002292 @iter15409) ([92m↓3.48%[0m) [0.10% of initial]
Iter:15799, L1 loss=0.0002602, Total loss=0.0002357, Time:53
[Iter 15800/20000] Loss: 0.0002533 (Best: 0.0002292 @iter15409) ([92m↓1.39%[0m) [0.10% of initial]
[Iter 15810/20000] Loss: 0.0002727 (Best: 0.0002292 @iter15409) ([91m↑7.65%[0m) [0.11% of initial]
[Iter 15820/20000] Loss: 0.0002776 (Best: 0.0002292 @iter15409) ([91m↑1.78%[0m) [0.11% of initial]
[Iter 15830/20000] Loss: 0.0002968 (Best: 0.0002292 @iter15409) ([91m↑6.93%[0m) [0.12% of initial]
[Iter 15840/20000] Loss: 0.0002687 (Best: 0.0002292 @iter15409) ([92m↓9.48%[0m) [0.11% of initial]
[Iter 15850/20000] Loss: 0.0002713 (Best: 0.0002292 @iter15409) ([91m↑0.97%[0m) [0.11% of initial]
[Iter 15860/20000] Loss: 0.0002756 (Best: 0.0002292 @iter15409) ([91m↑1.59%[0m) [0.11% of initial]
[Iter 15870/20000] Loss: 0.0002752 (Best: 0.0002292 @iter15409) ([92m↓0.13%[0m) [0.11% of initial]
[Iter 15880/20000] Loss: 0.0002701 (Best: 0.0002292 @iter15409) ([92m↓1.84%[0m) [0.11% of initial]
[Iter 15890/20000] Loss: 0.0002623 (Best: 0.0002292 @iter15409) ([92m↓2.90%[0m) [0.10% of initial]
Iter:15899, L1 loss=0.0002584, Total loss=0.0002328, Time:54
[Iter 15900/20000] Loss: 0.0002421 (Best: 0.0002292 @iter15409) ([92m↓7.70%[0m) [0.10% of initial]
[Iter 15910/20000] Loss: 0.0002363 (Best: 0.0002252 @iter15907) ([92m↓2.40%[0m) [0.09% of initial]
[Iter 15920/20000] Loss: 0.0002421 (Best: 0.0002225 @iter15916) ([91m↑2.44%[0m) [0.10% of initial]
[Iter 15930/20000] Loss: 0.0002370 (Best: 0.0002225 @iter15916) ([92m↓2.08%[0m) [0.09% of initial]
[Iter 15940/20000] Loss: 0.0002288 (Best: 0.0002192 @iter15940) ([92m↓3.46%[0m) [0.09% of initial]
[Iter 15950/20000] Loss: 0.0002765 (Best: 0.0002192 @iter15940) ([91m↑20.84%[0m) [0.11% of initial]
[Iter 15960/20000] Loss: 0.0002513 (Best: 0.0002192 @iter15940) ([92m↓9.11%[0m) [0.10% of initial]
[Iter 15970/20000] Loss: 0.0002393 (Best: 0.0002192 @iter15940) ([92m↓4.80%[0m) [0.10% of initial]
[Iter 15980/20000] Loss: 0.0002352 (Best: 0.0002192 @iter15940) ([92m↓1.72%[0m) [0.09% of initial]
[Iter 15990/20000] Loss: 0.0002584 (Best: 0.0002192 @iter15940) ([91m↑9.88%[0m) [0.10% of initial]
Iter:15999, L1 loss=0.000295, Total loss=0.0002746, Time:47
[Iter 16000/20000] Loss: 0.0002768 (Best: 0.0002192 @iter15940) ([91m↑7.11%[0m) [0.11% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 16000
Pruning 1 points (0.0%) from gaussian1 at iteration 16000
[Iter 16010/20000] Loss: 0.0136174 (Best: 0.0002192 @iter15940) ([91m↑4820.10%[0m) [5.41% of initial]
[Iter 16020/20000] Loss: 0.0055585 (Best: 0.0002192 @iter15940) ([92m↓59.18%[0m) [2.21% of initial]
[Iter 16030/20000] Loss: 0.0026645 (Best: 0.0002192 @iter15940) ([92m↓52.06%[0m) [1.06% of initial]
[Iter 16040/20000] Loss: 0.0017834 (Best: 0.0002192 @iter15940) ([92m↓33.07%[0m) [0.71% of initial]
[Iter 16050/20000] Loss: 0.0011882 (Best: 0.0002192 @iter15940) ([92m↓33.37%[0m) [0.47% of initial]
[Iter 16060/20000] Loss: 0.0009063 (Best: 0.0002192 @iter15940) ([92m↓23.73%[0m) [0.36% of initial]
[Iter 16070/20000] Loss: 0.0007262 (Best: 0.0002192 @iter15940) ([92m↓19.87%[0m) [0.29% of initial]
[Iter 16080/20000] Loss: 0.0006201 (Best: 0.0002192 @iter15940) ([92m↓14.61%[0m) [0.25% of initial]
[Iter 16090/20000] Loss: 0.0005379 (Best: 0.0002192 @iter15940) ([92m↓13.26%[0m) [0.21% of initial]
Iter:16099, L1 loss=0.0004823, Total loss=0.0004697, Time:53
[Iter 16100/20000] Loss: 0.0004761 (Best: 0.0002192 @iter15940) ([92m↓11.47%[0m) [0.19% of initial]
[Iter 16110/20000] Loss: 0.0004471 (Best: 0.0002192 @iter15940) ([92m↓6.09%[0m) [0.18% of initial]
[Iter 16120/20000] Loss: 0.0004154 (Best: 0.0002192 @iter15940) ([92m↓7.11%[0m) [0.17% of initial]
[Iter 16130/20000] Loss: 0.0003953 (Best: 0.0002192 @iter15940) ([92m↓4.83%[0m) [0.16% of initial]
[Iter 16140/20000] Loss: 0.0003722 (Best: 0.0002192 @iter15940) ([92m↓5.85%[0m) [0.15% of initial]
[Iter 16150/20000] Loss: 0.0003563 (Best: 0.0002192 @iter15940) ([92m↓4.26%[0m) [0.14% of initial]
[Iter 16160/20000] Loss: 0.0003496 (Best: 0.0002192 @iter15940) ([92m↓1.88%[0m) [0.14% of initial]
[Iter 16170/20000] Loss: 0.0003521 (Best: 0.0002192 @iter15940) ([91m↑0.70%[0m) [0.14% of initial]
[Iter 16180/20000] Loss: 0.0003432 (Best: 0.0002192 @iter15940) ([92m↓2.52%[0m) [0.14% of initial]
[Iter 16190/20000] Loss: 0.0003365 (Best: 0.0002192 @iter15940) ([92m↓1.96%[0m) [0.13% of initial]
Iter:16199, L1 loss=0.0003719, Total loss=0.0003302, Time:53
[Iter 16200/20000] Loss: 0.0003372 (Best: 0.0002192 @iter15940) ([91m↑0.21%[0m) [0.13% of initial]
[Iter 16210/20000] Loss: 0.0003449 (Best: 0.0002192 @iter15940) ([91m↑2.30%[0m) [0.14% of initial]
[Iter 16220/20000] Loss: 0.0003341 (Best: 0.0002192 @iter15940) ([92m↓3.16%[0m) [0.13% of initial]
[Iter 16230/20000] Loss: 0.0003326 (Best: 0.0002192 @iter15940) ([92m↓0.44%[0m) [0.13% of initial]
[Iter 16240/20000] Loss: 0.0003663 (Best: 0.0002192 @iter15940) ([91m↑10.12%[0m) [0.15% of initial]
[Iter 16250/20000] Loss: 0.0003305 (Best: 0.0002192 @iter15940) ([92m↓9.76%[0m) [0.13% of initial]
[Iter 16260/20000] Loss: 0.0003121 (Best: 0.0002192 @iter15940) ([92m↓5.58%[0m) [0.12% of initial]
[Iter 16270/20000] Loss: 0.0002997 (Best: 0.0002192 @iter15940) ([92m↓3.96%[0m) [0.12% of initial]
[Iter 16280/20000] Loss: 0.0002945 (Best: 0.0002192 @iter15940) ([92m↓1.74%[0m) [0.12% of initial]
[Iter 16290/20000] Loss: 0.0003073 (Best: 0.0002192 @iter15940) ([91m↑4.34%[0m) [0.12% of initial]
Iter:16299, L1 loss=0.0003762, Total loss=0.0003362, Time:50
[Iter 16300/20000] Loss: 0.0003004 (Best: 0.0002192 @iter15940) ([92m↓2.24%[0m) [0.12% of initial]
[Iter 16310/20000] Loss: 0.0003317 (Best: 0.0002192 @iter15940) ([91m↑10.41%[0m) [0.13% of initial]
[Iter 16320/20000] Loss: 0.0003267 (Best: 0.0002192 @iter15940) ([92m↓1.49%[0m) [0.13% of initial]
[Iter 16330/20000] Loss: 0.0003223 (Best: 0.0002192 @iter15940) ([92m↓1.34%[0m) [0.13% of initial]
[Iter 16340/20000] Loss: 0.0003040 (Best: 0.0002192 @iter15940) ([92m↓5.70%[0m) [0.12% of initial]
[Iter 16350/20000] Loss: 0.0003148 (Best: 0.0002192 @iter15940) ([91m↑3.56%[0m) [0.13% of initial]
[Iter 16360/20000] Loss: 0.0003141 (Best: 0.0002192 @iter15940) ([92m↓0.21%[0m) [0.12% of initial]
[Iter 16370/20000] Loss: 0.0003417 (Best: 0.0002192 @iter15940) ([91m↑8.76%[0m) [0.14% of initial]
[Iter 16380/20000] Loss: 0.0003393 (Best: 0.0002192 @iter15940) ([92m↓0.70%[0m) [0.13% of initial]
[Iter 16390/20000] Loss: 0.0003420 (Best: 0.0002192 @iter15940) ([91m↑0.80%[0m) [0.14% of initial]
Iter:16399, L1 loss=0.0003218, Total loss=0.0002904, Time:53
[Iter 16400/20000] Loss: 0.0003144 (Best: 0.0002192 @iter15940) ([92m↓8.07%[0m) [0.12% of initial]
[Iter 16410/20000] Loss: 0.0003152 (Best: 0.0002192 @iter15940) ([91m↑0.25%[0m) [0.13% of initial]
[Iter 16420/20000] Loss: 0.0002954 (Best: 0.0002192 @iter15940) ([92m↓6.28%[0m) [0.12% of initial]
[Iter 16430/20000] Loss: 0.0002909 (Best: 0.0002192 @iter15940) ([92m↓1.52%[0m) [0.12% of initial]
[Iter 16440/20000] Loss: 0.0002974 (Best: 0.0002192 @iter15940) ([91m↑2.24%[0m) [0.12% of initial]
[Iter 16450/20000] Loss: 0.0002936 (Best: 0.0002192 @iter15940) ([92m↓1.28%[0m) [0.12% of initial]
[Iter 16460/20000] Loss: 0.0002871 (Best: 0.0002192 @iter15940) ([92m↓2.20%[0m) [0.11% of initial]
[Iter 16470/20000] Loss: 0.0003059 (Best: 0.0002192 @iter15940) ([91m↑6.53%[0m) [0.12% of initial]
[Iter 16480/20000] Loss: 0.0002946 (Best: 0.0002192 @iter15940) ([92m↓3.70%[0m) [0.12% of initial]
[Iter 16490/20000] Loss: 0.0002934 (Best: 0.0002192 @iter15940) ([92m↓0.40%[0m) [0.12% of initial]
Iter:16499, L1 loss=0.0003443, Total loss=0.0003288, Time:52
[Iter 16500/20000] Loss: 0.0003389 (Best: 0.0002192 @iter15940) ([91m↑15.50%[0m) [0.13% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 16500
Pruning 15 points (0.0%) from gaussian1 at iteration 16500
[Iter 16510/20000] Loss: 0.0005189 (Best: 0.0002192 @iter15940) ([91m↑53.13%[0m) [0.21% of initial]
[Iter 16520/20000] Loss: 0.0003996 (Best: 0.0002192 @iter15940) ([92m↓22.98%[0m) [0.16% of initial]
[Iter 16530/20000] Loss: 0.0003426 (Best: 0.0002192 @iter15940) ([92m↓14.28%[0m) [0.14% of initial]
[Iter 16540/20000] Loss: 0.0003296 (Best: 0.0002192 @iter15940) ([92m↓3.81%[0m) [0.13% of initial]
[Iter 16550/20000] Loss: 0.0003070 (Best: 0.0002192 @iter15940) ([92m↓6.84%[0m) [0.12% of initial]
[Iter 16560/20000] Loss: 0.0003061 (Best: 0.0002192 @iter15940) ([92m↓0.30%[0m) [0.12% of initial]
[Iter 16570/20000] Loss: 0.0002938 (Best: 0.0002192 @iter15940) ([92m↓4.01%[0m) [0.12% of initial]
[Iter 16580/20000] Loss: 0.0002966 (Best: 0.0002192 @iter15940) ([91m↑0.95%[0m) [0.12% of initial]
[Iter 16590/20000] Loss: 0.0003018 (Best: 0.0002192 @iter15940) ([91m↑1.76%[0m) [0.12% of initial]
Iter:16599, L1 loss=0.0003385, Total loss=0.0003006, Time:51
[Iter 16600/20000] Loss: 0.0002901 (Best: 0.0002192 @iter15940) ([92m↓3.89%[0m) [0.12% of initial]
[Iter 16610/20000] Loss: 0.0002883 (Best: 0.0002192 @iter15940) ([92m↓0.60%[0m) [0.11% of initial]
[Iter 16620/20000] Loss: 0.0002939 (Best: 0.0002192 @iter15940) ([91m↑1.94%[0m) [0.12% of initial]
[Iter 16630/20000] Loss: 0.0003080 (Best: 0.0002192 @iter15940) ([91m↑4.77%[0m) [0.12% of initial]
[Iter 16640/20000] Loss: 0.0003277 (Best: 0.0002192 @iter15940) ([91m↑6.43%[0m) [0.13% of initial]
[Iter 16650/20000] Loss: 0.0003709 (Best: 0.0002192 @iter15940) ([91m↑13.16%[0m) [0.15% of initial]
[Iter 16660/20000] Loss: 0.0003854 (Best: 0.0002192 @iter15940) ([91m↑3.91%[0m) [0.15% of initial]
[Iter 16670/20000] Loss: 0.0003529 (Best: 0.0002192 @iter15940) ([92m↓8.43%[0m) [0.14% of initial]
[Iter 16680/20000] Loss: 0.0003146 (Best: 0.0002192 @iter15940) ([92m↓10.84%[0m) [0.13% of initial]
[Iter 16690/20000] Loss: 0.0002947 (Best: 0.0002192 @iter15940) ([92m↓6.34%[0m) [0.12% of initial]
Iter:16699, L1 loss=0.0003531, Total loss=0.0003162, Time:56
[Iter 16700/20000] Loss: 0.0002979 (Best: 0.0002192 @iter15940) ([91m↑1.10%[0m) [0.12% of initial]
[Iter 16710/20000] Loss: 0.0002977 (Best: 0.0002192 @iter15940) ([92m↓0.08%[0m) [0.12% of initial]
[Iter 16720/20000] Loss: 0.0003107 (Best: 0.0002192 @iter15940) ([91m↑4.36%[0m) [0.12% of initial]
[Iter 16730/20000] Loss: 0.0002906 (Best: 0.0002192 @iter15940) ([92m↓6.45%[0m) [0.12% of initial]
[Iter 16740/20000] Loss: 0.0003009 (Best: 0.0002192 @iter15940) ([91m↑3.53%[0m) [0.12% of initial]
[Iter 16750/20000] Loss: 0.0002908 (Best: 0.0002192 @iter15940) ([92m↓3.37%[0m) [0.12% of initial]
[Iter 16760/20000] Loss: 0.0002855 (Best: 0.0002192 @iter15940) ([92m↓1.81%[0m) [0.11% of initial]
[Iter 16770/20000] Loss: 0.0002891 (Best: 0.0002192 @iter15940) ([91m↑1.27%[0m) [0.11% of initial]
[Iter 16780/20000] Loss: 0.0002899 (Best: 0.0002192 @iter15940) ([91m↑0.27%[0m) [0.12% of initial]
[Iter 16790/20000] Loss: 0.0003047 (Best: 0.0002192 @iter15940) ([91m↑5.10%[0m) [0.12% of initial]
Iter:16799, L1 loss=0.00036, Total loss=0.000319, Time:51
[Iter 16800/20000] Loss: 0.0003080 (Best: 0.0002192 @iter15940) ([91m↑1.08%[0m) [0.12% of initial]
[Iter 16810/20000] Loss: 0.0003548 (Best: 0.0002192 @iter15940) ([91m↑15.20%[0m) [0.14% of initial]
[Iter 16820/20000] Loss: 0.0003449 (Best: 0.0002192 @iter15940) ([92m↓2.77%[0m) [0.14% of initial]
[Iter 16830/20000] Loss: 0.0003311 (Best: 0.0002192 @iter15940) ([92m↓4.00%[0m) [0.13% of initial]
[Iter 16840/20000] Loss: 0.0004153 (Best: 0.0002192 @iter15940) ([91m↑25.41%[0m) [0.16% of initial]
[Iter 16850/20000] Loss: 0.0003446 (Best: 0.0002192 @iter15940) ([92m↓17.01%[0m) [0.14% of initial]
[Iter 16860/20000] Loss: 0.0003141 (Best: 0.0002192 @iter15940) ([92m↓8.86%[0m) [0.12% of initial]
[Iter 16870/20000] Loss: 0.0002909 (Best: 0.0002192 @iter15940) ([92m↓7.37%[0m) [0.12% of initial]
[Iter 16880/20000] Loss: 0.0002872 (Best: 0.0002192 @iter15940) ([92m↓1.29%[0m) [0.11% of initial]
[Iter 16890/20000] Loss: 0.0003117 (Best: 0.0002192 @iter15940) ([91m↑8.55%[0m) [0.12% of initial]
Iter:16899, L1 loss=0.0003761, Total loss=0.0003544, Time:51
[Iter 16900/20000] Loss: 0.0003082 (Best: 0.0002192 @iter15940) ([92m↓1.15%[0m) [0.12% of initial]
[Iter 16910/20000] Loss: 0.0002988 (Best: 0.0002192 @iter15940) ([92m↓3.03%[0m) [0.12% of initial]
[Iter 16920/20000] Loss: 0.0003534 (Best: 0.0002192 @iter15940) ([91m↑18.26%[0m) [0.14% of initial]
[Iter 16930/20000] Loss: 0.0003257 (Best: 0.0002192 @iter15940) ([92m↓7.86%[0m) [0.13% of initial]
[Iter 16940/20000] Loss: 0.0003390 (Best: 0.0002192 @iter15940) ([91m↑4.09%[0m) [0.13% of initial]
[Iter 16950/20000] Loss: 0.0003340 (Best: 0.0002192 @iter15940) ([92m↓1.46%[0m) [0.13% of initial]
[Iter 16960/20000] Loss: 0.0003310 (Best: 0.0002192 @iter15940) ([92m↓0.92%[0m) [0.13% of initial]
[Iter 16970/20000] Loss: 0.0003187 (Best: 0.0002192 @iter15940) ([92m↓3.70%[0m) [0.13% of initial]
[Iter 16980/20000] Loss: 0.0003009 (Best: 0.0002192 @iter15940) ([92m↓5.58%[0m) [0.12% of initial]
[Iter 16990/20000] Loss: 0.0003150 (Best: 0.0002192 @iter15940) ([91m↑4.69%[0m) [0.13% of initial]
Iter:16999, L1 loss=0.0003372, Total loss=0.0003015, Time:53
[Iter 17000/20000] Loss: 0.0002999 (Best: 0.0002192 @iter15940) ([92m↓4.82%[0m) [0.12% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 17000
Pruning 8 points (0.0%) from gaussian1 at iteration 17000
[Iter 17010/20000] Loss: 0.0005706 (Best: 0.0002192 @iter15940) ([91m↑90.27%[0m) [0.23% of initial]
[Iter 17020/20000] Loss: 0.0003960 (Best: 0.0002192 @iter15940) ([92m↓30.59%[0m) [0.16% of initial]
[Iter 17030/20000] Loss: 0.0003288 (Best: 0.0002192 @iter15940) ([92m↓16.99%[0m) [0.13% of initial]
[Iter 17040/20000] Loss: 0.0002976 (Best: 0.0002192 @iter15940) ([92m↓9.46%[0m) [0.12% of initial]
[Iter 17050/20000] Loss: 0.0003022 (Best: 0.0002192 @iter15940) ([91m↑1.53%[0m) [0.12% of initial]
[Iter 17060/20000] Loss: 0.0003350 (Best: 0.0002192 @iter15940) ([91m↑10.85%[0m) [0.13% of initial]
[Iter 17070/20000] Loss: 0.0003436 (Best: 0.0002192 @iter15940) ([91m↑2.57%[0m) [0.14% of initial]
[Iter 17080/20000] Loss: 0.0003037 (Best: 0.0002192 @iter15940) ([92m↓11.62%[0m) [0.12% of initial]
[Iter 17090/20000] Loss: 0.0002789 (Best: 0.0002192 @iter15940) ([92m↓8.16%[0m) [0.11% of initial]
Iter:17099, L1 loss=0.0002922, Total loss=0.0002502, Time:52
[Iter 17100/20000] Loss: 0.0002648 (Best: 0.0002192 @iter15940) ([92m↓5.05%[0m) [0.11% of initial]
[Iter 17110/20000] Loss: 0.0002722 (Best: 0.0002192 @iter15940) ([91m↑2.80%[0m) [0.11% of initial]
[Iter 17120/20000] Loss: 0.0002649 (Best: 0.0002192 @iter15940) ([92m↓2.70%[0m) [0.11% of initial]
[Iter 17130/20000] Loss: 0.0002710 (Best: 0.0002192 @iter15940) ([91m↑2.32%[0m) [0.11% of initial]
[Iter 17140/20000] Loss: 0.0002909 (Best: 0.0002192 @iter15940) ([91m↑7.32%[0m) [0.12% of initial]
[Iter 17150/20000] Loss: 0.0002807 (Best: 0.0002192 @iter15940) ([92m↓3.52%[0m) [0.11% of initial]
[Iter 17160/20000] Loss: 0.0002938 (Best: 0.0002192 @iter15940) ([91m↑4.67%[0m) [0.12% of initial]
[Iter 17170/20000] Loss: 0.0003054 (Best: 0.0002192 @iter15940) ([91m↑3.96%[0m) [0.12% of initial]
[Iter 17180/20000] Loss: 0.0002814 (Best: 0.0002192 @iter15940) ([92m↓7.86%[0m) [0.11% of initial]
[Iter 17190/20000] Loss: 0.0002872 (Best: 0.0002192 @iter15940) ([91m↑2.07%[0m) [0.11% of initial]
Iter:17199, L1 loss=0.0003165, Total loss=0.0002691, Time:53
[Iter 17200/20000] Loss: 0.0002750 (Best: 0.0002192 @iter15940) ([92m↓4.26%[0m) [0.11% of initial]
[Iter 17210/20000] Loss: 0.0002757 (Best: 0.0002192 @iter15940) ([91m↑0.28%[0m) [0.11% of initial]
[Iter 17220/20000] Loss: 0.0002695 (Best: 0.0002192 @iter15940) ([92m↓2.27%[0m) [0.11% of initial]
[Iter 17230/20000] Loss: 0.0002687 (Best: 0.0002192 @iter15940) ([92m↓0.28%[0m) [0.11% of initial]
[Iter 17240/20000] Loss: 0.0003019 (Best: 0.0002192 @iter15940) ([91m↑12.34%[0m) [0.12% of initial]
[Iter 17250/20000] Loss: 0.0003295 (Best: 0.0002192 @iter15940) ([91m↑9.16%[0m) [0.13% of initial]
[Iter 17260/20000] Loss: 0.0002950 (Best: 0.0002192 @iter15940) ([92m↓10.49%[0m) [0.12% of initial]
[Iter 17270/20000] Loss: 0.0003095 (Best: 0.0002192 @iter15940) ([91m↑4.91%[0m) [0.12% of initial]
[Iter 17280/20000] Loss: 0.0003086 (Best: 0.0002192 @iter15940) ([92m↓0.27%[0m) [0.12% of initial]
[Iter 17290/20000] Loss: 0.0004109 (Best: 0.0002192 @iter15940) ([91m↑33.14%[0m) [0.16% of initial]
Iter:17299, L1 loss=0.0003396, Total loss=0.00031, Time:50
[Iter 17300/20000] Loss: 0.0003195 (Best: 0.0002192 @iter15940) ([92m↓22.24%[0m) [0.13% of initial]
[Iter 17310/20000] Loss: 0.0003030 (Best: 0.0002192 @iter15940) ([92m↓5.16%[0m) [0.12% of initial]
[Iter 17320/20000] Loss: 0.0003200 (Best: 0.0002192 @iter15940) ([91m↑5.59%[0m) [0.13% of initial]
[Iter 17330/20000] Loss: 0.0002831 (Best: 0.0002192 @iter15940) ([92m↓11.53%[0m) [0.11% of initial]
[Iter 17340/20000] Loss: 0.0002752 (Best: 0.0002192 @iter15940) ([92m↓2.78%[0m) [0.11% of initial]
[Iter 17350/20000] Loss: 0.0003017 (Best: 0.0002192 @iter15940) ([91m↑9.61%[0m) [0.12% of initial]
[Iter 17360/20000] Loss: 0.0003284 (Best: 0.0002192 @iter15940) ([91m↑8.86%[0m) [0.13% of initial]
[Iter 17370/20000] Loss: 0.0003022 (Best: 0.0002192 @iter15940) ([92m↓7.97%[0m) [0.12% of initial]
[Iter 17380/20000] Loss: 0.0003505 (Best: 0.0002192 @iter15940) ([91m↑16.00%[0m) [0.14% of initial]
[Iter 17390/20000] Loss: 0.0003289 (Best: 0.0002192 @iter15940) ([92m↓6.16%[0m) [0.13% of initial]
Iter:17399, L1 loss=0.0003124, Total loss=0.0002783, Time:53
[Iter 17400/20000] Loss: 0.0002976 (Best: 0.0002192 @iter15940) ([92m↓9.52%[0m) [0.12% of initial]
[Iter 17410/20000] Loss: 0.0002938 (Best: 0.0002192 @iter15940) ([92m↓1.28%[0m) [0.12% of initial]
[Iter 17420/20000] Loss: 0.0003031 (Best: 0.0002192 @iter15940) ([91m↑3.16%[0m) [0.12% of initial]
[Iter 17430/20000] Loss: 0.0002995 (Best: 0.0002192 @iter15940) ([92m↓1.19%[0m) [0.12% of initial]
[Iter 17440/20000] Loss: 0.0002806 (Best: 0.0002192 @iter15940) ([92m↓6.30%[0m) [0.11% of initial]
[Iter 17450/20000] Loss: 0.0002936 (Best: 0.0002192 @iter15940) ([91m↑4.61%[0m) [0.12% of initial]
[Iter 17460/20000] Loss: 0.0003076 (Best: 0.0002192 @iter15940) ([91m↑4.80%[0m) [0.12% of initial]
[Iter 17470/20000] Loss: 0.0002839 (Best: 0.0002192 @iter15940) ([92m↓7.70%[0m) [0.11% of initial]
[Iter 17480/20000] Loss: 0.0002809 (Best: 0.0002192 @iter15940) ([92m↓1.06%[0m) [0.11% of initial]
[Iter 17490/20000] Loss: 0.0002891 (Best: 0.0002192 @iter15940) ([91m↑2.91%[0m) [0.11% of initial]
Iter:17499, L1 loss=0.0003371, Total loss=0.000278, Time:41
[Iter 17500/20000] Loss: 0.0002688 (Best: 0.0002192 @iter15940) ([92m↓7.01%[0m) [0.11% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 17500
Pruning 5 points (0.0%) from gaussian1 at iteration 17500
[Iter 17510/20000] Loss: 0.0005654 (Best: 0.0002192 @iter15940) ([91m↑110.31%[0m) [0.22% of initial]
[Iter 17520/20000] Loss: 0.0004005 (Best: 0.0002192 @iter15940) ([92m↓29.16%[0m) [0.16% of initial]
[Iter 17530/20000] Loss: 0.0003137 (Best: 0.0002192 @iter15940) ([92m↓21.68%[0m) [0.12% of initial]
[Iter 17540/20000] Loss: 0.0002897 (Best: 0.0002192 @iter15940) ([92m↓7.65%[0m) [0.12% of initial]
[Iter 17550/20000] Loss: 0.0002684 (Best: 0.0002192 @iter15940) ([92m↓7.34%[0m) [0.11% of initial]
[Iter 17560/20000] Loss: 0.0002609 (Best: 0.0002192 @iter15940) ([92m↓2.82%[0m) [0.10% of initial]
[Iter 17570/20000] Loss: 0.0002791 (Best: 0.0002192 @iter15940) ([91m↑7.00%[0m) [0.11% of initial]
[Iter 17580/20000] Loss: 0.0002740 (Best: 0.0002192 @iter15940) ([92m↓1.84%[0m) [0.11% of initial]
[Iter 17590/20000] Loss: 0.0002702 (Best: 0.0002192 @iter15940) ([92m↓1.37%[0m) [0.11% of initial]
Iter:17599, L1 loss=0.0002931, Total loss=0.0002638, Time:50
[Iter 17600/20000] Loss: 0.0002924 (Best: 0.0002192 @iter15940) ([91m↑8.20%[0m) [0.12% of initial]
[Iter 17610/20000] Loss: 0.0002929 (Best: 0.0002192 @iter15940) ([91m↑0.17%[0m) [0.12% of initial]
[Iter 17620/20000] Loss: 0.0002901 (Best: 0.0002192 @iter15940) ([92m↓0.93%[0m) [0.12% of initial]
[Iter 17630/20000] Loss: 0.0002755 (Best: 0.0002192 @iter15940) ([92m↓5.04%[0m) [0.11% of initial]
[Iter 17640/20000] Loss: 0.0002767 (Best: 0.0002192 @iter15940) ([91m↑0.44%[0m) [0.11% of initial]
[Iter 17650/20000] Loss: 0.0002916 (Best: 0.0002192 @iter15940) ([91m↑5.38%[0m) [0.12% of initial]
[Iter 17660/20000] Loss: 0.0002799 (Best: 0.0002192 @iter15940) ([92m↓4.01%[0m) [0.11% of initial]
[Iter 17670/20000] Loss: 0.0002873 (Best: 0.0002192 @iter15940) ([91m↑2.64%[0m) [0.11% of initial]
[Iter 17680/20000] Loss: 0.0002904 (Best: 0.0002192 @iter15940) ([91m↑1.10%[0m) [0.12% of initial]
[Iter 17690/20000] Loss: 0.0002874 (Best: 0.0002192 @iter15940) ([92m↓1.04%[0m) [0.11% of initial]
Iter:17699, L1 loss=0.0003041, Total loss=0.0002589, Time:49
[Iter 17700/20000] Loss: 0.0002787 (Best: 0.0002192 @iter15940) ([92m↓3.02%[0m) [0.11% of initial]
[Iter 17710/20000] Loss: 0.0002627 (Best: 0.0002192 @iter15940) ([92m↓5.75%[0m) [0.10% of initial]
[Iter 17720/20000] Loss: 0.0002986 (Best: 0.0002192 @iter15940) ([91m↑13.68%[0m) [0.12% of initial]
[Iter 17730/20000] Loss: 0.0002928 (Best: 0.0002192 @iter15940) ([92m↓1.95%[0m) [0.12% of initial]
[Iter 17740/20000] Loss: 0.0002772 (Best: 0.0002192 @iter15940) ([92m↓5.32%[0m) [0.11% of initial]
[Iter 17750/20000] Loss: 0.0002757 (Best: 0.0002192 @iter15940) ([92m↓0.56%[0m) [0.11% of initial]
[Iter 17760/20000] Loss: 0.0002633 (Best: 0.0002192 @iter15940) ([92m↓4.49%[0m) [0.10% of initial]
[Iter 17770/20000] Loss: 0.0002579 (Best: 0.0002192 @iter15940) ([92m↓2.06%[0m) [0.10% of initial]
[Iter 17780/20000] Loss: 0.0002634 (Best: 0.0002192 @iter15940) ([91m↑2.15%[0m) [0.10% of initial]
[Iter 17790/20000] Loss: 0.0003128 (Best: 0.0002192 @iter15940) ([91m↑18.76%[0m) [0.12% of initial]
Iter:17799, L1 loss=0.0004134, Total loss=0.0003697, Time:56
[Iter 17800/20000] Loss: 0.0003255 (Best: 0.0002192 @iter15940) ([91m↑4.06%[0m) [0.13% of initial]
[Iter 17810/20000] Loss: 0.0003184 (Best: 0.0002192 @iter15940) ([92m↓2.19%[0m) [0.13% of initial]
[Iter 17820/20000] Loss: 0.0003035 (Best: 0.0002192 @iter15940) ([92m↓4.67%[0m) [0.12% of initial]
[Iter 17830/20000] Loss: 0.0002745 (Best: 0.0002192 @iter15940) ([92m↓9.58%[0m) [0.11% of initial]
[Iter 17840/20000] Loss: 0.0002583 (Best: 0.0002192 @iter15940) ([92m↓5.90%[0m) [0.10% of initial]
[Iter 17850/20000] Loss: 0.0002555 (Best: 0.0002192 @iter15940) ([92m↓1.07%[0m) [0.10% of initial]
[Iter 17860/20000] Loss: 0.0002536 (Best: 0.0002192 @iter15940) ([92m↓0.74%[0m) [0.10% of initial]
[Iter 17870/20000] Loss: 0.0002659 (Best: 0.0002192 @iter15940) ([91m↑4.85%[0m) [0.11% of initial]
[Iter 17880/20000] Loss: 0.0002881 (Best: 0.0002192 @iter15940) ([91m↑8.36%[0m) [0.11% of initial]
[Iter 17890/20000] Loss: 0.0002561 (Best: 0.0002192 @iter15940) ([92m↓11.11%[0m) [0.10% of initial]
Iter:17899, L1 loss=0.0003068, Total loss=0.0002462, Time:52
[Iter 17900/20000] Loss: 0.0002586 (Best: 0.0002192 @iter15940) ([91m↑0.97%[0m) [0.10% of initial]
[Iter 17910/20000] Loss: 0.0002595 (Best: 0.0002192 @iter15940) ([91m↑0.35%[0m) [0.10% of initial]
[Iter 17920/20000] Loss: 0.0002710 (Best: 0.0002192 @iter15940) ([91m↑4.43%[0m) [0.11% of initial]
[Iter 17930/20000] Loss: 0.0002567 (Best: 0.0002192 @iter15940) ([92m↓5.27%[0m) [0.10% of initial]
[Iter 17940/20000] Loss: 0.0002584 (Best: 0.0002192 @iter15940) ([91m↑0.64%[0m) [0.10% of initial]
[Iter 17950/20000] Loss: 0.0002562 (Best: 0.0002192 @iter15940) ([92m↓0.85%[0m) [0.10% of initial]
[Iter 17960/20000] Loss: 0.0002655 (Best: 0.0002192 @iter15940) ([91m↑3.65%[0m) [0.11% of initial]
[Iter 17970/20000] Loss: 0.0002654 (Best: 0.0002192 @iter15940) ([92m↓0.06%[0m) [0.11% of initial]
[Iter 17980/20000] Loss: 0.0002868 (Best: 0.0002192 @iter15940) ([91m↑8.06%[0m) [0.11% of initial]
[Iter 17990/20000] Loss: 0.0002591 (Best: 0.0002192 @iter15940) ([92m↓9.64%[0m) [0.10% of initial]
Iter:17999, L1 loss=0.0003089, Total loss=0.0002661, Time:53
[Iter 18000/20000] Loss: 0.0002574 (Best: 0.0002192 @iter15940) ([92m↓0.66%[0m) [0.10% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 18000
Pruning 1 points (0.0%) from gaussian1 at iteration 18000
[Iter 18010/20000] Loss: 0.0006537 (Best: 0.0002192 @iter15940) ([91m↑153.95%[0m) [0.26% of initial]
[Iter 18020/20000] Loss: 0.0004073 (Best: 0.0002192 @iter15940) ([92m↓37.70%[0m) [0.16% of initial]
[Iter 18030/20000] Loss: 0.0003437 (Best: 0.0002192 @iter15940) ([92m↓15.62%[0m) [0.14% of initial]
[Iter 18040/20000] Loss: 0.0002847 (Best: 0.0002192 @iter15940) ([92m↓17.17%[0m) [0.11% of initial]
[Iter 18050/20000] Loss: 0.0002651 (Best: 0.0002192 @iter15940) ([92m↓6.89%[0m) [0.11% of initial]
[Iter 18060/20000] Loss: 0.0002709 (Best: 0.0002192 @iter15940) ([91m↑2.18%[0m) [0.11% of initial]
[Iter 18070/20000] Loss: 0.0002642 (Best: 0.0002192 @iter15940) ([92m↓2.47%[0m) [0.10% of initial]
[Iter 18080/20000] Loss: 0.0002655 (Best: 0.0002192 @iter15940) ([91m↑0.52%[0m) [0.11% of initial]
[Iter 18090/20000] Loss: 0.0002862 (Best: 0.0002192 @iter15940) ([91m↑7.79%[0m) [0.11% of initial]
Iter:18099, L1 loss=0.0003421, Total loss=0.0003086, Time:51
[Iter 18100/20000] Loss: 0.0002751 (Best: 0.0002192 @iter15940) ([92m↓3.87%[0m) [0.11% of initial]
[Iter 18110/20000] Loss: 0.0002636 (Best: 0.0002192 @iter15940) ([92m↓4.21%[0m) [0.10% of initial]
[Iter 18120/20000] Loss: 0.0002599 (Best: 0.0002192 @iter15940) ([92m↓1.39%[0m) [0.10% of initial]
[Iter 18130/20000] Loss: 0.0002517 (Best: 0.0002192 @iter15940) ([92m↓3.17%[0m) [0.10% of initial]
[Iter 18140/20000] Loss: 0.0002598 (Best: 0.0002192 @iter15940) ([91m↑3.24%[0m) [0.10% of initial]
[Iter 18150/20000] Loss: 0.0002601 (Best: 0.0002192 @iter15940) ([91m↑0.12%[0m) [0.10% of initial]
[Iter 18160/20000] Loss: 0.0002513 (Best: 0.0002192 @iter15940) ([92m↓3.40%[0m) [0.10% of initial]
[Iter 18170/20000] Loss: 0.0002610 (Best: 0.0002192 @iter15940) ([91m↑3.86%[0m) [0.10% of initial]
[Iter 18180/20000] Loss: 0.0003114 (Best: 0.0002192 @iter15940) ([91m↑19.30%[0m) [0.12% of initial]
[Iter 18190/20000] Loss: 0.0003383 (Best: 0.0002192 @iter15940) ([91m↑8.65%[0m) [0.13% of initial]
Iter:18199, L1 loss=0.0003249, Total loss=0.0003006, Time:50
[Iter 18200/20000] Loss: 0.0003314 (Best: 0.0002192 @iter15940) ([92m↓2.02%[0m) [0.13% of initial]
[Iter 18210/20000] Loss: 0.0002894 (Best: 0.0002192 @iter15940) ([92m↓12.68%[0m) [0.11% of initial]
[Iter 18220/20000] Loss: 0.0002635 (Best: 0.0002192 @iter15940) ([92m↓8.94%[0m) [0.10% of initial]
[Iter 18230/20000] Loss: 0.0002992 (Best: 0.0002192 @iter15940) ([91m↑13.54%[0m) [0.12% of initial]
[Iter 18240/20000] Loss: 0.0002813 (Best: 0.0002192 @iter15940) ([92m↓5.97%[0m) [0.11% of initial]
[Iter 18250/20000] Loss: 0.0002775 (Best: 0.0002192 @iter15940) ([92m↓1.35%[0m) [0.11% of initial]
[Iter 18260/20000] Loss: 0.0002692 (Best: 0.0002192 @iter15940) ([92m↓3.01%[0m) [0.11% of initial]
[Iter 18270/20000] Loss: 0.0002742 (Best: 0.0002192 @iter15940) ([91m↑1.86%[0m) [0.11% of initial]
[Iter 18280/20000] Loss: 0.0002677 (Best: 0.0002192 @iter15940) ([92m↓2.38%[0m) [0.11% of initial]
[Iter 18290/20000] Loss: 0.0002975 (Best: 0.0002192 @iter15940) ([91m↑11.15%[0m) [0.12% of initial]
Iter:18299, L1 loss=0.0003791, Total loss=0.0003204, Time:54
[Iter 18300/20000] Loss: 0.0003028 (Best: 0.0002192 @iter15940) ([91m↑1.78%[0m) [0.12% of initial]
[Iter 18310/20000] Loss: 0.0002944 (Best: 0.0002192 @iter15940) ([92m↓2.78%[0m) [0.12% of initial]
[Iter 18320/20000] Loss: 0.0003140 (Best: 0.0002192 @iter15940) ([91m↑6.68%[0m) [0.12% of initial]
[Iter 18330/20000] Loss: 0.0003623 (Best: 0.0002192 @iter15940) ([91m↑15.36%[0m) [0.14% of initial]
[Iter 18340/20000] Loss: 0.0003532 (Best: 0.0002192 @iter15940) ([92m↓2.51%[0m) [0.14% of initial]
[Iter 18350/20000] Loss: 0.0003334 (Best: 0.0002192 @iter15940) ([92m↓5.59%[0m) [0.13% of initial]
[Iter 18360/20000] Loss: 0.0003912 (Best: 0.0002192 @iter15940) ([91m↑17.34%[0m) [0.16% of initial]
[Iter 18370/20000] Loss: 0.0003105 (Best: 0.0002192 @iter15940) ([92m↓20.63%[0m) [0.12% of initial]
[Iter 18380/20000] Loss: 0.0002755 (Best: 0.0002192 @iter15940) ([92m↓11.26%[0m) [0.11% of initial]
[Iter 18390/20000] Loss: 0.0002823 (Best: 0.0002192 @iter15940) ([91m↑2.46%[0m) [0.11% of initial]
Iter:18399, L1 loss=0.0002764, Total loss=0.0002522, Time:51
[Iter 18400/20000] Loss: 0.0002490 (Best: 0.0002192 @iter15940) ([92m↓11.80%[0m) [0.10% of initial]
[Iter 18410/20000] Loss: 0.0002592 (Best: 0.0002192 @iter15940) ([91m↑4.11%[0m) [0.10% of initial]
[Iter 18420/20000] Loss: 0.0002450 (Best: 0.0002192 @iter15940) ([92m↓5.49%[0m) [0.10% of initial]
[Iter 18430/20000] Loss: 0.0002412 (Best: 0.0002192 @iter15940) ([92m↓1.55%[0m) [0.10% of initial]
[Iter 18440/20000] Loss: 0.0002446 (Best: 0.0002192 @iter15940) ([91m↑1.39%[0m) [0.10% of initial]
[Iter 18450/20000] Loss: 0.0002500 (Best: 0.0002192 @iter15940) ([91m↑2.22%[0m) [0.10% of initial]
[Iter 18460/20000] Loss: 0.0002599 (Best: 0.0002192 @iter15940) ([91m↑3.98%[0m) [0.10% of initial]
[Iter 18470/20000] Loss: 0.0002642 (Best: 0.0002192 @iter15940) ([91m↑1.62%[0m) [0.10% of initial]
[Iter 18480/20000] Loss: 0.0002508 (Best: 0.0002192 @iter15940) ([92m↓5.07%[0m) [0.10% of initial]
[Iter 18490/20000] Loss: 0.0002625 (Best: 0.0002192 @iter15940) ([91m↑4.69%[0m) [0.10% of initial]
Iter:18499, L1 loss=0.0003, Total loss=0.0002728, Time:52
[Iter 18500/20000] Loss: 0.0002628 (Best: 0.0002192 @iter15940) ([91m↑0.10%[0m) [0.10% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 18500
Pruning 3 points (0.0%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0004883 (Best: 0.0002192 @iter15940) ([91m↑85.82%[0m) [0.19% of initial]
[Iter 18520/20000] Loss: 0.0003317 (Best: 0.0002192 @iter15940) ([92m↓32.06%[0m) [0.13% of initial]
[Iter 18530/20000] Loss: 0.0002844 (Best: 0.0002192 @iter15940) ([92m↓14.26%[0m) [0.11% of initial]
[Iter 18540/20000] Loss: 0.0002985 (Best: 0.0002192 @iter15940) ([91m↑4.95%[0m) [0.12% of initial]
[Iter 18550/20000] Loss: 0.0002814 (Best: 0.0002192 @iter15940) ([92m↓5.74%[0m) [0.11% of initial]
[Iter 18560/20000] Loss: 0.0002852 (Best: 0.0002192 @iter15940) ([91m↑1.35%[0m) [0.11% of initial]
[Iter 18570/20000] Loss: 0.0002890 (Best: 0.0002192 @iter15940) ([91m↑1.33%[0m) [0.11% of initial]
[Iter 18580/20000] Loss: 0.0002662 (Best: 0.0002192 @iter15940) ([92m↓7.88%[0m) [0.11% of initial]
[Iter 18590/20000] Loss: 0.0002744 (Best: 0.0002192 @iter15940) ([91m↑3.09%[0m) [0.11% of initial]
Iter:18599, L1 loss=0.0003414, Total loss=0.0003022, Time:51
[Iter 18600/20000] Loss: 0.0003059 (Best: 0.0002192 @iter15940) ([91m↑11.47%[0m) [0.12% of initial]
[Iter 18610/20000] Loss: 0.0002761 (Best: 0.0002192 @iter15940) ([92m↓9.75%[0m) [0.11% of initial]
[Iter 18620/20000] Loss: 0.0002603 (Best: 0.0002192 @iter15940) ([92m↓5.71%[0m) [0.10% of initial]
[Iter 18630/20000] Loss: 0.0003000 (Best: 0.0002192 @iter15940) ([91m↑15.25%[0m) [0.12% of initial]
[Iter 18640/20000] Loss: 0.0002779 (Best: 0.0002192 @iter15940) ([92m↓7.35%[0m) [0.11% of initial]
[Iter 18650/20000] Loss: 0.0002527 (Best: 0.0002192 @iter15940) ([92m↓9.09%[0m) [0.10% of initial]
[Iter 18660/20000] Loss: 0.0002533 (Best: 0.0002192 @iter15940) ([91m↑0.27%[0m) [0.10% of initial]
[Iter 18670/20000] Loss: 0.0002451 (Best: 0.0002192 @iter15940) ([92m↓3.27%[0m) [0.10% of initial]
[Iter 18680/20000] Loss: 0.0002441 (Best: 0.0002192 @iter15940) ([92m↓0.41%[0m) [0.10% of initial]
[Iter 18690/20000] Loss: 0.0002487 (Best: 0.0002192 @iter15940) ([91m↑1.90%[0m) [0.10% of initial]
Iter:18699, L1 loss=0.000271, Total loss=0.0002425, Time:51
[Iter 18700/20000] Loss: 0.0002362 (Best: 0.0002192 @iter15940) ([92m↓5.02%[0m) [0.09% of initial]
[Iter 18710/20000] Loss: 0.0002483 (Best: 0.0002192 @iter15940) ([91m↑5.13%[0m) [0.10% of initial]
[Iter 18720/20000] Loss: 0.0002396 (Best: 0.0002192 @iter15940) ([92m↓3.53%[0m) [0.10% of initial]
[Iter 18730/20000] Loss: 0.0002495 (Best: 0.0002192 @iter15940) ([91m↑4.16%[0m) [0.10% of initial]
[Iter 18740/20000] Loss: 0.0002514 (Best: 0.0002192 @iter15940) ([91m↑0.75%[0m) [0.10% of initial]
[Iter 18750/20000] Loss: 0.0002427 (Best: 0.0002192 @iter15940) ([92m↓3.48%[0m) [0.10% of initial]
[Iter 18760/20000] Loss: 0.0002473 (Best: 0.0002192 @iter15940) ([91m↑1.92%[0m) [0.10% of initial]
[Iter 18770/20000] Loss: 0.0002586 (Best: 0.0002192 @iter15940) ([91m↑4.56%[0m) [0.10% of initial]
[Iter 18780/20000] Loss: 0.0002616 (Best: 0.0002192 @iter15940) ([91m↑1.17%[0m) [0.10% of initial]
[Iter 18790/20000] Loss: 0.0002655 (Best: 0.0002192 @iter15940) ([91m↑1.50%[0m) [0.11% of initial]
Iter:18799, L1 loss=0.0002686, Total loss=0.0002366, Time:54
[Iter 18800/20000] Loss: 0.0002545 (Best: 0.0002192 @iter15940) ([92m↓4.17%[0m) [0.10% of initial]
[Iter 18810/20000] Loss: 0.0002703 (Best: 0.0002192 @iter15940) ([91m↑6.23%[0m) [0.11% of initial]
[Iter 18820/20000] Loss: 0.0002716 (Best: 0.0002192 @iter15940) ([91m↑0.47%[0m) [0.11% of initial]
[Iter 18830/20000] Loss: 0.0002781 (Best: 0.0002192 @iter15940) ([91m↑2.41%[0m) [0.11% of initial]
[Iter 18840/20000] Loss: 0.0002640 (Best: 0.0002192 @iter15940) ([92m↓5.09%[0m) [0.10% of initial]
[Iter 18850/20000] Loss: 0.0002583 (Best: 0.0002192 @iter15940) ([92m↓2.16%[0m) [0.10% of initial]
[Iter 18860/20000] Loss: 0.0003029 (Best: 0.0002192 @iter15940) ([91m↑17.29%[0m) [0.12% of initial]
[Iter 18870/20000] Loss: 0.0002660 (Best: 0.0002192 @iter15940) ([92m↓12.21%[0m) [0.11% of initial]
[Iter 18880/20000] Loss: 0.0002580 (Best: 0.0002192 @iter15940) ([92m↓3.00%[0m) [0.10% of initial]
[Iter 18890/20000] Loss: 0.0002622 (Best: 0.0002192 @iter15940) ([91m↑1.63%[0m) [0.10% of initial]
Iter:18899, L1 loss=0.0002974, Total loss=0.0002582, Time:54
[Iter 18900/20000] Loss: 0.0002633 (Best: 0.0002192 @iter15940) ([91m↑0.43%[0m) [0.10% of initial]
[Iter 18910/20000] Loss: 0.0002681 (Best: 0.0002192 @iter15940) ([91m↑1.83%[0m) [0.11% of initial]
[Iter 18920/20000] Loss: 0.0002453 (Best: 0.0002192 @iter15940) ([92m↓8.54%[0m) [0.10% of initial]
[Iter 18930/20000] Loss: 0.0002970 (Best: 0.0002192 @iter15940) ([91m↑21.10%[0m) [0.12% of initial]
[Iter 18940/20000] Loss: 0.0002638 (Best: 0.0002192 @iter15940) ([92m↓11.19%[0m) [0.10% of initial]
[Iter 18950/20000] Loss: 0.0002759 (Best: 0.0002192 @iter15940) ([91m↑4.60%[0m) [0.11% of initial]
[Iter 18960/20000] Loss: 0.0002711 (Best: 0.0002192 @iter15940) ([92m↓1.74%[0m) [0.11% of initial]
[Iter 18970/20000] Loss: 0.0002758 (Best: 0.0002192 @iter15940) ([91m↑1.73%[0m) [0.11% of initial]
[Iter 18980/20000] Loss: 0.0002496 (Best: 0.0002192 @iter15940) ([92m↓9.48%[0m) [0.10% of initial]
[Iter 18990/20000] Loss: 0.0002499 (Best: 0.0002192 @iter15940) ([91m↑0.10%[0m) [0.10% of initial]
Iter:18999, L1 loss=0.0002809, Total loss=0.0002458, Time:52
[Iter 19000/20000] Loss: 0.0002410 (Best: 0.0002192 @iter15940) ([92m↓3.55%[0m) [0.10% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 19000
Pruning 3 points (0.0%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0005909 (Best: 0.0002192 @iter15940) ([91m↑145.15%[0m) [0.23% of initial]
[Iter 19020/20000] Loss: 0.0004237 (Best: 0.0002192 @iter15940) ([92m↓28.28%[0m) [0.17% of initial]
[Iter 19030/20000] Loss: 0.0003280 (Best: 0.0002192 @iter15940) ([92m↓22.60%[0m) [0.13% of initial]
[Iter 19040/20000] Loss: 0.0002741 (Best: 0.0002192 @iter15940) ([92m↓16.43%[0m) [0.11% of initial]
[Iter 19050/20000] Loss: 0.0002604 (Best: 0.0002192 @iter15940) ([92m↓5.02%[0m) [0.10% of initial]
[Iter 19060/20000] Loss: 0.0002479 (Best: 0.0002192 @iter15940) ([92m↓4.81%[0m) [0.10% of initial]
[Iter 19070/20000] Loss: 0.0002700 (Best: 0.0002192 @iter15940) ([91m↑8.93%[0m) [0.11% of initial]
[Iter 19080/20000] Loss: 0.0002457 (Best: 0.0002192 @iter15940) ([92m↓9.01%[0m) [0.10% of initial]
[Iter 19090/20000] Loss: 0.0002455 (Best: 0.0002192 @iter15940) ([92m↓0.04%[0m) [0.10% of initial]
Iter:19099, L1 loss=0.0002754, Total loss=0.0002372, Time:54
[Iter 19100/20000] Loss: 0.0002673 (Best: 0.0002192 @iter15940) ([91m↑8.87%[0m) [0.11% of initial]
[Iter 19110/20000] Loss: 0.0002883 (Best: 0.0002192 @iter15940) ([91m↑7.85%[0m) [0.11% of initial]
[Iter 19120/20000] Loss: 0.0002514 (Best: 0.0002192 @iter15940) ([92m↓12.80%[0m) [0.10% of initial]
[Iter 19130/20000] Loss: 0.0002468 (Best: 0.0002192 @iter15940) ([92m↓1.84%[0m) [0.10% of initial]
[Iter 19140/20000] Loss: 0.0002721 (Best: 0.0002192 @iter15940) ([91m↑10.26%[0m) [0.11% of initial]
[Iter 19150/20000] Loss: 0.0002541 (Best: 0.0002192 @iter15940) ([92m↓6.60%[0m) [0.10% of initial]
[Iter 19160/20000] Loss: 0.0002546 (Best: 0.0002192 @iter15940) ([91m↑0.20%[0m) [0.10% of initial]
[Iter 19170/20000] Loss: 0.0002433 (Best: 0.0002192 @iter15940) ([92m↓4.45%[0m) [0.10% of initial]
[Iter 19180/20000] Loss: 0.0002400 (Best: 0.0002192 @iter15940) ([92m↓1.37%[0m) [0.10% of initial]
[Iter 19190/20000] Loss: 0.0002600 (Best: 0.0002192 @iter15940) ([91m↑8.34%[0m) [0.10% of initial]
Iter:19199, L1 loss=0.0003791, Total loss=0.0003018, Time:52
[Iter 19200/20000] Loss: 0.0002812 (Best: 0.0002192 @iter15940) ([91m↑8.18%[0m) [0.11% of initial]
[Iter 19210/20000] Loss: 0.0002594 (Best: 0.0002192 @iter15940) ([92m↓7.78%[0m) [0.10% of initial]
[Iter 19220/20000] Loss: 0.0002789 (Best: 0.0002192 @iter15940) ([91m↑7.54%[0m) [0.11% of initial]
[Iter 19230/20000] Loss: 0.0002412 (Best: 0.0002192 @iter15940) ([92m↓13.53%[0m) [0.10% of initial]
[Iter 19240/20000] Loss: 0.0002306 (Best: 0.0002143 @iter19240) ([92m↓4.38%[0m) [0.09% of initial]
[Iter 19250/20000] Loss: 0.0002423 (Best: 0.0002143 @iter19240) ([91m↑5.05%[0m) [0.10% of initial]
[Iter 19260/20000] Loss: 0.0002417 (Best: 0.0002143 @iter19240) ([92m↓0.23%[0m) [0.10% of initial]
[Iter 19270/20000] Loss: 0.0002556 (Best: 0.0002143 @iter19240) ([91m↑5.75%[0m) [0.10% of initial]
[Iter 19280/20000] Loss: 0.0002632 (Best: 0.0002143 @iter19240) ([91m↑2.96%[0m) [0.10% of initial]
[Iter 19290/20000] Loss: 0.0002475 (Best: 0.0002143 @iter19240) ([92m↓5.97%[0m) [0.10% of initial]
Iter:19299, L1 loss=0.0002819, Total loss=0.000239, Time:54
[Iter 19300/20000] Loss: 0.0002412 (Best: 0.0002143 @iter19240) ([92m↓2.54%[0m) [0.10% of initial]
[Iter 19310/20000] Loss: 0.0002537 (Best: 0.0002143 @iter19240) ([91m↑5.21%[0m) [0.10% of initial]
[Iter 19320/20000] Loss: 0.0002542 (Best: 0.0002143 @iter19240) ([91m↑0.19%[0m) [0.10% of initial]
[Iter 19330/20000] Loss: 0.0002710 (Best: 0.0002143 @iter19240) ([91m↑6.62%[0m) [0.11% of initial]
[Iter 19340/20000] Loss: 0.0003074 (Best: 0.0002143 @iter19240) ([91m↑13.41%[0m) [0.12% of initial]
[Iter 19350/20000] Loss: 0.0003476 (Best: 0.0002143 @iter19240) ([91m↑13.08%[0m) [0.14% of initial]
[Iter 19360/20000] Loss: 0.0003126 (Best: 0.0002143 @iter19240) ([92m↓10.07%[0m) [0.12% of initial]
[Iter 19370/20000] Loss: 0.0003070 (Best: 0.0002143 @iter19240) ([92m↓1.78%[0m) [0.12% of initial]
[Iter 19380/20000] Loss: 0.0003277 (Best: 0.0002143 @iter19240) ([91m↑6.73%[0m) [0.13% of initial]
[Iter 19390/20000] Loss: 0.0002668 (Best: 0.0002143 @iter19240) ([92m↓18.57%[0m) [0.11% of initial]
Iter:19399, L1 loss=0.0002733, Total loss=0.000246, Time:53
[Iter 19400/20000] Loss: 0.0002605 (Best: 0.0002143 @iter19240) ([92m↓2.36%[0m) [0.10% of initial]
[Iter 19410/20000] Loss: 0.0002358 (Best: 0.0002143 @iter19240) ([92m↓9.48%[0m) [0.09% of initial]
[Iter 19420/20000] Loss: 0.0002347 (Best: 0.0002143 @iter19240) ([92m↓0.46%[0m) [0.09% of initial]
[Iter 19430/20000] Loss: 0.0002256 (Best: 0.0002143 @iter19240) ([92m↓3.89%[0m) [0.09% of initial]
[Iter 19440/20000] Loss: 0.0002390 (Best: 0.0002143 @iter19240) ([91m↑5.91%[0m) [0.09% of initial]
[Iter 19450/20000] Loss: 0.0002460 (Best: 0.0002143 @iter19240) ([91m↑2.94%[0m) [0.10% of initial]
[Iter 19460/20000] Loss: 0.0003031 (Best: 0.0002143 @iter19240) ([91m↑23.21%[0m) [0.12% of initial]
[Iter 19470/20000] Loss: 0.0003613 (Best: 0.0002143 @iter19240) ([91m↑19.22%[0m) [0.14% of initial]
[Iter 19480/20000] Loss: 0.0004148 (Best: 0.0002143 @iter19240) ([91m↑14.80%[0m) [0.16% of initial]
[Iter 19490/20000] Loss: 0.0003404 (Best: 0.0002143 @iter19240) ([92m↓17.94%[0m) [0.14% of initial]
Iter:19499, L1 loss=0.0003059, Total loss=0.0002834, Time:51
[Iter 19500/20000] Loss: 0.0003154 (Best: 0.0002143 @iter19240) ([92m↓7.35%[0m) [0.13% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 19500
Pruning 1 points (0.0%) from gaussian1 at iteration 19500
[Iter 19510/20000] Loss: 0.0005309 (Best: 0.0002143 @iter19240) ([91m↑68.33%[0m) [0.21% of initial]
[Iter 19520/20000] Loss: 0.0003514 (Best: 0.0002143 @iter19240) ([92m↓33.81%[0m) [0.14% of initial]
[Iter 19530/20000] Loss: 0.0002937 (Best: 0.0002143 @iter19240) ([92m↓16.42%[0m) [0.12% of initial]
[Iter 19540/20000] Loss: 0.0002505 (Best: 0.0002143 @iter19240) ([92m↓14.70%[0m) [0.10% of initial]
[Iter 19550/20000] Loss: 0.0002519 (Best: 0.0002143 @iter19240) ([91m↑0.53%[0m) [0.10% of initial]
[Iter 19560/20000] Loss: 0.0002441 (Best: 0.0002143 @iter19240) ([92m↓3.08%[0m) [0.10% of initial]
[Iter 19570/20000] Loss: 0.0002228 (Best: 0.0002124 @iter19570) ([92m↓8.72%[0m) [0.09% of initial]
[Iter 19580/20000] Loss: 0.0002581 (Best: 0.0002124 @iter19570) ([91m↑15.83%[0m) [0.10% of initial]
[Iter 19590/20000] Loss: 0.0002362 (Best: 0.0002124 @iter19570) ([92m↓8.48%[0m) [0.09% of initial]
Iter:19599, L1 loss=0.0002804, Total loss=0.0002357, Time:49
[Iter 19600/20000] Loss: 0.0002352 (Best: 0.0002124 @iter19570) ([92m↓0.43%[0m) [0.09% of initial]
[Iter 19610/20000] Loss: 0.0002485 (Best: 0.0002124 @iter19570) ([91m↑5.64%[0m) [0.10% of initial]
[Iter 19620/20000] Loss: 0.0002759 (Best: 0.0002124 @iter19570) ([91m↑11.05%[0m) [0.11% of initial]
[Iter 19630/20000] Loss: 0.0002603 (Best: 0.0002124 @iter19570) ([92m↓5.66%[0m) [0.10% of initial]
[Iter 19640/20000] Loss: 0.0002420 (Best: 0.0002124 @iter19570) ([92m↓7.04%[0m) [0.10% of initial]
[Iter 19650/20000] Loss: 0.0002635 (Best: 0.0002124 @iter19570) ([91m↑8.91%[0m) [0.10% of initial]
[Iter 19660/20000] Loss: 0.0002319 (Best: 0.0002124 @iter19570) ([92m↓12.00%[0m) [0.09% of initial]
[Iter 19670/20000] Loss: 0.0002300 (Best: 0.0002124 @iter19570) ([92m↓0.83%[0m) [0.09% of initial]
[Iter 19680/20000] Loss: 0.0002342 (Best: 0.0002124 @iter19570) ([91m↑1.85%[0m) [0.09% of initial]
[Iter 19690/20000] Loss: 0.0002308 (Best: 0.0002124 @iter19570) ([92m↓1.48%[0m) [0.09% of initial]
Iter:19699, L1 loss=0.0002702, Total loss=0.000245, Time:48
[Iter 19700/20000] Loss: 0.0002415 (Best: 0.0002124 @iter19570) ([91m↑4.66%[0m) [0.10% of initial]
[Iter 19710/20000] Loss: 0.0002608 (Best: 0.0002124 @iter19570) ([91m↑7.99%[0m) [0.10% of initial]
[Iter 19720/20000] Loss: 0.0002411 (Best: 0.0002124 @iter19570) ([92m↓7.57%[0m) [0.10% of initial]
[Iter 19730/20000] Loss: 0.0002410 (Best: 0.0002124 @iter19570) ([92m↓0.02%[0m) [0.10% of initial]
[Iter 19740/20000] Loss: 0.0002333 (Best: 0.0002124 @iter19570) ([92m↓3.21%[0m) [0.09% of initial]
[Iter 19750/20000] Loss: 0.0002272 (Best: 0.0002124 @iter19570) ([92m↓2.62%[0m) [0.09% of initial]
[Iter 19760/20000] Loss: 0.0002301 (Best: 0.0002124 @iter19570) ([91m↑1.29%[0m) [0.09% of initial]
[Iter 19770/20000] Loss: 0.0002307 (Best: 0.0002124 @iter19570) ([91m↑0.27%[0m) [0.09% of initial]
[Iter 19780/20000] Loss: 0.0002441 (Best: 0.0002124 @iter19570) ([91m↑5.80%[0m) [0.10% of initial]
[Iter 19790/20000] Loss: 0.0002304 (Best: 0.0002124 @iter19570) ([92m↓5.61%[0m) [0.09% of initial]
Iter:19799, L1 loss=0.0003008, Total loss=0.0002491, Time:48
[Iter 19800/20000] Loss: 0.0002369 (Best: 0.0002124 @iter19570) ([91m↑2.84%[0m) [0.09% of initial]
[Iter 19810/20000] Loss: 0.0002445 (Best: 0.0002124 @iter19570) ([91m↑3.19%[0m) [0.10% of initial]
[Iter 19820/20000] Loss: 0.0002433 (Best: 0.0002124 @iter19570) ([92m↓0.48%[0m) [0.10% of initial]
[Iter 19830/20000] Loss: 0.0002998 (Best: 0.0002124 @iter19570) ([91m↑23.22%[0m) [0.12% of initial]
[Iter 19840/20000] Loss: 0.0002934 (Best: 0.0002124 @iter19570) ([92m↓2.15%[0m) [0.12% of initial]
[Iter 19850/20000] Loss: 0.0002762 (Best: 0.0002124 @iter19570) ([92m↓5.85%[0m) [0.11% of initial]
[Iter 19860/20000] Loss: 0.0003293 (Best: 0.0002124 @iter19570) ([91m↑19.24%[0m) [0.13% of initial]
[Iter 19870/20000] Loss: 0.0003113 (Best: 0.0002124 @iter19570) ([92m↓5.47%[0m) [0.12% of initial]
[Iter 19880/20000] Loss: 0.0003059 (Best: 0.0002124 @iter19570) ([92m↓1.75%[0m) [0.12% of initial]
[Iter 19890/20000] Loss: 0.0003403 (Best: 0.0002124 @iter19570) ([91m↑11.27%[0m) [0.14% of initial]
Iter:19899, L1 loss=0.0003168, Total loss=0.0002744, Time:52
[Iter 19900/20000] Loss: 0.0002738 (Best: 0.0002124 @iter19570) ([92m↓19.54%[0m) [0.11% of initial]
[Iter 19910/20000] Loss: 0.0003052 (Best: 0.0002124 @iter19570) ([91m↑11.46%[0m) [0.12% of initial]
[Iter 19920/20000] Loss: 0.0003009 (Best: 0.0002124 @iter19570) ([92m↓1.43%[0m) [0.12% of initial]
[Iter 19930/20000] Loss: 0.0002882 (Best: 0.0002124 @iter19570) ([92m↓4.19%[0m) [0.11% of initial]
[Iter 19940/20000] Loss: 0.0003065 (Best: 0.0002124 @iter19570) ([91m↑6.34%[0m) [0.12% of initial]
[Iter 19950/20000] Loss: 0.0002963 (Best: 0.0002124 @iter19570) ([92m↓3.32%[0m) [0.12% of initial]
[Iter 19960/20000] Loss: 0.0002796 (Best: 0.0002124 @iter19570) ([92m↓5.64%[0m) [0.11% of initial]
[Iter 19970/20000] Loss: 0.0002759 (Best: 0.0002124 @iter19570) ([92m↓1.35%[0m) [0.11% of initial]
[Iter 19980/20000] Loss: 0.0002717 (Best: 0.0002124 @iter19570) ([92m↓1.50%[0m) [0.11% of initial]
[Iter 19990/20000] Loss: 0.0002313 (Best: 0.0002124 @iter19570) ([92m↓14.89%[0m) [0.09% of initial]
Iter:19999, L1 loss=0.0002625, Total loss=0.0002325, Time:46
[Iter 20000/20000] Loss: 0.0002322 (Best: 0.0002124 @iter19570) ([91m↑0.40%[0m) [0.09% of initial]
Testing Speed: 67.73908678695808 fps
Testing Time: 0.738126277923584 s

[ITER 20000] Evaluating test: SSIM = 0.9273344993591309, PSNR = 21.19315607070923
Testing Speed: 78.44414797451466 fps
Testing Time: 0.038243770599365234 s

[ITER 20000] Evaluating train: SSIM = 0.9999991456667582, PSNR = 65.80201975504556
Iter:20000, total_points:183237

[ITER 20000] Saving Gaussians
Pruning 2 points (0.0%) from gaussian0 at iteration 20000
Pruning 4 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 67 fps
Total time: 24.44 minutes
Test SSIM: 0.9273
Test PSNR: 21.193
Gaussian0 final points count: 183235
Gaussian1 final points count: 183266
Final loss: 0.0002322 (0.09% of initial)
Save path: 2024_11_26_14_53_04
Initial loss: 0.2517052
Best loss: 0.0002124 @iteration 19570 (0.08% of initial)
Train SSIM: 1.0000
Train PSNR: 65.802
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.4272577 (Best: 0.4221882 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.3858143 (Best: 0.3798439 @iter19) ([92m↓9.70%[0m) [83.69% of initial]
[Iter 30/20000] Loss: 0.3362649 (Best: 0.3274108 @iter30) ([92m↓12.84%[0m) [72.94% of initial]
[Iter 40/20000] Loss: 0.2812108 (Best: 0.2715389 @iter40) ([92m↓16.37%[0m) [61.00% of initial]
[Iter 50/20000] Loss: 0.2309219 (Best: 0.2239401 @iter50) ([92m↓17.88%[0m) [50.09% of initial]
[Iter 60/20000] Loss: 0.1870836 (Best: 0.1816229 @iter60) ([92m↓18.98%[0m) [40.58% of initial]
[Iter 70/20000] Loss: 0.1485783 (Best: 0.1438986 @iter70) ([92m↓20.58%[0m) [32.23% of initial]
[Iter 80/20000] Loss: 0.1185747 (Best: 0.1151163 @iter79) ([92m↓20.19%[0m) [25.72% of initial]
[Iter 90/20000] Loss: 0.0996288 (Best: 0.0952262 @iter89) ([92m↓15.98%[0m) [21.61% of initial]
Iter:99, L1 loss=0.05612, Total loss=0.0859, Time:19
[Iter 100/20000] Loss: 0.0852998 (Best: 0.0817075 @iter98) ([92m↓14.38%[0m) [18.50% of initial]
[Iter 110/20000] Loss: 0.0720435 (Best: 0.0685760 @iter109) ([92m↓15.54%[0m) [15.63% of initial]
[Iter 120/20000] Loss: 0.0621897 (Best: 0.0587540 @iter120) ([92m↓13.68%[0m) [13.49% of initial]
[Iter 130/20000] Loss: 0.0554251 (Best: 0.0526331 @iter129) ([92m↓10.88%[0m) [12.02% of initial]
[Iter 140/20000] Loss: 0.0498623 (Best: 0.0473141 @iter139) ([92m↓10.04%[0m) [10.82% of initial]
[Iter 150/20000] Loss: 0.0462464 (Best: 0.0433821 @iter149) ([92m↓7.25%[0m) [10.03% of initial]
[Iter 160/20000] Loss: 0.0420008 (Best: 0.0400462 @iter160) ([92m↓9.18%[0m) [9.11% of initial]
[Iter 170/20000] Loss: 0.0395048 (Best: 0.0376183 @iter170) ([92m↓5.94%[0m) [8.57% of initial]
[Iter 180/20000] Loss: 0.0383310 (Best: 0.0358858 @iter178) ([92m↓2.97%[0m) [8.31% of initial]
[Iter 190/20000] Loss: 0.0369114 (Best: 0.0341638 @iter187) ([92m↓3.70%[0m) [8.01% of initial]
Iter:199, L1 loss=0.02038, Total loss=0.03216, Time:16
[Iter 200/20000] Loss: 0.0342124 (Best: 0.0321637 @iter199) ([92m↓7.31%[0m) [7.42% of initial]
[Iter 210/20000] Loss: 0.0330080 (Best: 0.0309398 @iter208) ([92m↓3.52%[0m) [7.16% of initial]
[Iter 220/20000] Loss: 0.0307644 (Best: 0.0295579 @iter220) ([92m↓6.80%[0m) [6.67% of initial]
[Iter 230/20000] Loss: 0.0302543 (Best: 0.0286542 @iter229) ([92m↓1.66%[0m) [6.56% of initial]
[Iter 240/20000] Loss: 0.0294089 (Best: 0.0277329 @iter239) ([92m↓2.79%[0m) [6.38% of initial]
[Iter 250/20000] Loss: 0.0289554 (Best: 0.0270381 @iter247) ([92m↓1.54%[0m) [6.28% of initial]
[Iter 260/20000] Loss: 0.0277337 (Best: 0.0261494 @iter258) ([92m↓4.22%[0m) [6.02% of initial]
[Iter 270/20000] Loss: 0.0268530 (Best: 0.0253660 @iter268) ([92m↓3.18%[0m) [5.83% of initial]
[Iter 280/20000] Loss: 0.0254823 (Best: 0.0245091 @iter280) ([92m↓5.10%[0m) [5.53% of initial]
[Iter 290/20000] Loss: 0.0251244 (Best: 0.0239073 @iter289) ([92m↓1.40%[0m) [5.45% of initial]
Iter:299, L1 loss=0.01436, Total loss=0.02326, Time:13
[Iter 300/20000] Loss: 0.0244455 (Best: 0.0232612 @iter299) ([92m↓2.70%[0m) [5.30% of initial]
[Iter 310/20000] Loss: 0.0237670 (Best: 0.0226627 @iter309) ([92m↓2.78%[0m) [5.16% of initial]
[Iter 320/20000] Loss: 0.0234300 (Best: 0.0221433 @iter318) ([92m↓1.42%[0m) [5.08% of initial]
[Iter 330/20000] Loss: 0.0225528 (Best: 0.0215500 @iter329) ([92m↓3.74%[0m) [4.89% of initial]
[Iter 340/20000] Loss: 0.0222240 (Best: 0.0211285 @iter337) ([92m↓1.46%[0m) [4.82% of initial]
[Iter 350/20000] Loss: 0.0211086 (Best: 0.0204850 @iter350) ([92m↓5.02%[0m) [4.58% of initial]
[Iter 360/20000] Loss: 0.0212243 (Best: 0.0200529 @iter359) ([91m↑0.55%[0m) [4.60% of initial]
[Iter 370/20000] Loss: 0.0203080 (Best: 0.0195307 @iter370) ([92m↓4.32%[0m) [4.41% of initial]
[Iter 380/20000] Loss: 0.0204408 (Best: 0.0192653 @iter376) ([91m↑0.65%[0m) [4.43% of initial]
[Iter 390/20000] Loss: 0.0196714 (Best: 0.0187493 @iter388) ([92m↓3.76%[0m) [4.27% of initial]
Iter:399, L1 loss=0.01213, Total loss=0.01987, Time:21
[Iter 400/20000] Loss: 0.0192066 (Best: 0.0183368 @iter398) ([92m↓2.36%[0m) [4.17% of initial]
[Iter 410/20000] Loss: 0.0189711 (Best: 0.0180099 @iter406) ([92m↓1.23%[0m) [4.12% of initial]
[Iter 420/20000] Loss: 0.0181610 (Best: 0.0174679 @iter420) ([92m↓4.27%[0m) [3.94% of initial]
[Iter 430/20000] Loss: 0.0179912 (Best: 0.0172053 @iter427) ([92m↓0.93%[0m) [3.90% of initial]
[Iter 440/20000] Loss: 0.0173675 (Best: 0.0167213 @iter440) ([92m↓3.47%[0m) [3.77% of initial]
[Iter 450/20000] Loss: 0.0169879 (Best: 0.0163914 @iter450) ([92m↓2.19%[0m) [3.69% of initial]
[Iter 460/20000] Loss: 0.0165907 (Best: 0.0160392 @iter460) ([92m↓2.34%[0m) [3.60% of initial]
[Iter 470/20000] Loss: 0.0166435 (Best: 0.0158772 @iter466) ([91m↑0.32%[0m) [3.61% of initial]
[Iter 480/20000] Loss: 0.0162559 (Best: 0.0154763 @iter478) ([92m↓2.33%[0m) [3.53% of initial]
[Iter 490/20000] Loss: 0.0158279 (Best: 0.0151796 @iter488) ([92m↓2.63%[0m) [3.43% of initial]
Iter:499, L1 loss=0.008676, Total loss=0.01486, Time:17
[Iter 500/20000] Loss: 0.0155248 (Best: 0.0148569 @iter499) ([92m↓1.91%[0m) [3.37% of initial]
[Iter 510/20000] Loss: 0.0152151 (Best: 0.0145776 @iter509) ([92m↓2.00%[0m) [3.30% of initial]
[Iter 520/20000] Loss: 0.0150569 (Best: 0.0143822 @iter517) ([92m↓1.04%[0m) [3.27% of initial]
[Iter 530/20000] Loss: 0.0147417 (Best: 0.0141017 @iter528) ([92m↓2.09%[0m) [3.20% of initial]
[Iter 540/20000] Loss: 0.0143927 (Best: 0.0138122 @iter539) ([92m↓2.37%[0m) [3.12% of initial]
[Iter 550/20000] Loss: 0.0142576 (Best: 0.0136290 @iter547) ([92m↓0.94%[0m) [3.09% of initial]
[Iter 560/20000] Loss: 0.0138550 (Best: 0.0133174 @iter559) ([92m↓2.82%[0m) [3.01% of initial]
[Iter 570/20000] Loss: 0.0134400 (Best: 0.0130769 @iter570) ([92m↓3.00%[0m) [2.92% of initial]
[Iter 580/20000] Loss: 0.0135339 (Best: 0.0129144 @iter577) ([91m↑0.70%[0m) [2.94% of initial]
[Iter 590/20000] Loss: 0.0131284 (Best: 0.0126400 @iter589) ([92m↓3.00%[0m) [2.85% of initial]
Iter:599, L1 loss=0.007027, Total loss=0.01245, Time:17
[Iter 600/20000] Loss: 0.0129101 (Best: 0.0124482 @iter599) ([92m↓1.66%[0m) [2.80% of initial]
[Iter 610/20000] Loss: 0.0180409 (Best: 0.0124482 @iter599) ([91m↑39.74%[0m) [3.91% of initial]
[Iter 620/20000] Loss: 0.0148400 (Best: 0.0124482 @iter599) ([92m↓17.74%[0m) [3.22% of initial]
[Iter 630/20000] Loss: 0.0129663 (Best: 0.0123532 @iter629) ([92m↓12.63%[0m) [2.81% of initial]
[Iter 640/20000] Loss: 0.0122871 (Best: 0.0118456 @iter637) ([92m↓5.24%[0m) [2.67% of initial]
[Iter 650/20000] Loss: 0.0117942 (Best: 0.0113176 @iter649) ([92m↓4.01%[0m) [2.56% of initial]
[Iter 660/20000] Loss: 0.0113902 (Best: 0.0110457 @iter660) ([92m↓3.43%[0m) [2.47% of initial]
[Iter 670/20000] Loss: 0.0114058 (Best: 0.0108560 @iter668) ([91m↑0.14%[0m) [2.47% of initial]
[Iter 680/20000] Loss: 0.0108850 (Best: 0.0106009 @iter679) ([92m↓4.57%[0m) [2.36% of initial]
[Iter 690/20000] Loss: 0.0108012 (Best: 0.0104531 @iter688) ([92m↓0.77%[0m) [2.34% of initial]
Iter:699, L1 loss=0.005492, Total loss=0.01025, Time:17
[Iter 700/20000] Loss: 0.0106012 (Best: 0.0102482 @iter699) ([92m↓1.85%[0m) [2.30% of initial]
[Iter 710/20000] Loss: 0.0104058 (Best: 0.0100770 @iter706) ([92m↓1.84%[0m) [2.26% of initial]
[Iter 720/20000] Loss: 0.0100608 (Best: 0.0098182 @iter719) ([92m↓3.32%[0m) [2.18% of initial]
[Iter 730/20000] Loss: 0.0099692 (Best: 0.0096618 @iter728) ([92m↓0.91%[0m) [2.16% of initial]
[Iter 740/20000] Loss: 0.0095659 (Best: 0.0093400 @iter740) ([92m↓4.05%[0m) [2.08% of initial]
[Iter 750/20000] Loss: 0.0093593 (Best: 0.0091401 @iter749) ([92m↓2.16%[0m) [2.03% of initial]
[Iter 760/20000] Loss: 0.0089920 (Best: 0.0088604 @iter757) ([92m↓3.92%[0m) [1.95% of initial]
[Iter 770/20000] Loss: 0.0086844 (Best: 0.0085440 @iter767) ([92m↓3.42%[0m) [1.88% of initial]
[Iter 780/20000] Loss: 0.0083211 (Best: 0.0082053 @iter780) ([92m↓4.18%[0m) [1.81% of initial]
[Iter 790/20000] Loss: 0.0080836 (Best: 0.0079311 @iter788) ([92m↓2.85%[0m) [1.75% of initial]
Iter:799, L1 loss=0.003978, Total loss=0.007725, Time:17
[Iter 800/20000] Loss: 0.0077569 (Best: 0.0076967 @iter800) ([92m↓4.04%[0m) [1.68% of initial]
[Iter 810/20000] Loss: 0.0143936 (Best: 0.0076967 @iter800) ([91m↑85.56%[0m) [3.12% of initial]
[Iter 820/20000] Loss: 0.0104537 (Best: 0.0076967 @iter800) ([92m↓27.37%[0m) [2.27% of initial]
[Iter 830/20000] Loss: 0.0083037 (Best: 0.0076967 @iter800) ([92m↓20.57%[0m) [1.80% of initial]
[Iter 840/20000] Loss: 0.0077972 (Best: 0.0076478 @iter840) ([92m↓6.10%[0m) [1.69% of initial]
[Iter 850/20000] Loss: 0.0074504 (Best: 0.0072862 @iter848) ([92m↓4.45%[0m) [1.62% of initial]
[Iter 860/20000] Loss: 0.0071029 (Best: 0.0069961 @iter859) ([92m↓4.66%[0m) [1.54% of initial]
[Iter 870/20000] Loss: 0.0068392 (Best: 0.0067519 @iter868) ([92m↓3.71%[0m) [1.48% of initial]
[Iter 880/20000] Loss: 0.0066641 (Best: 0.0065685 @iter878) ([92m↓2.56%[0m) [1.45% of initial]
[Iter 890/20000] Loss: 0.0064594 (Best: 0.0063527 @iter890) ([92m↓3.07%[0m) [1.40% of initial]
Iter:899, L1 loss=0.0032, Total loss=0.006162, Time:15
[Iter 900/20000] Loss: 0.0062417 (Best: 0.0061618 @iter899) ([92m↓3.37%[0m) [1.35% of initial]
[Iter 910/20000] Loss: 0.0059145 (Best: 0.0058262 @iter910) ([92m↓5.24%[0m) [1.28% of initial]
[Iter 920/20000] Loss: 0.0055741 (Best: 0.0054996 @iter919) ([92m↓5.75%[0m) [1.21% of initial]
[Iter 930/20000] Loss: 0.0052464 (Best: 0.0051927 @iter930) ([92m↓5.88%[0m) [1.14% of initial]
[Iter 940/20000] Loss: 0.0049776 (Best: 0.0049341 @iter940) ([92m↓5.12%[0m) [1.08% of initial]
[Iter 950/20000] Loss: 0.0046806 (Best: 0.0045947 @iter950) ([92m↓5.97%[0m) [1.02% of initial]
[Iter 960/20000] Loss: 0.0046141 (Best: 0.0045201 @iter956) ([92m↓1.42%[0m) [1.00% of initial]
[Iter 970/20000] Loss: 0.0042629 (Best: 0.0042016 @iter968) ([92m↓7.61%[0m) [0.92% of initial]
[Iter 980/20000] Loss: 0.0039447 (Best: 0.0038849 @iter979) ([92m↓7.46%[0m) [0.86% of initial]
[Iter 990/20000] Loss: 0.0037043 (Best: 0.0036792 @iter990) ([92m↓6.10%[0m) [0.80% of initial]
Iter:999, L1 loss=0.002341, Total loss=0.003503, Time:20
[Iter 1000/20000] Loss: 0.0034864 (Best: 0.0034450 @iter997) ([92m↓5.88%[0m) [0.76% of initial]
Pruning 357 points (6.3%) from gaussian0 at iteration 1000
Pruning 352 points (6.2%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0203598 (Best: 0.0034450 @iter997) ([91m↑483.98%[0m) [4.42% of initial]
[Iter 1020/20000] Loss: 0.0116393 (Best: 0.0034450 @iter997) ([92m↓42.83%[0m) [2.52% of initial]
[Iter 1030/20000] Loss: 0.0076257 (Best: 0.0034450 @iter997) ([92m↓34.48%[0m) [1.65% of initial]
[Iter 1040/20000] Loss: 0.0055379 (Best: 0.0034450 @iter997) ([92m↓27.38%[0m) [1.20% of initial]
[Iter 1050/20000] Loss: 0.0044844 (Best: 0.0034450 @iter997) ([92m↓19.02%[0m) [0.97% of initial]
[Iter 1060/20000] Loss: 0.0039078 (Best: 0.0034450 @iter997) ([92m↓12.86%[0m) [0.85% of initial]
[Iter 1070/20000] Loss: 0.0034697 (Best: 0.0033712 @iter1068) ([92m↓11.21%[0m) [0.75% of initial]
[Iter 1080/20000] Loss: 0.0030838 (Best: 0.0029499 @iter1079) ([92m↓11.12%[0m) [0.67% of initial]
[Iter 1090/20000] Loss: 0.0027698 (Best: 0.0026829 @iter1090) ([92m↓10.18%[0m) [0.60% of initial]
Iter:1099, L1 loss=0.001557, Total loss=0.002643, Time:16
[Iter 1100/20000] Loss: 0.0026595 (Best: 0.0025565 @iter1094) ([92m↓3.98%[0m) [0.58% of initial]
[Iter 1110/20000] Loss: 0.0023889 (Best: 0.0022932 @iter1109) ([92m↓10.18%[0m) [0.52% of initial]
[Iter 1120/20000] Loss: 0.0022250 (Best: 0.0021647 @iter1120) ([92m↓6.86%[0m) [0.48% of initial]
[Iter 1130/20000] Loss: 0.0021195 (Best: 0.0020259 @iter1129) ([92m↓4.74%[0m) [0.46% of initial]
[Iter 1140/20000] Loss: 0.0020032 (Best: 0.0019703 @iter1139) ([92m↓5.49%[0m) [0.43% of initial]
[Iter 1150/20000] Loss: 0.0018696 (Best: 0.0018209 @iter1150) ([92m↓6.67%[0m) [0.41% of initial]
[Iter 1160/20000] Loss: 0.0018670 (Best: 0.0017977 @iter1153) ([92m↓0.14%[0m) [0.41% of initial]
[Iter 1170/20000] Loss: 0.0017277 (Best: 0.0016493 @iter1170) ([92m↓7.46%[0m) [0.37% of initial]
[Iter 1180/20000] Loss: 0.0016307 (Best: 0.0015828 @iter1180) ([92m↓5.62%[0m) [0.35% of initial]
[Iter 1190/20000] Loss: 0.0015804 (Best: 0.0015109 @iter1186) ([92m↓3.08%[0m) [0.34% of initial]
Iter:1199, L1 loss=0.0009578, Total loss=0.001569, Time:17
[Iter 1200/20000] Loss: 0.0014963 (Best: 0.0014130 @iter1198) ([92m↓5.32%[0m) [0.32% of initial]
[Iter 1210/20000] Loss: 0.0089146 (Best: 0.0014130 @iter1198) ([91m↑495.79%[0m) [1.93% of initial]
[Iter 1220/20000] Loss: 0.0041364 (Best: 0.0014130 @iter1198) ([92m↓53.60%[0m) [0.90% of initial]
[Iter 1230/20000] Loss: 0.0024336 (Best: 0.0014130 @iter1198) ([92m↓41.17%[0m) [0.53% of initial]
[Iter 1240/20000] Loss: 0.0016739 (Best: 0.0014130 @iter1198) ([92m↓31.22%[0m) [0.36% of initial]
[Iter 1250/20000] Loss: 0.0013229 (Best: 0.0012826 @iter1250) ([92m↓20.97%[0m) [0.29% of initial]
[Iter 1260/20000] Loss: 0.0011758 (Best: 0.0010290 @iter1258) ([92m↓11.12%[0m) [0.26% of initial]
[Iter 1270/20000] Loss: 0.0010390 (Best: 0.0010202 @iter1270) ([92m↓11.64%[0m) [0.23% of initial]
[Iter 1280/20000] Loss: 0.0010565 (Best: 0.0009503 @iter1273) ([91m↑1.69%[0m) [0.23% of initial]
[Iter 1290/20000] Loss: 0.0010998 (Best: 0.0009079 @iter1288) ([91m↑4.10%[0m) [0.24% of initial]
Iter:1299, L1 loss=0.0008219, Total loss=0.0009308, Time:15
[Iter 1300/20000] Loss: 0.0009531 (Best: 0.0009079 @iter1288) ([92m↓13.34%[0m) [0.21% of initial]
[Iter 1310/20000] Loss: 0.0009390 (Best: 0.0008478 @iter1307) ([92m↓1.48%[0m) [0.20% of initial]
[Iter 1320/20000] Loss: 0.0009171 (Best: 0.0008272 @iter1317) ([92m↓2.34%[0m) [0.20% of initial]
[Iter 1330/20000] Loss: 0.0009127 (Best: 0.0008086 @iter1321) ([92m↓0.48%[0m) [0.20% of initial]
[Iter 1340/20000] Loss: 0.0009423 (Best: 0.0008086 @iter1321) ([91m↑3.25%[0m) [0.20% of initial]
[Iter 1350/20000] Loss: 0.0008747 (Best: 0.0008086 @iter1321) ([92m↓7.17%[0m) [0.19% of initial]
[Iter 1360/20000] Loss: 0.0008693 (Best: 0.0007967 @iter1360) ([92m↓0.62%[0m) [0.19% of initial]
[Iter 1370/20000] Loss: 0.0008506 (Best: 0.0007926 @iter1370) ([92m↓2.15%[0m) [0.18% of initial]
[Iter 1380/20000] Loss: 0.0008427 (Best: 0.0007926 @iter1370) ([92m↓0.93%[0m) [0.18% of initial]
[Iter 1390/20000] Loss: 0.0008062 (Best: 0.0007760 @iter1384) ([92m↓4.33%[0m) [0.17% of initial]
Iter:1399, L1 loss=0.0006566, Total loss=0.0007313, Time:17
[Iter 1400/20000] Loss: 0.0007722 (Best: 0.0007153 @iter1397) ([92m↓4.22%[0m) [0.17% of initial]
[Iter 1410/20000] Loss: 0.0067504 (Best: 0.0007153 @iter1397) ([91m↑774.15%[0m) [1.46% of initial]
[Iter 1420/20000] Loss: 0.0034626 (Best: 0.0007153 @iter1397) ([92m↓48.71%[0m) [0.75% of initial]
[Iter 1430/20000] Loss: 0.0018812 (Best: 0.0007153 @iter1397) ([92m↓45.67%[0m) [0.41% of initial]
[Iter 1440/20000] Loss: 0.0012981 (Best: 0.0007153 @iter1397) ([92m↓31.00%[0m) [0.28% of initial]
[Iter 1450/20000] Loss: 0.0010524 (Best: 0.0007153 @iter1397) ([92m↓18.93%[0m) [0.23% of initial]
[Iter 1460/20000] Loss: 0.0009857 (Best: 0.0007153 @iter1397) ([92m↓6.34%[0m) [0.21% of initial]
[Iter 1470/20000] Loss: 0.0010096 (Best: 0.0007153 @iter1397) ([91m↑2.43%[0m) [0.22% of initial]
[Iter 1480/20000] Loss: 0.0009276 (Best: 0.0007153 @iter1397) ([92m↓8.13%[0m) [0.20% of initial]
[Iter 1490/20000] Loss: 0.0008905 (Best: 0.0007153 @iter1397) ([92m↓4.00%[0m) [0.19% of initial]
Iter:1499, L1 loss=0.0007199, Total loss=0.0007897, Time:16
[Iter 1500/20000] Loss: 0.0008210 (Best: 0.0007153 @iter1397) ([92m↓7.80%[0m) [0.18% of initial]
Pruning 327 points (6.8%) from gaussian0 at iteration 1500
Pruning 409 points (10.6%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0072931 (Best: 0.0007153 @iter1397) ([91m↑788.27%[0m) [1.58% of initial]
[Iter 1520/20000] Loss: 0.0029958 (Best: 0.0007153 @iter1397) ([92m↓58.92%[0m) [0.65% of initial]
[Iter 1530/20000] Loss: 0.0015172 (Best: 0.0007153 @iter1397) ([92m↓49.35%[0m) [0.33% of initial]
[Iter 1540/20000] Loss: 0.0012044 (Best: 0.0007153 @iter1397) ([92m↓20.62%[0m) [0.26% of initial]
[Iter 1550/20000] Loss: 0.0010272 (Best: 0.0007153 @iter1397) ([92m↓14.71%[0m) [0.22% of initial]
[Iter 1560/20000] Loss: 0.0009484 (Best: 0.0007153 @iter1397) ([92m↓7.67%[0m) [0.21% of initial]
[Iter 1570/20000] Loss: 0.0009155 (Best: 0.0007153 @iter1397) ([92m↓3.47%[0m) [0.20% of initial]
[Iter 1580/20000] Loss: 0.0008718 (Best: 0.0007153 @iter1397) ([92m↓4.77%[0m) [0.19% of initial]
[Iter 1590/20000] Loss: 0.0008853 (Best: 0.0007153 @iter1397) ([91m↑1.55%[0m) [0.19% of initial]
Iter:1599, L1 loss=0.0006886, Total loss=0.0009131, Time:16
[Iter 1600/20000] Loss: 0.0008784 (Best: 0.0007153 @iter1397) ([92m↓0.78%[0m) [0.19% of initial]
[Iter 1610/20000] Loss: 0.0095240 (Best: 0.0007153 @iter1397) ([91m↑984.27%[0m) [2.07% of initial]
[Iter 1620/20000] Loss: 0.0026463 (Best: 0.0007153 @iter1397) ([92m↓72.21%[0m) [0.57% of initial]
[Iter 1630/20000] Loss: 0.0023663 (Best: 0.0007153 @iter1397) ([92m↓10.58%[0m) [0.51% of initial]
[Iter 1640/20000] Loss: 0.0012995 (Best: 0.0007153 @iter1397) ([92m↓45.08%[0m) [0.28% of initial]
[Iter 1650/20000] Loss: 0.0011113 (Best: 0.0007153 @iter1397) ([92m↓14.48%[0m) [0.24% of initial]
[Iter 1660/20000] Loss: 0.0009808 (Best: 0.0007153 @iter1397) ([92m↓11.75%[0m) [0.21% of initial]
[Iter 1670/20000] Loss: 0.0008990 (Best: 0.0007153 @iter1397) ([92m↓8.34%[0m) [0.20% of initial]
[Iter 1680/20000] Loss: 0.0008541 (Best: 0.0007153 @iter1397) ([92m↓5.00%[0m) [0.19% of initial]
[Iter 1690/20000] Loss: 0.0007931 (Best: 0.0007153 @iter1397) ([92m↓7.14%[0m) [0.17% of initial]
Iter:1699, L1 loss=0.0006325, Total loss=0.0007706, Time:16
[Iter 1700/20000] Loss: 0.0007740 (Best: 0.0007153 @iter1397) ([92m↓2.41%[0m) [0.17% of initial]
[Iter 1710/20000] Loss: 0.0007319 (Best: 0.0007132 @iter1710) ([92m↓5.44%[0m) [0.16% of initial]
[Iter 1720/20000] Loss: 0.0006911 (Best: 0.0006635 @iter1720) ([92m↓5.58%[0m) [0.15% of initial]
[Iter 1730/20000] Loss: 0.0006916 (Best: 0.0006635 @iter1730) ([91m↑0.08%[0m) [0.15% of initial]
[Iter 1740/20000] Loss: 0.0007125 (Best: 0.0006407 @iter1735) ([91m↑3.03%[0m) [0.15% of initial]
[Iter 1750/20000] Loss: 0.0006632 (Best: 0.0006318 @iter1750) ([92m↓6.93%[0m) [0.14% of initial]
[Iter 1760/20000] Loss: 0.0006725 (Best: 0.0006181 @iter1753) ([91m↑1.40%[0m) [0.15% of initial]
[Iter 1770/20000] Loss: 0.0006785 (Best: 0.0005983 @iter1765) ([91m↑0.89%[0m) [0.15% of initial]
[Iter 1780/20000] Loss: 0.0006700 (Best: 0.0005983 @iter1765) ([92m↓1.26%[0m) [0.15% of initial]
[Iter 1790/20000] Loss: 0.0006437 (Best: 0.0005983 @iter1765) ([92m↓3.92%[0m) [0.14% of initial]
Iter:1799, L1 loss=0.0006195, Total loss=0.0006256, Time:16
[Iter 1800/20000] Loss: 0.0006412 (Best: 0.0005983 @iter1765) ([92m↓0.39%[0m) [0.14% of initial]
[Iter 1810/20000] Loss: 0.0068470 (Best: 0.0005983 @iter1765) ([91m↑967.85%[0m) [1.49% of initial]
[Iter 1820/20000] Loss: 0.0023615 (Best: 0.0005983 @iter1765) ([92m↓65.51%[0m) [0.51% of initial]
[Iter 1830/20000] Loss: 0.0016600 (Best: 0.0005983 @iter1765) ([92m↓29.71%[0m) [0.36% of initial]
[Iter 1840/20000] Loss: 0.0010402 (Best: 0.0005983 @iter1765) ([92m↓37.34%[0m) [0.23% of initial]
[Iter 1850/20000] Loss: 0.0008985 (Best: 0.0005983 @iter1765) ([92m↓13.62%[0m) [0.19% of initial]
[Iter 1860/20000] Loss: 0.0008394 (Best: 0.0005983 @iter1765) ([92m↓6.57%[0m) [0.18% of initial]
[Iter 1870/20000] Loss: 0.0007425 (Best: 0.0005983 @iter1765) ([92m↓11.55%[0m) [0.16% of initial]
[Iter 1880/20000] Loss: 0.0007130 (Best: 0.0005983 @iter1765) ([92m↓3.97%[0m) [0.15% of initial]
[Iter 1890/20000] Loss: 0.0006531 (Best: 0.0005983 @iter1765) ([92m↓8.40%[0m) [0.14% of initial]
Iter:1899, L1 loss=0.0006456, Total loss=0.0006655, Time:16
[Iter 1900/20000] Loss: 0.0006766 (Best: 0.0005983 @iter1765) ([91m↑3.60%[0m) [0.15% of initial]
[Iter 1910/20000] Loss: 0.0006311 (Best: 0.0005983 @iter1765) ([92m↓6.73%[0m) [0.14% of initial]
[Iter 1920/20000] Loss: 0.0006327 (Best: 0.0005976 @iter1912) ([91m↑0.26%[0m) [0.14% of initial]
[Iter 1930/20000] Loss: 0.0006029 (Best: 0.0005885 @iter1930) ([92m↓4.71%[0m) [0.13% of initial]
[Iter 1940/20000] Loss: 0.0005834 (Best: 0.0005760 @iter1940) ([92m↓3.24%[0m) [0.13% of initial]
[Iter 1950/20000] Loss: 0.0005932 (Best: 0.0005724 @iter1949) ([91m↑1.68%[0m) [0.13% of initial]
[Iter 1960/20000] Loss: 0.0005681 (Best: 0.0005601 @iter1957) ([92m↓4.23%[0m) [0.12% of initial]
[Iter 1970/20000] Loss: 0.0005660 (Best: 0.0005392 @iter1963) ([92m↓0.36%[0m) [0.12% of initial]
[Iter 1980/20000] Loss: 0.0005620 (Best: 0.0005392 @iter1963) ([92m↓0.71%[0m) [0.12% of initial]
[Iter 1990/20000] Loss: 0.0005547 (Best: 0.0005350 @iter1987) ([92m↓1.31%[0m) [0.12% of initial]
Iter:1999, L1 loss=0.0005458, Total loss=0.0005136, Time:16
[Iter 2000/20000] Loss: 0.0005401 (Best: 0.0005136 @iter1999) ([92m↓2.64%[0m) [0.12% of initial]
Testing Speed: 137.37430376189656 fps
Testing Time: 0.363969087600708 s

[ITER 2000] Evaluating test: SSIM = 0.5838120210170746, PSNR = 8.492803707122803
Testing Speed: 132.62341768816466 fps
Testing Time: 0.022620439529418945 s

[ITER 2000] Evaluating train: SSIM = 0.5381272832552592, PSNR = 7.62992779413859
Iter:2000, total_points:5417
Pruning 516 points (8.0%) from gaussian0 at iteration 2000
Pruning 489 points (8.5%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.0073880 (Best: 0.0005136 @iter1999) ([91m↑1268.02%[0m) [1.60% of initial]
[Iter 2020/20000] Loss: 0.0029229 (Best: 0.0005136 @iter1999) ([92m↓60.44%[0m) [0.63% of initial]
[Iter 2030/20000] Loss: 0.0020117 (Best: 0.0005136 @iter1999) ([92m↓31.17%[0m) [0.44% of initial]
[Iter 2040/20000] Loss: 0.0015737 (Best: 0.0005136 @iter1999) ([92m↓21.77%[0m) [0.34% of initial]
[Iter 2050/20000] Loss: 0.0012744 (Best: 0.0005136 @iter1999) ([92m↓19.02%[0m) [0.28% of initial]
[Iter 2060/20000] Loss: 0.0012230 (Best: 0.0005136 @iter1999) ([92m↓4.03%[0m) [0.27% of initial]
[Iter 2070/20000] Loss: 0.0011021 (Best: 0.0005136 @iter1999) ([92m↓9.88%[0m) [0.24% of initial]
[Iter 2080/20000] Loss: 0.0010264 (Best: 0.0005136 @iter1999) ([92m↓6.87%[0m) [0.22% of initial]
[Iter 2090/20000] Loss: 0.0010090 (Best: 0.0005136 @iter1999) ([92m↓1.69%[0m) [0.22% of initial]
Iter:2099, L1 loss=0.0008147, Total loss=0.001055, Time:17
[Iter 2100/20000] Loss: 0.0009840 (Best: 0.0005136 @iter1999) ([92m↓2.48%[0m) [0.21% of initial]
[Iter 2110/20000] Loss: 0.0009325 (Best: 0.0005136 @iter1999) ([92m↓5.24%[0m) [0.20% of initial]
[Iter 2120/20000] Loss: 0.0009242 (Best: 0.0005136 @iter1999) ([92m↓0.89%[0m) [0.20% of initial]
[Iter 2130/20000] Loss: 0.0009193 (Best: 0.0005136 @iter1999) ([92m↓0.52%[0m) [0.20% of initial]
[Iter 2140/20000] Loss: 0.0008645 (Best: 0.0005136 @iter1999) ([92m↓5.97%[0m) [0.19% of initial]
[Iter 2150/20000] Loss: 0.0008770 (Best: 0.0005136 @iter1999) ([91m↑1.46%[0m) [0.19% of initial]
[Iter 2160/20000] Loss: 0.0008398 (Best: 0.0005136 @iter1999) ([92m↓4.24%[0m) [0.18% of initial]
[Iter 2170/20000] Loss: 0.0008008 (Best: 0.0005136 @iter1999) ([92m↓4.65%[0m) [0.17% of initial]
[Iter 2180/20000] Loss: 0.0008071 (Best: 0.0005136 @iter1999) ([91m↑0.79%[0m) [0.18% of initial]
[Iter 2190/20000] Loss: 0.0007758 (Best: 0.0005136 @iter1999) ([92m↓3.88%[0m) [0.17% of initial]
Iter:2199, L1 loss=0.0006372, Total loss=0.0007531, Time:21
[Iter 2200/20000] Loss: 0.0007326 (Best: 0.0005136 @iter1999) ([92m↓5.57%[0m) [0.16% of initial]
[Iter 2210/20000] Loss: 0.0047481 (Best: 0.0005136 @iter1999) ([91m↑548.09%[0m) [1.03% of initial]
[Iter 2220/20000] Loss: 0.0020338 (Best: 0.0005136 @iter1999) ([92m↓57.17%[0m) [0.44% of initial]
[Iter 2230/20000] Loss: 0.0014577 (Best: 0.0005136 @iter1999) ([92m↓28.33%[0m) [0.32% of initial]
[Iter 2240/20000] Loss: 0.0009929 (Best: 0.0005136 @iter1999) ([92m↓31.89%[0m) [0.22% of initial]
[Iter 2250/20000] Loss: 0.0009651 (Best: 0.0005136 @iter1999) ([92m↓2.79%[0m) [0.21% of initial]
[Iter 2260/20000] Loss: 0.0008298 (Best: 0.0005136 @iter1999) ([92m↓14.03%[0m) [0.18% of initial]
[Iter 2270/20000] Loss: 0.0007445 (Best: 0.0005136 @iter1999) ([92m↓10.28%[0m) [0.16% of initial]
[Iter 2280/20000] Loss: 0.0007780 (Best: 0.0005136 @iter1999) ([91m↑4.49%[0m) [0.17% of initial]
[Iter 2290/20000] Loss: 0.0007632 (Best: 0.0005136 @iter1999) ([92m↓1.89%[0m) [0.17% of initial]
Iter:2299, L1 loss=0.0005956, Total loss=0.0007405, Time:16
[Iter 2300/20000] Loss: 0.0007111 (Best: 0.0005136 @iter1999) ([92m↓6.83%[0m) [0.15% of initial]
[Iter 2310/20000] Loss: 0.0007054 (Best: 0.0005136 @iter1999) ([92m↓0.80%[0m) [0.15% of initial]
[Iter 2320/20000] Loss: 0.0006866 (Best: 0.0005136 @iter1999) ([92m↓2.66%[0m) [0.15% of initial]
[Iter 2330/20000] Loss: 0.0007260 (Best: 0.0005136 @iter1999) ([91m↑5.73%[0m) [0.16% of initial]
[Iter 2340/20000] Loss: 0.0007027 (Best: 0.0005136 @iter1999) ([92m↓3.21%[0m) [0.15% of initial]
[Iter 2350/20000] Loss: 0.0006340 (Best: 0.0005136 @iter1999) ([92m↓9.77%[0m) [0.14% of initial]
[Iter 2360/20000] Loss: 0.0006504 (Best: 0.0005136 @iter1999) ([91m↑2.58%[0m) [0.14% of initial]
[Iter 2370/20000] Loss: 0.0006447 (Best: 0.0005136 @iter1999) ([92m↓0.88%[0m) [0.14% of initial]
[Iter 2380/20000] Loss: 0.0005898 (Best: 0.0005136 @iter1999) ([92m↓8.51%[0m) [0.13% of initial]
[Iter 2390/20000] Loss: 0.0005761 (Best: 0.0005136 @iter1999) ([92m↓2.32%[0m) [0.12% of initial]
Iter:2399, L1 loss=0.0004782, Total loss=0.0005666, Time:16
[Iter 2400/20000] Loss: 0.0005641 (Best: 0.0005136 @iter1999) ([92m↓2.09%[0m) [0.12% of initial]
[Iter 2410/20000] Loss: 0.0032182 (Best: 0.0005136 @iter1999) ([91m↑470.55%[0m) [0.70% of initial]
[Iter 2420/20000] Loss: 0.0015070 (Best: 0.0005136 @iter1999) ([92m↓53.17%[0m) [0.33% of initial]
[Iter 2430/20000] Loss: 0.0010575 (Best: 0.0005136 @iter1999) ([92m↓29.83%[0m) [0.23% of initial]
[Iter 2440/20000] Loss: 0.0007776 (Best: 0.0005136 @iter1999) ([92m↓26.47%[0m) [0.17% of initial]
[Iter 2450/20000] Loss: 0.0006822 (Best: 0.0005136 @iter1999) ([92m↓12.26%[0m) [0.15% of initial]
[Iter 2460/20000] Loss: 0.0007021 (Best: 0.0005136 @iter1999) ([91m↑2.91%[0m) [0.15% of initial]
[Iter 2470/20000] Loss: 0.0006338 (Best: 0.0005136 @iter1999) ([92m↓9.72%[0m) [0.14% of initial]
[Iter 2480/20000] Loss: 0.0006115 (Best: 0.0005136 @iter1999) ([92m↓3.53%[0m) [0.13% of initial]
[Iter 2490/20000] Loss: 0.0005590 (Best: 0.0005136 @iter1999) ([92m↓8.58%[0m) [0.12% of initial]
Iter:2499, L1 loss=0.0005007, Total loss=0.000574, Time:16
[Iter 2500/20000] Loss: 0.0005415 (Best: 0.0005123 @iter2498) ([92m↓3.14%[0m) [0.12% of initial]
Pruning 506 points (6.0%) from gaussian0 at iteration 2500
Pruning 610 points (7.9%) from gaussian1 at iteration 2500
[Iter 2510/20000] Loss: 0.0014183 (Best: 0.0005123 @iter2498) ([91m↑161.94%[0m) [0.31% of initial]
[Iter 2520/20000] Loss: 0.0008887 (Best: 0.0005123 @iter2498) ([92m↓37.34%[0m) [0.19% of initial]
[Iter 2530/20000] Loss: 0.0007284 (Best: 0.0005123 @iter2498) ([92m↓18.04%[0m) [0.16% of initial]
[Iter 2540/20000] Loss: 0.0006487 (Best: 0.0005123 @iter2498) ([92m↓10.94%[0m) [0.14% of initial]
[Iter 2550/20000] Loss: 0.0005802 (Best: 0.0005123 @iter2498) ([92m↓10.56%[0m) [0.13% of initial]
[Iter 2560/20000] Loss: 0.0005460 (Best: 0.0004890 @iter2554) ([92m↓5.89%[0m) [0.12% of initial]
[Iter 2570/20000] Loss: 0.0005265 (Best: 0.0004890 @iter2554) ([92m↓3.57%[0m) [0.11% of initial]
[Iter 2580/20000] Loss: 0.0005208 (Best: 0.0004805 @iter2576) ([92m↓1.08%[0m) [0.11% of initial]
[Iter 2590/20000] Loss: 0.0005120 (Best: 0.0004757 @iter2590) ([92m↓1.70%[0m) [0.11% of initial]
Iter:2599, L1 loss=0.0004822, Total loss=0.0005007, Time:15
[Iter 2600/20000] Loss: 0.0005003 (Best: 0.0004742 @iter2593) ([92m↓2.28%[0m) [0.11% of initial]
[Iter 2610/20000] Loss: 0.0037059 (Best: 0.0004742 @iter2593) ([91m↑640.73%[0m) [0.80% of initial]
[Iter 2620/20000] Loss: 0.0015156 (Best: 0.0004742 @iter2593) ([92m↓59.10%[0m) [0.33% of initial]
[Iter 2630/20000] Loss: 0.0010556 (Best: 0.0004742 @iter2593) ([92m↓30.35%[0m) [0.23% of initial]
[Iter 2640/20000] Loss: 0.0007205 (Best: 0.0004742 @iter2593) ([92m↓31.75%[0m) [0.16% of initial]
[Iter 2650/20000] Loss: 0.0005938 (Best: 0.0004742 @iter2593) ([92m↓17.58%[0m) [0.13% of initial]
[Iter 2660/20000] Loss: 0.0005701 (Best: 0.0004742 @iter2593) ([92m↓4.01%[0m) [0.12% of initial]
[Iter 2670/20000] Loss: 0.0005354 (Best: 0.0004742 @iter2593) ([92m↓6.08%[0m) [0.12% of initial]
[Iter 2680/20000] Loss: 0.0005097 (Best: 0.0004739 @iter2679) ([92m↓4.81%[0m) [0.11% of initial]
[Iter 2690/20000] Loss: 0.0004994 (Best: 0.0004618 @iter2683) ([92m↓2.01%[0m) [0.11% of initial]
Iter:2699, L1 loss=0.000474, Total loss=0.0004967, Time:16
[Iter 2700/20000] Loss: 0.0004907 (Best: 0.0004618 @iter2683) ([92m↓1.74%[0m) [0.11% of initial]
[Iter 2710/20000] Loss: 0.0004563 (Best: 0.0004265 @iter2710) ([92m↓7.02%[0m) [0.10% of initial]
[Iter 2720/20000] Loss: 0.0004604 (Best: 0.0004265 @iter2710) ([91m↑0.92%[0m) [0.10% of initial]
[Iter 2730/20000] Loss: 0.0004567 (Best: 0.0004265 @iter2710) ([92m↓0.81%[0m) [0.10% of initial]
[Iter 2740/20000] Loss: 0.0004618 (Best: 0.0004135 @iter2737) ([91m↑1.11%[0m) [0.10% of initial]
[Iter 2750/20000] Loss: 0.0004391 (Best: 0.0004135 @iter2737) ([92m↓4.91%[0m) [0.10% of initial]
[Iter 2760/20000] Loss: 0.0004638 (Best: 0.0004135 @iter2737) ([91m↑5.61%[0m) [0.10% of initial]
[Iter 2770/20000] Loss: 0.0004497 (Best: 0.0004135 @iter2737) ([92m↓3.03%[0m) [0.10% of initial]
[Iter 2780/20000] Loss: 0.0004294 (Best: 0.0004084 @iter2776) ([92m↓4.52%[0m) [0.09% of initial]
[Iter 2790/20000] Loss: 0.0004558 (Best: 0.0004084 @iter2776) ([91m↑6.16%[0m) [0.10% of initial]
Iter:2799, L1 loss=0.000429, Total loss=0.0004559, Time:10
[Iter 2800/20000] Loss: 0.0004715 (Best: 0.0004084 @iter2776) ([91m↑3.43%[0m) [0.10% of initial]
[Iter 2810/20000] Loss: 0.0022093 (Best: 0.0004084 @iter2776) ([91m↑368.60%[0m) [0.48% of initial]
[Iter 2820/20000] Loss: 0.0012567 (Best: 0.0004084 @iter2776) ([92m↓43.12%[0m) [0.27% of initial]
[Iter 2830/20000] Loss: 0.0007740 (Best: 0.0004084 @iter2776) ([92m↓38.41%[0m) [0.17% of initial]
[Iter 2840/20000] Loss: 0.0006154 (Best: 0.0004084 @iter2776) ([92m↓20.49%[0m) [0.13% of initial]
[Iter 2850/20000] Loss: 0.0005546 (Best: 0.0004084 @iter2776) ([92m↓9.88%[0m) [0.12% of initial]
[Iter 2860/20000] Loss: 0.0004996 (Best: 0.0004084 @iter2776) ([92m↓9.92%[0m) [0.11% of initial]
[Iter 2870/20000] Loss: 0.0005684 (Best: 0.0004084 @iter2776) ([91m↑13.78%[0m) [0.12% of initial]
[Iter 2880/20000] Loss: 0.0005726 (Best: 0.0004084 @iter2776) ([91m↑0.73%[0m) [0.12% of initial]
[Iter 2890/20000] Loss: 0.0004871 (Best: 0.0004084 @iter2776) ([92m↓14.92%[0m) [0.11% of initial]
Iter:2899, L1 loss=0.0004297, Total loss=0.0005215, Time:9
[Iter 2900/20000] Loss: 0.0004954 (Best: 0.0004084 @iter2776) ([91m↑1.71%[0m) [0.11% of initial]
[Iter 2910/20000] Loss: 0.0004520 (Best: 0.0004084 @iter2776) ([92m↓8.77%[0m) [0.10% of initial]
[Iter 2920/20000] Loss: 0.0004469 (Best: 0.0004084 @iter2776) ([92m↓1.12%[0m) [0.10% of initial]
[Iter 2930/20000] Loss: 0.0004125 (Best: 0.0003971 @iter2927) ([92m↓7.70%[0m) [0.09% of initial]
[Iter 2940/20000] Loss: 0.0004126 (Best: 0.0003846 @iter2938) ([91m↑0.02%[0m) [0.09% of initial]
[Iter 2950/20000] Loss: 0.0004110 (Best: 0.0003846 @iter2938) ([92m↓0.40%[0m) [0.09% of initial]
[Iter 2960/20000] Loss: 0.0003922 (Best: 0.0003681 @iter2956) ([92m↓4.56%[0m) [0.09% of initial]
[Iter 2970/20000] Loss: 0.0003777 (Best: 0.0003681 @iter2956) ([92m↓3.69%[0m) [0.08% of initial]
[Iter 2980/20000] Loss: 0.0003858 (Best: 0.0003532 @iter2974) ([91m↑2.14%[0m) [0.08% of initial]
[Iter 2990/20000] Loss: 0.0003686 (Best: 0.0003532 @iter2974) ([92m↓4.47%[0m) [0.08% of initial]
Iter:2999, L1 loss=0.0003814, Total loss=0.000371, Time:11
[Iter 3000/20000] Loss: 0.0003746 (Best: 0.0003532 @iter2974) ([91m↑1.63%[0m) [0.08% of initial]
Pruning 560 points (5.1%) from gaussian0 at iteration 3000
Pruning 521 points (5.2%) from gaussian1 at iteration 3000
[Iter 3010/20000] Loss: 0.0025132 (Best: 0.0003532 @iter2974) ([91m↑570.95%[0m) [0.55% of initial]
[Iter 3020/20000] Loss: 0.0011841 (Best: 0.0003532 @iter2974) ([92m↓52.88%[0m) [0.26% of initial]
[Iter 3030/20000] Loss: 0.0009836 (Best: 0.0003532 @iter2974) ([92m↓16.94%[0m) [0.21% of initial]
[Iter 3040/20000] Loss: 0.0007642 (Best: 0.0003532 @iter2974) ([92m↓22.30%[0m) [0.17% of initial]
[Iter 3050/20000] Loss: 0.0007161 (Best: 0.0003532 @iter2974) ([92m↓6.30%[0m) [0.16% of initial]
[Iter 3060/20000] Loss: 0.0006531 (Best: 0.0003532 @iter2974) ([92m↓8.80%[0m) [0.14% of initial]
[Iter 3070/20000] Loss: 0.0005745 (Best: 0.0003532 @iter2974) ([92m↓12.04%[0m) [0.12% of initial]
[Iter 3080/20000] Loss: 0.0005447 (Best: 0.0003532 @iter2974) ([92m↓5.18%[0m) [0.12% of initial]
[Iter 3090/20000] Loss: 0.0005344 (Best: 0.0003532 @iter2974) ([92m↓1.90%[0m) [0.12% of initial]
Iter:3099, L1 loss=0.0004926, Total loss=0.0005141, Time:11
[Iter 3100/20000] Loss: 0.0004837 (Best: 0.0003532 @iter2974) ([92m↓9.49%[0m) [0.10% of initial]
[Iter 3110/20000] Loss: 0.0004925 (Best: 0.0003532 @iter2974) ([91m↑1.84%[0m) [0.11% of initial]
[Iter 3120/20000] Loss: 0.0005723 (Best: 0.0003532 @iter2974) ([91m↑16.20%[0m) [0.12% of initial]
[Iter 3130/20000] Loss: 0.0004877 (Best: 0.0003532 @iter2974) ([92m↓14.78%[0m) [0.11% of initial]
[Iter 3140/20000] Loss: 0.0004581 (Best: 0.0003532 @iter2974) ([92m↓6.08%[0m) [0.10% of initial]
[Iter 3150/20000] Loss: 0.0007173 (Best: 0.0003532 @iter2974) ([91m↑56.59%[0m) [0.16% of initial]
[Iter 3160/20000] Loss: 0.0005506 (Best: 0.0003532 @iter2974) ([92m↓23.25%[0m) [0.12% of initial]
[Iter 3170/20000] Loss: 0.0004832 (Best: 0.0003532 @iter2974) ([92m↓12.23%[0m) [0.10% of initial]
[Iter 3180/20000] Loss: 0.0004702 (Best: 0.0003532 @iter2974) ([92m↓2.70%[0m) [0.10% of initial]
[Iter 3190/20000] Loss: 0.0004393 (Best: 0.0003532 @iter2974) ([92m↓6.58%[0m) [0.10% of initial]
Iter:3199, L1 loss=0.0004165, Total loss=0.0004138, Time:17
[Iter 3200/20000] Loss: 0.0004087 (Best: 0.0003532 @iter2974) ([92m↓6.95%[0m) [0.09% of initial]
[Iter 3210/20000] Loss: 0.0019502 (Best: 0.0003532 @iter2974) ([91m↑377.16%[0m) [0.42% of initial]
[Iter 3220/20000] Loss: 0.0011767 (Best: 0.0003532 @iter2974) ([92m↓39.66%[0m) [0.26% of initial]
[Iter 3230/20000] Loss: 0.0007986 (Best: 0.0003532 @iter2974) ([92m↓32.13%[0m) [0.17% of initial]
[Iter 3240/20000] Loss: 0.0006218 (Best: 0.0003532 @iter2974) ([92m↓22.14%[0m) [0.13% of initial]
[Iter 3250/20000] Loss: 0.0005133 (Best: 0.0003532 @iter2974) ([92m↓17.45%[0m) [0.11% of initial]
[Iter 3260/20000] Loss: 0.0005018 (Best: 0.0003532 @iter2974) ([92m↓2.23%[0m) [0.11% of initial]
[Iter 3270/20000] Loss: 0.0004504 (Best: 0.0003532 @iter2974) ([92m↓10.25%[0m) [0.10% of initial]
[Iter 3280/20000] Loss: 0.0004253 (Best: 0.0003532 @iter2974) ([92m↓5.58%[0m) [0.09% of initial]
[Iter 3290/20000] Loss: 0.0004135 (Best: 0.0003532 @iter2974) ([92m↓2.77%[0m) [0.09% of initial]
Iter:3299, L1 loss=0.0004753, Total loss=0.0004204, Time:16
[Iter 3300/20000] Loss: 0.0004178 (Best: 0.0003532 @iter2974) ([91m↑1.06%[0m) [0.09% of initial]
[Iter 3310/20000] Loss: 0.0004489 (Best: 0.0003532 @iter2974) ([91m↑7.42%[0m) [0.10% of initial]
[Iter 3320/20000] Loss: 0.0005093 (Best: 0.0003532 @iter2974) ([91m↑13.46%[0m) [0.11% of initial]
[Iter 3330/20000] Loss: 0.0004472 (Best: 0.0003532 @iter2974) ([92m↓12.18%[0m) [0.10% of initial]
[Iter 3340/20000] Loss: 0.0004192 (Best: 0.0003532 @iter2974) ([92m↓6.27%[0m) [0.09% of initial]
[Iter 3350/20000] Loss: 0.0005297 (Best: 0.0003532 @iter2974) ([91m↑26.36%[0m) [0.11% of initial]
[Iter 3360/20000] Loss: 0.0004596 (Best: 0.0003532 @iter2974) ([92m↓13.23%[0m) [0.10% of initial]
[Iter 3370/20000] Loss: 0.0003994 (Best: 0.0003532 @iter2974) ([92m↓13.10%[0m) [0.09% of initial]
[Iter 3380/20000] Loss: 0.0003695 (Best: 0.0003532 @iter2974) ([92m↓7.49%[0m) [0.08% of initial]
[Iter 3390/20000] Loss: 0.0003720 (Best: 0.0003482 @iter3388) ([91m↑0.68%[0m) [0.08% of initial]
Iter:3399, L1 loss=0.0003308, Total loss=0.0003547, Time:16
[Iter 3400/20000] Loss: 0.0003616 (Best: 0.0003482 @iter3388) ([92m↓2.78%[0m) [0.08% of initial]
[Iter 3410/20000] Loss: 0.0014306 (Best: 0.0003482 @iter3388) ([91m↑295.58%[0m) [0.31% of initial]
[Iter 3420/20000] Loss: 0.0008753 (Best: 0.0003482 @iter3388) ([92m↓38.82%[0m) [0.19% of initial]
[Iter 3430/20000] Loss: 0.0005856 (Best: 0.0003482 @iter3388) ([92m↓33.09%[0m) [0.13% of initial]
[Iter 3440/20000] Loss: 0.0005225 (Best: 0.0003482 @iter3388) ([92m↓10.78%[0m) [0.11% of initial]
[Iter 3450/20000] Loss: 0.0004812 (Best: 0.0003482 @iter3388) ([92m↓7.91%[0m) [0.10% of initial]
[Iter 3460/20000] Loss: 0.0004491 (Best: 0.0003482 @iter3388) ([92m↓6.67%[0m) [0.10% of initial]
[Iter 3470/20000] Loss: 0.0004342 (Best: 0.0003482 @iter3388) ([92m↓3.32%[0m) [0.09% of initial]
[Iter 3480/20000] Loss: 0.0003777 (Best: 0.0003482 @iter3388) ([92m↓13.01%[0m) [0.08% of initial]
[Iter 3490/20000] Loss: 0.0003822 (Best: 0.0003482 @iter3388) ([91m↑1.19%[0m) [0.08% of initial]
Iter:3499, L1 loss=0.0003346, Total loss=0.0003827, Time:17
[Iter 3500/20000] Loss: 0.0003735 (Best: 0.0003482 @iter3388) ([92m↓2.26%[0m) [0.08% of initial]
Pruning 485 points (4.0%) from gaussian0 at iteration 3500
Pruning 505 points (4.7%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0007422 (Best: 0.0003482 @iter3388) ([91m↑98.70%[0m) [0.16% of initial]
[Iter 3520/20000] Loss: 0.0004835 (Best: 0.0003482 @iter3388) ([92m↓34.85%[0m) [0.10% of initial]
[Iter 3530/20000] Loss: 0.0004289 (Best: 0.0003482 @iter3388) ([92m↓11.30%[0m) [0.09% of initial]
[Iter 3540/20000] Loss: 0.0004024 (Best: 0.0003482 @iter3388) ([92m↓6.17%[0m) [0.09% of initial]
[Iter 3550/20000] Loss: 0.0003862 (Best: 0.0003452 @iter3547) ([92m↓4.02%[0m) [0.08% of initial]
[Iter 3560/20000] Loss: 0.0003880 (Best: 0.0003452 @iter3547) ([91m↑0.46%[0m) [0.08% of initial]
[Iter 3570/20000] Loss: 0.0003749 (Best: 0.0003452 @iter3547) ([92m↓3.39%[0m) [0.08% of initial]
[Iter 3580/20000] Loss: 0.0003680 (Best: 0.0003452 @iter3547) ([92m↓1.84%[0m) [0.08% of initial]
[Iter 3590/20000] Loss: 0.0003485 (Best: 0.0003341 @iter3588) ([92m↓5.28%[0m) [0.08% of initial]
Iter:3599, L1 loss=0.0003278, Total loss=0.0003615, Time:17
[Iter 3600/20000] Loss: 0.0003525 (Best: 0.0003192 @iter3595) ([91m↑1.14%[0m) [0.08% of initial]
[Iter 3610/20000] Loss: 0.0013325 (Best: 0.0003192 @iter3595) ([91m↑277.99%[0m) [0.29% of initial]
[Iter 3620/20000] Loss: 0.0008844 (Best: 0.0003192 @iter3595) ([92m↓33.63%[0m) [0.19% of initial]
[Iter 3630/20000] Loss: 0.0005673 (Best: 0.0003192 @iter3595) ([92m↓35.85%[0m) [0.12% of initial]
[Iter 3640/20000] Loss: 0.0004676 (Best: 0.0003192 @iter3595) ([92m↓17.58%[0m) [0.10% of initial]
[Iter 3650/20000] Loss: 0.0004264 (Best: 0.0003192 @iter3595) ([92m↓8.80%[0m) [0.09% of initial]
[Iter 3660/20000] Loss: 0.0003972 (Best: 0.0003192 @iter3595) ([92m↓6.86%[0m) [0.09% of initial]
[Iter 3670/20000] Loss: 0.0003699 (Best: 0.0003192 @iter3595) ([92m↓6.88%[0m) [0.08% of initial]
[Iter 3680/20000] Loss: 0.0003486 (Best: 0.0003192 @iter3595) ([92m↓5.75%[0m) [0.08% of initial]
[Iter 3690/20000] Loss: 0.0003434 (Best: 0.0003192 @iter3595) ([92m↓1.50%[0m) [0.07% of initial]
Iter:3699, L1 loss=0.0003218, Total loss=0.0003592, Time:15
[Iter 3700/20000] Loss: 0.0003340 (Best: 0.0003155 @iter3691) ([92m↓2.73%[0m) [0.07% of initial]
[Iter 3710/20000] Loss: 0.0003183 (Best: 0.0003124 @iter3710) ([92m↓4.70%[0m) [0.07% of initial]
[Iter 3720/20000] Loss: 0.0003178 (Best: 0.0003067 @iter3718) ([92m↓0.16%[0m) [0.07% of initial]
[Iter 3730/20000] Loss: 0.0003105 (Best: 0.0003004 @iter3722) ([92m↓2.31%[0m) [0.07% of initial]
[Iter 3740/20000] Loss: 0.0003035 (Best: 0.0002917 @iter3733) ([92m↓2.25%[0m) [0.07% of initial]
[Iter 3750/20000] Loss: 0.0003076 (Best: 0.0002917 @iter3733) ([91m↑1.37%[0m) [0.07% of initial]
[Iter 3760/20000] Loss: 0.0003510 (Best: 0.0002917 @iter3733) ([91m↑14.10%[0m) [0.08% of initial]
[Iter 3770/20000] Loss: 0.0003506 (Best: 0.0002917 @iter3733) ([92m↓0.12%[0m) [0.08% of initial]
[Iter 3780/20000] Loss: 0.0003407 (Best: 0.0002917 @iter3733) ([92m↓2.81%[0m) [0.07% of initial]
[Iter 3790/20000] Loss: 0.0003259 (Best: 0.0002917 @iter3733) ([92m↓4.36%[0m) [0.07% of initial]
Iter:3799, L1 loss=0.0002791, Total loss=0.0003356, Time:12
[Iter 3800/20000] Loss: 0.0003318 (Best: 0.0002917 @iter3733) ([91m↑1.81%[0m) [0.07% of initial]
[Iter 3810/20000] Loss: 0.0012507 (Best: 0.0002917 @iter3733) ([91m↑276.97%[0m) [0.27% of initial]
[Iter 3820/20000] Loss: 0.0007644 (Best: 0.0002917 @iter3733) ([92m↓38.88%[0m) [0.17% of initial]
[Iter 3830/20000] Loss: 0.0004912 (Best: 0.0002917 @iter3733) ([92m↓35.75%[0m) [0.11% of initial]
[Iter 3840/20000] Loss: 0.0004352 (Best: 0.0002917 @iter3733) ([92m↓11.38%[0m) [0.09% of initial]
[Iter 3850/20000] Loss: 0.0003901 (Best: 0.0002917 @iter3733) ([92m↓10.36%[0m) [0.08% of initial]
[Iter 3860/20000] Loss: 0.0003507 (Best: 0.0002917 @iter3733) ([92m↓10.12%[0m) [0.08% of initial]
[Iter 3870/20000] Loss: 0.0003251 (Best: 0.0002917 @iter3733) ([92m↓7.28%[0m) [0.07% of initial]
[Iter 3880/20000] Loss: 0.0003219 (Best: 0.0002917 @iter3733) ([92m↓1.00%[0m) [0.07% of initial]
[Iter 3890/20000] Loss: 0.0003089 (Best: 0.0002891 @iter3888) ([92m↓4.03%[0m) [0.07% of initial]
Iter:3899, L1 loss=0.0002826, Total loss=0.0003133, Time:16
[Iter 3900/20000] Loss: 0.0002985 (Best: 0.0002733 @iter3896) ([92m↓3.36%[0m) [0.06% of initial]
[Iter 3910/20000] Loss: 0.0002972 (Best: 0.0002733 @iter3896) ([92m↓0.45%[0m) [0.06% of initial]
[Iter 3920/20000] Loss: 0.0002780 (Best: 0.0002712 @iter3920) ([92m↓6.45%[0m) [0.06% of initial]
[Iter 3930/20000] Loss: 0.0002832 (Best: 0.0002712 @iter3920) ([91m↑1.88%[0m) [0.06% of initial]
[Iter 3940/20000] Loss: 0.0002953 (Best: 0.0002644 @iter3934) ([91m↑4.25%[0m) [0.06% of initial]
[Iter 3950/20000] Loss: 0.0002951 (Best: 0.0002644 @iter3934) ([92m↓0.06%[0m) [0.06% of initial]
[Iter 3960/20000] Loss: 0.0003026 (Best: 0.0002644 @iter3934) ([91m↑2.56%[0m) [0.07% of initial]
[Iter 3970/20000] Loss: 0.0002804 (Best: 0.0002644 @iter3934) ([92m↓7.35%[0m) [0.06% of initial]
[Iter 3980/20000] Loss: 0.0003017 (Best: 0.0002644 @iter3934) ([91m↑7.59%[0m) [0.07% of initial]
[Iter 3990/20000] Loss: 0.0002784 (Best: 0.0002640 @iter3989) ([92m↓7.74%[0m) [0.06% of initial]
Iter:3999, L1 loss=0.0002609, Total loss=0.0002659, Time:17
[Iter 4000/20000] Loss: 0.0002690 (Best: 0.0002627 @iter3995) ([92m↓3.36%[0m) [0.06% of initial]
Pruning 440 points (3.4%) from gaussian0 at iteration 4000
Pruning 461 points (4.1%) from gaussian1 at iteration 4000
[Iter 4010/20000] Loss: 0.0498433 (Best: 0.0002627 @iter3995) ([91m↑18429.40%[0m) [10.81% of initial]
[Iter 4020/20000] Loss: 0.0327545 (Best: 0.0002627 @iter3995) ([92m↓34.29%[0m) [7.11% of initial]
[Iter 4030/20000] Loss: 0.0174432 (Best: 0.0002627 @iter3995) ([92m↓46.75%[0m) [3.78% of initial]
[Iter 4040/20000] Loss: 0.0070037 (Best: 0.0002627 @iter3995) ([92m↓59.85%[0m) [1.52% of initial]
[Iter 4050/20000] Loss: 0.0025465 (Best: 0.0002627 @iter3995) ([92m↓63.64%[0m) [0.55% of initial]
[Iter 4060/20000] Loss: 0.0017718 (Best: 0.0002627 @iter3995) ([92m↓30.42%[0m) [0.38% of initial]
[Iter 4070/20000] Loss: 0.0013764 (Best: 0.0002627 @iter3995) ([92m↓22.32%[0m) [0.30% of initial]
[Iter 4080/20000] Loss: 0.0011487 (Best: 0.0002627 @iter3995) ([92m↓16.54%[0m) [0.25% of initial]
[Iter 4090/20000] Loss: 0.0010019 (Best: 0.0002627 @iter3995) ([92m↓12.78%[0m) [0.22% of initial]
Iter:4099, L1 loss=0.000783, Total loss=0.0009407, Time:13
[Iter 4100/20000] Loss: 0.0009444 (Best: 0.0002627 @iter3995) ([92m↓5.75%[0m) [0.20% of initial]
[Iter 4110/20000] Loss: 0.0008547 (Best: 0.0002627 @iter3995) ([92m↓9.49%[0m) [0.19% of initial]
[Iter 4120/20000] Loss: 0.0008410 (Best: 0.0002627 @iter3995) ([92m↓1.61%[0m) [0.18% of initial]
[Iter 4130/20000] Loss: 0.0007289 (Best: 0.0002627 @iter3995) ([92m↓13.33%[0m) [0.16% of initial]
[Iter 4140/20000] Loss: 0.0007542 (Best: 0.0002627 @iter3995) ([91m↑3.47%[0m) [0.16% of initial]
[Iter 4150/20000] Loss: 0.0006856 (Best: 0.0002627 @iter3995) ([92m↓9.10%[0m) [0.15% of initial]
[Iter 4160/20000] Loss: 0.0006854 (Best: 0.0002627 @iter3995) ([92m↓0.03%[0m) [0.15% of initial]
[Iter 4170/20000] Loss: 0.0006679 (Best: 0.0002627 @iter3995) ([92m↓2.55%[0m) [0.14% of initial]
[Iter 4180/20000] Loss: 0.0006454 (Best: 0.0002627 @iter3995) ([92m↓3.37%[0m) [0.14% of initial]
[Iter 4190/20000] Loss: 0.0006552 (Best: 0.0002627 @iter3995) ([91m↑1.52%[0m) [0.14% of initial]
Iter:4199, L1 loss=0.0005899, Total loss=0.0006582, Time:13
[Iter 4200/20000] Loss: 0.0006515 (Best: 0.0002627 @iter3995) ([92m↓0.56%[0m) [0.14% of initial]
[Iter 4210/20000] Loss: 0.0024312 (Best: 0.0002627 @iter3995) ([91m↑273.17%[0m) [0.53% of initial]
[Iter 4220/20000] Loss: 0.0018473 (Best: 0.0002627 @iter3995) ([92m↓24.02%[0m) [0.40% of initial]
[Iter 4230/20000] Loss: 0.0010309 (Best: 0.0002627 @iter3995) ([92m↓44.20%[0m) [0.22% of initial]
[Iter 4240/20000] Loss: 0.0007960 (Best: 0.0002627 @iter3995) ([92m↓22.78%[0m) [0.17% of initial]
[Iter 4250/20000] Loss: 0.0007332 (Best: 0.0002627 @iter3995) ([92m↓7.89%[0m) [0.16% of initial]
[Iter 4260/20000] Loss: 0.0006714 (Best: 0.0002627 @iter3995) ([92m↓8.43%[0m) [0.15% of initial]
[Iter 4270/20000] Loss: 0.0006163 (Best: 0.0002627 @iter3995) ([92m↓8.20%[0m) [0.13% of initial]
[Iter 4280/20000] Loss: 0.0006230 (Best: 0.0002627 @iter3995) ([91m↑1.08%[0m) [0.14% of initial]
[Iter 4290/20000] Loss: 0.0006009 (Best: 0.0002627 @iter3995) ([92m↓3.54%[0m) [0.13% of initial]
Iter:4299, L1 loss=0.0005355, Total loss=0.0005705, Time:12
[Iter 4300/20000] Loss: 0.0005827 (Best: 0.0002627 @iter3995) ([92m↓3.03%[0m) [0.13% of initial]
[Iter 4310/20000] Loss: 0.0005762 (Best: 0.0002627 @iter3995) ([92m↓1.13%[0m) [0.12% of initial]
[Iter 4320/20000] Loss: 0.0005605 (Best: 0.0002627 @iter3995) ([92m↓2.72%[0m) [0.12% of initial]
[Iter 4330/20000] Loss: 0.0005390 (Best: 0.0002627 @iter3995) ([92m↓3.83%[0m) [0.12% of initial]
[Iter 4340/20000] Loss: 0.0005332 (Best: 0.0002627 @iter3995) ([92m↓1.09%[0m) [0.12% of initial]
[Iter 4350/20000] Loss: 0.0005231 (Best: 0.0002627 @iter3995) ([92m↓1.89%[0m) [0.11% of initial]
[Iter 4360/20000] Loss: 0.0005193 (Best: 0.0002627 @iter3995) ([92m↓0.72%[0m) [0.11% of initial]
[Iter 4370/20000] Loss: 0.0005045 (Best: 0.0002627 @iter3995) ([92m↓2.85%[0m) [0.11% of initial]
[Iter 4380/20000] Loss: 0.0005094 (Best: 0.0002627 @iter3995) ([91m↑0.97%[0m) [0.11% of initial]
[Iter 4390/20000] Loss: 0.0004925 (Best: 0.0002627 @iter3995) ([92m↓3.32%[0m) [0.11% of initial]
Iter:4399, L1 loss=0.0004681, Total loss=0.0004811, Time:12
[Iter 4400/20000] Loss: 0.0004864 (Best: 0.0002627 @iter3995) ([92m↓1.23%[0m) [0.11% of initial]
[Iter 4410/20000] Loss: 0.0010660 (Best: 0.0002627 @iter3995) ([91m↑119.14%[0m) [0.23% of initial]
[Iter 4420/20000] Loss: 0.0008615 (Best: 0.0002627 @iter3995) ([92m↓19.18%[0m) [0.19% of initial]
[Iter 4430/20000] Loss: 0.0006327 (Best: 0.0002627 @iter3995) ([92m↓26.56%[0m) [0.14% of initial]
[Iter 4440/20000] Loss: 0.0005486 (Best: 0.0002627 @iter3995) ([92m↓13.30%[0m) [0.12% of initial]
[Iter 4450/20000] Loss: 0.0005088 (Best: 0.0002627 @iter3995) ([92m↓7.24%[0m) [0.11% of initial]
[Iter 4460/20000] Loss: 0.0005009 (Best: 0.0002627 @iter3995) ([92m↓1.56%[0m) [0.11% of initial]
[Iter 4470/20000] Loss: 0.0004908 (Best: 0.0002627 @iter3995) ([92m↓2.01%[0m) [0.11% of initial]
[Iter 4480/20000] Loss: 0.0004694 (Best: 0.0002627 @iter3995) ([92m↓4.36%[0m) [0.10% of initial]
[Iter 4490/20000] Loss: 0.0004636 (Best: 0.0002627 @iter3995) ([92m↓1.24%[0m) [0.10% of initial]
Iter:4499, L1 loss=0.000447, Total loss=0.000466, Time:12
[Iter 4500/20000] Loss: 0.0004567 (Best: 0.0002627 @iter3995) ([92m↓1.48%[0m) [0.10% of initial]
Pruning 329 points (2.2%) from gaussian0 at iteration 4500
Pruning 370 points (2.8%) from gaussian1 at iteration 4500
[Iter 4510/20000] Loss: 0.0007329 (Best: 0.0002627 @iter3995) ([91m↑60.47%[0m) [0.16% of initial]
[Iter 4520/20000] Loss: 0.0005806 (Best: 0.0002627 @iter3995) ([92m↓20.78%[0m) [0.13% of initial]
[Iter 4530/20000] Loss: 0.0005170 (Best: 0.0002627 @iter3995) ([92m↓10.97%[0m) [0.11% of initial]
[Iter 4540/20000] Loss: 0.0004786 (Best: 0.0002627 @iter3995) ([92m↓7.43%[0m) [0.10% of initial]
[Iter 4550/20000] Loss: 0.0004505 (Best: 0.0002627 @iter3995) ([92m↓5.86%[0m) [0.10% of initial]
[Iter 4560/20000] Loss: 0.0004365 (Best: 0.0002627 @iter3995) ([92m↓3.09%[0m) [0.09% of initial]
[Iter 4570/20000] Loss: 0.0004342 (Best: 0.0002627 @iter3995) ([92m↓0.55%[0m) [0.09% of initial]
[Iter 4580/20000] Loss: 0.0004121 (Best: 0.0002627 @iter3995) ([92m↓5.08%[0m) [0.09% of initial]
[Iter 4590/20000] Loss: 0.0004148 (Best: 0.0002627 @iter3995) ([91m↑0.66%[0m) [0.09% of initial]
Iter:4599, L1 loss=0.0004053, Total loss=0.0004045, Time:13
[Iter 4600/20000] Loss: 0.0004005 (Best: 0.0002627 @iter3995) ([92m↓3.46%[0m) [0.09% of initial]
[Iter 4610/20000] Loss: 0.0007675 (Best: 0.0002627 @iter3995) ([91m↑91.65%[0m) [0.17% of initial]
[Iter 4620/20000] Loss: 0.0005967 (Best: 0.0002627 @iter3995) ([92m↓22.26%[0m) [0.13% of initial]
[Iter 4630/20000] Loss: 0.0004697 (Best: 0.0002627 @iter3995) ([92m↓21.27%[0m) [0.10% of initial]
[Iter 4640/20000] Loss: 0.0004267 (Best: 0.0002627 @iter3995) ([92m↓9.16%[0m) [0.09% of initial]
[Iter 4650/20000] Loss: 0.0004019 (Best: 0.0002627 @iter3995) ([92m↓5.80%[0m) [0.09% of initial]
[Iter 4660/20000] Loss: 0.0003908 (Best: 0.0002627 @iter3995) ([92m↓2.77%[0m) [0.08% of initial]
[Iter 4670/20000] Loss: 0.0003839 (Best: 0.0002627 @iter3995) ([92m↓1.78%[0m) [0.08% of initial]
[Iter 4680/20000] Loss: 0.0003665 (Best: 0.0002627 @iter3995) ([92m↓4.53%[0m) [0.08% of initial]
[Iter 4690/20000] Loss: 0.0003589 (Best: 0.0002627 @iter3995) ([92m↓2.07%[0m) [0.08% of initial]
Iter:4699, L1 loss=0.0003554, Total loss=0.0003537, Time:12
[Iter 4700/20000] Loss: 0.0003553 (Best: 0.0002627 @iter3995) ([92m↓0.99%[0m) [0.08% of initial]
[Iter 4710/20000] Loss: 0.0003492 (Best: 0.0002627 @iter3995) ([92m↓1.73%[0m) [0.08% of initial]
[Iter 4720/20000] Loss: 0.0003385 (Best: 0.0002627 @iter3995) ([92m↓3.06%[0m) [0.07% of initial]
[Iter 4730/20000] Loss: 0.0003403 (Best: 0.0002627 @iter3995) ([91m↑0.55%[0m) [0.07% of initial]
[Iter 4740/20000] Loss: 0.0003438 (Best: 0.0002627 @iter3995) ([91m↑1.03%[0m) [0.07% of initial]
[Iter 4750/20000] Loss: 0.0003305 (Best: 0.0002627 @iter3995) ([92m↓3.87%[0m) [0.07% of initial]
[Iter 4760/20000] Loss: 0.0003245 (Best: 0.0002627 @iter3995) ([92m↓1.83%[0m) [0.07% of initial]
[Iter 4770/20000] Loss: 0.0003268 (Best: 0.0002627 @iter3995) ([91m↑0.72%[0m) [0.07% of initial]
[Iter 4780/20000] Loss: 0.0003219 (Best: 0.0002627 @iter3995) ([92m↓1.51%[0m) [0.07% of initial]
[Iter 4790/20000] Loss: 0.0003181 (Best: 0.0002627 @iter3995) ([92m↓1.18%[0m) [0.07% of initial]
Iter:4799, L1 loss=0.0003244, Total loss=0.0003218, Time:17
[Iter 4800/20000] Loss: 0.0003180 (Best: 0.0002627 @iter3995) ([92m↓0.03%[0m) [0.07% of initial]
[Iter 4810/20000] Loss: 0.0006049 (Best: 0.0002627 @iter3995) ([91m↑90.25%[0m) [0.13% of initial]
[Iter 4820/20000] Loss: 0.0004769 (Best: 0.0002627 @iter3995) ([92m↓21.16%[0m) [0.10% of initial]
[Iter 4830/20000] Loss: 0.0003799 (Best: 0.0002627 @iter3995) ([92m↓20.35%[0m) [0.08% of initial]
[Iter 4840/20000] Loss: 0.0003381 (Best: 0.0002627 @iter3995) ([92m↓10.98%[0m) [0.07% of initial]
[Iter 4850/20000] Loss: 0.0003228 (Best: 0.0002627 @iter3995) ([92m↓4.53%[0m) [0.07% of initial]
[Iter 4860/20000] Loss: 0.0003144 (Best: 0.0002627 @iter3995) ([92m↓2.60%[0m) [0.07% of initial]
[Iter 4870/20000] Loss: 0.0003064 (Best: 0.0002627 @iter3995) ([92m↓2.56%[0m) [0.07% of initial]
[Iter 4880/20000] Loss: 0.0003010 (Best: 0.0002627 @iter3995) ([92m↓1.76%[0m) [0.07% of initial]
[Iter 4890/20000] Loss: 0.0003013 (Best: 0.0002627 @iter3995) ([91m↑0.12%[0m) [0.07% of initial]
Iter:4899, L1 loss=0.0003061, Total loss=0.0002987, Time:16
[Iter 4900/20000] Loss: 0.0002935 (Best: 0.0002627 @iter3995) ([92m↓2.60%[0m) [0.06% of initial]
[Iter 4910/20000] Loss: 0.0002914 (Best: 0.0002627 @iter3995) ([92m↓0.71%[0m) [0.06% of initial]
[Iter 4920/20000] Loss: 0.0002939 (Best: 0.0002627 @iter3995) ([91m↑0.85%[0m) [0.06% of initial]
[Iter 4930/20000] Loss: 0.0002920 (Best: 0.0002627 @iter3995) ([92m↓0.66%[0m) [0.06% of initial]
[Iter 4940/20000] Loss: 0.0002815 (Best: 0.0002627 @iter3995) ([92m↓3.59%[0m) [0.06% of initial]
[Iter 4950/20000] Loss: 0.0002809 (Best: 0.0002627 @iter3995) ([92m↓0.21%[0m) [0.06% of initial]
[Iter 4960/20000] Loss: 0.0002762 (Best: 0.0002627 @iter3995) ([92m↓1.68%[0m) [0.06% of initial]
[Iter 4970/20000] Loss: 0.0002756 (Best: 0.0002627 @iter3995) ([92m↓0.21%[0m) [0.06% of initial]
[Iter 4980/20000] Loss: 0.0002729 (Best: 0.0002627 @iter3995) ([92m↓0.96%[0m) [0.06% of initial]
[Iter 4990/20000] Loss: 0.0002662 (Best: 0.0002624 @iter4990) ([92m↓2.45%[0m) [0.06% of initial]
Iter:4999, L1 loss=0.0002803, Total loss=0.0002699, Time:34
[Iter 5000/20000] Loss: 0.0002709 (Best: 0.0002576 @iter4996) ([91m↑1.76%[0m) [0.06% of initial]
Pruning 349 points (3.1%) from gaussian0 at iteration 5000
Pruning 338 points (3.3%) from gaussian1 at iteration 5000
[Iter 5010/20000] Loss: 0.0010560 (Best: 0.0002576 @iter4996) ([91m↑289.76%[0m) [0.23% of initial]
[Iter 5020/20000] Loss: 0.0005718 (Best: 0.0002576 @iter4996) ([92m↓45.85%[0m) [0.12% of initial]
[Iter 5030/20000] Loss: 0.0004683 (Best: 0.0002576 @iter4996) ([92m↓18.11%[0m) [0.10% of initial]
[Iter 5040/20000] Loss: 0.0004010 (Best: 0.0002576 @iter4996) ([92m↓14.36%[0m) [0.09% of initial]
[Iter 5050/20000] Loss: 0.0003568 (Best: 0.0002576 @iter4996) ([92m↓11.02%[0m) [0.08% of initial]
[Iter 5060/20000] Loss: 0.0003377 (Best: 0.0002576 @iter4996) ([92m↓5.34%[0m) [0.07% of initial]
[Iter 5070/20000] Loss: 0.0003343 (Best: 0.0002576 @iter4996) ([92m↓1.01%[0m) [0.07% of initial]
[Iter 5080/20000] Loss: 0.0003164 (Best: 0.0002576 @iter4996) ([92m↓5.35%[0m) [0.07% of initial]
[Iter 5090/20000] Loss: 0.0003121 (Best: 0.0002576 @iter4996) ([92m↓1.36%[0m) [0.07% of initial]
Iter:5099, L1 loss=0.0003023, Total loss=0.000317, Time:16
[Iter 5100/20000] Loss: 0.0003139 (Best: 0.0002576 @iter4996) ([91m↑0.57%[0m) [0.07% of initial]
[Iter 5110/20000] Loss: 0.0003039 (Best: 0.0002576 @iter4996) ([92m↓3.19%[0m) [0.07% of initial]
[Iter 5120/20000] Loss: 0.0002935 (Best: 0.0002576 @iter4996) ([92m↓3.41%[0m) [0.06% of initial]
[Iter 5130/20000] Loss: 0.0002936 (Best: 0.0002576 @iter4996) ([91m↑0.04%[0m) [0.06% of initial]
[Iter 5140/20000] Loss: 0.0002862 (Best: 0.0002576 @iter4996) ([92m↓2.54%[0m) [0.06% of initial]
[Iter 5150/20000] Loss: 0.0002827 (Best: 0.0002576 @iter4996) ([92m↓1.20%[0m) [0.06% of initial]
[Iter 5160/20000] Loss: 0.0002839 (Best: 0.0002576 @iter4996) ([91m↑0.42%[0m) [0.06% of initial]
[Iter 5170/20000] Loss: 0.0002781 (Best: 0.0002576 @iter4996) ([92m↓2.04%[0m) [0.06% of initial]
[Iter 5180/20000] Loss: 0.0002772 (Best: 0.0002576 @iter4996) ([92m↓0.35%[0m) [0.06% of initial]
[Iter 5190/20000] Loss: 0.0002721 (Best: 0.0002576 @iter4996) ([92m↓1.84%[0m) [0.06% of initial]
Iter:5199, L1 loss=0.000274, Total loss=0.0002834, Time:18
[Iter 5200/20000] Loss: 0.0002764 (Best: 0.0002576 @iter4996) ([91m↑1.61%[0m) [0.06% of initial]
[Iter 5210/20000] Loss: 0.0013133 (Best: 0.0002576 @iter4996) ([91m↑375.09%[0m) [0.28% of initial]
[Iter 5220/20000] Loss: 0.0006528 (Best: 0.0002576 @iter4996) ([92m↓50.29%[0m) [0.14% of initial]
[Iter 5230/20000] Loss: 0.0004432 (Best: 0.0002576 @iter4996) ([92m↓32.11%[0m) [0.10% of initial]
[Iter 5240/20000] Loss: 0.0003604 (Best: 0.0002576 @iter4996) ([92m↓18.68%[0m) [0.08% of initial]
[Iter 5250/20000] Loss: 0.0003285 (Best: 0.0002576 @iter4996) ([92m↓8.87%[0m) [0.07% of initial]
[Iter 5260/20000] Loss: 0.0003002 (Best: 0.0002576 @iter4996) ([92m↓8.62%[0m) [0.07% of initial]
[Iter 5270/20000] Loss: 0.0002918 (Best: 0.0002576 @iter4996) ([92m↓2.80%[0m) [0.06% of initial]
[Iter 5280/20000] Loss: 0.0002845 (Best: 0.0002576 @iter4996) ([92m↓2.49%[0m) [0.06% of initial]
[Iter 5290/20000] Loss: 0.0002752 (Best: 0.0002576 @iter4996) ([92m↓3.27%[0m) [0.06% of initial]
Iter:5299, L1 loss=0.0002638, Total loss=0.0002682, Time:13
[Iter 5300/20000] Loss: 0.0002768 (Best: 0.0002576 @iter4996) ([91m↑0.60%[0m) [0.06% of initial]
[Iter 5310/20000] Loss: 0.0002669 (Best: 0.0002576 @iter4996) ([92m↓3.60%[0m) [0.06% of initial]
[Iter 5320/20000] Loss: 0.0002614 (Best: 0.0002522 @iter5320) ([92m↓2.05%[0m) [0.06% of initial]
[Iter 5330/20000] Loss: 0.0002634 (Best: 0.0002520 @iter5329) ([91m↑0.78%[0m) [0.06% of initial]
[Iter 5340/20000] Loss: 0.0002621 (Best: 0.0002520 @iter5329) ([92m↓0.51%[0m) [0.06% of initial]
[Iter 5350/20000] Loss: 0.0002616 (Best: 0.0002494 @iter5341) ([92m↓0.18%[0m) [0.06% of initial]
[Iter 5360/20000] Loss: 0.0002546 (Best: 0.0002494 @iter5341) ([92m↓2.69%[0m) [0.06% of initial]
[Iter 5370/20000] Loss: 0.0002520 (Best: 0.0002486 @iter5370) ([92m↓1.00%[0m) [0.05% of initial]
[Iter 5380/20000] Loss: 0.0002532 (Best: 0.0002420 @iter5374) ([91m↑0.47%[0m) [0.05% of initial]
[Iter 5390/20000] Loss: 0.0002585 (Best: 0.0002420 @iter5374) ([91m↑2.10%[0m) [0.06% of initial]
Iter:5399, L1 loss=0.0002528, Total loss=0.0002531, Time:14
[Iter 5400/20000] Loss: 0.0002490 (Best: 0.0002420 @iter5396) ([92m↓3.68%[0m) [0.05% of initial]
[Iter 5410/20000] Loss: 0.0010716 (Best: 0.0002420 @iter5396) ([91m↑330.37%[0m) [0.23% of initial]
[Iter 5420/20000] Loss: 0.0006107 (Best: 0.0002420 @iter5396) ([92m↓43.01%[0m) [0.13% of initial]
[Iter 5430/20000] Loss: 0.0003921 (Best: 0.0002420 @iter5396) ([92m↓35.79%[0m) [0.09% of initial]
[Iter 5440/20000] Loss: 0.0003146 (Best: 0.0002420 @iter5396) ([92m↓19.79%[0m) [0.07% of initial]
[Iter 5450/20000] Loss: 0.0002828 (Best: 0.0002420 @iter5396) ([92m↓10.11%[0m) [0.06% of initial]
[Iter 5460/20000] Loss: 0.0002738 (Best: 0.0002420 @iter5396) ([92m↓3.17%[0m) [0.06% of initial]
[Iter 5470/20000] Loss: 0.0002575 (Best: 0.0002420 @iter5396) ([92m↓5.95%[0m) [0.06% of initial]
[Iter 5480/20000] Loss: 0.0002553 (Best: 0.0002420 @iter5396) ([92m↓0.85%[0m) [0.06% of initial]
[Iter 5490/20000] Loss: 0.0002538 (Best: 0.0002420 @iter5396) ([92m↓0.61%[0m) [0.06% of initial]
Iter:5499, L1 loss=0.0002532, Total loss=0.0002573, Time:18
[Iter 5500/20000] Loss: 0.0002476 (Best: 0.0002396 @iter5500) ([92m↓2.41%[0m) [0.05% of initial]
Pruning 396 points (4.7%) from gaussian0 at iteration 5500
Pruning 293 points (4.0%) from gaussian1 at iteration 5500
[Iter 5510/20000] Loss: 0.0010456 (Best: 0.0002396 @iter5500) ([91m↑322.23%[0m) [0.23% of initial]
[Iter 5520/20000] Loss: 0.0005252 (Best: 0.0002396 @iter5500) ([92m↓49.77%[0m) [0.11% of initial]
[Iter 5530/20000] Loss: 0.0003885 (Best: 0.0002396 @iter5500) ([92m↓26.03%[0m) [0.08% of initial]
[Iter 5540/20000] Loss: 0.0003287 (Best: 0.0002396 @iter5500) ([92m↓15.39%[0m) [0.07% of initial]
[Iter 5550/20000] Loss: 0.0003012 (Best: 0.0002396 @iter5500) ([92m↓8.35%[0m) [0.07% of initial]
[Iter 5560/20000] Loss: 0.0002921 (Best: 0.0002396 @iter5500) ([92m↓3.02%[0m) [0.06% of initial]
[Iter 5570/20000] Loss: 0.0002833 (Best: 0.0002396 @iter5500) ([92m↓3.03%[0m) [0.06% of initial]
[Iter 5580/20000] Loss: 0.0002762 (Best: 0.0002396 @iter5500) ([92m↓2.52%[0m) [0.06% of initial]
[Iter 5590/20000] Loss: 0.0002739 (Best: 0.0002396 @iter5500) ([92m↓0.83%[0m) [0.06% of initial]
Iter:5599, L1 loss=0.0002515, Total loss=0.0002577, Time:14
[Iter 5600/20000] Loss: 0.0002684 (Best: 0.0002396 @iter5500) ([92m↓1.99%[0m) [0.06% of initial]
[Iter 5610/20000] Loss: 0.0017969 (Best: 0.0002396 @iter5500) ([91m↑569.44%[0m) [0.39% of initial]
[Iter 5620/20000] Loss: 0.0009460 (Best: 0.0002396 @iter5500) ([92m↓47.35%[0m) [0.21% of initial]
[Iter 5630/20000] Loss: 0.0005376 (Best: 0.0002396 @iter5500) ([92m↓43.17%[0m) [0.12% of initial]
[Iter 5640/20000] Loss: 0.0004061 (Best: 0.0002396 @iter5500) ([92m↓24.46%[0m) [0.09% of initial]
[Iter 5650/20000] Loss: 0.0003501 (Best: 0.0002396 @iter5500) ([92m↓13.78%[0m) [0.08% of initial]
[Iter 5660/20000] Loss: 0.0003102 (Best: 0.0002396 @iter5500) ([92m↓11.39%[0m) [0.07% of initial]
[Iter 5670/20000] Loss: 0.0002890 (Best: 0.0002396 @iter5500) ([92m↓6.83%[0m) [0.06% of initial]
[Iter 5680/20000] Loss: 0.0002747 (Best: 0.0002396 @iter5500) ([92m↓4.97%[0m) [0.06% of initial]
[Iter 5690/20000] Loss: 0.0002671 (Best: 0.0002396 @iter5500) ([92m↓2.75%[0m) [0.06% of initial]
Iter:5699, L1 loss=0.000258, Total loss=0.000273, Time:15
[Iter 5700/20000] Loss: 0.0002630 (Best: 0.0002396 @iter5500) ([92m↓1.55%[0m) [0.06% of initial]
[Iter 5710/20000] Loss: 0.0002578 (Best: 0.0002396 @iter5500) ([92m↓1.95%[0m) [0.06% of initial]
[Iter 5720/20000] Loss: 0.0002539 (Best: 0.0002396 @iter5500) ([92m↓1.53%[0m) [0.06% of initial]
[Iter 5730/20000] Loss: 0.0002532 (Best: 0.0002396 @iter5500) ([92m↓0.27%[0m) [0.05% of initial]
[Iter 5740/20000] Loss: 0.0002494 (Best: 0.0002396 @iter5500) ([92m↓1.51%[0m) [0.05% of initial]
[Iter 5750/20000] Loss: 0.0002488 (Best: 0.0002385 @iter5749) ([92m↓0.24%[0m) [0.05% of initial]
[Iter 5760/20000] Loss: 0.0002473 (Best: 0.0002385 @iter5749) ([92m↓0.61%[0m) [0.05% of initial]
[Iter 5770/20000] Loss: 0.0002443 (Best: 0.0002367 @iter5764) ([92m↓1.21%[0m) [0.05% of initial]
[Iter 5780/20000] Loss: 0.0002410 (Best: 0.0002353 @iter5777) ([92m↓1.33%[0m) [0.05% of initial]
[Iter 5790/20000] Loss: 0.0002419 (Best: 0.0002335 @iter5788) ([91m↑0.35%[0m) [0.05% of initial]
Iter:5799, L1 loss=0.0002357, Total loss=0.0002406, Time:17
[Iter 5800/20000] Loss: 0.0002396 (Best: 0.0002287 @iter5791) ([92m↓0.93%[0m) [0.05% of initial]
[Iter 5810/20000] Loss: 0.0014320 (Best: 0.0002287 @iter5791) ([91m↑497.57%[0m) [0.31% of initial]
[Iter 5820/20000] Loss: 0.0007619 (Best: 0.0002287 @iter5791) ([92m↓46.79%[0m) [0.17% of initial]
[Iter 5830/20000] Loss: 0.0004419 (Best: 0.0002287 @iter5791) ([92m↓42.00%[0m) [0.10% of initial]
[Iter 5840/20000] Loss: 0.0003290 (Best: 0.0002287 @iter5791) ([92m↓25.55%[0m) [0.07% of initial]
[Iter 5850/20000] Loss: 0.0002839 (Best: 0.0002287 @iter5791) ([92m↓13.69%[0m) [0.06% of initial]
[Iter 5860/20000] Loss: 0.0002632 (Best: 0.0002287 @iter5791) ([92m↓7.30%[0m) [0.06% of initial]
[Iter 5870/20000] Loss: 0.0002472 (Best: 0.0002287 @iter5791) ([92m↓6.07%[0m) [0.05% of initial]
[Iter 5880/20000] Loss: 0.0002465 (Best: 0.0002287 @iter5791) ([92m↓0.29%[0m) [0.05% of initial]
[Iter 5890/20000] Loss: 0.0002385 (Best: 0.0002287 @iter5791) ([92m↓3.23%[0m) [0.05% of initial]
Iter:5899, L1 loss=0.0002252, Total loss=0.0002269, Time:17
[Iter 5900/20000] Loss: 0.0002393 (Best: 0.0002269 @iter5899) ([91m↑0.32%[0m) [0.05% of initial]
[Iter 5910/20000] Loss: 0.0002362 (Best: 0.0002264 @iter5902) ([92m↓1.28%[0m) [0.05% of initial]
[Iter 5920/20000] Loss: 0.0002309 (Best: 0.0002245 @iter5920) ([92m↓2.27%[0m) [0.05% of initial]
[Iter 5930/20000] Loss: 0.0002320 (Best: 0.0002214 @iter5929) ([91m↑0.46%[0m) [0.05% of initial]
[Iter 5940/20000] Loss: 0.0002291 (Best: 0.0002214 @iter5929) ([92m↓1.25%[0m) [0.05% of initial]
[Iter 5950/20000] Loss: 0.0002241 (Best: 0.0002214 @iter5929) ([92m↓2.18%[0m) [0.05% of initial]
[Iter 5960/20000] Loss: 0.0002255 (Best: 0.0002213 @iter5960) ([91m↑0.61%[0m) [0.05% of initial]
[Iter 5970/20000] Loss: 0.0002263 (Best: 0.0002190 @iter5963) ([91m↑0.38%[0m) [0.05% of initial]
[Iter 5980/20000] Loss: 0.0002297 (Best: 0.0002171 @iter5977) ([91m↑1.51%[0m) [0.05% of initial]
[Iter 5990/20000] Loss: 0.0002194 (Best: 0.0002150 @iter5989) ([92m↓4.51%[0m) [0.05% of initial]
Iter:5999, L1 loss=0.000224, Total loss=0.0002209, Time:17
[Iter 6000/20000] Loss: 0.0002257 (Best: 0.0002150 @iter5989) ([91m↑2.87%[0m) [0.05% of initial]
Pruning 450 points (6.5%) from gaussian0 at iteration 6000
Pruning 308 points (5.3%) from gaussian1 at iteration 6000
[Iter 6010/20000] Loss: 0.0010521 (Best: 0.0002150 @iter5989) ([91m↑366.22%[0m) [0.23% of initial]
[Iter 6020/20000] Loss: 0.0005315 (Best: 0.0002150 @iter5989) ([92m↓49.48%[0m) [0.12% of initial]
[Iter 6030/20000] Loss: 0.0003980 (Best: 0.0002150 @iter5989) ([92m↓25.13%[0m) [0.09% of initial]
[Iter 6040/20000] Loss: 0.0003402 (Best: 0.0002150 @iter5989) ([92m↓14.53%[0m) [0.07% of initial]
[Iter 6050/20000] Loss: 0.0003020 (Best: 0.0002150 @iter5989) ([92m↓11.21%[0m) [0.07% of initial]
[Iter 6060/20000] Loss: 0.0002910 (Best: 0.0002150 @iter5989) ([92m↓3.64%[0m) [0.06% of initial]
[Iter 6070/20000] Loss: 0.0002804 (Best: 0.0002150 @iter5989) ([92m↓3.66%[0m) [0.06% of initial]
[Iter 6080/20000] Loss: 0.0002722 (Best: 0.0002150 @iter5989) ([92m↓2.91%[0m) [0.06% of initial]
[Iter 6090/20000] Loss: 0.0002693 (Best: 0.0002150 @iter5989) ([92m↓1.08%[0m) [0.06% of initial]
Iter:6099, L1 loss=0.0002432, Total loss=0.0002572, Time:16
[Iter 6100/20000] Loss: 0.0002592 (Best: 0.0002150 @iter5989) ([92m↓3.76%[0m) [0.06% of initial]
[Iter 6110/20000] Loss: 0.0002566 (Best: 0.0002150 @iter5989) ([92m↓0.99%[0m) [0.06% of initial]
[Iter 6120/20000] Loss: 0.0002592 (Best: 0.0002150 @iter5989) ([91m↑0.99%[0m) [0.06% of initial]
[Iter 6130/20000] Loss: 0.0002526 (Best: 0.0002150 @iter5989) ([92m↓2.52%[0m) [0.05% of initial]
[Iter 6140/20000] Loss: 0.0002462 (Best: 0.0002150 @iter5989) ([92m↓2.54%[0m) [0.05% of initial]
[Iter 6150/20000] Loss: 0.0002496 (Best: 0.0002150 @iter5989) ([91m↑1.40%[0m) [0.05% of initial]
[Iter 6160/20000] Loss: 0.0002455 (Best: 0.0002150 @iter5989) ([92m↓1.64%[0m) [0.05% of initial]
[Iter 6170/20000] Loss: 0.0002393 (Best: 0.0002150 @iter5989) ([92m↓2.56%[0m) [0.05% of initial]
[Iter 6180/20000] Loss: 0.0002457 (Best: 0.0002150 @iter5989) ([91m↑2.70%[0m) [0.05% of initial]
[Iter 6190/20000] Loss: 0.0002457 (Best: 0.0002150 @iter5989) ([92m↓0.01%[0m) [0.05% of initial]
Iter:6199, L1 loss=0.000222, Total loss=0.0002311, Time:17
[Iter 6200/20000] Loss: 0.0002387 (Best: 0.0002150 @iter5989) ([92m↓2.85%[0m) [0.05% of initial]
[Iter 6210/20000] Loss: 0.0011531 (Best: 0.0002150 @iter5989) ([91m↑383.06%[0m) [0.25% of initial]
[Iter 6220/20000] Loss: 0.0006088 (Best: 0.0002150 @iter5989) ([92m↓47.20%[0m) [0.13% of initial]
[Iter 6230/20000] Loss: 0.0004089 (Best: 0.0002150 @iter5989) ([92m↓32.84%[0m) [0.09% of initial]
[Iter 6240/20000] Loss: 0.0003111 (Best: 0.0002150 @iter5989) ([92m↓23.92%[0m) [0.07% of initial]
[Iter 6250/20000] Loss: 0.0002664 (Best: 0.0002150 @iter5989) ([92m↓14.37%[0m) [0.06% of initial]
[Iter 6260/20000] Loss: 0.0002532 (Best: 0.0002150 @iter5989) ([92m↓4.95%[0m) [0.05% of initial]
[Iter 6270/20000] Loss: 0.0002488 (Best: 0.0002150 @iter5989) ([92m↓1.74%[0m) [0.05% of initial]
[Iter 6280/20000] Loss: 0.0002423 (Best: 0.0002150 @iter5989) ([92m↓2.62%[0m) [0.05% of initial]
[Iter 6290/20000] Loss: 0.0002342 (Best: 0.0002150 @iter5989) ([92m↓3.33%[0m) [0.05% of initial]
Iter:6299, L1 loss=0.0002183, Total loss=0.0002295, Time:17
[Iter 6300/20000] Loss: 0.0002356 (Best: 0.0002150 @iter5989) ([91m↑0.61%[0m) [0.05% of initial]
[Iter 6310/20000] Loss: 0.0002331 (Best: 0.0002150 @iter5989) ([92m↓1.08%[0m) [0.05% of initial]
[Iter 6320/20000] Loss: 0.0002294 (Best: 0.0002150 @iter5989) ([92m↓1.57%[0m) [0.05% of initial]
[Iter 6330/20000] Loss: 0.0002270 (Best: 0.0002150 @iter5989) ([92m↓1.05%[0m) [0.05% of initial]
[Iter 6340/20000] Loss: 0.0002264 (Best: 0.0002150 @iter5989) ([92m↓0.27%[0m) [0.05% of initial]
[Iter 6350/20000] Loss: 0.0002241 (Best: 0.0002150 @iter5989) ([92m↓0.99%[0m) [0.05% of initial]
[Iter 6360/20000] Loss: 0.0002260 (Best: 0.0002150 @iter5989) ([91m↑0.81%[0m) [0.05% of initial]
[Iter 6370/20000] Loss: 0.0002268 (Best: 0.0002150 @iter5989) ([91m↑0.37%[0m) [0.05% of initial]
[Iter 6380/20000] Loss: 0.0002239 (Best: 0.0002142 @iter6373) ([92m↓1.29%[0m) [0.05% of initial]
[Iter 6390/20000] Loss: 0.0002235 (Best: 0.0002142 @iter6373) ([92m↓0.18%[0m) [0.05% of initial]
Iter:6399, L1 loss=0.0002168, Total loss=0.0002268, Time:17
[Iter 6400/20000] Loss: 0.0002167 (Best: 0.0002104 @iter6400) ([92m↓3.05%[0m) [0.05% of initial]
[Iter 6410/20000] Loss: 0.0009012 (Best: 0.0002104 @iter6400) ([91m↑315.96%[0m) [0.20% of initial]
[Iter 6420/20000] Loss: 0.0005038 (Best: 0.0002104 @iter6400) ([92m↓44.10%[0m) [0.11% of initial]
[Iter 6430/20000] Loss: 0.0003535 (Best: 0.0002104 @iter6400) ([92m↓29.83%[0m) [0.08% of initial]
[Iter 6440/20000] Loss: 0.0002826 (Best: 0.0002104 @iter6400) ([92m↓20.05%[0m) [0.06% of initial]
[Iter 6450/20000] Loss: 0.0002526 (Best: 0.0002104 @iter6400) ([92m↓10.62%[0m) [0.05% of initial]
[Iter 6460/20000] Loss: 0.0002320 (Best: 0.0002104 @iter6400) ([92m↓8.17%[0m) [0.05% of initial]
[Iter 6470/20000] Loss: 0.0002238 (Best: 0.0002104 @iter6400) ([92m↓3.51%[0m) [0.05% of initial]
[Iter 6480/20000] Loss: 0.0002228 (Best: 0.0002104 @iter6400) ([92m↓0.45%[0m) [0.05% of initial]
[Iter 6490/20000] Loss: 0.0002191 (Best: 0.0002104 @iter6400) ([92m↓1.65%[0m) [0.05% of initial]
Iter:6499, L1 loss=0.0002105, Total loss=0.0002134, Time:15
[Iter 6500/20000] Loss: 0.0002173 (Best: 0.0002104 @iter6400) ([92m↓0.86%[0m) [0.05% of initial]
Pruning 410 points (6.6%) from gaussian0 at iteration 6500
Pruning 278 points (5.3%) from gaussian1 at iteration 6500
[Iter 6510/20000] Loss: 0.0010389 (Best: 0.0002104 @iter6400) ([91m↑378.19%[0m) [0.23% of initial]
[Iter 6520/20000] Loss: 0.0005234 (Best: 0.0002104 @iter6400) ([92m↓49.61%[0m) [0.11% of initial]
[Iter 6530/20000] Loss: 0.0003695 (Best: 0.0002104 @iter6400) ([92m↓29.41%[0m) [0.08% of initial]
[Iter 6540/20000] Loss: 0.0003027 (Best: 0.0002104 @iter6400) ([92m↓18.08%[0m) [0.07% of initial]
[Iter 6550/20000] Loss: 0.0002753 (Best: 0.0002104 @iter6400) ([92m↓9.07%[0m) [0.06% of initial]
[Iter 6560/20000] Loss: 0.0002615 (Best: 0.0002104 @iter6400) ([92m↓5.01%[0m) [0.06% of initial]
[Iter 6570/20000] Loss: 0.0002485 (Best: 0.0002104 @iter6400) ([92m↓4.94%[0m) [0.05% of initial]
[Iter 6580/20000] Loss: 0.0002457 (Best: 0.0002104 @iter6400) ([92m↓1.15%[0m) [0.05% of initial]
[Iter 6590/20000] Loss: 0.0002389 (Best: 0.0002104 @iter6400) ([92m↓2.75%[0m) [0.05% of initial]
Iter:6599, L1 loss=0.0002262, Total loss=0.0002351, Time:17
[Iter 6600/20000] Loss: 0.0002327 (Best: 0.0002104 @iter6400) ([92m↓2.62%[0m) [0.05% of initial]
[Iter 6610/20000] Loss: 0.0012979 (Best: 0.0002104 @iter6400) ([91m↑457.82%[0m) [0.28% of initial]
[Iter 6620/20000] Loss: 0.0007262 (Best: 0.0002104 @iter6400) ([92m↓44.05%[0m) [0.16% of initial]
[Iter 6630/20000] Loss: 0.0004109 (Best: 0.0002104 @iter6400) ([92m↓43.42%[0m) [0.09% of initial]
[Iter 6640/20000] Loss: 0.0003042 (Best: 0.0002104 @iter6400) ([92m↓25.98%[0m) [0.07% of initial]
[Iter 6650/20000] Loss: 0.0002647 (Best: 0.0002104 @iter6400) ([92m↓12.97%[0m) [0.06% of initial]
[Iter 6660/20000] Loss: 0.0002476 (Best: 0.0002104 @iter6400) ([92m↓6.48%[0m) [0.05% of initial]
[Iter 6670/20000] Loss: 0.0002351 (Best: 0.0002104 @iter6400) ([92m↓5.05%[0m) [0.05% of initial]
[Iter 6680/20000] Loss: 0.0002308 (Best: 0.0002104 @iter6400) ([92m↓1.82%[0m) [0.05% of initial]
[Iter 6690/20000] Loss: 0.0002286 (Best: 0.0002104 @iter6400) ([92m↓0.93%[0m) [0.05% of initial]
Iter:6699, L1 loss=0.0002244, Total loss=0.0002298, Time:17
[Iter 6700/20000] Loss: 0.0002270 (Best: 0.0002104 @iter6400) ([92m↓0.73%[0m) [0.05% of initial]
[Iter 6710/20000] Loss: 0.0002218 (Best: 0.0002104 @iter6400) ([92m↓2.27%[0m) [0.05% of initial]
[Iter 6720/20000] Loss: 0.0002169 (Best: 0.0002104 @iter6400) ([92m↓2.21%[0m) [0.05% of initial]
[Iter 6730/20000] Loss: 0.0002165 (Best: 0.0002104 @iter6400) ([92m↓0.19%[0m) [0.05% of initial]
[Iter 6740/20000] Loss: 0.0002133 (Best: 0.0002075 @iter6739) ([92m↓1.48%[0m) [0.05% of initial]
[Iter 6750/20000] Loss: 0.0002126 (Best: 0.0002075 @iter6739) ([92m↓0.31%[0m) [0.05% of initial]
[Iter 6760/20000] Loss: 0.0002164 (Best: 0.0002043 @iter6754) ([91m↑1.76%[0m) [0.05% of initial]
[Iter 6770/20000] Loss: 0.0002115 (Best: 0.0002043 @iter6754) ([92m↓2.27%[0m) [0.05% of initial]
[Iter 6780/20000] Loss: 0.0002099 (Best: 0.0002029 @iter6779) ([92m↓0.73%[0m) [0.05% of initial]
[Iter 6790/20000] Loss: 0.0002093 (Best: 0.0002029 @iter6779) ([92m↓0.28%[0m) [0.05% of initial]
Iter:6799, L1 loss=0.0002087, Total loss=0.0002086, Time:16
[Iter 6800/20000] Loss: 0.0002104 (Best: 0.0002003 @iter6796) ([91m↑0.52%[0m) [0.05% of initial]
[Iter 6810/20000] Loss: 0.0005763 (Best: 0.0002003 @iter6796) ([91m↑173.89%[0m) [0.13% of initial]
[Iter 6820/20000] Loss: 0.0003583 (Best: 0.0002003 @iter6796) ([92m↓37.83%[0m) [0.08% of initial]
[Iter 6830/20000] Loss: 0.0002729 (Best: 0.0002003 @iter6796) ([92m↓23.84%[0m) [0.06% of initial]
[Iter 6840/20000] Loss: 0.0002352 (Best: 0.0002003 @iter6796) ([92m↓13.81%[0m) [0.05% of initial]
[Iter 6850/20000] Loss: 0.0002196 (Best: 0.0002003 @iter6796) ([92m↓6.65%[0m) [0.05% of initial]
[Iter 6860/20000] Loss: 0.0002124 (Best: 0.0002003 @iter6796) ([92m↓3.29%[0m) [0.05% of initial]
[Iter 6870/20000] Loss: 0.0002108 (Best: 0.0002003 @iter6796) ([92m↓0.75%[0m) [0.05% of initial]
[Iter 6880/20000] Loss: 0.0002046 (Best: 0.0002003 @iter6796) ([92m↓2.93%[0m) [0.04% of initial]
[Iter 6890/20000] Loss: 0.0002070 (Best: 0.0001980 @iter6883) ([91m↑1.15%[0m) [0.04% of initial]
Iter:6899, L1 loss=0.0002061, Total loss=0.0002011, Time:16
[Iter 6900/20000] Loss: 0.0002060 (Best: 0.0001980 @iter6883) ([92m↓0.47%[0m) [0.04% of initial]
[Iter 6910/20000] Loss: 0.0002000 (Best: 0.0001944 @iter6910) ([92m↓2.92%[0m) [0.04% of initial]
[Iter 6920/20000] Loss: 0.0001979 (Best: 0.0001939 @iter6916) ([92m↓1.05%[0m) [0.04% of initial]
[Iter 6930/20000] Loss: 0.0001989 (Best: 0.0001931 @iter6922) ([91m↑0.54%[0m) [0.04% of initial]
[Iter 6940/20000] Loss: 0.0001955 (Best: 0.0001892 @iter6940) ([92m↓1.71%[0m) [0.04% of initial]
[Iter 6950/20000] Loss: 0.0001977 (Best: 0.0001888 @iter6943) ([91m↑1.11%[0m) [0.04% of initial]
[Iter 6960/20000] Loss: 0.0001986 (Best: 0.0001888 @iter6943) ([91m↑0.45%[0m) [0.04% of initial]
[Iter 6970/20000] Loss: 0.0001984 (Best: 0.0001888 @iter6943) ([92m↓0.09%[0m) [0.04% of initial]
[Iter 6980/20000] Loss: 0.0001948 (Best: 0.0001886 @iter6979) ([92m↓1.82%[0m) [0.04% of initial]
[Iter 6990/20000] Loss: 0.0001936 (Best: 0.0001886 @iter6979) ([92m↓0.63%[0m) [0.04% of initial]
Iter:6999, L1 loss=0.0002036, Total loss=0.0001905, Time:16
[Iter 7000/20000] Loss: 0.0001919 (Best: 0.0001859 @iter6994) ([92m↓0.86%[0m) [0.04% of initial]
Pruning 356 points (6.1%) from gaussian0 at iteration 7000
Pruning 227 points (4.5%) from gaussian1 at iteration 7000
[Iter 7010/20000] Loss: 0.0007254 (Best: 0.0001859 @iter6994) ([91m↑277.96%[0m) [0.16% of initial]
[Iter 7020/20000] Loss: 0.0004176 (Best: 0.0001859 @iter6994) ([92m↓42.43%[0m) [0.09% of initial]
[Iter 7030/20000] Loss: 0.0003163 (Best: 0.0001859 @iter6994) ([92m↓24.26%[0m) [0.07% of initial]
[Iter 7040/20000] Loss: 0.0002786 (Best: 0.0001859 @iter6994) ([92m↓11.91%[0m) [0.06% of initial]
[Iter 7050/20000] Loss: 0.0002571 (Best: 0.0001859 @iter6994) ([92m↓7.75%[0m) [0.06% of initial]
[Iter 7060/20000] Loss: 0.0002421 (Best: 0.0001859 @iter6994) ([92m↓5.80%[0m) [0.05% of initial]
[Iter 7070/20000] Loss: 0.0002337 (Best: 0.0001859 @iter6994) ([92m↓3.49%[0m) [0.05% of initial]
[Iter 7080/20000] Loss: 0.0002304 (Best: 0.0001859 @iter6994) ([92m↓1.42%[0m) [0.05% of initial]
[Iter 7090/20000] Loss: 0.0002260 (Best: 0.0001859 @iter6994) ([92m↓1.90%[0m) [0.05% of initial]
Iter:7099, L1 loss=0.0002162, Total loss=0.0002172, Time:16
[Iter 7100/20000] Loss: 0.0002265 (Best: 0.0001859 @iter6994) ([91m↑0.23%[0m) [0.05% of initial]
[Iter 7110/20000] Loss: 0.0002232 (Best: 0.0001859 @iter6994) ([92m↓1.47%[0m) [0.05% of initial]
[Iter 7120/20000] Loss: 0.0002177 (Best: 0.0001859 @iter6994) ([92m↓2.44%[0m) [0.05% of initial]
[Iter 7130/20000] Loss: 0.0002151 (Best: 0.0001859 @iter6994) ([92m↓1.21%[0m) [0.05% of initial]
[Iter 7140/20000] Loss: 0.0002178 (Best: 0.0001859 @iter6994) ([91m↑1.26%[0m) [0.05% of initial]
[Iter 7150/20000] Loss: 0.0002135 (Best: 0.0001859 @iter6994) ([92m↓1.99%[0m) [0.05% of initial]
[Iter 7160/20000] Loss: 0.0002153 (Best: 0.0001859 @iter6994) ([91m↑0.86%[0m) [0.05% of initial]
[Iter 7170/20000] Loss: 0.0002112 (Best: 0.0001859 @iter6994) ([92m↓1.89%[0m) [0.05% of initial]
[Iter 7180/20000] Loss: 0.0002079 (Best: 0.0001859 @iter6994) ([92m↓1.57%[0m) [0.05% of initial]
[Iter 7190/20000] Loss: 0.0002095 (Best: 0.0001859 @iter6994) ([91m↑0.77%[0m) [0.05% of initial]
Iter:7199, L1 loss=0.0002116, Total loss=0.0002048, Time:11
[Iter 7200/20000] Loss: 0.0002083 (Best: 0.0001859 @iter6994) ([92m↓0.56%[0m) [0.05% of initial]
[Iter 7210/20000] Loss: 0.0004583 (Best: 0.0001859 @iter6994) ([91m↑119.98%[0m) [0.10% of initial]
[Iter 7220/20000] Loss: 0.0003122 (Best: 0.0001859 @iter6994) ([92m↓31.88%[0m) [0.07% of initial]
[Iter 7230/20000] Loss: 0.0002506 (Best: 0.0001859 @iter6994) ([92m↓19.73%[0m) [0.05% of initial]
[Iter 7240/20000] Loss: 0.0002258 (Best: 0.0001859 @iter6994) ([92m↓9.88%[0m) [0.05% of initial]
[Iter 7250/20000] Loss: 0.0002119 (Best: 0.0001859 @iter6994) ([92m↓6.17%[0m) [0.05% of initial]
[Iter 7260/20000] Loss: 0.0002072 (Best: 0.0001859 @iter6994) ([92m↓2.20%[0m) [0.04% of initial]
[Iter 7270/20000] Loss: 0.0002044 (Best: 0.0001859 @iter6994) ([92m↓1.37%[0m) [0.04% of initial]
[Iter 7280/20000] Loss: 0.0002027 (Best: 0.0001859 @iter6994) ([92m↓0.83%[0m) [0.04% of initial]
[Iter 7290/20000] Loss: 0.0001998 (Best: 0.0001859 @iter6994) ([92m↓1.40%[0m) [0.04% of initial]
Iter:7299, L1 loss=0.0002072, Total loss=0.0001948, Time:14
[Iter 7300/20000] Loss: 0.0001996 (Best: 0.0001859 @iter6994) ([92m↓0.11%[0m) [0.04% of initial]
[Iter 7310/20000] Loss: 0.0001988 (Best: 0.0001859 @iter6994) ([92m↓0.40%[0m) [0.04% of initial]
[Iter 7320/20000] Loss: 0.0001967 (Best: 0.0001859 @iter6994) ([92m↓1.08%[0m) [0.04% of initial]
[Iter 7330/20000] Loss: 0.0001941 (Best: 0.0001859 @iter6994) ([92m↓1.32%[0m) [0.04% of initial]
[Iter 7340/20000] Loss: 0.0001974 (Best: 0.0001859 @iter6994) ([91m↑1.70%[0m) [0.04% of initial]
[Iter 7350/20000] Loss: 0.0001967 (Best: 0.0001859 @iter6994) ([92m↓0.34%[0m) [0.04% of initial]
[Iter 7360/20000] Loss: 0.0001922 (Best: 0.0001859 @iter6994) ([92m↓2.29%[0m) [0.04% of initial]
[Iter 7370/20000] Loss: 0.0001937 (Best: 0.0001859 @iter6994) ([91m↑0.80%[0m) [0.04% of initial]
[Iter 7380/20000] Loss: 0.0001951 (Best: 0.0001859 @iter6994) ([91m↑0.72%[0m) [0.04% of initial]
[Iter 7390/20000] Loss: 0.0001931 (Best: 0.0001859 @iter6994) ([92m↓1.04%[0m) [0.04% of initial]
Iter:7399, L1 loss=0.0002089, Total loss=0.0001964, Time:16
[Iter 7400/20000] Loss: 0.0001917 (Best: 0.0001859 @iter6994) ([92m↓0.73%[0m) [0.04% of initial]
[Iter 7410/20000] Loss: 0.0003080 (Best: 0.0001859 @iter6994) ([91m↑60.68%[0m) [0.07% of initial]
[Iter 7420/20000] Loss: 0.0002445 (Best: 0.0001859 @iter6994) ([92m↓20.60%[0m) [0.05% of initial]
[Iter 7430/20000] Loss: 0.0002144 (Best: 0.0001859 @iter6994) ([92m↓12.34%[0m) [0.05% of initial]
[Iter 7440/20000] Loss: 0.0002044 (Best: 0.0001859 @iter6994) ([92m↓4.66%[0m) [0.04% of initial]
[Iter 7450/20000] Loss: 0.0002012 (Best: 0.0001859 @iter6994) ([92m↓1.53%[0m) [0.04% of initial]
[Iter 7460/20000] Loss: 0.0001916 (Best: 0.0001859 @iter6994) ([92m↓4.79%[0m) [0.04% of initial]
[Iter 7470/20000] Loss: 0.0001902 (Best: 0.0001858 @iter7462) ([92m↓0.73%[0m) [0.04% of initial]
[Iter 7480/20000] Loss: 0.0001911 (Best: 0.0001850 @iter7474) ([91m↑0.47%[0m) [0.04% of initial]
[Iter 7490/20000] Loss: 0.0001843 (Best: 0.0001804 @iter7489) ([92m↓3.53%[0m) [0.04% of initial]
Iter:7499, L1 loss=0.0001974, Total loss=0.000195, Time:15
[Iter 7500/20000] Loss: 0.0001895 (Best: 0.0001804 @iter7489) ([91m↑2.83%[0m) [0.04% of initial]
Pruning 319 points (5.9%) from gaussian0 at iteration 7500
Pruning 178 points (3.7%) from gaussian1 at iteration 7500
[Iter 7510/20000] Loss: 0.0006875 (Best: 0.0001804 @iter7489) ([91m↑262.68%[0m) [0.15% of initial]
[Iter 7520/20000] Loss: 0.0003782 (Best: 0.0001804 @iter7489) ([92m↓44.98%[0m) [0.08% of initial]
[Iter 7530/20000] Loss: 0.0002845 (Best: 0.0001804 @iter7489) ([92m↓24.77%[0m) [0.06% of initial]
[Iter 7540/20000] Loss: 0.0002474 (Best: 0.0001804 @iter7489) ([92m↓13.03%[0m) [0.05% of initial]
[Iter 7550/20000] Loss: 0.0002280 (Best: 0.0001804 @iter7489) ([92m↓7.87%[0m) [0.05% of initial]
[Iter 7560/20000] Loss: 0.0002183 (Best: 0.0001804 @iter7489) ([92m↓4.24%[0m) [0.05% of initial]
[Iter 7570/20000] Loss: 0.0002108 (Best: 0.0001804 @iter7489) ([92m↓3.45%[0m) [0.05% of initial]
[Iter 7580/20000] Loss: 0.0002074 (Best: 0.0001804 @iter7489) ([92m↓1.58%[0m) [0.04% of initial]
[Iter 7590/20000] Loss: 0.0002051 (Best: 0.0001804 @iter7489) ([92m↓1.10%[0m) [0.04% of initial]
Iter:7599, L1 loss=0.0002124, Total loss=0.0002084, Time:19
[Iter 7600/20000] Loss: 0.0002015 (Best: 0.0001804 @iter7489) ([92m↓1.78%[0m) [0.04% of initial]
[Iter 7610/20000] Loss: 0.0010656 (Best: 0.0001804 @iter7489) ([91m↑428.87%[0m) [0.23% of initial]
[Iter 7620/20000] Loss: 0.0006674 (Best: 0.0001804 @iter7489) ([92m↓37.36%[0m) [0.14% of initial]
[Iter 7630/20000] Loss: 0.0003896 (Best: 0.0001804 @iter7489) ([92m↓41.63%[0m) [0.08% of initial]
[Iter 7640/20000] Loss: 0.0002688 (Best: 0.0001804 @iter7489) ([92m↓30.99%[0m) [0.06% of initial]
[Iter 7650/20000] Loss: 0.0002302 (Best: 0.0001804 @iter7489) ([92m↓14.38%[0m) [0.05% of initial]
[Iter 7660/20000] Loss: 0.0002140 (Best: 0.0001804 @iter7489) ([92m↓7.04%[0m) [0.05% of initial]
[Iter 7670/20000] Loss: 0.0002018 (Best: 0.0001804 @iter7489) ([92m↓5.70%[0m) [0.04% of initial]
[Iter 7680/20000] Loss: 0.0002008 (Best: 0.0001804 @iter7489) ([92m↓0.50%[0m) [0.04% of initial]
[Iter 7690/20000] Loss: 0.0002011 (Best: 0.0001804 @iter7489) ([91m↑0.15%[0m) [0.04% of initial]
Iter:7699, L1 loss=0.0002004, Total loss=0.0001935, Time:12
[Iter 7700/20000] Loss: 0.0001936 (Best: 0.0001804 @iter7489) ([92m↓3.71%[0m) [0.04% of initial]
[Iter 7710/20000] Loss: 0.0001944 (Best: 0.0001804 @iter7489) ([91m↑0.43%[0m) [0.04% of initial]
[Iter 7720/20000] Loss: 0.0001906 (Best: 0.0001804 @iter7489) ([92m↓1.99%[0m) [0.04% of initial]
[Iter 7730/20000] Loss: 0.0001887 (Best: 0.0001804 @iter7489) ([92m↓0.95%[0m) [0.04% of initial]
[Iter 7740/20000] Loss: 0.0001891 (Best: 0.0001804 @iter7489) ([91m↑0.21%[0m) [0.04% of initial]
[Iter 7750/20000] Loss: 0.0001896 (Best: 0.0001804 @iter7489) ([91m↑0.26%[0m) [0.04% of initial]
[Iter 7760/20000] Loss: 0.0001872 (Best: 0.0001804 @iter7489) ([92m↓1.28%[0m) [0.04% of initial]
[Iter 7770/20000] Loss: 0.0001889 (Best: 0.0001804 @iter7489) ([91m↑0.92%[0m) [0.04% of initial]
[Iter 7780/20000] Loss: 0.0001865 (Best: 0.0001804 @iter7489) ([92m↓1.29%[0m) [0.04% of initial]
[Iter 7790/20000] Loss: 0.0001885 (Best: 0.0001804 @iter7489) ([91m↑1.10%[0m) [0.04% of initial]
Iter:7799, L1 loss=0.0001932, Total loss=0.0001835, Time:19
[Iter 7800/20000] Loss: 0.0001858 (Best: 0.0001804 @iter7489) ([92m↓1.44%[0m) [0.04% of initial]
[Iter 7810/20000] Loss: 0.0006151 (Best: 0.0001804 @iter7489) ([91m↑230.97%[0m) [0.13% of initial]
[Iter 7820/20000] Loss: 0.0003843 (Best: 0.0001804 @iter7489) ([92m↓37.52%[0m) [0.08% of initial]
[Iter 7830/20000] Loss: 0.0002644 (Best: 0.0001804 @iter7489) ([92m↓31.19%[0m) [0.06% of initial]
[Iter 7840/20000] Loss: 0.0002179 (Best: 0.0001804 @iter7489) ([92m↓17.61%[0m) [0.05% of initial]
[Iter 7850/20000] Loss: 0.0002050 (Best: 0.0001804 @iter7489) ([92m↓5.89%[0m) [0.04% of initial]
[Iter 7860/20000] Loss: 0.0001960 (Best: 0.0001804 @iter7489) ([92m↓4.40%[0m) [0.04% of initial]
[Iter 7870/20000] Loss: 0.0001927 (Best: 0.0001804 @iter7489) ([92m↓1.68%[0m) [0.04% of initial]
[Iter 7880/20000] Loss: 0.0001873 (Best: 0.0001804 @iter7489) ([92m↓2.84%[0m) [0.04% of initial]
[Iter 7890/20000] Loss: 0.0001886 (Best: 0.0001804 @iter7489) ([91m↑0.74%[0m) [0.04% of initial]
Iter:7899, L1 loss=0.0001945, Total loss=0.0001854, Time:16
[Iter 7900/20000] Loss: 0.0001858 (Best: 0.0001804 @iter7489) ([92m↓1.52%[0m) [0.04% of initial]
[Iter 7910/20000] Loss: 0.0001812 (Best: 0.0001795 @iter7907) ([92m↓2.47%[0m) [0.04% of initial]
[Iter 7920/20000] Loss: 0.0001838 (Best: 0.0001792 @iter7915) ([91m↑1.44%[0m) [0.04% of initial]
[Iter 7930/20000] Loss: 0.0001831 (Best: 0.0001768 @iter7928) ([92m↓0.38%[0m) [0.04% of initial]
[Iter 7940/20000] Loss: 0.0001810 (Best: 0.0001768 @iter7928) ([92m↓1.15%[0m) [0.04% of initial]
[Iter 7950/20000] Loss: 0.0001804 (Best: 0.0001743 @iter7948) ([92m↓0.34%[0m) [0.04% of initial]
[Iter 7960/20000] Loss: 0.0001809 (Best: 0.0001743 @iter7948) ([91m↑0.29%[0m) [0.04% of initial]
[Iter 7970/20000] Loss: 0.0001778 (Best: 0.0001738 @iter7970) ([92m↓1.72%[0m) [0.04% of initial]
[Iter 7980/20000] Loss: 0.0001784 (Best: 0.0001738 @iter7970) ([91m↑0.37%[0m) [0.04% of initial]
[Iter 7990/20000] Loss: 0.0001769 (Best: 0.0001729 @iter7988) ([92m↓0.88%[0m) [0.04% of initial]
Iter:7999, L1 loss=0.0001845, Total loss=0.0001712, Time:16
[Iter 8000/20000] Loss: 0.0001775 (Best: 0.0001712 @iter7999) ([91m↑0.38%[0m) [0.04% of initial]
Pruning 273 points (5.1%) from gaussian0 at iteration 8000
Pruning 227 points (4.6%) from gaussian1 at iteration 8000
[Iter 8010/20000] Loss: 0.0558042 (Best: 0.0001712 @iter7999) ([91m↑31334.55%[0m) [12.11% of initial]
[Iter 8020/20000] Loss: 0.0376824 (Best: 0.0001712 @iter7999) ([92m↓32.47%[0m) [8.17% of initial]
[Iter 8030/20000] Loss: 0.0202540 (Best: 0.0001712 @iter7999) ([92m↓46.25%[0m) [4.39% of initial]
[Iter 8040/20000] Loss: 0.0080297 (Best: 0.0001712 @iter7999) ([92m↓60.35%[0m) [1.74% of initial]
[Iter 8050/20000] Loss: 0.0025816 (Best: 0.0001712 @iter7999) ([92m↓67.85%[0m) [0.56% of initial]
[Iter 8060/20000] Loss: 0.0013476 (Best: 0.0001712 @iter7999) ([92m↓47.80%[0m) [0.29% of initial]
[Iter 8070/20000] Loss: 0.0009828 (Best: 0.0001712 @iter7999) ([92m↓27.07%[0m) [0.21% of initial]
[Iter 8080/20000] Loss: 0.0007060 (Best: 0.0001712 @iter7999) ([92m↓28.17%[0m) [0.15% of initial]
[Iter 8090/20000] Loss: 0.0006207 (Best: 0.0001712 @iter7999) ([92m↓12.08%[0m) [0.13% of initial]
Iter:8099, L1 loss=0.0005355, Total loss=0.0005535, Time:20
[Iter 8100/20000] Loss: 0.0005262 (Best: 0.0001712 @iter7999) ([92m↓15.23%[0m) [0.11% of initial]
[Iter 8110/20000] Loss: 0.0004931 (Best: 0.0001712 @iter7999) ([92m↓6.29%[0m) [0.11% of initial]
[Iter 8120/20000] Loss: 0.0004798 (Best: 0.0001712 @iter7999) ([92m↓2.71%[0m) [0.10% of initial]
[Iter 8130/20000] Loss: 0.0004500 (Best: 0.0001712 @iter7999) ([92m↓6.21%[0m) [0.10% of initial]
[Iter 8140/20000] Loss: 0.0004189 (Best: 0.0001712 @iter7999) ([92m↓6.89%[0m) [0.09% of initial]
[Iter 8150/20000] Loss: 0.0004136 (Best: 0.0001712 @iter7999) ([92m↓1.27%[0m) [0.09% of initial]
[Iter 8160/20000] Loss: 0.0004089 (Best: 0.0001712 @iter7999) ([92m↓1.14%[0m) [0.09% of initial]
[Iter 8170/20000] Loss: 0.0004031 (Best: 0.0001712 @iter7999) ([92m↓1.40%[0m) [0.09% of initial]
[Iter 8180/20000] Loss: 0.0003799 (Best: 0.0001712 @iter7999) ([92m↓5.77%[0m) [0.08% of initial]
[Iter 8190/20000] Loss: 0.0003738 (Best: 0.0001712 @iter7999) ([92m↓1.60%[0m) [0.08% of initial]
Iter:8199, L1 loss=0.0004078, Total loss=0.0003868, Time:16
[Iter 8200/20000] Loss: 0.0003789 (Best: 0.0001712 @iter7999) ([91m↑1.38%[0m) [0.08% of initial]
[Iter 8210/20000] Loss: 0.0003554 (Best: 0.0001712 @iter7999) ([92m↓6.21%[0m) [0.08% of initial]
[Iter 8220/20000] Loss: 0.0003568 (Best: 0.0001712 @iter7999) ([91m↑0.38%[0m) [0.08% of initial]
[Iter 8230/20000] Loss: 0.0003431 (Best: 0.0001712 @iter7999) ([92m↓3.82%[0m) [0.07% of initial]
[Iter 8240/20000] Loss: 0.0003450 (Best: 0.0001712 @iter7999) ([91m↑0.53%[0m) [0.07% of initial]
[Iter 8250/20000] Loss: 0.0003387 (Best: 0.0001712 @iter7999) ([92m↓1.81%[0m) [0.07% of initial]
[Iter 8260/20000] Loss: 0.0003374 (Best: 0.0001712 @iter7999) ([92m↓0.39%[0m) [0.07% of initial]
[Iter 8270/20000] Loss: 0.0003288 (Best: 0.0001712 @iter7999) ([92m↓2.54%[0m) [0.07% of initial]
[Iter 8280/20000] Loss: 0.0003280 (Best: 0.0001712 @iter7999) ([92m↓0.25%[0m) [0.07% of initial]
[Iter 8290/20000] Loss: 0.0003257 (Best: 0.0001712 @iter7999) ([92m↓0.68%[0m) [0.07% of initial]
Iter:8299, L1 loss=0.0003145, Total loss=0.0003065, Time:19
[Iter 8300/20000] Loss: 0.0003184 (Best: 0.0001712 @iter7999) ([92m↓2.25%[0m) [0.07% of initial]
[Iter 8310/20000] Loss: 0.0003187 (Best: 0.0001712 @iter7999) ([91m↑0.08%[0m) [0.07% of initial]
[Iter 8320/20000] Loss: 0.0003151 (Best: 0.0001712 @iter7999) ([92m↓1.11%[0m) [0.07% of initial]
[Iter 8330/20000] Loss: 0.0003117 (Best: 0.0001712 @iter7999) ([92m↓1.10%[0m) [0.07% of initial]
[Iter 8340/20000] Loss: 0.0003093 (Best: 0.0001712 @iter7999) ([92m↓0.75%[0m) [0.07% of initial]
[Iter 8350/20000] Loss: 0.0003051 (Best: 0.0001712 @iter7999) ([92m↓1.37%[0m) [0.07% of initial]
[Iter 8360/20000] Loss: 0.0003013 (Best: 0.0001712 @iter7999) ([92m↓1.26%[0m) [0.07% of initial]
[Iter 8370/20000] Loss: 0.0002998 (Best: 0.0001712 @iter7999) ([92m↓0.49%[0m) [0.07% of initial]
[Iter 8380/20000] Loss: 0.0002946 (Best: 0.0001712 @iter7999) ([92m↓1.72%[0m) [0.06% of initial]
[Iter 8390/20000] Loss: 0.0002974 (Best: 0.0001712 @iter7999) ([91m↑0.95%[0m) [0.06% of initial]
Iter:8399, L1 loss=0.0003184, Total loss=0.0003024, Time:19
[Iter 8400/20000] Loss: 0.0002947 (Best: 0.0001712 @iter7999) ([92m↓0.91%[0m) [0.06% of initial]
[Iter 8410/20000] Loss: 0.0002921 (Best: 0.0001712 @iter7999) ([92m↓0.90%[0m) [0.06% of initial]
[Iter 8420/20000] Loss: 0.0002870 (Best: 0.0001712 @iter7999) ([92m↓1.74%[0m) [0.06% of initial]
[Iter 8430/20000] Loss: 0.0002879 (Best: 0.0001712 @iter7999) ([91m↑0.33%[0m) [0.06% of initial]
[Iter 8440/20000] Loss: 0.0002839 (Best: 0.0001712 @iter7999) ([92m↓1.39%[0m) [0.06% of initial]
[Iter 8450/20000] Loss: 0.0002827 (Best: 0.0001712 @iter7999) ([92m↓0.44%[0m) [0.06% of initial]
[Iter 8460/20000] Loss: 0.0002840 (Best: 0.0001712 @iter7999) ([91m↑0.48%[0m) [0.06% of initial]
[Iter 8470/20000] Loss: 0.0002801 (Best: 0.0001712 @iter7999) ([92m↓1.39%[0m) [0.06% of initial]
[Iter 8480/20000] Loss: 0.0002777 (Best: 0.0001712 @iter7999) ([92m↓0.85%[0m) [0.06% of initial]
[Iter 8490/20000] Loss: 0.0002811 (Best: 0.0001712 @iter7999) ([91m↑1.24%[0m) [0.06% of initial]
Iter:8499, L1 loss=0.0003004, Total loss=0.0002847, Time:18
[Iter 8500/20000] Loss: 0.0002755 (Best: 0.0001712 @iter7999) ([92m↓2.00%[0m) [0.06% of initial]
Pruning 231 points (4.6%) from gaussian0 at iteration 8500
Pruning 187 points (4.0%) from gaussian1 at iteration 8500
[Iter 8510/20000] Loss: 0.0006352 (Best: 0.0001712 @iter7999) ([91m↑130.57%[0m) [0.14% of initial]
[Iter 8520/20000] Loss: 0.0004372 (Best: 0.0001712 @iter7999) ([92m↓31.18%[0m) [0.09% of initial]
[Iter 8530/20000] Loss: 0.0003655 (Best: 0.0001712 @iter7999) ([92m↓16.40%[0m) [0.08% of initial]
[Iter 8540/20000] Loss: 0.0003350 (Best: 0.0001712 @iter7999) ([92m↓8.33%[0m) [0.07% of initial]
[Iter 8550/20000] Loss: 0.0003186 (Best: 0.0001712 @iter7999) ([92m↓4.92%[0m) [0.07% of initial]
[Iter 8560/20000] Loss: 0.0003052 (Best: 0.0001712 @iter7999) ([92m↓4.20%[0m) [0.07% of initial]
[Iter 8570/20000] Loss: 0.0003043 (Best: 0.0001712 @iter7999) ([92m↓0.28%[0m) [0.07% of initial]
[Iter 8580/20000] Loss: 0.0002983 (Best: 0.0001712 @iter7999) ([92m↓1.98%[0m) [0.06% of initial]
[Iter 8590/20000] Loss: 0.0002934 (Best: 0.0001712 @iter7999) ([92m↓1.64%[0m) [0.06% of initial]
Iter:8599, L1 loss=0.0002974, Total loss=0.0002946, Time:12
[Iter 8600/20000] Loss: 0.0002886 (Best: 0.0001712 @iter7999) ([92m↓1.66%[0m) [0.06% of initial]
[Iter 8610/20000] Loss: 0.0002858 (Best: 0.0001712 @iter7999) ([92m↓0.96%[0m) [0.06% of initial]
[Iter 8620/20000] Loss: 0.0002854 (Best: 0.0001712 @iter7999) ([92m↓0.15%[0m) [0.06% of initial]
[Iter 8630/20000] Loss: 0.0002817 (Best: 0.0001712 @iter7999) ([92m↓1.30%[0m) [0.06% of initial]
[Iter 8640/20000] Loss: 0.0002757 (Best: 0.0001712 @iter7999) ([92m↓2.11%[0m) [0.06% of initial]
[Iter 8650/20000] Loss: 0.0002747 (Best: 0.0001712 @iter7999) ([92m↓0.38%[0m) [0.06% of initial]
[Iter 8660/20000] Loss: 0.0002704 (Best: 0.0001712 @iter7999) ([92m↓1.54%[0m) [0.06% of initial]
[Iter 8670/20000] Loss: 0.0002692 (Best: 0.0001712 @iter7999) ([92m↓0.45%[0m) [0.06% of initial]
[Iter 8680/20000] Loss: 0.0002686 (Best: 0.0001712 @iter7999) ([92m↓0.23%[0m) [0.06% of initial]
[Iter 8690/20000] Loss: 0.0002676 (Best: 0.0001712 @iter7999) ([92m↓0.36%[0m) [0.06% of initial]
Iter:8699, L1 loss=0.0002737, Total loss=0.0002597, Time:19
[Iter 8700/20000] Loss: 0.0002664 (Best: 0.0001712 @iter7999) ([92m↓0.45%[0m) [0.06% of initial]
[Iter 8710/20000] Loss: 0.0002633 (Best: 0.0001712 @iter7999) ([92m↓1.18%[0m) [0.06% of initial]
[Iter 8720/20000] Loss: 0.0002611 (Best: 0.0001712 @iter7999) ([92m↓0.82%[0m) [0.06% of initial]
[Iter 8730/20000] Loss: 0.0002647 (Best: 0.0001712 @iter7999) ([91m↑1.36%[0m) [0.06% of initial]
[Iter 8740/20000] Loss: 0.0002607 (Best: 0.0001712 @iter7999) ([92m↓1.51%[0m) [0.06% of initial]
[Iter 8750/20000] Loss: 0.0002649 (Best: 0.0001712 @iter7999) ([91m↑1.62%[0m) [0.06% of initial]
[Iter 8760/20000] Loss: 0.0002628 (Best: 0.0001712 @iter7999) ([92m↓0.78%[0m) [0.06% of initial]
[Iter 8770/20000] Loss: 0.0002603 (Best: 0.0001712 @iter7999) ([92m↓0.97%[0m) [0.06% of initial]
[Iter 8780/20000] Loss: 0.0002595 (Best: 0.0001712 @iter7999) ([92m↓0.29%[0m) [0.06% of initial]
[Iter 8790/20000] Loss: 0.0002604 (Best: 0.0001712 @iter7999) ([91m↑0.34%[0m) [0.06% of initial]
Iter:8799, L1 loss=0.0002729, Total loss=0.0002595, Time:16
[Iter 8800/20000] Loss: 0.0002589 (Best: 0.0001712 @iter7999) ([92m↓0.56%[0m) [0.06% of initial]
[Iter 8810/20000] Loss: 0.0002588 (Best: 0.0001712 @iter7999) ([92m↓0.05%[0m) [0.06% of initial]
[Iter 8820/20000] Loss: 0.0002586 (Best: 0.0001712 @iter7999) ([92m↓0.09%[0m) [0.06% of initial]
[Iter 8830/20000] Loss: 0.0002552 (Best: 0.0001712 @iter7999) ([92m↓1.31%[0m) [0.06% of initial]
[Iter 8840/20000] Loss: 0.0002572 (Best: 0.0001712 @iter7999) ([91m↑0.80%[0m) [0.06% of initial]
[Iter 8850/20000] Loss: 0.0002603 (Best: 0.0001712 @iter7999) ([91m↑1.20%[0m) [0.06% of initial]
[Iter 8860/20000] Loss: 0.0002523 (Best: 0.0001712 @iter7999) ([92m↓3.08%[0m) [0.05% of initial]
[Iter 8870/20000] Loss: 0.0002515 (Best: 0.0001712 @iter7999) ([92m↓0.31%[0m) [0.05% of initial]
[Iter 8880/20000] Loss: 0.0002544 (Best: 0.0001712 @iter7999) ([91m↑1.15%[0m) [0.06% of initial]
[Iter 8890/20000] Loss: 0.0002546 (Best: 0.0001712 @iter7999) ([91m↑0.07%[0m) [0.06% of initial]
Iter:8899, L1 loss=0.0002602, Total loss=0.0002481, Time:16
[Iter 8900/20000] Loss: 0.0002519 (Best: 0.0001712 @iter7999) ([92m↓1.07%[0m) [0.05% of initial]
[Iter 8910/20000] Loss: 0.0002524 (Best: 0.0001712 @iter7999) ([91m↑0.23%[0m) [0.05% of initial]
[Iter 8920/20000] Loss: 0.0002490 (Best: 0.0001712 @iter7999) ([92m↓1.35%[0m) [0.05% of initial]
[Iter 8930/20000] Loss: 0.0002523 (Best: 0.0001712 @iter7999) ([91m↑1.31%[0m) [0.05% of initial]
[Iter 8940/20000] Loss: 0.0002517 (Best: 0.0001712 @iter7999) ([92m↓0.23%[0m) [0.05% of initial]
[Iter 8950/20000] Loss: 0.0002551 (Best: 0.0001712 @iter7999) ([91m↑1.36%[0m) [0.06% of initial]
[Iter 8960/20000] Loss: 0.0002523 (Best: 0.0001712 @iter7999) ([92m↓1.12%[0m) [0.05% of initial]
[Iter 8970/20000] Loss: 0.0002519 (Best: 0.0001712 @iter7999) ([92m↓0.14%[0m) [0.05% of initial]
[Iter 8980/20000] Loss: 0.0002518 (Best: 0.0001712 @iter7999) ([92m↓0.06%[0m) [0.05% of initial]
[Iter 8990/20000] Loss: 0.0002492 (Best: 0.0001712 @iter7999) ([92m↓1.01%[0m) [0.05% of initial]
Iter:8999, L1 loss=0.0002683, Total loss=0.0002534, Time:19
[Iter 9000/20000] Loss: 0.0002501 (Best: 0.0001712 @iter7999) ([91m↑0.36%[0m) [0.05% of initial]
Pruning 183 points (3.8%) from gaussian0 at iteration 9000
Pruning 119 points (2.7%) from gaussian1 at iteration 9000
[Iter 9010/20000] Loss: 0.0009945 (Best: 0.0001712 @iter7999) ([91m↑297.59%[0m) [0.22% of initial]
[Iter 9020/20000] Loss: 0.0005472 (Best: 0.0001712 @iter7999) ([92m↓44.98%[0m) [0.12% of initial]
[Iter 9030/20000] Loss: 0.0004048 (Best: 0.0001712 @iter7999) ([92m↓26.03%[0m) [0.09% of initial]
[Iter 9040/20000] Loss: 0.0003498 (Best: 0.0001712 @iter7999) ([92m↓13.57%[0m) [0.08% of initial]
[Iter 9050/20000] Loss: 0.0003190 (Best: 0.0001712 @iter7999) ([92m↓8.81%[0m) [0.07% of initial]
[Iter 9060/20000] Loss: 0.0003030 (Best: 0.0001712 @iter7999) ([92m↓5.02%[0m) [0.07% of initial]
[Iter 9070/20000] Loss: 0.0002962 (Best: 0.0001712 @iter7999) ([92m↓2.23%[0m) [0.06% of initial]
[Iter 9080/20000] Loss: 0.0002863 (Best: 0.0001712 @iter7999) ([92m↓3.34%[0m) [0.06% of initial]
[Iter 9090/20000] Loss: 0.0002846 (Best: 0.0001712 @iter7999) ([92m↓0.60%[0m) [0.06% of initial]
Iter:9099, L1 loss=0.0002774, Total loss=0.0002815, Time:18
[Iter 9100/20000] Loss: 0.0002802 (Best: 0.0001712 @iter7999) ([92m↓1.57%[0m) [0.06% of initial]
[Iter 9110/20000] Loss: 0.0002768 (Best: 0.0001712 @iter7999) ([92m↓1.19%[0m) [0.06% of initial]
[Iter 9120/20000] Loss: 0.0002743 (Best: 0.0001712 @iter7999) ([92m↓0.93%[0m) [0.06% of initial]
[Iter 9130/20000] Loss: 0.0002713 (Best: 0.0001712 @iter7999) ([92m↓1.06%[0m) [0.06% of initial]
[Iter 9140/20000] Loss: 0.0002694 (Best: 0.0001712 @iter7999) ([92m↓0.72%[0m) [0.06% of initial]
[Iter 9150/20000] Loss: 0.0002662 (Best: 0.0001712 @iter7999) ([92m↓1.17%[0m) [0.06% of initial]
[Iter 9160/20000] Loss: 0.0002611 (Best: 0.0001712 @iter7999) ([92m↓1.94%[0m) [0.06% of initial]
[Iter 9170/20000] Loss: 0.0002629 (Best: 0.0001712 @iter7999) ([91m↑0.72%[0m) [0.06% of initial]
[Iter 9180/20000] Loss: 0.0002621 (Best: 0.0001712 @iter7999) ([92m↓0.32%[0m) [0.06% of initial]
[Iter 9190/20000] Loss: 0.0002580 (Best: 0.0001712 @iter7999) ([92m↓1.55%[0m) [0.06% of initial]
Iter:9199, L1 loss=0.0002638, Total loss=0.0002558, Time:16
[Iter 9200/20000] Loss: 0.0002589 (Best: 0.0001712 @iter7999) ([91m↑0.33%[0m) [0.06% of initial]
[Iter 9210/20000] Loss: 0.0002579 (Best: 0.0001712 @iter7999) ([92m↓0.38%[0m) [0.06% of initial]
[Iter 9220/20000] Loss: 0.0002556 (Best: 0.0001712 @iter7999) ([92m↓0.91%[0m) [0.06% of initial]
[Iter 9230/20000] Loss: 0.0002554 (Best: 0.0001712 @iter7999) ([92m↓0.08%[0m) [0.06% of initial]
[Iter 9240/20000] Loss: 0.0002533 (Best: 0.0001712 @iter7999) ([92m↓0.82%[0m) [0.05% of initial]
[Iter 9250/20000] Loss: 0.0002524 (Best: 0.0001712 @iter7999) ([92m↓0.36%[0m) [0.05% of initial]
[Iter 9260/20000] Loss: 0.0002517 (Best: 0.0001712 @iter7999) ([92m↓0.29%[0m) [0.05% of initial]
[Iter 9270/20000] Loss: 0.0002533 (Best: 0.0001712 @iter7999) ([91m↑0.64%[0m) [0.05% of initial]
[Iter 9280/20000] Loss: 0.0002500 (Best: 0.0001712 @iter7999) ([92m↓1.30%[0m) [0.05% of initial]
[Iter 9290/20000] Loss: 0.0002510 (Best: 0.0001712 @iter7999) ([91m↑0.40%[0m) [0.05% of initial]
Iter:9299, L1 loss=0.0002679, Total loss=0.0002595, Time:15
[Iter 9300/20000] Loss: 0.0002529 (Best: 0.0001712 @iter7999) ([91m↑0.75%[0m) [0.05% of initial]
[Iter 9310/20000] Loss: 0.0002490 (Best: 0.0001712 @iter7999) ([92m↓1.53%[0m) [0.05% of initial]
[Iter 9320/20000] Loss: 0.0002506 (Best: 0.0001712 @iter7999) ([91m↑0.64%[0m) [0.05% of initial]
[Iter 9330/20000] Loss: 0.0002515 (Best: 0.0001712 @iter7999) ([91m↑0.36%[0m) [0.05% of initial]
[Iter 9340/20000] Loss: 0.0002464 (Best: 0.0001712 @iter7999) ([92m↓2.04%[0m) [0.05% of initial]
[Iter 9350/20000] Loss: 0.0002503 (Best: 0.0001712 @iter7999) ([91m↑1.60%[0m) [0.05% of initial]
[Iter 9360/20000] Loss: 0.0002472 (Best: 0.0001712 @iter7999) ([92m↓1.26%[0m) [0.05% of initial]
[Iter 9370/20000] Loss: 0.0002494 (Best: 0.0001712 @iter7999) ([91m↑0.89%[0m) [0.05% of initial]
[Iter 9380/20000] Loss: 0.0002453 (Best: 0.0001712 @iter7999) ([92m↓1.64%[0m) [0.05% of initial]
[Iter 9390/20000] Loss: 0.0002448 (Best: 0.0001712 @iter7999) ([92m↓0.19%[0m) [0.05% of initial]
Iter:9399, L1 loss=0.0002583, Total loss=0.0002439, Time:20
[Iter 9400/20000] Loss: 0.0002461 (Best: 0.0001712 @iter7999) ([91m↑0.54%[0m) [0.05% of initial]
[Iter 9410/20000] Loss: 0.0002450 (Best: 0.0001712 @iter7999) ([92m↓0.46%[0m) [0.05% of initial]
[Iter 9420/20000] Loss: 0.0002453 (Best: 0.0001712 @iter7999) ([91m↑0.11%[0m) [0.05% of initial]
[Iter 9430/20000] Loss: 0.0002425 (Best: 0.0001712 @iter7999) ([92m↓1.14%[0m) [0.05% of initial]
[Iter 9440/20000] Loss: 0.0002432 (Best: 0.0001712 @iter7999) ([91m↑0.31%[0m) [0.05% of initial]
[Iter 9450/20000] Loss: 0.0002437 (Best: 0.0001712 @iter7999) ([91m↑0.21%[0m) [0.05% of initial]
[Iter 9460/20000] Loss: 0.0002412 (Best: 0.0001712 @iter7999) ([92m↓1.02%[0m) [0.05% of initial]
[Iter 9470/20000] Loss: 0.0002431 (Best: 0.0001712 @iter7999) ([91m↑0.79%[0m) [0.05% of initial]
[Iter 9480/20000] Loss: 0.0002432 (Best: 0.0001712 @iter7999) ([91m↑0.02%[0m) [0.05% of initial]
[Iter 9490/20000] Loss: 0.0002434 (Best: 0.0001712 @iter7999) ([91m↑0.09%[0m) [0.05% of initial]
Iter:9499, L1 loss=0.0002478, Total loss=0.0002371, Time:23
[Iter 9500/20000] Loss: 0.0002436 (Best: 0.0001712 @iter7999) ([91m↑0.10%[0m) [0.05% of initial]
Pruning 159 points (3.4%) from gaussian0 at iteration 9500
Pruning 131 points (3.0%) from gaussian1 at iteration 9500
[Iter 9510/20000] Loss: 0.0006471 (Best: 0.0001712 @iter7999) ([91m↑165.62%[0m) [0.14% of initial]
[Iter 9520/20000] Loss: 0.0004335 (Best: 0.0001712 @iter7999) ([92m↓33.01%[0m) [0.09% of initial]
[Iter 9530/20000] Loss: 0.0003556 (Best: 0.0001712 @iter7999) ([92m↓17.98%[0m) [0.08% of initial]
[Iter 9540/20000] Loss: 0.0003201 (Best: 0.0001712 @iter7999) ([92m↓9.99%[0m) [0.07% of initial]
[Iter 9550/20000] Loss: 0.0003018 (Best: 0.0001712 @iter7999) ([92m↓5.72%[0m) [0.07% of initial]
[Iter 9560/20000] Loss: 0.0002902 (Best: 0.0001712 @iter7999) ([92m↓3.84%[0m) [0.06% of initial]
[Iter 9570/20000] Loss: 0.0002843 (Best: 0.0001712 @iter7999) ([92m↓2.02%[0m) [0.06% of initial]
[Iter 9580/20000] Loss: 0.0002796 (Best: 0.0001712 @iter7999) ([92m↓1.64%[0m) [0.06% of initial]
[Iter 9590/20000] Loss: 0.0002732 (Best: 0.0001712 @iter7999) ([92m↓2.31%[0m) [0.06% of initial]
Iter:9599, L1 loss=0.0002802, Total loss=0.0002708, Time:21
[Iter 9600/20000] Loss: 0.0002693 (Best: 0.0001712 @iter7999) ([92m↓1.41%[0m) [0.06% of initial]
[Iter 9610/20000] Loss: 0.0002689 (Best: 0.0001712 @iter7999) ([92m↓0.15%[0m) [0.06% of initial]
[Iter 9620/20000] Loss: 0.0002646 (Best: 0.0001712 @iter7999) ([92m↓1.60%[0m) [0.06% of initial]
[Iter 9630/20000] Loss: 0.0002635 (Best: 0.0001712 @iter7999) ([92m↓0.41%[0m) [0.06% of initial]
[Iter 9640/20000] Loss: 0.0002576 (Best: 0.0001712 @iter7999) ([92m↓2.23%[0m) [0.06% of initial]
[Iter 9650/20000] Loss: 0.0002596 (Best: 0.0001712 @iter7999) ([91m↑0.76%[0m) [0.06% of initial]
[Iter 9660/20000] Loss: 0.0002555 (Best: 0.0001712 @iter7999) ([92m↓1.56%[0m) [0.06% of initial]
[Iter 9670/20000] Loss: 0.0002573 (Best: 0.0001712 @iter7999) ([91m↑0.68%[0m) [0.06% of initial]
[Iter 9680/20000] Loss: 0.0002542 (Best: 0.0001712 @iter7999) ([92m↓1.18%[0m) [0.06% of initial]
[Iter 9690/20000] Loss: 0.0002561 (Best: 0.0001712 @iter7999) ([91m↑0.76%[0m) [0.06% of initial]
Iter:9699, L1 loss=0.0002709, Total loss=0.0002569, Time:20
[Iter 9700/20000] Loss: 0.0002520 (Best: 0.0001712 @iter7999) ([92m↓1.62%[0m) [0.05% of initial]
[Iter 9710/20000] Loss: 0.0002545 (Best: 0.0001712 @iter7999) ([91m↑0.98%[0m) [0.06% of initial]
[Iter 9720/20000] Loss: 0.0002523 (Best: 0.0001712 @iter7999) ([92m↓0.87%[0m) [0.05% of initial]
[Iter 9730/20000] Loss: 0.0002550 (Best: 0.0001712 @iter7999) ([91m↑1.09%[0m) [0.06% of initial]
[Iter 9740/20000] Loss: 0.0002553 (Best: 0.0001712 @iter7999) ([91m↑0.10%[0m) [0.06% of initial]
[Iter 9750/20000] Loss: 0.0002526 (Best: 0.0001712 @iter7999) ([92m↓1.06%[0m) [0.05% of initial]
[Iter 9760/20000] Loss: 0.0002491 (Best: 0.0001712 @iter7999) ([92m↓1.39%[0m) [0.05% of initial]
[Iter 9770/20000] Loss: 0.0002479 (Best: 0.0001712 @iter7999) ([92m↓0.46%[0m) [0.05% of initial]
[Iter 9780/20000] Loss: 0.0002485 (Best: 0.0001712 @iter7999) ([91m↑0.25%[0m) [0.05% of initial]
[Iter 9790/20000] Loss: 0.0002467 (Best: 0.0001712 @iter7999) ([92m↓0.73%[0m) [0.05% of initial]
Iter:9799, L1 loss=0.0002609, Total loss=0.0002485, Time:11
[Iter 9800/20000] Loss: 0.0002478 (Best: 0.0001712 @iter7999) ([91m↑0.43%[0m) [0.05% of initial]
[Iter 9810/20000] Loss: 0.0002472 (Best: 0.0001712 @iter7999) ([92m↓0.24%[0m) [0.05% of initial]
[Iter 9820/20000] Loss: 0.0002433 (Best: 0.0001712 @iter7999) ([92m↓1.57%[0m) [0.05% of initial]
[Iter 9830/20000] Loss: 0.0002448 (Best: 0.0001712 @iter7999) ([91m↑0.62%[0m) [0.05% of initial]
[Iter 9840/20000] Loss: 0.0002475 (Best: 0.0001712 @iter7999) ([91m↑1.11%[0m) [0.05% of initial]
[Iter 9850/20000] Loss: 0.0002448 (Best: 0.0001712 @iter7999) ([92m↓1.12%[0m) [0.05% of initial]
[Iter 9860/20000] Loss: 0.0002434 (Best: 0.0001712 @iter7999) ([92m↓0.58%[0m) [0.05% of initial]
[Iter 9870/20000] Loss: 0.0002435 (Best: 0.0001712 @iter7999) ([91m↑0.05%[0m) [0.05% of initial]
[Iter 9880/20000] Loss: 0.0002430 (Best: 0.0001712 @iter7999) ([92m↓0.21%[0m) [0.05% of initial]
[Iter 9890/20000] Loss: 0.0002448 (Best: 0.0001712 @iter7999) ([91m↑0.74%[0m) [0.05% of initial]
Iter:9899, L1 loss=0.0002595, Total loss=0.0002447, Time:19
[Iter 9900/20000] Loss: 0.0002437 (Best: 0.0001712 @iter7999) ([92m↓0.42%[0m) [0.05% of initial]
[Iter 9910/20000] Loss: 0.0002388 (Best: 0.0001712 @iter7999) ([92m↓2.02%[0m) [0.05% of initial]
[Iter 9920/20000] Loss: 0.0002424 (Best: 0.0001712 @iter7999) ([91m↑1.51%[0m) [0.05% of initial]
[Iter 9930/20000] Loss: 0.0002412 (Best: 0.0001712 @iter7999) ([92m↓0.50%[0m) [0.05% of initial]
[Iter 9940/20000] Loss: 0.0002413 (Best: 0.0001712 @iter7999) ([91m↑0.03%[0m) [0.05% of initial]
[Iter 9950/20000] Loss: 0.0002428 (Best: 0.0001712 @iter7999) ([91m↑0.64%[0m) [0.05% of initial]
[Iter 9960/20000] Loss: 0.0002449 (Best: 0.0001712 @iter7999) ([91m↑0.85%[0m) [0.05% of initial]
[Iter 9970/20000] Loss: 0.0002424 (Best: 0.0001712 @iter7999) ([92m↓1.03%[0m) [0.05% of initial]
[Iter 9980/20000] Loss: 0.0002401 (Best: 0.0001712 @iter7999) ([92m↓0.95%[0m) [0.05% of initial]
[Iter 9990/20000] Loss: 0.0002408 (Best: 0.0001712 @iter7999) ([91m↑0.29%[0m) [0.05% of initial]
Iter:9999, L1 loss=0.0002587, Total loss=0.0002425, Time:19
[Iter 10000/20000] Loss: 0.0002422 (Best: 0.0001712 @iter7999) ([91m↑0.59%[0m) [0.05% of initial]
Pruning 129 points (2.9%) from gaussian0 at iteration 10000
Pruning 88 points (2.1%) from gaussian1 at iteration 10000
[Iter 10010/20000] Loss: 0.0004916 (Best: 0.0001712 @iter7999) ([91m↑103.00%[0m) [0.11% of initial]
[Iter 10020/20000] Loss: 0.0003677 (Best: 0.0001712 @iter7999) ([92m↓25.20%[0m) [0.08% of initial]
[Iter 10030/20000] Loss: 0.0003151 (Best: 0.0001712 @iter7999) ([92m↓14.31%[0m) [0.07% of initial]
[Iter 10040/20000] Loss: 0.0002898 (Best: 0.0001712 @iter7999) ([92m↓8.03%[0m) [0.06% of initial]
[Iter 10050/20000] Loss: 0.0002850 (Best: 0.0001712 @iter7999) ([92m↓1.66%[0m) [0.06% of initial]
[Iter 10060/20000] Loss: 0.0002821 (Best: 0.0001712 @iter7999) ([92m↓1.01%[0m) [0.06% of initial]
[Iter 10070/20000] Loss: 0.0002719 (Best: 0.0001712 @iter7999) ([92m↓3.63%[0m) [0.06% of initial]
[Iter 10080/20000] Loss: 0.0002661 (Best: 0.0001712 @iter7999) ([92m↓2.13%[0m) [0.06% of initial]
[Iter 10090/20000] Loss: 0.0002600 (Best: 0.0001712 @iter7999) ([92m↓2.28%[0m) [0.06% of initial]
Iter:10099, L1 loss=0.0002721, Total loss=0.00026, Time:16
[Iter 10100/20000] Loss: 0.0002627 (Best: 0.0001712 @iter7999) ([91m↑1.02%[0m) [0.06% of initial]
[Iter 10110/20000] Loss: 0.0002589 (Best: 0.0001712 @iter7999) ([92m↓1.43%[0m) [0.06% of initial]
[Iter 10120/20000] Loss: 0.0002563 (Best: 0.0001712 @iter7999) ([92m↓1.00%[0m) [0.06% of initial]
[Iter 10130/20000] Loss: 0.0002527 (Best: 0.0001712 @iter7999) ([92m↓1.42%[0m) [0.05% of initial]
[Iter 10140/20000] Loss: 0.0002536 (Best: 0.0001712 @iter7999) ([91m↑0.34%[0m) [0.06% of initial]
[Iter 10150/20000] Loss: 0.0002519 (Best: 0.0001712 @iter7999) ([92m↓0.66%[0m) [0.05% of initial]
[Iter 10160/20000] Loss: 0.0002541 (Best: 0.0001712 @iter7999) ([91m↑0.89%[0m) [0.06% of initial]
[Iter 10170/20000] Loss: 0.0002504 (Best: 0.0001712 @iter7999) ([92m↓1.47%[0m) [0.05% of initial]
[Iter 10180/20000] Loss: 0.0002482 (Best: 0.0001712 @iter7999) ([92m↓0.88%[0m) [0.05% of initial]
[Iter 10190/20000] Loss: 0.0002479 (Best: 0.0001712 @iter7999) ([92m↓0.13%[0m) [0.05% of initial]
Iter:10199, L1 loss=0.0002592, Total loss=0.0002455, Time:20
[Iter 10200/20000] Loss: 0.0002449 (Best: 0.0001712 @iter7999) ([92m↓1.21%[0m) [0.05% of initial]
[Iter 10210/20000] Loss: 0.0002437 (Best: 0.0001712 @iter7999) ([92m↓0.48%[0m) [0.05% of initial]
[Iter 10220/20000] Loss: 0.0002433 (Best: 0.0001712 @iter7999) ([92m↓0.16%[0m) [0.05% of initial]
[Iter 10230/20000] Loss: 0.0002454 (Best: 0.0001712 @iter7999) ([91m↑0.85%[0m) [0.05% of initial]
[Iter 10240/20000] Loss: 0.0002441 (Best: 0.0001712 @iter7999) ([92m↓0.50%[0m) [0.05% of initial]
[Iter 10250/20000] Loss: 0.0002452 (Best: 0.0001712 @iter7999) ([91m↑0.43%[0m) [0.05% of initial]
[Iter 10260/20000] Loss: 0.0002542 (Best: 0.0001712 @iter7999) ([91m↑3.67%[0m) [0.06% of initial]
[Iter 10270/20000] Loss: 0.0002457 (Best: 0.0001712 @iter7999) ([92m↓3.34%[0m) [0.05% of initial]
[Iter 10280/20000] Loss: 0.0002492 (Best: 0.0001712 @iter7999) ([91m↑1.42%[0m) [0.05% of initial]
[Iter 10290/20000] Loss: 0.0002451 (Best: 0.0001712 @iter7999) ([92m↓1.65%[0m) [0.05% of initial]
Iter:10299, L1 loss=0.0002542, Total loss=0.0002449, Time:16
[Iter 10300/20000] Loss: 0.0002424 (Best: 0.0001712 @iter7999) ([92m↓1.09%[0m) [0.05% of initial]
[Iter 10310/20000] Loss: 0.0002443 (Best: 0.0001712 @iter7999) ([91m↑0.77%[0m) [0.05% of initial]
[Iter 10320/20000] Loss: 0.0002452 (Best: 0.0001712 @iter7999) ([91m↑0.37%[0m) [0.05% of initial]
[Iter 10330/20000] Loss: 0.0002439 (Best: 0.0001712 @iter7999) ([92m↓0.51%[0m) [0.05% of initial]
[Iter 10340/20000] Loss: 0.0002442 (Best: 0.0001712 @iter7999) ([91m↑0.10%[0m) [0.05% of initial]
[Iter 10350/20000] Loss: 0.0002449 (Best: 0.0001712 @iter7999) ([91m↑0.30%[0m) [0.05% of initial]
[Iter 10360/20000] Loss: 0.0002435 (Best: 0.0001712 @iter7999) ([92m↓0.56%[0m) [0.05% of initial]
[Iter 10370/20000] Loss: 0.0002462 (Best: 0.0001712 @iter7999) ([91m↑1.11%[0m) [0.05% of initial]
[Iter 10380/20000] Loss: 0.0002442 (Best: 0.0001712 @iter7999) ([92m↓0.82%[0m) [0.05% of initial]
[Iter 10390/20000] Loss: 0.0002403 (Best: 0.0001712 @iter7999) ([92m↓1.61%[0m) [0.05% of initial]
Iter:10399, L1 loss=0.0002497, Total loss=0.0002403, Time:21
[Iter 10400/20000] Loss: 0.0002417 (Best: 0.0001712 @iter7999) ([91m↑0.60%[0m) [0.05% of initial]
[Iter 10410/20000] Loss: 0.0002414 (Best: 0.0001712 @iter7999) ([92m↓0.16%[0m) [0.05% of initial]
[Iter 10420/20000] Loss: 0.0002383 (Best: 0.0001712 @iter7999) ([92m↓1.26%[0m) [0.05% of initial]
[Iter 10430/20000] Loss: 0.0002410 (Best: 0.0001712 @iter7999) ([91m↑1.13%[0m) [0.05% of initial]
[Iter 10440/20000] Loss: 0.0002418 (Best: 0.0001712 @iter7999) ([91m↑0.33%[0m) [0.05% of initial]
[Iter 10450/20000] Loss: 0.0002441 (Best: 0.0001712 @iter7999) ([91m↑0.96%[0m) [0.05% of initial]
[Iter 10460/20000] Loss: 0.0002385 (Best: 0.0001712 @iter7999) ([92m↓2.32%[0m) [0.05% of initial]
[Iter 10470/20000] Loss: 0.0002410 (Best: 0.0001712 @iter7999) ([91m↑1.04%[0m) [0.05% of initial]
[Iter 10480/20000] Loss: 0.0002392 (Best: 0.0001712 @iter7999) ([92m↓0.71%[0m) [0.05% of initial]
[Iter 10490/20000] Loss: 0.0002370 (Best: 0.0001712 @iter7999) ([92m↓0.94%[0m) [0.05% of initial]
Iter:10499, L1 loss=0.0002627, Total loss=0.0002403, Time:14
[Iter 10500/20000] Loss: 0.0002383 (Best: 0.0001712 @iter7999) ([91m↑0.56%[0m) [0.05% of initial]
Pruning 93 points (2.1%) from gaussian0 at iteration 10500
Pruning 81 points (2.0%) from gaussian1 at iteration 10500
[Iter 10510/20000] Loss: 0.0004174 (Best: 0.0001712 @iter7999) ([91m↑75.11%[0m) [0.09% of initial]
[Iter 10520/20000] Loss: 0.0003394 (Best: 0.0001712 @iter7999) ([92m↓18.67%[0m) [0.07% of initial]
[Iter 10530/20000] Loss: 0.0003063 (Best: 0.0001712 @iter7999) ([92m↓9.76%[0m) [0.07% of initial]
[Iter 10540/20000] Loss: 0.0002869 (Best: 0.0001712 @iter7999) ([92m↓6.34%[0m) [0.06% of initial]
[Iter 10550/20000] Loss: 0.0002770 (Best: 0.0001712 @iter7999) ([92m↓3.45%[0m) [0.06% of initial]
[Iter 10560/20000] Loss: 0.0002678 (Best: 0.0001712 @iter7999) ([92m↓3.31%[0m) [0.06% of initial]
[Iter 10570/20000] Loss: 0.0002600 (Best: 0.0001712 @iter7999) ([92m↓2.92%[0m) [0.06% of initial]
[Iter 10580/20000] Loss: 0.0002575 (Best: 0.0001712 @iter7999) ([92m↓0.97%[0m) [0.06% of initial]
[Iter 10590/20000] Loss: 0.0002578 (Best: 0.0001712 @iter7999) ([91m↑0.13%[0m) [0.06% of initial]
Iter:10599, L1 loss=0.0002712, Total loss=0.0002517, Time:15
[Iter 10600/20000] Loss: 0.0002534 (Best: 0.0001712 @iter7999) ([92m↓1.73%[0m) [0.05% of initial]
[Iter 10610/20000] Loss: 0.0002544 (Best: 0.0001712 @iter7999) ([91m↑0.39%[0m) [0.06% of initial]
[Iter 10620/20000] Loss: 0.0002520 (Best: 0.0001712 @iter7999) ([92m↓0.93%[0m) [0.05% of initial]
[Iter 10630/20000] Loss: 0.0002507 (Best: 0.0001712 @iter7999) ([92m↓0.53%[0m) [0.05% of initial]
[Iter 10640/20000] Loss: 0.0002513 (Best: 0.0001712 @iter7999) ([91m↑0.26%[0m) [0.05% of initial]
[Iter 10650/20000] Loss: 0.0002495 (Best: 0.0001712 @iter7999) ([92m↓0.70%[0m) [0.05% of initial]
[Iter 10660/20000] Loss: 0.0002456 (Best: 0.0001712 @iter7999) ([92m↓1.60%[0m) [0.05% of initial]
[Iter 10670/20000] Loss: 0.0002463 (Best: 0.0001712 @iter7999) ([91m↑0.31%[0m) [0.05% of initial]
[Iter 10680/20000] Loss: 0.0002446 (Best: 0.0001712 @iter7999) ([92m↓0.69%[0m) [0.05% of initial]
[Iter 10690/20000] Loss: 0.0002467 (Best: 0.0001712 @iter7999) ([91m↑0.85%[0m) [0.05% of initial]
Iter:10699, L1 loss=0.0002591, Total loss=0.0002416, Time:16
[Iter 10700/20000] Loss: 0.0002461 (Best: 0.0001712 @iter7999) ([92m↓0.25%[0m) [0.05% of initial]
[Iter 10710/20000] Loss: 0.0002453 (Best: 0.0001712 @iter7999) ([92m↓0.33%[0m) [0.05% of initial]
[Iter 10720/20000] Loss: 0.0002448 (Best: 0.0001712 @iter7999) ([92m↓0.17%[0m) [0.05% of initial]
[Iter 10730/20000] Loss: 0.0002483 (Best: 0.0001712 @iter7999) ([91m↑1.44%[0m) [0.05% of initial]
[Iter 10740/20000] Loss: 0.0002445 (Best: 0.0001712 @iter7999) ([92m↓1.55%[0m) [0.05% of initial]
[Iter 10750/20000] Loss: 0.0002461 (Best: 0.0001712 @iter7999) ([91m↑0.67%[0m) [0.05% of initial]
[Iter 10760/20000] Loss: 0.0002453 (Best: 0.0001712 @iter7999) ([92m↓0.31%[0m) [0.05% of initial]
[Iter 10770/20000] Loss: 0.0002444 (Best: 0.0001712 @iter7999) ([92m↓0.40%[0m) [0.05% of initial]
[Iter 10780/20000] Loss: 0.0002417 (Best: 0.0001712 @iter7999) ([92m↓1.10%[0m) [0.05% of initial]
[Iter 10790/20000] Loss: 0.0002403 (Best: 0.0001712 @iter7999) ([92m↓0.56%[0m) [0.05% of initial]
Iter:10799, L1 loss=0.0002504, Total loss=0.0002376, Time:15
[Iter 10800/20000] Loss: 0.0002426 (Best: 0.0001712 @iter7999) ([91m↑0.93%[0m) [0.05% of initial]
[Iter 10810/20000] Loss: 0.0002431 (Best: 0.0001712 @iter7999) ([91m↑0.20%[0m) [0.05% of initial]
[Iter 10820/20000] Loss: 0.0002412 (Best: 0.0001712 @iter7999) ([92m↓0.77%[0m) [0.05% of initial]
[Iter 10830/20000] Loss: 0.0002404 (Best: 0.0001712 @iter7999) ([92m↓0.32%[0m) [0.05% of initial]
[Iter 10840/20000] Loss: 0.0002387 (Best: 0.0001712 @iter7999) ([92m↓0.74%[0m) [0.05% of initial]
[Iter 10850/20000] Loss: 0.0002418 (Best: 0.0001712 @iter7999) ([91m↑1.31%[0m) [0.05% of initial]
[Iter 10860/20000] Loss: 0.0002395 (Best: 0.0001712 @iter7999) ([92m↓0.93%[0m) [0.05% of initial]
[Iter 10870/20000] Loss: 0.0002388 (Best: 0.0001712 @iter7999) ([92m↓0.30%[0m) [0.05% of initial]
[Iter 10880/20000] Loss: 0.0002415 (Best: 0.0001712 @iter7999) ([91m↑1.13%[0m) [0.05% of initial]
[Iter 10890/20000] Loss: 0.0002429 (Best: 0.0001712 @iter7999) ([91m↑0.56%[0m) [0.05% of initial]
Iter:10899, L1 loss=0.0002643, Total loss=0.0002442, Time:18
[Iter 10900/20000] Loss: 0.0002398 (Best: 0.0001712 @iter7999) ([92m↓1.28%[0m) [0.05% of initial]
[Iter 10910/20000] Loss: 0.0002388 (Best: 0.0001712 @iter7999) ([92m↓0.42%[0m) [0.05% of initial]
[Iter 10920/20000] Loss: 0.0002401 (Best: 0.0001712 @iter7999) ([91m↑0.57%[0m) [0.05% of initial]
[Iter 10930/20000] Loss: 0.0002404 (Best: 0.0001712 @iter7999) ([91m↑0.10%[0m) [0.05% of initial]
[Iter 10940/20000] Loss: 0.0002397 (Best: 0.0001712 @iter7999) ([92m↓0.25%[0m) [0.05% of initial]
[Iter 10950/20000] Loss: 0.0002394 (Best: 0.0001712 @iter7999) ([92m↓0.15%[0m) [0.05% of initial]
[Iter 10960/20000] Loss: 0.0002403 (Best: 0.0001712 @iter7999) ([91m↑0.37%[0m) [0.05% of initial]
[Iter 10970/20000] Loss: 0.0002406 (Best: 0.0001712 @iter7999) ([91m↑0.12%[0m) [0.05% of initial]
[Iter 10980/20000] Loss: 0.0002380 (Best: 0.0001712 @iter7999) ([92m↓1.06%[0m) [0.05% of initial]
[Iter 10990/20000] Loss: 0.0002377 (Best: 0.0001712 @iter7999) ([92m↓0.13%[0m) [0.05% of initial]
Iter:10999, L1 loss=0.00025, Total loss=0.0002366, Time:16
[Iter 11000/20000] Loss: 0.0002385 (Best: 0.0001712 @iter7999) ([91m↑0.34%[0m) [0.05% of initial]
Pruning 107 points (2.5%) from gaussian0 at iteration 11000
Pruning 81 points (2.0%) from gaussian1 at iteration 11000
[Iter 11010/20000] Loss: 0.0014772 (Best: 0.0001712 @iter7999) ([91m↑519.31%[0m) [0.32% of initial]
[Iter 11020/20000] Loss: 0.0006963 (Best: 0.0001712 @iter7999) ([92m↓52.86%[0m) [0.15% of initial]
[Iter 11030/20000] Loss: 0.0004795 (Best: 0.0001712 @iter7999) ([92m↓31.13%[0m) [0.10% of initial]
[Iter 11040/20000] Loss: 0.0003852 (Best: 0.0001712 @iter7999) ([92m↓19.68%[0m) [0.08% of initial]
[Iter 11050/20000] Loss: 0.0003449 (Best: 0.0001712 @iter7999) ([92m↓10.45%[0m) [0.07% of initial]
[Iter 11060/20000] Loss: 0.0003214 (Best: 0.0001712 @iter7999) ([92m↓6.81%[0m) [0.07% of initial]
[Iter 11070/20000] Loss: 0.0003072 (Best: 0.0001712 @iter7999) ([92m↓4.44%[0m) [0.07% of initial]
[Iter 11080/20000] Loss: 0.0003019 (Best: 0.0001712 @iter7999) ([92m↓1.72%[0m) [0.07% of initial]
[Iter 11090/20000] Loss: 0.0002972 (Best: 0.0001712 @iter7999) ([92m↓1.55%[0m) [0.06% of initial]
Iter:11099, L1 loss=0.0002904, Total loss=0.0002994, Time:18
[Iter 11100/20000] Loss: 0.0002903 (Best: 0.0001712 @iter7999) ([92m↓2.31%[0m) [0.06% of initial]
[Iter 11110/20000] Loss: 0.0002855 (Best: 0.0001712 @iter7999) ([92m↓1.65%[0m) [0.06% of initial]
[Iter 11120/20000] Loss: 0.0002781 (Best: 0.0001712 @iter7999) ([92m↓2.61%[0m) [0.06% of initial]
[Iter 11130/20000] Loss: 0.0002774 (Best: 0.0001712 @iter7999) ([92m↓0.24%[0m) [0.06% of initial]
[Iter 11140/20000] Loss: 0.0002689 (Best: 0.0001712 @iter7999) ([92m↓3.06%[0m) [0.06% of initial]
[Iter 11150/20000] Loss: 0.0002727 (Best: 0.0001712 @iter7999) ([91m↑1.40%[0m) [0.06% of initial]
[Iter 11160/20000] Loss: 0.0002707 (Best: 0.0001712 @iter7999) ([92m↓0.74%[0m) [0.06% of initial]
[Iter 11170/20000] Loss: 0.0002699 (Best: 0.0001712 @iter7999) ([92m↓0.26%[0m) [0.06% of initial]
[Iter 11180/20000] Loss: 0.0002698 (Best: 0.0001712 @iter7999) ([92m↓0.05%[0m) [0.06% of initial]
[Iter 11190/20000] Loss: 0.0002614 (Best: 0.0001712 @iter7999) ([92m↓3.13%[0m) [0.06% of initial]
Iter:11199, L1 loss=0.0002533, Total loss=0.0002522, Time:14
[Iter 11200/20000] Loss: 0.0002643 (Best: 0.0001712 @iter7999) ([91m↑1.10%[0m) [0.06% of initial]
[Iter 11210/20000] Loss: 0.0002584 (Best: 0.0001712 @iter7999) ([92m↓2.23%[0m) [0.06% of initial]
[Iter 11220/20000] Loss: 0.0002636 (Best: 0.0001712 @iter7999) ([91m↑2.03%[0m) [0.06% of initial]
[Iter 11230/20000] Loss: 0.0002589 (Best: 0.0001712 @iter7999) ([92m↓1.77%[0m) [0.06% of initial]
[Iter 11240/20000] Loss: 0.0002585 (Best: 0.0001712 @iter7999) ([92m↓0.17%[0m) [0.06% of initial]
[Iter 11250/20000] Loss: 0.0002589 (Best: 0.0001712 @iter7999) ([91m↑0.15%[0m) [0.06% of initial]
[Iter 11260/20000] Loss: 0.0002545 (Best: 0.0001712 @iter7999) ([92m↓1.68%[0m) [0.06% of initial]
[Iter 11270/20000] Loss: 0.0002571 (Best: 0.0001712 @iter7999) ([91m↑1.02%[0m) [0.06% of initial]
[Iter 11280/20000] Loss: 0.0002517 (Best: 0.0001712 @iter7999) ([92m↓2.11%[0m) [0.05% of initial]
[Iter 11290/20000] Loss: 0.0002520 (Best: 0.0001712 @iter7999) ([91m↑0.11%[0m) [0.05% of initial]
Iter:11299, L1 loss=0.0002477, Total loss=0.0002418, Time:16
[Iter 11300/20000] Loss: 0.0002502 (Best: 0.0001712 @iter7999) ([92m↓0.72%[0m) [0.05% of initial]
[Iter 11310/20000] Loss: 0.0002504 (Best: 0.0001712 @iter7999) ([91m↑0.07%[0m) [0.05% of initial]
[Iter 11320/20000] Loss: 0.0002478 (Best: 0.0001712 @iter7999) ([92m↓1.01%[0m) [0.05% of initial]
[Iter 11330/20000] Loss: 0.0002486 (Best: 0.0001712 @iter7999) ([91m↑0.29%[0m) [0.05% of initial]
[Iter 11340/20000] Loss: 0.0002517 (Best: 0.0001712 @iter7999) ([91m↑1.26%[0m) [0.05% of initial]
[Iter 11350/20000] Loss: 0.0002518 (Best: 0.0001712 @iter7999) ([91m↑0.06%[0m) [0.05% of initial]
[Iter 11360/20000] Loss: 0.0002467 (Best: 0.0001712 @iter7999) ([92m↓2.02%[0m) [0.05% of initial]
[Iter 11370/20000] Loss: 0.0002480 (Best: 0.0001712 @iter7999) ([91m↑0.49%[0m) [0.05% of initial]
[Iter 11380/20000] Loss: 0.0002470 (Best: 0.0001712 @iter7999) ([92m↓0.38%[0m) [0.05% of initial]
[Iter 11390/20000] Loss: 0.0002454 (Best: 0.0001712 @iter7999) ([92m↓0.65%[0m) [0.05% of initial]
Iter:11399, L1 loss=0.0002658, Total loss=0.0002505, Time:20
[Iter 11400/20000] Loss: 0.0002464 (Best: 0.0001712 @iter7999) ([91m↑0.42%[0m) [0.05% of initial]
[Iter 11410/20000] Loss: 0.0002437 (Best: 0.0001712 @iter7999) ([92m↓1.13%[0m) [0.05% of initial]
[Iter 11420/20000] Loss: 0.0002462 (Best: 0.0001712 @iter7999) ([91m↑1.04%[0m) [0.05% of initial]
[Iter 11430/20000] Loss: 0.0002472 (Best: 0.0001712 @iter7999) ([91m↑0.39%[0m) [0.05% of initial]
[Iter 11440/20000] Loss: 0.0002439 (Best: 0.0001712 @iter7999) ([92m↓1.32%[0m) [0.05% of initial]
[Iter 11450/20000] Loss: 0.0002427 (Best: 0.0001712 @iter7999) ([92m↓0.49%[0m) [0.05% of initial]
[Iter 11460/20000] Loss: 0.0002413 (Best: 0.0001712 @iter7999) ([92m↓0.58%[0m) [0.05% of initial]
[Iter 11470/20000] Loss: 0.0002435 (Best: 0.0001712 @iter7999) ([91m↑0.90%[0m) [0.05% of initial]
[Iter 11480/20000] Loss: 0.0002457 (Best: 0.0001712 @iter7999) ([91m↑0.91%[0m) [0.05% of initial]
[Iter 11490/20000] Loss: 0.0002438 (Best: 0.0001712 @iter7999) ([92m↓0.77%[0m) [0.05% of initial]
Iter:11499, L1 loss=0.0002587, Total loss=0.0002481, Time:18
[Iter 11500/20000] Loss: 0.0002458 (Best: 0.0001712 @iter7999) ([91m↑0.81%[0m) [0.05% of initial]
Pruning 88 points (2.1%) from gaussian0 at iteration 11500
Pruning 72 points (1.8%) from gaussian1 at iteration 11500
[Iter 11510/20000] Loss: 0.0010666 (Best: 0.0001712 @iter7999) ([91m↑334.01%[0m) [0.23% of initial]
[Iter 11520/20000] Loss: 0.0006799 (Best: 0.0001712 @iter7999) ([92m↓36.26%[0m) [0.15% of initial]
[Iter 11530/20000] Loss: 0.0005137 (Best: 0.0001712 @iter7999) ([92m↓24.44%[0m) [0.11% of initial]
[Iter 11540/20000] Loss: 0.0004234 (Best: 0.0001712 @iter7999) ([92m↓17.58%[0m) [0.09% of initial]
[Iter 11550/20000] Loss: 0.0003838 (Best: 0.0001712 @iter7999) ([92m↓9.36%[0m) [0.08% of initial]
[Iter 11560/20000] Loss: 0.0003441 (Best: 0.0001712 @iter7999) ([92m↓10.34%[0m) [0.07% of initial]
[Iter 11570/20000] Loss: 0.0003396 (Best: 0.0001712 @iter7999) ([92m↓1.32%[0m) [0.07% of initial]
[Iter 11580/20000] Loss: 0.0003148 (Best: 0.0001712 @iter7999) ([92m↓7.30%[0m) [0.07% of initial]
[Iter 11590/20000] Loss: 0.0003158 (Best: 0.0001712 @iter7999) ([91m↑0.31%[0m) [0.07% of initial]
Iter:11599, L1 loss=0.0002799, Total loss=0.0002806, Time:20
[Iter 11600/20000] Loss: 0.0002941 (Best: 0.0001712 @iter7999) ([92m↓6.86%[0m) [0.06% of initial]
[Iter 11610/20000] Loss: 0.0002982 (Best: 0.0001712 @iter7999) ([91m↑1.39%[0m) [0.06% of initial]
[Iter 11620/20000] Loss: 0.0002896 (Best: 0.0001712 @iter7999) ([92m↓2.86%[0m) [0.06% of initial]
[Iter 11630/20000] Loss: 0.0002844 (Best: 0.0001712 @iter7999) ([92m↓1.80%[0m) [0.06% of initial]
[Iter 11640/20000] Loss: 0.0002819 (Best: 0.0001712 @iter7999) ([92m↓0.86%[0m) [0.06% of initial]
[Iter 11650/20000] Loss: 0.0002791 (Best: 0.0001712 @iter7999) ([92m↓0.99%[0m) [0.06% of initial]
[Iter 11660/20000] Loss: 0.0002739 (Best: 0.0001712 @iter7999) ([92m↓1.88%[0m) [0.06% of initial]
[Iter 11670/20000] Loss: 0.0002730 (Best: 0.0001712 @iter7999) ([92m↓0.33%[0m) [0.06% of initial]
[Iter 11680/20000] Loss: 0.0002700 (Best: 0.0001712 @iter7999) ([92m↓1.11%[0m) [0.06% of initial]
[Iter 11690/20000] Loss: 0.0002705 (Best: 0.0001712 @iter7999) ([91m↑0.21%[0m) [0.06% of initial]
Iter:11699, L1 loss=0.0002559, Total loss=0.0002529, Time:19
[Iter 11700/20000] Loss: 0.0002660 (Best: 0.0001712 @iter7999) ([92m↓1.70%[0m) [0.06% of initial]
[Iter 11710/20000] Loss: 0.0002641 (Best: 0.0001712 @iter7999) ([92m↓0.70%[0m) [0.06% of initial]
[Iter 11720/20000] Loss: 0.0002609 (Best: 0.0001712 @iter7999) ([92m↓1.20%[0m) [0.06% of initial]
[Iter 11730/20000] Loss: 0.0002593 (Best: 0.0001712 @iter7999) ([92m↓0.61%[0m) [0.06% of initial]
[Iter 11740/20000] Loss: 0.0002605 (Best: 0.0001712 @iter7999) ([91m↑0.45%[0m) [0.06% of initial]
[Iter 11750/20000] Loss: 0.0002588 (Best: 0.0001712 @iter7999) ([92m↓0.65%[0m) [0.06% of initial]
[Iter 11760/20000] Loss: 0.0002596 (Best: 0.0001712 @iter7999) ([91m↑0.31%[0m) [0.06% of initial]
[Iter 11770/20000] Loss: 0.0002545 (Best: 0.0001712 @iter7999) ([92m↓1.97%[0m) [0.06% of initial]
[Iter 11780/20000] Loss: 0.0002575 (Best: 0.0001712 @iter7999) ([91m↑1.18%[0m) [0.06% of initial]
[Iter 11790/20000] Loss: 0.0002595 (Best: 0.0001712 @iter7999) ([91m↑0.76%[0m) [0.06% of initial]
Iter:11799, L1 loss=0.0002613, Total loss=0.0002596, Time:18
[Iter 11800/20000] Loss: 0.0002525 (Best: 0.0001712 @iter7999) ([92m↓2.69%[0m) [0.05% of initial]
[Iter 11810/20000] Loss: 0.0002529 (Best: 0.0001712 @iter7999) ([91m↑0.15%[0m) [0.05% of initial]
[Iter 11820/20000] Loss: 0.0002502 (Best: 0.0001712 @iter7999) ([92m↓1.07%[0m) [0.05% of initial]
[Iter 11830/20000] Loss: 0.0002505 (Best: 0.0001712 @iter7999) ([91m↑0.14%[0m) [0.05% of initial]
[Iter 11840/20000] Loss: 0.0002497 (Best: 0.0001712 @iter7999) ([92m↓0.32%[0m) [0.05% of initial]
[Iter 11850/20000] Loss: 0.0002504 (Best: 0.0001712 @iter7999) ([91m↑0.27%[0m) [0.05% of initial]
[Iter 11860/20000] Loss: 0.0002487 (Best: 0.0001712 @iter7999) ([92m↓0.65%[0m) [0.05% of initial]
[Iter 11870/20000] Loss: 0.0002482 (Best: 0.0001712 @iter7999) ([92m↓0.20%[0m) [0.05% of initial]
[Iter 11880/20000] Loss: 0.0002465 (Best: 0.0001712 @iter7999) ([92m↓0.71%[0m) [0.05% of initial]
[Iter 11890/20000] Loss: 0.0002478 (Best: 0.0001712 @iter7999) ([91m↑0.53%[0m) [0.05% of initial]
Iter:11899, L1 loss=0.0002526, Total loss=0.0002467, Time:14
[Iter 11900/20000] Loss: 0.0002438 (Best: 0.0001712 @iter7999) ([92m↓1.63%[0m) [0.05% of initial]
[Iter 11910/20000] Loss: 0.0002458 (Best: 0.0001712 @iter7999) ([91m↑0.84%[0m) [0.05% of initial]
[Iter 11920/20000] Loss: 0.0002461 (Best: 0.0001712 @iter7999) ([91m↑0.11%[0m) [0.05% of initial]
[Iter 11930/20000] Loss: 0.0002434 (Best: 0.0001712 @iter7999) ([92m↓1.08%[0m) [0.05% of initial]
[Iter 11940/20000] Loss: 0.0002434 (Best: 0.0001712 @iter7999) ([92m↓0.00%[0m) [0.05% of initial]
[Iter 11950/20000] Loss: 0.0002427 (Best: 0.0001712 @iter7999) ([92m↓0.31%[0m) [0.05% of initial]
[Iter 11960/20000] Loss: 0.0002424 (Best: 0.0001712 @iter7999) ([92m↓0.13%[0m) [0.05% of initial]
[Iter 11970/20000] Loss: 0.0002414 (Best: 0.0001712 @iter7999) ([92m↓0.38%[0m) [0.05% of initial]
[Iter 11980/20000] Loss: 0.0002414 (Best: 0.0001712 @iter7999) ([92m↓0.03%[0m) [0.05% of initial]
[Iter 11990/20000] Loss: 0.0002404 (Best: 0.0001712 @iter7999) ([92m↓0.41%[0m) [0.05% of initial]
Iter:11999, L1 loss=0.000241, Total loss=0.0002374, Time:17
[Iter 12000/20000] Loss: 0.0002413 (Best: 0.0001712 @iter7999) ([91m↑0.40%[0m) [0.05% of initial]
Pruning 68 points (1.7%) from gaussian0 at iteration 12000
Pruning 68 points (1.7%) from gaussian1 at iteration 12000
[Iter 12010/20000] Loss: 0.0655315 (Best: 0.0001712 @iter7999) ([91m↑27053.81%[0m) [14.22% of initial]
[Iter 12020/20000] Loss: 0.0517364 (Best: 0.0001712 @iter7999) ([92m↓21.05%[0m) [11.22% of initial]
[Iter 12030/20000] Loss: 0.0359815 (Best: 0.0001712 @iter7999) ([92m↓30.45%[0m) [7.81% of initial]
[Iter 12040/20000] Loss: 0.0215187 (Best: 0.0001712 @iter7999) ([92m↓40.20%[0m) [4.67% of initial]
[Iter 12050/20000] Loss: 0.0112459 (Best: 0.0001712 @iter7999) ([92m↓47.74%[0m) [2.44% of initial]
[Iter 12060/20000] Loss: 0.0059803 (Best: 0.0001712 @iter7999) ([92m↓46.82%[0m) [1.30% of initial]
[Iter 12070/20000] Loss: 0.0036977 (Best: 0.0001712 @iter7999) ([92m↓38.17%[0m) [0.80% of initial]
[Iter 12080/20000] Loss: 0.0023962 (Best: 0.0001712 @iter7999) ([92m↓35.20%[0m) [0.52% of initial]
[Iter 12090/20000] Loss: 0.0016192 (Best: 0.0001712 @iter7999) ([92m↓32.43%[0m) [0.35% of initial]
Iter:12099, L1 loss=0.000841, Total loss=0.001175, Time:17
[Iter 12100/20000] Loss: 0.0012043 (Best: 0.0001712 @iter7999) ([92m↓25.62%[0m) [0.26% of initial]
[Iter 12110/20000] Loss: 0.0010346 (Best: 0.0001712 @iter7999) ([92m↓14.09%[0m) [0.22% of initial]
[Iter 12120/20000] Loss: 0.0008861 (Best: 0.0001712 @iter7999) ([92m↓14.35%[0m) [0.19% of initial]
[Iter 12130/20000] Loss: 0.0008023 (Best: 0.0001712 @iter7999) ([92m↓9.45%[0m) [0.17% of initial]
[Iter 12140/20000] Loss: 0.0007549 (Best: 0.0001712 @iter7999) ([92m↓5.92%[0m) [0.16% of initial]
[Iter 12150/20000] Loss: 0.0006891 (Best: 0.0001712 @iter7999) ([92m↓8.71%[0m) [0.15% of initial]
[Iter 12160/20000] Loss: 0.0006390 (Best: 0.0001712 @iter7999) ([92m↓7.27%[0m) [0.14% of initial]
[Iter 12170/20000] Loss: 0.0005999 (Best: 0.0001712 @iter7999) ([92m↓6.12%[0m) [0.13% of initial]
[Iter 12180/20000] Loss: 0.0005977 (Best: 0.0001712 @iter7999) ([92m↓0.36%[0m) [0.13% of initial]
[Iter 12190/20000] Loss: 0.0005662 (Best: 0.0001712 @iter7999) ([92m↓5.26%[0m) [0.12% of initial]
Iter:12199, L1 loss=0.0004927, Total loss=0.0005528, Time:20
[Iter 12200/20000] Loss: 0.0005294 (Best: 0.0001712 @iter7999) ([92m↓6.51%[0m) [0.11% of initial]
[Iter 12210/20000] Loss: 0.0005304 (Best: 0.0001712 @iter7999) ([91m↑0.19%[0m) [0.12% of initial]
[Iter 12220/20000] Loss: 0.0005145 (Best: 0.0001712 @iter7999) ([92m↓2.99%[0m) [0.11% of initial]
[Iter 12230/20000] Loss: 0.0004976 (Best: 0.0001712 @iter7999) ([92m↓3.29%[0m) [0.11% of initial]
[Iter 12240/20000] Loss: 0.0004888 (Best: 0.0001712 @iter7999) ([92m↓1.77%[0m) [0.11% of initial]
[Iter 12250/20000] Loss: 0.0004637 (Best: 0.0001712 @iter7999) ([92m↓5.13%[0m) [0.10% of initial]
[Iter 12260/20000] Loss: 0.0004781 (Best: 0.0001712 @iter7999) ([91m↑3.11%[0m) [0.10% of initial]
[Iter 12270/20000] Loss: 0.0004636 (Best: 0.0001712 @iter7999) ([92m↓3.04%[0m) [0.10% of initial]
[Iter 12280/20000] Loss: 0.0004631 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.10% of initial]
[Iter 12290/20000] Loss: 0.0004535 (Best: 0.0001712 @iter7999) ([92m↓2.07%[0m) [0.10% of initial]
Iter:12299, L1 loss=0.00044, Total loss=0.0004593, Time:15
[Iter 12300/20000] Loss: 0.0004318 (Best: 0.0001712 @iter7999) ([92m↓4.79%[0m) [0.09% of initial]
[Iter 12310/20000] Loss: 0.0004344 (Best: 0.0001712 @iter7999) ([91m↑0.59%[0m) [0.09% of initial]
[Iter 12320/20000] Loss: 0.0004154 (Best: 0.0001712 @iter7999) ([92m↓4.37%[0m) [0.09% of initial]
[Iter 12330/20000] Loss: 0.0004202 (Best: 0.0001712 @iter7999) ([91m↑1.17%[0m) [0.09% of initial]
[Iter 12340/20000] Loss: 0.0004184 (Best: 0.0001712 @iter7999) ([92m↓0.44%[0m) [0.09% of initial]
[Iter 12350/20000] Loss: 0.0004146 (Best: 0.0001712 @iter7999) ([92m↓0.91%[0m) [0.09% of initial]
[Iter 12360/20000] Loss: 0.0003988 (Best: 0.0001712 @iter7999) ([92m↓3.80%[0m) [0.09% of initial]
[Iter 12370/20000] Loss: 0.0004057 (Best: 0.0001712 @iter7999) ([91m↑1.72%[0m) [0.09% of initial]
[Iter 12380/20000] Loss: 0.0003902 (Best: 0.0001712 @iter7999) ([92m↓3.80%[0m) [0.08% of initial]
[Iter 12390/20000] Loss: 0.0003865 (Best: 0.0001712 @iter7999) ([92m↓0.95%[0m) [0.08% of initial]
Iter:12399, L1 loss=0.0003634, Total loss=0.0003681, Time:18
[Iter 12400/20000] Loss: 0.0003868 (Best: 0.0001712 @iter7999) ([91m↑0.08%[0m) [0.08% of initial]
[Iter 12410/20000] Loss: 0.0003939 (Best: 0.0001712 @iter7999) ([91m↑1.81%[0m) [0.09% of initial]
[Iter 12420/20000] Loss: 0.0003787 (Best: 0.0001712 @iter7999) ([92m↓3.84%[0m) [0.08% of initial]
[Iter 12430/20000] Loss: 0.0003795 (Best: 0.0001712 @iter7999) ([91m↑0.22%[0m) [0.08% of initial]
[Iter 12440/20000] Loss: 0.0003847 (Best: 0.0001712 @iter7999) ([91m↑1.36%[0m) [0.08% of initial]
[Iter 12450/20000] Loss: 0.0003784 (Best: 0.0001712 @iter7999) ([92m↓1.65%[0m) [0.08% of initial]
[Iter 12460/20000] Loss: 0.0003805 (Best: 0.0001712 @iter7999) ([91m↑0.55%[0m) [0.08% of initial]
[Iter 12470/20000] Loss: 0.0003669 (Best: 0.0001712 @iter7999) ([92m↓3.56%[0m) [0.08% of initial]
[Iter 12480/20000] Loss: 0.0003680 (Best: 0.0001712 @iter7999) ([91m↑0.30%[0m) [0.08% of initial]
[Iter 12490/20000] Loss: 0.0003737 (Best: 0.0001712 @iter7999) ([91m↑1.55%[0m) [0.08% of initial]
Iter:12499, L1 loss=0.0003777, Total loss=0.0003757, Time:21
[Iter 12500/20000] Loss: 0.0003615 (Best: 0.0001712 @iter7999) ([92m↓3.28%[0m) [0.08% of initial]
Pruning 81 points (2.0%) from gaussian0 at iteration 12500
Pruning 66 points (1.7%) from gaussian1 at iteration 12500
[Iter 12510/20000] Loss: 0.0007696 (Best: 0.0001712 @iter7999) ([91m↑112.90%[0m) [0.17% of initial]
[Iter 12520/20000] Loss: 0.0005649 (Best: 0.0001712 @iter7999) ([92m↓26.61%[0m) [0.12% of initial]
[Iter 12530/20000] Loss: 0.0004861 (Best: 0.0001712 @iter7999) ([92m↓13.94%[0m) [0.11% of initial]
[Iter 12540/20000] Loss: 0.0004544 (Best: 0.0001712 @iter7999) ([92m↓6.52%[0m) [0.10% of initial]
[Iter 12550/20000] Loss: 0.0004140 (Best: 0.0001712 @iter7999) ([92m↓8.88%[0m) [0.09% of initial]
[Iter 12560/20000] Loss: 0.0004198 (Best: 0.0001712 @iter7999) ([91m↑1.39%[0m) [0.09% of initial]
[Iter 12570/20000] Loss: 0.0004040 (Best: 0.0001712 @iter7999) ([92m↓3.76%[0m) [0.09% of initial]
[Iter 12580/20000] Loss: 0.0003955 (Best: 0.0001712 @iter7999) ([92m↓2.09%[0m) [0.09% of initial]
[Iter 12590/20000] Loss: 0.0003831 (Best: 0.0001712 @iter7999) ([92m↓3.14%[0m) [0.08% of initial]
Iter:12599, L1 loss=0.0003786, Total loss=0.0003854, Time:16
[Iter 12600/20000] Loss: 0.0003756 (Best: 0.0001712 @iter7999) ([92m↓1.97%[0m) [0.08% of initial]
[Iter 12610/20000] Loss: 0.0003798 (Best: 0.0001712 @iter7999) ([91m↑1.12%[0m) [0.08% of initial]
[Iter 12620/20000] Loss: 0.0003718 (Best: 0.0001712 @iter7999) ([92m↓2.11%[0m) [0.08% of initial]
[Iter 12630/20000] Loss: 0.0003718 (Best: 0.0001712 @iter7999) ([91m↑0.00%[0m) [0.08% of initial]
[Iter 12640/20000] Loss: 0.0003680 (Best: 0.0001712 @iter7999) ([92m↓1.03%[0m) [0.08% of initial]
[Iter 12650/20000] Loss: 0.0003666 (Best: 0.0001712 @iter7999) ([92m↓0.36%[0m) [0.08% of initial]
[Iter 12660/20000] Loss: 0.0003674 (Best: 0.0001712 @iter7999) ([91m↑0.20%[0m) [0.08% of initial]
[Iter 12670/20000] Loss: 0.0003694 (Best: 0.0001712 @iter7999) ([91m↑0.55%[0m) [0.08% of initial]
[Iter 12680/20000] Loss: 0.0003643 (Best: 0.0001712 @iter7999) ([92m↓1.38%[0m) [0.08% of initial]
[Iter 12690/20000] Loss: 0.0003606 (Best: 0.0001712 @iter7999) ([92m↓1.01%[0m) [0.08% of initial]
Iter:12699, L1 loss=0.0003721, Total loss=0.0003685, Time:19
[Iter 12700/20000] Loss: 0.0003567 (Best: 0.0001712 @iter7999) ([92m↓1.09%[0m) [0.08% of initial]
[Iter 12710/20000] Loss: 0.0003617 (Best: 0.0001712 @iter7999) ([91m↑1.39%[0m) [0.08% of initial]
[Iter 12720/20000] Loss: 0.0003550 (Best: 0.0001712 @iter7999) ([92m↓1.85%[0m) [0.08% of initial]
[Iter 12730/20000] Loss: 0.0003622 (Best: 0.0001712 @iter7999) ([91m↑2.03%[0m) [0.08% of initial]
[Iter 12740/20000] Loss: 0.0003597 (Best: 0.0001712 @iter7999) ([92m↓0.69%[0m) [0.08% of initial]
[Iter 12750/20000] Loss: 0.0003499 (Best: 0.0001712 @iter7999) ([92m↓2.73%[0m) [0.08% of initial]
[Iter 12760/20000] Loss: 0.0003530 (Best: 0.0001712 @iter7999) ([91m↑0.89%[0m) [0.08% of initial]
[Iter 12770/20000] Loss: 0.0003484 (Best: 0.0001712 @iter7999) ([92m↓1.30%[0m) [0.08% of initial]
[Iter 12780/20000] Loss: 0.0003570 (Best: 0.0001712 @iter7999) ([91m↑2.47%[0m) [0.08% of initial]
[Iter 12790/20000] Loss: 0.0003454 (Best: 0.0001712 @iter7999) ([92m↓3.25%[0m) [0.07% of initial]
Iter:12799, L1 loss=0.0003391, Total loss=0.0003344, Time:18
[Iter 12800/20000] Loss: 0.0003494 (Best: 0.0001712 @iter7999) ([91m↑1.15%[0m) [0.08% of initial]
[Iter 12810/20000] Loss: 0.0003498 (Best: 0.0001712 @iter7999) ([91m↑0.11%[0m) [0.08% of initial]
[Iter 12820/20000] Loss: 0.0003427 (Best: 0.0001712 @iter7999) ([92m↓2.04%[0m) [0.07% of initial]
[Iter 12830/20000] Loss: 0.0003437 (Best: 0.0001712 @iter7999) ([91m↑0.29%[0m) [0.07% of initial]
[Iter 12840/20000] Loss: 0.0003464 (Best: 0.0001712 @iter7999) ([91m↑0.79%[0m) [0.08% of initial]
[Iter 12850/20000] Loss: 0.0003543 (Best: 0.0001712 @iter7999) ([91m↑2.29%[0m) [0.08% of initial]
[Iter 12860/20000] Loss: 0.0003485 (Best: 0.0001712 @iter7999) ([92m↓1.65%[0m) [0.08% of initial]
[Iter 12870/20000] Loss: 0.0003451 (Best: 0.0001712 @iter7999) ([92m↓0.97%[0m) [0.07% of initial]
[Iter 12880/20000] Loss: 0.0003442 (Best: 0.0001712 @iter7999) ([92m↓0.26%[0m) [0.07% of initial]
[Iter 12890/20000] Loss: 0.0003449 (Best: 0.0001712 @iter7999) ([91m↑0.21%[0m) [0.07% of initial]
Iter:12899, L1 loss=0.0003514, Total loss=0.0003508, Time:16
[Iter 12900/20000] Loss: 0.0003427 (Best: 0.0001712 @iter7999) ([92m↓0.64%[0m) [0.07% of initial]
[Iter 12910/20000] Loss: 0.0003471 (Best: 0.0001712 @iter7999) ([91m↑1.27%[0m) [0.08% of initial]
[Iter 12920/20000] Loss: 0.0003454 (Best: 0.0001712 @iter7999) ([92m↓0.49%[0m) [0.07% of initial]
[Iter 12930/20000] Loss: 0.0003467 (Best: 0.0001712 @iter7999) ([91m↑0.38%[0m) [0.08% of initial]
[Iter 12940/20000] Loss: 0.0003487 (Best: 0.0001712 @iter7999) ([91m↑0.59%[0m) [0.08% of initial]
[Iter 12950/20000] Loss: 0.0003427 (Best: 0.0001712 @iter7999) ([92m↓1.73%[0m) [0.07% of initial]
[Iter 12960/20000] Loss: 0.0003473 (Best: 0.0001712 @iter7999) ([91m↑1.35%[0m) [0.08% of initial]
[Iter 12970/20000] Loss: 0.0003489 (Best: 0.0001712 @iter7999) ([91m↑0.45%[0m) [0.08% of initial]
[Iter 12980/20000] Loss: 0.0003483 (Best: 0.0001712 @iter7999) ([92m↓0.17%[0m) [0.08% of initial]
[Iter 12990/20000] Loss: 0.0003456 (Best: 0.0001712 @iter7999) ([92m↓0.79%[0m) [0.07% of initial]
Iter:12999, L1 loss=0.0003362, Total loss=0.0003345, Time:18
[Iter 13000/20000] Loss: 0.0003469 (Best: 0.0001712 @iter7999) ([91m↑0.40%[0m) [0.08% of initial]
Pruning 59 points (1.5%) from gaussian0 at iteration 13000
Pruning 51 points (1.4%) from gaussian1 at iteration 13000
[Iter 13010/20000] Loss: 0.0009887 (Best: 0.0001712 @iter7999) ([91m↑184.96%[0m) [0.21% of initial]
[Iter 13020/20000] Loss: 0.0007046 (Best: 0.0001712 @iter7999) ([92m↓28.74%[0m) [0.15% of initial]
[Iter 13030/20000] Loss: 0.0006201 (Best: 0.0001712 @iter7999) ([92m↓11.99%[0m) [0.13% of initial]
[Iter 13040/20000] Loss: 0.0005066 (Best: 0.0001712 @iter7999) ([92m↓18.30%[0m) [0.11% of initial]
[Iter 13050/20000] Loss: 0.0004831 (Best: 0.0001712 @iter7999) ([92m↓4.65%[0m) [0.10% of initial]
[Iter 13060/20000] Loss: 0.0004383 (Best: 0.0001712 @iter7999) ([92m↓9.26%[0m) [0.10% of initial]
[Iter 13070/20000] Loss: 0.0004406 (Best: 0.0001712 @iter7999) ([91m↑0.52%[0m) [0.10% of initial]
[Iter 13080/20000] Loss: 0.0004051 (Best: 0.0001712 @iter7999) ([92m↓8.05%[0m) [0.09% of initial]
[Iter 13090/20000] Loss: 0.0003990 (Best: 0.0001712 @iter7999) ([92m↓1.51%[0m) [0.09% of initial]
Iter:13099, L1 loss=0.0003872, Total loss=0.0003684, Time:20
[Iter 13100/20000] Loss: 0.0003834 (Best: 0.0001712 @iter7999) ([92m↓3.89%[0m) [0.08% of initial]
[Iter 13110/20000] Loss: 0.0003816 (Best: 0.0001712 @iter7999) ([92m↓0.48%[0m) [0.08% of initial]
[Iter 13120/20000] Loss: 0.0003921 (Best: 0.0001712 @iter7999) ([91m↑2.76%[0m) [0.09% of initial]
[Iter 13130/20000] Loss: 0.0003679 (Best: 0.0001712 @iter7999) ([92m↓6.17%[0m) [0.08% of initial]
[Iter 13140/20000] Loss: 0.0003701 (Best: 0.0001712 @iter7999) ([91m↑0.60%[0m) [0.08% of initial]
[Iter 13150/20000] Loss: 0.0003744 (Best: 0.0001712 @iter7999) ([91m↑1.14%[0m) [0.08% of initial]
[Iter 13160/20000] Loss: 0.0003595 (Best: 0.0001712 @iter7999) ([92m↓3.97%[0m) [0.08% of initial]
[Iter 13170/20000] Loss: 0.0003660 (Best: 0.0001712 @iter7999) ([91m↑1.80%[0m) [0.08% of initial]
[Iter 13180/20000] Loss: 0.0003601 (Best: 0.0001712 @iter7999) ([92m↓1.62%[0m) [0.08% of initial]
[Iter 13190/20000] Loss: 0.0003606 (Best: 0.0001712 @iter7999) ([91m↑0.17%[0m) [0.08% of initial]
Iter:13199, L1 loss=0.000346, Total loss=0.0003403, Time:18
[Iter 13200/20000] Loss: 0.0003545 (Best: 0.0001712 @iter7999) ([92m↓1.71%[0m) [0.08% of initial]
[Iter 13210/20000] Loss: 0.0003564 (Best: 0.0001712 @iter7999) ([91m↑0.55%[0m) [0.08% of initial]
[Iter 13220/20000] Loss: 0.0003466 (Best: 0.0001712 @iter7999) ([92m↓2.76%[0m) [0.08% of initial]
[Iter 13230/20000] Loss: 0.0003479 (Best: 0.0001712 @iter7999) ([91m↑0.38%[0m) [0.08% of initial]
[Iter 13240/20000] Loss: 0.0003530 (Best: 0.0001712 @iter7999) ([91m↑1.48%[0m) [0.08% of initial]
[Iter 13250/20000] Loss: 0.0003484 (Best: 0.0001712 @iter7999) ([92m↓1.30%[0m) [0.08% of initial]
[Iter 13260/20000] Loss: 0.0003447 (Best: 0.0001712 @iter7999) ([92m↓1.06%[0m) [0.07% of initial]
[Iter 13270/20000] Loss: 0.0003461 (Best: 0.0001712 @iter7999) ([91m↑0.41%[0m) [0.08% of initial]
[Iter 13280/20000] Loss: 0.0003415 (Best: 0.0001712 @iter7999) ([92m↓1.34%[0m) [0.07% of initial]
[Iter 13290/20000] Loss: 0.0003449 (Best: 0.0001712 @iter7999) ([91m↑1.01%[0m) [0.07% of initial]
Iter:13299, L1 loss=0.000337, Total loss=0.0003313, Time:19
[Iter 13300/20000] Loss: 0.0003346 (Best: 0.0001712 @iter7999) ([92m↓2.99%[0m) [0.07% of initial]
[Iter 13310/20000] Loss: 0.0003442 (Best: 0.0001712 @iter7999) ([91m↑2.86%[0m) [0.07% of initial]
[Iter 13320/20000] Loss: 0.0003450 (Best: 0.0001712 @iter7999) ([91m↑0.25%[0m) [0.07% of initial]
[Iter 13330/20000] Loss: 0.0003404 (Best: 0.0001712 @iter7999) ([92m↓1.33%[0m) [0.07% of initial]
[Iter 13340/20000] Loss: 0.0003401 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.07% of initial]
[Iter 13350/20000] Loss: 0.0003371 (Best: 0.0001712 @iter7999) ([92m↓0.89%[0m) [0.07% of initial]
[Iter 13360/20000] Loss: 0.0003401 (Best: 0.0001712 @iter7999) ([91m↑0.90%[0m) [0.07% of initial]
[Iter 13370/20000] Loss: 0.0003304 (Best: 0.0001712 @iter7999) ([92m↓2.86%[0m) [0.07% of initial]
[Iter 13380/20000] Loss: 0.0003377 (Best: 0.0001712 @iter7999) ([91m↑2.21%[0m) [0.07% of initial]
[Iter 13390/20000] Loss: 0.0003400 (Best: 0.0001712 @iter7999) ([91m↑0.68%[0m) [0.07% of initial]
Iter:13399, L1 loss=0.0003475, Total loss=0.0003463, Time:18
[Iter 13400/20000] Loss: 0.0003401 (Best: 0.0001712 @iter7999) ([91m↑0.03%[0m) [0.07% of initial]
[Iter 13410/20000] Loss: 0.0003398 (Best: 0.0001712 @iter7999) ([92m↓0.09%[0m) [0.07% of initial]
[Iter 13420/20000] Loss: 0.0003412 (Best: 0.0001712 @iter7999) ([91m↑0.41%[0m) [0.07% of initial]
[Iter 13430/20000] Loss: 0.0003330 (Best: 0.0001712 @iter7999) ([92m↓2.40%[0m) [0.07% of initial]
[Iter 13440/20000] Loss: 0.0003363 (Best: 0.0001712 @iter7999) ([91m↑0.98%[0m) [0.07% of initial]
[Iter 13450/20000] Loss: 0.0003285 (Best: 0.0001712 @iter7999) ([92m↓2.31%[0m) [0.07% of initial]
[Iter 13460/20000] Loss: 0.0003303 (Best: 0.0001712 @iter7999) ([91m↑0.56%[0m) [0.07% of initial]
[Iter 13470/20000] Loss: 0.0003329 (Best: 0.0001712 @iter7999) ([91m↑0.77%[0m) [0.07% of initial]
[Iter 13480/20000] Loss: 0.0003405 (Best: 0.0001712 @iter7999) ([91m↑2.30%[0m) [0.07% of initial]
[Iter 13490/20000] Loss: 0.0003423 (Best: 0.0001712 @iter7999) ([91m↑0.53%[0m) [0.07% of initial]
Iter:13499, L1 loss=0.0003276, Total loss=0.0003307, Time:15
[Iter 13500/20000] Loss: 0.0003402 (Best: 0.0001712 @iter7999) ([92m↓0.64%[0m) [0.07% of initial]
Pruning 42 points (1.1%) from gaussian0 at iteration 13500
Pruning 45 points (1.2%) from gaussian1 at iteration 13500
[Iter 13510/20000] Loss: 0.0004319 (Best: 0.0001712 @iter7999) ([91m↑26.96%[0m) [0.09% of initial]
[Iter 13520/20000] Loss: 0.0003944 (Best: 0.0001712 @iter7999) ([92m↓8.68%[0m) [0.09% of initial]
[Iter 13530/20000] Loss: 0.0003791 (Best: 0.0001712 @iter7999) ([92m↓3.88%[0m) [0.08% of initial]
[Iter 13540/20000] Loss: 0.0003731 (Best: 0.0001712 @iter7999) ([92m↓1.58%[0m) [0.08% of initial]
[Iter 13550/20000] Loss: 0.0003638 (Best: 0.0001712 @iter7999) ([92m↓2.50%[0m) [0.08% of initial]
[Iter 13560/20000] Loss: 0.0003625 (Best: 0.0001712 @iter7999) ([92m↓0.34%[0m) [0.08% of initial]
[Iter 13570/20000] Loss: 0.0003614 (Best: 0.0001712 @iter7999) ([92m↓0.30%[0m) [0.08% of initial]
[Iter 13580/20000] Loss: 0.0003573 (Best: 0.0001712 @iter7999) ([92m↓1.15%[0m) [0.08% of initial]
[Iter 13590/20000] Loss: 0.0003533 (Best: 0.0001712 @iter7999) ([92m↓1.10%[0m) [0.08% of initial]
Iter:13599, L1 loss=0.0004121, Total loss=0.0003616, Time:14
[Iter 13600/20000] Loss: 0.0003554 (Best: 0.0001712 @iter7999) ([91m↑0.59%[0m) [0.08% of initial]
[Iter 13610/20000] Loss: 0.0003446 (Best: 0.0001712 @iter7999) ([92m↓3.02%[0m) [0.07% of initial]
[Iter 13620/20000] Loss: 0.0003443 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.07% of initial]
[Iter 13630/20000] Loss: 0.0003404 (Best: 0.0001712 @iter7999) ([92m↓1.14%[0m) [0.07% of initial]
[Iter 13640/20000] Loss: 0.0003379 (Best: 0.0001712 @iter7999) ([92m↓0.72%[0m) [0.07% of initial]
[Iter 13650/20000] Loss: 0.0003434 (Best: 0.0001712 @iter7999) ([91m↑1.63%[0m) [0.07% of initial]
[Iter 13660/20000] Loss: 0.0003339 (Best: 0.0001712 @iter7999) ([92m↓2.79%[0m) [0.07% of initial]
[Iter 13670/20000] Loss: 0.0003410 (Best: 0.0001712 @iter7999) ([91m↑2.15%[0m) [0.07% of initial]
[Iter 13680/20000] Loss: 0.0003359 (Best: 0.0001712 @iter7999) ([92m↓1.51%[0m) [0.07% of initial]
[Iter 13690/20000] Loss: 0.0003335 (Best: 0.0001712 @iter7999) ([92m↓0.72%[0m) [0.07% of initial]
Iter:13699, L1 loss=0.0003588, Total loss=0.0003326, Time:19
[Iter 13700/20000] Loss: 0.0003384 (Best: 0.0001712 @iter7999) ([91m↑1.49%[0m) [0.07% of initial]
[Iter 13710/20000] Loss: 0.0003371 (Best: 0.0001712 @iter7999) ([92m↓0.40%[0m) [0.07% of initial]
[Iter 13720/20000] Loss: 0.0003293 (Best: 0.0001712 @iter7999) ([92m↓2.30%[0m) [0.07% of initial]
[Iter 13730/20000] Loss: 0.0003323 (Best: 0.0001712 @iter7999) ([91m↑0.90%[0m) [0.07% of initial]
[Iter 13740/20000] Loss: 0.0003348 (Best: 0.0001712 @iter7999) ([91m↑0.74%[0m) [0.07% of initial]
[Iter 13750/20000] Loss: 0.0003349 (Best: 0.0001712 @iter7999) ([91m↑0.04%[0m) [0.07% of initial]
[Iter 13760/20000] Loss: 0.0003356 (Best: 0.0001712 @iter7999) ([91m↑0.22%[0m) [0.07% of initial]
[Iter 13770/20000] Loss: 0.0003311 (Best: 0.0001712 @iter7999) ([92m↓1.35%[0m) [0.07% of initial]
[Iter 13780/20000] Loss: 0.0003305 (Best: 0.0001712 @iter7999) ([92m↓0.19%[0m) [0.07% of initial]
[Iter 13790/20000] Loss: 0.0003316 (Best: 0.0001712 @iter7999) ([91m↑0.33%[0m) [0.07% of initial]
Iter:13799, L1 loss=0.0003581, Total loss=0.0003389, Time:18
[Iter 13800/20000] Loss: 0.0003271 (Best: 0.0001712 @iter7999) ([92m↓1.35%[0m) [0.07% of initial]
[Iter 13810/20000] Loss: 0.0003395 (Best: 0.0001712 @iter7999) ([91m↑3.79%[0m) [0.07% of initial]
[Iter 13820/20000] Loss: 0.0003349 (Best: 0.0001712 @iter7999) ([92m↓1.35%[0m) [0.07% of initial]
[Iter 13830/20000] Loss: 0.0003336 (Best: 0.0001712 @iter7999) ([92m↓0.36%[0m) [0.07% of initial]
[Iter 13840/20000] Loss: 0.0003321 (Best: 0.0001712 @iter7999) ([92m↓0.46%[0m) [0.07% of initial]
[Iter 13850/20000] Loss: 0.0003301 (Best: 0.0001712 @iter7999) ([92m↓0.60%[0m) [0.07% of initial]
[Iter 13860/20000] Loss: 0.0003316 (Best: 0.0001712 @iter7999) ([91m↑0.44%[0m) [0.07% of initial]
[Iter 13870/20000] Loss: 0.0003253 (Best: 0.0001712 @iter7999) ([92m↓1.88%[0m) [0.07% of initial]
[Iter 13880/20000] Loss: 0.0003268 (Best: 0.0001712 @iter7999) ([91m↑0.44%[0m) [0.07% of initial]
[Iter 13890/20000] Loss: 0.0003272 (Best: 0.0001712 @iter7999) ([91m↑0.13%[0m) [0.07% of initial]
Iter:13899, L1 loss=0.000351, Total loss=0.0003385, Time:11
[Iter 13900/20000] Loss: 0.0003338 (Best: 0.0001712 @iter7999) ([91m↑2.01%[0m) [0.07% of initial]
[Iter 13910/20000] Loss: 0.0003266 (Best: 0.0001712 @iter7999) ([92m↓2.15%[0m) [0.07% of initial]
[Iter 13920/20000] Loss: 0.0003285 (Best: 0.0001712 @iter7999) ([91m↑0.60%[0m) [0.07% of initial]
[Iter 13930/20000] Loss: 0.0003211 (Best: 0.0001712 @iter7999) ([92m↓2.27%[0m) [0.07% of initial]
[Iter 13940/20000] Loss: 0.0003220 (Best: 0.0001712 @iter7999) ([91m↑0.29%[0m) [0.07% of initial]
[Iter 13950/20000] Loss: 0.0003210 (Best: 0.0001712 @iter7999) ([92m↓0.31%[0m) [0.07% of initial]
[Iter 13960/20000] Loss: 0.0003142 (Best: 0.0001712 @iter7999) ([92m↓2.14%[0m) [0.07% of initial]
[Iter 13970/20000] Loss: 0.0003269 (Best: 0.0001712 @iter7999) ([91m↑4.07%[0m) [0.07% of initial]
[Iter 13980/20000] Loss: 0.0003212 (Best: 0.0001712 @iter7999) ([92m↓1.75%[0m) [0.07% of initial]
[Iter 13990/20000] Loss: 0.0003231 (Best: 0.0001712 @iter7999) ([91m↑0.57%[0m) [0.07% of initial]
Iter:13999, L1 loss=0.0003453, Total loss=0.0003276, Time:20
[Iter 14000/20000] Loss: 0.0003225 (Best: 0.0001712 @iter7999) ([92m↓0.17%[0m) [0.07% of initial]
Pruning 36 points (0.9%) from gaussian0 at iteration 14000
Pruning 28 points (0.8%) from gaussian1 at iteration 14000
[Iter 14010/20000] Loss: 0.0005117 (Best: 0.0001712 @iter7999) ([91m↑58.66%[0m) [0.11% of initial]
[Iter 14020/20000] Loss: 0.0004235 (Best: 0.0001712 @iter7999) ([92m↓17.23%[0m) [0.09% of initial]
[Iter 14030/20000] Loss: 0.0003932 (Best: 0.0001712 @iter7999) ([92m↓7.17%[0m) [0.09% of initial]
[Iter 14040/20000] Loss: 0.0003695 (Best: 0.0001712 @iter7999) ([92m↓6.03%[0m) [0.08% of initial]
[Iter 14050/20000] Loss: 0.0003673 (Best: 0.0001712 @iter7999) ([92m↓0.59%[0m) [0.08% of initial]
[Iter 14060/20000] Loss: 0.0003536 (Best: 0.0001712 @iter7999) ([92m↓3.71%[0m) [0.08% of initial]
[Iter 14070/20000] Loss: 0.0003540 (Best: 0.0001712 @iter7999) ([91m↑0.09%[0m) [0.08% of initial]
[Iter 14080/20000] Loss: 0.0003445 (Best: 0.0001712 @iter7999) ([92m↓2.66%[0m) [0.07% of initial]
[Iter 14090/20000] Loss: 0.0003479 (Best: 0.0001712 @iter7999) ([91m↑0.98%[0m) [0.08% of initial]
Iter:14099, L1 loss=0.0003997, Total loss=0.0003505, Time:14
[Iter 14100/20000] Loss: 0.0003406 (Best: 0.0001712 @iter7999) ([92m↓2.11%[0m) [0.07% of initial]
[Iter 14110/20000] Loss: 0.0003430 (Best: 0.0001712 @iter7999) ([91m↑0.71%[0m) [0.07% of initial]
[Iter 14120/20000] Loss: 0.0003369 (Best: 0.0001712 @iter7999) ([92m↓1.78%[0m) [0.07% of initial]
[Iter 14130/20000] Loss: 0.0003325 (Best: 0.0001712 @iter7999) ([92m↓1.30%[0m) [0.07% of initial]
[Iter 14140/20000] Loss: 0.0003292 (Best: 0.0001712 @iter7999) ([92m↓0.98%[0m) [0.07% of initial]
[Iter 14150/20000] Loss: 0.0003299 (Best: 0.0001712 @iter7999) ([91m↑0.21%[0m) [0.07% of initial]
[Iter 14160/20000] Loss: 0.0003266 (Best: 0.0001712 @iter7999) ([92m↓1.00%[0m) [0.07% of initial]
[Iter 14170/20000] Loss: 0.0003245 (Best: 0.0001712 @iter7999) ([92m↓0.65%[0m) [0.07% of initial]
[Iter 14180/20000] Loss: 0.0003324 (Best: 0.0001712 @iter7999) ([91m↑2.45%[0m) [0.07% of initial]
[Iter 14190/20000] Loss: 0.0003286 (Best: 0.0001712 @iter7999) ([92m↓1.14%[0m) [0.07% of initial]
Iter:14199, L1 loss=0.0003656, Total loss=0.0003383, Time:18
[Iter 14200/20000] Loss: 0.0003291 (Best: 0.0001712 @iter7999) ([91m↑0.13%[0m) [0.07% of initial]
[Iter 14210/20000] Loss: 0.0003215 (Best: 0.0001712 @iter7999) ([92m↓2.31%[0m) [0.07% of initial]
[Iter 14220/20000] Loss: 0.0003275 (Best: 0.0001712 @iter7999) ([91m↑1.89%[0m) [0.07% of initial]
[Iter 14230/20000] Loss: 0.0003291 (Best: 0.0001712 @iter7999) ([91m↑0.47%[0m) [0.07% of initial]
[Iter 14240/20000] Loss: 0.0003235 (Best: 0.0001712 @iter7999) ([92m↓1.69%[0m) [0.07% of initial]
[Iter 14250/20000] Loss: 0.0003274 (Best: 0.0001712 @iter7999) ([91m↑1.18%[0m) [0.07% of initial]
[Iter 14260/20000] Loss: 0.0003227 (Best: 0.0001712 @iter7999) ([92m↓1.42%[0m) [0.07% of initial]
[Iter 14270/20000] Loss: 0.0003267 (Best: 0.0001712 @iter7999) ([91m↑1.24%[0m) [0.07% of initial]
[Iter 14280/20000] Loss: 0.0003218 (Best: 0.0001712 @iter7999) ([92m↓1.50%[0m) [0.07% of initial]
[Iter 14290/20000] Loss: 0.0003304 (Best: 0.0001712 @iter7999) ([91m↑2.65%[0m) [0.07% of initial]
Iter:14299, L1 loss=0.0003433, Total loss=0.0003215, Time:19
[Iter 14300/20000] Loss: 0.0003202 (Best: 0.0001712 @iter7999) ([92m↓3.07%[0m) [0.07% of initial]
[Iter 14310/20000] Loss: 0.0003234 (Best: 0.0001712 @iter7999) ([91m↑0.99%[0m) [0.07% of initial]
[Iter 14320/20000] Loss: 0.0003175 (Best: 0.0001712 @iter7999) ([92m↓1.83%[0m) [0.07% of initial]
[Iter 14330/20000] Loss: 0.0003185 (Best: 0.0001712 @iter7999) ([91m↑0.34%[0m) [0.07% of initial]
[Iter 14340/20000] Loss: 0.0003589 (Best: 0.0001712 @iter7999) ([91m↑12.67%[0m) [0.08% of initial]
[Iter 14350/20000] Loss: 0.0003349 (Best: 0.0001712 @iter7999) ([92m↓6.70%[0m) [0.07% of initial]
[Iter 14360/20000] Loss: 0.0003254 (Best: 0.0001712 @iter7999) ([92m↓2.83%[0m) [0.07% of initial]
[Iter 14370/20000] Loss: 0.0003230 (Best: 0.0001712 @iter7999) ([92m↓0.74%[0m) [0.07% of initial]
[Iter 14380/20000] Loss: 0.0003238 (Best: 0.0001712 @iter7999) ([91m↑0.25%[0m) [0.07% of initial]
[Iter 14390/20000] Loss: 0.0003241 (Best: 0.0001712 @iter7999) ([91m↑0.10%[0m) [0.07% of initial]
Iter:14399, L1 loss=0.0003205, Total loss=0.0003117, Time:19
[Iter 14400/20000] Loss: 0.0003226 (Best: 0.0001712 @iter7999) ([92m↓0.46%[0m) [0.07% of initial]
[Iter 14410/20000] Loss: 0.0003214 (Best: 0.0001712 @iter7999) ([92m↓0.39%[0m) [0.07% of initial]
[Iter 14420/20000] Loss: 0.0003254 (Best: 0.0001712 @iter7999) ([91m↑1.27%[0m) [0.07% of initial]
[Iter 14430/20000] Loss: 0.0003238 (Best: 0.0001712 @iter7999) ([92m↓0.50%[0m) [0.07% of initial]
[Iter 14440/20000] Loss: 0.0003186 (Best: 0.0001712 @iter7999) ([92m↓1.60%[0m) [0.07% of initial]
[Iter 14450/20000] Loss: 0.0003236 (Best: 0.0001712 @iter7999) ([91m↑1.56%[0m) [0.07% of initial]
[Iter 14460/20000] Loss: 0.0003239 (Best: 0.0001712 @iter7999) ([91m↑0.09%[0m) [0.07% of initial]
[Iter 14470/20000] Loss: 0.0003191 (Best: 0.0001712 @iter7999) ([92m↓1.48%[0m) [0.07% of initial]
[Iter 14480/20000] Loss: 0.0003203 (Best: 0.0001712 @iter7999) ([91m↑0.39%[0m) [0.07% of initial]
[Iter 14490/20000] Loss: 0.0003173 (Best: 0.0001712 @iter7999) ([92m↓0.94%[0m) [0.07% of initial]
Iter:14499, L1 loss=0.0003192, Total loss=0.0003086, Time:14
[Iter 14500/20000] Loss: 0.0003115 (Best: 0.0001712 @iter7999) ([92m↓1.84%[0m) [0.07% of initial]
Pruning 31 points (0.8%) from gaussian0 at iteration 14500
Pruning 30 points (0.8%) from gaussian1 at iteration 14500
[Iter 14510/20000] Loss: 0.0006045 (Best: 0.0001712 @iter7999) ([91m↑94.08%[0m) [0.13% of initial]
[Iter 14520/20000] Loss: 0.0004713 (Best: 0.0001712 @iter7999) ([92m↓22.03%[0m) [0.10% of initial]
[Iter 14530/20000] Loss: 0.0004145 (Best: 0.0001712 @iter7999) ([92m↓12.06%[0m) [0.09% of initial]
[Iter 14540/20000] Loss: 0.0003930 (Best: 0.0001712 @iter7999) ([92m↓5.18%[0m) [0.09% of initial]
[Iter 14550/20000] Loss: 0.0003731 (Best: 0.0001712 @iter7999) ([92m↓5.07%[0m) [0.08% of initial]
[Iter 14560/20000] Loss: 0.0003578 (Best: 0.0001712 @iter7999) ([92m↓4.10%[0m) [0.08% of initial]
[Iter 14570/20000] Loss: 0.0003593 (Best: 0.0001712 @iter7999) ([91m↑0.43%[0m) [0.08% of initial]
[Iter 14580/20000] Loss: 0.0003567 (Best: 0.0001712 @iter7999) ([92m↓0.74%[0m) [0.08% of initial]
[Iter 14590/20000] Loss: 0.0003567 (Best: 0.0001712 @iter7999) ([91m↑0.01%[0m) [0.08% of initial]
Iter:14599, L1 loss=0.0003478, Total loss=0.0003454, Time:15
[Iter 14600/20000] Loss: 0.0003395 (Best: 0.0001712 @iter7999) ([92m↓4.83%[0m) [0.07% of initial]
[Iter 14610/20000] Loss: 0.0003412 (Best: 0.0001712 @iter7999) ([91m↑0.53%[0m) [0.07% of initial]
[Iter 14620/20000] Loss: 0.0003409 (Best: 0.0001712 @iter7999) ([92m↓0.11%[0m) [0.07% of initial]
[Iter 14630/20000] Loss: 0.0003371 (Best: 0.0001712 @iter7999) ([92m↓1.11%[0m) [0.07% of initial]
[Iter 14640/20000] Loss: 0.0003421 (Best: 0.0001712 @iter7999) ([91m↑1.48%[0m) [0.07% of initial]
[Iter 14650/20000] Loss: 0.0003353 (Best: 0.0001712 @iter7999) ([92m↓1.98%[0m) [0.07% of initial]
[Iter 14660/20000] Loss: 0.0003320 (Best: 0.0001712 @iter7999) ([92m↓1.00%[0m) [0.07% of initial]
[Iter 14670/20000] Loss: 0.0003321 (Best: 0.0001712 @iter7999) ([91m↑0.04%[0m) [0.07% of initial]
[Iter 14680/20000] Loss: 0.0003270 (Best: 0.0001712 @iter7999) ([92m↓1.53%[0m) [0.07% of initial]
[Iter 14690/20000] Loss: 0.0003303 (Best: 0.0001712 @iter7999) ([91m↑1.01%[0m) [0.07% of initial]
Iter:14699, L1 loss=0.0003401, Total loss=0.0003312, Time:20
[Iter 14700/20000] Loss: 0.0003285 (Best: 0.0001712 @iter7999) ([92m↓0.56%[0m) [0.07% of initial]
[Iter 14710/20000] Loss: 0.0003276 (Best: 0.0001712 @iter7999) ([92m↓0.27%[0m) [0.07% of initial]
[Iter 14720/20000] Loss: 0.0003349 (Best: 0.0001712 @iter7999) ([91m↑2.23%[0m) [0.07% of initial]
[Iter 14730/20000] Loss: 0.0003345 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.07% of initial]
[Iter 14740/20000] Loss: 0.0003347 (Best: 0.0001712 @iter7999) ([91m↑0.06%[0m) [0.07% of initial]
[Iter 14750/20000] Loss: 0.0003262 (Best: 0.0001712 @iter7999) ([92m↓2.54%[0m) [0.07% of initial]
[Iter 14760/20000] Loss: 0.0003311 (Best: 0.0001712 @iter7999) ([91m↑1.48%[0m) [0.07% of initial]
[Iter 14770/20000] Loss: 0.0003365 (Best: 0.0001712 @iter7999) ([91m↑1.63%[0m) [0.07% of initial]
[Iter 14780/20000] Loss: 0.0003346 (Best: 0.0001712 @iter7999) ([92m↓0.57%[0m) [0.07% of initial]
[Iter 14790/20000] Loss: 0.0003281 (Best: 0.0001712 @iter7999) ([92m↓1.92%[0m) [0.07% of initial]
Iter:14799, L1 loss=0.0003419, Total loss=0.0003307, Time:17
[Iter 14800/20000] Loss: 0.0003244 (Best: 0.0001712 @iter7999) ([92m↓1.12%[0m) [0.07% of initial]
[Iter 14810/20000] Loss: 0.0003298 (Best: 0.0001712 @iter7999) ([91m↑1.64%[0m) [0.07% of initial]
[Iter 14820/20000] Loss: 0.0003294 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.07% of initial]
[Iter 14830/20000] Loss: 0.0003255 (Best: 0.0001712 @iter7999) ([92m↓1.18%[0m) [0.07% of initial]
[Iter 14840/20000] Loss: 0.0003314 (Best: 0.0001712 @iter7999) ([91m↑1.79%[0m) [0.07% of initial]
[Iter 14850/20000] Loss: 0.0003263 (Best: 0.0001712 @iter7999) ([92m↓1.52%[0m) [0.07% of initial]
[Iter 14860/20000] Loss: 0.0003246 (Best: 0.0001712 @iter7999) ([92m↓0.54%[0m) [0.07% of initial]
[Iter 14870/20000] Loss: 0.0003296 (Best: 0.0001712 @iter7999) ([91m↑1.54%[0m) [0.07% of initial]
[Iter 14880/20000] Loss: 0.0003296 (Best: 0.0001712 @iter7999) ([91m↑0.01%[0m) [0.07% of initial]
[Iter 14890/20000] Loss: 0.0003251 (Best: 0.0001712 @iter7999) ([92m↓1.36%[0m) [0.07% of initial]
Iter:14899, L1 loss=0.000325, Total loss=0.0003318, Time:15
[Iter 14900/20000] Loss: 0.0003211 (Best: 0.0001712 @iter7999) ([92m↓1.25%[0m) [0.07% of initial]
[Iter 14910/20000] Loss: 0.0003244 (Best: 0.0001712 @iter7999) ([91m↑1.03%[0m) [0.07% of initial]
[Iter 14920/20000] Loss: 0.0003243 (Best: 0.0001712 @iter7999) ([92m↓0.03%[0m) [0.07% of initial]
[Iter 14930/20000] Loss: 0.0003281 (Best: 0.0001712 @iter7999) ([91m↑1.17%[0m) [0.07% of initial]
[Iter 14940/20000] Loss: 0.0003208 (Best: 0.0001712 @iter7999) ([92m↓2.21%[0m) [0.07% of initial]
[Iter 14950/20000] Loss: 0.0003184 (Best: 0.0001712 @iter7999) ([92m↓0.77%[0m) [0.07% of initial]
[Iter 14960/20000] Loss: 0.0003196 (Best: 0.0001712 @iter7999) ([91m↑0.38%[0m) [0.07% of initial]
[Iter 14970/20000] Loss: 0.0003231 (Best: 0.0001712 @iter7999) ([91m↑1.10%[0m) [0.07% of initial]
[Iter 14980/20000] Loss: 0.0003247 (Best: 0.0001712 @iter7999) ([91m↑0.49%[0m) [0.07% of initial]
[Iter 14990/20000] Loss: 0.0003175 (Best: 0.0001712 @iter7999) ([92m↓2.23%[0m) [0.07% of initial]
Iter:14999, L1 loss=0.0003273, Total loss=0.000328, Time:22
[Iter 15000/20000] Loss: 0.0003223 (Best: 0.0001712 @iter7999) ([91m↑1.54%[0m) [0.07% of initial]
Pruning 35 points (0.9%) from gaussian0 at iteration 15000
Pruning 31 points (0.9%) from gaussian1 at iteration 15000
[Iter 15010/20000] Loss: 0.0007397 (Best: 0.0001712 @iter7999) ([91m↑129.48%[0m) [0.16% of initial]
[Iter 15020/20000] Loss: 0.0005181 (Best: 0.0001712 @iter7999) ([92m↓29.96%[0m) [0.11% of initial]
[Iter 15030/20000] Loss: 0.0004468 (Best: 0.0001712 @iter7999) ([92m↓13.77%[0m) [0.10% of initial]
[Iter 15040/20000] Loss: 0.0004081 (Best: 0.0001712 @iter7999) ([92m↓8.65%[0m) [0.09% of initial]
[Iter 15050/20000] Loss: 0.0003994 (Best: 0.0001712 @iter7999) ([92m↓2.12%[0m) [0.09% of initial]
[Iter 15060/20000] Loss: 0.0003793 (Best: 0.0001712 @iter7999) ([92m↓5.05%[0m) [0.08% of initial]
[Iter 15070/20000] Loss: 0.0003792 (Best: 0.0001712 @iter7999) ([92m↓0.01%[0m) [0.08% of initial]
[Iter 15080/20000] Loss: 0.0003681 (Best: 0.0001712 @iter7999) ([92m↓2.94%[0m) [0.08% of initial]
[Iter 15090/20000] Loss: 0.0003577 (Best: 0.0001712 @iter7999) ([92m↓2.81%[0m) [0.08% of initial]
Iter:15099, L1 loss=0.0004104, Total loss=0.0003443, Time:16
[Iter 15100/20000] Loss: 0.0003573 (Best: 0.0001712 @iter7999) ([92m↓0.13%[0m) [0.08% of initial]
[Iter 15110/20000] Loss: 0.0003473 (Best: 0.0001712 @iter7999) ([92m↓2.78%[0m) [0.08% of initial]
[Iter 15120/20000] Loss: 0.0003470 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.08% of initial]
[Iter 15130/20000] Loss: 0.0003451 (Best: 0.0001712 @iter7999) ([92m↓0.53%[0m) [0.07% of initial]
[Iter 15140/20000] Loss: 0.0003403 (Best: 0.0001712 @iter7999) ([92m↓1.40%[0m) [0.07% of initial]
[Iter 15150/20000] Loss: 0.0003426 (Best: 0.0001712 @iter7999) ([91m↑0.66%[0m) [0.07% of initial]
[Iter 15160/20000] Loss: 0.0003358 (Best: 0.0001712 @iter7999) ([92m↓1.97%[0m) [0.07% of initial]
[Iter 15170/20000] Loss: 0.0003387 (Best: 0.0001712 @iter7999) ([91m↑0.87%[0m) [0.07% of initial]
[Iter 15180/20000] Loss: 0.0003336 (Best: 0.0001712 @iter7999) ([92m↓1.52%[0m) [0.07% of initial]
[Iter 15190/20000] Loss: 0.0003266 (Best: 0.0001712 @iter7999) ([92m↓2.09%[0m) [0.07% of initial]
Iter:15199, L1 loss=0.0003597, Total loss=0.0003303, Time:17
[Iter 15200/20000] Loss: 0.0003268 (Best: 0.0001712 @iter7999) ([91m↑0.08%[0m) [0.07% of initial]
[Iter 15210/20000] Loss: 0.0003282 (Best: 0.0001712 @iter7999) ([91m↑0.41%[0m) [0.07% of initial]
[Iter 15220/20000] Loss: 0.0003303 (Best: 0.0001712 @iter7999) ([91m↑0.64%[0m) [0.07% of initial]
[Iter 15230/20000] Loss: 0.0003257 (Best: 0.0001712 @iter7999) ([92m↓1.38%[0m) [0.07% of initial]
[Iter 15240/20000] Loss: 0.0003241 (Best: 0.0001712 @iter7999) ([92m↓0.48%[0m) [0.07% of initial]
[Iter 15250/20000] Loss: 0.0003180 (Best: 0.0001712 @iter7999) ([92m↓1.91%[0m) [0.07% of initial]
[Iter 15260/20000] Loss: 0.0003211 (Best: 0.0001712 @iter7999) ([91m↑0.99%[0m) [0.07% of initial]
[Iter 15270/20000] Loss: 0.0003216 (Best: 0.0001712 @iter7999) ([91m↑0.16%[0m) [0.07% of initial]
[Iter 15280/20000] Loss: 0.0003235 (Best: 0.0001712 @iter7999) ([91m↑0.60%[0m) [0.07% of initial]
[Iter 15290/20000] Loss: 0.0003194 (Best: 0.0001712 @iter7999) ([92m↓1.28%[0m) [0.07% of initial]
Iter:15299, L1 loss=0.000343, Total loss=0.000322, Time:13
[Iter 15300/20000] Loss: 0.0003240 (Best: 0.0001712 @iter7999) ([91m↑1.43%[0m) [0.07% of initial]
[Iter 15310/20000] Loss: 0.0003203 (Best: 0.0001712 @iter7999) ([92m↓1.15%[0m) [0.07% of initial]
[Iter 15320/20000] Loss: 0.0003176 (Best: 0.0001712 @iter7999) ([92m↓0.83%[0m) [0.07% of initial]
[Iter 15330/20000] Loss: 0.0003191 (Best: 0.0001712 @iter7999) ([91m↑0.46%[0m) [0.07% of initial]
[Iter 15340/20000] Loss: 0.0003152 (Best: 0.0001712 @iter7999) ([92m↓1.20%[0m) [0.07% of initial]
[Iter 15350/20000] Loss: 0.0003172 (Best: 0.0001712 @iter7999) ([91m↑0.63%[0m) [0.07% of initial]
[Iter 15360/20000] Loss: 0.0003180 (Best: 0.0001712 @iter7999) ([91m↑0.25%[0m) [0.07% of initial]
[Iter 15370/20000] Loss: 0.0003187 (Best: 0.0001712 @iter7999) ([91m↑0.22%[0m) [0.07% of initial]
[Iter 15380/20000] Loss: 0.0003138 (Best: 0.0001712 @iter7999) ([92m↓1.54%[0m) [0.07% of initial]
[Iter 15390/20000] Loss: 0.0003157 (Best: 0.0001712 @iter7999) ([91m↑0.62%[0m) [0.07% of initial]
Iter:15399, L1 loss=0.0003193, Total loss=0.0003082, Time:16
[Iter 15400/20000] Loss: 0.0003154 (Best: 0.0001712 @iter7999) ([92m↓0.11%[0m) [0.07% of initial]
[Iter 15410/20000] Loss: 0.0003104 (Best: 0.0001712 @iter7999) ([92m↓1.60%[0m) [0.07% of initial]
[Iter 15420/20000] Loss: 0.0003127 (Best: 0.0001712 @iter7999) ([91m↑0.75%[0m) [0.07% of initial]
[Iter 15430/20000] Loss: 0.0003094 (Best: 0.0001712 @iter7999) ([92m↓1.04%[0m) [0.07% of initial]
[Iter 15440/20000] Loss: 0.0003164 (Best: 0.0001712 @iter7999) ([91m↑2.26%[0m) [0.07% of initial]
[Iter 15450/20000] Loss: 0.0003125 (Best: 0.0001712 @iter7999) ([92m↓1.24%[0m) [0.07% of initial]
[Iter 15460/20000] Loss: 0.0003116 (Best: 0.0001712 @iter7999) ([92m↓0.29%[0m) [0.07% of initial]
[Iter 15470/20000] Loss: 0.0003144 (Best: 0.0001712 @iter7999) ([91m↑0.91%[0m) [0.07% of initial]
[Iter 15480/20000] Loss: 0.0003130 (Best: 0.0001712 @iter7999) ([92m↓0.46%[0m) [0.07% of initial]
[Iter 15490/20000] Loss: 0.0003078 (Best: 0.0001712 @iter7999) ([92m↓1.64%[0m) [0.07% of initial]
Iter:15499, L1 loss=0.0003241, Total loss=0.0003162, Time:16
[Iter 15500/20000] Loss: 0.0003101 (Best: 0.0001712 @iter7999) ([91m↑0.74%[0m) [0.07% of initial]
Pruning 30 points (0.8%) from gaussian0 at iteration 15500
Pruning 28 points (0.8%) from gaussian1 at iteration 15500
[Iter 15510/20000] Loss: 0.0019463 (Best: 0.0001712 @iter7999) ([91m↑527.66%[0m) [0.42% of initial]
[Iter 15520/20000] Loss: 0.0012791 (Best: 0.0001712 @iter7999) ([92m↓34.28%[0m) [0.28% of initial]
[Iter 15530/20000] Loss: 0.0008895 (Best: 0.0001712 @iter7999) ([92m↓30.45%[0m) [0.19% of initial]
[Iter 15540/20000] Loss: 0.0006860 (Best: 0.0001712 @iter7999) ([92m↓22.88%[0m) [0.15% of initial]
[Iter 15550/20000] Loss: 0.0005921 (Best: 0.0001712 @iter7999) ([92m↓13.69%[0m) [0.13% of initial]
[Iter 15560/20000] Loss: 0.0005111 (Best: 0.0001712 @iter7999) ([92m↓13.67%[0m) [0.11% of initial]
[Iter 15570/20000] Loss: 0.0004825 (Best: 0.0001712 @iter7999) ([92m↓5.60%[0m) [0.10% of initial]
[Iter 15580/20000] Loss: 0.0004516 (Best: 0.0001712 @iter7999) ([92m↓6.40%[0m) [0.10% of initial]
[Iter 15590/20000] Loss: 0.0004316 (Best: 0.0001712 @iter7999) ([92m↓4.42%[0m) [0.09% of initial]
Iter:15599, L1 loss=0.0003456, Total loss=0.000428, Time:22
[Iter 15600/20000] Loss: 0.0004224 (Best: 0.0001712 @iter7999) ([92m↓2.14%[0m) [0.09% of initial]
[Iter 15610/20000] Loss: 0.0004088 (Best: 0.0001712 @iter7999) ([92m↓3.21%[0m) [0.09% of initial]
[Iter 15620/20000] Loss: 0.0003964 (Best: 0.0001712 @iter7999) ([92m↓3.05%[0m) [0.09% of initial]
[Iter 15630/20000] Loss: 0.0003871 (Best: 0.0001712 @iter7999) ([92m↓2.33%[0m) [0.08% of initial]
[Iter 15640/20000] Loss: 0.0003748 (Best: 0.0001712 @iter7999) ([92m↓3.19%[0m) [0.08% of initial]
[Iter 15650/20000] Loss: 0.0003768 (Best: 0.0001712 @iter7999) ([91m↑0.54%[0m) [0.08% of initial]
[Iter 15660/20000] Loss: 0.0003631 (Best: 0.0001712 @iter7999) ([92m↓3.63%[0m) [0.08% of initial]
[Iter 15670/20000] Loss: 0.0003627 (Best: 0.0001712 @iter7999) ([92m↓0.12%[0m) [0.08% of initial]
[Iter 15680/20000] Loss: 0.0003551 (Best: 0.0001712 @iter7999) ([92m↓2.11%[0m) [0.08% of initial]
[Iter 15690/20000] Loss: 0.0003581 (Best: 0.0001712 @iter7999) ([91m↑0.87%[0m) [0.08% of initial]
Iter:15699, L1 loss=0.0003265, Total loss=0.000346, Time:20
[Iter 15700/20000] Loss: 0.0003483 (Best: 0.0001712 @iter7999) ([92m↓2.75%[0m) [0.08% of initial]
[Iter 15710/20000] Loss: 0.0003457 (Best: 0.0001712 @iter7999) ([92m↓0.75%[0m) [0.07% of initial]
[Iter 15720/20000] Loss: 0.0003473 (Best: 0.0001712 @iter7999) ([91m↑0.46%[0m) [0.08% of initial]
[Iter 15730/20000] Loss: 0.0003426 (Best: 0.0001712 @iter7999) ([92m↓1.34%[0m) [0.07% of initial]
[Iter 15740/20000] Loss: 0.0003387 (Best: 0.0001712 @iter7999) ([92m↓1.15%[0m) [0.07% of initial]
[Iter 15750/20000] Loss: 0.0003409 (Best: 0.0001712 @iter7999) ([91m↑0.65%[0m) [0.07% of initial]
[Iter 15760/20000] Loss: 0.0003321 (Best: 0.0001712 @iter7999) ([92m↓2.58%[0m) [0.07% of initial]
[Iter 15770/20000] Loss: 0.0003303 (Best: 0.0001712 @iter7999) ([92m↓0.54%[0m) [0.07% of initial]
[Iter 15780/20000] Loss: 0.0003332 (Best: 0.0001712 @iter7999) ([91m↑0.89%[0m) [0.07% of initial]
[Iter 15790/20000] Loss: 0.0003333 (Best: 0.0001712 @iter7999) ([91m↑0.02%[0m) [0.07% of initial]
Iter:15799, L1 loss=0.0003334, Total loss=0.0003394, Time:17
[Iter 15800/20000] Loss: 0.0003275 (Best: 0.0001712 @iter7999) ([92m↓1.74%[0m) [0.07% of initial]
[Iter 15810/20000] Loss: 0.0003215 (Best: 0.0001712 @iter7999) ([92m↓1.83%[0m) [0.07% of initial]
[Iter 15820/20000] Loss: 0.0003255 (Best: 0.0001712 @iter7999) ([91m↑1.25%[0m) [0.07% of initial]
[Iter 15830/20000] Loss: 0.0003191 (Best: 0.0001712 @iter7999) ([92m↓1.98%[0m) [0.07% of initial]
[Iter 15840/20000] Loss: 0.0003231 (Best: 0.0001712 @iter7999) ([91m↑1.26%[0m) [0.07% of initial]
[Iter 15850/20000] Loss: 0.0003192 (Best: 0.0001712 @iter7999) ([92m↓1.22%[0m) [0.07% of initial]
[Iter 15860/20000] Loss: 0.0003159 (Best: 0.0001712 @iter7999) ([92m↓1.02%[0m) [0.07% of initial]
[Iter 15870/20000] Loss: 0.0003143 (Best: 0.0001712 @iter7999) ([92m↓0.51%[0m) [0.07% of initial]
[Iter 15880/20000] Loss: 0.0003098 (Best: 0.0001712 @iter7999) ([92m↓1.43%[0m) [0.07% of initial]
[Iter 15890/20000] Loss: 0.0003101 (Best: 0.0001712 @iter7999) ([91m↑0.09%[0m) [0.07% of initial]
Iter:15899, L1 loss=0.0003069, Total loss=0.000303, Time:18
[Iter 15900/20000] Loss: 0.0003142 (Best: 0.0001712 @iter7999) ([91m↑1.34%[0m) [0.07% of initial]
[Iter 15910/20000] Loss: 0.0003167 (Best: 0.0001712 @iter7999) ([91m↑0.77%[0m) [0.07% of initial]
[Iter 15920/20000] Loss: 0.0003118 (Best: 0.0001712 @iter7999) ([92m↓1.54%[0m) [0.07% of initial]
[Iter 15930/20000] Loss: 0.0003082 (Best: 0.0001712 @iter7999) ([92m↓1.15%[0m) [0.07% of initial]
[Iter 15940/20000] Loss: 0.0003017 (Best: 0.0001712 @iter7999) ([92m↓2.10%[0m) [0.07% of initial]
[Iter 15950/20000] Loss: 0.0003113 (Best: 0.0001712 @iter7999) ([91m↑3.16%[0m) [0.07% of initial]
[Iter 15960/20000] Loss: 0.0003090 (Best: 0.0001712 @iter7999) ([92m↓0.71%[0m) [0.07% of initial]
[Iter 15970/20000] Loss: 0.0003020 (Best: 0.0001712 @iter7999) ([92m↓2.27%[0m) [0.07% of initial]
[Iter 15980/20000] Loss: 0.0003051 (Best: 0.0001712 @iter7999) ([91m↑1.04%[0m) [0.07% of initial]
[Iter 15990/20000] Loss: 0.0003080 (Best: 0.0001712 @iter7999) ([91m↑0.92%[0m) [0.07% of initial]
Iter:15999, L1 loss=0.0003059, Total loss=0.0002979, Time:22
[Iter 16000/20000] Loss: 0.0003079 (Best: 0.0001712 @iter7999) ([92m↓0.02%[0m) [0.07% of initial]
Pruning 28 points (0.8%) from gaussian0 at iteration 16000
Pruning 26 points (0.7%) from gaussian1 at iteration 16000
[Iter 16010/20000] Loss: 0.0774802 (Best: 0.0001712 @iter7999) ([91m↑25065.23%[0m) [16.81% of initial]
[Iter 16020/20000] Loss: 0.0668809 (Best: 0.0001712 @iter7999) ([92m↓13.68%[0m) [14.51% of initial]
[Iter 16030/20000] Loss: 0.0533323 (Best: 0.0001712 @iter7999) ([92m↓20.26%[0m) [11.57% of initial]
[Iter 16040/20000] Loss: 0.0384633 (Best: 0.0001712 @iter7999) ([92m↓27.88%[0m) [8.34% of initial]
[Iter 16050/20000] Loss: 0.0245613 (Best: 0.0001712 @iter7999) ([92m↓36.14%[0m) [5.33% of initial]
[Iter 16060/20000] Loss: 0.0144815 (Best: 0.0001712 @iter7999) ([92m↓41.04%[0m) [3.14% of initial]
[Iter 16070/20000] Loss: 0.0092606 (Best: 0.0001712 @iter7999) ([92m↓36.05%[0m) [2.01% of initial]
[Iter 16080/20000] Loss: 0.0070741 (Best: 0.0001712 @iter7999) ([92m↓23.61%[0m) [1.53% of initial]
[Iter 16090/20000] Loss: 0.0051632 (Best: 0.0001712 @iter7999) ([92m↓27.01%[0m) [1.12% of initial]
Iter:16099, L1 loss=0.002307, Total loss=0.00391, Time:20
[Iter 16100/20000] Loss: 0.0038499 (Best: 0.0001712 @iter7999) ([92m↓25.44%[0m) [0.84% of initial]
[Iter 16110/20000] Loss: 0.0028468 (Best: 0.0001712 @iter7999) ([92m↓26.06%[0m) [0.62% of initial]
[Iter 16120/20000] Loss: 0.0022910 (Best: 0.0001712 @iter7999) ([92m↓19.52%[0m) [0.50% of initial]
[Iter 16130/20000] Loss: 0.0018908 (Best: 0.0001712 @iter7999) ([92m↓17.47%[0m) [0.41% of initial]
[Iter 16140/20000] Loss: 0.0015808 (Best: 0.0001712 @iter7999) ([92m↓16.39%[0m) [0.34% of initial]
[Iter 16150/20000] Loss: 0.0014027 (Best: 0.0001712 @iter7999) ([92m↓11.27%[0m) [0.30% of initial]
[Iter 16160/20000] Loss: 0.0011933 (Best: 0.0001712 @iter7999) ([92m↓14.93%[0m) [0.26% of initial]
[Iter 16170/20000] Loss: 0.0011573 (Best: 0.0001712 @iter7999) ([92m↓3.02%[0m) [0.25% of initial]
[Iter 16180/20000] Loss: 0.0010211 (Best: 0.0001712 @iter7999) ([92m↓11.77%[0m) [0.22% of initial]
[Iter 16190/20000] Loss: 0.0010200 (Best: 0.0001712 @iter7999) ([92m↓0.11%[0m) [0.22% of initial]
Iter:16199, L1 loss=0.0007043, Total loss=0.0008663, Time:19
[Iter 16200/20000] Loss: 0.0009657 (Best: 0.0001712 @iter7999) ([92m↓5.33%[0m) [0.21% of initial]
[Iter 16210/20000] Loss: 0.0009529 (Best: 0.0001712 @iter7999) ([92m↓1.32%[0m) [0.21% of initial]
[Iter 16220/20000] Loss: 0.0008529 (Best: 0.0001712 @iter7999) ([92m↓10.50%[0m) [0.19% of initial]
[Iter 16230/20000] Loss: 0.0008465 (Best: 0.0001712 @iter7999) ([92m↓0.75%[0m) [0.18% of initial]
[Iter 16240/20000] Loss: 0.0008544 (Best: 0.0001712 @iter7999) ([91m↑0.93%[0m) [0.19% of initial]
[Iter 16250/20000] Loss: 0.0007708 (Best: 0.0001712 @iter7999) ([92m↓9.79%[0m) [0.17% of initial]
[Iter 16260/20000] Loss: 0.0007526 (Best: 0.0001712 @iter7999) ([92m↓2.36%[0m) [0.16% of initial]
[Iter 16270/20000] Loss: 0.0007569 (Best: 0.0001712 @iter7999) ([91m↑0.57%[0m) [0.16% of initial]
[Iter 16280/20000] Loss: 0.0007306 (Best: 0.0001712 @iter7999) ([92m↓3.47%[0m) [0.16% of initial]
[Iter 16290/20000] Loss: 0.0007084 (Best: 0.0001712 @iter7999) ([92m↓3.04%[0m) [0.15% of initial]
Iter:16299, L1 loss=0.0006152, Total loss=0.0006922, Time:15
[Iter 16300/20000] Loss: 0.0006642 (Best: 0.0001712 @iter7999) ([92m↓6.25%[0m) [0.14% of initial]
[Iter 16310/20000] Loss: 0.0006676 (Best: 0.0001712 @iter7999) ([91m↑0.52%[0m) [0.14% of initial]
[Iter 16320/20000] Loss: 0.0006616 (Best: 0.0001712 @iter7999) ([92m↓0.90%[0m) [0.14% of initial]
[Iter 16330/20000] Loss: 0.0006647 (Best: 0.0001712 @iter7999) ([91m↑0.48%[0m) [0.14% of initial]
[Iter 16340/20000] Loss: 0.0006214 (Best: 0.0001712 @iter7999) ([92m↓6.51%[0m) [0.13% of initial]
[Iter 16350/20000] Loss: 0.0006379 (Best: 0.0001712 @iter7999) ([91m↑2.64%[0m) [0.14% of initial]
[Iter 16360/20000] Loss: 0.0005953 (Best: 0.0001712 @iter7999) ([92m↓6.68%[0m) [0.13% of initial]
[Iter 16370/20000] Loss: 0.0006049 (Best: 0.0001712 @iter7999) ([91m↑1.62%[0m) [0.13% of initial]
[Iter 16380/20000] Loss: 0.0006070 (Best: 0.0001712 @iter7999) ([91m↑0.33%[0m) [0.13% of initial]
[Iter 16390/20000] Loss: 0.0005905 (Best: 0.0001712 @iter7999) ([92m↓2.71%[0m) [0.13% of initial]
Iter:16399, L1 loss=0.0005512, Total loss=0.0006168, Time:16
[Iter 16400/20000] Loss: 0.0005941 (Best: 0.0001712 @iter7999) ([91m↑0.61%[0m) [0.13% of initial]
[Iter 16410/20000] Loss: 0.0005689 (Best: 0.0001712 @iter7999) ([92m↓4.24%[0m) [0.12% of initial]
[Iter 16420/20000] Loss: 0.0005570 (Best: 0.0001712 @iter7999) ([92m↓2.09%[0m) [0.12% of initial]
[Iter 16430/20000] Loss: 0.0005525 (Best: 0.0001712 @iter7999) ([92m↓0.80%[0m) [0.12% of initial]
[Iter 16440/20000] Loss: 0.0005519 (Best: 0.0001712 @iter7999) ([92m↓0.11%[0m) [0.12% of initial]
[Iter 16450/20000] Loss: 0.0005413 (Best: 0.0001712 @iter7999) ([92m↓1.93%[0m) [0.12% of initial]
[Iter 16460/20000] Loss: 0.0005453 (Best: 0.0001712 @iter7999) ([91m↑0.74%[0m) [0.12% of initial]
[Iter 16470/20000] Loss: 0.0005425 (Best: 0.0001712 @iter7999) ([92m↓0.50%[0m) [0.12% of initial]
[Iter 16480/20000] Loss: 0.0005276 (Best: 0.0001712 @iter7999) ([92m↓2.75%[0m) [0.11% of initial]
[Iter 16490/20000] Loss: 0.0005225 (Best: 0.0001712 @iter7999) ([92m↓0.97%[0m) [0.11% of initial]
Iter:16499, L1 loss=0.0004611, Total loss=0.0004949, Time:16
[Iter 16500/20000] Loss: 0.0005325 (Best: 0.0001712 @iter7999) ([91m↑1.91%[0m) [0.12% of initial]
Pruning 26 points (0.7%) from gaussian0 at iteration 16500
Pruning 20 points (0.6%) from gaussian1 at iteration 16500
[Iter 16510/20000] Loss: 0.0010390 (Best: 0.0001712 @iter7999) ([91m↑95.12%[0m) [0.23% of initial]
[Iter 16520/20000] Loss: 0.0008033 (Best: 0.0001712 @iter7999) ([92m↓22.69%[0m) [0.17% of initial]
[Iter 16530/20000] Loss: 0.0006976 (Best: 0.0001712 @iter7999) ([92m↓13.15%[0m) [0.15% of initial]
[Iter 16540/20000] Loss: 0.0006398 (Best: 0.0001712 @iter7999) ([92m↓8.30%[0m) [0.14% of initial]
[Iter 16550/20000] Loss: 0.0005937 (Best: 0.0001712 @iter7999) ([92m↓7.20%[0m) [0.13% of initial]
[Iter 16560/20000] Loss: 0.0005819 (Best: 0.0001712 @iter7999) ([92m↓1.99%[0m) [0.13% of initial]
[Iter 16570/20000] Loss: 0.0005471 (Best: 0.0001712 @iter7999) ([92m↓5.98%[0m) [0.12% of initial]
[Iter 16580/20000] Loss: 0.0005431 (Best: 0.0001712 @iter7999) ([92m↓0.72%[0m) [0.12% of initial]
[Iter 16590/20000] Loss: 0.0005417 (Best: 0.0001712 @iter7999) ([92m↓0.26%[0m) [0.12% of initial]
Iter:16599, L1 loss=0.000481, Total loss=0.0005429, Time:18
[Iter 16600/20000] Loss: 0.0005201 (Best: 0.0001712 @iter7999) ([92m↓4.00%[0m) [0.11% of initial]
[Iter 16610/20000] Loss: 0.0005312 (Best: 0.0001712 @iter7999) ([91m↑2.13%[0m) [0.12% of initial]
[Iter 16620/20000] Loss: 0.0005175 (Best: 0.0001712 @iter7999) ([92m↓2.57%[0m) [0.11% of initial]
[Iter 16630/20000] Loss: 0.0005173 (Best: 0.0001712 @iter7999) ([92m↓0.04%[0m) [0.11% of initial]
[Iter 16640/20000] Loss: 0.0005086 (Best: 0.0001712 @iter7999) ([92m↓1.67%[0m) [0.11% of initial]
[Iter 16650/20000] Loss: 0.0005103 (Best: 0.0001712 @iter7999) ([91m↑0.33%[0m) [0.11% of initial]
[Iter 16660/20000] Loss: 0.0004937 (Best: 0.0001712 @iter7999) ([92m↓3.26%[0m) [0.11% of initial]
[Iter 16670/20000] Loss: 0.0005075 (Best: 0.0001712 @iter7999) ([91m↑2.81%[0m) [0.11% of initial]
[Iter 16680/20000] Loss: 0.0005015 (Best: 0.0001712 @iter7999) ([92m↓1.19%[0m) [0.11% of initial]
[Iter 16690/20000] Loss: 0.0004871 (Best: 0.0001712 @iter7999) ([92m↓2.86%[0m) [0.11% of initial]
Iter:16699, L1 loss=0.0004562, Total loss=0.0005067, Time:16
[Iter 16700/20000] Loss: 0.0005059 (Best: 0.0001712 @iter7999) ([91m↑3.86%[0m) [0.11% of initial]
[Iter 16710/20000] Loss: 0.0005004 (Best: 0.0001712 @iter7999) ([92m↓1.09%[0m) [0.11% of initial]
[Iter 16720/20000] Loss: 0.0005058 (Best: 0.0001712 @iter7999) ([91m↑1.08%[0m) [0.11% of initial]
[Iter 16730/20000] Loss: 0.0004947 (Best: 0.0001712 @iter7999) ([92m↓2.20%[0m) [0.11% of initial]
[Iter 16740/20000] Loss: 0.0005022 (Best: 0.0001712 @iter7999) ([91m↑1.52%[0m) [0.11% of initial]
[Iter 16750/20000] Loss: 0.0004878 (Best: 0.0001712 @iter7999) ([92m↓2.87%[0m) [0.11% of initial]
[Iter 16760/20000] Loss: 0.0004923 (Best: 0.0001712 @iter7999) ([91m↑0.92%[0m) [0.11% of initial]
[Iter 16770/20000] Loss: 0.0004866 (Best: 0.0001712 @iter7999) ([92m↓1.15%[0m) [0.11% of initial]
[Iter 16780/20000] Loss: 0.0004966 (Best: 0.0001712 @iter7999) ([91m↑2.05%[0m) [0.11% of initial]
[Iter 16790/20000] Loss: 0.0004892 (Best: 0.0001712 @iter7999) ([92m↓1.49%[0m) [0.11% of initial]
Iter:16799, L1 loss=0.0004434, Total loss=0.0004889, Time:14
[Iter 16800/20000] Loss: 0.0004845 (Best: 0.0001712 @iter7999) ([92m↓0.96%[0m) [0.11% of initial]
[Iter 16810/20000] Loss: 0.0004842 (Best: 0.0001712 @iter7999) ([92m↓0.06%[0m) [0.11% of initial]
[Iter 16820/20000] Loss: 0.0004727 (Best: 0.0001712 @iter7999) ([92m↓2.37%[0m) [0.10% of initial]
[Iter 16830/20000] Loss: 0.0004707 (Best: 0.0001712 @iter7999) ([92m↓0.41%[0m) [0.10% of initial]
[Iter 16840/20000] Loss: 0.0004731 (Best: 0.0001712 @iter7999) ([91m↑0.51%[0m) [0.10% of initial]
[Iter 16850/20000] Loss: 0.0004692 (Best: 0.0001712 @iter7999) ([92m↓0.83%[0m) [0.10% of initial]
[Iter 16860/20000] Loss: 0.0004611 (Best: 0.0001712 @iter7999) ([92m↓1.72%[0m) [0.10% of initial]
[Iter 16870/20000] Loss: 0.0004495 (Best: 0.0001712 @iter7999) ([92m↓2.52%[0m) [0.10% of initial]
[Iter 16880/20000] Loss: 0.0004477 (Best: 0.0001712 @iter7999) ([92m↓0.41%[0m) [0.10% of initial]
[Iter 16890/20000] Loss: 0.0004561 (Best: 0.0001712 @iter7999) ([91m↑1.88%[0m) [0.10% of initial]
Iter:16899, L1 loss=0.0004441, Total loss=0.0004638, Time:19
[Iter 16900/20000] Loss: 0.0004460 (Best: 0.0001712 @iter7999) ([92m↓2.20%[0m) [0.10% of initial]
[Iter 16910/20000] Loss: 0.0004450 (Best: 0.0001712 @iter7999) ([92m↓0.24%[0m) [0.10% of initial]
[Iter 16920/20000] Loss: 0.0004549 (Best: 0.0001712 @iter7999) ([91m↑2.22%[0m) [0.10% of initial]
[Iter 16930/20000] Loss: 0.0004514 (Best: 0.0001712 @iter7999) ([92m↓0.75%[0m) [0.10% of initial]
[Iter 16940/20000] Loss: 0.0004445 (Best: 0.0001712 @iter7999) ([92m↓1.55%[0m) [0.10% of initial]
[Iter 16950/20000] Loss: 0.0004483 (Best: 0.0001712 @iter7999) ([91m↑0.86%[0m) [0.10% of initial]
[Iter 16960/20000] Loss: 0.0004475 (Best: 0.0001712 @iter7999) ([92m↓0.16%[0m) [0.10% of initial]
[Iter 16970/20000] Loss: 0.0004501 (Best: 0.0001712 @iter7999) ([91m↑0.58%[0m) [0.10% of initial]
[Iter 16980/20000] Loss: 0.0004416 (Best: 0.0001712 @iter7999) ([92m↓1.90%[0m) [0.10% of initial]
[Iter 16990/20000] Loss: 0.0004420 (Best: 0.0001712 @iter7999) ([91m↑0.10%[0m) [0.10% of initial]
Iter:16999, L1 loss=0.0004424, Total loss=0.000444, Time:19
[Iter 17000/20000] Loss: 0.0004331 (Best: 0.0001712 @iter7999) ([92m↓2.01%[0m) [0.09% of initial]
Pruning 16 points (0.4%) from gaussian0 at iteration 17000
Pruning 17 points (0.5%) from gaussian1 at iteration 17000
[Iter 17010/20000] Loss: 0.0004808 (Best: 0.0001712 @iter7999) ([91m↑11.00%[0m) [0.10% of initial]
[Iter 17020/20000] Loss: 0.0004644 (Best: 0.0001712 @iter7999) ([92m↓3.41%[0m) [0.10% of initial]
[Iter 17030/20000] Loss: 0.0004550 (Best: 0.0001712 @iter7999) ([92m↓2.02%[0m) [0.10% of initial]
[Iter 17040/20000] Loss: 0.0004473 (Best: 0.0001712 @iter7999) ([92m↓1.70%[0m) [0.10% of initial]
[Iter 17050/20000] Loss: 0.0004578 (Best: 0.0001712 @iter7999) ([91m↑2.34%[0m) [0.10% of initial]
[Iter 17060/20000] Loss: 0.0004447 (Best: 0.0001712 @iter7999) ([92m↓2.86%[0m) [0.10% of initial]
[Iter 17070/20000] Loss: 0.0004439 (Best: 0.0001712 @iter7999) ([92m↓0.18%[0m) [0.10% of initial]
[Iter 17080/20000] Loss: 0.0004448 (Best: 0.0001712 @iter7999) ([91m↑0.21%[0m) [0.10% of initial]
[Iter 17090/20000] Loss: 0.0004371 (Best: 0.0001712 @iter7999) ([92m↓1.74%[0m) [0.09% of initial]
Iter:17099, L1 loss=0.0004715, Total loss=0.0004529, Time:21
[Iter 17100/20000] Loss: 0.0004429 (Best: 0.0001712 @iter7999) ([91m↑1.32%[0m) [0.10% of initial]
[Iter 17110/20000] Loss: 0.0004476 (Best: 0.0001712 @iter7999) ([91m↑1.07%[0m) [0.10% of initial]
[Iter 17120/20000] Loss: 0.0004465 (Best: 0.0001712 @iter7999) ([92m↓0.24%[0m) [0.10% of initial]
[Iter 17130/20000] Loss: 0.0004496 (Best: 0.0001712 @iter7999) ([91m↑0.69%[0m) [0.10% of initial]
[Iter 17140/20000] Loss: 0.0004469 (Best: 0.0001712 @iter7999) ([92m↓0.60%[0m) [0.10% of initial]
[Iter 17150/20000] Loss: 0.0004448 (Best: 0.0001712 @iter7999) ([92m↓0.47%[0m) [0.10% of initial]
[Iter 17160/20000] Loss: 0.0004412 (Best: 0.0001712 @iter7999) ([92m↓0.81%[0m) [0.10% of initial]
[Iter 17170/20000] Loss: 0.0004391 (Best: 0.0001712 @iter7999) ([92m↓0.47%[0m) [0.10% of initial]
[Iter 17180/20000] Loss: 0.0004220 (Best: 0.0001712 @iter7999) ([92m↓3.90%[0m) [0.09% of initial]
[Iter 17190/20000] Loss: 0.0004320 (Best: 0.0001712 @iter7999) ([91m↑2.38%[0m) [0.09% of initial]
Iter:17199, L1 loss=0.0004106, Total loss=0.000413, Time:16
[Iter 17200/20000] Loss: 0.0004261 (Best: 0.0001712 @iter7999) ([92m↓1.38%[0m) [0.09% of initial]
[Iter 17210/20000] Loss: 0.0004203 (Best: 0.0001712 @iter7999) ([92m↓1.36%[0m) [0.09% of initial]
[Iter 17220/20000] Loss: 0.0004196 (Best: 0.0001712 @iter7999) ([92m↓0.17%[0m) [0.09% of initial]
[Iter 17230/20000] Loss: 0.0004328 (Best: 0.0001712 @iter7999) ([91m↑3.16%[0m) [0.09% of initial]
[Iter 17240/20000] Loss: 0.0004279 (Best: 0.0001712 @iter7999) ([92m↓1.13%[0m) [0.09% of initial]
[Iter 17250/20000] Loss: 0.0004251 (Best: 0.0001712 @iter7999) ([92m↓0.67%[0m) [0.09% of initial]
[Iter 17260/20000] Loss: 0.0004165 (Best: 0.0001712 @iter7999) ([92m↓2.01%[0m) [0.09% of initial]
[Iter 17270/20000] Loss: 0.0004292 (Best: 0.0001712 @iter7999) ([91m↑3.05%[0m) [0.09% of initial]
[Iter 17280/20000] Loss: 0.0004239 (Best: 0.0001712 @iter7999) ([92m↓1.25%[0m) [0.09% of initial]
[Iter 17290/20000] Loss: 0.0004231 (Best: 0.0001712 @iter7999) ([92m↓0.18%[0m) [0.09% of initial]
Iter:17299, L1 loss=0.0003867, Total loss=0.0003978, Time:21
[Iter 17300/20000] Loss: 0.0004151 (Best: 0.0001712 @iter7999) ([92m↓1.89%[0m) [0.09% of initial]
[Iter 17310/20000] Loss: 0.0004176 (Best: 0.0001712 @iter7999) ([91m↑0.60%[0m) [0.09% of initial]
[Iter 17320/20000] Loss: 0.0004165 (Best: 0.0001712 @iter7999) ([92m↓0.26%[0m) [0.09% of initial]
[Iter 17330/20000] Loss: 0.0004102 (Best: 0.0001712 @iter7999) ([92m↓1.52%[0m) [0.09% of initial]
[Iter 17340/20000] Loss: 0.0004128 (Best: 0.0001712 @iter7999) ([91m↑0.63%[0m) [0.09% of initial]
[Iter 17350/20000] Loss: 0.0004063 (Best: 0.0001712 @iter7999) ([92m↓1.56%[0m) [0.09% of initial]
[Iter 17360/20000] Loss: 0.0004176 (Best: 0.0001712 @iter7999) ([91m↑2.76%[0m) [0.09% of initial]
[Iter 17370/20000] Loss: 0.0004165 (Best: 0.0001712 @iter7999) ([92m↓0.25%[0m) [0.09% of initial]
[Iter 17380/20000] Loss: 0.0004181 (Best: 0.0001712 @iter7999) ([91m↑0.39%[0m) [0.09% of initial]
[Iter 17390/20000] Loss: 0.0004087 (Best: 0.0001712 @iter7999) ([92m↓2.26%[0m) [0.09% of initial]
Iter:17399, L1 loss=0.0003819, Total loss=0.0003983, Time:18
[Iter 17400/20000] Loss: 0.0004123 (Best: 0.0001712 @iter7999) ([91m↑0.90%[0m) [0.09% of initial]
[Iter 17410/20000] Loss: 0.0003994 (Best: 0.0001712 @iter7999) ([92m↓3.14%[0m) [0.09% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 17420/20000] Loss: 0.0004029 (Best: 0.0001712 @iter7999) ([91m↑0.88%[0m) [0.09% of initial]
[Iter 17430/20000] Loss: 0.0004048 (Best: 0.0001712 @iter7999) ([91m↑0.47%[0m) [0.09% of initial]
[Iter 17440/20000] Loss: 0.0003960 (Best: 0.0001712 @iter7999) ([92m↓2.16%[0m) [0.09% of initial]
[Iter 17450/20000] Loss: 0.0003979 (Best: 0.0001712 @iter7999) ([91m↑0.47%[0m) [0.09% of initial]
[Iter 17460/20000] Loss: 0.0004078 (Best: 0.0001712 @iter7999) ([91m↑2.50%[0m) [0.09% of initial]
[Iter 17470/20000] Loss: 0.0003978 (Best: 0.0001712 @iter7999) ([92m↓2.45%[0m) [0.09% of initial]
[Iter 17480/20000] Loss: 0.0003961 (Best: 0.0001712 @iter7999) ([92m↓0.43%[0m) [0.09% of initial]
[Iter 17490/20000] Loss: 0.0003971 (Best: 0.0001712 @iter7999) ([91m↑0.26%[0m) [0.09% of initial]
Iter:17499, L1 loss=0.0003832, Total loss=0.000382, Time:18
[Iter 17500/20000] Loss: 0.0003873 (Best: 0.0001712 @iter7999) ([92m↓2.49%[0m) [0.08% of initial]
Pruning 14 points (0.4%) from gaussian0 at iteration 17500
Pruning 15 points (0.4%) from gaussian1 at iteration 17500
[Iter 17510/20000] Loss: 0.0013350 (Best: 0.0001712 @iter7999) ([91m↑244.72%[0m) [0.29% of initial]
[Iter 17520/20000] Loss: 0.0009077 (Best: 0.0001712 @iter7999) ([92m↓32.00%[0m) [0.20% of initial]
[Iter 17530/20000] Loss: 0.0007000 (Best: 0.0001712 @iter7999) ([92m↓22.89%[0m) [0.15% of initial]
[Iter 17540/20000] Loss: 0.0005939 (Best: 0.0001712 @iter7999) ([92m↓15.16%[0m) [0.13% of initial]
[Iter 17550/20000] Loss: 0.0005294 (Best: 0.0001712 @iter7999) ([92m↓10.86%[0m) [0.11% of initial]
[Iter 17560/20000] Loss: 0.0004914 (Best: 0.0001712 @iter7999) ([92m↓7.17%[0m) [0.11% of initial]
[Iter 17570/20000] Loss: 0.0004605 (Best: 0.0001712 @iter7999) ([92m↓6.29%[0m) [0.10% of initial]
[Iter 17580/20000] Loss: 0.0004418 (Best: 0.0001712 @iter7999) ([92m↓4.06%[0m) [0.10% of initial]
[Iter 17590/20000] Loss: 0.0004335 (Best: 0.0001712 @iter7999) ([92m↓1.88%[0m) [0.09% of initial]
Iter:17599, L1 loss=0.0004741, Total loss=0.0004341, Time:15
[Iter 17600/20000] Loss: 0.0004266 (Best: 0.0001712 @iter7999) ([92m↓1.60%[0m) [0.09% of initial]
[Iter 17610/20000] Loss: 0.0004230 (Best: 0.0001712 @iter7999) ([92m↓0.83%[0m) [0.09% of initial]
[Iter 17620/20000] Loss: 0.0004215 (Best: 0.0001712 @iter7999) ([92m↓0.36%[0m) [0.09% of initial]
[Iter 17630/20000] Loss: 0.0004103 (Best: 0.0001712 @iter7999) ([92m↓2.65%[0m) [0.09% of initial]
[Iter 17640/20000] Loss: 0.0004090 (Best: 0.0001712 @iter7999) ([92m↓0.32%[0m) [0.09% of initial]
[Iter 17650/20000] Loss: 0.0004057 (Best: 0.0001712 @iter7999) ([92m↓0.81%[0m) [0.09% of initial]
[Iter 17660/20000] Loss: 0.0004094 (Best: 0.0001712 @iter7999) ([91m↑0.91%[0m) [0.09% of initial]
[Iter 17670/20000] Loss: 0.0004051 (Best: 0.0001712 @iter7999) ([92m↓1.04%[0m) [0.09% of initial]
[Iter 17680/20000] Loss: 0.0004115 (Best: 0.0001712 @iter7999) ([91m↑1.59%[0m) [0.09% of initial]
[Iter 17690/20000] Loss: 0.0004092 (Best: 0.0001712 @iter7999) ([92m↓0.56%[0m) [0.09% of initial]
Iter:17699, L1 loss=0.0004081, Total loss=0.0003899, Time:15
[Iter 17700/20000] Loss: 0.0003993 (Best: 0.0001712 @iter7999) ([92m↓2.43%[0m) [0.09% of initial]
[Iter 17710/20000] Loss: 0.0004092 (Best: 0.0001712 @iter7999) ([91m↑2.48%[0m) [0.09% of initial]
[Iter 17720/20000] Loss: 0.0004055 (Best: 0.0001712 @iter7999) ([92m↓0.92%[0m) [0.09% of initial]
[Iter 17730/20000] Loss: 0.0004001 (Best: 0.0001712 @iter7999) ([92m↓1.32%[0m) [0.09% of initial]
[Iter 17740/20000] Loss: 0.0003905 (Best: 0.0001712 @iter7999) ([92m↓2.39%[0m) [0.08% of initial]
[Iter 17750/20000] Loss: 0.0003914 (Best: 0.0001712 @iter7999) ([91m↑0.23%[0m) [0.08% of initial]
[Iter 17760/20000] Loss: 0.0003932 (Best: 0.0001712 @iter7999) ([91m↑0.45%[0m) [0.09% of initial]
[Iter 17770/20000] Loss: 0.0003913 (Best: 0.0001712 @iter7999) ([92m↓0.50%[0m) [0.08% of initial]
[Iter 17780/20000] Loss: 0.0003982 (Best: 0.0001712 @iter7999) ([91m↑1.76%[0m) [0.09% of initial]
[Iter 17790/20000] Loss: 0.0004032 (Best: 0.0001712 @iter7999) ([91m↑1.26%[0m) [0.09% of initial]
Iter:17799, L1 loss=0.000421, Total loss=0.0004016, Time:15
[Iter 17800/20000] Loss: 0.0003957 (Best: 0.0001712 @iter7999) ([92m↓1.86%[0m) [0.09% of initial]
[Iter 17810/20000] Loss: 0.0003959 (Best: 0.0001712 @iter7999) ([91m↑0.05%[0m) [0.09% of initial]
[Iter 17820/20000] Loss: 0.0004001 (Best: 0.0001712 @iter7999) ([91m↑1.07%[0m) [0.09% of initial]
[Iter 17830/20000] Loss: 0.0003977 (Best: 0.0001712 @iter7999) ([92m↓0.59%[0m) [0.09% of initial]
[Iter 17840/20000] Loss: 0.0003970 (Best: 0.0001712 @iter7999) ([92m↓0.19%[0m) [0.09% of initial]
[Iter 17850/20000] Loss: 0.0003978 (Best: 0.0001712 @iter7999) ([91m↑0.20%[0m) [0.09% of initial]
[Iter 17860/20000] Loss: 0.0003921 (Best: 0.0001712 @iter7999) ([92m↓1.44%[0m) [0.09% of initial]
[Iter 17870/20000] Loss: 0.0003861 (Best: 0.0001712 @iter7999) ([92m↓1.51%[0m) [0.08% of initial]
[Iter 17880/20000] Loss: 0.0003926 (Best: 0.0001712 @iter7999) ([91m↑1.68%[0m) [0.09% of initial]
[Iter 17890/20000] Loss: 0.0003845 (Best: 0.0001712 @iter7999) ([92m↓2.07%[0m) [0.08% of initial]
Iter:17899, L1 loss=0.0003956, Total loss=0.0004023, Time:18
[Iter 17900/20000] Loss: 0.0003915 (Best: 0.0001712 @iter7999) ([91m↑1.82%[0m) [0.08% of initial]
[Iter 17910/20000] Loss: 0.0003930 (Best: 0.0001712 @iter7999) ([91m↑0.40%[0m) [0.09% of initial]
[Iter 17920/20000] Loss: 0.0004014 (Best: 0.0001712 @iter7999) ([91m↑2.12%[0m) [0.09% of initial]
[Iter 17930/20000] Loss: 0.0003972 (Best: 0.0001712 @iter7999) ([92m↓1.04%[0m) [0.09% of initial]
[Iter 17940/20000] Loss: 0.0003959 (Best: 0.0001712 @iter7999) ([92m↓0.34%[0m) [0.09% of initial]
[Iter 17950/20000] Loss: 0.0003879 (Best: 0.0001712 @iter7999) ([92m↓2.02%[0m) [0.08% of initial]
[Iter 17960/20000] Loss: 0.0003906 (Best: 0.0001712 @iter7999) ([91m↑0.70%[0m) [0.08% of initial]
[Iter 17970/20000] Loss: 0.0003936 (Best: 0.0001712 @iter7999) ([91m↑0.78%[0m) [0.09% of initial]
[Iter 17980/20000] Loss: 0.0003899 (Best: 0.0001712 @iter7999) ([92m↓0.96%[0m) [0.08% of initial]
[Iter 17990/20000] Loss: 0.0003938 (Best: 0.0001712 @iter7999) ([91m↑1.00%[0m) [0.09% of initial]
Iter:17999, L1 loss=0.0003901, Total loss=0.0003987, Time:13
[Iter 18000/20000] Loss: 0.0003848 (Best: 0.0001712 @iter7999) ([92m↓2.29%[0m) [0.08% of initial]
Pruning 15 points (0.4%) from gaussian0 at iteration 18000
Pruning 18 points (0.5%) from gaussian1 at iteration 18000
[Iter 18010/20000] Loss: 0.0010756 (Best: 0.0001712 @iter7999) ([91m↑179.56%[0m) [0.23% of initial]
[Iter 18020/20000] Loss: 0.0007247 (Best: 0.0001712 @iter7999) ([92m↓32.62%[0m) [0.16% of initial]
[Iter 18030/20000] Loss: 0.0005858 (Best: 0.0001712 @iter7999) ([92m↓19.17%[0m) [0.13% of initial]
[Iter 18040/20000] Loss: 0.0005232 (Best: 0.0001712 @iter7999) ([92m↓10.69%[0m) [0.11% of initial]
[Iter 18050/20000] Loss: 0.0004756 (Best: 0.0001712 @iter7999) ([92m↓9.09%[0m) [0.10% of initial]
[Iter 18060/20000] Loss: 0.0004655 (Best: 0.0001712 @iter7999) ([92m↓2.14%[0m) [0.10% of initial]
[Iter 18070/20000] Loss: 0.0004383 (Best: 0.0001712 @iter7999) ([92m↓5.85%[0m) [0.10% of initial]
[Iter 18080/20000] Loss: 0.0004452 (Best: 0.0001712 @iter7999) ([91m↑1.59%[0m) [0.10% of initial]
[Iter 18090/20000] Loss: 0.0004353 (Best: 0.0001712 @iter7999) ([92m↓2.24%[0m) [0.09% of initial]
Iter:18099, L1 loss=0.0003905, Total loss=0.000437, Time:17
[Iter 18100/20000] Loss: 0.0004366 (Best: 0.0001712 @iter7999) ([91m↑0.31%[0m) [0.09% of initial]
[Iter 18110/20000] Loss: 0.0004202 (Best: 0.0001712 @iter7999) ([92m↓3.77%[0m) [0.09% of initial]
[Iter 18120/20000] Loss: 0.0004240 (Best: 0.0001712 @iter7999) ([91m↑0.92%[0m) [0.09% of initial]
[Iter 18130/20000] Loss: 0.0004072 (Best: 0.0001712 @iter7999) ([92m↓3.97%[0m) [0.09% of initial]
[Iter 18140/20000] Loss: 0.0004217 (Best: 0.0001712 @iter7999) ([91m↑3.54%[0m) [0.09% of initial]
[Iter 18150/20000] Loss: 0.0004137 (Best: 0.0001712 @iter7999) ([92m↓1.89%[0m) [0.09% of initial]
[Iter 18160/20000] Loss: 0.0004013 (Best: 0.0001712 @iter7999) ([92m↓3.00%[0m) [0.09% of initial]
[Iter 18170/20000] Loss: 0.0004015 (Best: 0.0001712 @iter7999) ([91m↑0.05%[0m) [0.09% of initial]
[Iter 18180/20000] Loss: 0.0004057 (Best: 0.0001712 @iter7999) ([91m↑1.06%[0m) [0.09% of initial]
[Iter 18190/20000] Loss: 0.0004040 (Best: 0.0001712 @iter7999) ([92m↓0.42%[0m) [0.09% of initial]
Iter:18199, L1 loss=0.0003608, Total loss=0.0003788, Time:17
[Iter 18200/20000] Loss: 0.0004000 (Best: 0.0001712 @iter7999) ([92m↓0.99%[0m) [0.09% of initial]
[Iter 18210/20000] Loss: 0.0004031 (Best: 0.0001712 @iter7999) ([91m↑0.79%[0m) [0.09% of initial]
[Iter 18220/20000] Loss: 0.0003917 (Best: 0.0001712 @iter7999) ([92m↓2.85%[0m) [0.08% of initial]
[Iter 18230/20000] Loss: 0.0003950 (Best: 0.0001712 @iter7999) ([91m↑0.87%[0m) [0.09% of initial]
[Iter 18240/20000] Loss: 0.0003977 (Best: 0.0001712 @iter7999) ([91m↑0.68%[0m) [0.09% of initial]
[Iter 18250/20000] Loss: 0.0004035 (Best: 0.0001712 @iter7999) ([91m↑1.45%[0m) [0.09% of initial]
[Iter 18260/20000] Loss: 0.0003960 (Best: 0.0001712 @iter7999) ([92m↓1.86%[0m) [0.09% of initial]
[Iter 18270/20000] Loss: 0.0003884 (Best: 0.0001712 @iter7999) ([92m↓1.90%[0m) [0.08% of initial]
[Iter 18280/20000] Loss: 0.0003998 (Best: 0.0001712 @iter7999) ([91m↑2.93%[0m) [0.09% of initial]
[Iter 18290/20000] Loss: 0.0003819 (Best: 0.0001712 @iter7999) ([92m↓4.47%[0m) [0.08% of initial]
Iter:18299, L1 loss=0.0003753, Total loss=0.0003863, Time:18
[Iter 18300/20000] Loss: 0.0003932 (Best: 0.0001712 @iter7999) ([91m↑2.94%[0m) [0.09% of initial]
[Iter 18310/20000] Loss: 0.0003964 (Best: 0.0001712 @iter7999) ([91m↑0.82%[0m) [0.09% of initial]
[Iter 18320/20000] Loss: 0.0003842 (Best: 0.0001712 @iter7999) ([92m↓3.07%[0m) [0.08% of initial]
[Iter 18330/20000] Loss: 0.0003901 (Best: 0.0001712 @iter7999) ([91m↑1.52%[0m) [0.08% of initial]
[Iter 18340/20000] Loss: 0.0003964 (Best: 0.0001712 @iter7999) ([91m↑1.62%[0m) [0.09% of initial]
[Iter 18350/20000] Loss: 0.0003802 (Best: 0.0001712 @iter7999) ([92m↓4.08%[0m) [0.08% of initial]
[Iter 18360/20000] Loss: 0.0003822 (Best: 0.0001712 @iter7999) ([91m↑0.52%[0m) [0.08% of initial]
[Iter 18370/20000] Loss: 0.0003860 (Best: 0.0001712 @iter7999) ([91m↑1.01%[0m) [0.08% of initial]
[Iter 18380/20000] Loss: 0.0003805 (Best: 0.0001712 @iter7999) ([92m↓1.45%[0m) [0.08% of initial]
[Iter 18390/20000] Loss: 0.0003829 (Best: 0.0001712 @iter7999) ([91m↑0.64%[0m) [0.08% of initial]
Iter:18399, L1 loss=0.0003754, Total loss=0.0004006, Time:15
[Iter 18400/20000] Loss: 0.0003777 (Best: 0.0001712 @iter7999) ([92m↓1.36%[0m) [0.08% of initial]
[Iter 18410/20000] Loss: 0.0003871 (Best: 0.0001712 @iter7999) ([91m↑2.50%[0m) [0.08% of initial]
[Iter 18420/20000] Loss: 0.0003813 (Best: 0.0001712 @iter7999) ([92m↓1.51%[0m) [0.08% of initial]
[Iter 18430/20000] Loss: 0.0003728 (Best: 0.0001712 @iter7999) ([92m↓2.23%[0m) [0.08% of initial]
[Iter 18440/20000] Loss: 0.0003770 (Best: 0.0001712 @iter7999) ([91m↑1.14%[0m) [0.08% of initial]
[Iter 18450/20000] Loss: 0.0003734 (Best: 0.0001712 @iter7999) ([92m↓0.96%[0m) [0.08% of initial]
[Iter 18460/20000] Loss: 0.0003768 (Best: 0.0001712 @iter7999) ([91m↑0.90%[0m) [0.08% of initial]
[Iter 18470/20000] Loss: 0.0003829 (Best: 0.0001712 @iter7999) ([91m↑1.64%[0m) [0.08% of initial]
[Iter 18480/20000] Loss: 0.0003731 (Best: 0.0001712 @iter7999) ([92m↓2.58%[0m) [0.08% of initial]
[Iter 18490/20000] Loss: 0.0003707 (Best: 0.0001712 @iter7999) ([92m↓0.63%[0m) [0.08% of initial]
Iter:18499, L1 loss=0.0003678, Total loss=0.0003708, Time:17
[Iter 18500/20000] Loss: 0.0003716 (Best: 0.0001712 @iter7999) ([91m↑0.25%[0m) [0.08% of initial]
Pruning 14 points (0.4%) from gaussian0 at iteration 18500
Pruning 15 points (0.4%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0015870 (Best: 0.0001712 @iter7999) ([91m↑327.03%[0m) [0.34% of initial]
[Iter 18520/20000] Loss: 0.0011296 (Best: 0.0001712 @iter7999) ([92m↓28.82%[0m) [0.25% of initial]
[Iter 18530/20000] Loss: 0.0008583 (Best: 0.0001712 @iter7999) ([92m↓24.02%[0m) [0.19% of initial]
[Iter 18540/20000] Loss: 0.0006850 (Best: 0.0001712 @iter7999) ([92m↓20.19%[0m) [0.15% of initial]
[Iter 18550/20000] Loss: 0.0005716 (Best: 0.0001712 @iter7999) ([92m↓16.55%[0m) [0.12% of initial]
[Iter 18560/20000] Loss: 0.0005165 (Best: 0.0001712 @iter7999) ([92m↓9.65%[0m) [0.11% of initial]
[Iter 18570/20000] Loss: 0.0004882 (Best: 0.0001712 @iter7999) ([92m↓5.48%[0m) [0.11% of initial]
[Iter 18580/20000] Loss: 0.0004700 (Best: 0.0001712 @iter7999) ([92m↓3.72%[0m) [0.10% of initial]
[Iter 18590/20000] Loss: 0.0004420 (Best: 0.0001712 @iter7999) ([92m↓5.97%[0m) [0.10% of initial]
Iter:18599, L1 loss=0.0003704, Total loss=0.0004109, Time:13
[Iter 18600/20000] Loss: 0.0004372 (Best: 0.0001712 @iter7999) ([92m↓1.08%[0m) [0.09% of initial]
[Iter 18610/20000] Loss: 0.0004302 (Best: 0.0001712 @iter7999) ([92m↓1.61%[0m) [0.09% of initial]
[Iter 18620/20000] Loss: 0.0004220 (Best: 0.0001712 @iter7999) ([92m↓1.92%[0m) [0.09% of initial]
[Iter 18630/20000] Loss: 0.0004156 (Best: 0.0001712 @iter7999) ([92m↓1.51%[0m) [0.09% of initial]
[Iter 18640/20000] Loss: 0.0004062 (Best: 0.0001712 @iter7999) ([92m↓2.26%[0m) [0.09% of initial]
[Iter 18650/20000] Loss: 0.0004034 (Best: 0.0001712 @iter7999) ([92m↓0.69%[0m) [0.09% of initial]
[Iter 18660/20000] Loss: 0.0003984 (Best: 0.0001712 @iter7999) ([92m↓1.24%[0m) [0.09% of initial]
[Iter 18670/20000] Loss: 0.0003912 (Best: 0.0001712 @iter7999) ([92m↓1.80%[0m) [0.08% of initial]
[Iter 18680/20000] Loss: 0.0003914 (Best: 0.0001712 @iter7999) ([91m↑0.04%[0m) [0.08% of initial]
[Iter 18690/20000] Loss: 0.0003966 (Best: 0.0001712 @iter7999) ([91m↑1.34%[0m) [0.09% of initial]
Iter:18699, L1 loss=0.0003802, Total loss=0.0004083, Time:17
[Iter 18700/20000] Loss: 0.0003998 (Best: 0.0001712 @iter7999) ([91m↑0.81%[0m) [0.09% of initial]
[Iter 18710/20000] Loss: 0.0003877 (Best: 0.0001712 @iter7999) ([92m↓3.04%[0m) [0.08% of initial]
[Iter 18720/20000] Loss: 0.0003849 (Best: 0.0001712 @iter7999) ([92m↓0.72%[0m) [0.08% of initial]
[Iter 18730/20000] Loss: 0.0003882 (Best: 0.0001712 @iter7999) ([91m↑0.87%[0m) [0.08% of initial]
[Iter 18740/20000] Loss: 0.0003911 (Best: 0.0001712 @iter7999) ([91m↑0.73%[0m) [0.08% of initial]
[Iter 18750/20000] Loss: 0.0003814 (Best: 0.0001712 @iter7999) ([92m↓2.46%[0m) [0.08% of initial]
[Iter 18760/20000] Loss: 0.0003873 (Best: 0.0001712 @iter7999) ([91m↑1.54%[0m) [0.08% of initial]
[Iter 18770/20000] Loss: 0.0003817 (Best: 0.0001712 @iter7999) ([92m↓1.43%[0m) [0.08% of initial]
[Iter 18780/20000] Loss: 0.0003844 (Best: 0.0001712 @iter7999) ([91m↑0.70%[0m) [0.08% of initial]
[Iter 18790/20000] Loss: 0.0003842 (Best: 0.0001712 @iter7999) ([92m↓0.06%[0m) [0.08% of initial]
Iter:18799, L1 loss=0.0003727, Total loss=0.0003869, Time:17
[Iter 18800/20000] Loss: 0.0003850 (Best: 0.0001712 @iter7999) ([91m↑0.22%[0m) [0.08% of initial]
[Iter 18810/20000] Loss: 0.0003824 (Best: 0.0001712 @iter7999) ([92m↓0.68%[0m) [0.08% of initial]
[Iter 18820/20000] Loss: 0.0003720 (Best: 0.0001712 @iter7999) ([92m↓2.71%[0m) [0.08% of initial]
[Iter 18830/20000] Loss: 0.0003774 (Best: 0.0001712 @iter7999) ([91m↑1.44%[0m) [0.08% of initial]
[Iter 18840/20000] Loss: 0.0003781 (Best: 0.0001712 @iter7999) ([91m↑0.18%[0m) [0.08% of initial]
[Iter 18850/20000] Loss: 0.0003714 (Best: 0.0001712 @iter7999) ([92m↓1.77%[0m) [0.08% of initial]
[Iter 18860/20000] Loss: 0.0003787 (Best: 0.0001712 @iter7999) ([91m↑1.96%[0m) [0.08% of initial]
[Iter 18870/20000] Loss: 0.0003731 (Best: 0.0001712 @iter7999) ([92m↓1.47%[0m) [0.08% of initial]
[Iter 18880/20000] Loss: 0.0003750 (Best: 0.0001712 @iter7999) ([91m↑0.51%[0m) [0.08% of initial]
[Iter 18890/20000] Loss: 0.0003782 (Best: 0.0001712 @iter7999) ([91m↑0.86%[0m) [0.08% of initial]
Iter:18899, L1 loss=0.0003732, Total loss=0.0003838, Time:17
[Iter 18900/20000] Loss: 0.0003719 (Best: 0.0001712 @iter7999) ([92m↓1.68%[0m) [0.08% of initial]
[Iter 18910/20000] Loss: 0.0003730 (Best: 0.0001712 @iter7999) ([91m↑0.31%[0m) [0.08% of initial]
[Iter 18920/20000] Loss: 0.0003720 (Best: 0.0001712 @iter7999) ([92m↓0.26%[0m) [0.08% of initial]
[Iter 18930/20000] Loss: 0.0003776 (Best: 0.0001712 @iter7999) ([91m↑1.49%[0m) [0.08% of initial]
[Iter 18940/20000] Loss: 0.0003838 (Best: 0.0001712 @iter7999) ([91m↑1.65%[0m) [0.08% of initial]
[Iter 18950/20000] Loss: 0.0003761 (Best: 0.0001712 @iter7999) ([92m↓2.00%[0m) [0.08% of initial]
[Iter 18960/20000] Loss: 0.0003735 (Best: 0.0001712 @iter7999) ([92m↓0.69%[0m) [0.08% of initial]
[Iter 18970/20000] Loss: 0.0003722 (Best: 0.0001712 @iter7999) ([92m↓0.35%[0m) [0.08% of initial]
[Iter 18980/20000] Loss: 0.0003689 (Best: 0.0001712 @iter7999) ([92m↓0.89%[0m) [0.08% of initial]
[Iter 18990/20000] Loss: 0.0003664 (Best: 0.0001712 @iter7999) ([92m↓0.68%[0m) [0.08% of initial]
Iter:18999, L1 loss=0.0003687, Total loss=0.0003774, Time:17
[Iter 19000/20000] Loss: 0.0003640 (Best: 0.0001712 @iter7999) ([92m↓0.66%[0m) [0.08% of initial]
Pruning 15 points (0.4%) from gaussian0 at iteration 19000
Pruning 20 points (0.6%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0029598 (Best: 0.0001712 @iter7999) ([91m↑713.25%[0m) [0.64% of initial]
[Iter 19020/20000] Loss: 0.0018491 (Best: 0.0001712 @iter7999) ([92m↓37.53%[0m) [0.40% of initial]
[Iter 19030/20000] Loss: 0.0012457 (Best: 0.0001712 @iter7999) ([92m↓32.63%[0m) [0.27% of initial]
[Iter 19040/20000] Loss: 0.0009228 (Best: 0.0001712 @iter7999) ([92m↓25.92%[0m) [0.20% of initial]
[Iter 19050/20000] Loss: 0.0007643 (Best: 0.0001712 @iter7999) ([92m↓17.18%[0m) [0.17% of initial]
[Iter 19060/20000] Loss: 0.0006700 (Best: 0.0001712 @iter7999) ([92m↓12.34%[0m) [0.15% of initial]
[Iter 19070/20000] Loss: 0.0006230 (Best: 0.0001712 @iter7999) ([92m↓7.02%[0m) [0.14% of initial]
[Iter 19080/20000] Loss: 0.0005933 (Best: 0.0001712 @iter7999) ([92m↓4.77%[0m) [0.13% of initial]
[Iter 19090/20000] Loss: 0.0005629 (Best: 0.0001712 @iter7999) ([92m↓5.12%[0m) [0.12% of initial]
Iter:19099, L1 loss=0.0005593, Total loss=0.0005357, Time:19
[Iter 19100/20000] Loss: 0.0005400 (Best: 0.0001712 @iter7999) ([92m↓4.07%[0m) [0.12% of initial]
[Iter 19110/20000] Loss: 0.0005346 (Best: 0.0001712 @iter7999) ([92m↓1.00%[0m) [0.12% of initial]
[Iter 19120/20000] Loss: 0.0005095 (Best: 0.0001712 @iter7999) ([92m↓4.69%[0m) [0.11% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 19130/20000] Loss: 0.0004929 (Best: 0.0001712 @iter7999) ([92m↓3.27%[0m) [0.11% of initial]
[Iter 19140/20000] Loss: 0.0004905 (Best: 0.0001712 @iter7999) ([92m↓0.47%[0m) [0.11% of initial]
[Iter 19150/20000] Loss: 0.0004881 (Best: 0.0001712 @iter7999) ([92m↓0.49%[0m) [0.11% of initial]
[Iter 19160/20000] Loss: 0.0004721 (Best: 0.0001712 @iter7999) ([92m↓3.29%[0m) [0.10% of initial]
[Iter 19170/20000] Loss: 0.0004633 (Best: 0.0001712 @iter7999) ([92m↓1.86%[0m) [0.10% of initial]
[Iter 19180/20000] Loss: 0.0004548 (Best: 0.0001712 @iter7999) ([92m↓1.85%[0m) [0.10% of initial]
[Iter 19190/20000] Loss: 0.0004451 (Best: 0.0001712 @iter7999) ([92m↓2.13%[0m) [0.10% of initial]
Iter:19199, L1 loss=0.0004458, Total loss=0.0004558, Time:17
[Iter 19200/20000] Loss: 0.0004443 (Best: 0.0001712 @iter7999) ([92m↓0.18%[0m) [0.10% of initial]
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 19210/20000] Loss: 0.0004342 (Best: 0.0001712 @iter7999) ([92m↓2.28%[0m) [0.09% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 19220/20000] Loss: 0.0004357 (Best: 0.0001712 @iter7999) ([91m↑0.34%[0m) [0.09% of initial]
[Iter 19230/20000] Loss: 0.0004296 (Best: 0.0001712 @iter7999) ([92m↓1.40%[0m) [0.09% of initial]
[Iter 30/20000] Loss: 0.1374905 (Best: 0.1327876 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 19240/20000] Loss: 0.0004214 (Best: 0.0001712 @iter7999) ([92m↓1.91%[0m) [0.09% of initial]
[Iter 19250/20000] Loss: 0.0004218 (Best: 0.0001712 @iter7999) ([91m↑0.11%[0m) [0.09% of initial]
[Iter 40/20000] Loss: 0.1123914 (Best: 0.1098367 @iter40) ([92m↓18.26%[0m) [44.65% of initial]
[Iter 19260/20000] Loss: 0.0004201 (Best: 0.0001712 @iter7999) ([92m↓0.41%[0m) [0.09% of initial]
[Iter 19270/20000] Loss: 0.0004132 (Best: 0.0001712 @iter7999) ([92m↓1.63%[0m) [0.09% of initial]
[Iter 50/20000] Loss: 0.0993452 (Best: 0.0965430 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 19280/20000] Loss: 0.0004110 (Best: 0.0001712 @iter7999) ([92m↓0.54%[0m) [0.09% of initial]
[Iter 60/20000] Loss: 0.0936732 (Best: 0.0908516 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 19290/20000] Loss: 0.0004106 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.09% of initial]
Iter:19299, L1 loss=0.0004153, Total loss=0.0004072, Time:17
[Iter 19300/20000] Loss: 0.0004029 (Best: 0.0001712 @iter7999) ([92m↓1.86%[0m) [0.09% of initial]
[Iter 70/20000] Loss: 0.0884455 (Best: 0.0869358 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 19310/20000] Loss: 0.0004104 (Best: 0.0001712 @iter7999) ([91m↑1.85%[0m) [0.09% of initial]
[Iter 80/20000] Loss: 0.0851792 (Best: 0.0830906 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 19320/20000] Loss: 0.0004094 (Best: 0.0001712 @iter7999) ([92m↓0.23%[0m) [0.09% of initial]
[Iter 90/20000] Loss: 0.0824216 (Best: 0.0801581 @iter88) ([92m↓3.24%[0m) [32.75% of initial]
[Iter 19330/20000] Loss: 0.0004311 (Best: 0.0001712 @iter7999) ([91m↑5.28%[0m) [0.09% of initial]
[Iter 19340/20000] Loss: 0.0004741 (Best: 0.0001712 @iter7999) ([91m↑9.98%[0m) [0.10% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:16
[Iter 100/20000] Loss: 0.0786656 (Best: 0.0766216 @iter97) ([92m↓4.56%[0m) [31.25% of initial]
[Iter 19350/20000] Loss: 0.0004215 (Best: 0.0001712 @iter7999) ([92m↓11.10%[0m) [0.09% of initial]
[Iter 110/20000] Loss: 0.0753289 (Best: 0.0731431 @iter106) ([92m↓4.24%[0m) [29.93% of initial]
[Iter 19360/20000] Loss: 0.0003976 (Best: 0.0001712 @iter7999) ([92m↓5.66%[0m) [0.09% of initial]
[Iter 120/20000] Loss: 0.0714293 (Best: 0.0685629 @iter118) ([92m↓5.18%[0m) [28.38% of initial]
[Iter 19370/20000] Loss: 0.0004056 (Best: 0.0001712 @iter7999) ([91m↑2.00%[0m) [0.09% of initial]
[Iter 19380/20000] Loss: 0.0003949 (Best: 0.0001712 @iter7999) ([92m↓2.63%[0m) [0.09% of initial]
[Iter 130/20000] Loss: 0.0666889 (Best: 0.0641955 @iter130) ([92m↓6.64%[0m) [26.49% of initial]
[Iter 19390/20000] Loss: 0.0004005 (Best: 0.0001712 @iter7999) ([91m↑1.42%[0m) [0.09% of initial]
Iter:19399, L1 loss=0.0003899, Total loss=0.0003889, Time:14
[Iter 140/20000] Loss: 0.0635230 (Best: 0.0612699 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 19400/20000] Loss: 0.0003993 (Best: 0.0001712 @iter7999) ([92m↓0.29%[0m) [0.09% of initial]
[Iter 19410/20000] Loss: 0.0003892 (Best: 0.0001712 @iter7999) ([92m↓2.53%[0m) [0.08% of initial]
[Iter 150/20000] Loss: 0.0612524 (Best: 0.0583646 @iter148) ([92m↓3.57%[0m) [24.33% of initial]
[Iter 19420/20000] Loss: 0.0003909 (Best: 0.0001712 @iter7999) ([91m↑0.45%[0m) [0.08% of initial]
[Iter 19430/20000] Loss: 0.0003781 (Best: 0.0001712 @iter7999) ([92m↓3.28%[0m) [0.08% of initial]
[Iter 160/20000] Loss: 0.0590533 (Best: 0.0559307 @iter157) ([92m↓3.59%[0m) [23.46% of initial]
[Iter 19440/20000] Loss: 0.0003845 (Best: 0.0001712 @iter7999) ([91m↑1.69%[0m) [0.08% of initial]
[Iter 170/20000] Loss: 0.0563335 (Best: 0.0534600 @iter167) ([92m↓4.61%[0m) [22.38% of initial]
[Iter 19450/20000] Loss: 0.0003918 (Best: 0.0001712 @iter7999) ([91m↑1.90%[0m) [0.08% of initial]
[Iter 19460/20000] Loss: 0.0003773 (Best: 0.0001712 @iter7999) ([92m↓3.70%[0m) [0.08% of initial]
[Iter 180/20000] Loss: 0.0523341 (Best: 0.0500195 @iter179) ([92m↓7.10%[0m) [20.79% of initial]
[Iter 19470/20000] Loss: 0.0003825 (Best: 0.0001712 @iter7999) ([91m↑1.38%[0m) [0.08% of initial]
[Iter 190/20000] Loss: 0.0495346 (Best: 0.0477952 @iter188) ([92m↓5.35%[0m) [19.68% of initial]
[Iter 19480/20000] Loss: 0.0003832 (Best: 0.0001712 @iter7999) ([91m↑0.19%[0m) [0.08% of initial]
[Iter 19490/20000] Loss: 0.0003800 (Best: 0.0001712 @iter7999) ([92m↓0.84%[0m) [0.08% of initial]
Iter:199, L1 loss=0.03442, Total loss=0.04973, Time:19
[Iter 200/20000] Loss: 0.0478038 (Best: 0.0456611 @iter198) ([92m↓3.49%[0m) [18.99% of initial]
Iter:19499, L1 loss=0.0003849, Total loss=0.0003883, Time:18
[Iter 19500/20000] Loss: 0.0003861 (Best: 0.0001712 @iter7999) ([91m↑1.60%[0m) [0.08% of initial]
Pruning 7 points (0.2%) from gaussian0 at iteration 19500
Pruning 2 points (0.1%) from gaussian1 at iteration 19500
[Iter 210/20000] Loss: 0.0451399 (Best: 0.0428880 @iter209) ([92m↓5.57%[0m) [17.93% of initial]
[Iter 19510/20000] Loss: 0.0004030 (Best: 0.0001712 @iter7999) ([91m↑4.38%[0m) [0.09% of initial]
[Iter 19520/20000] Loss: 0.0003855 (Best: 0.0001712 @iter7999) ([92m↓4.35%[0m) [0.08% of initial]
[Iter 220/20000] Loss: 0.0440799 (Best: 0.0412129 @iter219) ([92m↓2.35%[0m) [17.51% of initial]
[Iter 19530/20000] Loss: 0.0003858 (Best: 0.0001712 @iter7999) ([91m↑0.08%[0m) [0.08% of initial]
[Iter 230/20000] Loss: 0.0423869 (Best: 0.0398883 @iter227) ([92m↓3.84%[0m) [16.84% of initial]
[Iter 19540/20000] Loss: 0.0003721 (Best: 0.0001712 @iter7999) ([92m↓3.54%[0m) [0.08% of initial]
[Iter 19550/20000] Loss: 0.0003740 (Best: 0.0001712 @iter7999) ([91m↑0.53%[0m) [0.08% of initial]
[Iter 240/20000] Loss: 0.0402915 (Best: 0.0378717 @iter238) ([92m↓4.94%[0m) [16.01% of initial]
[Iter 19560/20000] Loss: 0.0004470 (Best: 0.0001712 @iter7999) ([91m↑19.51%[0m) [0.10% of initial]
[Iter 19570/20000] Loss: 0.0003977 (Best: 0.0001712 @iter7999) ([92m↓11.04%[0m) [0.09% of initial]
[Iter 250/20000] Loss: 0.0380632 (Best: 0.0364109 @iter248) ([92m↓5.53%[0m) [15.12% of initial]
[Iter 19580/20000] Loss: 0.0004273 (Best: 0.0001712 @iter7999) ([91m↑7.45%[0m) [0.09% of initial]
[Iter 260/20000] Loss: 0.0359751 (Best: 0.0344586 @iter260) ([92m↓5.49%[0m) [14.29% of initial]
[Iter 19590/20000] Loss: 0.0003981 (Best: 0.0001712 @iter7999) ([92m↓6.82%[0m) [0.09% of initial]
Iter:19599, L1 loss=0.0003764, Total loss=0.0003859, Time:19
[Iter 19600/20000] Loss: 0.0003823 (Best: 0.0001712 @iter7999) ([92m↓3.98%[0m) [0.08% of initial]
[Iter 270/20000] Loss: 0.0351519 (Best: 0.0331034 @iter269) ([92m↓2.29%[0m) [13.97% of initial]
[Iter 19610/20000] Loss: 0.0003727 (Best: 0.0001712 @iter7999) ([92m↓2.50%[0m) [0.08% of initial]
[Iter 280/20000] Loss: 0.0347172 (Best: 0.0319839 @iter277) ([92m↓1.24%[0m) [13.79% of initial]
[Iter 19620/20000] Loss: 0.0003753 (Best: 0.0001712 @iter7999) ([91m↑0.69%[0m) [0.08% of initial]
[Iter 19630/20000] Loss: 0.0003754 (Best: 0.0001712 @iter7999) ([91m↑0.02%[0m) [0.08% of initial]
[Iter 290/20000] Loss: 0.0330263 (Best: 0.0304968 @iter287) ([92m↓4.87%[0m) [13.12% of initial]
[Iter 19640/20000] Loss: 0.0003670 (Best: 0.0001712 @iter7999) ([92m↓2.23%[0m) [0.08% of initial]
Iter:299, L1 loss=0.0221, Total loss=0.03331, Time:19
[Iter 300/20000] Loss: 0.0307449 (Best: 0.0289559 @iter300) ([92m↓6.91%[0m) [12.21% of initial]
[Iter 19650/20000] Loss: 0.0003659 (Best: 0.0001712 @iter7999) ([92m↓0.32%[0m) [0.08% of initial]
[Iter 19660/20000] Loss: 0.0003572 (Best: 0.0001712 @iter7999) ([92m↓2.38%[0m) [0.08% of initial]
[Iter 310/20000] Loss: 0.0293434 (Best: 0.0273799 @iter310) ([92m↓4.56%[0m) [11.66% of initial]
[Iter 19670/20000] Loss: 0.0003639 (Best: 0.0001712 @iter7999) ([91m↑1.90%[0m) [0.08% of initial]
[Iter 19680/20000] Loss: 0.0003619 (Best: 0.0001712 @iter7999) ([92m↓0.55%[0m) [0.08% of initial]
[Iter 320/20000] Loss: 0.0278456 (Best: 0.0264366 @iter320) ([92m↓5.10%[0m) [11.06% of initial]
[Iter 19690/20000] Loss: 0.0003566 (Best: 0.0001712 @iter7999) ([92m↓1.47%[0m) [0.08% of initial]
[Iter 330/20000] Loss: 0.0274419 (Best: 0.0255479 @iter330) ([92m↓1.45%[0m) [10.90% of initial]
Iter:19699, L1 loss=0.0003639, Total loss=0.0003712, Time:17
[Iter 19700/20000] Loss: 0.0003605 (Best: 0.0001712 @iter7999) ([91m↑1.09%[0m) [0.08% of initial]
[Iter 19710/20000] Loss: 0.0003617 (Best: 0.0001712 @iter7999) ([91m↑0.33%[0m) [0.08% of initial]
[Iter 340/20000] Loss: 0.0252749 (Best: 0.0241661 @iter340) ([92m↓7.90%[0m) [10.04% of initial]
[Iter 19720/20000] Loss: 0.0003508 (Best: 0.0001712 @iter7999) ([92m↓3.02%[0m) [0.08% of initial]
[Iter 350/20000] Loss: 0.0257881 (Best: 0.0232315 @iter349) ([91m↑2.03%[0m) [10.25% of initial]
[Iter 19730/20000] Loss: 0.0003604 (Best: 0.0001712 @iter7999) ([91m↑2.76%[0m) [0.08% of initial]
[Iter 19740/20000] Loss: 0.0003570 (Best: 0.0001712 @iter7999) ([92m↓0.95%[0m) [0.08% of initial]
[Iter 360/20000] Loss: 0.0242684 (Best: 0.0223686 @iter358) ([92m↓5.89%[0m) [9.64% of initial]
[Iter 19750/20000] Loss: 0.0003601 (Best: 0.0001712 @iter7999) ([91m↑0.86%[0m) [0.08% of initial]
[Iter 19760/20000] Loss: 0.0003687 (Best: 0.0001712 @iter7999) ([91m↑2.38%[0m) [0.08% of initial]
[Iter 370/20000] Loss: 0.0239548 (Best: 0.0217048 @iter368) ([92m↓1.29%[0m) [9.52% of initial]
[Iter 19770/20000] Loss: 0.0004003 (Best: 0.0001712 @iter7999) ([91m↑8.58%[0m) [0.09% of initial]
[Iter 380/20000] Loss: 0.0218852 (Best: 0.0208641 @iter379) ([92m↓8.64%[0m) [8.69% of initial]
[Iter 19780/20000] Loss: 0.0004189 (Best: 0.0001712 @iter7999) ([91m↑4.63%[0m) [0.09% of initial]
[Iter 19790/20000] Loss: 0.0003708 (Best: 0.0001712 @iter7999) ([92m↓11.48%[0m) [0.08% of initial]
[Iter 390/20000] Loss: 0.0214817 (Best: 0.0201063 @iter385) ([92m↓1.84%[0m) [8.53% of initial]
Iter:19799, L1 loss=0.0003589, Total loss=0.0003866, Time:15
[Iter 19800/20000] Loss: 0.0003740 (Best: 0.0001712 @iter7999) ([91m↑0.88%[0m) [0.08% of initial]
Iter:399, L1 loss=0.01359, Total loss=0.02118, Time:14
[Iter 400/20000] Loss: 0.0203946 (Best: 0.0189470 @iter400) ([92m↓5.06%[0m) [8.10% of initial]
[Iter 19810/20000] Loss: 0.0003619 (Best: 0.0001712 @iter7999) ([92m↓3.26%[0m) [0.08% of initial]
[Iter 19820/20000] Loss: 0.0003638 (Best: 0.0001712 @iter7999) ([91m↑0.55%[0m) [0.08% of initial]
[Iter 410/20000] Loss: 0.0197070 (Best: 0.0187694 @iter407) ([92m↓3.37%[0m) [7.83% of initial]
[Iter 19830/20000] Loss: 0.0003648 (Best: 0.0001712 @iter7999) ([91m↑0.26%[0m) [0.08% of initial]
[Iter 19840/20000] Loss: 0.0003712 (Best: 0.0001712 @iter7999) ([91m↑1.75%[0m) [0.08% of initial]
[Iter 420/20000] Loss: 0.0200950 (Best: 0.0181673 @iter418) ([91m↑1.97%[0m) [7.98% of initial]
[Iter 19850/20000] Loss: 0.0003708 (Best: 0.0001712 @iter7999) ([92m↓0.10%[0m) [0.08% of initial]
[Iter 430/20000] Loss: 0.0180819 (Best: 0.0172190 @iter430) ([92m↓10.02%[0m) [7.18% of initial]
[Iter 19860/20000] Loss: 0.0003752 (Best: 0.0001712 @iter7999) ([91m↑1.19%[0m) [0.08% of initial]
[Iter 19870/20000] Loss: 0.0003725 (Best: 0.0001712 @iter7999) ([92m↓0.73%[0m) [0.08% of initial]
[Iter 440/20000] Loss: 0.0182919 (Best: 0.0166726 @iter438) ([91m↑1.16%[0m) [7.27% of initial]
[Iter 19880/20000] Loss: 0.0003611 (Best: 0.0001712 @iter7999) ([92m↓3.06%[0m) [0.08% of initial]
[Iter 450/20000] Loss: 0.0172819 (Best: 0.0154390 @iter449) ([92m↓5.52%[0m) [6.87% of initial]
[Iter 19890/20000] Loss: 0.0003632 (Best: 0.0001712 @iter7999) ([91m↑0.60%[0m) [0.08% of initial]
Iter:19899, L1 loss=0.0003594, Total loss=0.0003649, Time:18
[Iter 19900/20000] Loss: 0.0003593 (Best: 0.0001712 @iter7999) ([92m↓1.09%[0m) [0.08% of initial]
[Iter 460/20000] Loss: 0.0166196 (Best: 0.0148971 @iter458) ([92m↓3.83%[0m) [6.60% of initial]
[Iter 19910/20000] Loss: 0.0003526 (Best: 0.0001712 @iter7999) ([92m↓1.87%[0m) [0.08% of initial]
[Iter 470/20000] Loss: 0.0149896 (Best: 0.0140625 @iter470) ([92m↓9.81%[0m) [5.96% of initial]
[Iter 19920/20000] Loss: 0.0003514 (Best: 0.0001712 @iter7999) ([92m↓0.33%[0m) [0.08% of initial]
[Iter 19930/20000] Loss: 0.0003555 (Best: 0.0001712 @iter7999) ([91m↑1.17%[0m) [0.08% of initial]
[Iter 480/20000] Loss: 0.0153833 (Best: 0.0137404 @iter475) ([91m↑2.63%[0m) [6.11% of initial]
[Iter 19940/20000] Loss: 0.0003493 (Best: 0.0001712 @iter7999) ([92m↓1.75%[0m) [0.08% of initial]
[Iter 490/20000] Loss: 0.0139825 (Best: 0.0128139 @iter490) ([92m↓9.11%[0m) [5.56% of initial]
[Iter 19950/20000] Loss: 0.0003449 (Best: 0.0001712 @iter7999) ([92m↓1.24%[0m) [0.07% of initial]
[Iter 19960/20000] Loss: 0.0003440 (Best: 0.0001712 @iter7999) ([92m↓0.27%[0m) [0.07% of initial]
Iter:499, L1 loss=0.008458, Total loss=0.01482, Time:19
[Iter 500/20000] Loss: 0.0139350 (Best: 0.0126335 @iter498) ([92m↓0.34%[0m) [5.54% of initial]
[Iter 19970/20000] Loss: 0.0003540 (Best: 0.0001712 @iter7999) ([91m↑2.93%[0m) [0.08% of initial]
[Iter 510/20000] Loss: 0.0141897 (Best: 0.0122285 @iter503) ([91m↑1.83%[0m) [5.64% of initial]
[Iter 19980/20000] Loss: 0.0003484 (Best: 0.0001712 @iter7999) ([92m↓1.60%[0m) [0.08% of initial]
[Iter 520/20000] Loss: 0.0133197 (Best: 0.0122285 @iter503) ([92m↓6.13%[0m) [5.29% of initial]
[Iter 19990/20000] Loss: 0.0003401 (Best: 0.0001712 @iter7999) ([92m↓2.38%[0m) [0.07% of initial]
Iter:19999, L1 loss=0.000346, Total loss=0.0003386, Time:18
[Iter 20000/20000] Loss: 0.0003373 (Best: 0.0001712 @iter7999) ([92m↓0.83%[0m) [0.07% of initial]
[Iter 530/20000] Loss: 0.0126927 (Best: 0.0115205 @iter529) ([92m↓4.71%[0m) [5.04% of initial]
Testing Speed: 137.3512708820037 fps
Testing Time: 0.364030122756958 s

[ITER 20000] Evaluating test: SSIM = 0.5837986648082734, PSNR = 8.413148832321166
Testing Speed: 136.3676088087394 fps
Testing Time: 0.021999359130859375 s

[ITER 20000] Evaluating train: SSIM = 0.5382476647694905, PSNR = 7.631223042805989
Iter:20000, total_points:3549

[ITER 20000] Saving Gaussians
Pruning 10 points (0.3%) from gaussian0 at iteration 20000
Pruning 11 points (0.3%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 137 fps
Total time: 14.92 minutes
Test SSIM: 0.5838
Test PSNR: 8.413
Gaussian0 final points count: 3539
Gaussian1 final points count: 3409
Final loss: 0.0003373 (0.07% of initial)
Save path: 2024_11_26_15_32_20
Initial loss: 0.4609871
Best loss: 0.0001712 @iteration 7999 (0.04% of initial)
Train SSIM: 0.5382
Train PSNR: 7.631
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
[Iter 540/20000] Loss: 0.0128086 (Best: 0.0112436 @iter538) ([91m↑0.91%[0m) [5.09% of initial]
[Iter 550/20000] Loss: 0.0124826 (Best: 0.0112436 @iter538) ([92m↓2.55%[0m) [4.96% of initial]
[Iter 560/20000] Loss: 0.0121896 (Best: 0.0108005 @iter556) ([92m↓2.35%[0m) [4.84% of initial]
[Iter 570/20000] Loss: 0.0118519 (Best: 0.0106802 @iter569) ([92m↓2.77%[0m) [4.71% of initial]
[Iter 580/20000] Loss: 0.0113507 (Best: 0.0103199 @iter578) ([92m↓4.23%[0m) [4.51% of initial]
[Iter 590/20000] Loss: 0.0113892 (Best: 0.0101645 @iter583) ([91m↑0.34%[0m) [4.52% of initial]
Iter:599, L1 loss=0.006957, Total loss=0.01211, Time:17
[Iter 600/20000] Loss: 0.0111770 (Best: 0.0099830 @iter598) ([92m↓1.86%[0m) [4.44% of initial]
[Iter 610/20000] Loss: 0.0248096 (Best: 0.0099830 @iter598) ([91m↑121.97%[0m) [9.86% of initial]
[Iter 620/20000] Loss: 0.0151680 (Best: 0.0099830 @iter598) ([92m↓38.86%[0m) [6.03% of initial]
[Iter 630/20000] Loss: 0.0124847 (Best: 0.0099830 @iter598) ([92m↓17.69%[0m) [4.96% of initial]
[Iter 640/20000] Loss: 0.0104859 (Best: 0.0096538 @iter640) ([92m↓16.01%[0m) [4.17% of initial]
[Iter 650/20000] Loss: 0.0105898 (Best: 0.0093557 @iter646) ([91m↑0.99%[0m) [4.21% of initial]
[Iter 660/20000] Loss: 0.0100467 (Best: 0.0089309 @iter655) ([92m↓5.13%[0m) [3.99% of initial]
[Iter 670/20000] Loss: 0.0095543 (Best: 0.0083987 @iter667) ([92m↓4.90%[0m) [3.80% of initial]
[Iter 680/20000] Loss: 0.0088072 (Best: 0.0082220 @iter680) ([92m↓7.82%[0m) [3.50% of initial]
[Iter 690/20000] Loss: 0.0091188 (Best: 0.0077519 @iter685) ([91m↑3.54%[0m) [3.62% of initial]
Iter:699, L1 loss=0.006241, Total loss=0.009508, Time:18
[Iter 700/20000] Loss: 0.0087769 (Best: 0.0077519 @iter685) ([92m↓3.75%[0m) [3.49% of initial]
[Iter 710/20000] Loss: 0.0082093 (Best: 0.0075641 @iter703) ([92m↓6.47%[0m) [3.26% of initial]
[Iter 720/20000] Loss: 0.0083574 (Best: 0.0075256 @iter715) ([91m↑1.80%[0m) [3.32% of initial]
[Iter 730/20000] Loss: 0.0084275 (Best: 0.0074279 @iter724) ([91m↑0.84%[0m) [3.35% of initial]
[Iter 740/20000] Loss: 0.0086290 (Best: 0.0072431 @iter736) ([91m↑2.39%[0m) [3.43% of initial]
[Iter 750/20000] Loss: 0.0080583 (Best: 0.0069599 @iter748) ([92m↓6.61%[0m) [3.20% of initial]
[Iter 760/20000] Loss: 0.0074277 (Best: 0.0069116 @iter754) ([92m↓7.83%[0m) [2.95% of initial]
[Iter 770/20000] Loss: 0.0075797 (Best: 0.0069116 @iter754) ([91m↑2.05%[0m) [3.01% of initial]
[Iter 780/20000] Loss: 0.0078355 (Best: 0.0067172 @iter775) ([91m↑3.37%[0m) [3.11% of initial]
[Iter 790/20000] Loss: 0.0075546 (Best: 0.0065794 @iter787) ([92m↓3.58%[0m) [3.00% of initial]
Iter:799, L1 loss=0.005075, Total loss=0.008132, Time:12
[Iter 800/20000] Loss: 0.0073363 (Best: 0.0064761 @iter796) ([92m↓2.89%[0m) [2.91% of initial]
[Iter 810/20000] Loss: 0.0154595 (Best: 0.0064761 @iter796) ([91m↑110.72%[0m) [6.14% of initial]
[Iter 820/20000] Loss: 0.0107637 (Best: 0.0064761 @iter796) ([92m↓30.38%[0m) [4.28% of initial]
[Iter 830/20000] Loss: 0.0087915 (Best: 0.0064761 @iter796) ([92m↓18.32%[0m) [3.49% of initial]
[Iter 840/20000] Loss: 0.0080442 (Best: 0.0064761 @iter796) ([92m↓8.50%[0m) [3.20% of initial]
[Iter 850/20000] Loss: 0.0074442 (Best: 0.0064761 @iter796) ([92m↓7.46%[0m) [2.96% of initial]
[Iter 860/20000] Loss: 0.0070371 (Best: 0.0062984 @iter856) ([92m↓5.47%[0m) [2.80% of initial]
[Iter 870/20000] Loss: 0.0066864 (Best: 0.0062173 @iter862) ([92m↓4.98%[0m) [2.66% of initial]
[Iter 880/20000] Loss: 0.0066494 (Best: 0.0059097 @iter875) ([92m↓0.55%[0m) [2.64% of initial]
[Iter 890/20000] Loss: 0.0062625 (Best: 0.0057087 @iter884) ([92m↓5.82%[0m) [2.49% of initial]
Iter:899, L1 loss=0.003775, Total loss=0.00558, Time:17
[Iter 900/20000] Loss: 0.0063857 (Best: 0.0055805 @iter899) ([91m↑1.97%[0m) [2.54% of initial]
[Iter 910/20000] Loss: 0.0065390 (Best: 0.0053529 @iter907) ([91m↑2.40%[0m) [2.60% of initial]
[Iter 920/20000] Loss: 0.0058188 (Best: 0.0051973 @iter916) ([92m↓11.02%[0m) [2.31% of initial]
[Iter 930/20000] Loss: 0.0062249 (Best: 0.0051666 @iter925) ([91m↑6.98%[0m) [2.47% of initial]
[Iter 940/20000] Loss: 0.0062259 (Best: 0.0051146 @iter938) ([91m↑0.02%[0m) [2.47% of initial]
[Iter 950/20000] Loss: 0.0056798 (Best: 0.0051146 @iter938) ([92m↓8.77%[0m) [2.26% of initial]
[Iter 960/20000] Loss: 0.0058620 (Best: 0.0051146 @iter938) ([91m↑3.21%[0m) [2.33% of initial]
[Iter 970/20000] Loss: 0.0057928 (Best: 0.0049807 @iter964) ([92m↓1.18%[0m) [2.30% of initial]
[Iter 980/20000] Loss: 0.0058598 (Best: 0.0049730 @iter974) ([91m↑1.16%[0m) [2.33% of initial]
[Iter 990/20000] Loss: 0.0059157 (Best: 0.0049730 @iter974) ([91m↑0.95%[0m) [2.35% of initial]
Iter:999, L1 loss=0.004475, Total loss=0.006376, Time:16
[Iter 1000/20000] Loss: 0.0060223 (Best: 0.0049730 @iter974) ([91m↑1.80%[0m) [2.39% of initial]
Pruning 950 points (6.9%) from gaussian0 at iteration 1000
Pruning 1087 points (7.8%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0143154 (Best: 0.0049730 @iter974) ([91m↑137.71%[0m) [5.69% of initial]
[Iter 1020/20000] Loss: 0.0098977 (Best: 0.0049730 @iter974) ([92m↓30.86%[0m) [3.93% of initial]
[Iter 1030/20000] Loss: 0.0081138 (Best: 0.0049730 @iter974) ([92m↓18.02%[0m) [3.22% of initial]
[Iter 1040/20000] Loss: 0.0072368 (Best: 0.0049730 @iter974) ([92m↓10.81%[0m) [2.88% of initial]
[Iter 1050/20000] Loss: 0.0067215 (Best: 0.0049730 @iter974) ([92m↓7.12%[0m) [2.67% of initial]
[Iter 1060/20000] Loss: 0.0063770 (Best: 0.0049730 @iter974) ([92m↓5.12%[0m) [2.53% of initial]
[Iter 1070/20000] Loss: 0.0061717 (Best: 0.0049730 @iter974) ([92m↓3.22%[0m) [2.45% of initial]
[Iter 1080/20000] Loss: 0.0060467 (Best: 0.0049730 @iter974) ([92m↓2.02%[0m) [2.40% of initial]
[Iter 1090/20000] Loss: 0.0058992 (Best: 0.0049730 @iter974) ([92m↓2.44%[0m) [2.34% of initial]
Iter:1099, L1 loss=0.004026, Total loss=0.005834, Time:15
[Iter 1100/20000] Loss: 0.0057100 (Best: 0.0049730 @iter974) ([92m↓3.21%[0m) [2.27% of initial]
[Iter 1110/20000] Loss: 0.0056809 (Best: 0.0049730 @iter974) ([92m↓0.51%[0m) [2.26% of initial]
[Iter 1120/20000] Loss: 0.0056734 (Best: 0.0049391 @iter1117) ([92m↓0.13%[0m) [2.25% of initial]
[Iter 1130/20000] Loss: 0.0056886 (Best: 0.0049391 @iter1117) ([91m↑0.27%[0m) [2.26% of initial]
[Iter 1140/20000] Loss: 0.0053505 (Best: 0.0048470 @iter1135) ([92m↓5.94%[0m) [2.13% of initial]
[Iter 1150/20000] Loss: 0.0049873 (Best: 0.0046914 @iter1150) ([92m↓6.79%[0m) [1.98% of initial]
[Iter 1160/20000] Loss: 0.0054117 (Best: 0.0046163 @iter1156) ([91m↑8.51%[0m) [2.15% of initial]
[Iter 1170/20000] Loss: 0.0051286 (Best: 0.0046163 @iter1156) ([92m↓5.23%[0m) [2.04% of initial]
[Iter 1180/20000] Loss: 0.0049021 (Best: 0.0045908 @iter1180) ([92m↓4.42%[0m) [1.95% of initial]
[Iter 1190/20000] Loss: 0.0051534 (Best: 0.0045548 @iter1186) ([91m↑5.13%[0m) [2.05% of initial]
Iter:1199, L1 loss=0.003749, Total loss=0.00539, Time:13
[Iter 1200/20000] Loss: 0.0051222 (Best: 0.0044520 @iter1198) ([92m↓0.60%[0m) [2.04% of initial]
[Iter 1210/20000] Loss: 0.0121064 (Best: 0.0044520 @iter1198) ([91m↑136.35%[0m) [4.81% of initial]
[Iter 1220/20000] Loss: 0.0079423 (Best: 0.0044520 @iter1198) ([92m↓34.40%[0m) [3.16% of initial]
[Iter 1230/20000] Loss: 0.0066568 (Best: 0.0044520 @iter1198) ([92m↓16.19%[0m) [2.64% of initial]
[Iter 1240/20000] Loss: 0.0059961 (Best: 0.0044520 @iter1198) ([92m↓9.93%[0m) [2.38% of initial]
[Iter 1250/20000] Loss: 0.0052620 (Best: 0.0044520 @iter1198) ([92m↓12.24%[0m) [2.09% of initial]
[Iter 1260/20000] Loss: 0.0050677 (Best: 0.0043587 @iter1258) ([92m↓3.69%[0m) [2.01% of initial]
[Iter 1270/20000] Loss: 0.0046413 (Best: 0.0043270 @iter1269) ([92m↓8.41%[0m) [1.84% of initial]
[Iter 1280/20000] Loss: 0.0048506 (Best: 0.0040162 @iter1273) ([91m↑4.51%[0m) [1.93% of initial]
[Iter 1290/20000] Loss: 0.0047300 (Best: 0.0039536 @iter1288) ([92m↓2.49%[0m) [1.88% of initial]
Iter:1299, L1 loss=0.003054, Total loss=0.004194, Time:19
[Iter 1300/20000] Loss: 0.0045065 (Best: 0.0039536 @iter1288) ([92m↓4.72%[0m) [1.79% of initial]
[Iter 1310/20000] Loss: 0.0045365 (Best: 0.0039536 @iter1288) ([91m↑0.66%[0m) [1.80% of initial]
[Iter 1320/20000] Loss: 0.0043772 (Best: 0.0037252 @iter1319) ([92m↓3.51%[0m) [1.74% of initial]
[Iter 1330/20000] Loss: 0.0043605 (Best: 0.0036471 @iter1321) ([92m↓0.38%[0m) [1.73% of initial]
[Iter 1340/20000] Loss: 0.0041335 (Best: 0.0036471 @iter1321) ([92m↓5.21%[0m) [1.64% of initial]
[Iter 1350/20000] Loss: 0.0041495 (Best: 0.0036471 @iter1321) ([91m↑0.39%[0m) [1.65% of initial]
[Iter 1360/20000] Loss: 0.0041944 (Best: 0.0036471 @iter1321) ([91m↑1.08%[0m) [1.67% of initial]
[Iter 1370/20000] Loss: 0.0039839 (Best: 0.0036051 @iter1363) ([92m↓5.02%[0m) [1.58% of initial]
[Iter 1380/20000] Loss: 0.0041927 (Best: 0.0034900 @iter1375) ([91m↑5.24%[0m) [1.67% of initial]
[Iter 1390/20000] Loss: 0.0040544 (Best: 0.0034900 @iter1375) ([92m↓3.30%[0m) [1.61% of initial]
Iter:1399, L1 loss=0.002541, Total loss=0.00345, Time:18
[Iter 1400/20000] Loss: 0.0038686 (Best: 0.0034334 @iter1397) ([92m↓4.58%[0m) [1.54% of initial]
[Iter 1410/20000] Loss: 0.0095305 (Best: 0.0034334 @iter1397) ([91m↑146.36%[0m) [3.79% of initial]
[Iter 1420/20000] Loss: 0.0068078 (Best: 0.0034334 @iter1397) ([92m↓28.57%[0m) [2.70% of initial]
[Iter 1430/20000] Loss: 0.0054963 (Best: 0.0034334 @iter1397) ([92m↓19.26%[0m) [2.18% of initial]
[Iter 1440/20000] Loss: 0.0049058 (Best: 0.0034334 @iter1397) ([92m↓10.74%[0m) [1.95% of initial]
[Iter 1450/20000] Loss: 0.0040034 (Best: 0.0034334 @iter1397) ([92m↓18.39%[0m) [1.59% of initial]
[Iter 1460/20000] Loss: 0.0039709 (Best: 0.0034232 @iter1459) ([92m↓0.81%[0m) [1.58% of initial]
[Iter 1470/20000] Loss: 0.0038057 (Best: 0.0034232 @iter1459) ([92m↓4.16%[0m) [1.51% of initial]
[Iter 1480/20000] Loss: 0.0036030 (Best: 0.0031362 @iter1480) ([92m↓5.32%[0m) [1.43% of initial]
[Iter 1490/20000] Loss: 0.0035798 (Best: 0.0031362 @iter1480) ([92m↓0.64%[0m) [1.42% of initial]
Iter:1499, L1 loss=0.003024, Total loss=0.003861, Time:14
[Iter 1500/20000] Loss: 0.0036206 (Best: 0.0031362 @iter1480) ([91m↑1.14%[0m) [1.44% of initial]
Pruning 745 points (3.0%) from gaussian0 at iteration 1500
Pruning 706 points (2.8%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0047893 (Best: 0.0031362 @iter1480) ([91m↑32.28%[0m) [1.90% of initial]
[Iter 1520/20000] Loss: 0.0040973 (Best: 0.0031362 @iter1480) ([92m↓14.45%[0m) [1.63% of initial]
[Iter 1530/20000] Loss: 0.0038403 (Best: 0.0031362 @iter1480) ([92m↓6.27%[0m) [1.53% of initial]
[Iter 1540/20000] Loss: 0.0036350 (Best: 0.0031362 @iter1480) ([92m↓5.35%[0m) [1.44% of initial]
[Iter 1550/20000] Loss: 0.0033786 (Best: 0.0030542 @iter1543) ([92m↓7.05%[0m) [1.34% of initial]
[Iter 1560/20000] Loss: 0.0035553 (Best: 0.0029182 @iter1558) ([91m↑5.23%[0m) [1.41% of initial]
[Iter 1570/20000] Loss: 0.0033578 (Best: 0.0029182 @iter1558) ([92m↓5.56%[0m) [1.33% of initial]
[Iter 1580/20000] Loss: 0.0032852 (Best: 0.0028487 @iter1573) ([92m↓2.16%[0m) [1.31% of initial]
[Iter 1590/20000] Loss: 0.0031921 (Best: 0.0028487 @iter1573) ([92m↓2.83%[0m) [1.27% of initial]
Iter:1599, L1 loss=0.002953, Total loss=0.003704, Time:19
[Iter 1600/20000] Loss: 0.0034434 (Best: 0.0028487 @iter1573) ([91m↑7.87%[0m) [1.37% of initial]
[Iter 1610/20000] Loss: 0.0093942 (Best: 0.0028487 @iter1573) ([91m↑172.82%[0m) [3.73% of initial]
[Iter 1620/20000] Loss: 0.0062647 (Best: 0.0028487 @iter1573) ([92m↓33.31%[0m) [2.49% of initial]
[Iter 1630/20000] Loss: 0.0049195 (Best: 0.0028487 @iter1573) ([92m↓21.47%[0m) [1.95% of initial]
[Iter 1640/20000] Loss: 0.0042441 (Best: 0.0028487 @iter1573) ([92m↓13.73%[0m) [1.69% of initial]
[Iter 1650/20000] Loss: 0.0037952 (Best: 0.0028487 @iter1573) ([92m↓10.58%[0m) [1.51% of initial]
[Iter 1660/20000] Loss: 0.0033396 (Best: 0.0028487 @iter1573) ([92m↓12.01%[0m) [1.33% of initial]
[Iter 1670/20000] Loss: 0.0031797 (Best: 0.0027502 @iter1669) ([92m↓4.79%[0m) [1.26% of initial]
[Iter 1680/20000] Loss: 0.0032421 (Best: 0.0027502 @iter1669) ([91m↑1.96%[0m) [1.29% of initial]
[Iter 1690/20000] Loss: 0.0033136 (Best: 0.0027371 @iter1684) ([91m↑2.21%[0m) [1.32% of initial]
Iter:1699, L1 loss=0.00267, Total loss=0.003311, Time:20
[Iter 1700/20000] Loss: 0.0030460 (Best: 0.0027371 @iter1684) ([92m↓8.08%[0m) [1.21% of initial]
[Iter 1710/20000] Loss: 0.0032531 (Best: 0.0027031 @iter1705) ([91m↑6.80%[0m) [1.29% of initial]
[Iter 1720/20000] Loss: 0.0027991 (Best: 0.0026157 @iter1720) ([92m↓13.96%[0m) [1.11% of initial]
[Iter 1730/20000] Loss: 0.0028928 (Best: 0.0026157 @iter1720) ([91m↑3.35%[0m) [1.15% of initial]
[Iter 1740/20000] Loss: 0.0028703 (Best: 0.0026157 @iter1720) ([92m↓0.78%[0m) [1.14% of initial]
[Iter 1750/20000] Loss: 0.0026128 (Best: 0.0023964 @iter1750) ([92m↓8.97%[0m) [1.04% of initial]
[Iter 1760/20000] Loss: 0.0027981 (Best: 0.0023964 @iter1750) ([91m↑7.09%[0m) [1.11% of initial]
[Iter 1770/20000] Loss: 0.0027157 (Best: 0.0023617 @iter1762) ([92m↓2.94%[0m) [1.08% of initial]
[Iter 1780/20000] Loss: 0.0026867 (Best: 0.0023617 @iter1762) ([92m↓1.07%[0m) [1.07% of initial]
[Iter 1790/20000] Loss: 0.0024705 (Best: 0.0021484 @iter1789) ([92m↓8.05%[0m) [0.98% of initial]
Iter:1799, L1 loss=0.001881, Total loss=0.002277, Time:20
[Iter 1800/20000] Loss: 0.0024940 (Best: 0.0021484 @iter1789) ([91m↑0.95%[0m) [0.99% of initial]
[Iter 1810/20000] Loss: 0.0084771 (Best: 0.0021484 @iter1789) ([91m↑239.90%[0m) [3.37% of initial]
[Iter 1820/20000] Loss: 0.0049851 (Best: 0.0021484 @iter1789) ([92m↓41.19%[0m) [1.98% of initial]
[Iter 1830/20000] Loss: 0.0043542 (Best: 0.0021484 @iter1789) ([92m↓12.66%[0m) [1.73% of initial]
[Iter 1840/20000] Loss: 0.0031483 (Best: 0.0021484 @iter1789) ([92m↓27.70%[0m) [1.25% of initial]
[Iter 1850/20000] Loss: 0.0028994 (Best: 0.0021484 @iter1789) ([92m↓7.90%[0m) [1.15% of initial]
[Iter 1860/20000] Loss: 0.0026406 (Best: 0.0021484 @iter1789) ([92m↓8.93%[0m) [1.05% of initial]
[Iter 1870/20000] Loss: 0.0024590 (Best: 0.0021217 @iter1867) ([92m↓6.88%[0m) [0.98% of initial]
[Iter 1880/20000] Loss: 0.0023556 (Best: 0.0021217 @iter1867) ([92m↓4.21%[0m) [0.94% of initial]
[Iter 1890/20000] Loss: 0.0021593 (Best: 0.0020277 @iter1890) ([92m↓8.33%[0m) [0.86% of initial]
Iter:1899, L1 loss=0.00197, Total loss=0.002197, Time:25
[Iter 1900/20000] Loss: 0.0022461 (Best: 0.0019080 @iter1891) ([91m↑4.02%[0m) [0.89% of initial]
[Iter 1910/20000] Loss: 0.0022737 (Best: 0.0019080 @iter1891) ([91m↑1.23%[0m) [0.90% of initial]
[Iter 1920/20000] Loss: 0.0023246 (Best: 0.0019080 @iter1891) ([91m↑2.24%[0m) [0.92% of initial]
[Iter 1930/20000] Loss: 0.0020076 (Best: 0.0018568 @iter1930) ([92m↓13.64%[0m) [0.80% of initial]
[Iter 1940/20000] Loss: 0.0020677 (Best: 0.0017785 @iter1939) ([91m↑3.00%[0m) [0.82% of initial]
[Iter 1950/20000] Loss: 0.0022808 (Best: 0.0017785 @iter1939) ([91m↑10.31%[0m) [0.91% of initial]
[Iter 1960/20000] Loss: 0.0020969 (Best: 0.0017785 @iter1939) ([92m↓8.06%[0m) [0.83% of initial]
[Iter 1970/20000] Loss: 0.0019505 (Best: 0.0017558 @iter1963) ([92m↓6.98%[0m) [0.77% of initial]
[Iter 1980/20000] Loss: 0.0022141 (Best: 0.0017558 @iter1963) ([91m↑13.51%[0m) [0.88% of initial]
[Iter 1990/20000] Loss: 0.0019903 (Best: 0.0017558 @iter1963) ([92m↓10.11%[0m) [0.79% of initial]
Iter:1999, L1 loss=0.001721, Total loss=0.001904, Time:25
[Iter 2000/20000] Loss: 0.0020584 (Best: 0.0016594 @iter1996) ([91m↑3.43%[0m) [0.82% of initial]
Testing Speed: 121.11379655858462 fps
Testing Time: 0.41283488273620605 s

[ITER 2000] Evaluating test: SSIM = 0.8592940068244934, PSNR = 41.96186531066895
Testing Speed: 170.05543767653697 fps
Testing Time: 0.017641305923461914 s

[ITER 2000] Evaluating train: SSIM = 0.9999566674232483, PSNR = 74.45432535807291
Iter:2000, total_points:43347
Pruning 740 points (1.3%) from gaussian0 at iteration 2000
Pruning 674 points (1.2%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.0077650 (Best: 0.0016594 @iter1996) ([91m↑277.23%[0m) [3.08% of initial]
[Iter 2020/20000] Loss: 0.0050680 (Best: 0.0016594 @iter1996) ([92m↓34.73%[0m) [2.01% of initial]
[Iter 2030/20000] Loss: 0.0037289 (Best: 0.0016594 @iter1996) ([92m↓26.42%[0m) [1.48% of initial]
[Iter 2040/20000] Loss: 0.0031605 (Best: 0.0016594 @iter1996) ([92m↓15.24%[0m) [1.26% of initial]
[Iter 2050/20000] Loss: 0.0026968 (Best: 0.0016594 @iter1996) ([92m↓14.67%[0m) [1.07% of initial]
[Iter 2060/20000] Loss: 0.0023646 (Best: 0.0016594 @iter1996) ([92m↓12.32%[0m) [0.94% of initial]
[Iter 2070/20000] Loss: 0.0024594 (Best: 0.0016594 @iter1996) ([91m↑4.01%[0m) [0.98% of initial]
[Iter 2080/20000] Loss: 0.0023576 (Best: 0.0016594 @iter1996) ([92m↓4.14%[0m) [0.94% of initial]
[Iter 2090/20000] Loss: 0.0022917 (Best: 0.0016594 @iter1996) ([92m↓2.79%[0m) [0.91% of initial]
Iter:2099, L1 loss=0.001996, Total loss=0.002247, Time:21
[Iter 2100/20000] Loss: 0.0021506 (Best: 0.0016594 @iter1996) ([92m↓6.16%[0m) [0.85% of initial]
[Iter 2110/20000] Loss: 0.0020628 (Best: 0.0016594 @iter1996) ([92m↓4.08%[0m) [0.82% of initial]
[Iter 2120/20000] Loss: 0.0018929 (Best: 0.0016594 @iter1996) ([92m↓8.24%[0m) [0.75% of initial]
[Iter 2130/20000] Loss: 0.0020245 (Best: 0.0016594 @iter1996) ([91m↑6.95%[0m) [0.80% of initial]
[Iter 2140/20000] Loss: 0.0021130 (Best: 0.0016594 @iter1996) ([91m↑4.37%[0m) [0.84% of initial]
[Iter 2150/20000] Loss: 0.0022203 (Best: 0.0016594 @iter1996) ([91m↑5.08%[0m) [0.88% of initial]
[Iter 2160/20000] Loss: 0.0020052 (Best: 0.0016594 @iter1996) ([92m↓9.69%[0m) [0.80% of initial]
[Iter 2170/20000] Loss: 0.0019942 (Best: 0.0016594 @iter1996) ([92m↓0.55%[0m) [0.79% of initial]
[Iter 2180/20000] Loss: 0.0017580 (Best: 0.0016146 @iter2180) ([92m↓11.84%[0m) [0.70% of initial]
[Iter 2190/20000] Loss: 0.0019908 (Best: 0.0016146 @iter2180) ([91m↑13.24%[0m) [0.79% of initial]
Iter:2199, L1 loss=0.001762, Total loss=0.001924, Time:24
[Iter 2200/20000] Loss: 0.0019497 (Best: 0.0016146 @iter2180) ([92m↓2.06%[0m) [0.77% of initial]
[Iter 2210/20000] Loss: 0.0087256 (Best: 0.0016146 @iter2180) ([91m↑347.53%[0m) [3.47% of initial]
[Iter 2220/20000] Loss: 0.0051900 (Best: 0.0016146 @iter2180) ([92m↓40.52%[0m) [2.06% of initial]
[Iter 2230/20000] Loss: 0.0033121 (Best: 0.0016146 @iter2180) ([92m↓36.18%[0m) [1.32% of initial]
[Iter 2240/20000] Loss: 0.0027443 (Best: 0.0016146 @iter2180) ([92m↓17.14%[0m) [1.09% of initial]
[Iter 2250/20000] Loss: 0.0025375 (Best: 0.0016146 @iter2180) ([92m↓7.54%[0m) [1.01% of initial]
[Iter 2260/20000] Loss: 0.0021360 (Best: 0.0016146 @iter2180) ([92m↓15.82%[0m) [0.85% of initial]
[Iter 2270/20000] Loss: 0.0021433 (Best: 0.0016146 @iter2180) ([91m↑0.34%[0m) [0.85% of initial]
[Iter 2280/20000] Loss: 0.0018002 (Best: 0.0016146 @iter2180) ([92m↓16.01%[0m) [0.72% of initial]
[Iter 2290/20000] Loss: 0.0017303 (Best: 0.0015123 @iter2287) ([92m↓3.88%[0m) [0.69% of initial]
Iter:2299, L1 loss=0.001592, Total loss=0.001681, Time:27
[Iter 2300/20000] Loss: 0.0019506 (Best: 0.0015123 @iter2287) ([91m↑12.73%[0m) [0.77% of initial]
[Iter 2310/20000] Loss: 0.0018233 (Best: 0.0015123 @iter2287) ([92m↓6.53%[0m) [0.72% of initial]
[Iter 2320/20000] Loss: 0.0016258 (Best: 0.0015120 @iter2320) ([92m↓10.83%[0m) [0.65% of initial]
[Iter 2330/20000] Loss: 0.0015962 (Best: 0.0014410 @iter2326) ([92m↓1.82%[0m) [0.63% of initial]
[Iter 2340/20000] Loss: 0.0016409 (Best: 0.0014207 @iter2338) ([91m↑2.80%[0m) [0.65% of initial]
[Iter 2350/20000] Loss: 0.0017731 (Best: 0.0014207 @iter2338) ([91m↑8.05%[0m) [0.70% of initial]
[Iter 2360/20000] Loss: 0.0016363 (Best: 0.0013674 @iter2359) ([92m↓7.71%[0m) [0.65% of initial]
[Iter 2370/20000] Loss: 0.0016935 (Best: 0.0013674 @iter2359) ([91m↑3.50%[0m) [0.67% of initial]
[Iter 2380/20000] Loss: 0.0017368 (Best: 0.0013674 @iter2359) ([91m↑2.55%[0m) [0.69% of initial]
[Iter 2390/20000] Loss: 0.0018985 (Best: 0.0013674 @iter2359) ([91m↑9.31%[0m) [0.75% of initial]
Iter:2399, L1 loss=0.001484, Total loss=0.001533, Time:27
[Iter 2400/20000] Loss: 0.0016294 (Best: 0.0013674 @iter2359) ([92m↓14.17%[0m) [0.65% of initial]
[Iter 2410/20000] Loss: 0.0066443 (Best: 0.0013674 @iter2359) ([91m↑307.77%[0m) [2.64% of initial]
[Iter 2420/20000] Loss: 0.0039672 (Best: 0.0013674 @iter2359) ([92m↓40.29%[0m) [1.58% of initial]
[Iter 2430/20000] Loss: 0.0028396 (Best: 0.0013674 @iter2359) ([92m↓28.42%[0m) [1.13% of initial]
[Iter 2440/20000] Loss: 0.0023286 (Best: 0.0013674 @iter2359) ([92m↓18.00%[0m) [0.93% of initial]
[Iter 2450/20000] Loss: 0.0022128 (Best: 0.0013674 @iter2359) ([92m↓4.97%[0m) [0.88% of initial]
[Iter 2460/20000] Loss: 0.0019623 (Best: 0.0013674 @iter2359) ([92m↓11.32%[0m) [0.78% of initial]
[Iter 2470/20000] Loss: 0.0018508 (Best: 0.0013674 @iter2359) ([92m↓5.68%[0m) [0.74% of initial]
[Iter 2480/20000] Loss: 0.0018949 (Best: 0.0013674 @iter2359) ([91m↑2.38%[0m) [0.75% of initial]
[Iter 2490/20000] Loss: 0.0017133 (Best: 0.0013674 @iter2359) ([92m↓9.58%[0m) [0.68% of initial]
Iter:2499, L1 loss=0.001391, Total loss=0.001478, Time:22
[Iter 2500/20000] Loss: 0.0015470 (Best: 0.0013674 @iter2359) ([92m↓9.71%[0m) [0.61% of initial]
Pruning 484 points (0.6%) from gaussian0 at iteration 2500
Pruning 392 points (0.5%) from gaussian1 at iteration 2500
[Iter 2510/20000] Loss: 0.0034188 (Best: 0.0013674 @iter2359) ([91m↑121.00%[0m) [1.36% of initial]
[Iter 2520/20000] Loss: 0.0022268 (Best: 0.0013674 @iter2359) ([92m↓34.87%[0m) [0.88% of initial]
[Iter 2530/20000] Loss: 0.0016534 (Best: 0.0013674 @iter2359) ([92m↓25.75%[0m) [0.66% of initial]
[Iter 2540/20000] Loss: 0.0015250 (Best: 0.0013673 @iter2533) ([92m↓7.76%[0m) [0.61% of initial]
[Iter 2550/20000] Loss: 0.0016143 (Best: 0.0012256 @iter2548) ([91m↑5.86%[0m) [0.64% of initial]
[Iter 2560/20000] Loss: 0.0013681 (Best: 0.0011848 @iter2557) ([92m↓15.25%[0m) [0.54% of initial]
[Iter 2570/20000] Loss: 0.0015739 (Best: 0.0011848 @iter2557) ([91m↑15.04%[0m) [0.63% of initial]
[Iter 2580/20000] Loss: 0.0014282 (Best: 0.0011391 @iter2578) ([92m↓9.25%[0m) [0.57% of initial]
[Iter 2590/20000] Loss: 0.0015267 (Best: 0.0011391 @iter2578) ([91m↑6.89%[0m) [0.61% of initial]
Iter:2599, L1 loss=0.001189, Total loss=0.001223, Time:25
[Iter 2600/20000] Loss: 0.0013852 (Best: 0.0011391 @iter2578) ([92m↓9.27%[0m) [0.55% of initial]
[Iter 2610/20000] Loss: 0.0066833 (Best: 0.0011391 @iter2578) ([91m↑382.50%[0m) [2.66% of initial]
[Iter 2620/20000] Loss: 0.0038004 (Best: 0.0011391 @iter2578) ([92m↓43.14%[0m) [1.51% of initial]
[Iter 2630/20000] Loss: 0.0024816 (Best: 0.0011391 @iter2578) ([92m↓34.70%[0m) [0.99% of initial]
[Iter 2640/20000] Loss: 0.0019916 (Best: 0.0011391 @iter2578) ([92m↓19.75%[0m) [0.79% of initial]
[Iter 2650/20000] Loss: 0.0016443 (Best: 0.0011391 @iter2578) ([92m↓17.44%[0m) [0.65% of initial]
[Iter 2660/20000] Loss: 0.0018610 (Best: 0.0011391 @iter2578) ([91m↑13.18%[0m) [0.74% of initial]
[Iter 2670/20000] Loss: 0.0017697 (Best: 0.0011391 @iter2578) ([92m↓4.91%[0m) [0.70% of initial]
[Iter 2680/20000] Loss: 0.0014007 (Best: 0.0011391 @iter2578) ([92m↓20.85%[0m) [0.56% of initial]
[Iter 2690/20000] Loss: 0.0013566 (Best: 0.0011391 @iter2578) ([92m↓3.15%[0m) [0.54% of initial]
Iter:2699, L1 loss=0.001332, Total loss=0.001373, Time:28
[Iter 2700/20000] Loss: 0.0016770 (Best: 0.0011391 @iter2578) ([91m↑23.61%[0m) [0.67% of initial]
[Iter 2710/20000] Loss: 0.0013966 (Best: 0.0011391 @iter2578) ([92m↓16.72%[0m) [0.55% of initial]
[Iter 2720/20000] Loss: 0.0012649 (Best: 0.0011229 @iter2718) ([92m↓9.43%[0m) [0.50% of initial]
[Iter 2730/20000] Loss: 0.0011598 (Best: 0.0010164 @iter2727) ([92m↓8.31%[0m) [0.46% of initial]
[Iter 2740/20000] Loss: 0.0010210 (Best: 0.0009257 @iter2740) ([92m↓11.97%[0m) [0.41% of initial]
[Iter 2750/20000] Loss: 0.0012929 (Best: 0.0009257 @iter2740) ([91m↑26.63%[0m) [0.51% of initial]
[Iter 2760/20000] Loss: 0.0014376 (Best: 0.0009257 @iter2740) ([91m↑11.19%[0m) [0.57% of initial]
[Iter 2770/20000] Loss: 0.0015718 (Best: 0.0009257 @iter2740) ([91m↑9.33%[0m) [0.62% of initial]
[Iter 2780/20000] Loss: 0.0012627 (Best: 0.0009257 @iter2740) ([92m↓19.67%[0m) [0.50% of initial]
[Iter 2790/20000] Loss: 0.0013266 (Best: 0.0009257 @iter2740) ([91m↑5.06%[0m) [0.53% of initial]
Iter:2799, L1 loss=0.001442, Total loss=0.001438, Time:25
[Iter 2800/20000] Loss: 0.0013323 (Best: 0.0009257 @iter2740) ([91m↑0.43%[0m) [0.53% of initial]
[Iter 2810/20000] Loss: 0.0057724 (Best: 0.0009257 @iter2740) ([91m↑333.27%[0m) [2.29% of initial]
[Iter 2820/20000] Loss: 0.0030994 (Best: 0.0009257 @iter2740) ([92m↓46.31%[0m) [1.23% of initial]
[Iter 2830/20000] Loss: 0.0019888 (Best: 0.0009257 @iter2740) ([92m↓35.83%[0m) [0.79% of initial]
[Iter 2840/20000] Loss: 0.0016873 (Best: 0.0009257 @iter2740) ([92m↓15.16%[0m) [0.67% of initial]
[Iter 2850/20000] Loss: 0.0014726 (Best: 0.0009257 @iter2740) ([92m↓12.72%[0m) [0.59% of initial]
[Iter 2860/20000] Loss: 0.0015794 (Best: 0.0009257 @iter2740) ([91m↑7.25%[0m) [0.63% of initial]
[Iter 2870/20000] Loss: 0.0013680 (Best: 0.0009257 @iter2740) ([92m↓13.39%[0m) [0.54% of initial]
[Iter 2880/20000] Loss: 0.0013356 (Best: 0.0009257 @iter2740) ([92m↓2.36%[0m) [0.53% of initial]
[Iter 2890/20000] Loss: 0.0012210 (Best: 0.0009257 @iter2740) ([92m↓8.58%[0m) [0.49% of initial]
Iter:2899, L1 loss=0.00101, Total loss=0.0009916, Time:32
[Iter 2900/20000] Loss: 0.0011659 (Best: 0.0009257 @iter2740) ([92m↓4.52%[0m) [0.46% of initial]
[Iter 2910/20000] Loss: 0.0013181 (Best: 0.0009257 @iter2740) ([91m↑13.05%[0m) [0.52% of initial]
[Iter 2920/20000] Loss: 0.0014106 (Best: 0.0009257 @iter2740) ([91m↑7.02%[0m) [0.56% of initial]
[Iter 2930/20000] Loss: 0.0012991 (Best: 0.0009257 @iter2740) ([92m↓7.91%[0m) [0.52% of initial]
[Iter 2940/20000] Loss: 0.0011308 (Best: 0.0009257 @iter2740) ([92m↓12.95%[0m) [0.45% of initial]
[Iter 2950/20000] Loss: 0.0010263 (Best: 0.0008734 @iter2950) ([92m↓9.24%[0m) [0.41% of initial]
[Iter 2960/20000] Loss: 0.0011302 (Best: 0.0008734 @iter2950) ([91m↑10.12%[0m) [0.45% of initial]
[Iter 2970/20000] Loss: 0.0010001 (Best: 0.0008272 @iter2969) ([92m↓11.51%[0m) [0.40% of initial]
[Iter 2980/20000] Loss: 0.0009483 (Best: 0.0008272 @iter2969) ([92m↓5.18%[0m) [0.38% of initial]
[Iter 2990/20000] Loss: 0.0009779 (Best: 0.0007695 @iter2983) ([91m↑3.12%[0m) [0.39% of initial]
Iter:2999, L1 loss=0.0008248, Total loss=0.0007638, Time:32
[Iter 3000/20000] Loss: 0.0009592 (Best: 0.0007638 @iter2999) ([92m↓1.90%[0m) [0.38% of initial]
Pruning 456 points (0.4%) from gaussian0 at iteration 3000
Pruning 322 points (0.3%) from gaussian1 at iteration 3000
[Iter 3010/20000] Loss: 0.0057659 (Best: 0.0007638 @iter2999) ([91m↑501.10%[0m) [2.29% of initial]
[Iter 3020/20000] Loss: 0.0034405 (Best: 0.0007638 @iter2999) ([92m↓40.33%[0m) [1.37% of initial]
[Iter 3030/20000] Loss: 0.0024185 (Best: 0.0007638 @iter2999) ([92m↓29.71%[0m) [0.96% of initial]
[Iter 3040/20000] Loss: 0.0018752 (Best: 0.0007638 @iter2999) ([92m↓22.46%[0m) [0.74% of initial]
[Iter 3050/20000] Loss: 0.0016783 (Best: 0.0007638 @iter2999) ([92m↓10.50%[0m) [0.67% of initial]
[Iter 3060/20000] Loss: 0.0015892 (Best: 0.0007638 @iter2999) ([92m↓5.31%[0m) [0.63% of initial]
[Iter 3070/20000] Loss: 0.0013693 (Best: 0.0007638 @iter2999) ([92m↓13.84%[0m) [0.54% of initial]
[Iter 3080/20000] Loss: 0.0013706 (Best: 0.0007638 @iter2999) ([91m↑0.10%[0m) [0.54% of initial]
[Iter 3090/20000] Loss: 0.0013381 (Best: 0.0007638 @iter2999) ([92m↓2.37%[0m) [0.53% of initial]
Iter:3099, L1 loss=0.001163, Total loss=0.001116, Time:19
[Iter 3100/20000] Loss: 0.0012172 (Best: 0.0007638 @iter2999) ([92m↓9.04%[0m) [0.48% of initial]
[Iter 3110/20000] Loss: 0.0013842 (Best: 0.0007638 @iter2999) ([91m↑13.72%[0m) [0.55% of initial]
[Iter 3120/20000] Loss: 0.0013302 (Best: 0.0007638 @iter2999) ([92m↓3.90%[0m) [0.53% of initial]
[Iter 3130/20000] Loss: 0.0011284 (Best: 0.0007638 @iter2999) ([92m↓15.18%[0m) [0.45% of initial]
[Iter 3140/20000] Loss: 0.0010869 (Best: 0.0007638 @iter2999) ([92m↓3.68%[0m) [0.43% of initial]
[Iter 3150/20000] Loss: 0.0011279 (Best: 0.0007638 @iter2999) ([91m↑3.77%[0m) [0.45% of initial]
[Iter 3160/20000] Loss: 0.0010428 (Best: 0.0007638 @iter2999) ([92m↓7.54%[0m) [0.41% of initial]
[Iter 3170/20000] Loss: 0.0010312 (Best: 0.0007638 @iter2999) ([92m↓1.11%[0m) [0.41% of initial]
[Iter 3180/20000] Loss: 0.0011145 (Best: 0.0007638 @iter2999) ([91m↑8.07%[0m) [0.44% of initial]
[Iter 3190/20000] Loss: 0.0010919 (Best: 0.0007638 @iter2999) ([92m↓2.02%[0m) [0.43% of initial]
Iter:3199, L1 loss=0.001039, Total loss=0.0009609, Time:35
[Iter 3200/20000] Loss: 0.0010202 (Best: 0.0007638 @iter2999) ([92m↓6.57%[0m) [0.41% of initial]
[Iter 3210/20000] Loss: 0.0056091 (Best: 0.0007638 @iter2999) ([91m↑449.82%[0m) [2.23% of initial]
[Iter 3220/20000] Loss: 0.0032431 (Best: 0.0007638 @iter2999) ([92m↓42.18%[0m) [1.29% of initial]
[Iter 3230/20000] Loss: 0.0019957 (Best: 0.0007638 @iter2999) ([92m↓38.46%[0m) [0.79% of initial]
[Iter 3240/20000] Loss: 0.0017798 (Best: 0.0007638 @iter2999) ([92m↓10.82%[0m) [0.71% of initial]
[Iter 3250/20000] Loss: 0.0013205 (Best: 0.0007638 @iter2999) ([92m↓25.80%[0m) [0.52% of initial]
[Iter 3260/20000] Loss: 0.0011871 (Best: 0.0007638 @iter2999) ([92m↓10.11%[0m) [0.47% of initial]
[Iter 3270/20000] Loss: 0.0012173 (Best: 0.0007638 @iter2999) ([91m↑2.55%[0m) [0.48% of initial]
[Iter 3280/20000] Loss: 0.0012749 (Best: 0.0007638 @iter2999) ([91m↑4.73%[0m) [0.51% of initial]
[Iter 3290/20000] Loss: 0.0009632 (Best: 0.0007638 @iter2999) ([92m↓24.45%[0m) [0.38% of initial]
Iter:3299, L1 loss=0.001532, Total loss=0.001582, Time:34
[Iter 3300/20000] Loss: 0.0013342 (Best: 0.0007638 @iter2999) ([91m↑38.52%[0m) [0.53% of initial]
[Iter 3310/20000] Loss: 0.0009981 (Best: 0.0007638 @iter2999) ([92m↓25.19%[0m) [0.40% of initial]
[Iter 3320/20000] Loss: 0.0011333 (Best: 0.0007638 @iter2999) ([91m↑13.55%[0m) [0.45% of initial]
[Iter 3330/20000] Loss: 0.0012288 (Best: 0.0007638 @iter2999) ([91m↑8.43%[0m) [0.49% of initial]
[Iter 3340/20000] Loss: 0.0013175 (Best: 0.0007638 @iter2999) ([91m↑7.22%[0m) [0.52% of initial]
[Iter 3350/20000] Loss: 0.0010784 (Best: 0.0007638 @iter2999) ([92m↓18.15%[0m) [0.43% of initial]
[Iter 3360/20000] Loss: 0.0013333 (Best: 0.0007638 @iter2999) ([91m↑23.64%[0m) [0.53% of initial]
[Iter 3370/20000] Loss: 0.0009761 (Best: 0.0007638 @iter2999) ([92m↓26.79%[0m) [0.39% of initial]
[Iter 3380/20000] Loss: 0.0009155 (Best: 0.0007638 @iter2999) ([92m↓6.20%[0m) [0.36% of initial]
[Iter 3390/20000] Loss: 0.0012058 (Best: 0.0007638 @iter2999) ([91m↑31.70%[0m) [0.48% of initial]
Iter:3399, L1 loss=0.001484, Total loss=0.001507, Time:36
[Iter 3400/20000] Loss: 0.0012620 (Best: 0.0007638 @iter2999) ([91m↑4.67%[0m) [0.50% of initial]
[Iter 3410/20000] Loss: 0.0049955 (Best: 0.0007638 @iter2999) ([91m↑295.82%[0m) [1.98% of initial]
[Iter 3420/20000] Loss: 0.0025728 (Best: 0.0007638 @iter2999) ([92m↓48.50%[0m) [1.02% of initial]
[Iter 3430/20000] Loss: 0.0016598 (Best: 0.0007638 @iter2999) ([92m↓35.49%[0m) [0.66% of initial]
[Iter 3440/20000] Loss: 0.0014795 (Best: 0.0007638 @iter2999) ([92m↓10.86%[0m) [0.59% of initial]
[Iter 3450/20000] Loss: 0.0014084 (Best: 0.0007638 @iter2999) ([92m↓4.81%[0m) [0.56% of initial]
[Iter 3460/20000] Loss: 0.0012432 (Best: 0.0007638 @iter2999) ([92m↓11.73%[0m) [0.49% of initial]
[Iter 3470/20000] Loss: 0.0012064 (Best: 0.0007638 @iter2999) ([92m↓2.96%[0m) [0.48% of initial]
[Iter 3480/20000] Loss: 0.0010799 (Best: 0.0007638 @iter2999) ([92m↓10.49%[0m) [0.43% of initial]
[Iter 3490/20000] Loss: 0.0010303 (Best: 0.0007638 @iter2999) ([92m↓4.59%[0m) [0.41% of initial]
Iter:3499, L1 loss=0.000785, Total loss=0.0007193, Time:28
[Iter 3500/20000] Loss: 0.0007981 (Best: 0.0007193 @iter3499) ([92m↓22.54%[0m) [0.32% of initial]
Pruning 355 points (0.2%) from gaussian0 at iteration 3500
Pruning 281 points (0.2%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0026526 (Best: 0.0007193 @iter3499) ([91m↑232.36%[0m) [1.05% of initial]
[Iter 3520/20000] Loss: 0.0016336 (Best: 0.0007193 @iter3499) ([92m↓38.42%[0m) [0.65% of initial]
[Iter 3530/20000] Loss: 0.0012067 (Best: 0.0007193 @iter3499) ([92m↓26.13%[0m) [0.48% of initial]
[Iter 3540/20000] Loss: 0.0013639 (Best: 0.0007193 @iter3499) ([91m↑13.02%[0m) [0.54% of initial]
[Iter 3550/20000] Loss: 0.0012014 (Best: 0.0007193 @iter3499) ([92m↓11.91%[0m) [0.48% of initial]
[Iter 3560/20000] Loss: 0.0010698 (Best: 0.0007193 @iter3499) ([92m↓10.95%[0m) [0.43% of initial]
[Iter 3570/20000] Loss: 0.0011623 (Best: 0.0007193 @iter3499) ([91m↑8.64%[0m) [0.46% of initial]
[Iter 3580/20000] Loss: 0.0008661 (Best: 0.0007193 @iter3499) ([92m↓25.48%[0m) [0.34% of initial]
[Iter 3590/20000] Loss: 0.0008474 (Best: 0.0007193 @iter3499) ([92m↓2.17%[0m) [0.34% of initial]
Iter:3599, L1 loss=0.0008002, Total loss=0.0007245, Time:34
[Iter 3600/20000] Loss: 0.0008205 (Best: 0.0006863 @iter3598) ([92m↓3.16%[0m) [0.33% of initial]
[Iter 3610/20000] Loss: 0.0046926 (Best: 0.0006863 @iter3598) ([91m↑471.88%[0m) [1.86% of initial]
[Iter 3620/20000] Loss: 0.0029718 (Best: 0.0006863 @iter3598) ([92m↓36.67%[0m) [1.18% of initial]
[Iter 3630/20000] Loss: 0.0017641 (Best: 0.0006863 @iter3598) ([92m↓40.64%[0m) [0.70% of initial]
[Iter 3640/20000] Loss: 0.0013210 (Best: 0.0006863 @iter3598) ([92m↓25.12%[0m) [0.52% of initial]
[Iter 3650/20000] Loss: 0.0013052 (Best: 0.0006863 @iter3598) ([92m↓1.19%[0m) [0.52% of initial]
[Iter 3660/20000] Loss: 0.0010808 (Best: 0.0006863 @iter3598) ([92m↓17.20%[0m) [0.43% of initial]
[Iter 3670/20000] Loss: 0.0009462 (Best: 0.0006863 @iter3598) ([92m↓12.45%[0m) [0.38% of initial]
[Iter 3680/20000] Loss: 0.0011772 (Best: 0.0006863 @iter3598) ([91m↑24.41%[0m) [0.47% of initial]
[Iter 3690/20000] Loss: 0.0014454 (Best: 0.0006863 @iter3598) ([91m↑22.79%[0m) [0.57% of initial]
Iter:3699, L1 loss=0.001215, Total loss=0.001217, Time:38
[Iter 3700/20000] Loss: 0.0012515 (Best: 0.0006863 @iter3598) ([92m↓13.41%[0m) [0.50% of initial]
[Iter 3710/20000] Loss: 0.0009534 (Best: 0.0006863 @iter3598) ([92m↓23.82%[0m) [0.38% of initial]
[Iter 3720/20000] Loss: 0.0010532 (Best: 0.0006863 @iter3598) ([91m↑10.47%[0m) [0.42% of initial]
[Iter 3730/20000] Loss: 0.0008857 (Best: 0.0006863 @iter3598) ([92m↓15.90%[0m) [0.35% of initial]
[Iter 3740/20000] Loss: 0.0008835 (Best: 0.0006863 @iter3598) ([92m↓0.25%[0m) [0.35% of initial]
[Iter 3750/20000] Loss: 0.0009215 (Best: 0.0006863 @iter3598) ([91m↑4.31%[0m) [0.37% of initial]
[Iter 3760/20000] Loss: 0.0009111 (Best: 0.0006863 @iter3598) ([92m↓1.13%[0m) [0.36% of initial]
[Iter 3770/20000] Loss: 0.0008938 (Best: 0.0006863 @iter3598) ([92m↓1.90%[0m) [0.36% of initial]
[Iter 3780/20000] Loss: 0.0008110 (Best: 0.0006479 @iter3775) ([92m↓9.27%[0m) [0.32% of initial]
[Iter 3790/20000] Loss: 0.0006746 (Best: 0.0006061 @iter3785) ([92m↓16.81%[0m) [0.27% of initial]
Iter:3799, L1 loss=0.0009336, Total loss=0.0008375, Time:36
[Iter 3800/20000] Loss: 0.0008384 (Best: 0.0006061 @iter3785) ([91m↑24.28%[0m) [0.33% of initial]
[Iter 3810/20000] Loss: 0.0044725 (Best: 0.0006061 @iter3785) ([91m↑433.42%[0m) [1.78% of initial]
[Iter 3820/20000] Loss: 0.0024588 (Best: 0.0006061 @iter3785) ([92m↓45.02%[0m) [0.98% of initial]
[Iter 3830/20000] Loss: 0.0014480 (Best: 0.0006061 @iter3785) ([92m↓41.11%[0m) [0.58% of initial]
[Iter 3840/20000] Loss: 0.0015775 (Best: 0.0006061 @iter3785) ([91m↑8.94%[0m) [0.63% of initial]
[Iter 3850/20000] Loss: 0.0012002 (Best: 0.0006061 @iter3785) ([92m↓23.91%[0m) [0.48% of initial]
[Iter 3860/20000] Loss: 0.0011369 (Best: 0.0006061 @iter3785) ([92m↓5.27%[0m) [0.45% of initial]
[Iter 3870/20000] Loss: 0.0008852 (Best: 0.0006061 @iter3785) ([92m↓22.14%[0m) [0.35% of initial]
[Iter 3880/20000] Loss: 0.0009542 (Best: 0.0006061 @iter3785) ([91m↑7.78%[0m) [0.38% of initial]
[Iter 3890/20000] Loss: 0.0007661 (Best: 0.0006061 @iter3785) ([92m↓19.71%[0m) [0.30% of initial]
Iter:3899, L1 loss=0.000856, Total loss=0.0008094, Time:37
[Iter 3900/20000] Loss: 0.0007565 (Best: 0.0005713 @iter3898) ([92m↓1.25%[0m) [0.30% of initial]
[Iter 3910/20000] Loss: 0.0009426 (Best: 0.0005713 @iter3898) ([91m↑24.60%[0m) [0.37% of initial]
[Iter 3920/20000] Loss: 0.0009765 (Best: 0.0005713 @iter3898) ([91m↑3.59%[0m) [0.39% of initial]
[Iter 3930/20000] Loss: 0.0009817 (Best: 0.0005713 @iter3898) ([91m↑0.53%[0m) [0.39% of initial]
[Iter 3940/20000] Loss: 0.0007927 (Best: 0.0005713 @iter3898) ([92m↓19.25%[0m) [0.31% of initial]
[Iter 3950/20000] Loss: 0.0008563 (Best: 0.0005713 @iter3898) ([91m↑8.02%[0m) [0.34% of initial]
[Iter 3960/20000] Loss: 0.0008487 (Best: 0.0005713 @iter3898) ([92m↓0.89%[0m) [0.34% of initial]
[Iter 3970/20000] Loss: 0.0007670 (Best: 0.0005713 @iter3898) ([92m↓9.63%[0m) [0.30% of initial]
[Iter 3980/20000] Loss: 0.0011019 (Best: 0.0005713 @iter3898) ([91m↑43.66%[0m) [0.44% of initial]
[Iter 3990/20000] Loss: 0.0008308 (Best: 0.0005713 @iter3898) ([92m↓24.61%[0m) [0.33% of initial]
Iter:3999, L1 loss=0.0009696, Total loss=0.0009028, Time:35
[Iter 4000/20000] Loss: 0.0008134 (Best: 0.0005713 @iter3898) ([92m↓2.09%[0m) [0.32% of initial]
Pruning 290 points (0.2%) from gaussian0 at iteration 4000
Pruning 267 points (0.2%) from gaussian1 at iteration 4000
[Iter 4010/20000] Loss: 0.1477817 (Best: 0.0005713 @iter3898) ([91m↑18069.36%[0m) [58.71% of initial]
[Iter 4020/20000] Loss: 0.1015363 (Best: 0.0005713 @iter3898) ([92m↓31.29%[0m) [40.34% of initial]
[Iter 4030/20000] Loss: 0.0653152 (Best: 0.0005713 @iter3898) ([92m↓35.67%[0m) [25.95% of initial]
[Iter 4040/20000] Loss: 0.0362852 (Best: 0.0005713 @iter3898) ([92m↓44.45%[0m) [14.42% of initial]
[Iter 4050/20000] Loss: 0.0167638 (Best: 0.0005713 @iter3898) ([92m↓53.80%[0m) [6.66% of initial]
[Iter 4060/20000] Loss: 0.0080618 (Best: 0.0005713 @iter3898) ([92m↓51.91%[0m) [3.20% of initial]
[Iter 4070/20000] Loss: 0.0049417 (Best: 0.0005713 @iter3898) ([92m↓38.70%[0m) [1.96% of initial]
[Iter 4080/20000] Loss: 0.0036465 (Best: 0.0005713 @iter3898) ([92m↓26.21%[0m) [1.45% of initial]
[Iter 4090/20000] Loss: 0.0027720 (Best: 0.0005713 @iter3898) ([92m↓23.98%[0m) [1.10% of initial]
Iter:4099, L1 loss=0.002207, Total loss=0.002273, Time:45
[Iter 4100/20000] Loss: 0.0023289 (Best: 0.0005713 @iter3898) ([92m↓15.99%[0m) [0.93% of initial]
[Iter 4110/20000] Loss: 0.0020746 (Best: 0.0005713 @iter3898) ([92m↓10.92%[0m) [0.82% of initial]
[Iter 4120/20000] Loss: 0.0018249 (Best: 0.0005713 @iter3898) ([92m↓12.04%[0m) [0.73% of initial]
[Iter 4130/20000] Loss: 0.0018280 (Best: 0.0005713 @iter3898) ([91m↑0.17%[0m) [0.73% of initial]
[Iter 4140/20000] Loss: 0.0016627 (Best: 0.0005713 @iter3898) ([92m↓9.04%[0m) [0.66% of initial]
[Iter 4150/20000] Loss: 0.0015038 (Best: 0.0005713 @iter3898) ([92m↓9.55%[0m) [0.60% of initial]
[Iter 4160/20000] Loss: 0.0015914 (Best: 0.0005713 @iter3898) ([91m↑5.82%[0m) [0.63% of initial]
[Iter 4170/20000] Loss: 0.0014884 (Best: 0.0005713 @iter3898) ([92m↓6.47%[0m) [0.59% of initial]
[Iter 4180/20000] Loss: 0.0014754 (Best: 0.0005713 @iter3898) ([92m↓0.87%[0m) [0.59% of initial]
[Iter 4190/20000] Loss: 0.0012909 (Best: 0.0005713 @iter3898) ([92m↓12.50%[0m) [0.51% of initial]
Iter:4199, L1 loss=0.001238, Total loss=0.001225, Time:45
[Iter 4200/20000] Loss: 0.0013596 (Best: 0.0005713 @iter3898) ([91m↑5.32%[0m) [0.54% of initial]
[Iter 4210/20000] Loss: 0.0031523 (Best: 0.0005713 @iter3898) ([91m↑131.86%[0m) [1.25% of initial]
[Iter 4220/20000] Loss: 0.0020752 (Best: 0.0005713 @iter3898) ([92m↓34.17%[0m) [0.82% of initial]
[Iter 4230/20000] Loss: 0.0014872 (Best: 0.0005713 @iter3898) ([92m↓28.33%[0m) [0.59% of initial]
[Iter 4240/20000] Loss: 0.0013292 (Best: 0.0005713 @iter3898) ([92m↓10.62%[0m) [0.53% of initial]
[Iter 4250/20000] Loss: 0.0013296 (Best: 0.0005713 @iter3898) ([91m↑0.03%[0m) [0.53% of initial]
[Iter 4260/20000] Loss: 0.0014172 (Best: 0.0005713 @iter3898) ([91m↑6.59%[0m) [0.56% of initial]
[Iter 4270/20000] Loss: 0.0012966 (Best: 0.0005713 @iter3898) ([92m↓8.51%[0m) [0.52% of initial]
[Iter 4280/20000] Loss: 0.0010804 (Best: 0.0005713 @iter3898) ([92m↓16.67%[0m) [0.43% of initial]
[Iter 4290/20000] Loss: 0.0010954 (Best: 0.0005713 @iter3898) ([91m↑1.39%[0m) [0.44% of initial]
Iter:4299, L1 loss=0.001254, Total loss=0.001232, Time:44
[Iter 4300/20000] Loss: 0.0010462 (Best: 0.0005713 @iter3898) ([92m↓4.49%[0m) [0.42% of initial]
[Iter 4310/20000] Loss: 0.0010077 (Best: 0.0005713 @iter3898) ([92m↓3.69%[0m) [0.40% of initial]
[Iter 4320/20000] Loss: 0.0011970 (Best: 0.0005713 @iter3898) ([91m↑18.79%[0m) [0.48% of initial]
[Iter 4330/20000] Loss: 0.0010191 (Best: 0.0005713 @iter3898) ([92m↓14.86%[0m) [0.40% of initial]
[Iter 4340/20000] Loss: 0.0010025 (Best: 0.0005713 @iter3898) ([92m↓1.63%[0m) [0.40% of initial]
[Iter 4350/20000] Loss: 0.0009907 (Best: 0.0005713 @iter3898) ([92m↓1.18%[0m) [0.39% of initial]
[Iter 4360/20000] Loss: 0.0009571 (Best: 0.0005713 @iter3898) ([92m↓3.39%[0m) [0.38% of initial]
[Iter 4370/20000] Loss: 0.0009825 (Best: 0.0005713 @iter3898) ([91m↑2.65%[0m) [0.39% of initial]
[Iter 4380/20000] Loss: 0.0010056 (Best: 0.0005713 @iter3898) ([91m↑2.35%[0m) [0.40% of initial]
[Iter 4390/20000] Loss: 0.0009424 (Best: 0.0005713 @iter3898) ([92m↓6.28%[0m) [0.37% of initial]
Iter:4399, L1 loss=0.0008635, Total loss=0.0008206, Time:46
[Iter 4400/20000] Loss: 0.0009198 (Best: 0.0005713 @iter3898) ([92m↓2.41%[0m) [0.37% of initial]
[Iter 4410/20000] Loss: 0.0021368 (Best: 0.0005713 @iter3898) ([91m↑132.32%[0m) [0.85% of initial]
[Iter 4420/20000] Loss: 0.0014034 (Best: 0.0005713 @iter3898) ([92m↓34.32%[0m) [0.56% of initial]
[Iter 4430/20000] Loss: 0.0012095 (Best: 0.0005713 @iter3898) ([92m↓13.82%[0m) [0.48% of initial]
[Iter 4440/20000] Loss: 0.0010559 (Best: 0.0005713 @iter3898) ([92m↓12.70%[0m) [0.42% of initial]
[Iter 4450/20000] Loss: 0.0009612 (Best: 0.0005713 @iter3898) ([92m↓8.97%[0m) [0.38% of initial]
[Iter 4460/20000] Loss: 0.0009489 (Best: 0.0005713 @iter3898) ([92m↓1.28%[0m) [0.38% of initial]
[Iter 4470/20000] Loss: 0.0010268 (Best: 0.0005713 @iter3898) ([91m↑8.21%[0m) [0.41% of initial]
[Iter 4480/20000] Loss: 0.0009820 (Best: 0.0005713 @iter3898) ([92m↓4.37%[0m) [0.39% of initial]
[Iter 4490/20000] Loss: 0.0009942 (Best: 0.0005713 @iter3898) ([91m↑1.24%[0m) [0.39% of initial]
Iter:4499, L1 loss=0.001054, Total loss=0.001063, Time:54
[Iter 4500/20000] Loss: 0.0011390 (Best: 0.0005713 @iter3898) ([91m↑14.57%[0m) [0.45% of initial]
Pruning 305 points (0.2%) from gaussian0 at iteration 4500
Pruning 332 points (0.2%) from gaussian1 at iteration 4500
[Iter 4510/20000] Loss: 0.0019020 (Best: 0.0005713 @iter3898) ([91m↑66.99%[0m) [0.76% of initial]
[Iter 4520/20000] Loss: 0.0015301 (Best: 0.0005713 @iter3898) ([92m↓19.56%[0m) [0.61% of initial]
[Iter 4530/20000] Loss: 0.0014258 (Best: 0.0005713 @iter3898) ([92m↓6.82%[0m) [0.57% of initial]
[Iter 4540/20000] Loss: 0.0011573 (Best: 0.0005713 @iter3898) ([92m↓18.83%[0m) [0.46% of initial]
[Iter 4550/20000] Loss: 0.0010318 (Best: 0.0005713 @iter3898) ([92m↓10.85%[0m) [0.41% of initial]
[Iter 4560/20000] Loss: 0.0010342 (Best: 0.0005713 @iter3898) ([91m↑0.23%[0m) [0.41% of initial]
[Iter 4570/20000] Loss: 0.0008957 (Best: 0.0005713 @iter3898) ([92m↓13.39%[0m) [0.36% of initial]
[Iter 4580/20000] Loss: 0.0008743 (Best: 0.0005713 @iter3898) ([92m↓2.40%[0m) [0.35% of initial]
[Iter 4590/20000] Loss: 0.0009931 (Best: 0.0005713 @iter3898) ([91m↑13.60%[0m) [0.39% of initial]
Iter:4599, L1 loss=0.0009914, Total loss=0.000938, Time:45
[Iter 4600/20000] Loss: 0.0009168 (Best: 0.0005713 @iter3898) ([92m↓7.68%[0m) [0.36% of initial]
[Iter 4610/20000] Loss: 0.0022374 (Best: 0.0005713 @iter3898) ([91m↑144.03%[0m) [0.89% of initial]
[Iter 4620/20000] Loss: 0.0015945 (Best: 0.0005713 @iter3898) ([92m↓28.73%[0m) [0.63% of initial]
[Iter 4630/20000] Loss: 0.0011997 (Best: 0.0005713 @iter3898) ([92m↓24.76%[0m) [0.48% of initial]
[Iter 4640/20000] Loss: 0.0010656 (Best: 0.0005713 @iter3898) ([92m↓11.17%[0m) [0.42% of initial]
[Iter 4650/20000] Loss: 0.0009561 (Best: 0.0005713 @iter3898) ([92m↓10.28%[0m) [0.38% of initial]
[Iter 4660/20000] Loss: 0.0008510 (Best: 0.0005713 @iter3898) ([92m↓10.99%[0m) [0.34% of initial]
[Iter 4670/20000] Loss: 0.0008291 (Best: 0.0005713 @iter3898) ([92m↓2.58%[0m) [0.33% of initial]
[Iter 4680/20000] Loss: 0.0008152 (Best: 0.0005713 @iter3898) ([92m↓1.67%[0m) [0.32% of initial]
[Iter 4690/20000] Loss: 0.0007778 (Best: 0.0005713 @iter3898) ([92m↓4.59%[0m) [0.31% of initial]
Iter:4699, L1 loss=0.0008802, Total loss=0.0008222, Time:47
[Iter 4700/20000] Loss: 0.0008479 (Best: 0.0005713 @iter3898) ([91m↑9.02%[0m) [0.34% of initial]
[Iter 4710/20000] Loss: 0.0007776 (Best: 0.0005713 @iter3898) ([92m↓8.29%[0m) [0.31% of initial]
[Iter 4720/20000] Loss: 0.0008517 (Best: 0.0005713 @iter3898) ([91m↑9.53%[0m) [0.34% of initial]
[Iter 4730/20000] Loss: 0.0008358 (Best: 0.0005713 @iter3898) ([92m↓1.87%[0m) [0.33% of initial]
[Iter 4740/20000] Loss: 0.0009186 (Best: 0.0005713 @iter3898) ([91m↑9.90%[0m) [0.36% of initial]
[Iter 4750/20000] Loss: 0.0009026 (Best: 0.0005713 @iter3898) ([92m↓1.73%[0m) [0.36% of initial]
[Iter 4760/20000] Loss: 0.0008223 (Best: 0.0005713 @iter3898) ([92m↓8.90%[0m) [0.33% of initial]
[Iter 4770/20000] Loss: 0.0008804 (Best: 0.0005713 @iter3898) ([91m↑7.07%[0m) [0.35% of initial]
[Iter 4780/20000] Loss: 0.0009518 (Best: 0.0005713 @iter3898) ([91m↑8.10%[0m) [0.38% of initial]
[Iter 4790/20000] Loss: 0.0008473 (Best: 0.0005713 @iter3898) ([92m↓10.98%[0m) [0.34% of initial]
Iter:4799, L1 loss=0.0008739, Total loss=0.0008397, Time:48
[Iter 4800/20000] Loss: 0.0009600 (Best: 0.0005713 @iter3898) ([91m↑13.30%[0m) [0.38% of initial]
[Iter 4810/20000] Loss: 0.0018527 (Best: 0.0005713 @iter3898) ([91m↑92.98%[0m) [0.74% of initial]
[Iter 4820/20000] Loss: 0.0013310 (Best: 0.0005713 @iter3898) ([92m↓28.16%[0m) [0.53% of initial]
[Iter 4830/20000] Loss: 0.0011381 (Best: 0.0005713 @iter3898) ([92m↓14.49%[0m) [0.45% of initial]
[Iter 4840/20000] Loss: 0.0009326 (Best: 0.0005713 @iter3898) ([92m↓18.06%[0m) [0.37% of initial]
[Iter 4850/20000] Loss: 0.0007886 (Best: 0.0005713 @iter3898) ([92m↓15.44%[0m) [0.31% of initial]
[Iter 4860/20000] Loss: 0.0008309 (Best: 0.0005713 @iter3898) ([91m↑5.36%[0m) [0.33% of initial]
[Iter 4870/20000] Loss: 0.0007643 (Best: 0.0005713 @iter3898) ([92m↓8.01%[0m) [0.30% of initial]
[Iter 4880/20000] Loss: 0.0008306 (Best: 0.0005713 @iter3898) ([91m↑8.67%[0m) [0.33% of initial]
[Iter 4890/20000] Loss: 0.0007652 (Best: 0.0005713 @iter3898) ([92m↓7.87%[0m) [0.30% of initial]
Iter:4899, L1 loss=0.0009202, Total loss=0.0009126, Time:48
[Iter 4900/20000] Loss: 0.0007753 (Best: 0.0005713 @iter3898) ([91m↑1.31%[0m) [0.31% of initial]
[Iter 4910/20000] Loss: 0.0009521 (Best: 0.0005713 @iter3898) ([91m↑22.80%[0m) [0.38% of initial]
[Iter 4920/20000] Loss: 0.0008366 (Best: 0.0005713 @iter3898) ([92m↓12.13%[0m) [0.33% of initial]
[Iter 4930/20000] Loss: 0.0007530 (Best: 0.0005713 @iter3898) ([92m↓9.99%[0m) [0.30% of initial]
[Iter 4940/20000] Loss: 0.0007817 (Best: 0.0005713 @iter3898) ([91m↑3.81%[0m) [0.31% of initial]
[Iter 4950/20000] Loss: 0.0006865 (Best: 0.0005713 @iter3898) ([92m↓12.18%[0m) [0.27% of initial]
[Iter 4960/20000] Loss: 0.0007264 (Best: 0.0005713 @iter3898) ([91m↑5.82%[0m) [0.29% of initial]
[Iter 4970/20000] Loss: 0.0007555 (Best: 0.0005713 @iter3898) ([91m↑4.01%[0m) [0.30% of initial]
[Iter 4980/20000] Loss: 0.0007758 (Best: 0.0005713 @iter3898) ([91m↑2.68%[0m) [0.31% of initial]
[Iter 4990/20000] Loss: 0.0007140 (Best: 0.0005713 @iter3898) ([92m↓7.97%[0m) [0.28% of initial]
Iter:4999, L1 loss=0.0007221, Total loss=0.0006827, Time:48
[Iter 5000/20000] Loss: 0.0006749 (Best: 0.0005713 @iter3898) ([92m↓5.47%[0m) [0.27% of initial]
Pruning 163 points (0.1%) from gaussian0 at iteration 5000
Pruning 177 points (0.1%) from gaussian1 at iteration 5000
[Iter 5010/20000] Loss: 0.0021083 (Best: 0.0005713 @iter3898) ([91m↑212.40%[0m) [0.84% of initial]
[Iter 5020/20000] Loss: 0.0014721 (Best: 0.0005713 @iter3898) ([92m↓30.17%[0m) [0.58% of initial]
[Iter 5030/20000] Loss: 0.0010397 (Best: 0.0005713 @iter3898) ([92m↓29.38%[0m) [0.41% of initial]
[Iter 5040/20000] Loss: 0.0010264 (Best: 0.0005713 @iter3898) ([92m↓1.28%[0m) [0.41% of initial]
[Iter 5050/20000] Loss: 0.0009182 (Best: 0.0005713 @iter3898) ([92m↓10.54%[0m) [0.36% of initial]
[Iter 5060/20000] Loss: 0.0007454 (Best: 0.0005713 @iter3898) ([92m↓18.82%[0m) [0.30% of initial]
[Iter 5070/20000] Loss: 0.0008158 (Best: 0.0005713 @iter3898) ([91m↑9.45%[0m) [0.32% of initial]
[Iter 5080/20000] Loss: 0.0007165 (Best: 0.0005713 @iter3898) ([92m↓12.17%[0m) [0.28% of initial]
[Iter 5090/20000] Loss: 0.0007579 (Best: 0.0005713 @iter3898) ([91m↑5.77%[0m) [0.30% of initial]
Iter:5099, L1 loss=0.0008341, Total loss=0.0007501, Time:55
[Iter 5100/20000] Loss: 0.0008041 (Best: 0.0005713 @iter3898) ([91m↑6.09%[0m) [0.32% of initial]
[Iter 5110/20000] Loss: 0.0007815 (Best: 0.0005713 @iter3898) ([92m↓2.80%[0m) [0.31% of initial]
[Iter 5120/20000] Loss: 0.0007789 (Best: 0.0005713 @iter3898) ([92m↓0.34%[0m) [0.31% of initial]
[Iter 5130/20000] Loss: 0.0008011 (Best: 0.0005713 @iter3898) ([91m↑2.85%[0m) [0.32% of initial]
[Iter 5140/20000] Loss: 0.0006939 (Best: 0.0005713 @iter3898) ([92m↓13.39%[0m) [0.28% of initial]
[Iter 5150/20000] Loss: 0.0007037 (Best: 0.0005713 @iter3898) ([91m↑1.42%[0m) [0.28% of initial]
[Iter 5160/20000] Loss: 0.0006953 (Best: 0.0005713 @iter3898) ([92m↓1.19%[0m) [0.28% of initial]
[Iter 5170/20000] Loss: 0.0007525 (Best: 0.0005713 @iter3898) ([91m↑8.22%[0m) [0.30% of initial]
[Iter 5180/20000] Loss: 0.0006984 (Best: 0.0005713 @iter3898) ([92m↓7.19%[0m) [0.28% of initial]
[Iter 5190/20000] Loss: 0.0007125 (Best: 0.0005713 @iter3898) ([91m↑2.03%[0m) [0.28% of initial]
Iter:5199, L1 loss=0.0008094, Total loss=0.0007654, Time:55
[Iter 5200/20000] Loss: 0.0006988 (Best: 0.0005713 @iter3898) ([92m↓1.92%[0m) [0.28% of initial]
[Iter 5210/20000] Loss: 0.0018905 (Best: 0.0005713 @iter3898) ([91m↑170.53%[0m) [0.75% of initial]
[Iter 5220/20000] Loss: 0.0013371 (Best: 0.0005713 @iter3898) ([92m↓29.27%[0m) [0.53% of initial]
[Iter 5230/20000] Loss: 0.0010426 (Best: 0.0005713 @iter3898) ([92m↓22.02%[0m) [0.41% of initial]
[Iter 5240/20000] Loss: 0.0008051 (Best: 0.0005713 @iter3898) ([92m↓22.79%[0m) [0.32% of initial]
[Iter 5250/20000] Loss: 0.0010460 (Best: 0.0005713 @iter3898) ([91m↑29.92%[0m) [0.42% of initial]
[Iter 5260/20000] Loss: 0.0008546 (Best: 0.0005713 @iter3898) ([92m↓18.30%[0m) [0.34% of initial]
[Iter 5270/20000] Loss: 0.0007809 (Best: 0.0005713 @iter3898) ([92m↓8.62%[0m) [0.31% of initial]
[Iter 5280/20000] Loss: 0.0008438 (Best: 0.0005713 @iter3898) ([91m↑8.06%[0m) [0.34% of initial]
[Iter 5290/20000] Loss: 0.0007993 (Best: 0.0005713 @iter3898) ([92m↓5.28%[0m) [0.32% of initial]
Iter:5299, L1 loss=0.0008891, Total loss=0.0008586, Time:51
[Iter 5300/20000] Loss: 0.0008976 (Best: 0.0005713 @iter3898) ([91m↑12.30%[0m) [0.36% of initial]
[Iter 5310/20000] Loss: 0.0008824 (Best: 0.0005713 @iter3898) ([92m↓1.69%[0m) [0.35% of initial]
[Iter 5320/20000] Loss: 0.0007628 (Best: 0.0005713 @iter3898) ([92m↓13.55%[0m) [0.30% of initial]
[Iter 5330/20000] Loss: 0.0006530 (Best: 0.0005713 @iter3898) ([92m↓14.40%[0m) [0.26% of initial]
[Iter 5340/20000] Loss: 0.0006849 (Best: 0.0005713 @iter3898) ([91m↑4.88%[0m) [0.27% of initial]
[Iter 5350/20000] Loss: 0.0007120 (Best: 0.0005584 @iter5344) ([91m↑3.96%[0m) [0.28% of initial]
[Iter 5360/20000] Loss: 0.0007116 (Best: 0.0005584 @iter5344) ([92m↓0.06%[0m) [0.28% of initial]
[Iter 5370/20000] Loss: 0.0007327 (Best: 0.0005584 @iter5344) ([91m↑2.97%[0m) [0.29% of initial]
[Iter 5380/20000] Loss: 0.0007206 (Best: 0.0005584 @iter5344) ([92m↓1.65%[0m) [0.29% of initial]
[Iter 5390/20000] Loss: 0.0007455 (Best: 0.0005584 @iter5344) ([91m↑3.45%[0m) [0.30% of initial]
Iter:5399, L1 loss=0.0006963, Total loss=0.0006514, Time:47
[Iter 5400/20000] Loss: 0.0007460 (Best: 0.0005584 @iter5344) ([91m↑0.06%[0m) [0.30% of initial]
[Iter 5410/20000] Loss: 0.0015834 (Best: 0.0005584 @iter5344) ([91m↑112.27%[0m) [0.63% of initial]
[Iter 5420/20000] Loss: 0.0012076 (Best: 0.0005584 @iter5344) ([92m↓23.73%[0m) [0.48% of initial]
[Iter 5430/20000] Loss: 0.0008601 (Best: 0.0005584 @iter5344) ([92m↓28.77%[0m) [0.34% of initial]
[Iter 5440/20000] Loss: 0.0008133 (Best: 0.0005584 @iter5344) ([92m↓5.45%[0m) [0.32% of initial]
[Iter 5450/20000] Loss: 0.0007040 (Best: 0.0005584 @iter5344) ([92m↓13.44%[0m) [0.28% of initial]
[Iter 5460/20000] Loss: 0.0007824 (Best: 0.0005584 @iter5344) ([91m↑11.15%[0m) [0.31% of initial]
[Iter 5470/20000] Loss: 0.0006712 (Best: 0.0005584 @iter5344) ([92m↓14.22%[0m) [0.27% of initial]
[Iter 5480/20000] Loss: 0.0006388 (Best: 0.0005432 @iter5476) ([92m↓4.83%[0m) [0.25% of initial]
[Iter 5490/20000] Loss: 0.0006700 (Best: 0.0005432 @iter5476) ([91m↑4.89%[0m) [0.27% of initial]
Iter:5499, L1 loss=0.0007295, Total loss=0.0006957, Time:50
[Iter 5500/20000] Loss: 0.0006253 (Best: 0.0005432 @iter5476) ([92m↓6.67%[0m) [0.25% of initial]
Pruning 108 points (0.1%) from gaussian0 at iteration 5500
Pruning 102 points (0.1%) from gaussian1 at iteration 5500
[Iter 5510/20000] Loss: 0.0011565 (Best: 0.0005432 @iter5476) ([91m↑84.94%[0m) [0.46% of initial]
[Iter 5520/20000] Loss: 0.0008792 (Best: 0.0005432 @iter5476) ([92m↓23.98%[0m) [0.35% of initial]
[Iter 5530/20000] Loss: 0.0007964 (Best: 0.0005432 @iter5476) ([92m↓9.42%[0m) [0.32% of initial]
[Iter 5540/20000] Loss: 0.0007236 (Best: 0.0005432 @iter5476) ([92m↓9.14%[0m) [0.29% of initial]
[Iter 5550/20000] Loss: 0.0007056 (Best: 0.0005432 @iter5476) ([92m↓2.48%[0m) [0.28% of initial]
[Iter 5560/20000] Loss: 0.0006535 (Best: 0.0005432 @iter5476) ([92m↓7.38%[0m) [0.26% of initial]
[Iter 5570/20000] Loss: 0.0006581 (Best: 0.0005432 @iter5476) ([91m↑0.70%[0m) [0.26% of initial]
[Iter 5580/20000] Loss: 0.0007672 (Best: 0.0005432 @iter5476) ([91m↑16.59%[0m) [0.30% of initial]
[Iter 5590/20000] Loss: 0.0008338 (Best: 0.0005432 @iter5476) ([91m↑8.67%[0m) [0.33% of initial]
Iter:5599, L1 loss=0.000682, Total loss=0.0006424, Time:52
[Iter 5600/20000] Loss: 0.0006558 (Best: 0.0005432 @iter5476) ([92m↓21.35%[0m) [0.26% of initial]
[Iter 5610/20000] Loss: 0.0016876 (Best: 0.0005432 @iter5476) ([91m↑157.35%[0m) [0.67% of initial]
[Iter 5620/20000] Loss: 0.0010681 (Best: 0.0005432 @iter5476) ([92m↓36.71%[0m) [0.42% of initial]
[Iter 5630/20000] Loss: 0.0008696 (Best: 0.0005432 @iter5476) ([92m↓18.58%[0m) [0.35% of initial]
[Iter 5640/20000] Loss: 0.0007997 (Best: 0.0005432 @iter5476) ([92m↓8.04%[0m) [0.32% of initial]
[Iter 5650/20000] Loss: 0.0006998 (Best: 0.0005432 @iter5476) ([92m↓12.49%[0m) [0.28% of initial]
[Iter 5660/20000] Loss: 0.0006858 (Best: 0.0005432 @iter5476) ([92m↓2.00%[0m) [0.27% of initial]
[Iter 5670/20000] Loss: 0.0006845 (Best: 0.0005432 @iter5476) ([92m↓0.19%[0m) [0.27% of initial]
[Iter 5680/20000] Loss: 0.0006346 (Best: 0.0005432 @iter5476) ([92m↓7.29%[0m) [0.25% of initial]
[Iter 5690/20000] Loss: 0.0006871 (Best: 0.0005432 @iter5476) ([91m↑8.27%[0m) [0.27% of initial]
Iter:5699, L1 loss=0.0006503, Total loss=0.0005982, Time:48
[Iter 5700/20000] Loss: 0.0005862 (Best: 0.0005432 @iter5476) ([92m↓14.69%[0m) [0.23% of initial]
[Iter 5710/20000] Loss: 0.0007414 (Best: 0.0005153 @iter5701) ([91m↑26.49%[0m) [0.29% of initial]
[Iter 5720/20000] Loss: 0.0006569 (Best: 0.0005153 @iter5701) ([92m↓11.40%[0m) [0.26% of initial]
[Iter 5730/20000] Loss: 0.0006735 (Best: 0.0005153 @iter5701) ([91m↑2.52%[0m) [0.27% of initial]
[Iter 5740/20000] Loss: 0.0005865 (Best: 0.0005153 @iter5701) ([92m↓12.92%[0m) [0.23% of initial]
[Iter 5750/20000] Loss: 0.0006015 (Best: 0.0005153 @iter5701) ([91m↑2.57%[0m) [0.24% of initial]
[Iter 5760/20000] Loss: 0.0006010 (Best: 0.0005153 @iter5701) ([92m↓0.09%[0m) [0.24% of initial]
[Iter 5770/20000] Loss: 0.0005399 (Best: 0.0004888 @iter5770) ([92m↓10.16%[0m) [0.21% of initial]
[Iter 5780/20000] Loss: 0.0005421 (Best: 0.0004888 @iter5770) ([91m↑0.41%[0m) [0.22% of initial]
[Iter 5790/20000] Loss: 0.0005856 (Best: 0.0004817 @iter5788) ([91m↑8.02%[0m) [0.23% of initial]
Iter:5799, L1 loss=0.0006369, Total loss=0.0005819, Time:49
[Iter 5800/20000] Loss: 0.0005664 (Best: 0.0004582 @iter5797) ([92m↓3.29%[0m) [0.23% of initial]
[Iter 5810/20000] Loss: 0.0013237 (Best: 0.0004582 @iter5797) ([91m↑133.73%[0m) [0.53% of initial]
[Iter 5820/20000] Loss: 0.0010204 (Best: 0.0004582 @iter5797) ([92m↓22.92%[0m) [0.41% of initial]
[Iter 5830/20000] Loss: 0.0008028 (Best: 0.0004582 @iter5797) ([92m↓21.32%[0m) [0.32% of initial]
[Iter 5840/20000] Loss: 0.0007084 (Best: 0.0004582 @iter5797) ([92m↓11.75%[0m) [0.28% of initial]
[Iter 5850/20000] Loss: 0.0007101 (Best: 0.0004582 @iter5797) ([91m↑0.23%[0m) [0.28% of initial]
[Iter 5860/20000] Loss: 0.0005975 (Best: 0.0004582 @iter5797) ([92m↓15.86%[0m) [0.24% of initial]
[Iter 5870/20000] Loss: 0.0006909 (Best: 0.0004582 @iter5797) ([91m↑15.64%[0m) [0.27% of initial]
[Iter 5880/20000] Loss: 0.0006349 (Best: 0.0004582 @iter5797) ([92m↓8.11%[0m) [0.25% of initial]
[Iter 5890/20000] Loss: 0.0005916 (Best: 0.0004582 @iter5797) ([92m↓6.82%[0m) [0.24% of initial]
Iter:5899, L1 loss=0.0006353, Total loss=0.0005696, Time:48
[Iter 5900/20000] Loss: 0.0005792 (Best: 0.0004582 @iter5797) ([92m↓2.10%[0m) [0.23% of initial]
[Iter 5910/20000] Loss: 0.0006113 (Best: 0.0004582 @iter5797) ([91m↑5.54%[0m) [0.24% of initial]
[Iter 5920/20000] Loss: 0.0005862 (Best: 0.0004582 @iter5797) ([92m↓4.11%[0m) [0.23% of initial]
[Iter 5930/20000] Loss: 0.0005013 (Best: 0.0004582 @iter5797) ([92m↓14.48%[0m) [0.20% of initial]
[Iter 5940/20000] Loss: 0.0006545 (Best: 0.0004582 @iter5797) ([91m↑30.56%[0m) [0.26% of initial]
[Iter 5950/20000] Loss: 0.0005378 (Best: 0.0004582 @iter5797) ([92m↓17.83%[0m) [0.21% of initial]
[Iter 5960/20000] Loss: 0.0005798 (Best: 0.0004582 @iter5797) ([91m↑7.82%[0m) [0.23% of initial]
[Iter 5970/20000] Loss: 0.0006674 (Best: 0.0004582 @iter5797) ([91m↑15.11%[0m) [0.27% of initial]
[Iter 5980/20000] Loss: 0.0005982 (Best: 0.0004582 @iter5797) ([92m↓10.37%[0m) [0.24% of initial]
[Iter 5990/20000] Loss: 0.0006011 (Best: 0.0004582 @iter5797) ([91m↑0.48%[0m) [0.24% of initial]
Iter:5999, L1 loss=0.0006825, Total loss=0.0006127, Time:50
[Iter 6000/20000] Loss: 0.0006216 (Best: 0.0004582 @iter5797) ([91m↑3.42%[0m) [0.25% of initial]
Pruning 86 points (0.0%) from gaussian0 at iteration 6000
Pruning 106 points (0.1%) from gaussian1 at iteration 6000
[Iter 6010/20000] Loss: 0.0019498 (Best: 0.0004582 @iter5797) ([91m↑213.64%[0m) [0.77% of initial]
[Iter 6020/20000] Loss: 0.0012768 (Best: 0.0004582 @iter5797) ([92m↓34.52%[0m) [0.51% of initial]
[Iter 6030/20000] Loss: 0.0008795 (Best: 0.0004582 @iter5797) ([92m↓31.11%[0m) [0.35% of initial]
[Iter 6040/20000] Loss: 0.0006797 (Best: 0.0004582 @iter5797) ([92m↓22.72%[0m) [0.27% of initial]
[Iter 6050/20000] Loss: 0.0006211 (Best: 0.0004582 @iter5797) ([92m↓8.62%[0m) [0.25% of initial]
[Iter 6060/20000] Loss: 0.0006486 (Best: 0.0004582 @iter5797) ([91m↑4.42%[0m) [0.26% of initial]
[Iter 6070/20000] Loss: 0.0006478 (Best: 0.0004582 @iter5797) ([92m↓0.12%[0m) [0.26% of initial]
[Iter 6080/20000] Loss: 0.0006342 (Best: 0.0004582 @iter5797) ([92m↓2.10%[0m) [0.25% of initial]
[Iter 6090/20000] Loss: 0.0005753 (Best: 0.0004582 @iter5797) ([92m↓9.28%[0m) [0.23% of initial]
Iter:6099, L1 loss=0.000615, Total loss=0.0005483, Time:30
[Iter 6100/20000] Loss: 0.0005778 (Best: 0.0004582 @iter5797) ([91m↑0.44%[0m) [0.23% of initial]
[Iter 6110/20000] Loss: 0.0005761 (Best: 0.0004582 @iter5797) ([92m↓0.30%[0m) [0.23% of initial]
[Iter 6120/20000] Loss: 0.0006407 (Best: 0.0004582 @iter5797) ([91m↑11.22%[0m) [0.25% of initial]
[Iter 6130/20000] Loss: 0.0006089 (Best: 0.0004582 @iter5797) ([92m↓4.97%[0m) [0.24% of initial]
[Iter 6140/20000] Loss: 0.0005319 (Best: 0.0004582 @iter5797) ([92m↓12.65%[0m) [0.21% of initial]
[Iter 6150/20000] Loss: 0.0005533 (Best: 0.0004582 @iter5797) ([91m↑4.04%[0m) [0.22% of initial]
[Iter 6160/20000] Loss: 0.0005253 (Best: 0.0004582 @iter5797) ([92m↓5.06%[0m) [0.21% of initial]
[Iter 6170/20000] Loss: 0.0005456 (Best: 0.0004582 @iter5797) ([91m↑3.85%[0m) [0.22% of initial]
[Iter 6180/20000] Loss: 0.0006215 (Best: 0.0004582 @iter5797) ([91m↑13.92%[0m) [0.25% of initial]
[Iter 6190/20000] Loss: 0.0005269 (Best: 0.0004582 @iter5797) ([92m↓15.22%[0m) [0.21% of initial]
Iter:6199, L1 loss=0.0005415, Total loss=0.0004854, Time:61
[Iter 6200/20000] Loss: 0.0005364 (Best: 0.0004582 @iter5797) ([91m↑1.80%[0m) [0.21% of initial]
[Iter 6210/20000] Loss: 0.0013782 (Best: 0.0004582 @iter5797) ([91m↑156.93%[0m) [0.55% of initial]
[Iter 6220/20000] Loss: 0.0009212 (Best: 0.0004582 @iter5797) ([92m↓33.16%[0m) [0.37% of initial]
[Iter 6230/20000] Loss: 0.0008491 (Best: 0.0004582 @iter5797) ([92m↓7.82%[0m) [0.34% of initial]
[Iter 6240/20000] Loss: 0.0006814 (Best: 0.0004582 @iter5797) ([92m↓19.76%[0m) [0.27% of initial]
[Iter 6250/20000] Loss: 0.0006081 (Best: 0.0004582 @iter5797) ([92m↓10.74%[0m) [0.24% of initial]
[Iter 6260/20000] Loss: 0.0006576 (Best: 0.0004582 @iter5797) ([91m↑8.13%[0m) [0.26% of initial]
[Iter 6270/20000] Loss: 0.0006023 (Best: 0.0004582 @iter5797) ([92m↓8.41%[0m) [0.24% of initial]
[Iter 6280/20000] Loss: 0.0006382 (Best: 0.0004582 @iter5797) ([91m↑5.96%[0m) [0.25% of initial]
[Iter 6290/20000] Loss: 0.0005829 (Best: 0.0004582 @iter5797) ([92m↓8.65%[0m) [0.23% of initial]
Iter:6299, L1 loss=0.0007262, Total loss=0.0006617, Time:58
[Iter 6300/20000] Loss: 0.0007641 (Best: 0.0004582 @iter5797) ([91m↑31.07%[0m) [0.30% of initial]
[Iter 6310/20000] Loss: 0.0006668 (Best: 0.0004582 @iter5797) ([92m↓12.72%[0m) [0.26% of initial]
[Iter 6320/20000] Loss: 0.0006655 (Best: 0.0004582 @iter5797) ([92m↓0.20%[0m) [0.26% of initial]
[Iter 6330/20000] Loss: 0.0006280 (Best: 0.0004582 @iter5797) ([92m↓5.64%[0m) [0.25% of initial]
[Iter 6340/20000] Loss: 0.0005130 (Best: 0.0004565 @iter6340) ([92m↓18.31%[0m) [0.20% of initial]
[Iter 6350/20000] Loss: 0.0005146 (Best: 0.0004565 @iter6340) ([91m↑0.32%[0m) [0.20% of initial]
[Iter 6360/20000] Loss: 0.0005842 (Best: 0.0004565 @iter6340) ([91m↑13.51%[0m) [0.23% of initial]
[Iter 6370/20000] Loss: 0.0005726 (Best: 0.0004565 @iter6340) ([92m↓1.98%[0m) [0.23% of initial]
[Iter 6380/20000] Loss: 0.0005233 (Best: 0.0004565 @iter6340) ([92m↓8.60%[0m) [0.21% of initial]
[Iter 6390/20000] Loss: 0.0005462 (Best: 0.0004545 @iter6382) ([91m↑4.38%[0m) [0.22% of initial]
Iter:6399, L1 loss=0.0005893, Total loss=0.000519, Time:49
[Iter 6400/20000] Loss: 0.0005784 (Best: 0.0004545 @iter6382) ([91m↑5.89%[0m) [0.23% of initial]
[Iter 6410/20000] Loss: 0.0012549 (Best: 0.0004545 @iter6382) ([91m↑116.95%[0m) [0.50% of initial]
[Iter 6420/20000] Loss: 0.0010779 (Best: 0.0004545 @iter6382) ([92m↓14.11%[0m) [0.43% of initial]
[Iter 6430/20000] Loss: 0.0009466 (Best: 0.0004545 @iter6382) ([92m↓12.18%[0m) [0.38% of initial]
[Iter 6440/20000] Loss: 0.0007620 (Best: 0.0004545 @iter6382) ([92m↓19.49%[0m) [0.30% of initial]
[Iter 6450/20000] Loss: 0.0006582 (Best: 0.0004545 @iter6382) ([92m↓13.63%[0m) [0.26% of initial]
[Iter 6460/20000] Loss: 0.0005722 (Best: 0.0004545 @iter6382) ([92m↓13.06%[0m) [0.23% of initial]
[Iter 6470/20000] Loss: 0.0005546 (Best: 0.0004545 @iter6382) ([92m↓3.07%[0m) [0.22% of initial]
[Iter 6480/20000] Loss: 0.0005594 (Best: 0.0004545 @iter6382) ([91m↑0.85%[0m) [0.22% of initial]
[Iter 6490/20000] Loss: 0.0005227 (Best: 0.0004545 @iter6382) ([92m↓6.55%[0m) [0.21% of initial]
Iter:6499, L1 loss=0.0006891, Total loss=0.000614, Time:50
[Iter 6500/20000] Loss: 0.0006037 (Best: 0.0004545 @iter6382) ([91m↑15.50%[0m) [0.24% of initial]
Pruning 73 points (0.0%) from gaussian0 at iteration 6500
Pruning 80 points (0.0%) from gaussian1 at iteration 6500
[Iter 6510/20000] Loss: 0.0013431 (Best: 0.0004545 @iter6382) ([91m↑122.46%[0m) [0.53% of initial]
[Iter 6520/20000] Loss: 0.0008439 (Best: 0.0004545 @iter6382) ([92m↓37.17%[0m) [0.34% of initial]
[Iter 6530/20000] Loss: 0.0007662 (Best: 0.0004545 @iter6382) ([92m↓9.20%[0m) [0.30% of initial]
[Iter 6540/20000] Loss: 0.0006092 (Best: 0.0004545 @iter6382) ([92m↓20.50%[0m) [0.24% of initial]
[Iter 6550/20000] Loss: 0.0005515 (Best: 0.0004545 @iter6382) ([92m↓9.47%[0m) [0.22% of initial]
[Iter 6560/20000] Loss: 0.0004734 (Best: 0.0004458 @iter6559) ([92m↓14.17%[0m) [0.19% of initial]
[Iter 6570/20000] Loss: 0.0005419 (Best: 0.0004247 @iter6568) ([91m↑14.48%[0m) [0.22% of initial]
[Iter 6580/20000] Loss: 0.0005515 (Best: 0.0004247 @iter6568) ([91m↑1.78%[0m) [0.22% of initial]
[Iter 6590/20000] Loss: 0.0004720 (Best: 0.0004247 @iter6568) ([92m↓14.43%[0m) [0.19% of initial]
Iter:6599, L1 loss=0.000562, Total loss=0.0004983, Time:47
[Iter 6600/20000] Loss: 0.0004981 (Best: 0.0004236 @iter6592) ([91m↑5.53%[0m) [0.20% of initial]
[Iter 6610/20000] Loss: 0.0012087 (Best: 0.0004236 @iter6592) ([91m↑142.67%[0m) [0.48% of initial]
[Iter 6620/20000] Loss: 0.0008541 (Best: 0.0004236 @iter6592) ([92m↓29.34%[0m) [0.34% of initial]
[Iter 6630/20000] Loss: 0.0006479 (Best: 0.0004236 @iter6592) ([92m↓24.14%[0m) [0.26% of initial]
[Iter 6640/20000] Loss: 0.0005454 (Best: 0.0004236 @iter6592) ([92m↓15.83%[0m) [0.22% of initial]
[Iter 6650/20000] Loss: 0.0005271 (Best: 0.0004236 @iter6592) ([92m↓3.34%[0m) [0.21% of initial]
[Iter 6660/20000] Loss: 0.0005849 (Best: 0.0004236 @iter6592) ([91m↑10.96%[0m) [0.23% of initial]
[Iter 6670/20000] Loss: 0.0005734 (Best: 0.0004236 @iter6592) ([92m↓1.97%[0m) [0.23% of initial]
[Iter 6680/20000] Loss: 0.0005992 (Best: 0.0004236 @iter6592) ([91m↑4.50%[0m) [0.24% of initial]
[Iter 6690/20000] Loss: 0.0005523 (Best: 0.0004236 @iter6592) ([92m↓7.83%[0m) [0.22% of initial]
Iter:6699, L1 loss=0.0006071, Total loss=0.0005446, Time:48
[Iter 6700/20000] Loss: 0.0005219 (Best: 0.0004236 @iter6592) ([92m↓5.50%[0m) [0.21% of initial]
[Iter 6710/20000] Loss: 0.0005765 (Best: 0.0004236 @iter6592) ([91m↑10.45%[0m) [0.23% of initial]
[Iter 6720/20000] Loss: 0.0005199 (Best: 0.0004236 @iter6592) ([92m↓9.82%[0m) [0.21% of initial]
[Iter 6730/20000] Loss: 0.0004667 (Best: 0.0004236 @iter6592) ([92m↓10.22%[0m) [0.19% of initial]
[Iter 6740/20000] Loss: 0.0004998 (Best: 0.0004236 @iter6592) ([91m↑7.08%[0m) [0.20% of initial]
[Iter 6750/20000] Loss: 0.0005233 (Best: 0.0004236 @iter6592) ([91m↑4.71%[0m) [0.21% of initial]
[Iter 6760/20000] Loss: 0.0004925 (Best: 0.0004236 @iter6592) ([92m↓5.89%[0m) [0.20% of initial]
[Iter 6770/20000] Loss: 0.0004817 (Best: 0.0004236 @iter6592) ([92m↓2.19%[0m) [0.19% of initial]
[Iter 6780/20000] Loss: 0.0004402 (Best: 0.0004179 @iter6780) ([92m↓8.62%[0m) [0.17% of initial]
[Iter 6790/20000] Loss: 0.0005075 (Best: 0.0003851 @iter6781) ([91m↑15.29%[0m) [0.20% of initial]
Iter:6799, L1 loss=0.0004778, Total loss=0.0004237, Time:49
[Iter 6800/20000] Loss: 0.0004400 (Best: 0.0003851 @iter6781) ([92m↓13.30%[0m) [0.17% of initial]
[Iter 6810/20000] Loss: 0.0010739 (Best: 0.0003851 @iter6781) ([91m↑144.05%[0m) [0.43% of initial]
[Iter 6820/20000] Loss: 0.0008993 (Best: 0.0003851 @iter6781) ([92m↓16.25%[0m) [0.36% of initial]
[Iter 6830/20000] Loss: 0.0006556 (Best: 0.0003851 @iter6781) ([92m↓27.10%[0m) [0.26% of initial]
[Iter 6840/20000] Loss: 0.0005668 (Best: 0.0003851 @iter6781) ([92m↓13.54%[0m) [0.23% of initial]
[Iter 6850/20000] Loss: 0.0005447 (Best: 0.0003851 @iter6781) ([92m↓3.91%[0m) [0.22% of initial]
[Iter 6860/20000] Loss: 0.0005073 (Best: 0.0003851 @iter6781) ([92m↓6.87%[0m) [0.20% of initial]
[Iter 6870/20000] Loss: 0.0004974 (Best: 0.0003851 @iter6781) ([92m↓1.94%[0m) [0.20% of initial]
[Iter 6880/20000] Loss: 0.0004657 (Best: 0.0003851 @iter6781) ([92m↓6.37%[0m) [0.19% of initial]
[Iter 6890/20000] Loss: 0.0005591 (Best: 0.0003851 @iter6781) ([91m↑20.05%[0m) [0.22% of initial]
Iter:6899, L1 loss=0.0006379, Total loss=0.0005734, Time:48
[Iter 6900/20000] Loss: 0.0005612 (Best: 0.0003851 @iter6781) ([91m↑0.38%[0m) [0.22% of initial]
[Iter 6910/20000] Loss: 0.0005594 (Best: 0.0003851 @iter6781) ([92m↓0.32%[0m) [0.22% of initial]
[Iter 6920/20000] Loss: 0.0005012 (Best: 0.0003851 @iter6781) ([92m↓10.42%[0m) [0.20% of initial]
[Iter 6930/20000] Loss: 0.0005046 (Best: 0.0003851 @iter6781) ([91m↑0.69%[0m) [0.20% of initial]
[Iter 6940/20000] Loss: 0.0004449 (Best: 0.0003851 @iter6781) ([92m↓11.84%[0m) [0.18% of initial]
[Iter 6950/20000] Loss: 0.0004533 (Best: 0.0003851 @iter6781) ([91m↑1.89%[0m) [0.18% of initial]
[Iter 6960/20000] Loss: 0.0004359 (Best: 0.0003851 @iter6781) ([92m↓3.84%[0m) [0.17% of initial]
[Iter 6970/20000] Loss: 0.0005190 (Best: 0.0003843 @iter6961) ([91m↑19.07%[0m) [0.21% of initial]
[Iter 6980/20000] Loss: 0.0005329 (Best: 0.0003843 @iter6961) ([91m↑2.68%[0m) [0.21% of initial]
[Iter 6990/20000] Loss: 0.0004764 (Best: 0.0003843 @iter6961) ([92m↓10.61%[0m) [0.19% of initial]
Iter:6999, L1 loss=0.0006275, Total loss=0.0005644, Time:53
[Iter 7000/20000] Loss: 0.0004763 (Best: 0.0003843 @iter6961) ([92m↓0.01%[0m) [0.19% of initial]
Pruning 88 points (0.0%) from gaussian0 at iteration 7000
Pruning 50 points (0.0%) from gaussian1 at iteration 7000
[Iter 7010/20000] Loss: 0.0014391 (Best: 0.0003843 @iter6961) ([91m↑202.12%[0m) [0.57% of initial]
[Iter 7020/20000] Loss: 0.0009642 (Best: 0.0003843 @iter6961) ([92m↓33.00%[0m) [0.38% of initial]
[Iter 7030/20000] Loss: 0.0006924 (Best: 0.0003843 @iter6961) ([92m↓28.19%[0m) [0.28% of initial]
[Iter 7040/20000] Loss: 0.0005651 (Best: 0.0003843 @iter6961) ([92m↓18.39%[0m) [0.22% of initial]
[Iter 7050/20000] Loss: 0.0005364 (Best: 0.0003843 @iter6961) ([92m↓5.07%[0m) [0.21% of initial]
[Iter 7060/20000] Loss: 0.0005600 (Best: 0.0003843 @iter6961) ([91m↑4.40%[0m) [0.22% of initial]
[Iter 7070/20000] Loss: 0.0005004 (Best: 0.0003843 @iter6961) ([92m↓10.65%[0m) [0.20% of initial]
[Iter 7080/20000] Loss: 0.0005193 (Best: 0.0003843 @iter6961) ([91m↑3.77%[0m) [0.21% of initial]
[Iter 7090/20000] Loss: 0.0005344 (Best: 0.0003843 @iter6961) ([91m↑2.91%[0m) [0.21% of initial]
Iter:7099, L1 loss=0.0005465, Total loss=0.0004749, Time:50
[Iter 7100/20000] Loss: 0.0005017 (Best: 0.0003843 @iter6961) ([92m↓6.12%[0m) [0.20% of initial]
[Iter 7110/20000] Loss: 0.0005062 (Best: 0.0003843 @iter6961) ([91m↑0.89%[0m) [0.20% of initial]
[Iter 7120/20000] Loss: 0.0004734 (Best: 0.0003843 @iter6961) ([92m↓6.47%[0m) [0.19% of initial]
[Iter 7130/20000] Loss: 0.0004613 (Best: 0.0003843 @iter6961) ([92m↓2.56%[0m) [0.18% of initial]
[Iter 7140/20000] Loss: 0.0005471 (Best: 0.0003843 @iter6961) ([91m↑18.61%[0m) [0.22% of initial]
[Iter 7150/20000] Loss: 0.0004937 (Best: 0.0003843 @iter6961) ([92m↓9.76%[0m) [0.20% of initial]
[Iter 7160/20000] Loss: 0.0004893 (Best: 0.0003843 @iter6961) ([92m↓0.89%[0m) [0.19% of initial]
[Iter 7170/20000] Loss: 0.0004971 (Best: 0.0003843 @iter6961) ([91m↑1.59%[0m) [0.20% of initial]
[Iter 7180/20000] Loss: 0.0005090 (Best: 0.0003843 @iter6961) ([91m↑2.40%[0m) [0.20% of initial]
[Iter 7190/20000] Loss: 0.0004372 (Best: 0.0003843 @iter6961) ([92m↓14.10%[0m) [0.17% of initial]
Iter:7199, L1 loss=0.0005135, Total loss=0.0004534, Time:49
[Iter 7200/20000] Loss: 0.0004626 (Best: 0.0003843 @iter6961) ([91m↑5.79%[0m) [0.18% of initial]
[Iter 7210/20000] Loss: 0.0010986 (Best: 0.0003843 @iter6961) ([91m↑137.49%[0m) [0.44% of initial]
[Iter 7220/20000] Loss: 0.0009513 (Best: 0.0003843 @iter6961) ([92m↓13.40%[0m) [0.38% of initial]
[Iter 7230/20000] Loss: 0.0007480 (Best: 0.0003843 @iter6961) ([92m↓21.37%[0m) [0.30% of initial]
[Iter 7240/20000] Loss: 0.0006065 (Best: 0.0003843 @iter6961) ([92m↓18.92%[0m) [0.24% of initial]
[Iter 7250/20000] Loss: 0.0005042 (Best: 0.0003843 @iter6961) ([92m↓16.87%[0m) [0.20% of initial]
[Iter 7260/20000] Loss: 0.0004754 (Best: 0.0003843 @iter6961) ([92m↓5.70%[0m) [0.19% of initial]
[Iter 7270/20000] Loss: 0.0004442 (Best: 0.0003843 @iter6961) ([92m↓6.58%[0m) [0.18% of initial]
[Iter 7280/20000] Loss: 0.0004248 (Best: 0.0003677 @iter7276) ([92m↓4.35%[0m) [0.17% of initial]
[Iter 7290/20000] Loss: 0.0004491 (Best: 0.0003677 @iter7276) ([91m↑5.70%[0m) [0.18% of initial]
Iter:7299, L1 loss=0.000591, Total loss=0.0005177, Time:51
[Iter 7300/20000] Loss: 0.0004700 (Best: 0.0003677 @iter7276) ([91m↑4.66%[0m) [0.19% of initial]
[Iter 7310/20000] Loss: 0.0004631 (Best: 0.0003677 @iter7276) ([92m↓1.47%[0m) [0.18% of initial]
[Iter 7320/20000] Loss: 0.0005328 (Best: 0.0003677 @iter7276) ([91m↑15.06%[0m) [0.21% of initial]
[Iter 7330/20000] Loss: 0.0004874 (Best: 0.0003677 @iter7276) ([92m↓8.52%[0m) [0.19% of initial]
[Iter 7340/20000] Loss: 0.0004509 (Best: 0.0003677 @iter7276) ([92m↓7.49%[0m) [0.18% of initial]
[Iter 7350/20000] Loss: 0.0005052 (Best: 0.0003677 @iter7276) ([91m↑12.04%[0m) [0.20% of initial]
[Iter 7360/20000] Loss: 0.0005153 (Best: 0.0003677 @iter7276) ([91m↑2.00%[0m) [0.20% of initial]
[Iter 7370/20000] Loss: 0.0004544 (Best: 0.0003677 @iter7276) ([92m↓11.82%[0m) [0.18% of initial]
[Iter 7380/20000] Loss: 0.0005782 (Best: 0.0003677 @iter7276) ([91m↑27.26%[0m) [0.23% of initial]
[Iter 7390/20000] Loss: 0.0006183 (Best: 0.0003677 @iter7276) ([91m↑6.94%[0m) [0.25% of initial]
Iter:7399, L1 loss=0.0006629, Total loss=0.0005632, Time:48
[Iter 7400/20000] Loss: 0.0005992 (Best: 0.0003677 @iter7276) ([92m↓3.09%[0m) [0.24% of initial]
[Iter 7410/20000] Loss: 0.0013170 (Best: 0.0003677 @iter7276) ([91m↑119.78%[0m) [0.52% of initial]
[Iter 7420/20000] Loss: 0.0008400 (Best: 0.0003677 @iter7276) ([92m↓36.22%[0m) [0.33% of initial]
[Iter 7430/20000] Loss: 0.0006901 (Best: 0.0003677 @iter7276) ([92m↓17.85%[0m) [0.27% of initial]
[Iter 7440/20000] Loss: 0.0006107 (Best: 0.0003677 @iter7276) ([92m↓11.51%[0m) [0.24% of initial]
[Iter 7450/20000] Loss: 0.0005562 (Best: 0.0003677 @iter7276) ([92m↓8.92%[0m) [0.22% of initial]
[Iter 7460/20000] Loss: 0.0005227 (Best: 0.0003677 @iter7276) ([92m↓6.03%[0m) [0.21% of initial]
[Iter 7470/20000] Loss: 0.0004852 (Best: 0.0003677 @iter7276) ([92m↓7.18%[0m) [0.19% of initial]
[Iter 7480/20000] Loss: 0.0004785 (Best: 0.0003677 @iter7276) ([92m↓1.38%[0m) [0.19% of initial]
[Iter 7490/20000] Loss: 0.0004127 (Best: 0.0003677 @iter7276) ([92m↓13.74%[0m) [0.16% of initial]
Iter:7499, L1 loss=0.0004997, Total loss=0.0004322, Time:49
[Iter 7500/20000] Loss: 0.0004484 (Best: 0.0003677 @iter7276) ([91m↑8.65%[0m) [0.18% of initial]
Pruning 96 points (0.1%) from gaussian0 at iteration 7500
Pruning 60 points (0.0%) from gaussian1 at iteration 7500
[Iter 7510/20000] Loss: 0.0011565 (Best: 0.0003677 @iter7276) ([91m↑157.92%[0m) [0.46% of initial]
[Iter 7520/20000] Loss: 0.0007735 (Best: 0.0003677 @iter7276) ([92m↓33.12%[0m) [0.31% of initial]
[Iter 7530/20000] Loss: 0.0005829 (Best: 0.0003677 @iter7276) ([92m↓24.64%[0m) [0.23% of initial]
[Iter 7540/20000] Loss: 0.0004352 (Best: 0.0003677 @iter7276) ([92m↓25.34%[0m) [0.17% of initial]
[Iter 7550/20000] Loss: 0.0004269 (Best: 0.0003677 @iter7276) ([92m↓1.90%[0m) [0.17% of initial]
[Iter 7560/20000] Loss: 0.0004155 (Best: 0.0003658 @iter7555) ([92m↓2.68%[0m) [0.17% of initial]
[Iter 7570/20000] Loss: 0.0004289 (Best: 0.0003658 @iter7555) ([91m↑3.22%[0m) [0.17% of initial]
[Iter 7580/20000] Loss: 0.0004564 (Best: 0.0003658 @iter7555) ([91m↑6.41%[0m) [0.18% of initial]
[Iter 7590/20000] Loss: 0.0004643 (Best: 0.0003658 @iter7555) ([91m↑1.74%[0m) [0.18% of initial]
Iter:7599, L1 loss=0.0004751, Total loss=0.0004034, Time:49
[Iter 7600/20000] Loss: 0.0004145 (Best: 0.0003658 @iter7555) ([92m↓10.72%[0m) [0.16% of initial]
[Iter 7610/20000] Loss: 0.0010556 (Best: 0.0003658 @iter7555) ([91m↑154.65%[0m) [0.42% of initial]
[Iter 7620/20000] Loss: 0.0007552 (Best: 0.0003658 @iter7555) ([92m↓28.45%[0m) [0.30% of initial]
[Iter 7630/20000] Loss: 0.0006547 (Best: 0.0003658 @iter7555) ([92m↓13.31%[0m) [0.26% of initial]
[Iter 7640/20000] Loss: 0.0005458 (Best: 0.0003658 @iter7555) ([92m↓16.64%[0m) [0.22% of initial]
[Iter 7650/20000] Loss: 0.0004804 (Best: 0.0003658 @iter7555) ([92m↓11.98%[0m) [0.19% of initial]
[Iter 7660/20000] Loss: 0.0004025 (Best: 0.0003658 @iter7555) ([92m↓16.22%[0m) [0.16% of initial]
[Iter 7670/20000] Loss: 0.0003850 (Best: 0.0003658 @iter7555) ([92m↓4.35%[0m) [0.15% of initial]
[Iter 7680/20000] Loss: 0.0004140 (Best: 0.0003646 @iter7675) ([91m↑7.53%[0m) [0.16% of initial]
[Iter 7690/20000] Loss: 0.0004010 (Best: 0.0003632 @iter7690) ([92m↓3.13%[0m) [0.16% of initial]
Iter:7699, L1 loss=0.0004326, Total loss=0.0003847, Time:47
[Iter 7700/20000] Loss: 0.0003935 (Best: 0.0003632 @iter7690) ([92m↓1.87%[0m) [0.16% of initial]
[Iter 7710/20000] Loss: 0.0003843 (Best: 0.0003632 @iter7690) ([92m↓2.34%[0m) [0.15% of initial]
[Iter 7720/20000] Loss: 0.0003769 (Best: 0.0003309 @iter7714) ([92m↓1.94%[0m) [0.15% of initial]
[Iter 7730/20000] Loss: 0.0003734 (Best: 0.0003301 @iter7729) ([92m↓0.92%[0m) [0.15% of initial]
[Iter 7740/20000] Loss: 0.0003775 (Best: 0.0003298 @iter7738) ([91m↑1.10%[0m) [0.15% of initial]
[Iter 7750/20000] Loss: 0.0004183 (Best: 0.0003298 @iter7738) ([91m↑10.81%[0m) [0.17% of initial]
[Iter 7760/20000] Loss: 0.0004661 (Best: 0.0003298 @iter7738) ([91m↑11.43%[0m) [0.19% of initial]
[Iter 7770/20000] Loss: 0.0004573 (Best: 0.0003298 @iter7738) ([92m↓1.88%[0m) [0.18% of initial]
[Iter 7780/20000] Loss: 0.0004432 (Best: 0.0003298 @iter7738) ([92m↓3.10%[0m) [0.18% of initial]
[Iter 7790/20000] Loss: 0.0004647 (Best: 0.0003298 @iter7738) ([91m↑4.86%[0m) [0.18% of initial]
Iter:7799, L1 loss=0.0004487, Total loss=0.0004094, Time:50
[Iter 7800/20000] Loss: 0.0004599 (Best: 0.0003298 @iter7738) ([92m↓1.04%[0m) [0.18% of initial]
[Iter 7810/20000] Loss: 0.0008714 (Best: 0.0003298 @iter7738) ([91m↑89.48%[0m) [0.35% of initial]
[Iter 7820/20000] Loss: 0.0007106 (Best: 0.0003298 @iter7738) ([92m↓18.45%[0m) [0.28% of initial]
[Iter 7830/20000] Loss: 0.0006486 (Best: 0.0003298 @iter7738) ([92m↓8.72%[0m) [0.26% of initial]
[Iter 7840/20000] Loss: 0.0005425 (Best: 0.0003298 @iter7738) ([92m↓16.36%[0m) [0.22% of initial]
[Iter 7850/20000] Loss: 0.0005291 (Best: 0.0003298 @iter7738) ([92m↓2.47%[0m) [0.21% of initial]
[Iter 7860/20000] Loss: 0.0005239 (Best: 0.0003298 @iter7738) ([92m↓0.99%[0m) [0.21% of initial]
[Iter 7870/20000] Loss: 0.0004844 (Best: 0.0003298 @iter7738) ([92m↓7.53%[0m) [0.19% of initial]
[Iter 7880/20000] Loss: 0.0004296 (Best: 0.0003298 @iter7738) ([92m↓11.33%[0m) [0.17% of initial]
[Iter 7890/20000] Loss: 0.0005184 (Best: 0.0003298 @iter7738) ([91m↑20.69%[0m) [0.21% of initial]
Iter:7899, L1 loss=0.0005115, Total loss=0.0004466, Time:48
[Iter 7900/20000] Loss: 0.0004467 (Best: 0.0003298 @iter7738) ([92m↓13.83%[0m) [0.18% of initial]
[Iter 7910/20000] Loss: 0.0004418 (Best: 0.0003298 @iter7738) ([92m↓1.10%[0m) [0.18% of initial]
[Iter 7920/20000] Loss: 0.0005255 (Best: 0.0003298 @iter7738) ([91m↑18.96%[0m) [0.21% of initial]
[Iter 7930/20000] Loss: 0.0004446 (Best: 0.0003298 @iter7738) ([92m↓15.40%[0m) [0.18% of initial]
[Iter 7940/20000] Loss: 0.0004024 (Best: 0.0003298 @iter7738) ([92m↓9.49%[0m) [0.16% of initial]
[Iter 7950/20000] Loss: 0.0003914 (Best: 0.0003298 @iter7738) ([92m↓2.73%[0m) [0.16% of initial]
[Iter 7960/20000] Loss: 0.0004559 (Best: 0.0003298 @iter7738) ([91m↑16.48%[0m) [0.18% of initial]
[Iter 7970/20000] Loss: 0.0004477 (Best: 0.0003298 @iter7738) ([92m↓1.81%[0m) [0.18% of initial]
[Iter 7980/20000] Loss: 0.0004575 (Best: 0.0003298 @iter7738) ([91m↑2.18%[0m) [0.18% of initial]
[Iter 7990/20000] Loss: 0.0004038 (Best: 0.0003298 @iter7738) ([92m↓11.73%[0m) [0.16% of initial]
Iter:7999, L1 loss=0.0004612, Total loss=0.0003906, Time:47
[Iter 8000/20000] Loss: 0.0004008 (Best: 0.0003298 @iter7738) ([92m↓0.74%[0m) [0.16% of initial]
Pruning 56 points (0.0%) from gaussian0 at iteration 8000
Pruning 41 points (0.0%) from gaussian1 at iteration 8000
[Iter 8010/20000] Loss: 0.0423391 (Best: 0.0003298 @iter7738) ([91m↑10463.50%[0m) [16.82% of initial]
[Iter 8020/20000] Loss: 0.0175109 (Best: 0.0003298 @iter7738) ([92m↓58.64%[0m) [6.96% of initial]
[Iter 8030/20000] Loss: 0.0053739 (Best: 0.0003298 @iter7738) ([92m↓69.31%[0m) [2.14% of initial]
[Iter 8040/20000] Loss: 0.0040566 (Best: 0.0003298 @iter7738) ([92m↓24.51%[0m) [1.61% of initial]
[Iter 8050/20000] Loss: 0.0022804 (Best: 0.0003298 @iter7738) ([92m↓43.79%[0m) [0.91% of initial]
[Iter 8060/20000] Loss: 0.0015627 (Best: 0.0003298 @iter7738) ([92m↓31.47%[0m) [0.62% of initial]
[Iter 8070/20000] Loss: 0.0012467 (Best: 0.0003298 @iter7738) ([92m↓20.22%[0m) [0.50% of initial]
[Iter 8080/20000] Loss: 0.0009720 (Best: 0.0003298 @iter7738) ([92m↓22.04%[0m) [0.39% of initial]
[Iter 8090/20000] Loss: 0.0008048 (Best: 0.0003298 @iter7738) ([92m↓17.20%[0m) [0.32% of initial]
Iter:8099, L1 loss=0.0007469, Total loss=0.0007039, Time:62
[Iter 8100/20000] Loss: 0.0007698 (Best: 0.0003298 @iter7738) ([92m↓4.36%[0m) [0.31% of initial]
[Iter 8110/20000] Loss: 0.0006705 (Best: 0.0003298 @iter7738) ([92m↓12.89%[0m) [0.27% of initial]
[Iter 8120/20000] Loss: 0.0006016 (Best: 0.0003298 @iter7738) ([92m↓10.28%[0m) [0.24% of initial]
[Iter 8130/20000] Loss: 0.0006263 (Best: 0.0003298 @iter7738) ([91m↑4.09%[0m) [0.25% of initial]
[Iter 8140/20000] Loss: 0.0005957 (Best: 0.0003298 @iter7738) ([92m↓4.88%[0m) [0.24% of initial]
[Iter 8150/20000] Loss: 0.0005818 (Best: 0.0003298 @iter7738) ([92m↓2.33%[0m) [0.23% of initial]
[Iter 8160/20000] Loss: 0.0005836 (Best: 0.0003298 @iter7738) ([91m↑0.31%[0m) [0.23% of initial]
[Iter 8170/20000] Loss: 0.0005672 (Best: 0.0003298 @iter7738) ([92m↓2.81%[0m) [0.23% of initial]
[Iter 8180/20000] Loss: 0.0005684 (Best: 0.0003298 @iter7738) ([91m↑0.21%[0m) [0.23% of initial]
[Iter 8190/20000] Loss: 0.0005487 (Best: 0.0003298 @iter7738) ([92m↓3.47%[0m) [0.22% of initial]
Iter:8199, L1 loss=0.0006083, Total loss=0.0005467, Time:50
[Iter 8200/20000] Loss: 0.0005255 (Best: 0.0003298 @iter7738) ([92m↓4.22%[0m) [0.21% of initial]
[Iter 8210/20000] Loss: 0.0005043 (Best: 0.0003298 @iter7738) ([92m↓4.04%[0m) [0.20% of initial]
[Iter 8220/20000] Loss: 0.0005116 (Best: 0.0003298 @iter7738) ([91m↑1.45%[0m) [0.20% of initial]
[Iter 8230/20000] Loss: 0.0005160 (Best: 0.0003298 @iter7738) ([91m↑0.85%[0m) [0.20% of initial]
[Iter 8240/20000] Loss: 0.0005114 (Best: 0.0003298 @iter7738) ([92m↓0.88%[0m) [0.20% of initial]
[Iter 8250/20000] Loss: 0.0005454 (Best: 0.0003298 @iter7738) ([91m↑6.64%[0m) [0.22% of initial]
[Iter 8260/20000] Loss: 0.0005267 (Best: 0.0003298 @iter7738) ([92m↓3.43%[0m) [0.21% of initial]
[Iter 8270/20000] Loss: 0.0005364 (Best: 0.0003298 @iter7738) ([91m↑1.85%[0m) [0.21% of initial]
[Iter 8280/20000] Loss: 0.0005287 (Best: 0.0003298 @iter7738) ([92m↓1.44%[0m) [0.21% of initial]
[Iter 8290/20000] Loss: 0.0005520 (Best: 0.0003298 @iter7738) ([91m↑4.40%[0m) [0.22% of initial]
Iter:8299, L1 loss=0.0005183, Total loss=0.0004645, Time:45
[Iter 8300/20000] Loss: 0.0005046 (Best: 0.0003298 @iter7738) ([92m↓8.59%[0m) [0.20% of initial]
[Iter 8310/20000] Loss: 0.0004938 (Best: 0.0003298 @iter7738) ([92m↓2.15%[0m) [0.20% of initial]
[Iter 8320/20000] Loss: 0.0004733 (Best: 0.0003298 @iter7738) ([92m↓4.16%[0m) [0.19% of initial]
[Iter 8330/20000] Loss: 0.0004832 (Best: 0.0003298 @iter7738) ([91m↑2.10%[0m) [0.19% of initial]
[Iter 8340/20000] Loss: 0.0004970 (Best: 0.0003298 @iter7738) ([91m↑2.86%[0m) [0.20% of initial]
[Iter 8350/20000] Loss: 0.0004517 (Best: 0.0003298 @iter7738) ([92m↓9.13%[0m) [0.18% of initial]
[Iter 8360/20000] Loss: 0.0004584 (Best: 0.0003298 @iter7738) ([91m↑1.49%[0m) [0.18% of initial]
[Iter 8370/20000] Loss: 0.0004522 (Best: 0.0003298 @iter7738) ([92m↓1.34%[0m) [0.18% of initial]
[Iter 8380/20000] Loss: 0.0004604 (Best: 0.0003298 @iter7738) ([91m↑1.81%[0m) [0.18% of initial]
[Iter 8390/20000] Loss: 0.0004294 (Best: 0.0003298 @iter7738) ([92m↓6.74%[0m) [0.17% of initial]
Iter:8399, L1 loss=0.0005007, Total loss=0.0004475, Time:53
[Iter 8400/20000] Loss: 0.0004771 (Best: 0.0003298 @iter7738) ([91m↑11.11%[0m) [0.19% of initial]
[Iter 8410/20000] Loss: 0.0004575 (Best: 0.0003298 @iter7738) ([92m↓4.10%[0m) [0.18% of initial]
[Iter 8420/20000] Loss: 0.0004445 (Best: 0.0003298 @iter7738) ([92m↓2.84%[0m) [0.18% of initial]
[Iter 8430/20000] Loss: 0.0004654 (Best: 0.0003298 @iter7738) ([91m↑4.69%[0m) [0.18% of initial]
[Iter 8440/20000] Loss: 0.0004474 (Best: 0.0003298 @iter7738) ([92m↓3.86%[0m) [0.18% of initial]
[Iter 8450/20000] Loss: 0.0004790 (Best: 0.0003298 @iter7738) ([91m↑7.07%[0m) [0.19% of initial]
[Iter 8460/20000] Loss: 0.0004615 (Best: 0.0003298 @iter7738) ([92m↓3.65%[0m) [0.18% of initial]
[Iter 8470/20000] Loss: 0.0004791 (Best: 0.0003298 @iter7738) ([91m↑3.81%[0m) [0.19% of initial]
[Iter 8480/20000] Loss: 0.0004602 (Best: 0.0003298 @iter7738) ([92m↓3.94%[0m) [0.18% of initial]
[Iter 8490/20000] Loss: 0.0004814 (Best: 0.0003298 @iter7738) ([91m↑4.61%[0m) [0.19% of initial]
Iter:8499, L1 loss=0.0005637, Total loss=0.0005022, Time:56
[Iter 8500/20000] Loss: 0.0005028 (Best: 0.0003298 @iter7738) ([91m↑4.45%[0m) [0.20% of initial]
Pruning 63 points (0.0%) from gaussian0 at iteration 8500
Pruning 63 points (0.0%) from gaussian1 at iteration 8500
[Iter 8510/20000] Loss: 0.0010327 (Best: 0.0003298 @iter7738) ([91m↑105.37%[0m) [0.41% of initial]
[Iter 8520/20000] Loss: 0.0007492 (Best: 0.0003298 @iter7738) ([92m↓27.45%[0m) [0.30% of initial]
[Iter 8530/20000] Loss: 0.0005929 (Best: 0.0003298 @iter7738) ([92m↓20.86%[0m) [0.24% of initial]
[Iter 8540/20000] Loss: 0.0005485 (Best: 0.0003298 @iter7738) ([92m↓7.50%[0m) [0.22% of initial]
[Iter 8550/20000] Loss: 0.0005191 (Best: 0.0003298 @iter7738) ([92m↓5.35%[0m) [0.21% of initial]
[Iter 8560/20000] Loss: 0.0004982 (Best: 0.0003298 @iter7738) ([92m↓4.02%[0m) [0.20% of initial]
[Iter 8570/20000] Loss: 0.0004850 (Best: 0.0003298 @iter7738) ([92m↓2.65%[0m) [0.19% of initial]
[Iter 8580/20000] Loss: 0.0004815 (Best: 0.0003298 @iter7738) ([92m↓0.74%[0m) [0.19% of initial]
[Iter 8590/20000] Loss: 0.0004622 (Best: 0.0003298 @iter7738) ([92m↓4.00%[0m) [0.18% of initial]
Iter:8599, L1 loss=0.0004768, Total loss=0.0004189, Time:53
[Iter 8600/20000] Loss: 0.0004577 (Best: 0.0003298 @iter7738) ([92m↓0.97%[0m) [0.18% of initial]
[Iter 8610/20000] Loss: 0.0004798 (Best: 0.0003298 @iter7738) ([91m↑4.82%[0m) [0.19% of initial]
[Iter 8620/20000] Loss: 0.0004716 (Best: 0.0003298 @iter7738) ([92m↓1.70%[0m) [0.19% of initial]
[Iter 8630/20000] Loss: 0.0004620 (Best: 0.0003298 @iter7738) ([92m↓2.05%[0m) [0.18% of initial]
[Iter 8640/20000] Loss: 0.0004405 (Best: 0.0003298 @iter7738) ([92m↓4.64%[0m) [0.18% of initial]
[Iter 8650/20000] Loss: 0.0004529 (Best: 0.0003298 @iter7738) ([91m↑2.80%[0m) [0.18% of initial]
[Iter 8660/20000] Loss: 0.0004975 (Best: 0.0003298 @iter7738) ([91m↑9.85%[0m) [0.20% of initial]
[Iter 8670/20000] Loss: 0.0005078 (Best: 0.0003298 @iter7738) ([91m↑2.07%[0m) [0.20% of initial]
[Iter 8680/20000] Loss: 0.0004780 (Best: 0.0003298 @iter7738) ([92m↓5.86%[0m) [0.19% of initial]
[Iter 8690/20000] Loss: 0.0005752 (Best: 0.0003298 @iter7738) ([91m↑20.32%[0m) [0.23% of initial]
Iter:8699, L1 loss=0.0005512, Total loss=0.0004816, Time:55
[Iter 8700/20000] Loss: 0.0005076 (Best: 0.0003298 @iter7738) ([92m↓11.75%[0m) [0.20% of initial]
[Iter 8710/20000] Loss: 0.0004826 (Best: 0.0003298 @iter7738) ([92m↓4.92%[0m) [0.19% of initial]
[Iter 8720/20000] Loss: 0.0004629 (Best: 0.0003298 @iter7738) ([92m↓4.08%[0m) [0.18% of initial]
[Iter 8730/20000] Loss: 0.0004945 (Best: 0.0003298 @iter7738) ([91m↑6.81%[0m) [0.20% of initial]
[Iter 8740/20000] Loss: 0.0004699 (Best: 0.0003298 @iter7738) ([92m↓4.96%[0m) [0.19% of initial]
[Iter 8750/20000] Loss: 0.0005522 (Best: 0.0003298 @iter7738) ([91m↑17.49%[0m) [0.22% of initial]
[Iter 8760/20000] Loss: 0.0005208 (Best: 0.0003298 @iter7738) ([92m↓5.69%[0m) [0.21% of initial]
[Iter 8770/20000] Loss: 0.0005266 (Best: 0.0003298 @iter7738) ([91m↑1.13%[0m) [0.21% of initial]
[Iter 8780/20000] Loss: 0.0005283 (Best: 0.0003298 @iter7738) ([91m↑0.32%[0m) [0.21% of initial]
[Iter 8790/20000] Loss: 0.0005229 (Best: 0.0003298 @iter7738) ([92m↓1.03%[0m) [0.21% of initial]
Iter:8799, L1 loss=0.0006068, Total loss=0.000547, Time:61
[Iter 8800/20000] Loss: 0.0005055 (Best: 0.0003298 @iter7738) ([92m↓3.32%[0m) [0.20% of initial]
[Iter 8810/20000] Loss: 0.0004468 (Best: 0.0003298 @iter7738) ([92m↓11.60%[0m) [0.18% of initial]
[Iter 8820/20000] Loss: 0.0005193 (Best: 0.0003298 @iter7738) ([91m↑16.21%[0m) [0.21% of initial]
[Iter 8830/20000] Loss: 0.0006268 (Best: 0.0003298 @iter7738) ([91m↑20.69%[0m) [0.25% of initial]
[Iter 8840/20000] Loss: 0.0005853 (Best: 0.0003298 @iter7738) ([92m↓6.61%[0m) [0.23% of initial]
[Iter 8850/20000] Loss: 0.0005832 (Best: 0.0003298 @iter7738) ([92m↓0.36%[0m) [0.23% of initial]
[Iter 8860/20000] Loss: 0.0004898 (Best: 0.0003298 @iter7738) ([92m↓16.03%[0m) [0.19% of initial]
[Iter 8870/20000] Loss: 0.0004568 (Best: 0.0003298 @iter7738) ([92m↓6.73%[0m) [0.18% of initial]
[Iter 8880/20000] Loss: 0.0004562 (Best: 0.0003298 @iter7738) ([92m↓0.13%[0m) [0.18% of initial]
[Iter 8890/20000] Loss: 0.0004337 (Best: 0.0003298 @iter7738) ([92m↓4.93%[0m) [0.17% of initial]
Iter:8899, L1 loss=0.000482, Total loss=0.0004276, Time:57
[Iter 8900/20000] Loss: 0.0004640 (Best: 0.0003298 @iter7738) ([91m↑6.98%[0m) [0.18% of initial]
[Iter 8910/20000] Loss: 0.0004525 (Best: 0.0003298 @iter7738) ([92m↓2.49%[0m) [0.18% of initial]
[Iter 8920/20000] Loss: 0.0004371 (Best: 0.0003298 @iter7738) ([92m↓3.41%[0m) [0.17% of initial]
[Iter 8930/20000] Loss: 0.0004453 (Best: 0.0003298 @iter7738) ([91m↑1.88%[0m) [0.18% of initial]
[Iter 8940/20000] Loss: 0.0004463 (Best: 0.0003298 @iter7738) ([91m↑0.22%[0m) [0.18% of initial]
[Iter 8950/20000] Loss: 0.0004761 (Best: 0.0003298 @iter7738) ([91m↑6.68%[0m) [0.19% of initial]
[Iter 8960/20000] Loss: 0.0004719 (Best: 0.0003298 @iter7738) ([92m↓0.89%[0m) [0.19% of initial]
[Iter 8970/20000] Loss: 0.0005252 (Best: 0.0003298 @iter7738) ([91m↑11.31%[0m) [0.21% of initial]
[Iter 8980/20000] Loss: 0.0004989 (Best: 0.0003298 @iter7738) ([92m↓5.01%[0m) [0.20% of initial]
[Iter 8990/20000] Loss: 0.0004558 (Best: 0.0003298 @iter7738) ([92m↓8.64%[0m) [0.18% of initial]
Iter:8999, L1 loss=0.0004684, Total loss=0.0004114, Time:54
[Iter 9000/20000] Loss: 0.0004425 (Best: 0.0003298 @iter7738) ([92m↓2.93%[0m) [0.18% of initial]
Pruning 46 points (0.0%) from gaussian0 at iteration 9000
Pruning 30 points (0.0%) from gaussian1 at iteration 9000
[Iter 9010/20000] Loss: 0.0008503 (Best: 0.0003298 @iter7738) ([91m↑92.17%[0m) [0.34% of initial]
[Iter 9020/20000] Loss: 0.0006442 (Best: 0.0003298 @iter7738) ([92m↓24.24%[0m) [0.26% of initial]
[Iter 9030/20000] Loss: 0.0005307 (Best: 0.0003298 @iter7738) ([92m↓17.62%[0m) [0.21% of initial]
[Iter 9040/20000] Loss: 0.0004815 (Best: 0.0003298 @iter7738) ([92m↓9.27%[0m) [0.19% of initial]
[Iter 9050/20000] Loss: 0.0004481 (Best: 0.0003298 @iter7738) ([92m↓6.93%[0m) [0.18% of initial]
[Iter 9060/20000] Loss: 0.0004637 (Best: 0.0003298 @iter7738) ([91m↑3.49%[0m) [0.18% of initial]
[Iter 9070/20000] Loss: 0.0004676 (Best: 0.0003298 @iter7738) ([91m↑0.82%[0m) [0.19% of initial]
[Iter 9080/20000] Loss: 0.0004886 (Best: 0.0003298 @iter7738) ([91m↑4.50%[0m) [0.19% of initial]
[Iter 9090/20000] Loss: 0.0004718 (Best: 0.0003298 @iter7738) ([92m↓3.44%[0m) [0.19% of initial]
Iter:9099, L1 loss=0.0005874, Total loss=0.0005303, Time:53
[Iter 9100/20000] Loss: 0.0004800 (Best: 0.0003298 @iter7738) ([91m↑1.74%[0m) [0.19% of initial]
[Iter 9110/20000] Loss: 0.0005432 (Best: 0.0003298 @iter7738) ([91m↑13.15%[0m) [0.22% of initial]
[Iter 9120/20000] Loss: 0.0004684 (Best: 0.0003298 @iter7738) ([92m↓13.76%[0m) [0.19% of initial]
[Iter 9130/20000] Loss: 0.0004731 (Best: 0.0003298 @iter7738) ([91m↑0.99%[0m) [0.19% of initial]
[Iter 9140/20000] Loss: 0.0004722 (Best: 0.0003298 @iter7738) ([92m↓0.20%[0m) [0.19% of initial]
[Iter 9150/20000] Loss: 0.0004327 (Best: 0.0003298 @iter7738) ([92m↓8.37%[0m) [0.17% of initial]
[Iter 9160/20000] Loss: 0.0004515 (Best: 0.0003298 @iter7738) ([91m↑4.35%[0m) [0.18% of initial]
[Iter 9170/20000] Loss: 0.0004267 (Best: 0.0003298 @iter7738) ([92m↓5.50%[0m) [0.17% of initial]
[Iter 9180/20000] Loss: 0.0004446 (Best: 0.0003298 @iter7738) ([91m↑4.20%[0m) [0.18% of initial]
[Iter 9190/20000] Loss: 0.0003957 (Best: 0.0003298 @iter7738) ([92m↓11.00%[0m) [0.16% of initial]
Iter:9199, L1 loss=0.0004704, Total loss=0.0004198, Time:55
[Iter 9200/20000] Loss: 0.0004179 (Best: 0.0003298 @iter7738) ([91m↑5.63%[0m) [0.17% of initial]
[Iter 9210/20000] Loss: 0.0004313 (Best: 0.0003298 @iter7738) ([91m↑3.20%[0m) [0.17% of initial]
[Iter 9220/20000] Loss: 0.0004313 (Best: 0.0003298 @iter7738) ([92m↓0.01%[0m) [0.17% of initial]
[Iter 9230/20000] Loss: 0.0004308 (Best: 0.0003298 @iter7738) ([92m↓0.11%[0m) [0.17% of initial]
[Iter 9240/20000] Loss: 0.0004468 (Best: 0.0003298 @iter7738) ([91m↑3.70%[0m) [0.18% of initial]
[Iter 9250/20000] Loss: 0.0004442 (Best: 0.0003298 @iter7738) ([92m↓0.57%[0m) [0.18% of initial]
[Iter 9260/20000] Loss: 0.0004419 (Best: 0.0003298 @iter7738) ([92m↓0.52%[0m) [0.18% of initial]
[Iter 9270/20000] Loss: 0.0004334 (Best: 0.0003298 @iter7738) ([92m↓1.92%[0m) [0.17% of initial]
[Iter 9280/20000] Loss: 0.0004010 (Best: 0.0003298 @iter7738) ([92m↓7.48%[0m) [0.16% of initial]
[Iter 9290/20000] Loss: 0.0003970 (Best: 0.0003298 @iter7738) ([92m↓1.00%[0m) [0.16% of initial]
Iter:9299, L1 loss=0.0004353, Total loss=0.0003746, Time:51
[Iter 9300/20000] Loss: 0.0004236 (Best: 0.0003298 @iter7738) ([91m↑6.71%[0m) [0.17% of initial]
[Iter 9310/20000] Loss: 0.0004259 (Best: 0.0003298 @iter7738) ([91m↑0.53%[0m) [0.17% of initial]
[Iter 9320/20000] Loss: 0.0004324 (Best: 0.0003298 @iter7738) ([91m↑1.53%[0m) [0.17% of initial]
[Iter 9330/20000] Loss: 0.0004702 (Best: 0.0003298 @iter7738) ([91m↑8.75%[0m) [0.19% of initial]
[Iter 9340/20000] Loss: 0.0004634 (Best: 0.0003298 @iter7738) ([92m↓1.45%[0m) [0.18% of initial]
[Iter 9350/20000] Loss: 0.0004201 (Best: 0.0003298 @iter7738) ([92m↓9.35%[0m) [0.17% of initial]
[Iter 9360/20000] Loss: 0.0004522 (Best: 0.0003298 @iter7738) ([91m↑7.66%[0m) [0.18% of initial]
[Iter 9370/20000] Loss: 0.0004044 (Best: 0.0003298 @iter7738) ([92m↓10.57%[0m) [0.16% of initial]
[Iter 9380/20000] Loss: 0.0004313 (Best: 0.0003298 @iter7738) ([91m↑6.64%[0m) [0.17% of initial]
[Iter 9390/20000] Loss: 0.0004219 (Best: 0.0003298 @iter7738) ([92m↓2.18%[0m) [0.17% of initial]
Iter:9399, L1 loss=0.0006203, Total loss=0.0005012, Time:57
[Iter 9400/20000] Loss: 0.0004195 (Best: 0.0003298 @iter7738) ([92m↓0.57%[0m) [0.17% of initial]
[Iter 9410/20000] Loss: 0.0004333 (Best: 0.0003298 @iter7738) ([91m↑3.31%[0m) [0.17% of initial]
[Iter 9420/20000] Loss: 0.0004515 (Best: 0.0003298 @iter7738) ([91m↑4.18%[0m) [0.18% of initial]
[Iter 9430/20000] Loss: 0.0004080 (Best: 0.0003298 @iter7738) ([92m↓9.63%[0m) [0.16% of initial]
[Iter 9440/20000] Loss: 0.0004419 (Best: 0.0003298 @iter7738) ([91m↑8.31%[0m) [0.18% of initial]
[Iter 9450/20000] Loss: 0.0004277 (Best: 0.0003298 @iter7738) ([92m↓3.22%[0m) [0.17% of initial]
[Iter 9460/20000] Loss: 0.0003779 (Best: 0.0003298 @iter7738) ([92m↓11.64%[0m) [0.15% of initial]
[Iter 9470/20000] Loss: 0.0003849 (Best: 0.0003298 @iter7738) ([91m↑1.86%[0m) [0.15% of initial]
[Iter 9480/20000] Loss: 0.0004729 (Best: 0.0003298 @iter7738) ([91m↑22.87%[0m) [0.19% of initial]
[Iter 9490/20000] Loss: 0.0004224 (Best: 0.0003298 @iter7738) ([92m↓10.68%[0m) [0.17% of initial]
Iter:9499, L1 loss=0.0004599, Total loss=0.0004053, Time:51
[Iter 9500/20000] Loss: 0.0004230 (Best: 0.0003298 @iter7738) ([91m↑0.14%[0m) [0.17% of initial]
Pruning 43 points (0.0%) from gaussian0 at iteration 9500
Pruning 24 points (0.0%) from gaussian1 at iteration 9500
[Iter 9510/20000] Loss: 0.0007204 (Best: 0.0003298 @iter7738) ([91m↑70.32%[0m) [0.29% of initial]
[Iter 9520/20000] Loss: 0.0005586 (Best: 0.0003298 @iter7738) ([92m↓22.46%[0m) [0.22% of initial]
[Iter 9530/20000] Loss: 0.0005981 (Best: 0.0003298 @iter7738) ([91m↑7.07%[0m) [0.24% of initial]
[Iter 9540/20000] Loss: 0.0004657 (Best: 0.0003298 @iter7738) ([92m↓22.14%[0m) [0.19% of initial]
[Iter 9550/20000] Loss: 0.0004054 (Best: 0.0003298 @iter7738) ([92m↓12.94%[0m) [0.16% of initial]
[Iter 9560/20000] Loss: 0.0003802 (Best: 0.0003298 @iter7738) ([92m↓6.22%[0m) [0.15% of initial]
[Iter 9570/20000] Loss: 0.0003686 (Best: 0.0003298 @iter7738) ([92m↓3.07%[0m) [0.15% of initial]
[Iter 9580/20000] Loss: 0.0003554 (Best: 0.0003261 @iter9574) ([92m↓3.58%[0m) [0.14% of initial]
[Iter 9590/20000] Loss: 0.0003573 (Best: 0.0003261 @iter9574) ([91m↑0.54%[0m) [0.14% of initial]
Iter:9599, L1 loss=0.0005142, Total loss=0.0004375, Time:52
[Iter 9600/20000] Loss: 0.0003877 (Best: 0.0003261 @iter9574) ([91m↑8.50%[0m) [0.15% of initial]
[Iter 9610/20000] Loss: 0.0003720 (Best: 0.0003261 @iter9574) ([92m↓4.05%[0m) [0.15% of initial]
[Iter 9620/20000] Loss: 0.0003864 (Best: 0.0003261 @iter9574) ([91m↑3.88%[0m) [0.15% of initial]
[Iter 9630/20000] Loss: 0.0003679 (Best: 0.0003247 @iter9628) ([92m↓4.79%[0m) [0.15% of initial]
[Iter 9640/20000] Loss: 0.0003651 (Best: 0.0003247 @iter9628) ([92m↓0.76%[0m) [0.15% of initial]
[Iter 9650/20000] Loss: 0.0004185 (Best: 0.0003247 @iter9628) ([91m↑14.63%[0m) [0.17% of initial]
[Iter 9660/20000] Loss: 0.0003942 (Best: 0.0003247 @iter9628) ([92m↓5.82%[0m) [0.16% of initial]
[Iter 9670/20000] Loss: 0.0004356 (Best: 0.0003247 @iter9628) ([91m↑10.52%[0m) [0.17% of initial]
[Iter 9680/20000] Loss: 0.0004331 (Best: 0.0003247 @iter9628) ([92m↓0.58%[0m) [0.17% of initial]
[Iter 9690/20000] Loss: 0.0004932 (Best: 0.0003247 @iter9628) ([91m↑13.88%[0m) [0.20% of initial]
Iter:9699, L1 loss=0.0006241, Total loss=0.0005841, Time:60
[Iter 9700/20000] Loss: 0.0004696 (Best: 0.0003247 @iter9628) ([92m↓4.80%[0m) [0.19% of initial]
[Iter 9710/20000] Loss: 0.0004595 (Best: 0.0003247 @iter9628) ([92m↓2.14%[0m) [0.18% of initial]
[Iter 9720/20000] Loss: 0.0004233 (Best: 0.0003247 @iter9628) ([92m↓7.87%[0m) [0.17% of initial]
[Iter 9730/20000] Loss: 0.0003975 (Best: 0.0003247 @iter9628) ([92m↓6.10%[0m) [0.16% of initial]
[Iter 9740/20000] Loss: 0.0004287 (Best: 0.0003247 @iter9628) ([91m↑7.86%[0m) [0.17% of initial]
[Iter 9750/20000] Loss: 0.0004219 (Best: 0.0003247 @iter9628) ([92m↓1.59%[0m) [0.17% of initial]
[Iter 9760/20000] Loss: 0.0003932 (Best: 0.0003247 @iter9628) ([92m↓6.80%[0m) [0.16% of initial]
[Iter 9770/20000] Loss: 0.0003989 (Best: 0.0003247 @iter9628) ([91m↑1.44%[0m) [0.16% of initial]
[Iter 9780/20000] Loss: 0.0003827 (Best: 0.0003247 @iter9628) ([92m↓4.07%[0m) [0.15% of initial]
[Iter 9790/20000] Loss: 0.0003703 (Best: 0.0003247 @iter9628) ([92m↓3.24%[0m) [0.15% of initial]
Iter:9799, L1 loss=0.0004229, Total loss=0.0003731, Time:56
[Iter 9800/20000] Loss: 0.0003927 (Best: 0.0003247 @iter9628) ([91m↑6.06%[0m) [0.16% of initial]
[Iter 9810/20000] Loss: 0.0003732 (Best: 0.0003247 @iter9628) ([92m↓4.98%[0m) [0.15% of initial]
[Iter 9820/20000] Loss: 0.0003505 (Best: 0.0003247 @iter9628) ([92m↓6.06%[0m) [0.14% of initial]
[Iter 9830/20000] Loss: 0.0003692 (Best: 0.0003247 @iter9628) ([91m↑5.32%[0m) [0.15% of initial]
[Iter 9840/20000] Loss: 0.0003899 (Best: 0.0003247 @iter9628) ([91m↑5.61%[0m) [0.15% of initial]
[Iter 9850/20000] Loss: 0.0003626 (Best: 0.0003247 @iter9628) ([92m↓7.01%[0m) [0.14% of initial]
[Iter 9860/20000] Loss: 0.0003643 (Best: 0.0003247 @iter9628) ([91m↑0.48%[0m) [0.14% of initial]
[Iter 9870/20000] Loss: 0.0003904 (Best: 0.0003247 @iter9628) ([91m↑7.18%[0m) [0.16% of initial]
[Iter 9880/20000] Loss: 0.0003917 (Best: 0.0003247 @iter9628) ([91m↑0.33%[0m) [0.16% of initial]
[Iter 9890/20000] Loss: 0.0004813 (Best: 0.0003247 @iter9628) ([91m↑22.85%[0m) [0.19% of initial]
Iter:9899, L1 loss=0.0005912, Total loss=0.0004719, Time:53
[Iter 9900/20000] Loss: 0.0004278 (Best: 0.0003247 @iter9628) ([92m↓11.10%[0m) [0.17% of initial]
[Iter 9910/20000] Loss: 0.0003687 (Best: 0.0003247 @iter9628) ([92m↓13.83%[0m) [0.15% of initial]
[Iter 9920/20000] Loss: 0.0003685 (Best: 0.0003213 @iter9919) ([92m↓0.06%[0m) [0.15% of initial]
[Iter 9930/20000] Loss: 0.0003934 (Best: 0.0003213 @iter9919) ([91m↑6.77%[0m) [0.16% of initial]
[Iter 9940/20000] Loss: 0.0003847 (Best: 0.0003213 @iter9919) ([92m↓2.22%[0m) [0.15% of initial]
[Iter 9950/20000] Loss: 0.0004316 (Best: 0.0003213 @iter9919) ([91m↑12.19%[0m) [0.17% of initial]
[Iter 9960/20000] Loss: 0.0004304 (Best: 0.0003213 @iter9919) ([92m↓0.27%[0m) [0.17% of initial]
[Iter 9970/20000] Loss: 0.0004015 (Best: 0.0003213 @iter9919) ([92m↓6.72%[0m) [0.16% of initial]
[Iter 9980/20000] Loss: 0.0003815 (Best: 0.0003213 @iter9919) ([92m↓4.97%[0m) [0.15% of initial]
[Iter 9990/20000] Loss: 0.0003969 (Best: 0.0003213 @iter9919) ([91m↑4.02%[0m) [0.16% of initial]
Iter:9999, L1 loss=0.0005777, Total loss=0.0004944, Time:51
[Iter 10000/20000] Loss: 0.0004505 (Best: 0.0003213 @iter9919) ([91m↑13.52%[0m) [0.18% of initial]
Pruning 34 points (0.0%) from gaussian0 at iteration 10000
Pruning 16 points (0.0%) from gaussian1 at iteration 10000
[Iter 10010/20000] Loss: 0.0007108 (Best: 0.0003213 @iter9919) ([91m↑57.78%[0m) [0.28% of initial]
[Iter 10020/20000] Loss: 0.0005745 (Best: 0.0003213 @iter9919) ([92m↓19.18%[0m) [0.23% of initial]
[Iter 10030/20000] Loss: 0.0004279 (Best: 0.0003213 @iter9919) ([92m↓25.51%[0m) [0.17% of initial]
[Iter 10040/20000] Loss: 0.0003917 (Best: 0.0003213 @iter9919) ([92m↓8.46%[0m) [0.16% of initial]
[Iter 10050/20000] Loss: 0.0003666 (Best: 0.0003213 @iter9919) ([92m↓6.41%[0m) [0.15% of initial]
[Iter 10060/20000] Loss: 0.0003359 (Best: 0.0003162 @iter10057) ([92m↓8.37%[0m) [0.13% of initial]
[Iter 10070/20000] Loss: 0.0003374 (Best: 0.0003162 @iter10057) ([91m↑0.44%[0m) [0.13% of initial]
[Iter 10080/20000] Loss: 0.0003463 (Best: 0.0003147 @iter10072) ([91m↑2.64%[0m) [0.14% of initial]
[Iter 10090/20000] Loss: 0.0003364 (Best: 0.0003098 @iter10084) ([92m↓2.86%[0m) [0.13% of initial]
Iter:10099, L1 loss=0.0004069, Total loss=0.000338, Time:59
[Iter 10100/20000] Loss: 0.0003513 (Best: 0.0003098 @iter10084) ([91m↑4.43%[0m) [0.14% of initial]
[Iter 10110/20000] Loss: 0.0003562 (Best: 0.0003098 @iter10084) ([91m↑1.38%[0m) [0.14% of initial]
[Iter 10120/20000] Loss: 0.0003544 (Best: 0.0003098 @iter10084) ([92m↓0.49%[0m) [0.14% of initial]
[Iter 10130/20000] Loss: 0.0003559 (Best: 0.0003098 @iter10084) ([91m↑0.42%[0m) [0.14% of initial]
[Iter 10140/20000] Loss: 0.0004051 (Best: 0.0003098 @iter10084) ([91m↑13.81%[0m) [0.16% of initial]
[Iter 10150/20000] Loss: 0.0004078 (Best: 0.0003098 @iter10084) ([91m↑0.66%[0m) [0.16% of initial]
[Iter 10160/20000] Loss: 0.0004111 (Best: 0.0003098 @iter10084) ([91m↑0.81%[0m) [0.16% of initial]
[Iter 10170/20000] Loss: 0.0003841 (Best: 0.0003098 @iter10084) ([92m↓6.56%[0m) [0.15% of initial]
[Iter 10180/20000] Loss: 0.0003445 (Best: 0.0003098 @iter10084) ([92m↓10.31%[0m) [0.14% of initial]
[Iter 10190/20000] Loss: 0.0003249 (Best: 0.0003098 @iter10084) ([92m↓5.68%[0m) [0.13% of initial]
Iter:10199, L1 loss=0.0004526, Total loss=0.0003794, Time:54
[Iter 10200/20000] Loss: 0.0003677 (Best: 0.0003098 @iter10084) ([91m↑13.18%[0m) [0.15% of initial]
[Iter 10210/20000] Loss: 0.0003452 (Best: 0.0003098 @iter10084) ([92m↓6.13%[0m) [0.14% of initial]
[Iter 10220/20000] Loss: 0.0003556 (Best: 0.0003098 @iter10084) ([91m↑3.00%[0m) [0.14% of initial]
[Iter 10230/20000] Loss: 0.0003568 (Best: 0.0003098 @iter10084) ([91m↑0.35%[0m) [0.14% of initial]
[Iter 10240/20000] Loss: 0.0003446 (Best: 0.0003024 @iter10237) ([92m↓3.43%[0m) [0.14% of initial]
[Iter 10250/20000] Loss: 0.0003510 (Best: 0.0003024 @iter10237) ([91m↑1.86%[0m) [0.14% of initial]
[Iter 10260/20000] Loss: 0.0003830 (Best: 0.0003024 @iter10237) ([91m↑9.13%[0m) [0.15% of initial]
[Iter 10270/20000] Loss: 0.0003521 (Best: 0.0003024 @iter10237) ([92m↓8.07%[0m) [0.14% of initial]
[Iter 10280/20000] Loss: 0.0003535 (Best: 0.0003024 @iter10237) ([91m↑0.39%[0m) [0.14% of initial]
[Iter 10290/20000] Loss: 0.0003900 (Best: 0.0003024 @iter10237) ([91m↑10.32%[0m) [0.15% of initial]
Iter:10299, L1 loss=0.0003953, Total loss=0.0003469, Time:50
[Iter 10300/20000] Loss: 0.0003571 (Best: 0.0003024 @iter10237) ([92m↓8.43%[0m) [0.14% of initial]
[Iter 10310/20000] Loss: 0.0003683 (Best: 0.0003024 @iter10237) ([91m↑3.12%[0m) [0.15% of initial]
[Iter 10320/20000] Loss: 0.0003737 (Best: 0.0003024 @iter10237) ([91m↑1.47%[0m) [0.15% of initial]
[Iter 10330/20000] Loss: 0.0003631 (Best: 0.0003024 @iter10237) ([92m↓2.84%[0m) [0.14% of initial]
[Iter 10340/20000] Loss: 0.0004116 (Best: 0.0003024 @iter10237) ([91m↑13.37%[0m) [0.16% of initial]
[Iter 10350/20000] Loss: 0.0003810 (Best: 0.0003024 @iter10237) ([92m↓7.44%[0m) [0.15% of initial]
[Iter 10360/20000] Loss: 0.0004318 (Best: 0.0003024 @iter10237) ([91m↑13.35%[0m) [0.17% of initial]
[Iter 10370/20000] Loss: 0.0004371 (Best: 0.0003024 @iter10237) ([91m↑1.22%[0m) [0.17% of initial]
[Iter 10380/20000] Loss: 0.0003796 (Best: 0.0003024 @iter10237) ([92m↓13.14%[0m) [0.15% of initial]
[Iter 10390/20000] Loss: 0.0004015 (Best: 0.0003024 @iter10237) ([91m↑5.75%[0m) [0.16% of initial]
Iter:10399, L1 loss=0.0004165, Total loss=0.0003529, Time:50
[Iter 10400/20000] Loss: 0.0003801 (Best: 0.0003024 @iter10237) ([92m↓5.32%[0m) [0.15% of initial]
[Iter 10410/20000] Loss: 0.0003531 (Best: 0.0003024 @iter10237) ([92m↓7.09%[0m) [0.14% of initial]
[Iter 10420/20000] Loss: 0.0003618 (Best: 0.0003024 @iter10237) ([91m↑2.46%[0m) [0.14% of initial]
[Iter 10430/20000] Loss: 0.0004109 (Best: 0.0003024 @iter10237) ([91m↑13.57%[0m) [0.16% of initial]
[Iter 10440/20000] Loss: 0.0003789 (Best: 0.0003024 @iter10237) ([92m↓7.79%[0m) [0.15% of initial]
[Iter 10450/20000] Loss: 0.0003939 (Best: 0.0003024 @iter10237) ([91m↑3.96%[0m) [0.16% of initial]
[Iter 10460/20000] Loss: 0.0003286 (Best: 0.0003024 @iter10237) ([92m↓16.57%[0m) [0.13% of initial]
[Iter 10470/20000] Loss: 0.0004016 (Best: 0.0003024 @iter10237) ([91m↑22.20%[0m) [0.16% of initial]
[Iter 10480/20000] Loss: 0.0003632 (Best: 0.0003024 @iter10237) ([92m↓9.57%[0m) [0.14% of initial]
[Iter 10490/20000] Loss: 0.0003413 (Best: 0.0003024 @iter10237) ([92m↓6.03%[0m) [0.14% of initial]
Iter:10499, L1 loss=0.0004004, Total loss=0.0003274, Time:55
[Iter 10500/20000] Loss: 0.0003459 (Best: 0.0003024 @iter10237) ([91m↑1.35%[0m) [0.14% of initial]
Pruning 23 points (0.0%) from gaussian0 at iteration 10500
Pruning 18 points (0.0%) from gaussian1 at iteration 10500
[Iter 10510/20000] Loss: 0.0006096 (Best: 0.0003024 @iter10237) ([91m↑76.23%[0m) [0.24% of initial]
[Iter 10520/20000] Loss: 0.0004739 (Best: 0.0003024 @iter10237) ([92m↓22.25%[0m) [0.19% of initial]
[Iter 10530/20000] Loss: 0.0004344 (Best: 0.0003024 @iter10237) ([92m↓8.34%[0m) [0.17% of initial]
[Iter 10540/20000] Loss: 0.0003901 (Best: 0.0003024 @iter10237) ([92m↓10.21%[0m) [0.15% of initial]
[Iter 10550/20000] Loss: 0.0003479 (Best: 0.0003024 @iter10237) ([92m↓10.80%[0m) [0.14% of initial]
[Iter 10560/20000] Loss: 0.0003334 (Best: 0.0003024 @iter10237) ([92m↓4.17%[0m) [0.13% of initial]
[Iter 10570/20000] Loss: 0.0003301 (Best: 0.0002987 @iter10561) ([92m↓1.00%[0m) [0.13% of initial]
[Iter 10580/20000] Loss: 0.0003350 (Best: 0.0002987 @iter10561) ([91m↑1.50%[0m) [0.13% of initial]
[Iter 10590/20000] Loss: 0.0003333 (Best: 0.0002987 @iter10583) ([92m↓0.51%[0m) [0.13% of initial]
Iter:10599, L1 loss=0.0003707, Total loss=0.0003178, Time:50
[Iter 10600/20000] Loss: 0.0003268 (Best: 0.0002987 @iter10583) ([92m↓1.94%[0m) [0.13% of initial]
[Iter 10610/20000] Loss: 0.0003239 (Best: 0.0002903 @iter10603) ([92m↓0.89%[0m) [0.13% of initial]
[Iter 10620/20000] Loss: 0.0003199 (Best: 0.0002903 @iter10603) ([92m↓1.23%[0m) [0.13% of initial]
[Iter 10630/20000] Loss: 0.0003312 (Best: 0.0002891 @iter10627) ([91m↑3.52%[0m) [0.13% of initial]
[Iter 10640/20000] Loss: 0.0003699 (Best: 0.0002891 @iter10627) ([91m↑11.69%[0m) [0.15% of initial]
[Iter 10650/20000] Loss: 0.0003602 (Best: 0.0002891 @iter10627) ([92m↓2.63%[0m) [0.14% of initial]
[Iter 10660/20000] Loss: 0.0003418 (Best: 0.0002891 @iter10627) ([92m↓5.11%[0m) [0.14% of initial]
[Iter 10670/20000] Loss: 0.0003303 (Best: 0.0002891 @iter10627) ([92m↓3.37%[0m) [0.13% of initial]
[Iter 10680/20000] Loss: 0.0003212 (Best: 0.0002891 @iter10627) ([92m↓2.74%[0m) [0.13% of initial]
[Iter 10690/20000] Loss: 0.0003368 (Best: 0.0002891 @iter10627) ([91m↑4.86%[0m) [0.13% of initial]
Iter:10699, L1 loss=0.0004125, Total loss=0.0003648, Time:51
[Iter 10700/20000] Loss: 0.0003908 (Best: 0.0002891 @iter10627) ([91m↑16.03%[0m) [0.16% of initial]
[Iter 10710/20000] Loss: 0.0003934 (Best: 0.0002891 @iter10627) ([91m↑0.66%[0m) [0.16% of initial]
[Iter 10720/20000] Loss: 0.0004405 (Best: 0.0002891 @iter10627) ([91m↑11.97%[0m) [0.18% of initial]
[Iter 10730/20000] Loss: 0.0004243 (Best: 0.0002891 @iter10627) ([92m↓3.68%[0m) [0.17% of initial]
[Iter 10740/20000] Loss: 0.0003665 (Best: 0.0002891 @iter10627) ([92m↓13.62%[0m) [0.15% of initial]
[Iter 10750/20000] Loss: 0.0003609 (Best: 0.0002891 @iter10627) ([92m↓1.52%[0m) [0.14% of initial]
[Iter 10760/20000] Loss: 0.0003286 (Best: 0.0002891 @iter10627) ([92m↓8.96%[0m) [0.13% of initial]
[Iter 10770/20000] Loss: 0.0003184 (Best: 0.0002891 @iter10627) ([92m↓3.09%[0m) [0.13% of initial]
[Iter 10780/20000] Loss: 0.0003141 (Best: 0.0002891 @iter10627) ([92m↓1.38%[0m) [0.12% of initial]
[Iter 10790/20000] Loss: 0.0003293 (Best: 0.0002849 @iter10784) ([91m↑4.87%[0m) [0.13% of initial]
Iter:10799, L1 loss=0.000378, Total loss=0.0003165, Time:55
[Iter 10800/20000] Loss: 0.0003515 (Best: 0.0002849 @iter10784) ([91m↑6.73%[0m) [0.14% of initial]
[Iter 10810/20000] Loss: 0.0004002 (Best: 0.0002849 @iter10784) ([91m↑13.85%[0m) [0.16% of initial]
[Iter 10820/20000] Loss: 0.0003698 (Best: 0.0002849 @iter10784) ([92m↓7.60%[0m) [0.15% of initial]
[Iter 10830/20000] Loss: 0.0003628 (Best: 0.0002849 @iter10784) ([92m↓1.88%[0m) [0.14% of initial]
[Iter 10840/20000] Loss: 0.0003273 (Best: 0.0002849 @iter10784) ([92m↓9.80%[0m) [0.13% of initial]
[Iter 10850/20000] Loss: 0.0003516 (Best: 0.0002849 @iter10784) ([91m↑7.44%[0m) [0.14% of initial]
[Iter 10860/20000] Loss: 0.0003304 (Best: 0.0002849 @iter10784) ([92m↓6.04%[0m) [0.13% of initial]
[Iter 10870/20000] Loss: 0.0003336 (Best: 0.0002844 @iter10865) ([91m↑0.98%[0m) [0.13% of initial]
[Iter 10880/20000] Loss: 0.0003179 (Best: 0.0002844 @iter10876) ([92m↓4.70%[0m) [0.13% of initial]
[Iter 10890/20000] Loss: 0.0003296 (Best: 0.0002844 @iter10876) ([91m↑3.67%[0m) [0.13% of initial]
Iter:10899, L1 loss=0.0004373, Total loss=0.0003636, Time:50
[Iter 10900/20000] Loss: 0.0003392 (Best: 0.0002844 @iter10876) ([91m↑2.91%[0m) [0.13% of initial]
[Iter 10910/20000] Loss: 0.0003356 (Best: 0.0002844 @iter10876) ([92m↓1.06%[0m) [0.13% of initial]
[Iter 10920/20000] Loss: 0.0003217 (Best: 0.0002819 @iter10915) ([92m↓4.14%[0m) [0.13% of initial]
[Iter 10930/20000] Loss: 0.0003219 (Best: 0.0002819 @iter10915) ([91m↑0.05%[0m) [0.13% of initial]
[Iter 10940/20000] Loss: 0.0003492 (Best: 0.0002819 @iter10915) ([91m↑8.50%[0m) [0.14% of initial]
[Iter 10950/20000] Loss: 0.0003312 (Best: 0.0002819 @iter10915) ([92m↓5.16%[0m) [0.13% of initial]
[Iter 10960/20000] Loss: 0.0003366 (Best: 0.0002819 @iter10915) ([91m↑1.61%[0m) [0.13% of initial]
[Iter 10970/20000] Loss: 0.0003214 (Best: 0.0002819 @iter10915) ([92m↓4.51%[0m) [0.13% of initial]
[Iter 10980/20000] Loss: 0.0003053 (Best: 0.0002819 @iter10915) ([92m↓5.00%[0m) [0.12% of initial]
[Iter 10990/20000] Loss: 0.0003156 (Best: 0.0002819 @iter10915) ([91m↑3.37%[0m) [0.13% of initial]
Iter:10999, L1 loss=0.0003959, Total loss=0.0003282, Time:51
[Iter 11000/20000] Loss: 0.0003097 (Best: 0.0002819 @iter10915) ([92m↓1.88%[0m) [0.12% of initial]
Pruning 32 points (0.0%) from gaussian0 at iteration 11000
Pruning 16 points (0.0%) from gaussian1 at iteration 11000
[Iter 11010/20000] Loss: 0.0006820 (Best: 0.0002819 @iter10915) ([91m↑120.20%[0m) [0.27% of initial]
[Iter 11020/20000] Loss: 0.0005127 (Best: 0.0002819 @iter10915) ([92m↓24.82%[0m) [0.20% of initial]
[Iter 11030/20000] Loss: 0.0003787 (Best: 0.0002819 @iter10915) ([92m↓26.13%[0m) [0.15% of initial]
[Iter 11040/20000] Loss: 0.0003293 (Best: 0.0002819 @iter10915) ([92m↓13.06%[0m) [0.13% of initial]
[Iter 11050/20000] Loss: 0.0003257 (Best: 0.0002819 @iter10915) ([92m↓1.10%[0m) [0.13% of initial]
[Iter 11060/20000] Loss: 0.0002986 (Best: 0.0002762 @iter11056) ([92m↓8.31%[0m) [0.12% of initial]
[Iter 11070/20000] Loss: 0.0003212 (Best: 0.0002762 @iter11056) ([91m↑7.58%[0m) [0.13% of initial]
[Iter 11080/20000] Loss: 0.0003059 (Best: 0.0002762 @iter11056) ([92m↓4.78%[0m) [0.12% of initial]
[Iter 11090/20000] Loss: 0.0003306 (Best: 0.0002762 @iter11056) ([91m↑8.07%[0m) [0.13% of initial]
Iter:11099, L1 loss=0.0003429, Total loss=0.000298, Time:51
[Iter 11100/20000] Loss: 0.0003408 (Best: 0.0002762 @iter11056) ([91m↑3.08%[0m) [0.14% of initial]
[Iter 11110/20000] Loss: 0.0003783 (Best: 0.0002762 @iter11056) ([91m↑11.03%[0m) [0.15% of initial]
[Iter 11120/20000] Loss: 0.0003306 (Best: 0.0002762 @iter11056) ([92m↓12.62%[0m) [0.13% of initial]
[Iter 11130/20000] Loss: 0.0003867 (Best: 0.0002762 @iter11056) ([91m↑16.96%[0m) [0.15% of initial]
[Iter 11140/20000] Loss: 0.0003379 (Best: 0.0002762 @iter11056) ([92m↓12.61%[0m) [0.13% of initial]
[Iter 11150/20000] Loss: 0.0003346 (Best: 0.0002762 @iter11056) ([92m↓0.98%[0m) [0.13% of initial]
[Iter 11160/20000] Loss: 0.0003405 (Best: 0.0002762 @iter11056) ([91m↑1.75%[0m) [0.14% of initial]
[Iter 11170/20000] Loss: 0.0003387 (Best: 0.0002762 @iter11056) ([92m↓0.52%[0m) [0.13% of initial]
[Iter 11180/20000] Loss: 0.0003239 (Best: 0.0002762 @iter11056) ([92m↓4.38%[0m) [0.13% of initial]
[Iter 11190/20000] Loss: 0.0003428 (Best: 0.0002762 @iter11056) ([91m↑5.84%[0m) [0.14% of initial]
Iter:11199, L1 loss=0.0003652, Total loss=0.0003158, Time:42
[Iter 11200/20000] Loss: 0.0003183 (Best: 0.0002762 @iter11056) ([92m↓7.14%[0m) [0.13% of initial]
[Iter 11210/20000] Loss: 0.0002966 (Best: 0.0002762 @iter11056) ([92m↓6.81%[0m) [0.12% of initial]
[Iter 11220/20000] Loss: 0.0003147 (Best: 0.0002762 @iter11056) ([91m↑6.10%[0m) [0.13% of initial]
[Iter 11230/20000] Loss: 0.0003127 (Best: 0.0002704 @iter11227) ([92m↓0.63%[0m) [0.12% of initial]
[Iter 11240/20000] Loss: 0.0003124 (Best: 0.0002704 @iter11227) ([92m↓0.10%[0m) [0.12% of initial]
[Iter 11250/20000] Loss: 0.0003142 (Best: 0.0002704 @iter11227) ([91m↑0.59%[0m) [0.12% of initial]
[Iter 11260/20000] Loss: 0.0002953 (Best: 0.0002704 @iter11227) ([92m↓6.02%[0m) [0.12% of initial]
[Iter 11270/20000] Loss: 0.0002886 (Best: 0.0002676 @iter11270) ([92m↓2.29%[0m) [0.11% of initial]
[Iter 11280/20000] Loss: 0.0003029 (Best: 0.0002676 @iter11270) ([91m↑4.95%[0m) [0.12% of initial]
[Iter 11290/20000] Loss: 0.0002991 (Best: 0.0002676 @iter11270) ([92m↓1.24%[0m) [0.12% of initial]
Iter:11299, L1 loss=0.0003359, Total loss=0.0002781, Time:43
[Iter 11300/20000] Loss: 0.0002972 (Best: 0.0002676 @iter11270) ([92m↓0.62%[0m) [0.12% of initial]
[Iter 11310/20000] Loss: 0.0002762 (Best: 0.0002676 @iter11270) ([92m↓7.08%[0m) [0.11% of initial]
[Iter 11320/20000] Loss: 0.0002927 (Best: 0.0002571 @iter11315) ([91m↑5.98%[0m) [0.12% of initial]
[Iter 11330/20000] Loss: 0.0003057 (Best: 0.0002571 @iter11315) ([91m↑4.44%[0m) [0.12% of initial]
[Iter 11340/20000] Loss: 0.0003300 (Best: 0.0002571 @iter11315) ([91m↑7.95%[0m) [0.13% of initial]
[Iter 11350/20000] Loss: 0.0004217 (Best: 0.0002571 @iter11315) ([91m↑27.78%[0m) [0.17% of initial]
[Iter 11360/20000] Loss: 0.0003288 (Best: 0.0002571 @iter11315) ([92m↓22.04%[0m) [0.13% of initial]
[Iter 11370/20000] Loss: 0.0003666 (Best: 0.0002571 @iter11315) ([91m↑11.52%[0m) [0.15% of initial]
[Iter 11380/20000] Loss: 0.0003739 (Best: 0.0002571 @iter11315) ([91m↑1.97%[0m) [0.15% of initial]
[Iter 11390/20000] Loss: 0.0003694 (Best: 0.0002571 @iter11315) ([92m↓1.20%[0m) [0.15% of initial]
Iter:11399, L1 loss=0.0003989, Total loss=0.0003486, Time:54
[Iter 11400/20000] Loss: 0.0003638 (Best: 0.0002571 @iter11315) ([92m↓1.51%[0m) [0.14% of initial]
[Iter 11410/20000] Loss: 0.0003308 (Best: 0.0002571 @iter11315) ([92m↓9.06%[0m) [0.13% of initial]
[Iter 11420/20000] Loss: 0.0003039 (Best: 0.0002571 @iter11315) ([92m↓8.14%[0m) [0.12% of initial]
[Iter 11430/20000] Loss: 0.0003398 (Best: 0.0002571 @iter11315) ([91m↑11.82%[0m) [0.14% of initial]
[Iter 11440/20000] Loss: 0.0003418 (Best: 0.0002571 @iter11315) ([91m↑0.58%[0m) [0.14% of initial]
[Iter 11450/20000] Loss: 0.0003709 (Best: 0.0002571 @iter11315) ([91m↑8.51%[0m) [0.15% of initial]
[Iter 11460/20000] Loss: 0.0003284 (Best: 0.0002571 @iter11315) ([92m↓11.44%[0m) [0.13% of initial]
[Iter 11470/20000] Loss: 0.0003186 (Best: 0.0002571 @iter11315) ([92m↓3.00%[0m) [0.13% of initial]
[Iter 11480/20000] Loss: 0.0003092 (Best: 0.0002571 @iter11315) ([92m↓2.94%[0m) [0.12% of initial]
[Iter 11490/20000] Loss: 0.0003118 (Best: 0.0002571 @iter11315) ([91m↑0.84%[0m) [0.12% of initial]
Iter:11499, L1 loss=0.0004657, Total loss=0.0003761, Time:54
[Iter 11500/20000] Loss: 0.0003236 (Best: 0.0002571 @iter11315) ([91m↑3.76%[0m) [0.13% of initial]
Pruning 19 points (0.0%) from gaussian0 at iteration 11500
Pruning 14 points (0.0%) from gaussian1 at iteration 11500
[Iter 11510/20000] Loss: 0.0006348 (Best: 0.0002571 @iter11315) ([91m↑96.19%[0m) [0.25% of initial]
[Iter 11520/20000] Loss: 0.0004420 (Best: 0.0002571 @iter11315) ([92m↓30.36%[0m) [0.18% of initial]
[Iter 11530/20000] Loss: 0.0003833 (Best: 0.0002571 @iter11315) ([92m↓13.30%[0m) [0.15% of initial]
[Iter 11540/20000] Loss: 0.0003349 (Best: 0.0002571 @iter11315) ([92m↓12.61%[0m) [0.13% of initial]
[Iter 11550/20000] Loss: 0.0003274 (Best: 0.0002571 @iter11315) ([92m↓2.26%[0m) [0.13% of initial]
[Iter 11560/20000] Loss: 0.0003336 (Best: 0.0002571 @iter11315) ([91m↑1.90%[0m) [0.13% of initial]
[Iter 11570/20000] Loss: 0.0003102 (Best: 0.0002571 @iter11315) ([92m↓7.02%[0m) [0.12% of initial]
[Iter 11580/20000] Loss: 0.0003317 (Best: 0.0002571 @iter11315) ([91m↑6.94%[0m) [0.13% of initial]
[Iter 11590/20000] Loss: 0.0003058 (Best: 0.0002571 @iter11315) ([92m↓7.82%[0m) [0.12% of initial]
Iter:11599, L1 loss=0.0003279, Total loss=0.000282, Time:42
[Iter 11600/20000] Loss: 0.0002993 (Best: 0.0002571 @iter11315) ([92m↓2.13%[0m) [0.12% of initial]
[Iter 11610/20000] Loss: 0.0002897 (Best: 0.0002571 @iter11315) ([92m↓3.18%[0m) [0.12% of initial]
[Iter 11620/20000] Loss: 0.0002860 (Best: 0.0002571 @iter11315) ([92m↓1.28%[0m) [0.11% of initial]
[Iter 11630/20000] Loss: 0.0002641 (Best: 0.0002537 @iter11630) ([92m↓7.66%[0m) [0.10% of initial]
[Iter 11640/20000] Loss: 0.0003006 (Best: 0.0002537 @iter11630) ([91m↑13.81%[0m) [0.12% of initial]
[Iter 11650/20000] Loss: 0.0003046 (Best: 0.0002537 @iter11630) ([91m↑1.31%[0m) [0.12% of initial]
[Iter 11660/20000] Loss: 0.0003102 (Best: 0.0002537 @iter11630) ([91m↑1.83%[0m) [0.12% of initial]
[Iter 11670/20000] Loss: 0.0002894 (Best: 0.0002537 @iter11630) ([92m↓6.68%[0m) [0.11% of initial]
[Iter 11680/20000] Loss: 0.0003005 (Best: 0.0002537 @iter11630) ([91m↑3.82%[0m) [0.12% of initial]
[Iter 11690/20000] Loss: 0.0002952 (Best: 0.0002537 @iter11630) ([92m↓1.75%[0m) [0.12% of initial]
Iter:11699, L1 loss=0.000331, Total loss=0.0002778, Time:54
[Iter 11700/20000] Loss: 0.0002835 (Best: 0.0002537 @iter11630) ([92m↓3.97%[0m) [0.11% of initial]
[Iter 11710/20000] Loss: 0.0002820 (Best: 0.0002496 @iter11705) ([92m↓0.52%[0m) [0.11% of initial]
[Iter 11720/20000] Loss: 0.0002744 (Best: 0.0002433 @iter11716) ([92m↓2.71%[0m) [0.11% of initial]
[Iter 11730/20000] Loss: 0.0002928 (Best: 0.0002433 @iter11716) ([91m↑6.71%[0m) [0.12% of initial]
[Iter 11740/20000] Loss: 0.0003152 (Best: 0.0002433 @iter11716) ([91m↑7.63%[0m) [0.13% of initial]
[Iter 11750/20000] Loss: 0.0003257 (Best: 0.0002433 @iter11716) ([91m↑3.34%[0m) [0.13% of initial]
[Iter 11760/20000] Loss: 0.0003472 (Best: 0.0002433 @iter11716) ([91m↑6.62%[0m) [0.14% of initial]
[Iter 11770/20000] Loss: 0.0002992 (Best: 0.0002433 @iter11716) ([92m↓13.84%[0m) [0.12% of initial]
[Iter 11780/20000] Loss: 0.0003040 (Best: 0.0002433 @iter11716) ([91m↑1.62%[0m) [0.12% of initial]
[Iter 11790/20000] Loss: 0.0002834 (Best: 0.0002433 @iter11716) ([92m↓6.79%[0m) [0.11% of initial]
Iter:11799, L1 loss=0.0003589, Total loss=0.0003009, Time:52
[Iter 11800/20000] Loss: 0.0002759 (Best: 0.0002433 @iter11716) ([92m↓2.64%[0m) [0.11% of initial]
[Iter 11810/20000] Loss: 0.0002615 (Best: 0.0002433 @iter11716) ([92m↓5.21%[0m) [0.10% of initial]
[Iter 11820/20000] Loss: 0.0002887 (Best: 0.0002433 @iter11716) ([91m↑10.41%[0m) [0.11% of initial]
[Iter 11830/20000] Loss: 0.0003107 (Best: 0.0002433 @iter11716) ([91m↑7.59%[0m) [0.12% of initial]
[Iter 11840/20000] Loss: 0.0003055 (Best: 0.0002433 @iter11716) ([92m↓1.67%[0m) [0.12% of initial]
[Iter 11850/20000] Loss: 0.0002947 (Best: 0.0002433 @iter11716) ([92m↓3.53%[0m) [0.12% of initial]
[Iter 11860/20000] Loss: 0.0002935 (Best: 0.0002433 @iter11716) ([92m↓0.40%[0m) [0.12% of initial]
[Iter 11870/20000] Loss: 0.0002962 (Best: 0.0002433 @iter11716) ([91m↑0.91%[0m) [0.12% of initial]
[Iter 11880/20000] Loss: 0.0002977 (Best: 0.0002433 @iter11716) ([91m↑0.52%[0m) [0.12% of initial]
[Iter 11890/20000] Loss: 0.0003732 (Best: 0.0002433 @iter11716) ([91m↑25.34%[0m) [0.15% of initial]
Iter:11899, L1 loss=0.0003681, Total loss=0.0003494, Time:49
[Iter 11900/20000] Loss: 0.0003364 (Best: 0.0002433 @iter11716) ([92m↓9.87%[0m) [0.13% of initial]
[Iter 11910/20000] Loss: 0.0003381 (Best: 0.0002433 @iter11716) ([91m↑0.53%[0m) [0.13% of initial]
[Iter 11920/20000] Loss: 0.0003899 (Best: 0.0002433 @iter11716) ([91m↑15.32%[0m) [0.15% of initial]
[Iter 11930/20000] Loss: 0.0003425 (Best: 0.0002433 @iter11716) ([92m↓12.16%[0m) [0.14% of initial]
[Iter 11940/20000] Loss: 0.0003163 (Best: 0.0002433 @iter11716) ([92m↓7.66%[0m) [0.13% of initial]
[Iter 11950/20000] Loss: 0.0003171 (Best: 0.0002433 @iter11716) ([91m↑0.27%[0m) [0.13% of initial]
[Iter 11960/20000] Loss: 0.0002700 (Best: 0.0002433 @iter11716) ([92m↓14.86%[0m) [0.11% of initial]
[Iter 11970/20000] Loss: 0.0002924 (Best: 0.0002433 @iter11716) ([91m↑8.31%[0m) [0.12% of initial]
[Iter 11980/20000] Loss: 0.0002725 (Best: 0.0002433 @iter11716) ([92m↓6.81%[0m) [0.11% of initial]
[Iter 11990/20000] Loss: 0.0002931 (Best: 0.0002433 @iter11716) ([91m↑7.56%[0m) [0.12% of initial]
Iter:11999, L1 loss=0.0003417, Total loss=0.0002907, Time:52
[Iter 12000/20000] Loss: 0.0003215 (Best: 0.0002433 @iter11716) ([91m↑9.68%[0m) [0.13% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 12000
Pruning 14 points (0.0%) from gaussian1 at iteration 12000
[Iter 12010/20000] Loss: 0.0210555 (Best: 0.0002433 @iter11716) ([91m↑6449.44%[0m) [8.37% of initial]
[Iter 12020/20000] Loss: 0.0056027 (Best: 0.0002433 @iter11716) ([92m↓73.39%[0m) [2.23% of initial]
[Iter 12030/20000] Loss: 0.0041610 (Best: 0.0002433 @iter11716) ([92m↓25.73%[0m) [1.65% of initial]
[Iter 12040/20000] Loss: 0.0022008 (Best: 0.0002433 @iter11716) ([92m↓47.11%[0m) [0.87% of initial]
[Iter 12050/20000] Loss: 0.0014315 (Best: 0.0002433 @iter11716) ([92m↓34.96%[0m) [0.57% of initial]
[Iter 12060/20000] Loss: 0.0009980 (Best: 0.0002433 @iter11716) ([92m↓30.28%[0m) [0.40% of initial]
[Iter 12070/20000] Loss: 0.0007630 (Best: 0.0002433 @iter11716) ([92m↓23.54%[0m) [0.30% of initial]
[Iter 12080/20000] Loss: 0.0006443 (Best: 0.0002433 @iter11716) ([92m↓15.56%[0m) [0.26% of initial]
[Iter 12090/20000] Loss: 0.0005603 (Best: 0.0002433 @iter11716) ([92m↓13.04%[0m) [0.22% of initial]
Iter:12099, L1 loss=0.0006146, Total loss=0.0005502, Time:48
[Iter 12100/20000] Loss: 0.0005211 (Best: 0.0002433 @iter11716) ([92m↓7.00%[0m) [0.21% of initial]
[Iter 12110/20000] Loss: 0.0004796 (Best: 0.0002433 @iter11716) ([92m↓7.95%[0m) [0.19% of initial]
[Iter 12120/20000] Loss: 0.0004569 (Best: 0.0002433 @iter11716) ([92m↓4.74%[0m) [0.18% of initial]
[Iter 12130/20000] Loss: 0.0004289 (Best: 0.0002433 @iter11716) ([92m↓6.13%[0m) [0.17% of initial]
[Iter 12140/20000] Loss: 0.0004084 (Best: 0.0002433 @iter11716) ([92m↓4.78%[0m) [0.16% of initial]
[Iter 12150/20000] Loss: 0.0004135 (Best: 0.0002433 @iter11716) ([91m↑1.27%[0m) [0.16% of initial]
[Iter 12160/20000] Loss: 0.0003890 (Best: 0.0002433 @iter11716) ([92m↓5.93%[0m) [0.15% of initial]
[Iter 12170/20000] Loss: 0.0003710 (Best: 0.0002433 @iter11716) ([92m↓4.64%[0m) [0.15% of initial]
[Iter 12180/20000] Loss: 0.0003625 (Best: 0.0002433 @iter11716) ([92m↓2.30%[0m) [0.14% of initial]
[Iter 12190/20000] Loss: 0.0003620 (Best: 0.0002433 @iter11716) ([92m↓0.13%[0m) [0.14% of initial]
Iter:12199, L1 loss=0.0004125, Total loss=0.000362, Time:42
[Iter 12200/20000] Loss: 0.0003488 (Best: 0.0002433 @iter11716) ([92m↓3.63%[0m) [0.14% of initial]
[Iter 12210/20000] Loss: 0.0003598 (Best: 0.0002433 @iter11716) ([91m↑3.13%[0m) [0.14% of initial]
[Iter 12220/20000] Loss: 0.0003445 (Best: 0.0002433 @iter11716) ([92m↓4.25%[0m) [0.14% of initial]
[Iter 12230/20000] Loss: 0.0003448 (Best: 0.0002433 @iter11716) ([91m↑0.08%[0m) [0.14% of initial]
[Iter 12240/20000] Loss: 0.0003614 (Best: 0.0002433 @iter11716) ([91m↑4.81%[0m) [0.14% of initial]
[Iter 12250/20000] Loss: 0.0003423 (Best: 0.0002433 @iter11716) ([92m↓5.26%[0m) [0.14% of initial]
[Iter 12260/20000] Loss: 0.0003384 (Best: 0.0002433 @iter11716) ([92m↓1.14%[0m) [0.13% of initial]
[Iter 12270/20000] Loss: 0.0003361 (Best: 0.0002433 @iter11716) ([92m↓0.69%[0m) [0.13% of initial]
[Iter 12280/20000] Loss: 0.0003449 (Best: 0.0002433 @iter11716) ([91m↑2.62%[0m) [0.14% of initial]
[Iter 12290/20000] Loss: 0.0003815 (Best: 0.0002433 @iter11716) ([91m↑10.61%[0m) [0.15% of initial]
Iter:12299, L1 loss=0.0003926, Total loss=0.000339, Time:56
[Iter 12300/20000] Loss: 0.0003429 (Best: 0.0002433 @iter11716) ([92m↓10.12%[0m) [0.14% of initial]
[Iter 12310/20000] Loss: 0.0003344 (Best: 0.0002433 @iter11716) ([92m↓2.48%[0m) [0.13% of initial]
[Iter 12320/20000] Loss: 0.0003370 (Best: 0.0002433 @iter11716) ([91m↑0.78%[0m) [0.13% of initial]
[Iter 12330/20000] Loss: 0.0003542 (Best: 0.0002433 @iter11716) ([91m↑5.10%[0m) [0.14% of initial]
[Iter 12340/20000] Loss: 0.0003522 (Best: 0.0002433 @iter11716) ([92m↓0.57%[0m) [0.14% of initial]
[Iter 12350/20000] Loss: 0.0003489 (Best: 0.0002433 @iter11716) ([92m↓0.91%[0m) [0.14% of initial]
[Iter 12360/20000] Loss: 0.0003467 (Best: 0.0002433 @iter11716) ([92m↓0.64%[0m) [0.14% of initial]
[Iter 12370/20000] Loss: 0.0003276 (Best: 0.0002433 @iter11716) ([92m↓5.51%[0m) [0.13% of initial]
[Iter 12380/20000] Loss: 0.0003273 (Best: 0.0002433 @iter11716) ([92m↓0.09%[0m) [0.13% of initial]
[Iter 12390/20000] Loss: 0.0003322 (Best: 0.0002433 @iter11716) ([91m↑1.49%[0m) [0.13% of initial]
Iter:12399, L1 loss=0.0003626, Total loss=0.0003221, Time:51
[Iter 12400/20000] Loss: 0.0003282 (Best: 0.0002433 @iter11716) ([92m↓1.20%[0m) [0.13% of initial]
[Iter 12410/20000] Loss: 0.0003449 (Best: 0.0002433 @iter11716) ([91m↑5.09%[0m) [0.14% of initial]
[Iter 12420/20000] Loss: 0.0003349 (Best: 0.0002433 @iter11716) ([92m↓2.91%[0m) [0.13% of initial]
[Iter 12430/20000] Loss: 0.0003330 (Best: 0.0002433 @iter11716) ([92m↓0.56%[0m) [0.13% of initial]
[Iter 12440/20000] Loss: 0.0003409 (Best: 0.0002433 @iter11716) ([91m↑2.37%[0m) [0.14% of initial]
[Iter 12450/20000] Loss: 0.0003393 (Best: 0.0002433 @iter11716) ([92m↓0.47%[0m) [0.13% of initial]
[Iter 12460/20000] Loss: 0.0003235 (Best: 0.0002433 @iter11716) ([92m↓4.67%[0m) [0.13% of initial]
[Iter 12470/20000] Loss: 0.0003314 (Best: 0.0002433 @iter11716) ([91m↑2.45%[0m) [0.13% of initial]
[Iter 12480/20000] Loss: 0.0003356 (Best: 0.0002433 @iter11716) ([91m↑1.26%[0m) [0.13% of initial]
[Iter 12490/20000] Loss: 0.0003345 (Best: 0.0002433 @iter11716) ([92m↓0.33%[0m) [0.13% of initial]
Iter:12499, L1 loss=0.0003941, Total loss=0.0003394, Time:24
[Iter 12500/20000] Loss: 0.0003433 (Best: 0.0002433 @iter11716) ([91m↑2.65%[0m) [0.14% of initial]
Pruning 20 points (0.0%) from gaussian0 at iteration 12500
Pruning 24 points (0.0%) from gaussian1 at iteration 12500
[Iter 12510/20000] Loss: 0.0006858 (Best: 0.0002433 @iter11716) ([91m↑99.74%[0m) [0.27% of initial]
[Iter 12520/20000] Loss: 0.0004777 (Best: 0.0002433 @iter11716) ([92m↓30.34%[0m) [0.19% of initial]
[Iter 12530/20000] Loss: 0.0003839 (Best: 0.0002433 @iter11716) ([92m↓19.63%[0m) [0.15% of initial]
[Iter 12540/20000] Loss: 0.0003539 (Best: 0.0002433 @iter11716) ([92m↓7.83%[0m) [0.14% of initial]
[Iter 12550/20000] Loss: 0.0003206 (Best: 0.0002433 @iter11716) ([92m↓9.40%[0m) [0.13% of initial]
[Iter 12560/20000] Loss: 0.0003150 (Best: 0.0002433 @iter11716) ([92m↓1.76%[0m) [0.13% of initial]
[Iter 12570/20000] Loss: 0.0003318 (Best: 0.0002433 @iter11716) ([91m↑5.34%[0m) [0.13% of initial]
[Iter 12580/20000] Loss: 0.0003444 (Best: 0.0002433 @iter11716) ([91m↑3.81%[0m) [0.14% of initial]
[Iter 12590/20000] Loss: 0.0003415 (Best: 0.0002433 @iter11716) ([92m↓0.86%[0m) [0.14% of initial]
Iter:12599, L1 loss=0.0004781, Total loss=0.0004105, Time:29
[Iter 12600/20000] Loss: 0.0003647 (Best: 0.0002433 @iter11716) ([91m↑6.81%[0m) [0.14% of initial]
[Iter 12610/20000] Loss: 0.0003664 (Best: 0.0002433 @iter11716) ([91m↑0.47%[0m) [0.15% of initial]
[Iter 12620/20000] Loss: 0.0003424 (Best: 0.0002433 @iter11716) ([92m↓6.56%[0m) [0.14% of initial]
[Iter 12630/20000] Loss: 0.0003559 (Best: 0.0002433 @iter11716) ([91m↑3.96%[0m) [0.14% of initial]
[Iter 12640/20000] Loss: 0.0003578 (Best: 0.0002433 @iter11716) ([91m↑0.53%[0m) [0.14% of initial]
[Iter 12650/20000] Loss: 0.0003465 (Best: 0.0002433 @iter11716) ([92m↓3.17%[0m) [0.14% of initial]
[Iter 12660/20000] Loss: 0.0003501 (Best: 0.0002433 @iter11716) ([91m↑1.06%[0m) [0.14% of initial]
[Iter 12670/20000] Loss: 0.0003520 (Best: 0.0002433 @iter11716) ([91m↑0.54%[0m) [0.14% of initial]
[Iter 12680/20000] Loss: 0.0003851 (Best: 0.0002433 @iter11716) ([91m↑9.41%[0m) [0.15% of initial]
[Iter 12690/20000] Loss: 0.0003582 (Best: 0.0002433 @iter11716) ([92m↓6.99%[0m) [0.14% of initial]
Iter:12699, L1 loss=0.0004355, Total loss=0.0003664, Time:29
[Iter 12700/20000] Loss: 0.0003537 (Best: 0.0002433 @iter11716) ([92m↓1.27%[0m) [0.14% of initial]
[Iter 12710/20000] Loss: 0.0003525 (Best: 0.0002433 @iter11716) ([92m↓0.33%[0m) [0.14% of initial]
[Iter 12720/20000] Loss: 0.0003483 (Best: 0.0002433 @iter11716) ([92m↓1.18%[0m) [0.14% of initial]
[Iter 12730/20000] Loss: 0.0003746 (Best: 0.0002433 @iter11716) ([91m↑7.54%[0m) [0.15% of initial]
[Iter 12740/20000] Loss: 0.0003512 (Best: 0.0002433 @iter11716) ([92m↓6.25%[0m) [0.14% of initial]
[Iter 12750/20000] Loss: 0.0003303 (Best: 0.0002433 @iter11716) ([92m↓5.94%[0m) [0.13% of initial]
[Iter 12760/20000] Loss: 0.0003293 (Best: 0.0002433 @iter11716) ([92m↓0.32%[0m) [0.13% of initial]
[Iter 12770/20000] Loss: 0.0003402 (Best: 0.0002433 @iter11716) ([91m↑3.32%[0m) [0.14% of initial]
[Iter 12780/20000] Loss: 0.0003656 (Best: 0.0002433 @iter11716) ([91m↑7.47%[0m) [0.15% of initial]
[Iter 12790/20000] Loss: 0.0003503 (Best: 0.0002433 @iter11716) ([92m↓4.17%[0m) [0.14% of initial]
Iter:12799, L1 loss=0.0003904, Total loss=0.0003325, Time:30
[Iter 12800/20000] Loss: 0.0003463 (Best: 0.0002433 @iter11716) ([92m↓1.16%[0m) [0.14% of initial]
[Iter 12810/20000] Loss: 0.0003809 (Best: 0.0002433 @iter11716) ([91m↑9.99%[0m) [0.15% of initial]
[Iter 12820/20000] Loss: 0.0003539 (Best: 0.0002433 @iter11716) ([92m↓7.09%[0m) [0.14% of initial]
[Iter 12830/20000] Loss: 0.0003467 (Best: 0.0002433 @iter11716) ([92m↓2.02%[0m) [0.14% of initial]
[Iter 12840/20000] Loss: 0.0003498 (Best: 0.0002433 @iter11716) ([91m↑0.88%[0m) [0.14% of initial]
[Iter 12850/20000] Loss: 0.0003384 (Best: 0.0002433 @iter11716) ([92m↓3.27%[0m) [0.13% of initial]
[Iter 12860/20000] Loss: 0.0003272 (Best: 0.0002433 @iter11716) ([92m↓3.29%[0m) [0.13% of initial]
[Iter 12870/20000] Loss: 0.0003259 (Best: 0.0002433 @iter11716) ([92m↓0.40%[0m) [0.13% of initial]
[Iter 12880/20000] Loss: 0.0003156 (Best: 0.0002433 @iter11716) ([92m↓3.16%[0m) [0.13% of initial]
[Iter 12890/20000] Loss: 0.0003186 (Best: 0.0002433 @iter11716) ([91m↑0.94%[0m) [0.13% of initial]
Iter:12899, L1 loss=0.0003733, Total loss=0.0003209, Time:28
[Iter 12900/20000] Loss: 0.0003106 (Best: 0.0002433 @iter11716) ([92m↓2.51%[0m) [0.12% of initial]
[Iter 12910/20000] Loss: 0.0003188 (Best: 0.0002433 @iter11716) ([91m↑2.66%[0m) [0.13% of initial]
[Iter 12920/20000] Loss: 0.0003408 (Best: 0.0002433 @iter11716) ([91m↑6.89%[0m) [0.14% of initial]
[Iter 12930/20000] Loss: 0.0003449 (Best: 0.0002433 @iter11716) ([91m↑1.19%[0m) [0.14% of initial]
[Iter 12940/20000] Loss: 0.0003649 (Best: 0.0002433 @iter11716) ([91m↑5.82%[0m) [0.14% of initial]
[Iter 12950/20000] Loss: 0.0003667 (Best: 0.0002433 @iter11716) ([91m↑0.49%[0m) [0.15% of initial]
[Iter 12960/20000] Loss: 0.0003975 (Best: 0.0002433 @iter11716) ([91m↑8.39%[0m) [0.16% of initial]
[Iter 12970/20000] Loss: 0.0003305 (Best: 0.0002433 @iter11716) ([92m↓16.87%[0m) [0.13% of initial]
[Iter 12980/20000] Loss: 0.0003631 (Best: 0.0002433 @iter11716) ([91m↑9.88%[0m) [0.14% of initial]
[Iter 12990/20000] Loss: 0.0003526 (Best: 0.0002433 @iter11716) ([92m↓2.89%[0m) [0.14% of initial]
Iter:12999, L1 loss=0.00037, Total loss=0.000324, Time:29
[Iter 13000/20000] Loss: 0.0003259 (Best: 0.0002433 @iter11716) ([92m↓7.58%[0m) [0.13% of initial]
Pruning 14 points (0.0%) from gaussian0 at iteration 13000
Pruning 7 points (0.0%) from gaussian1 at iteration 13000
[Iter 13010/20000] Loss: 0.0008952 (Best: 0.0002433 @iter11716) ([91m↑174.67%[0m) [0.36% of initial]
[Iter 13020/20000] Loss: 0.0005504 (Best: 0.0002433 @iter11716) ([92m↓38.52%[0m) [0.22% of initial]
[Iter 13030/20000] Loss: 0.0004220 (Best: 0.0002433 @iter11716) ([92m↓23.33%[0m) [0.17% of initial]
[Iter 13040/20000] Loss: 0.0003778 (Best: 0.0002433 @iter11716) ([92m↓10.48%[0m) [0.15% of initial]
[Iter 13050/20000] Loss: 0.0003293 (Best: 0.0002433 @iter11716) ([92m↓12.84%[0m) [0.13% of initial]
[Iter 13060/20000] Loss: 0.0003207 (Best: 0.0002433 @iter11716) ([92m↓2.59%[0m) [0.13% of initial]
[Iter 13070/20000] Loss: 0.0003230 (Best: 0.0002433 @iter11716) ([91m↑0.69%[0m) [0.13% of initial]
[Iter 13080/20000] Loss: 0.0003121 (Best: 0.0002433 @iter11716) ([92m↓3.35%[0m) [0.12% of initial]
[Iter 13090/20000] Loss: 0.0003226 (Best: 0.0002433 @iter11716) ([91m↑3.36%[0m) [0.13% of initial]
Iter:13099, L1 loss=0.0003715, Total loss=0.0003154, Time:28
[Iter 13100/20000] Loss: 0.0003246 (Best: 0.0002433 @iter11716) ([91m↑0.63%[0m) [0.13% of initial]
[Iter 13110/20000] Loss: 0.0003317 (Best: 0.0002433 @iter11716) ([91m↑2.17%[0m) [0.13% of initial]
[Iter 13120/20000] Loss: 0.0003141 (Best: 0.0002433 @iter11716) ([92m↓5.32%[0m) [0.12% of initial]
[Iter 13130/20000] Loss: 0.0003219 (Best: 0.0002433 @iter11716) ([91m↑2.50%[0m) [0.13% of initial]
[Iter 13140/20000] Loss: 0.0003128 (Best: 0.0002433 @iter11716) ([92m↓2.83%[0m) [0.12% of initial]
[Iter 13150/20000] Loss: 0.0003004 (Best: 0.0002433 @iter11716) ([92m↓3.97%[0m) [0.12% of initial]
[Iter 13160/20000] Loss: 0.0003217 (Best: 0.0002433 @iter11716) ([91m↑7.10%[0m) [0.13% of initial]
[Iter 13170/20000] Loss: 0.0003190 (Best: 0.0002433 @iter11716) ([92m↓0.85%[0m) [0.13% of initial]
[Iter 13180/20000] Loss: 0.0003452 (Best: 0.0002433 @iter11716) ([91m↑8.22%[0m) [0.14% of initial]
[Iter 13190/20000] Loss: 0.0003312 (Best: 0.0002433 @iter11716) ([92m↓4.06%[0m) [0.13% of initial]
Iter:13199, L1 loss=0.0003809, Total loss=0.000326, Time:28
[Iter 13200/20000] Loss: 0.0003374 (Best: 0.0002433 @iter11716) ([91m↑1.87%[0m) [0.13% of initial]
[Iter 13210/20000] Loss: 0.0003489 (Best: 0.0002433 @iter11716) ([91m↑3.41%[0m) [0.14% of initial]
[Iter 13220/20000] Loss: 0.0003128 (Best: 0.0002433 @iter11716) ([92m↓10.35%[0m) [0.12% of initial]
[Iter 13230/20000] Loss: 0.0003534 (Best: 0.0002433 @iter11716) ([91m↑12.97%[0m) [0.14% of initial]
[Iter 13240/20000] Loss: 0.0003297 (Best: 0.0002433 @iter11716) ([92m↓6.70%[0m) [0.13% of initial]
[Iter 13250/20000] Loss: 0.0003281 (Best: 0.0002433 @iter11716) ([92m↓0.50%[0m) [0.13% of initial]
[Iter 13260/20000] Loss: 0.0003140 (Best: 0.0002433 @iter11716) ([92m↓4.29%[0m) [0.12% of initial]
[Iter 13270/20000] Loss: 0.0003193 (Best: 0.0002433 @iter11716) ([91m↑1.68%[0m) [0.13% of initial]
[Iter 13280/20000] Loss: 0.0003289 (Best: 0.0002433 @iter11716) ([91m↑3.01%[0m) [0.13% of initial]
[Iter 13290/20000] Loss: 0.0003032 (Best: 0.0002433 @iter11716) ([92m↓7.80%[0m) [0.12% of initial]
Iter:13299, L1 loss=0.0003368, Total loss=0.0002966, Time:30
[Iter 13300/20000] Loss: 0.0002984 (Best: 0.0002433 @iter11716) ([92m↓1.58%[0m) [0.12% of initial]
[Iter 13310/20000] Loss: 0.0002964 (Best: 0.0002433 @iter11716) ([92m↓0.68%[0m) [0.12% of initial]
[Iter 13320/20000] Loss: 0.0002971 (Best: 0.0002433 @iter11716) ([91m↑0.24%[0m) [0.12% of initial]
[Iter 13330/20000] Loss: 0.0003045 (Best: 0.0002433 @iter11716) ([91m↑2.47%[0m) [0.12% of initial]
[Iter 13340/20000] Loss: 0.0003164 (Best: 0.0002433 @iter11716) ([91m↑3.91%[0m) [0.13% of initial]
[Iter 13350/20000] Loss: 0.0003017 (Best: 0.0002433 @iter11716) ([92m↓4.62%[0m) [0.12% of initial]
[Iter 13360/20000] Loss: 0.0003108 (Best: 0.0002433 @iter11716) ([91m↑3.02%[0m) [0.12% of initial]
[Iter 13370/20000] Loss: 0.0002889 (Best: 0.0002433 @iter11716) ([92m↓7.04%[0m) [0.11% of initial]
[Iter 13380/20000] Loss: 0.0003183 (Best: 0.0002433 @iter11716) ([91m↑10.15%[0m) [0.13% of initial]
[Iter 13390/20000] Loss: 0.0003228 (Best: 0.0002433 @iter11716) ([91m↑1.43%[0m) [0.13% of initial]
Iter:13399, L1 loss=0.0003462, Total loss=0.0002989, Time:29
[Iter 13400/20000] Loss: 0.0003287 (Best: 0.0002433 @iter11716) ([91m↑1.83%[0m) [0.13% of initial]
[Iter 13410/20000] Loss: 0.0003132 (Best: 0.0002433 @iter11716) ([92m↓4.73%[0m) [0.12% of initial]
[Iter 13420/20000] Loss: 0.0003110 (Best: 0.0002433 @iter11716) ([92m↓0.72%[0m) [0.12% of initial]
[Iter 13430/20000] Loss: 0.0002882 (Best: 0.0002433 @iter11716) ([92m↓7.31%[0m) [0.11% of initial]
[Iter 13440/20000] Loss: 0.0003007 (Best: 0.0002433 @iter11716) ([91m↑4.33%[0m) [0.12% of initial]
[Iter 13450/20000] Loss: 0.0002893 (Best: 0.0002433 @iter11716) ([92m↓3.79%[0m) [0.11% of initial]
[Iter 13460/20000] Loss: 0.0002835 (Best: 0.0002433 @iter11716) ([92m↓2.00%[0m) [0.11% of initial]
[Iter 13470/20000] Loss: 0.0003009 (Best: 0.0002433 @iter11716) ([91m↑6.13%[0m) [0.12% of initial]
[Iter 13480/20000] Loss: 0.0002990 (Best: 0.0002433 @iter11716) ([92m↓0.64%[0m) [0.12% of initial]
[Iter 13490/20000] Loss: 0.0003690 (Best: 0.0002433 @iter11716) ([91m↑23.41%[0m) [0.15% of initial]
Iter:13499, L1 loss=0.00038, Total loss=0.0003283, Time:29
[Iter 13500/20000] Loss: 0.0003439 (Best: 0.0002433 @iter11716) ([92m↓6.80%[0m) [0.14% of initial]
Pruning 16 points (0.0%) from gaussian0 at iteration 13500
Pruning 7 points (0.0%) from gaussian1 at iteration 13500
[Iter 13510/20000] Loss: 0.0006218 (Best: 0.0002433 @iter11716) ([91m↑80.83%[0m) [0.25% of initial]
[Iter 13520/20000] Loss: 0.0004311 (Best: 0.0002433 @iter11716) ([92m↓30.68%[0m) [0.17% of initial]
[Iter 13530/20000] Loss: 0.0003756 (Best: 0.0002433 @iter11716) ([92m↓12.86%[0m) [0.15% of initial]
[Iter 13540/20000] Loss: 0.0003293 (Best: 0.0002433 @iter11716) ([92m↓12.32%[0m) [0.13% of initial]
[Iter 13550/20000] Loss: 0.0003127 (Best: 0.0002433 @iter11716) ([92m↓5.05%[0m) [0.12% of initial]
[Iter 13560/20000] Loss: 0.0003028 (Best: 0.0002433 @iter11716) ([92m↓3.18%[0m) [0.12% of initial]
[Iter 13570/20000] Loss: 0.0002890 (Best: 0.0002433 @iter11716) ([92m↓4.55%[0m) [0.11% of initial]
[Iter 13580/20000] Loss: 0.0003174 (Best: 0.0002433 @iter11716) ([91m↑9.82%[0m) [0.13% of initial]
[Iter 13590/20000] Loss: 0.0003143 (Best: 0.0002433 @iter11716) ([92m↓0.98%[0m) [0.12% of initial]
Iter:13599, L1 loss=0.000326, Total loss=0.0002775, Time:30
[Iter 13600/20000] Loss: 0.0002784 (Best: 0.0002433 @iter11716) ([92m↓11.43%[0m) [0.11% of initial]
[Iter 13610/20000] Loss: 0.0002902 (Best: 0.0002433 @iter11716) ([91m↑4.25%[0m) [0.12% of initial]
[Iter 13620/20000] Loss: 0.0002836 (Best: 0.0002433 @iter11716) ([92m↓2.28%[0m) [0.11% of initial]
[Iter 13630/20000] Loss: 0.0002784 (Best: 0.0002433 @iter11716) ([92m↓1.82%[0m) [0.11% of initial]
[Iter 13640/20000] Loss: 0.0003297 (Best: 0.0002433 @iter11716) ([91m↑18.42%[0m) [0.13% of initial]
[Iter 13650/20000] Loss: 0.0003253 (Best: 0.0002433 @iter11716) ([92m↓1.33%[0m) [0.13% of initial]
[Iter 13660/20000] Loss: 0.0003093 (Best: 0.0002433 @iter11716) ([92m↓4.91%[0m) [0.12% of initial]
[Iter 13670/20000] Loss: 0.0003285 (Best: 0.0002433 @iter11716) ([91m↑6.20%[0m) [0.13% of initial]
[Iter 13680/20000] Loss: 0.0003219 (Best: 0.0002433 @iter11716) ([92m↓2.01%[0m) [0.13% of initial]
[Iter 13690/20000] Loss: 0.0003430 (Best: 0.0002433 @iter11716) ([91m↑6.57%[0m) [0.14% of initial]
Iter:13699, L1 loss=0.0004074, Total loss=0.0003385, Time:28
[Iter 13700/20000] Loss: 0.0003293 (Best: 0.0002433 @iter11716) ([92m↓4.00%[0m) [0.13% of initial]
[Iter 13710/20000] Loss: 0.0003062 (Best: 0.0002433 @iter11716) ([92m↓7.00%[0m) [0.12% of initial]
[Iter 13720/20000] Loss: 0.0003036 (Best: 0.0002433 @iter11716) ([92m↓0.86%[0m) [0.12% of initial]
[Iter 13730/20000] Loss: 0.0003164 (Best: 0.0002433 @iter11716) ([91m↑4.22%[0m) [0.13% of initial]
[Iter 13740/20000] Loss: 0.0003253 (Best: 0.0002433 @iter11716) ([91m↑2.82%[0m) [0.13% of initial]
[Iter 13750/20000] Loss: 0.0002995 (Best: 0.0002433 @iter11716) ([92m↓7.95%[0m) [0.12% of initial]
[Iter 13760/20000] Loss: 0.0003230 (Best: 0.0002433 @iter11716) ([91m↑7.84%[0m) [0.13% of initial]
[Iter 13770/20000] Loss: 0.0003330 (Best: 0.0002433 @iter11716) ([91m↑3.12%[0m) [0.13% of initial]
[Iter 13780/20000] Loss: 0.0003234 (Best: 0.0002433 @iter11716) ([92m↓2.89%[0m) [0.13% of initial]
[Iter 13790/20000] Loss: 0.0003821 (Best: 0.0002433 @iter11716) ([91m↑18.15%[0m) [0.15% of initial]
Iter:13799, L1 loss=0.0004148, Total loss=0.000331, Time:29
[Iter 13800/20000] Loss: 0.0003151 (Best: 0.0002433 @iter11716) ([92m↓17.54%[0m) [0.13% of initial]
[Iter 13810/20000] Loss: 0.0003097 (Best: 0.0002433 @iter11716) ([92m↓1.72%[0m) [0.12% of initial]
[Iter 13820/20000] Loss: 0.0003027 (Best: 0.0002433 @iter11716) ([92m↓2.25%[0m) [0.12% of initial]
[Iter 13830/20000] Loss: 0.0003141 (Best: 0.0002433 @iter11716) ([91m↑3.75%[0m) [0.12% of initial]
[Iter 13840/20000] Loss: 0.0003106 (Best: 0.0002433 @iter11716) ([92m↓1.11%[0m) [0.12% of initial]
[Iter 13850/20000] Loss: 0.0002865 (Best: 0.0002433 @iter11716) ([92m↓7.75%[0m) [0.11% of initial]
[Iter 13860/20000] Loss: 0.0002846 (Best: 0.0002433 @iter11716) ([92m↓0.66%[0m) [0.11% of initial]
[Iter 13870/20000] Loss: 0.0002783 (Best: 0.0002433 @iter11716) ([92m↓2.24%[0m) [0.11% of initial]
[Iter 13880/20000] Loss: 0.0002836 (Best: 0.0002433 @iter11716) ([91m↑1.94%[0m) [0.11% of initial]
[Iter 13890/20000] Loss: 0.0002899 (Best: 0.0002433 @iter11716) ([91m↑2.22%[0m) [0.12% of initial]
Iter:13899, L1 loss=0.0003835, Total loss=0.0003359, Time:29
[Iter 13900/20000] Loss: 0.0003130 (Best: 0.0002433 @iter11716) ([91m↑7.94%[0m) [0.12% of initial]
[Iter 13910/20000] Loss: 0.0002940 (Best: 0.0002433 @iter11716) ([92m↓6.04%[0m) [0.12% of initial]
[Iter 13920/20000] Loss: 0.0003067 (Best: 0.0002433 @iter11716) ([91m↑4.32%[0m) [0.12% of initial]
[Iter 13930/20000] Loss: 0.0002834 (Best: 0.0002433 @iter11716) ([92m↓7.62%[0m) [0.11% of initial]
[Iter 13940/20000] Loss: 0.0002893 (Best: 0.0002433 @iter11716) ([91m↑2.09%[0m) [0.11% of initial]
[Iter 13950/20000] Loss: 0.0003043 (Best: 0.0002433 @iter11716) ([91m↑5.18%[0m) [0.12% of initial]
[Iter 13960/20000] Loss: 0.0002810 (Best: 0.0002433 @iter11716) ([92m↓7.64%[0m) [0.11% of initial]
[Iter 13970/20000] Loss: 0.0002959 (Best: 0.0002433 @iter11716) ([91m↑5.32%[0m) [0.12% of initial]
[Iter 13980/20000] Loss: 0.0003008 (Best: 0.0002433 @iter11716) ([91m↑1.65%[0m) [0.12% of initial]
[Iter 13990/20000] Loss: 0.0003506 (Best: 0.0002433 @iter11716) ([91m↑16.53%[0m) [0.14% of initial]
Iter:13999, L1 loss=0.0003173, Total loss=0.0002816, Time:29
[Iter 14000/20000] Loss: 0.0003210 (Best: 0.0002433 @iter11716) ([92m↓8.44%[0m) [0.13% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 14000
Pruning 8 points (0.0%) from gaussian1 at iteration 14000
[Iter 14010/20000] Loss: 0.0005718 (Best: 0.0002433 @iter11716) ([91m↑78.15%[0m) [0.23% of initial]
[Iter 14020/20000] Loss: 0.0004256 (Best: 0.0002433 @iter11716) ([92m↓25.57%[0m) [0.17% of initial]
[Iter 14030/20000] Loss: 0.0003549 (Best: 0.0002433 @iter11716) ([92m↓16.61%[0m) [0.14% of initial]
[Iter 14040/20000] Loss: 0.0003133 (Best: 0.0002433 @iter11716) ([92m↓11.72%[0m) [0.12% of initial]
[Iter 14050/20000] Loss: 0.0003100 (Best: 0.0002433 @iter11716) ([92m↓1.07%[0m) [0.12% of initial]
[Iter 14060/20000] Loss: 0.0003153 (Best: 0.0002433 @iter11716) ([91m↑1.71%[0m) [0.13% of initial]
[Iter 14070/20000] Loss: 0.0003086 (Best: 0.0002433 @iter11716) ([92m↓2.14%[0m) [0.12% of initial]
[Iter 14080/20000] Loss: 0.0002906 (Best: 0.0002433 @iter11716) ([92m↓5.83%[0m) [0.12% of initial]
[Iter 14090/20000] Loss: 0.0002885 (Best: 0.0002433 @iter11716) ([92m↓0.70%[0m) [0.11% of initial]
Iter:14099, L1 loss=0.0003219, Total loss=0.0002849, Time:29
[Iter 14100/20000] Loss: 0.0002830 (Best: 0.0002433 @iter11716) ([92m↓1.91%[0m) [0.11% of initial]
[Iter 14110/20000] Loss: 0.0003118 (Best: 0.0002433 @iter11716) ([91m↑10.16%[0m) [0.12% of initial]
[Iter 14120/20000] Loss: 0.0002878 (Best: 0.0002433 @iter11716) ([92m↓7.70%[0m) [0.11% of initial]
[Iter 14130/20000] Loss: 0.0003003 (Best: 0.0002433 @iter11716) ([91m↑4.35%[0m) [0.12% of initial]
[Iter 14140/20000] Loss: 0.0002946 (Best: 0.0002433 @iter11716) ([92m↓1.90%[0m) [0.12% of initial]
[Iter 14150/20000] Loss: 0.0002898 (Best: 0.0002433 @iter11716) ([92m↓1.64%[0m) [0.12% of initial]
[Iter 14160/20000] Loss: 0.0002740 (Best: 0.0002433 @iter11716) ([92m↓5.44%[0m) [0.11% of initial]
[Iter 14170/20000] Loss: 0.0003092 (Best: 0.0002433 @iter11716) ([91m↑12.84%[0m) [0.12% of initial]
[Iter 14180/20000] Loss: 0.0002850 (Best: 0.0002433 @iter11716) ([92m↓7.81%[0m) [0.11% of initial]
[Iter 14190/20000] Loss: 0.0002868 (Best: 0.0002433 @iter11716) ([91m↑0.63%[0m) [0.11% of initial]
Iter:14199, L1 loss=0.0003173, Total loss=0.0002642, Time:31
[Iter 14200/20000] Loss: 0.0002742 (Best: 0.0002433 @iter11716) ([92m↓4.41%[0m) [0.11% of initial]
[Iter 14210/20000] Loss: 0.0002653 (Best: 0.0002411 @iter14206) ([92m↓3.24%[0m) [0.11% of initial]
[Iter 14220/20000] Loss: 0.0002639 (Best: 0.0002411 @iter14206) ([92m↓0.54%[0m) [0.10% of initial]
[Iter 14230/20000] Loss: 0.0003324 (Best: 0.0002411 @iter14206) ([91m↑25.98%[0m) [0.13% of initial]
[Iter 14240/20000] Loss: 0.0002907 (Best: 0.0002411 @iter14206) ([92m↓12.56%[0m) [0.12% of initial]
[Iter 14250/20000] Loss: 0.0003030 (Best: 0.0002411 @iter14206) ([91m↑4.23%[0m) [0.12% of initial]
[Iter 14260/20000] Loss: 0.0003013 (Best: 0.0002411 @iter14206) ([92m↓0.55%[0m) [0.12% of initial]
[Iter 14270/20000] Loss: 0.0003068 (Best: 0.0002411 @iter14206) ([91m↑1.80%[0m) [0.12% of initial]
[Iter 14280/20000] Loss: 0.0002829 (Best: 0.0002411 @iter14206) ([92m↓7.79%[0m) [0.11% of initial]
[Iter 14290/20000] Loss: 0.0002701 (Best: 0.0002411 @iter14206) ([92m↓4.51%[0m) [0.11% of initial]
Iter:14299, L1 loss=0.0003326, Total loss=0.0002718, Time:28
[Iter 14300/20000] Loss: 0.0002748 (Best: 0.0002411 @iter14206) ([91m↑1.73%[0m) [0.11% of initial]
[Iter 14310/20000] Loss: 0.0003003 (Best: 0.0002411 @iter14206) ([91m↑9.29%[0m) [0.12% of initial]
[Iter 14320/20000] Loss: 0.0002816 (Best: 0.0002411 @iter14206) ([92m↓6.22%[0m) [0.11% of initial]
[Iter 14330/20000] Loss: 0.0002894 (Best: 0.0002411 @iter14206) ([91m↑2.75%[0m) [0.11% of initial]
[Iter 14340/20000] Loss: 0.0003431 (Best: 0.0002411 @iter14206) ([91m↑18.55%[0m) [0.14% of initial]
[Iter 14350/20000] Loss: 0.0003328 (Best: 0.0002411 @iter14206) ([92m↓3.00%[0m) [0.13% of initial]
[Iter 14360/20000] Loss: 0.0003155 (Best: 0.0002411 @iter14206) ([92m↓5.21%[0m) [0.13% of initial]
[Iter 14370/20000] Loss: 0.0002923 (Best: 0.0002411 @iter14206) ([92m↓7.34%[0m) [0.12% of initial]
[Iter 14380/20000] Loss: 0.0002886 (Best: 0.0002411 @iter14206) ([92m↓1.28%[0m) [0.11% of initial]
[Iter 14390/20000] Loss: 0.0003104 (Best: 0.0002411 @iter14206) ([91m↑7.57%[0m) [0.12% of initial]
Iter:14399, L1 loss=0.0003141, Total loss=0.0002587, Time:26
[Iter 14400/20000] Loss: 0.0002849 (Best: 0.0002411 @iter14206) ([92m↓8.23%[0m) [0.11% of initial]
[Iter 14410/20000] Loss: 0.0002905 (Best: 0.0002411 @iter14206) ([91m↑1.96%[0m) [0.12% of initial]
[Iter 14420/20000] Loss: 0.0003553 (Best: 0.0002411 @iter14206) ([91m↑22.32%[0m) [0.14% of initial]
[Iter 14430/20000] Loss: 0.0003425 (Best: 0.0002411 @iter14206) ([92m↓3.61%[0m) [0.14% of initial]
[Iter 14440/20000] Loss: 0.0003479 (Best: 0.0002411 @iter14206) ([91m↑1.57%[0m) [0.14% of initial]
[Iter 14450/20000] Loss: 0.0003316 (Best: 0.0002411 @iter14206) ([92m↓4.67%[0m) [0.13% of initial]
[Iter 14460/20000] Loss: 0.0003455 (Best: 0.0002411 @iter14206) ([91m↑4.19%[0m) [0.14% of initial]
[Iter 14470/20000] Loss: 0.0003330 (Best: 0.0002411 @iter14206) ([92m↓3.62%[0m) [0.13% of initial]
[Iter 14480/20000] Loss: 0.0003056 (Best: 0.0002411 @iter14206) ([92m↓8.23%[0m) [0.12% of initial]
[Iter 14490/20000] Loss: 0.0002904 (Best: 0.0002411 @iter14206) ([92m↓4.96%[0m) [0.12% of initial]
Iter:14499, L1 loss=0.0003246, Total loss=0.000282, Time:25
[Iter 14500/20000] Loss: 0.0002764 (Best: 0.0002411 @iter14206) ([92m↓4.81%[0m) [0.11% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 14500
Pruning 7 points (0.0%) from gaussian1 at iteration 14500
[Iter 14510/20000] Loss: 0.0005936 (Best: 0.0002411 @iter14206) ([91m↑114.73%[0m) [0.24% of initial]
[Iter 14520/20000] Loss: 0.0004975 (Best: 0.0002411 @iter14206) ([92m↓16.18%[0m) [0.20% of initial]
[Iter 14530/20000] Loss: 0.0003789 (Best: 0.0002411 @iter14206) ([92m↓23.85%[0m) [0.15% of initial]
[Iter 14540/20000] Loss: 0.0003403 (Best: 0.0002411 @iter14206) ([92m↓10.17%[0m) [0.14% of initial]
[Iter 14550/20000] Loss: 0.0003152 (Best: 0.0002411 @iter14206) ([92m↓7.39%[0m) [0.13% of initial]
[Iter 14560/20000] Loss: 0.0002741 (Best: 0.0002411 @iter14206) ([92m↓13.05%[0m) [0.11% of initial]
[Iter 14570/20000] Loss: 0.0002743 (Best: 0.0002411 @iter14206) ([91m↑0.10%[0m) [0.11% of initial]
[Iter 14580/20000] Loss: 0.0002625 (Best: 0.0002411 @iter14206) ([92m↓4.31%[0m) [0.10% of initial]
[Iter 14590/20000] Loss: 0.0002655 (Best: 0.0002411 @iter14206) ([91m↑1.13%[0m) [0.11% of initial]
Iter:14599, L1 loss=0.0003405, Total loss=0.0002893, Time:28
[Iter 14600/20000] Loss: 0.0002841 (Best: 0.0002411 @iter14206) ([91m↑7.02%[0m) [0.11% of initial]
[Iter 14610/20000] Loss: 0.0003213 (Best: 0.0002411 @iter14206) ([91m↑13.12%[0m) [0.13% of initial]
[Iter 14620/20000] Loss: 0.0002894 (Best: 0.0002411 @iter14206) ([92m↓9.93%[0m) [0.11% of initial]
[Iter 14630/20000] Loss: 0.0002629 (Best: 0.0002411 @iter14206) ([92m↓9.19%[0m) [0.10% of initial]
[Iter 14640/20000] Loss: 0.0002868 (Best: 0.0002411 @iter14206) ([91m↑9.10%[0m) [0.11% of initial]
[Iter 14650/20000] Loss: 0.0002877 (Best: 0.0002411 @iter14206) ([91m↑0.32%[0m) [0.11% of initial]
[Iter 14660/20000] Loss: 0.0002773 (Best: 0.0002411 @iter14206) ([92m↓3.63%[0m) [0.11% of initial]
[Iter 14670/20000] Loss: 0.0002721 (Best: 0.0002411 @iter14206) ([92m↓1.85%[0m) [0.11% of initial]
[Iter 14680/20000] Loss: 0.0002758 (Best: 0.0002411 @iter14206) ([91m↑1.35%[0m) [0.11% of initial]
[Iter 14690/20000] Loss: 0.0002595 (Best: 0.0002411 @iter14206) ([92m↓5.90%[0m) [0.10% of initial]
Iter:14699, L1 loss=0.0003389, Total loss=0.0002834, Time:27
[Iter 14700/20000] Loss: 0.0002799 (Best: 0.0002411 @iter14206) ([91m↑7.86%[0m) [0.11% of initial]
[Iter 14710/20000] Loss: 0.0002665 (Best: 0.0002411 @iter14206) ([92m↓4.81%[0m) [0.11% of initial]
[Iter 14720/20000] Loss: 0.0002675 (Best: 0.0002411 @iter14206) ([91m↑0.40%[0m) [0.11% of initial]
[Iter 14730/20000] Loss: 0.0002699 (Best: 0.0002411 @iter14206) ([91m↑0.88%[0m) [0.11% of initial]
[Iter 14740/20000] Loss: 0.0002501 (Best: 0.0002382 @iter14740) ([92m↓7.34%[0m) [0.10% of initial]
[Iter 14750/20000] Loss: 0.0002557 (Best: 0.0002382 @iter14740) ([91m↑2.27%[0m) [0.10% of initial]
[Iter 14760/20000] Loss: 0.0002798 (Best: 0.0002382 @iter14740) ([91m↑9.40%[0m) [0.11% of initial]
[Iter 14770/20000] Loss: 0.0003843 (Best: 0.0002382 @iter14740) ([91m↑37.36%[0m) [0.15% of initial]
[Iter 14780/20000] Loss: 0.0004051 (Best: 0.0002382 @iter14740) ([91m↑5.40%[0m) [0.16% of initial]
[Iter 14790/20000] Loss: 0.0003767 (Best: 0.0002382 @iter14740) ([92m↓7.01%[0m) [0.15% of initial]
Iter:14799, L1 loss=0.000418, Total loss=0.0003997, Time:29
[Iter 14800/20000] Loss: 0.0003573 (Best: 0.0002382 @iter14740) ([92m↓5.14%[0m) [0.14% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 14810/20000] Loss: 0.0003191 (Best: 0.0002382 @iter14740) ([92m↓10.71%[0m) [0.13% of initial]
[Iter 14820/20000] Loss: 0.0002974 (Best: 0.0002382 @iter14740) ([92m↓6.81%[0m) [0.12% of initial]
[Iter 14830/20000] Loss: 0.0003049 (Best: 0.0002382 @iter14740) ([91m↑2.52%[0m) [0.12% of initial]
[Iter 14840/20000] Loss: 0.0002993 (Best: 0.0002382 @iter14740) ([92m↓1.83%[0m) [0.12% of initial]
[Iter 14850/20000] Loss: 0.0003048 (Best: 0.0002382 @iter14740) ([91m↑1.84%[0m) [0.12% of initial]
[Iter 14860/20000] Loss: 0.0003128 (Best: 0.0002382 @iter14740) ([91m↑2.64%[0m) [0.12% of initial]
[Iter 14870/20000] Loss: 0.0002815 (Best: 0.0002382 @iter14740) ([92m↓10.02%[0m) [0.11% of initial]
[Iter 14880/20000] Loss: 0.0002751 (Best: 0.0002382 @iter14740) ([92m↓2.28%[0m) [0.11% of initial]
[Iter 14890/20000] Loss: 0.0002670 (Best: 0.0002382 @iter14740) ([92m↓2.95%[0m) [0.11% of initial]
Iter:14899, L1 loss=0.0003025, Total loss=0.0002688, Time:28
[Iter 14900/20000] Loss: 0.0002567 (Best: 0.0002379 @iter14900) ([92m↓3.84%[0m) [0.10% of initial]
[Iter 14910/20000] Loss: 0.0002575 (Best: 0.0002306 @iter14905) ([91m↑0.31%[0m) [0.10% of initial]
[Iter 14920/20000] Loss: 0.0002616 (Best: 0.0002306 @iter14905) ([91m↑1.57%[0m) [0.10% of initial]
[Iter 14930/20000] Loss: 0.0002591 (Best: 0.0002306 @iter14905) ([92m↓0.96%[0m) [0.10% of initial]
[Iter 14940/20000] Loss: 0.0002469 (Best: 0.0002306 @iter14905) ([92m↓4.69%[0m) [0.10% of initial]
[Iter 14950/20000] Loss: 0.0002657 (Best: 0.0002303 @iter14942) ([91m↑7.62%[0m) [0.11% of initial]
[Iter 14960/20000] Loss: 0.0002564 (Best: 0.0002303 @iter14942) ([92m↓3.50%[0m) [0.10% of initial]
[Iter 14970/20000] Loss: 0.0002958 (Best: 0.0002303 @iter14942) ([91m↑15.38%[0m) [0.12% of initial]
[Iter 14980/20000] Loss: 0.0002886 (Best: 0.0002303 @iter14942) ([92m↓2.45%[0m) [0.11% of initial]
[Iter 14990/20000] Loss: 0.0003635 (Best: 0.0002303 @iter14942) ([91m↑25.96%[0m) [0.14% of initial]
Iter:14999, L1 loss=0.0004505, Total loss=0.0003463, Time:31
[Iter 15000/20000] Loss: 0.0004038 (Best: 0.0002303 @iter14942) ([91m↑11.07%[0m) [0.16% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 15000
Pruning 2 points (0.0%) from gaussian1 at iteration 15000
[Iter 15010/20000] Loss: 0.0004683 (Best: 0.0002303 @iter14942) ([91m↑15.99%[0m) [0.19% of initial]
[Iter 15020/20000] Loss: 0.0004105 (Best: 0.0002303 @iter14942) ([92m↓12.36%[0m) [0.16% of initial]
[Iter 15030/20000] Loss: 0.0003210 (Best: 0.0002303 @iter14942) ([92m↓21.78%[0m) [0.13% of initial]
[Iter 15040/20000] Loss: 0.0002891 (Best: 0.0002303 @iter14942) ([92m↓9.95%[0m) [0.11% of initial]
[Iter 15050/20000] Loss: 0.0002680 (Best: 0.0002303 @iter14942) ([92m↓7.29%[0m) [0.11% of initial]
[Iter 15060/20000] Loss: 0.0002925 (Best: 0.0002303 @iter14942) ([91m↑9.15%[0m) [0.12% of initial]
[Iter 15070/20000] Loss: 0.0002667 (Best: 0.0002303 @iter14942) ([92m↓8.83%[0m) [0.11% of initial]
[Iter 15080/20000] Loss: 0.0002562 (Best: 0.0002303 @iter14942) ([92m↓3.92%[0m) [0.10% of initial]
[Iter 15090/20000] Loss: 0.0002489 (Best: 0.0002303 @iter14942) ([92m↓2.86%[0m) [0.10% of initial]
Iter:15099, L1 loss=0.0002822, Total loss=0.0002358, Time:32
[Iter 15100/20000] Loss: 0.0002385 (Best: 0.0002303 @iter14942) ([92m↓4.19%[0m) [0.09% of initial]
[Iter 15110/20000] Loss: 0.0002586 (Best: 0.0002289 @iter15101) ([91m↑8.46%[0m) [0.10% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 15120/20000] Loss: 0.0002791 (Best: 0.0002289 @iter15101) ([91m↑7.91%[0m) [0.11% of initial]
[Iter 15130/20000] Loss: 0.0002936 (Best: 0.0002289 @iter15101) ([91m↑5.21%[0m) [0.12% of initial]
[Iter 15140/20000] Loss: 0.0002774 (Best: 0.0002289 @iter15101) ([92m↓5.54%[0m) [0.11% of initial]
[Iter 15150/20000] Loss: 0.0003163 (Best: 0.0002289 @iter15101) ([91m↑14.06%[0m) [0.13% of initial]
[Iter 15160/20000] Loss: 0.0002681 (Best: 0.0002289 @iter15101) ([92m↓15.23%[0m) [0.11% of initial]
[Iter 15170/20000] Loss: 0.0002546 (Best: 0.0002289 @iter15101) ([92m↓5.04%[0m) [0.10% of initial]
[Iter 15180/20000] Loss: 0.0002708 (Best: 0.0002289 @iter15101) ([91m↑6.34%[0m) [0.11% of initial]
[Iter 15190/20000] Loss: 0.0002516 (Best: 0.0002289 @iter15101) ([92m↓7.09%[0m) [0.10% of initial]
Iter:15199, L1 loss=0.0003132, Total loss=0.0002522, Time:28
[Iter 15200/20000] Loss: 0.0002527 (Best: 0.0002289 @iter15101) ([91m↑0.44%[0m) [0.10% of initial]
[Iter 15210/20000] Loss: 0.0003055 (Best: 0.0002289 @iter15101) ([91m↑20.90%[0m) [0.12% of initial]
[Iter 15220/20000] Loss: 0.0003020 (Best: 0.0002289 @iter15101) ([92m↓1.13%[0m) [0.12% of initial]
[Iter 15230/20000] Loss: 0.0002704 (Best: 0.0002289 @iter15101) ([92m↓10.47%[0m) [0.11% of initial]
[Iter 15240/20000] Loss: 0.0002680 (Best: 0.0002289 @iter15101) ([92m↓0.88%[0m) [0.11% of initial]
[Iter 15250/20000] Loss: 0.0002575 (Best: 0.0002289 @iter15101) ([92m↓3.94%[0m) [0.10% of initial]
[Iter 15260/20000] Loss: 0.0002640 (Best: 0.0002289 @iter15101) ([91m↑2.52%[0m) [0.10% of initial]
[Iter 15270/20000] Loss: 0.0002553 (Best: 0.0002289 @iter15101) ([92m↓3.30%[0m) [0.10% of initial]
[Iter 15280/20000] Loss: 0.0002496 (Best: 0.0002289 @iter15101) ([92m↓2.20%[0m) [0.10% of initial]
[Iter 15290/20000] Loss: 0.0002582 (Best: 0.0002289 @iter15101) ([91m↑3.43%[0m) [0.10% of initial]
Iter:15299, L1 loss=0.0003206, Total loss=0.0002792, Time:28
[Iter 15300/20000] Loss: 0.0002766 (Best: 0.0002289 @iter15101) ([91m↑7.13%[0m) [0.11% of initial]
[Iter 15310/20000] Loss: 0.0002975 (Best: 0.0002289 @iter15101) ([91m↑7.57%[0m) [0.12% of initial]
[Iter 15320/20000] Loss: 0.0002831 (Best: 0.0002289 @iter15101) ([92m↓4.85%[0m) [0.11% of initial]
[Iter 15330/20000] Loss: 0.0002787 (Best: 0.0002289 @iter15101) ([92m↓1.56%[0m) [0.11% of initial]
[Iter 15340/20000] Loss: 0.0002726 (Best: 0.0002289 @iter15101) ([92m↓2.18%[0m) [0.11% of initial]
[Iter 15350/20000] Loss: 0.0002750 (Best: 0.0002289 @iter15101) ([91m↑0.86%[0m) [0.11% of initial]
[Iter 15360/20000] Loss: 0.0003157 (Best: 0.0002289 @iter15101) ([91m↑14.82%[0m) [0.13% of initial]
[Iter 15370/20000] Loss: 0.0003091 (Best: 0.0002289 @iter15101) ([92m↓2.10%[0m) [0.12% of initial]
[Iter 15380/20000] Loss: 0.0002896 (Best: 0.0002289 @iter15101) ([92m↓6.29%[0m) [0.12% of initial]
[Iter 15390/20000] Loss: 0.0002706 (Best: 0.0002289 @iter15101) ([92m↓6.56%[0m) [0.11% of initial]
Iter:15399, L1 loss=0.0002916, Total loss=0.0002377, Time:28
[Iter 15400/20000] Loss: 0.0002403 (Best: 0.0002289 @iter15101) ([92m↓11.19%[0m) [0.10% of initial]
[Iter 15410/20000] Loss: 0.0002404 (Best: 0.0002212 @iter15409) ([91m↑0.01%[0m) [0.10% of initial]
[Iter 15420/20000] Loss: 0.0002441 (Best: 0.0002212 @iter15409) ([91m↑1.56%[0m) [0.10% of initial]
[Iter 15430/20000] Loss: 0.0002384 (Best: 0.0002212 @iter15409) ([92m↓2.34%[0m) [0.09% of initial]
[Iter 15440/20000] Loss: 0.0002473 (Best: 0.0002212 @iter15409) ([91m↑3.74%[0m) [0.10% of initial]
[Iter 15450/20000] Loss: 0.0002677 (Best: 0.0002212 @iter15409) ([91m↑8.26%[0m) [0.11% of initial]
[Iter 15460/20000] Loss: 0.0002898 (Best: 0.0002212 @iter15409) ([91m↑8.23%[0m) [0.12% of initial]
[Iter 15470/20000] Loss: 0.0003162 (Best: 0.0002212 @iter15409) ([91m↑9.13%[0m) [0.13% of initial]
[Iter 15480/20000] Loss: 0.0002966 (Best: 0.0002212 @iter15409) ([92m↓6.22%[0m) [0.12% of initial]
[Iter 15490/20000] Loss: 0.0002542 (Best: 0.0002212 @iter15409) ([92m↓14.28%[0m) [0.10% of initial]
Iter:15499, L1 loss=0.0003111, Total loss=0.0002541, Time:30
[Iter 15500/20000] Loss: 0.0002649 (Best: 0.0002212 @iter15409) ([91m↑4.19%[0m) [0.11% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 15500
Pruning 9 points (0.0%) from gaussian1 at iteration 15500
[Iter 15510/20000] Loss: 0.0006038 (Best: 0.0002212 @iter15409) ([91m↑127.98%[0m) [0.24% of initial]
[Iter 15520/20000] Loss: 0.0004321 (Best: 0.0002212 @iter15409) ([92m↓28.44%[0m) [0.17% of initial]
[Iter 15530/20000] Loss: 0.0003508 (Best: 0.0002212 @iter15409) ([92m↓18.82%[0m) [0.14% of initial]
[Iter 15540/20000] Loss: 0.0002827 (Best: 0.0002212 @iter15409) ([92m↓19.40%[0m) [0.11% of initial]
[Iter 15550/20000] Loss: 0.0002636 (Best: 0.0002212 @iter15409) ([92m↓6.78%[0m) [0.10% of initial]
[Iter 15560/20000] Loss: 0.0002638 (Best: 0.0002212 @iter15409) ([91m↑0.08%[0m) [0.10% of initial]
[Iter 15570/20000] Loss: 0.0002801 (Best: 0.0002212 @iter15409) ([91m↑6.18%[0m) [0.11% of initial]
[Iter 15580/20000] Loss: 0.0002499 (Best: 0.0002212 @iter15409) ([92m↓10.77%[0m) [0.10% of initial]
[Iter 15590/20000] Loss: 0.0002362 (Best: 0.0002212 @iter15409) ([92m↓5.48%[0m) [0.09% of initial]
Iter:15599, L1 loss=0.0002885, Total loss=0.0002383, Time:29
[Iter 15600/20000] Loss: 0.0002418 (Best: 0.0002212 @iter15409) ([91m↑2.36%[0m) [0.10% of initial]
[Iter 15610/20000] Loss: 0.0002497 (Best: 0.0002212 @iter15409) ([91m↑3.28%[0m) [0.10% of initial]
[Iter 15620/20000] Loss: 0.0002306 (Best: 0.0002212 @iter15409) ([92m↓7.64%[0m) [0.09% of initial]
[Iter 15630/20000] Loss: 0.0002614 (Best: 0.0002212 @iter15409) ([91m↑13.32%[0m) [0.10% of initial]
[Iter 15640/20000] Loss: 0.0002545 (Best: 0.0002212 @iter15409) ([92m↓2.61%[0m) [0.10% of initial]
[Iter 15650/20000] Loss: 0.0002916 (Best: 0.0002212 @iter15409) ([91m↑14.55%[0m) [0.12% of initial]
[Iter 15660/20000] Loss: 0.0002677 (Best: 0.0002212 @iter15409) ([92m↓8.18%[0m) [0.11% of initial]
[Iter 15670/20000] Loss: 0.0002763 (Best: 0.0002212 @iter15409) ([91m↑3.18%[0m) [0.11% of initial]
[Iter 15680/20000] Loss: 0.0003586 (Best: 0.0002212 @iter15409) ([91m↑29.80%[0m) [0.14% of initial]
[Iter 15690/20000] Loss: 0.0003218 (Best: 0.0002212 @iter15409) ([92m↓10.26%[0m) [0.13% of initial]
Iter:15699, L1 loss=0.0003147, Total loss=0.0002691, Time:28
[Iter 15700/20000] Loss: 0.0002651 (Best: 0.0002212 @iter15409) ([92m↓17.61%[0m) [0.11% of initial]
[Iter 15710/20000] Loss: 0.0002339 (Best: 0.0002212 @iter15409) ([92m↓11.78%[0m) [0.09% of initial]
[Iter 15720/20000] Loss: 0.0002452 (Best: 0.0002212 @iter15409) ([91m↑4.82%[0m) [0.10% of initial]
[Iter 15730/20000] Loss: 0.0002494 (Best: 0.0002212 @iter15409) ([91m↑1.75%[0m) [0.10% of initial]
[Iter 15740/20000] Loss: 0.0002494 (Best: 0.0002212 @iter15409) ([92m↓0.03%[0m) [0.10% of initial]
[Iter 15750/20000] Loss: 0.0002647 (Best: 0.0002212 @iter15409) ([91m↑6.13%[0m) [0.11% of initial]
[Iter 15760/20000] Loss: 0.0002847 (Best: 0.0002212 @iter15409) ([91m↑7.59%[0m) [0.11% of initial]
[Iter 15770/20000] Loss: 0.0003126 (Best: 0.0002212 @iter15409) ([91m↑9.77%[0m) [0.12% of initial]
[Iter 15780/20000] Loss: 0.0002649 (Best: 0.0002212 @iter15409) ([92m↓15.24%[0m) [0.11% of initial]
[Iter 15790/20000] Loss: 0.0002551 (Best: 0.0002212 @iter15409) ([92m↓3.70%[0m) [0.10% of initial]
Iter:15799, L1 loss=0.0002916, Total loss=0.0002392, Time:28
[Iter 15800/20000] Loss: 0.0002563 (Best: 0.0002212 @iter15409) ([91m↑0.47%[0m) [0.10% of initial]
[Iter 15810/20000] Loss: 0.0003006 (Best: 0.0002212 @iter15409) ([91m↑17.26%[0m) [0.12% of initial]
[Iter 15820/20000] Loss: 0.0003104 (Best: 0.0002212 @iter15409) ([91m↑3.28%[0m) [0.12% of initial]
[Iter 15830/20000] Loss: 0.0003545 (Best: 0.0002212 @iter15409) ([91m↑14.19%[0m) [0.14% of initial]
[Iter 15840/20000] Loss: 0.0002815 (Best: 0.0002212 @iter15409) ([92m↓20.59%[0m) [0.11% of initial]
[Iter 15850/20000] Loss: 0.0002785 (Best: 0.0002212 @iter15409) ([92m↓1.08%[0m) [0.11% of initial]
[Iter 15860/20000] Loss: 0.0002834 (Best: 0.0002212 @iter15409) ([91m↑1.76%[0m) [0.11% of initial]
[Iter 15870/20000] Loss: 0.0002851 (Best: 0.0002212 @iter15409) ([91m↑0.61%[0m) [0.11% of initial]
[Iter 15880/20000] Loss: 0.0002765 (Best: 0.0002212 @iter15409) ([92m↓3.01%[0m) [0.11% of initial]
[Iter 15890/20000] Loss: 0.0002517 (Best: 0.0002212 @iter15409) ([92m↓8.99%[0m) [0.10% of initial]
Iter:15899, L1 loss=0.0002605, Total loss=0.0002181, Time:28
[Iter 15900/20000] Loss: 0.0002309 (Best: 0.0002181 @iter15899) ([92m↓8.24%[0m) [0.09% of initial]
[Iter 15910/20000] Loss: 0.0002281 (Best: 0.0002130 @iter15904) ([92m↓1.22%[0m) [0.09% of initial]
[Iter 15920/20000] Loss: 0.0002341 (Best: 0.0002130 @iter15904) ([91m↑2.63%[0m) [0.09% of initial]
[Iter 15930/20000] Loss: 0.0002285 (Best: 0.0002130 @iter15904) ([92m↓2.39%[0m) [0.09% of initial]
[Iter 15940/20000] Loss: 0.0002186 (Best: 0.0002119 @iter15940) ([92m↓4.36%[0m) [0.09% of initial]
[Iter 15950/20000] Loss: 0.0002623 (Best: 0.0002119 @iter15940) ([91m↑20.01%[0m) [0.10% of initial]
[Iter 15960/20000] Loss: 0.0002403 (Best: 0.0002119 @iter15940) ([92m↓8.40%[0m) [0.10% of initial]
[Iter 15970/20000] Loss: 0.0002346 (Best: 0.0002119 @iter15940) ([92m↓2.34%[0m) [0.09% of initial]
[Iter 15980/20000] Loss: 0.0002328 (Best: 0.0002119 @iter15940) ([92m↓0.77%[0m) [0.09% of initial]
[Iter 15990/20000] Loss: 0.0002616 (Best: 0.0002119 @iter15940) ([91m↑12.34%[0m) [0.10% of initial]
Iter:15999, L1 loss=0.0003085, Total loss=0.0002689, Time:30
[Iter 16000/20000] Loss: 0.0002785 (Best: 0.0002119 @iter15940) ([91m↑6.48%[0m) [0.11% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 16000
Pruning 6 points (0.0%) from gaussian1 at iteration 16000
[Iter 16010/20000] Loss: 0.0127423 (Best: 0.0002119 @iter15940) ([91m↑4475.04%[0m) [5.06% of initial]
[Iter 16020/20000] Loss: 0.0052928 (Best: 0.0002119 @iter15940) ([92m↓58.46%[0m) [2.10% of initial]
[Iter 16030/20000] Loss: 0.0025837 (Best: 0.0002119 @iter15940) ([92m↓51.18%[0m) [1.03% of initial]
[Iter 16040/20000] Loss: 0.0016346 (Best: 0.0002119 @iter15940) ([92m↓36.73%[0m) [0.65% of initial]
[Iter 16050/20000] Loss: 0.0011237 (Best: 0.0002119 @iter15940) ([92m↓31.25%[0m) [0.45% of initial]
[Iter 16060/20000] Loss: 0.0008428 (Best: 0.0002119 @iter15940) ([92m↓25.00%[0m) [0.33% of initial]
[Iter 16070/20000] Loss: 0.0006685 (Best: 0.0002119 @iter15940) ([92m↓20.68%[0m) [0.27% of initial]
[Iter 16080/20000] Loss: 0.0005872 (Best: 0.0002119 @iter15940) ([92m↓12.16%[0m) [0.23% of initial]
[Iter 16090/20000] Loss: 0.0004997 (Best: 0.0002119 @iter15940) ([92m↓14.90%[0m) [0.20% of initial]
Iter:16099, L1 loss=0.0004873, Total loss=0.0004276, Time:27
[Iter 16100/20000] Loss: 0.0004486 (Best: 0.0002119 @iter15940) ([92m↓10.24%[0m) [0.18% of initial]
[Iter 16110/20000] Loss: 0.0004214 (Best: 0.0002119 @iter15940) ([92m↓6.06%[0m) [0.17% of initial]
[Iter 16120/20000] Loss: 0.0003948 (Best: 0.0002119 @iter15940) ([92m↓6.30%[0m) [0.16% of initial]
[Iter 16130/20000] Loss: 0.0003768 (Best: 0.0002119 @iter15940) ([92m↓4.57%[0m) [0.15% of initial]
[Iter 16140/20000] Loss: 0.0003524 (Best: 0.0002119 @iter15940) ([92m↓6.47%[0m) [0.14% of initial]
[Iter 16150/20000] Loss: 0.0003380 (Best: 0.0002119 @iter15940) ([92m↓4.10%[0m) [0.13% of initial]
[Iter 16160/20000] Loss: 0.0003338 (Best: 0.0002119 @iter15940) ([92m↓1.25%[0m) [0.13% of initial]
[Iter 16170/20000] Loss: 0.0003326 (Best: 0.0002119 @iter15940) ([92m↓0.35%[0m) [0.13% of initial]
[Iter 16180/20000] Loss: 0.0003296 (Best: 0.0002119 @iter15940) ([92m↓0.90%[0m) [0.13% of initial]
[Iter 16190/20000] Loss: 0.0003209 (Best: 0.0002119 @iter15940) ([92m↓2.65%[0m) [0.13% of initial]
Iter:16199, L1 loss=0.0003655, Total loss=0.0003193, Time:25
[Iter 16200/20000] Loss: 0.0003227 (Best: 0.0002119 @iter15940) ([91m↑0.58%[0m) [0.13% of initial]
[Iter 16210/20000] Loss: 0.0003372 (Best: 0.0002119 @iter15940) ([91m↑4.47%[0m) [0.13% of initial]
[Iter 16220/20000] Loss: 0.0003228 (Best: 0.0002119 @iter15940) ([92m↓4.27%[0m) [0.13% of initial]
[Iter 16230/20000] Loss: 0.0003200 (Best: 0.0002119 @iter15940) ([92m↓0.87%[0m) [0.13% of initial]
[Iter 16240/20000] Loss: 0.0003404 (Best: 0.0002119 @iter15940) ([91m↑6.40%[0m) [0.14% of initial]
[Iter 16250/20000] Loss: 0.0003129 (Best: 0.0002119 @iter15940) ([92m↓8.08%[0m) [0.12% of initial]
[Iter 16260/20000] Loss: 0.0002974 (Best: 0.0002119 @iter15940) ([92m↓4.96%[0m) [0.12% of initial]
[Iter 16270/20000] Loss: 0.0002872 (Best: 0.0002119 @iter15940) ([92m↓3.44%[0m) [0.11% of initial]
[Iter 16280/20000] Loss: 0.0002856 (Best: 0.0002119 @iter15940) ([92m↓0.56%[0m) [0.11% of initial]
[Iter 16290/20000] Loss: 0.0002954 (Best: 0.0002119 @iter15940) ([91m↑3.43%[0m) [0.12% of initial]
Iter:16299, L1 loss=0.00037, Total loss=0.0003159, Time:26
[Iter 16300/20000] Loss: 0.0002880 (Best: 0.0002119 @iter15940) ([92m↓2.50%[0m) [0.11% of initial]
[Iter 16310/20000] Loss: 0.0003020 (Best: 0.0002119 @iter15940) ([91m↑4.86%[0m) [0.12% of initial]
[Iter 16320/20000] Loss: 0.0003118 (Best: 0.0002119 @iter15940) ([91m↑3.23%[0m) [0.12% of initial]
[Iter 16330/20000] Loss: 0.0003204 (Best: 0.0002119 @iter15940) ([91m↑2.75%[0m) [0.13% of initial]
[Iter 16340/20000] Loss: 0.0002939 (Best: 0.0002119 @iter15940) ([92m↓8.25%[0m) [0.12% of initial]
[Iter 16350/20000] Loss: 0.0003092 (Best: 0.0002119 @iter15940) ([91m↑5.19%[0m) [0.12% of initial]
[Iter 16360/20000] Loss: 0.0002948 (Best: 0.0002119 @iter15940) ([92m↓4.66%[0m) [0.12% of initial]
[Iter 16370/20000] Loss: 0.0003191 (Best: 0.0002119 @iter15940) ([91m↑8.25%[0m) [0.13% of initial]
[Iter 16380/20000] Loss: 0.0003195 (Best: 0.0002119 @iter15940) ([91m↑0.14%[0m) [0.13% of initial]
[Iter 16390/20000] Loss: 0.0003161 (Best: 0.0002119 @iter15940) ([92m↓1.08%[0m) [0.13% of initial]
Iter:16399, L1 loss=0.0003289, Total loss=0.0002841, Time:29
[Iter 16400/20000] Loss: 0.0003027 (Best: 0.0002119 @iter15940) ([92m↓4.25%[0m) [0.12% of initial]
[Iter 16410/20000] Loss: 0.0002995 (Best: 0.0002119 @iter15940) ([92m↓1.05%[0m) [0.12% of initial]
[Iter 16420/20000] Loss: 0.0002828 (Best: 0.0002119 @iter15940) ([92m↓5.57%[0m) [0.11% of initial]
[Iter 16430/20000] Loss: 0.0002822 (Best: 0.0002119 @iter15940) ([92m↓0.22%[0m) [0.11% of initial]
[Iter 16440/20000] Loss: 0.0002881 (Best: 0.0002119 @iter15940) ([91m↑2.11%[0m) [0.11% of initial]
[Iter 16450/20000] Loss: 0.0002910 (Best: 0.0002119 @iter15940) ([91m↑0.98%[0m) [0.12% of initial]
[Iter 16460/20000] Loss: 0.0002838 (Best: 0.0002119 @iter15940) ([92m↓2.45%[0m) [0.11% of initial]
[Iter 16470/20000] Loss: 0.0003015 (Best: 0.0002119 @iter15940) ([91m↑6.24%[0m) [0.12% of initial]
[Iter 16480/20000] Loss: 0.0002948 (Best: 0.0002119 @iter15940) ([92m↓2.24%[0m) [0.12% of initial]
[Iter 16490/20000] Loss: 0.0002908 (Best: 0.0002119 @iter15940) ([92m↓1.34%[0m) [0.12% of initial]
Iter:16499, L1 loss=0.0003678, Total loss=0.0003101, Time:29
[Iter 16500/20000] Loss: 0.0003298 (Best: 0.0002119 @iter15940) ([91m↑13.41%[0m) [0.13% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 16500
Pruning 6 points (0.0%) from gaussian1 at iteration 16500
[Iter 16510/20000] Loss: 0.0005253 (Best: 0.0002119 @iter15940) ([91m↑59.28%[0m) [0.21% of initial]
[Iter 16520/20000] Loss: 0.0003959 (Best: 0.0002119 @iter15940) ([92m↓24.64%[0m) [0.16% of initial]
[Iter 16530/20000] Loss: 0.0003303 (Best: 0.0002119 @iter15940) ([92m↓16.57%[0m) [0.13% of initial]
[Iter 16540/20000] Loss: 0.0003177 (Best: 0.0002119 @iter15940) ([92m↓3.82%[0m) [0.13% of initial]
[Iter 16550/20000] Loss: 0.0003055 (Best: 0.0002119 @iter15940) ([92m↓3.83%[0m) [0.12% of initial]
[Iter 16560/20000] Loss: 0.0002939 (Best: 0.0002119 @iter15940) ([92m↓3.81%[0m) [0.12% of initial]
[Iter 16570/20000] Loss: 0.0002898 (Best: 0.0002119 @iter15940) ([92m↓1.39%[0m) [0.12% of initial]
[Iter 16580/20000] Loss: 0.0002857 (Best: 0.0002119 @iter15940) ([92m↓1.41%[0m) [0.11% of initial]
[Iter 16590/20000] Loss: 0.0002904 (Best: 0.0002119 @iter15940) ([91m↑1.65%[0m) [0.12% of initial]
Iter:16599, L1 loss=0.000328, Total loss=0.0002843, Time:29
[Iter 16600/20000] Loss: 0.0002776 (Best: 0.0002119 @iter15940) ([92m↓4.42%[0m) [0.11% of initial]
[Iter 16610/20000] Loss: 0.0002753 (Best: 0.0002119 @iter15940) ([92m↓0.81%[0m) [0.11% of initial]
[Iter 16620/20000] Loss: 0.0002850 (Best: 0.0002119 @iter15940) ([91m↑3.51%[0m) [0.11% of initial]
[Iter 16630/20000] Loss: 0.0002981 (Best: 0.0002119 @iter15940) ([91m↑4.59%[0m) [0.12% of initial]
[Iter 16640/20000] Loss: 0.0003193 (Best: 0.0002119 @iter15940) ([91m↑7.12%[0m) [0.13% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 16650/20000] Loss: 0.0003585 (Best: 0.0002119 @iter15940) ([91m↑12.26%[0m) [0.14% of initial]
[Iter 16660/20000] Loss: 0.0004041 (Best: 0.0002119 @iter15940) ([91m↑12.72%[0m) [0.16% of initial]
[Iter 16670/20000] Loss: 0.0003719 (Best: 0.0002119 @iter15940) ([92m↓7.96%[0m) [0.15% of initial]
[Iter 16680/20000] Loss: 0.0003121 (Best: 0.0002119 @iter15940) ([92m↓16.08%[0m) [0.12% of initial]
[Iter 16690/20000] Loss: 0.0002854 (Best: 0.0002119 @iter15940) ([92m↓8.56%[0m) [0.11% of initial]
Iter:16699, L1 loss=0.0003615, Total loss=0.0002984, Time:32
[Iter 16700/20000] Loss: 0.0002849 (Best: 0.0002119 @iter15940) ([92m↓0.16%[0m) [0.11% of initial]
[Iter 16710/20000] Loss: 0.0002822 (Best: 0.0002119 @iter15940) ([92m↓0.97%[0m) [0.11% of initial]
[Iter 16720/20000] Loss: 0.0002971 (Best: 0.0002119 @iter15940) ([91m↑5.30%[0m) [0.12% of initial]
[Iter 16730/20000] Loss: 0.0002850 (Best: 0.0002119 @iter15940) ([92m↓4.07%[0m) [0.11% of initial]
[Iter 16740/20000] Loss: 0.0002998 (Best: 0.0002119 @iter15940) ([91m↑5.19%[0m) [0.12% of initial]
[Iter 16750/20000] Loss: 0.0002933 (Best: 0.0002119 @iter15940) ([92m↓2.17%[0m) [0.12% of initial]
[Iter 16760/20000] Loss: 0.0002876 (Best: 0.0002119 @iter15940) ([92m↓1.93%[0m) [0.11% of initial]
[Iter 16770/20000] Loss: 0.0002862 (Best: 0.0002119 @iter15940) ([92m↓0.50%[0m) [0.11% of initial]
[Iter 16780/20000] Loss: 0.0002949 (Best: 0.0002119 @iter15940) ([91m↑3.03%[0m) [0.12% of initial]
[Iter 16790/20000] Loss: 0.0003247 (Best: 0.0002119 @iter15940) ([91m↑10.11%[0m) [0.13% of initial]
Iter:16799, L1 loss=0.0003633, Total loss=0.0003451, Time:32
[Iter 16800/20000] Loss: 0.0003145 (Best: 0.0002119 @iter15940) ([92m↓3.13%[0m) [0.12% of initial]
[Iter 16810/20000] Loss: 0.0003626 (Best: 0.0002119 @iter15940) ([91m↑15.29%[0m) [0.14% of initial]
[Iter 16820/20000] Loss: 0.0003141 (Best: 0.0002119 @iter15940) ([92m↓13.36%[0m) [0.12% of initial]
[Iter 16830/20000] Loss: 0.0003148 (Best: 0.0002119 @iter15940) ([91m↑0.20%[0m) [0.13% of initial]
[Iter 16840/20000] Loss: 0.0003612 (Best: 0.0002119 @iter15940) ([91m↑14.76%[0m) [0.14% of initial]
[Iter 16850/20000] Loss: 0.0003192 (Best: 0.0002119 @iter15940) ([92m↓11.63%[0m) [0.13% of initial]
[Iter 16860/20000] Loss: 0.0002942 (Best: 0.0002119 @iter15940) ([92m↓7.83%[0m) [0.12% of initial]
[Iter 16870/20000] Loss: 0.0002759 (Best: 0.0002119 @iter15940) ([92m↓6.22%[0m) [0.11% of initial]
[Iter 16880/20000] Loss: 0.0002744 (Best: 0.0002119 @iter15940) ([92m↓0.56%[0m) [0.11% of initial]
[Iter 16890/20000] Loss: 0.0002963 (Best: 0.0002119 @iter15940) ([91m↑8.00%[0m) [0.12% of initial]
Iter:16899, L1 loss=0.0003717, Total loss=0.0003084, Time:31
[Iter 16900/20000] Loss: 0.0002869 (Best: 0.0002119 @iter15940) ([92m↓3.18%[0m) [0.11% of initial]
[Iter 16910/20000] Loss: 0.0002807 (Best: 0.0002119 @iter15940) ([92m↓2.14%[0m) [0.11% of initial]
[Iter 16920/20000] Loss: 0.0003231 (Best: 0.0002119 @iter15940) ([91m↑15.10%[0m) [0.13% of initial]
[Iter 16930/20000] Loss: 0.0002965 (Best: 0.0002119 @iter15940) ([92m↓8.25%[0m) [0.12% of initial]
[Iter 16940/20000] Loss: 0.0003210 (Best: 0.0002119 @iter15940) ([91m↑8.28%[0m) [0.13% of initial]
[Iter 16950/20000] Loss: 0.0003143 (Best: 0.0002119 @iter15940) ([92m↓2.11%[0m) [0.12% of initial]
[Iter 16960/20000] Loss: 0.0003001 (Best: 0.0002119 @iter15940) ([92m↓4.52%[0m) [0.12% of initial]
[Iter 16970/20000] Loss: 0.0002947 (Best: 0.0002119 @iter15940) ([92m↓1.80%[0m) [0.12% of initial]
[Iter 16980/20000] Loss: 0.0002879 (Best: 0.0002119 @iter15940) ([92m↓2.31%[0m) [0.11% of initial]
[Iter 16990/20000] Loss: 0.0003054 (Best: 0.0002119 @iter15940) ([91m↑6.09%[0m) [0.12% of initial]
Iter:16999, L1 loss=0.0003355, Total loss=0.0002922, Time:32
[Iter 17000/20000] Loss: 0.0002865 (Best: 0.0002119 @iter15940) ([92m↓6.19%[0m) [0.11% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Pruning 4 points (0.0%) from gaussian0 at iteration 17000
Pruning 6 points (0.0%) from gaussian1 at iteration 17000
[Iter 17010/20000] Loss: 0.0005782 (Best: 0.0002119 @iter15940) ([91m↑101.85%[0m) [0.23% of initial]
[Iter 17020/20000] Loss: 0.0004057 (Best: 0.0002119 @iter15940) ([92m↓29.85%[0m) [0.16% of initial]
[Iter 17030/20000] Loss: 0.0003369 (Best: 0.0002119 @iter15940) ([92m↓16.94%[0m) [0.13% of initial]
[Iter 17040/20000] Loss: 0.0002942 (Best: 0.0002119 @iter15940) ([92m↓12.67%[0m) [0.12% of initial]
[Iter 17050/20000] Loss: 0.0002928 (Best: 0.0002119 @iter15940) ([92m↓0.50%[0m) [0.12% of initial]
[Iter 17060/20000] Loss: 0.0003201 (Best: 0.0002119 @iter15940) ([91m↑9.32%[0m) [0.13% of initial]
[Iter 17070/20000] Loss: 0.0003249 (Best: 0.0002119 @iter15940) ([91m↑1.51%[0m) [0.13% of initial]
[Iter 17080/20000] Loss: 0.0002978 (Best: 0.0002119 @iter15940) ([92m↓8.32%[0m) [0.12% of initial]
[Iter 17090/20000] Loss: 0.0002724 (Best: 0.0002119 @iter15940) ([92m↓8.56%[0m) [0.11% of initial]
Iter:17099, L1 loss=0.0002851, Total loss=0.0002503, Time:30
[Iter 17100/20000] Loss: 0.0002637 (Best: 0.0002119 @iter15940) ([92m↓3.18%[0m) [0.10% of initial]
[Iter 17110/20000] Loss: 0.0002677 (Best: 0.0002119 @iter15940) ([91m↑1.51%[0m) [0.11% of initial]
[Iter 17120/20000] Loss: 0.0002604 (Best: 0.0002119 @iter15940) ([92m↓2.71%[0m) [0.10% of initial]
[Iter 17130/20000] Loss: 0.0002690 (Best: 0.0002119 @iter15940) ([91m↑3.28%[0m) [0.11% of initial]
[Iter 17140/20000] Loss: 0.0002884 (Best: 0.0002119 @iter15940) ([91m↑7.24%[0m) [0.11% of initial]
[Iter 17150/20000] Loss: 0.0002806 (Best: 0.0002119 @iter15940) ([92m↓2.70%[0m) [0.11% of initial]
[Iter 17160/20000] Loss: 0.0003061 (Best: 0.0002119 @iter15940) ([91m↑9.09%[0m) [0.12% of initial]
[Iter 17170/20000] Loss: 0.0003145 (Best: 0.0002119 @iter15940) ([91m↑2.73%[0m) [0.12% of initial]
[Iter 17180/20000] Loss: 0.0002709 (Best: 0.0002119 @iter15940) ([92m↓13.86%[0m) [0.11% of initial]
[Iter 17190/20000] Loss: 0.0002754 (Best: 0.0002119 @iter15940) ([91m↑1.67%[0m) [0.11% of initial]
Iter:17199, L1 loss=0.0003047, Total loss=0.0002598, Time:29
[Iter 17200/20000] Loss: 0.0002662 (Best: 0.0002119 @iter15940) ([92m↓3.32%[0m) [0.11% of initial]
[Iter 17210/20000] Loss: 0.0002663 (Best: 0.0002119 @iter15940) ([91m↑0.00%[0m) [0.11% of initial]
[Iter 17220/20000] Loss: 0.0002595 (Best: 0.0002119 @iter15940) ([92m↓2.52%[0m) [0.10% of initial]
[Iter 17230/20000] Loss: 0.0002595 (Best: 0.0002119 @iter15940) ([92m↓0.02%[0m) [0.10% of initial]
[Iter 17240/20000] Loss: 0.0002992 (Best: 0.0002119 @iter15940) ([91m↑15.29%[0m) [0.12% of initial]
[Iter 17250/20000] Loss: 0.0003380 (Best: 0.0002119 @iter15940) ([91m↑12.98%[0m) [0.13% of initial]
[Iter 17260/20000] Loss: 0.0003060 (Best: 0.0002119 @iter15940) ([92m↓9.47%[0m) [0.12% of initial]
[Iter 17270/20000] Loss: 0.0003053 (Best: 0.0002119 @iter15940) ([92m↓0.23%[0m) [0.12% of initial]
[Iter 17280/20000] Loss: 0.0003047 (Best: 0.0002119 @iter15940) ([92m↓0.18%[0m) [0.12% of initial]
[Iter 17290/20000] Loss: 0.0004175 (Best: 0.0002119 @iter15940) ([91m↑37.01%[0m) [0.17% of initial]
Iter:17299, L1 loss=0.0003295, Total loss=0.0003106, Time:29
[Iter 17300/20000] Loss: 0.0003263 (Best: 0.0002119 @iter15940) ([92m↓21.84%[0m) [0.13% of initial]
[Iter 17310/20000] Loss: 0.0003136 (Best: 0.0002119 @iter15940) ([92m↓3.91%[0m) [0.12% of initial]
[Iter 17320/20000] Loss: 0.0003232 (Best: 0.0002119 @iter15940) ([91m↑3.06%[0m) [0.13% of initial]
[Iter 17330/20000] Loss: 0.0002808 (Best: 0.0002119 @iter15940) ([92m↓13.12%[0m) [0.11% of initial]
[Iter 17340/20000] Loss: 0.0002658 (Best: 0.0002119 @iter15940) ([92m↓5.35%[0m) [0.11% of initial]
[Iter 17350/20000] Loss: 0.0002830 (Best: 0.0002119 @iter15940) ([91m↑6.50%[0m) [0.11% of initial]
[Iter 17360/20000] Loss: 0.0002885 (Best: 0.0002119 @iter15940) ([91m↑1.93%[0m) [0.11% of initial]
[Iter 17370/20000] Loss: 0.0002647 (Best: 0.0002119 @iter15940) ([92m↓8.26%[0m) [0.11% of initial]
[Iter 17380/20000] Loss: 0.0002782 (Best: 0.0002119 @iter15940) ([91m↑5.12%[0m) [0.11% of initial]
[Iter 17390/20000] Loss: 0.0002805 (Best: 0.0002119 @iter15940) ([91m↑0.81%[0m) [0.11% of initial]
Iter:17399, L1 loss=0.0003392, Total loss=0.000267, Time:29
[Iter 17400/20000] Loss: 0.0002782 (Best: 0.0002119 @iter15940) ([92m↓0.81%[0m) [0.11% of initial]
[Iter 17410/20000] Loss: 0.0002779 (Best: 0.0002119 @iter15940) ([92m↓0.12%[0m) [0.11% of initial]
[Iter 17420/20000] Loss: 0.0002873 (Best: 0.0002119 @iter15940) ([91m↑3.39%[0m) [0.11% of initial]
[Iter 17430/20000] Loss: 0.0002923 (Best: 0.0002119 @iter15940) ([91m↑1.75%[0m) [0.12% of initial]
[Iter 17440/20000] Loss: 0.0002705 (Best: 0.0002119 @iter15940) ([92m↓7.45%[0m) [0.11% of initial]
[Iter 17450/20000] Loss: 0.0002779 (Best: 0.0002119 @iter15940) ([91m↑2.73%[0m) [0.11% of initial]
[Iter 17460/20000] Loss: 0.0003146 (Best: 0.0002119 @iter15940) ([91m↑13.20%[0m) [0.12% of initial]
[Iter 17470/20000] Loss: 0.0002799 (Best: 0.0002119 @iter15940) ([92m↓11.04%[0m) [0.11% of initial]
[Iter 17480/20000] Loss: 0.0002797 (Best: 0.0002119 @iter15940) ([92m↓0.04%[0m) [0.11% of initial]
[Iter 17490/20000] Loss: 0.0002948 (Best: 0.0002119 @iter15940) ([91m↑5.40%[0m) [0.12% of initial]
Iter:17499, L1 loss=0.0003084, Total loss=0.0002737, Time:29
[Iter 17500/20000] Loss: 0.0002689 (Best: 0.0002119 @iter15940) ([92m↓8.81%[0m) [0.11% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 17500
Pruning 1 points (0.0%) from gaussian1 at iteration 17500
[Iter 17510/20000] Loss: 0.0005335 (Best: 0.0002119 @iter15940) ([91m↑98.43%[0m) [0.21% of initial]
[Iter 17520/20000] Loss: 0.0003757 (Best: 0.0002119 @iter15940) ([92m↓29.58%[0m) [0.15% of initial]
[Iter 17530/20000] Loss: 0.0002946 (Best: 0.0002119 @iter15940) ([92m↓21.58%[0m) [0.12% of initial]
[Iter 17540/20000] Loss: 0.0002705 (Best: 0.0002119 @iter15940) ([92m↓8.21%[0m) [0.11% of initial]
[Iter 17550/20000] Loss: 0.0002569 (Best: 0.0002119 @iter15940) ([92m↓5.00%[0m) [0.10% of initial]
[Iter 17560/20000] Loss: 0.0002508 (Best: 0.0002119 @iter15940) ([92m↓2.38%[0m) [0.10% of initial]
[Iter 17570/20000] Loss: 0.0002633 (Best: 0.0002119 @iter15940) ([91m↑4.97%[0m) [0.10% of initial]
[Iter 17580/20000] Loss: 0.0002605 (Best: 0.0002119 @iter15940) ([92m↓1.07%[0m) [0.10% of initial]
[Iter 17590/20000] Loss: 0.0002550 (Best: 0.0002119 @iter15940) ([92m↓2.11%[0m) [0.10% of initial]
Iter:17599, L1 loss=0.0003004, Total loss=0.0002544, Time:31
[Iter 17600/20000] Loss: 0.0002813 (Best: 0.0002119 @iter15940) ([91m↑10.31%[0m) [0.11% of initial]
[Iter 17610/20000] Loss: 0.0002836 (Best: 0.0002119 @iter15940) ([91m↑0.83%[0m) [0.11% of initial]
[Iter 17620/20000] Loss: 0.0002972 (Best: 0.0002119 @iter15940) ([91m↑4.79%[0m) [0.12% of initial]
[Iter 17630/20000] Loss: 0.0002831 (Best: 0.0002119 @iter15940) ([92m↓4.75%[0m) [0.11% of initial]
[Iter 17640/20000] Loss: 0.0002798 (Best: 0.0002119 @iter15940) ([92m↓1.17%[0m) [0.11% of initial]
[Iter 17650/20000] Loss: 0.0002897 (Best: 0.0002119 @iter15940) ([91m↑3.53%[0m) [0.12% of initial]
[Iter 17660/20000] Loss: 0.0002847 (Best: 0.0002119 @iter15940) ([92m↓1.72%[0m) [0.11% of initial]
[Iter 17670/20000] Loss: 0.0002861 (Best: 0.0002119 @iter15940) ([91m↑0.49%[0m) [0.11% of initial]
[Iter 17680/20000] Loss: 0.0002770 (Best: 0.0002119 @iter15940) ([92m↓3.17%[0m) [0.11% of initial]
[Iter 17690/20000] Loss: 0.0002788 (Best: 0.0002119 @iter15940) ([91m↑0.63%[0m) [0.11% of initial]
Iter:17699, L1 loss=0.0003038, Total loss=0.0002493, Time:29
[Iter 17700/20000] Loss: 0.0002704 (Best: 0.0002119 @iter15940) ([92m↓2.99%[0m) [0.11% of initial]
[Iter 17710/20000] Loss: 0.0002676 (Best: 0.0002119 @iter15940) ([92m↓1.07%[0m) [0.11% of initial]
[Iter 17720/20000] Loss: 0.0003163 (Best: 0.0002119 @iter15940) ([91m↑18.21%[0m) [0.13% of initial]
[Iter 17730/20000] Loss: 0.0002874 (Best: 0.0002119 @iter15940) ([92m↓9.14%[0m) [0.11% of initial]
[Iter 17740/20000] Loss: 0.0002671 (Best: 0.0002119 @iter15940) ([92m↓7.07%[0m) [0.11% of initial]
[Iter 17750/20000] Loss: 0.0002688 (Best: 0.0002119 @iter15940) ([91m↑0.64%[0m) [0.11% of initial]
[Iter 17760/20000] Loss: 0.0002555 (Best: 0.0002119 @iter15940) ([92m↓4.95%[0m) [0.10% of initial]
[Iter 17770/20000] Loss: 0.0002482 (Best: 0.0002119 @iter15940) ([92m↓2.85%[0m) [0.10% of initial]
[Iter 17780/20000] Loss: 0.0002533 (Best: 0.0002119 @iter15940) ([91m↑2.06%[0m) [0.10% of initial]
[Iter 17790/20000] Loss: 0.0002973 (Best: 0.0002119 @iter15940) ([91m↑17.38%[0m) [0.12% of initial]
Iter:17799, L1 loss=0.0004131, Total loss=0.000353, Time:29
[Iter 17800/20000] Loss: 0.0003230 (Best: 0.0002119 @iter15940) ([91m↑8.65%[0m) [0.13% of initial]
[Iter 17810/20000] Loss: 0.0003281 (Best: 0.0002119 @iter15940) ([91m↑1.58%[0m) [0.13% of initial]
[Iter 17820/20000] Loss: 0.0003122 (Best: 0.0002119 @iter15940) ([92m↓4.85%[0m) [0.12% of initial]
[Iter 17830/20000] Loss: 0.0002695 (Best: 0.0002119 @iter15940) ([92m↓13.70%[0m) [0.11% of initial]
[Iter 17840/20000] Loss: 0.0002555 (Best: 0.0002119 @iter15940) ([92m↓5.16%[0m) [0.10% of initial]
[Iter 17850/20000] Loss: 0.0002562 (Best: 0.0002119 @iter15940) ([91m↑0.27%[0m) [0.10% of initial]
[Iter 17860/20000] Loss: 0.0002558 (Best: 0.0002119 @iter15940) ([92m↓0.17%[0m) [0.10% of initial]
[Iter 17870/20000] Loss: 0.0002855 (Best: 0.0002119 @iter15940) ([91m↑11.60%[0m) [0.11% of initial]
[Iter 17880/20000] Loss: 0.0003053 (Best: 0.0002119 @iter15940) ([91m↑6.95%[0m) [0.12% of initial]
[Iter 17890/20000] Loss: 0.0002586 (Best: 0.0002119 @iter15940) ([92m↓15.29%[0m) [0.10% of initial]
Iter:17899, L1 loss=0.0002862, Total loss=0.000251, Time:29
[Iter 17900/20000] Loss: 0.0002637 (Best: 0.0002119 @iter15940) ([91m↑1.95%[0m) [0.10% of initial]
[Iter 17910/20000] Loss: 0.0002628 (Best: 0.0002119 @iter15940) ([92m↓0.31%[0m) [0.10% of initial]
[Iter 17920/20000] Loss: 0.0002751 (Best: 0.0002119 @iter15940) ([91m↑4.67%[0m) [0.11% of initial]
[Iter 17930/20000] Loss: 0.0002600 (Best: 0.0002119 @iter15940) ([92m↓5.48%[0m) [0.10% of initial]
[Iter 17940/20000] Loss: 0.0002514 (Best: 0.0002119 @iter15940) ([92m↓3.33%[0m) [0.10% of initial]
[Iter 17950/20000] Loss: 0.0002557 (Best: 0.0002119 @iter15940) ([91m↑1.73%[0m) [0.10% of initial]
[Iter 17960/20000] Loss: 0.0002614 (Best: 0.0002119 @iter15940) ([91m↑2.20%[0m) [0.10% of initial]
[Iter 17970/20000] Loss: 0.0002569 (Best: 0.0002119 @iter15940) ([92m↓1.71%[0m) [0.10% of initial]
[Iter 17980/20000] Loss: 0.0002764 (Best: 0.0002119 @iter15940) ([91m↑7.59%[0m) [0.11% of initial]
[Iter 17990/20000] Loss: 0.0002446 (Best: 0.0002119 @iter15940) ([92m↓11.49%[0m) [0.10% of initial]
Iter:17999, L1 loss=0.0003267, Total loss=0.0002397, Time:29
[Iter 18000/20000] Loss: 0.0002405 (Best: 0.0002119 @iter15940) ([92m↓1.70%[0m) [0.10% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 18000
Pruning 6 points (0.0%) from gaussian1 at iteration 18000
[Iter 18010/20000] Loss: 0.0007217 (Best: 0.0002119 @iter15940) ([91m↑200.14%[0m) [0.29% of initial]
[Iter 18020/20000] Loss: 0.0004122 (Best: 0.0002119 @iter15940) ([92m↓42.88%[0m) [0.16% of initial]
[Iter 18030/20000] Loss: 0.0003610 (Best: 0.0002119 @iter15940) ([92m↓12.43%[0m) [0.14% of initial]
[Iter 18040/20000] Loss: 0.0002901 (Best: 0.0002119 @iter15940) ([92m↓19.65%[0m) [0.12% of initial]
[Iter 18050/20000] Loss: 0.0002646 (Best: 0.0002119 @iter15940) ([92m↓8.78%[0m) [0.11% of initial]
[Iter 18060/20000] Loss: 0.0002643 (Best: 0.0002119 @iter15940) ([92m↓0.09%[0m) [0.11% of initial]
[Iter 18070/20000] Loss: 0.0002578 (Best: 0.0002119 @iter15940) ([92m↓2.49%[0m) [0.10% of initial]
[Iter 18080/20000] Loss: 0.0002554 (Best: 0.0002119 @iter15940) ([92m↓0.93%[0m) [0.10% of initial]
[Iter 18090/20000] Loss: 0.0002755 (Best: 0.0002119 @iter15940) ([91m↑7.88%[0m) [0.11% of initial]
Iter:18099, L1 loss=0.0003521, Total loss=0.0003029, Time:29
[Iter 18100/20000] Loss: 0.0002692 (Best: 0.0002119 @iter15940) ([92m↓2.29%[0m) [0.11% of initial]
[Iter 18110/20000] Loss: 0.0002603 (Best: 0.0002119 @iter15940) ([92m↓3.30%[0m) [0.10% of initial]
[Iter 18120/20000] Loss: 0.0002639 (Best: 0.0002119 @iter15940) ([91m↑1.38%[0m) [0.10% of initial]
[Iter 18130/20000] Loss: 0.0002472 (Best: 0.0002119 @iter15940) ([92m↓6.33%[0m) [0.10% of initial]
[Iter 18140/20000] Loss: 0.0002511 (Best: 0.0002119 @iter15940) ([91m↑1.58%[0m) [0.10% of initial]
[Iter 18150/20000] Loss: 0.0002514 (Best: 0.0002119 @iter15940) ([91m↑0.12%[0m) [0.10% of initial]
[Iter 18160/20000] Loss: 0.0002408 (Best: 0.0002119 @iter15940) ([92m↓4.23%[0m) [0.10% of initial]
[Iter 18170/20000] Loss: 0.0002498 (Best: 0.0002119 @iter15940) ([91m↑3.77%[0m) [0.10% of initial]
[Iter 18180/20000] Loss: 0.0002904 (Best: 0.0002119 @iter15940) ([91m↑16.23%[0m) [0.12% of initial]
[Iter 18190/20000] Loss: 0.0003065 (Best: 0.0002119 @iter15940) ([91m↑5.55%[0m) [0.12% of initial]
Iter:18199, L1 loss=0.0003475, Total loss=0.0002602, Time:28
[Iter 18200/20000] Loss: 0.0003105 (Best: 0.0002119 @iter15940) ([91m↑1.30%[0m) [0.12% of initial]
[Iter 18210/20000] Loss: 0.0002816 (Best: 0.0002119 @iter15940) ([92m↓9.32%[0m) [0.11% of initial]
[Iter 18220/20000] Loss: 0.0002595 (Best: 0.0002119 @iter15940) ([92m↓7.86%[0m) [0.10% of initial]
[Iter 18230/20000] Loss: 0.0002919 (Best: 0.0002119 @iter15940) ([91m↑12.49%[0m) [0.12% of initial]
[Iter 18240/20000] Loss: 0.0002827 (Best: 0.0002119 @iter15940) ([92m↓3.14%[0m) [0.11% of initial]
[Iter 18250/20000] Loss: 0.0002876 (Best: 0.0002119 @iter15940) ([91m↑1.74%[0m) [0.11% of initial]
[Iter 18260/20000] Loss: 0.0002779 (Best: 0.0002119 @iter15940) ([92m↓3.39%[0m) [0.11% of initial]
[Iter 18270/20000] Loss: 0.0002724 (Best: 0.0002119 @iter15940) ([92m↓1.97%[0m) [0.11% of initial]
[Iter 18280/20000] Loss: 0.0002697 (Best: 0.0002119 @iter15940) ([92m↓0.99%[0m) [0.11% of initial]
[Iter 18290/20000] Loss: 0.0002927 (Best: 0.0002119 @iter15940) ([91m↑8.52%[0m) [0.12% of initial]
Iter:18299, L1 loss=0.0003479, Total loss=0.0003056, Time:28
[Iter 18300/20000] Loss: 0.0002892 (Best: 0.0002119 @iter15940) ([92m↓1.20%[0m) [0.11% of initial]
[Iter 18310/20000] Loss: 0.0002892 (Best: 0.0002119 @iter15940) ([91m↑0.00%[0m) [0.11% of initial]
[Iter 18320/20000] Loss: 0.0002980 (Best: 0.0002119 @iter15940) ([91m↑3.06%[0m) [0.12% of initial]
[Iter 18330/20000] Loss: 0.0003593 (Best: 0.0002119 @iter15940) ([91m↑20.54%[0m) [0.14% of initial]
[Iter 18340/20000] Loss: 0.0003339 (Best: 0.0002119 @iter15940) ([92m↓7.06%[0m) [0.13% of initial]
[Iter 18350/20000] Loss: 0.0003359 (Best: 0.0002119 @iter15940) ([91m↑0.61%[0m) [0.13% of initial]
[Iter 18360/20000] Loss: 0.0003970 (Best: 0.0002119 @iter15940) ([91m↑18.18%[0m) [0.16% of initial]
[Iter 18370/20000] Loss: 0.0003053 (Best: 0.0002119 @iter15940) ([92m↓23.09%[0m) [0.12% of initial]
[Iter 18380/20000] Loss: 0.0002601 (Best: 0.0002119 @iter15940) ([92m↓14.81%[0m) [0.10% of initial]
[Iter 18390/20000] Loss: 0.0002650 (Best: 0.0002119 @iter15940) ([91m↑1.89%[0m) [0.11% of initial]
Iter:18399, L1 loss=0.0003034, Total loss=0.0002338, Time:29
[Iter 18400/20000] Loss: 0.0002349 (Best: 0.0002119 @iter15940) ([92m↓11.37%[0m) [0.09% of initial]
[Iter 18410/20000] Loss: 0.0002496 (Best: 0.0002119 @iter15940) ([91m↑6.23%[0m) [0.10% of initial]
[Iter 18420/20000] Loss: 0.0002323 (Best: 0.0002119 @iter15940) ([92m↓6.92%[0m) [0.09% of initial]
[Iter 18430/20000] Loss: 0.0002325 (Best: 0.0002119 @iter15940) ([91m↑0.09%[0m) [0.09% of initial]
[Iter 18440/20000] Loss: 0.0002373 (Best: 0.0002119 @iter15940) ([91m↑2.06%[0m) [0.09% of initial]
[Iter 18450/20000] Loss: 0.0002497 (Best: 0.0002119 @iter15940) ([91m↑5.22%[0m) [0.10% of initial]
[Iter 18460/20000] Loss: 0.0002662 (Best: 0.0002119 @iter15940) ([91m↑6.60%[0m) [0.11% of initial]
[Iter 18470/20000] Loss: 0.0002574 (Best: 0.0002119 @iter15940) ([92m↓3.29%[0m) [0.10% of initial]
[Iter 18480/20000] Loss: 0.0002451 (Best: 0.0002119 @iter15940) ([92m↓4.79%[0m) [0.10% of initial]
[Iter 18490/20000] Loss: 0.0002564 (Best: 0.0002119 @iter15940) ([91m↑4.63%[0m) [0.10% of initial]
Iter:18499, L1 loss=0.0003056, Total loss=0.0002581, Time:29
[Iter 18500/20000] Loss: 0.0002518 (Best: 0.0002119 @iter15940) ([92m↓1.80%[0m) [0.10% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 18500
Pruning 3 points (0.0%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0004980 (Best: 0.0002119 @iter15940) ([91m↑97.77%[0m) [0.20% of initial]
[Iter 18520/20000] Loss: 0.0003398 (Best: 0.0002119 @iter15940) ([92m↓31.77%[0m) [0.13% of initial]
[Iter 18530/20000] Loss: 0.0002680 (Best: 0.0002119 @iter15940) ([92m↓21.14%[0m) [0.11% of initial]
[Iter 18540/20000] Loss: 0.0002816 (Best: 0.0002119 @iter15940) ([91m↑5.09%[0m) [0.11% of initial]
[Iter 18550/20000] Loss: 0.0002673 (Best: 0.0002119 @iter15940) ([92m↓5.08%[0m) [0.11% of initial]
[Iter 18560/20000] Loss: 0.0002824 (Best: 0.0002119 @iter15940) ([91m↑5.66%[0m) [0.11% of initial]
[Iter 18570/20000] Loss: 0.0002822 (Best: 0.0002119 @iter15940) ([92m↓0.06%[0m) [0.11% of initial]
[Iter 18580/20000] Loss: 0.0002520 (Best: 0.0002119 @iter15940) ([92m↓10.71%[0m) [0.10% of initial]
[Iter 18590/20000] Loss: 0.0002483 (Best: 0.0002119 @iter15940) ([92m↓1.48%[0m) [0.10% of initial]
Iter:18599, L1 loss=0.0003434, Total loss=0.0002566, Time:29
[Iter 18600/20000] Loss: 0.0002723 (Best: 0.0002119 @iter15940) ([91m↑9.66%[0m) [0.11% of initial]
[Iter 18610/20000] Loss: 0.0002532 (Best: 0.0002119 @iter15940) ([92m↓7.02%[0m) [0.10% of initial]
[Iter 18620/20000] Loss: 0.0002402 (Best: 0.0002119 @iter15940) ([92m↓5.10%[0m) [0.10% of initial]
[Iter 18630/20000] Loss: 0.0002936 (Best: 0.0002119 @iter15940) ([91m↑22.20%[0m) [0.12% of initial]
[Iter 18640/20000] Loss: 0.0002796 (Best: 0.0002119 @iter15940) ([92m↓4.74%[0m) [0.11% of initial]
[Iter 18650/20000] Loss: 0.0002506 (Best: 0.0002119 @iter15940) ([92m↓10.39%[0m) [0.10% of initial]
[Iter 18660/20000] Loss: 0.0002497 (Best: 0.0002119 @iter15940) ([92m↓0.34%[0m) [0.10% of initial]
[Iter 18670/20000] Loss: 0.0002443 (Best: 0.0002119 @iter15940) ([92m↓2.16%[0m) [0.10% of initial]
[Iter 18680/20000] Loss: 0.0002533 (Best: 0.0002119 @iter15940) ([91m↑3.67%[0m) [0.10% of initial]
[Iter 18690/20000] Loss: 0.0002590 (Best: 0.0002119 @iter15940) ([91m↑2.24%[0m) [0.10% of initial]
Iter:18699, L1 loss=0.0002906, Total loss=0.0002478, Time:25
[Iter 18700/20000] Loss: 0.0002357 (Best: 0.0002119 @iter15940) ([92m↓9.00%[0m) [0.09% of initial]
[Iter 18710/20000] Loss: 0.0002367 (Best: 0.0002119 @iter15940) ([91m↑0.44%[0m) [0.09% of initial]
[Iter 18720/20000] Loss: 0.0002340 (Best: 0.0002119 @iter15940) ([92m↓1.13%[0m) [0.09% of initial]
[Iter 18730/20000] Loss: 0.0002405 (Best: 0.0002119 @iter15940) ([91m↑2.76%[0m) [0.10% of initial]
[Iter 18740/20000] Loss: 0.0002481 (Best: 0.0002119 @iter15940) ([91m↑3.15%[0m) [0.10% of initial]
[Iter 18750/20000] Loss: 0.0002342 (Best: 0.0002119 @iter15940) ([92m↓5.58%[0m) [0.09% of initial]
[Iter 18760/20000] Loss: 0.0002412 (Best: 0.0002119 @iter15940) ([91m↑3.00%[0m) [0.10% of initial]
[Iter 18770/20000] Loss: 0.0002457 (Best: 0.0002119 @iter15940) ([91m↑1.86%[0m) [0.10% of initial]
[Iter 18780/20000] Loss: 0.0002497 (Best: 0.0002119 @iter15940) ([91m↑1.64%[0m) [0.10% of initial]
[Iter 18790/20000] Loss: 0.0002517 (Best: 0.0002119 @iter15940) ([91m↑0.77%[0m) [0.10% of initial]
Iter:18799, L1 loss=0.0002856, Total loss=0.0002282, Time:26
[Iter 18800/20000] Loss: 0.0002441 (Best: 0.0002119 @iter15940) ([92m↓3.00%[0m) [0.10% of initial]
[Iter 18810/20000] Loss: 0.0002495 (Best: 0.0002119 @iter15940) ([91m↑2.23%[0m) [0.10% of initial]
[Iter 18820/20000] Loss: 0.0002440 (Best: 0.0002119 @iter15940) ([92m↓2.23%[0m) [0.10% of initial]
[Iter 18830/20000] Loss: 0.0002589 (Best: 0.0002119 @iter15940) ([91m↑6.10%[0m) [0.10% of initial]
[Iter 18840/20000] Loss: 0.0002528 (Best: 0.0002119 @iter15940) ([92m↓2.34%[0m) [0.10% of initial]
[Iter 18850/20000] Loss: 0.0002552 (Best: 0.0002119 @iter15940) ([91m↑0.93%[0m) [0.10% of initial]
[Iter 18860/20000] Loss: 0.0002931 (Best: 0.0002119 @iter15940) ([91m↑14.88%[0m) [0.12% of initial]
[Iter 18870/20000] Loss: 0.0002585 (Best: 0.0002119 @iter15940) ([92m↓11.82%[0m) [0.10% of initial]
[Iter 18880/20000] Loss: 0.0002505 (Best: 0.0002119 @iter15940) ([92m↓3.09%[0m) [0.10% of initial]
[Iter 18890/20000] Loss: 0.0002556 (Best: 0.0002119 @iter15940) ([91m↑2.04%[0m) [0.10% of initial]
Iter:18899, L1 loss=0.0002917, Total loss=0.0002533, Time:30
[Iter 18900/20000] Loss: 0.0002553 (Best: 0.0002119 @iter15940) ([92m↓0.12%[0m) [0.10% of initial]
[Iter 18910/20000] Loss: 0.0002609 (Best: 0.0002119 @iter15940) ([91m↑2.20%[0m) [0.10% of initial]
[Iter 18920/20000] Loss: 0.0002382 (Best: 0.0002119 @iter15940) ([92m↓8.70%[0m) [0.09% of initial]
[Iter 18930/20000] Loss: 0.0002873 (Best: 0.0002119 @iter15940) ([91m↑20.60%[0m) [0.11% of initial]
[Iter 18940/20000] Loss: 0.0002595 (Best: 0.0002119 @iter15940) ([92m↓9.67%[0m) [0.10% of initial]
[Iter 18950/20000] Loss: 0.0002735 (Best: 0.0002119 @iter15940) ([91m↑5.41%[0m) [0.11% of initial]
[Iter 18960/20000] Loss: 0.0002865 (Best: 0.0002119 @iter15940) ([91m↑4.72%[0m) [0.11% of initial]
[Iter 18970/20000] Loss: 0.0003050 (Best: 0.0002119 @iter15940) ([91m↑6.49%[0m) [0.12% of initial]
[Iter 18980/20000] Loss: 0.0002649 (Best: 0.0002119 @iter15940) ([92m↓13.16%[0m) [0.11% of initial]
[Iter 18990/20000] Loss: 0.0002557 (Best: 0.0002119 @iter15940) ([92m↓3.46%[0m) [0.10% of initial]
Iter:18999, L1 loss=0.000279, Total loss=0.000239, Time:29
[Iter 19000/20000] Loss: 0.0002358 (Best: 0.0002119 @iter15940) ([92m↓7.80%[0m) [0.09% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 19000
Pruning 4 points (0.0%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0005892 (Best: 0.0002119 @iter15940) ([91m↑149.88%[0m) [0.23% of initial]
[Iter 19020/20000] Loss: 0.0004310 (Best: 0.0002119 @iter15940) ([92m↓26.84%[0m) [0.17% of initial]
[Iter 19030/20000] Loss: 0.0003294 (Best: 0.0002119 @iter15940) ([92m↓23.58%[0m) [0.13% of initial]
[Iter 19040/20000] Loss: 0.0002682 (Best: 0.0002119 @iter15940) ([92m↓18.56%[0m) [0.11% of initial]
[Iter 19050/20000] Loss: 0.0002522 (Best: 0.0002119 @iter15940) ([92m↓5.98%[0m) [0.10% of initial]
[Iter 19060/20000] Loss: 0.0002402 (Best: 0.0002119 @iter15940) ([92m↓4.75%[0m) [0.10% of initial]
[Iter 19070/20000] Loss: 0.0002600 (Best: 0.0002119 @iter15940) ([91m↑8.24%[0m) [0.10% of initial]
[Iter 19080/20000] Loss: 0.0002361 (Best: 0.0002119 @iter15940) ([92m↓9.21%[0m) [0.09% of initial]
[Iter 19090/20000] Loss: 0.0002389 (Best: 0.0002119 @iter15940) ([91m↑1.20%[0m) [0.09% of initial]
Iter:19099, L1 loss=0.0002845, Total loss=0.000237, Time:28
[Iter 19100/20000] Loss: 0.0002778 (Best: 0.0002119 @iter15940) ([91m↑16.28%[0m) [0.11% of initial]
[Iter 19110/20000] Loss: 0.0002769 (Best: 0.0002119 @iter15940) ([92m↓0.31%[0m) [0.11% of initial]
[Iter 19120/20000] Loss: 0.0002472 (Best: 0.0002119 @iter15940) ([92m↓10.73%[0m) [0.10% of initial]
[Iter 19130/20000] Loss: 0.0002401 (Best: 0.0002119 @iter15940) ([92m↓2.88%[0m) [0.10% of initial]
[Iter 19140/20000] Loss: 0.0002550 (Best: 0.0002119 @iter15940) ([91m↑6.22%[0m) [0.10% of initial]
[Iter 19150/20000] Loss: 0.0002520 (Best: 0.0002119 @iter15940) ([92m↓1.19%[0m) [0.10% of initial]
[Iter 19160/20000] Loss: 0.0002542 (Best: 0.0002119 @iter15940) ([91m↑0.87%[0m) [0.10% of initial]
[Iter 19170/20000] Loss: 0.0002383 (Best: 0.0002119 @iter15940) ([92m↓6.26%[0m) [0.09% of initial]
[Iter 19180/20000] Loss: 0.0002366 (Best: 0.0002119 @iter15940) ([92m↓0.68%[0m) [0.09% of initial]
[Iter 19190/20000] Loss: 0.0002629 (Best: 0.0002119 @iter15940) ([91m↑11.08%[0m) [0.10% of initial]
Iter:19199, L1 loss=0.0003306, Total loss=0.000333, Time:31
[Iter 19200/20000] Loss: 0.0002947 (Best: 0.0002119 @iter15940) ([91m↑12.12%[0m) [0.12% of initial]
[Iter 19210/20000] Loss: 0.0002601 (Best: 0.0002119 @iter15940) ([92m↓11.74%[0m) [0.10% of initial]
[Iter 19220/20000] Loss: 0.0002628 (Best: 0.0002119 @iter15940) ([91m↑1.04%[0m) [0.10% of initial]
[Iter 19230/20000] Loss: 0.0002339 (Best: 0.0002119 @iter15940) ([92m↓11.00%[0m) [0.09% of initial]
[Iter 19240/20000] Loss: 0.0002288 (Best: 0.0002119 @iter15940) ([92m↓2.18%[0m) [0.09% of initial]
[Iter 19250/20000] Loss: 0.0002365 (Best: 0.0002119 @iter15940) ([91m↑3.37%[0m) [0.09% of initial]
[Iter 19260/20000] Loss: 0.0002324 (Best: 0.0002119 @iter15940) ([92m↓1.75%[0m) [0.09% of initial]
[Iter 19270/20000] Loss: 0.0002411 (Best: 0.0002119 @iter15940) ([91m↑3.74%[0m) [0.10% of initial]
[Iter 19280/20000] Loss: 0.0002478 (Best: 0.0002119 @iter15940) ([91m↑2.80%[0m) [0.10% of initial]
[Iter 19290/20000] Loss: 0.0002406 (Best: 0.0002119 @iter15940) ([92m↓2.92%[0m) [0.10% of initial]
Iter:19299, L1 loss=0.0002752, Total loss=0.0002359, Time:29
[Iter 19300/20000] Loss: 0.0002401 (Best: 0.0002119 @iter15940) ([92m↓0.23%[0m) [0.10% of initial]
[Iter 19310/20000] Loss: 0.0002593 (Best: 0.0002119 @iter15940) ([91m↑8.01%[0m) [0.10% of initial]
[Iter 19320/20000] Loss: 0.0002500 (Best: 0.0002119 @iter15940) ([92m↓3.60%[0m) [0.10% of initial]
[Iter 19330/20000] Loss: 0.0002598 (Best: 0.0002119 @iter15940) ([91m↑3.93%[0m) [0.10% of initial]
[Iter 19340/20000] Loss: 0.0003209 (Best: 0.0002119 @iter15940) ([91m↑23.50%[0m) [0.13% of initial]
[Iter 19350/20000] Loss: 0.0003589 (Best: 0.0002119 @iter15940) ([91m↑11.87%[0m) [0.14% of initial]
[Iter 19360/20000] Loss: 0.0003234 (Best: 0.0002119 @iter15940) ([92m↓9.89%[0m) [0.13% of initial]
[Iter 19370/20000] Loss: 0.0003248 (Best: 0.0002119 @iter15940) ([91m↑0.43%[0m) [0.13% of initial]
[Iter 19380/20000] Loss: 0.0003387 (Best: 0.0002119 @iter15940) ([91m↑4.27%[0m) [0.13% of initial]
[Iter 19390/20000] Loss: 0.0002731 (Best: 0.0002119 @iter15940) ([92m↓19.37%[0m) [0.11% of initial]
Iter:19399, L1 loss=0.0002861, Total loss=0.0002349, Time:29
[Iter 19400/20000] Loss: 0.0002589 (Best: 0.0002119 @iter15940) ([92m↓5.18%[0m) [0.10% of initial]
[Iter 19410/20000] Loss: 0.0002347 (Best: 0.0002119 @iter15940) ([92m↓9.37%[0m) [0.09% of initial]
[Iter 19420/20000] Loss: 0.0002315 (Best: 0.0002099 @iter19417) ([92m↓1.37%[0m) [0.09% of initial]
[Iter 19430/20000] Loss: 0.0002251 (Best: 0.0002099 @iter19417) ([92m↓2.76%[0m) [0.09% of initial]
[Iter 19440/20000] Loss: 0.0002420 (Best: 0.0002099 @iter19417) ([91m↑7.53%[0m) [0.10% of initial]
[Iter 19450/20000] Loss: 0.0002394 (Best: 0.0002099 @iter19417) ([92m↓1.09%[0m) [0.10% of initial]
[Iter 19460/20000] Loss: 0.0002813 (Best: 0.0002099 @iter19417) ([91m↑17.49%[0m) [0.11% of initial]
[Iter 19470/20000] Loss: 0.0003479 (Best: 0.0002099 @iter19417) ([91m↑23.68%[0m) [0.14% of initial]
[Iter 19480/20000] Loss: 0.0003934 (Best: 0.0002099 @iter19417) ([91m↑13.08%[0m) [0.16% of initial]
[Iter 19490/20000] Loss: 0.0003299 (Best: 0.0002099 @iter19417) ([92m↓16.15%[0m) [0.13% of initial]
Iter:19499, L1 loss=0.0003036, Total loss=0.0002701, Time:29
[Iter 19500/20000] Loss: 0.0002934 (Best: 0.0002099 @iter19417) ([92m↓11.06%[0m) [0.12% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 19500
Pruning 4 points (0.0%) from gaussian1 at iteration 19500
[Iter 19510/20000] Loss: 0.0005081 (Best: 0.0002099 @iter19417) ([91m↑73.18%[0m) [0.20% of initial]
[Iter 19520/20000] Loss: 0.0003382 (Best: 0.0002099 @iter19417) ([92m↓33.43%[0m) [0.13% of initial]
[Iter 19530/20000] Loss: 0.0002810 (Best: 0.0002099 @iter19417) ([92m↓16.94%[0m) [0.11% of initial]
[Iter 19540/20000] Loss: 0.0002441 (Best: 0.0002099 @iter19417) ([92m↓13.11%[0m) [0.10% of initial]
[Iter 19550/20000] Loss: 0.0002438 (Best: 0.0002099 @iter19417) ([92m↓0.14%[0m) [0.10% of initial]
[Iter 19560/20000] Loss: 0.0002384 (Best: 0.0002099 @iter19417) ([92m↓2.21%[0m) [0.09% of initial]
[Iter 19570/20000] Loss: 0.0002201 (Best: 0.0002099 @iter19417) ([92m↓7.66%[0m) [0.09% of initial]
[Iter 19580/20000] Loss: 0.0002689 (Best: 0.0002099 @iter19417) ([91m↑22.16%[0m) [0.11% of initial]
[Iter 19590/20000] Loss: 0.0002337 (Best: 0.0002099 @iter19417) ([92m↓13.08%[0m) [0.09% of initial]
Iter:19599, L1 loss=0.0002816, Total loss=0.0002343, Time:28
[Iter 19600/20000] Loss: 0.0002337 (Best: 0.0002099 @iter19417) ([92m↓0.00%[0m) [0.09% of initial]
[Iter 19610/20000] Loss: 0.0002286 (Best: 0.0002089 @iter19609) ([92m↓2.21%[0m) [0.09% of initial]
[Iter 19620/20000] Loss: 0.0002456 (Best: 0.0002043 @iter19612) ([91m↑7.45%[0m) [0.10% of initial]
[Iter 19630/20000] Loss: 0.0002475 (Best: 0.0002043 @iter19612) ([91m↑0.77%[0m) [0.10% of initial]
[Iter 19640/20000] Loss: 0.0002404 (Best: 0.0002043 @iter19612) ([92m↓2.85%[0m) [0.10% of initial]
[Iter 19650/20000] Loss: 0.0002445 (Best: 0.0002043 @iter19612) ([91m↑1.72%[0m) [0.10% of initial]
[Iter 19660/20000] Loss: 0.0002174 (Best: 0.0002043 @iter19612) ([92m↓11.11%[0m) [0.09% of initial]
[Iter 19670/20000] Loss: 0.0002157 (Best: 0.0002022 @iter19663) ([92m↓0.78%[0m) [0.09% of initial]
[Iter 19680/20000] Loss: 0.0002179 (Best: 0.0002022 @iter19663) ([91m↑1.03%[0m) [0.09% of initial]
[Iter 19690/20000] Loss: 0.0002147 (Best: 0.0002022 @iter19663) ([92m↓1.45%[0m) [0.09% of initial]
Iter:19699, L1 loss=0.0002799, Total loss=0.0002303, Time:29
[Iter 19700/20000] Loss: 0.0002305 (Best: 0.0002022 @iter19663) ([91m↑7.35%[0m) [0.09% of initial]
[Iter 19710/20000] Loss: 0.0002515 (Best: 0.0002022 @iter19663) ([91m↑9.11%[0m) [0.10% of initial]
[Iter 19720/20000] Loss: 0.0002422 (Best: 0.0002022 @iter19663) ([92m↓3.73%[0m) [0.10% of initial]
[Iter 19730/20000] Loss: 0.0002401 (Best: 0.0002022 @iter19663) ([92m↓0.85%[0m) [0.10% of initial]
[Iter 19740/20000] Loss: 0.0002285 (Best: 0.0002022 @iter19663) ([92m↓4.83%[0m) [0.09% of initial]
[Iter 19750/20000] Loss: 0.0002303 (Best: 0.0002022 @iter19663) ([91m↑0.78%[0m) [0.09% of initial]
[Iter 19760/20000] Loss: 0.0002340 (Best: 0.0002022 @iter19663) ([91m↑1.61%[0m) [0.09% of initial]
[Iter 19770/20000] Loss: 0.0002307 (Best: 0.0002022 @iter19663) ([92m↓1.40%[0m) [0.09% of initial]
[Iter 19780/20000] Loss: 0.0002404 (Best: 0.0002022 @iter19663) ([91m↑4.21%[0m) [0.10% of initial]
[Iter 19790/20000] Loss: 0.0002249 (Best: 0.0002022 @iter19663) ([92m↓6.48%[0m) [0.09% of initial]
Iter:19799, L1 loss=0.0003032, Total loss=0.000239, Time:30
[Iter 19800/20000] Loss: 0.0002319 (Best: 0.0002022 @iter19663) ([91m↑3.12%[0m) [0.09% of initial]
[Iter 19810/20000] Loss: 0.0002403 (Best: 0.0002022 @iter19663) ([91m↑3.61%[0m) [0.10% of initial]
[Iter 19820/20000] Loss: 0.0002340 (Best: 0.0002022 @iter19663) ([92m↓2.60%[0m) [0.09% of initial]
[Iter 19830/20000] Loss: 0.0002958 (Best: 0.0002022 @iter19663) ([91m↑26.42%[0m) [0.12% of initial]
[Iter 19840/20000] Loss: 0.0002992 (Best: 0.0002022 @iter19663) ([91m↑1.15%[0m) [0.12% of initial]
[Iter 19850/20000] Loss: 0.0002752 (Best: 0.0002022 @iter19663) ([92m↓8.04%[0m) [0.11% of initial]
[Iter 19860/20000] Loss: 0.0003217 (Best: 0.0002022 @iter19663) ([91m↑16.90%[0m) [0.13% of initial]
[Iter 19870/20000] Loss: 0.0003044 (Best: 0.0002022 @iter19663) ([92m↓5.36%[0m) [0.12% of initial]
[Iter 19880/20000] Loss: 0.0003080 (Best: 0.0002022 @iter19663) ([91m↑1.18%[0m) [0.12% of initial]
[Iter 19890/20000] Loss: 0.0003415 (Best: 0.0002022 @iter19663) ([91m↑10.86%[0m) [0.14% of initial]
Iter:19899, L1 loss=0.0003567, Total loss=0.0002715, Time:28
[Iter 19900/20000] Loss: 0.0002678 (Best: 0.0002022 @iter19663) ([92m↓21.57%[0m) [0.11% of initial]
[Iter 19910/20000] Loss: 0.0002899 (Best: 0.0002022 @iter19663) ([91m↑8.23%[0m) [0.12% of initial]
[Iter 19920/20000] Loss: 0.0002878 (Best: 0.0002022 @iter19663) ([92m↓0.71%[0m) [0.11% of initial]
[Iter 19930/20000] Loss: 0.0002680 (Best: 0.0002022 @iter19663) ([92m↓6.89%[0m) [0.11% of initial]
[Iter 19940/20000] Loss: 0.0002920 (Best: 0.0002022 @iter19663) ([91m↑8.96%[0m) [0.12% of initial]
[Iter 19950/20000] Loss: 0.0002967 (Best: 0.0002022 @iter19663) ([91m↑1.60%[0m) [0.12% of initial]
[Iter 19960/20000] Loss: 0.0002483 (Best: 0.0002022 @iter19663) ([92m↓16.32%[0m) [0.10% of initial]
[Iter 19970/20000] Loss: 0.0002403 (Best: 0.0002022 @iter19663) ([92m↓3.21%[0m) [0.10% of initial]
[Iter 19980/20000] Loss: 0.0002457 (Best: 0.0002022 @iter19663) ([91m↑2.27%[0m) [0.10% of initial]
[Iter 19990/20000] Loss: 0.0002247 (Best: 0.0002022 @iter19663) ([92m↓8.55%[0m) [0.09% of initial]
Iter:19999, L1 loss=0.0002544, Total loss=0.0002259, Time:29
[Iter 20000/20000] Loss: 0.0002216 (Best: 0.0002022 @iter19663) ([92m↓1.41%[0m) [0.09% of initial]
Testing Speed: 132.53904151577777 fps
Testing Time: 0.37724733352661133 s

[ITER 20000] Evaluating test: SSIM = 0.8741527354717255, PSNR = 43.0644686126709
Testing Speed: 157.90618176342142 fps
Testing Time: 0.01899862289428711 s

[ITER 20000] Evaluating train: SSIM = 0.9999992648760477, PSNR = 91.79794565836588
Iter:20000, total_points:186175

[ITER 20000] Saving Gaussians
Pruning 3 points (0.0%) from gaussian0 at iteration 20000
Pruning 2 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 132 fps
Total time: 21.61 minutes
Test SSIM: 0.8742
Test PSNR: 43.064
Gaussian0 final points count: 186172
Gaussian1 final points count: 188059
Final loss: 0.0002216 (0.09% of initial)
Save path: 2024_11_26_15_45_41
Initial loss: 0.2517052
Best loss: 0.0002022 @iteration 19663 (0.08% of initial)
Train SSIM: 1.0000
Train PSNR: 91.798
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693033 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374905 (Best: 0.1327877 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123924 (Best: 0.1098377 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993436 (Best: 0.0965428 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936736 (Best: 0.0908505 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884480 (Best: 0.0869340 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851806 (Best: 0.0830981 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824111 (Best: 0.0801612 @iter88) ([92m↓3.25%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:51
[Iter 100/20000] Loss: 0.0786591 (Best: 0.0766077 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753142 (Best: 0.0731299 @iter106) ([92m↓4.25%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714287 (Best: 0.0685299 @iter118) ([92m↓5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0666855 (Best: 0.0641787 @iter130) ([92m↓6.64%[0m) [26.49% of initial]
[Iter 140/20000] Loss: 0.0635075 (Best: 0.0612466 @iter140) ([92m↓4.77%[0m) [25.23% of initial]
[Iter 150/20000] Loss: 0.0612530 (Best: 0.0583428 @iter148) ([92m↓3.55%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590201 (Best: 0.0559131 @iter157) ([92m↓3.65%[0m) [23.45% of initial]
[Iter 170/20000] Loss: 0.0563612 (Best: 0.0534781 @iter167) ([92m↓4.51%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523450 (Best: 0.0500586 @iter179) ([92m↓7.13%[0m) [20.80% of initial]
[Iter 190/20000] Loss: 0.0495444 (Best: 0.0478402 @iter188) ([92m↓5.35%[0m) [19.68% of initial]
Iter:199, L1 loss=0.0344, Total loss=0.04979, Time:48
[Iter 200/20000] Loss: 0.0477810 (Best: 0.0457952 @iter198) ([92m↓3.56%[0m) [18.98% of initial]
[Iter 210/20000] Loss: 0.0451777 (Best: 0.0429899 @iter209) ([92m↓5.45%[0m) [17.95% of initial]
[Iter 220/20000] Loss: 0.0441319 (Best: 0.0412720 @iter219) ([92m↓2.31%[0m) [17.53% of initial]
[Iter 230/20000] Loss: 0.0424990 (Best: 0.0398807 @iter227) ([92m↓3.70%[0m) [16.88% of initial]
[Iter 240/20000] Loss: 0.0403148 (Best: 0.0378484 @iter238) ([92m↓5.14%[0m) [16.02% of initial]
[Iter 250/20000] Loss: 0.0380660 (Best: 0.0365153 @iter248) ([92m↓5.58%[0m) [15.12% of initial]
[Iter 260/20000] Loss: 0.0358088 (Best: 0.0341613 @iter260) ([92m↓5.93%[0m) [14.23% of initial]
[Iter 270/20000] Loss: 0.0350726 (Best: 0.0329004 @iter269) ([92m↓2.06%[0m) [13.93% of initial]
[Iter 280/20000] Loss: 0.0346870 (Best: 0.0318554 @iter277) ([92m↓1.10%[0m) [13.78% of initial]
[Iter 290/20000] Loss: 0.0330431 (Best: 0.0303906 @iter287) ([92m↓4.74%[0m) [13.13% of initial]
Iter:299, L1 loss=0.02218, Total loss=0.03328, Time:50
[Iter 300/20000] Loss: 0.0307614 (Best: 0.0290127 @iter300) ([92m↓6.91%[0m) [12.22% of initial]
[Iter 310/20000] Loss: 0.0293803 (Best: 0.0274745 @iter310) ([92m↓4.49%[0m) [11.67% of initial]
[Iter 320/20000] Loss: 0.0278716 (Best: 0.0265104 @iter320) ([92m↓5.14%[0m) [11.07% of initial]
[Iter 330/20000] Loss: 0.0274925 (Best: 0.0256483 @iter330) ([92m↓1.36%[0m) [10.92% of initial]
[Iter 340/20000] Loss: 0.0253909 (Best: 0.0243381 @iter340) ([92m↓7.64%[0m) [10.09% of initial]
[Iter 350/20000] Loss: 0.0261167 (Best: 0.0236116 @iter349) ([91m↑2.86%[0m) [10.38% of initial]
[Iter 360/20000] Loss: 0.0244489 (Best: 0.0225503 @iter358) ([92m↓6.39%[0m) [9.71% of initial]
[Iter 370/20000] Loss: 0.0240384 (Best: 0.0218556 @iter368) ([92m↓1.68%[0m) [9.55% of initial]
[Iter 380/20000] Loss: 0.0220277 (Best: 0.0209125 @iter379) ([92m↓8.36%[0m) [8.75% of initial]
[Iter 390/20000] Loss: 0.0215100 (Best: 0.0201228 @iter385) ([92m↓2.35%[0m) [8.55% of initial]
Iter:399, L1 loss=0.01376, Total loss=0.02119, Time:55
[Iter 400/20000] Loss: 0.0204983 (Best: 0.0189989 @iter400) ([92m↓4.70%[0m) [8.14% of initial]
[Iter 410/20000] Loss: 0.0195559 (Best: 0.0184732 @iter410) ([92m↓4.60%[0m) [7.77% of initial]
[Iter 420/20000] Loss: 0.0200317 (Best: 0.0177548 @iter418) ([91m↑2.43%[0m) [7.96% of initial]
[Iter 430/20000] Loss: 0.0180913 (Best: 0.0172740 @iter425) ([92m↓9.69%[0m) [7.19% of initial]
[Iter 440/20000] Loss: 0.0188884 (Best: 0.0167976 @iter434) ([91m↑4.41%[0m) [7.50% of initial]
[Iter 450/20000] Loss: 0.0179901 (Best: 0.0160748 @iter449) ([92m↓4.76%[0m) [7.15% of initial]
[Iter 460/20000] Loss: 0.0173342 (Best: 0.0151875 @iter458) ([92m↓3.65%[0m) [6.89% of initial]
[Iter 470/20000] Loss: 0.0157475 (Best: 0.0145399 @iter470) ([92m↓9.15%[0m) [6.26% of initial]
[Iter 480/20000] Loss: 0.0156621 (Best: 0.0141212 @iter479) ([92m↓0.54%[0m) [6.22% of initial]
[Iter 490/20000] Loss: 0.0147540 (Best: 0.0135554 @iter490) ([92m↓5.80%[0m) [5.86% of initial]
Iter:499, L1 loss=0.008647, Total loss=0.01572, Time:54
[Iter 500/20000] Loss: 0.0148023 (Best: 0.0133486 @iter493) ([91m↑0.33%[0m) [5.88% of initial]
[Iter 510/20000] Loss: 0.0143847 (Best: 0.0128047 @iter508) ([92m↓2.82%[0m) [5.71% of initial]
[Iter 520/20000] Loss: 0.0133215 (Best: 0.0122493 @iter514) ([92m↓7.39%[0m) [5.29% of initial]
[Iter 530/20000] Loss: 0.0126884 (Best: 0.0111106 @iter529) ([92m↓4.75%[0m) [5.04% of initial]
[Iter 540/20000] Loss: 0.0124845 (Best: 0.0111106 @iter529) ([92m↓1.61%[0m) [4.96% of initial]
[Iter 550/20000] Loss: 0.0121281 (Best: 0.0109048 @iter548) ([92m↓2.85%[0m) [4.82% of initial]
[Iter 560/20000] Loss: 0.0121552 (Best: 0.0104938 @iter556) ([91m↑0.22%[0m) [4.83% of initial]
[Iter 570/20000] Loss: 0.0116734 (Best: 0.0103940 @iter569) ([92m↓3.96%[0m) [4.64% of initial]
[Iter 580/20000] Loss: 0.0112191 (Best: 0.0100765 @iter578) ([92m↓3.89%[0m) [4.46% of initial]
[Iter 590/20000] Loss: 0.0112403 (Best: 0.0098421 @iter583) ([91m↑0.19%[0m) [4.47% of initial]
Iter:599, L1 loss=0.006775, Total loss=0.01197, Time:45
[Iter 600/20000] Loss: 0.0110190 (Best: 0.0098333 @iter598) ([92m↓1.97%[0m) [4.38% of initial]
[Iter 610/20000] Loss: 0.0222372 (Best: 0.0098333 @iter598) ([91m↑101.81%[0m) [8.83% of initial]
[Iter 620/20000] Loss: 0.0144610 (Best: 0.0098333 @iter598) ([92m↓34.97%[0m) [5.75% of initial]
[Iter 630/20000] Loss: 0.0120576 (Best: 0.0098333 @iter598) ([92m↓16.62%[0m) [4.79% of initial]
[Iter 640/20000] Loss: 0.0102814 (Best: 0.0093505 @iter640) ([92m↓14.73%[0m) [4.08% of initial]
[Iter 650/20000] Loss: 0.0105595 (Best: 0.0093505 @iter640) ([91m↑2.71%[0m) [4.20% of initial]
[Iter 660/20000] Loss: 0.0100827 (Best: 0.0089463 @iter655) ([92m↓4.52%[0m) [4.01% of initial]
[Iter 670/20000] Loss: 0.0096550 (Best: 0.0085745 @iter667) ([92m↓4.24%[0m) [3.84% of initial]
[Iter 680/20000] Loss: 0.0088858 (Best: 0.0082461 @iter680) ([92m↓7.97%[0m) [3.53% of initial]
[Iter 690/20000] Loss: 0.0090248 (Best: 0.0078409 @iter685) ([91m↑1.56%[0m) [3.59% of initial]
Iter:699, L1 loss=0.005843, Total loss=0.009516, Time:47
[Iter 700/20000] Loss: 0.0088444 (Best: 0.0078023 @iter695) ([92m↓2.00%[0m) [3.51% of initial]
[Iter 710/20000] Loss: 0.0083543 (Best: 0.0074773 @iter703) ([92m↓5.54%[0m) [3.32% of initial]
[Iter 720/20000] Loss: 0.0083102 (Best: 0.0074773 @iter703) ([92m↓0.53%[0m) [3.30% of initial]
[Iter 730/20000] Loss: 0.0084117 (Best: 0.0072043 @iter727) ([91m↑1.22%[0m) [3.34% of initial]
[Iter 740/20000] Loss: 0.0084937 (Best: 0.0072043 @iter727) ([91m↑0.98%[0m) [3.37% of initial]
[Iter 750/20000] Loss: 0.0080323 (Best: 0.0069592 @iter748) ([92m↓5.43%[0m) [3.19% of initial]
[Iter 760/20000] Loss: 0.0075625 (Best: 0.0069592 @iter748) ([92m↓5.85%[0m) [3.00% of initial]
[Iter 770/20000] Loss: 0.0075788 (Best: 0.0069291 @iter769) ([91m↑0.21%[0m) [3.01% of initial]
[Iter 780/20000] Loss: 0.0079272 (Best: 0.0067886 @iter775) ([91m↑4.60%[0m) [3.15% of initial]
[Iter 790/20000] Loss: 0.0075972 (Best: 0.0066480 @iter787) ([92m↓4.16%[0m) [3.02% of initial]
Iter:799, L1 loss=0.005055, Total loss=0.008188, Time:49
[Iter 800/20000] Loss: 0.0074670 (Best: 0.0066480 @iter787) ([92m↓1.71%[0m) [2.97% of initial]
[Iter 810/20000] Loss: 0.0158117 (Best: 0.0066480 @iter787) ([91m↑111.75%[0m) [6.28% of initial]
[Iter 820/20000] Loss: 0.0109172 (Best: 0.0066480 @iter787) ([92m↓30.95%[0m) [4.34% of initial]
[Iter 830/20000] Loss: 0.0088059 (Best: 0.0066480 @iter787) ([92m↓19.34%[0m) [3.50% of initial]
[Iter 840/20000] Loss: 0.0079658 (Best: 0.0066480 @iter787) ([92m↓9.54%[0m) [3.16% of initial]
[Iter 850/20000] Loss: 0.0074281 (Best: 0.0066226 @iter844) ([92m↓6.75%[0m) [2.95% of initial]
[Iter 860/20000] Loss: 0.0070032 (Best: 0.0062986 @iter856) ([92m↓5.72%[0m) [2.78% of initial]
[Iter 870/20000] Loss: 0.0067399 (Best: 0.0061820 @iter862) ([92m↓3.76%[0m) [2.68% of initial]
[Iter 880/20000] Loss: 0.0066618 (Best: 0.0060678 @iter872) ([92m↓1.16%[0m) [2.65% of initial]
[Iter 890/20000] Loss: 0.0063059 (Best: 0.0057172 @iter884) ([92m↓5.34%[0m) [2.51% of initial]
Iter:899, L1 loss=0.003661, Total loss=0.005656, Time:49
[Iter 900/20000] Loss: 0.0064686 (Best: 0.0056564 @iter899) ([91m↑2.58%[0m) [2.57% of initial]
[Iter 910/20000] Loss: 0.0065325 (Best: 0.0054795 @iter907) ([91m↑0.99%[0m) [2.60% of initial]
[Iter 920/20000] Loss: 0.0058797 (Best: 0.0053367 @iter919) ([92m↓9.99%[0m) [2.34% of initial]
[Iter 930/20000] Loss: 0.0061767 (Best: 0.0051519 @iter928) ([91m↑5.05%[0m) [2.45% of initial]
[Iter 940/20000] Loss: 0.0062029 (Best: 0.0051180 @iter938) ([91m↑0.42%[0m) [2.46% of initial]
[Iter 950/20000] Loss: 0.0056985 (Best: 0.0051180 @iter938) ([92m↓8.13%[0m) [2.26% of initial]
[Iter 960/20000] Loss: 0.0058164 (Best: 0.0051180 @iter938) ([91m↑2.07%[0m) [2.31% of initial]
[Iter 970/20000] Loss: 0.0058558 (Best: 0.0050059 @iter964) ([91m↑0.68%[0m) [2.33% of initial]
[Iter 980/20000] Loss: 0.0060477 (Best: 0.0050059 @iter964) ([91m↑3.28%[0m) [2.40% of initial]
[Iter 990/20000] Loss: 0.0060927 (Best: 0.0050059 @iter964) ([91m↑0.74%[0m) [2.42% of initial]
Iter:999, L1 loss=0.004414, Total loss=0.006661, Time:42
[Iter 1000/20000] Loss: 0.0062438 (Best: 0.0050059 @iter964) ([91m↑2.48%[0m) [2.48% of initial]
Pruning 1006 points (7.4%) from gaussian0 at iteration 1000
Pruning 1034 points (7.5%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0141765 (Best: 0.0050059 @iter964) ([91m↑127.05%[0m) [5.63% of initial]
[Iter 1020/20000] Loss: 0.0097817 (Best: 0.0050059 @iter964) ([92m↓31.00%[0m) [3.89% of initial]
[Iter 1030/20000] Loss: 0.0080954 (Best: 0.0050059 @iter964) ([92m↓17.24%[0m) [3.22% of initial]
[Iter 1040/20000] Loss: 0.0072288 (Best: 0.0050059 @iter964) ([92m↓10.70%[0m) [2.87% of initial]
[Iter 1050/20000] Loss: 0.0068216 (Best: 0.0050059 @iter964) ([92m↓5.63%[0m) [2.71% of initial]
[Iter 1060/20000] Loss: 0.0065071 (Best: 0.0050059 @iter964) ([92m↓4.61%[0m) [2.59% of initial]
[Iter 1070/20000] Loss: 0.0062936 (Best: 0.0050059 @iter964) ([92m↓3.28%[0m) [2.50% of initial]
[Iter 1080/20000] Loss: 0.0062150 (Best: 0.0050059 @iter964) ([92m↓1.25%[0m) [2.47% of initial]
[Iter 1090/20000] Loss: 0.0058549 (Best: 0.0050059 @iter964) ([92m↓5.79%[0m) [2.33% of initial]
Iter:1099, L1 loss=0.003842, Total loss=0.005814, Time:39
[Iter 1100/20000] Loss: 0.0057224 (Best: 0.0050059 @iter964) ([92m↓2.26%[0m) [2.27% of initial]
[Iter 1110/20000] Loss: 0.0056551 (Best: 0.0050059 @iter964) ([92m↓1.18%[0m) [2.25% of initial]
[Iter 1120/20000] Loss: 0.0056969 (Best: 0.0050010 @iter1117) ([91m↑0.74%[0m) [2.26% of initial]
[Iter 1130/20000] Loss: 0.0057744 (Best: 0.0050010 @iter1117) ([91m↑1.36%[0m) [2.29% of initial]
[Iter 1140/20000] Loss: 0.0054548 (Best: 0.0048895 @iter1135) ([92m↓5.53%[0m) [2.17% of initial]
[Iter 1150/20000] Loss: 0.0053859 (Best: 0.0048287 @iter1145) ([92m↓1.26%[0m) [2.14% of initial]
[Iter 1160/20000] Loss: 0.0056318 (Best: 0.0048287 @iter1145) ([91m↑4.57%[0m) [2.24% of initial]
[Iter 1170/20000] Loss: 0.0053004 (Best: 0.0048287 @iter1145) ([92m↓5.88%[0m) [2.11% of initial]
[Iter 1180/20000] Loss: 0.0048874 (Best: 0.0045476 @iter1180) ([92m↓7.79%[0m) [1.94% of initial]
[Iter 1190/20000] Loss: 0.0051778 (Best: 0.0044619 @iter1186) ([91m↑5.94%[0m) [2.06% of initial]
Iter:1199, L1 loss=0.003815, Total loss=0.005535, Time:44
[Iter 1200/20000] Loss: 0.0051562 (Best: 0.0044411 @iter1195) ([92m↓0.42%[0m) [2.05% of initial]
[Iter 1210/20000] Loss: 0.0119134 (Best: 0.0044411 @iter1195) ([91m↑131.05%[0m) [4.73% of initial]
[Iter 1220/20000] Loss: 0.0079585 (Best: 0.0044411 @iter1195) ([92m↓33.20%[0m) [3.16% of initial]
[Iter 1230/20000] Loss: 0.0065518 (Best: 0.0044411 @iter1195) ([92m↓17.68%[0m) [2.60% of initial]
[Iter 1240/20000] Loss: 0.0059980 (Best: 0.0044411 @iter1195) ([92m↓8.45%[0m) [2.38% of initial]
[Iter 1250/20000] Loss: 0.0052892 (Best: 0.0044411 @iter1195) ([92m↓11.82%[0m) [2.10% of initial]
[Iter 1260/20000] Loss: 0.0053490 (Best: 0.0044411 @iter1195) ([91m↑1.13%[0m) [2.13% of initial]
[Iter 1270/20000] Loss: 0.0048189 (Best: 0.0044411 @iter1195) ([92m↓9.91%[0m) [1.91% of initial]
[Iter 1280/20000] Loss: 0.0049890 (Best: 0.0041264 @iter1273) ([91m↑3.53%[0m) [1.98% of initial]
[Iter 1290/20000] Loss: 0.0048049 (Best: 0.0038978 @iter1288) ([92m↓3.69%[0m) [1.91% of initial]
Iter:1299, L1 loss=0.003009, Total loss=0.004093, Time:40
[Iter 1300/20000] Loss: 0.0044483 (Best: 0.0038978 @iter1288) ([92m↓7.42%[0m) [1.77% of initial]
[Iter 1310/20000] Loss: 0.0045357 (Best: 0.0038978 @iter1288) ([91m↑1.97%[0m) [1.80% of initial]
[Iter 1320/20000] Loss: 0.0043994 (Best: 0.0036663 @iter1319) ([92m↓3.01%[0m) [1.75% of initial]
[Iter 1330/20000] Loss: 0.0043958 (Best: 0.0035841 @iter1321) ([92m↓0.08%[0m) [1.75% of initial]
[Iter 1340/20000] Loss: 0.0041287 (Best: 0.0035841 @iter1321) ([92m↓6.08%[0m) [1.64% of initial]
[Iter 1350/20000] Loss: 0.0041423 (Best: 0.0035841 @iter1321) ([91m↑0.33%[0m) [1.65% of initial]
[Iter 1360/20000] Loss: 0.0041972 (Best: 0.0035841 @iter1321) ([91m↑1.33%[0m) [1.67% of initial]
[Iter 1370/20000] Loss: 0.0040035 (Best: 0.0035670 @iter1363) ([92m↓4.62%[0m) [1.59% of initial]
[Iter 1380/20000] Loss: 0.0042480 (Best: 0.0034178 @iter1375) ([91m↑6.11%[0m) [1.69% of initial]
[Iter 1390/20000] Loss: 0.0040582 (Best: 0.0034178 @iter1375) ([92m↓4.47%[0m) [1.61% of initial]
Iter:1399, L1 loss=0.002712, Total loss=0.003405, Time:50
[Iter 1400/20000] Loss: 0.0038766 (Best: 0.0033866 @iter1394) ([92m↓4.47%[0m) [1.54% of initial]
[Iter 1410/20000] Loss: 0.0097410 (Best: 0.0033866 @iter1394) ([91m↑151.28%[0m) [3.87% of initial]
[Iter 1420/20000] Loss: 0.0067123 (Best: 0.0033866 @iter1394) ([92m↓31.09%[0m) [2.67% of initial]
[Iter 1430/20000] Loss: 0.0053558 (Best: 0.0033866 @iter1394) ([92m↓20.21%[0m) [2.13% of initial]
[Iter 1440/20000] Loss: 0.0048340 (Best: 0.0033866 @iter1394) ([92m↓9.74%[0m) [1.92% of initial]
[Iter 1450/20000] Loss: 0.0039639 (Best: 0.0033866 @iter1394) ([92m↓18.00%[0m) [1.57% of initial]
[Iter 1460/20000] Loss: 0.0039591 (Best: 0.0033866 @iter1394) ([92m↓0.12%[0m) [1.57% of initial]
[Iter 1470/20000] Loss: 0.0038042 (Best: 0.0033866 @iter1394) ([92m↓3.91%[0m) [1.51% of initial]
[Iter 1480/20000] Loss: 0.0036332 (Best: 0.0031541 @iter1480) ([92m↓4.49%[0m) [1.44% of initial]
[Iter 1490/20000] Loss: 0.0036121 (Best: 0.0031541 @iter1480) ([92m↓0.58%[0m) [1.44% of initial]
Iter:1499, L1 loss=0.002729, Total loss=0.003749, Time:55
[Iter 1500/20000] Loss: 0.0035459 (Best: 0.0031541 @iter1480) ([92m↓1.83%[0m) [1.41% of initial]
Pruning 681 points (2.8%) from gaussian0 at iteration 1500
Pruning 728 points (3.0%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0049254 (Best: 0.0031541 @iter1480) ([91m↑38.90%[0m) [1.96% of initial]
[Iter 1520/20000] Loss: 0.0041775 (Best: 0.0031541 @iter1480) ([92m↓15.18%[0m) [1.66% of initial]
[Iter 1530/20000] Loss: 0.0039253 (Best: 0.0031541 @iter1480) ([92m↓6.04%[0m) [1.56% of initial]
[Iter 1540/20000] Loss: 0.0036466 (Best: 0.0031541 @iter1480) ([92m↓7.10%[0m) [1.45% of initial]
[Iter 1550/20000] Loss: 0.0033332 (Best: 0.0030863 @iter1543) ([92m↓8.59%[0m) [1.32% of initial]
[Iter 1560/20000] Loss: 0.0035717 (Best: 0.0029531 @iter1558) ([91m↑7.16%[0m) [1.42% of initial]
[Iter 1570/20000] Loss: 0.0031800 (Best: 0.0028880 @iter1569) ([92m↓10.97%[0m) [1.26% of initial]
[Iter 1580/20000] Loss: 0.0032235 (Best: 0.0027440 @iter1573) ([91m↑1.37%[0m) [1.28% of initial]
[Iter 1590/20000] Loss: 0.0031378 (Best: 0.0027440 @iter1573) ([92m↓2.66%[0m) [1.25% of initial]
Iter:1599, L1 loss=0.002898, Total loss=0.003735, Time:55
[Iter 1600/20000] Loss: 0.0034166 (Best: 0.0027340 @iter1591) ([91m↑8.88%[0m) [1.36% of initial]
[Iter 1610/20000] Loss: 0.0094384 (Best: 0.0027340 @iter1591) ([91m↑176.25%[0m) [3.75% of initial]
[Iter 1620/20000] Loss: 0.0063257 (Best: 0.0027340 @iter1591) ([92m↓32.98%[0m) [2.51% of initial]
[Iter 1630/20000] Loss: 0.0047781 (Best: 0.0027340 @iter1591) ([92m↓24.47%[0m) [1.90% of initial]
[Iter 1640/20000] Loss: 0.0041742 (Best: 0.0027340 @iter1591) ([92m↓12.64%[0m) [1.66% of initial]
[Iter 1650/20000] Loss: 0.0037007 (Best: 0.0027340 @iter1591) ([92m↓11.34%[0m) [1.47% of initial]
[Iter 1660/20000] Loss: 0.0032636 (Best: 0.0027340 @iter1591) ([92m↓11.81%[0m) [1.30% of initial]
[Iter 1670/20000] Loss: 0.0030979 (Best: 0.0026789 @iter1669) ([92m↓5.08%[0m) [1.23% of initial]
[Iter 1680/20000] Loss: 0.0031381 (Best: 0.0026789 @iter1669) ([91m↑1.30%[0m) [1.25% of initial]
[Iter 1690/20000] Loss: 0.0034391 (Best: 0.0026666 @iter1684) ([91m↑9.59%[0m) [1.37% of initial]
Iter:1699, L1 loss=0.002607, Total loss=0.003317, Time:51
[Iter 1700/20000] Loss: 0.0030126 (Best: 0.0026666 @iter1684) ([92m↓12.40%[0m) [1.20% of initial]
[Iter 1710/20000] Loss: 0.0033480 (Best: 0.0026666 @iter1684) ([91m↑11.13%[0m) [1.33% of initial]
[Iter 1720/20000] Loss: 0.0028767 (Best: 0.0026666 @iter1684) ([92m↓14.08%[0m) [1.14% of initial]
[Iter 1730/20000] Loss: 0.0029130 (Best: 0.0026339 @iter1730) ([91m↑1.26%[0m) [1.16% of initial]
[Iter 1740/20000] Loss: 0.0028450 (Best: 0.0025689 @iter1732) ([92m↓2.33%[0m) [1.13% of initial]
[Iter 1750/20000] Loss: 0.0025909 (Best: 0.0023588 @iter1750) ([92m↓8.93%[0m) [1.03% of initial]
[Iter 1760/20000] Loss: 0.0028347 (Best: 0.0023588 @iter1750) ([91m↑9.41%[0m) [1.13% of initial]
[Iter 1770/20000] Loss: 0.0026861 (Best: 0.0023588 @iter1750) ([92m↓5.24%[0m) [1.07% of initial]
[Iter 1780/20000] Loss: 0.0027646 (Best: 0.0023588 @iter1750) ([91m↑2.92%[0m) [1.10% of initial]
[Iter 1790/20000] Loss: 0.0024601 (Best: 0.0021450 @iter1789) ([92m↓11.02%[0m) [0.98% of initial]
Iter:1799, L1 loss=0.001871, Total loss=0.00234, Time:43
[Iter 1800/20000] Loss: 0.0025459 (Best: 0.0021450 @iter1789) ([91m↑3.49%[0m) [1.01% of initial]
[Iter 1810/20000] Loss: 0.0083872 (Best: 0.0021450 @iter1789) ([91m↑229.44%[0m) [3.33% of initial]
[Iter 1820/20000] Loss: 0.0049775 (Best: 0.0021450 @iter1789) ([92m↓40.65%[0m) [1.98% of initial]
[Iter 1830/20000] Loss: 0.0043665 (Best: 0.0021450 @iter1789) ([92m↓12.27%[0m) [1.73% of initial]
[Iter 1840/20000] Loss: 0.0030786 (Best: 0.0021450 @iter1789) ([92m↓29.50%[0m) [1.22% of initial]
[Iter 1850/20000] Loss: 0.0029116 (Best: 0.0021450 @iter1789) ([92m↓5.43%[0m) [1.16% of initial]
[Iter 1860/20000] Loss: 0.0026560 (Best: 0.0021450 @iter1789) ([92m↓8.78%[0m) [1.06% of initial]
[Iter 1870/20000] Loss: 0.0024824 (Best: 0.0020958 @iter1867) ([92m↓6.53%[0m) [0.99% of initial]
[Iter 1880/20000] Loss: 0.0023441 (Best: 0.0020818 @iter1880) ([92m↓5.57%[0m) [0.93% of initial]
[Iter 1890/20000] Loss: 0.0021463 (Best: 0.0019989 @iter1890) ([92m↓8.44%[0m) [0.85% of initial]
Iter:1899, L1 loss=0.001829, Total loss=0.002191, Time:51
[Iter 1900/20000] Loss: 0.0022647 (Best: 0.0018897 @iter1891) ([91m↑5.52%[0m) [0.90% of initial]
[Iter 1910/20000] Loss: 0.0022844 (Best: 0.0018836 @iter1903) ([91m↑0.87%[0m) [0.91% of initial]
[Iter 1920/20000] Loss: 0.0023561 (Best: 0.0018836 @iter1903) ([91m↑3.14%[0m) [0.94% of initial]
[Iter 1930/20000] Loss: 0.0019862 (Best: 0.0018127 @iter1930) ([92m↓15.70%[0m) [0.79% of initial]
[Iter 1940/20000] Loss: 0.0021358 (Best: 0.0017685 @iter1939) ([91m↑7.53%[0m) [0.85% of initial]
[Iter 1950/20000] Loss: 0.0022709 (Best: 0.0017685 @iter1939) ([91m↑6.33%[0m) [0.90% of initial]
[Iter 1960/20000] Loss: 0.0020604 (Best: 0.0017685 @iter1939) ([92m↓9.27%[0m) [0.82% of initial]
[Iter 1970/20000] Loss: 0.0019229 (Best: 0.0017353 @iter1963) ([92m↓6.67%[0m) [0.76% of initial]
[Iter 1980/20000] Loss: 0.0022540 (Best: 0.0017353 @iter1963) ([91m↑17.22%[0m) [0.90% of initial]
[Iter 1990/20000] Loss: 0.0020284 (Best: 0.0017353 @iter1963) ([92m↓10.01%[0m) [0.81% of initial]
Iter:1999, L1 loss=0.001634, Total loss=0.001899, Time:54
[Iter 2000/20000] Loss: 0.0021198 (Best: 0.0016497 @iter1996) ([91m↑4.51%[0m) [0.84% of initial]
Testing Speed: 97.24600900608057 fps
Testing Time: 0.5141599178314209 s

[ITER 2000] Evaluating test: SSIM = 0.8614740228652954, PSNR = 17.350877151489257
Testing Speed: 103.07019110262858 fps
Testing Time: 0.02910637855529785 s

[ITER 2000] Evaluating train: SSIM = 0.9999538461367289, PSNR = 48.808293660481766
Iter:2000, total_points:43252
Pruning 664 points (1.2%) from gaussian0 at iteration 2000
Pruning 667 points (1.2%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.0078311 (Best: 0.0016497 @iter1996) ([91m↑269.42%[0m) [3.11% of initial]
[Iter 2020/20000] Loss: 0.0051419 (Best: 0.0016497 @iter1996) ([92m↓34.34%[0m) [2.04% of initial]
[Iter 2030/20000] Loss: 0.0037384 (Best: 0.0016497 @iter1996) ([92m↓27.30%[0m) [1.49% of initial]
[Iter 2040/20000] Loss: 0.0031660 (Best: 0.0016497 @iter1996) ([92m↓15.31%[0m) [1.26% of initial]
[Iter 2050/20000] Loss: 0.0027415 (Best: 0.0016497 @iter1996) ([92m↓13.41%[0m) [1.09% of initial]
[Iter 2060/20000] Loss: 0.0023561 (Best: 0.0016497 @iter1996) ([92m↓14.06%[0m) [0.94% of initial]
[Iter 2070/20000] Loss: 0.0025047 (Best: 0.0016497 @iter1996) ([91m↑6.31%[0m) [1.00% of initial]
[Iter 2080/20000] Loss: 0.0023904 (Best: 0.0016497 @iter1996) ([92m↓4.57%[0m) [0.95% of initial]
[Iter 2090/20000] Loss: 0.0023352 (Best: 0.0016497 @iter1996) ([92m↓2.31%[0m) [0.93% of initial]
Iter:2099, L1 loss=0.001944, Total loss=0.00218, Time:50
[Iter 2100/20000] Loss: 0.0021918 (Best: 0.0016497 @iter1996) ([92m↓6.14%[0m) [0.87% of initial]
[Iter 2110/20000] Loss: 0.0020995 (Best: 0.0016497 @iter1996) ([92m↓4.21%[0m) [0.83% of initial]
[Iter 2120/20000] Loss: 0.0019051 (Best: 0.0016497 @iter1996) ([92m↓9.26%[0m) [0.76% of initial]
[Iter 2130/20000] Loss: 0.0020356 (Best: 0.0016497 @iter1996) ([91m↑6.85%[0m) [0.81% of initial]
[Iter 2140/20000] Loss: 0.0021434 (Best: 0.0016497 @iter1996) ([91m↑5.30%[0m) [0.85% of initial]
[Iter 2150/20000] Loss: 0.0021625 (Best: 0.0016497 @iter1996) ([91m↑0.89%[0m) [0.86% of initial]
[Iter 2160/20000] Loss: 0.0019807 (Best: 0.0016497 @iter1996) ([92m↓8.40%[0m) [0.79% of initial]
[Iter 2170/20000] Loss: 0.0020591 (Best: 0.0016497 @iter1996) ([91m↑3.96%[0m) [0.82% of initial]
[Iter 2180/20000] Loss: 0.0017551 (Best: 0.0016328 @iter2180) ([92m↓14.77%[0m) [0.70% of initial]
[Iter 2190/20000] Loss: 0.0020102 (Best: 0.0016328 @iter2180) ([91m↑14.54%[0m) [0.80% of initial]
Iter:2199, L1 loss=0.001755, Total loss=0.001987, Time:54
[Iter 2200/20000] Loss: 0.0020068 (Best: 0.0016328 @iter2180) ([92m↓0.17%[0m) [0.80% of initial]
[Iter 2210/20000] Loss: 0.0086171 (Best: 0.0016328 @iter2180) ([91m↑329.39%[0m) [3.42% of initial]
[Iter 2220/20000] Loss: 0.0049845 (Best: 0.0016328 @iter2180) ([92m↓42.16%[0m) [1.98% of initial]
[Iter 2230/20000] Loss: 0.0032497 (Best: 0.0016328 @iter2180) ([92m↓34.80%[0m) [1.29% of initial]
[Iter 2240/20000] Loss: 0.0027181 (Best: 0.0016328 @iter2180) ([92m↓16.36%[0m) [1.08% of initial]
[Iter 2250/20000] Loss: 0.0025093 (Best: 0.0016328 @iter2180) ([92m↓7.68%[0m) [1.00% of initial]
[Iter 2260/20000] Loss: 0.0021103 (Best: 0.0016328 @iter2180) ([92m↓15.90%[0m) [0.84% of initial]
[Iter 2270/20000] Loss: 0.0021505 (Best: 0.0016328 @iter2180) ([91m↑1.90%[0m) [0.85% of initial]
[Iter 2280/20000] Loss: 0.0018124 (Best: 0.0016328 @iter2180) ([92m↓15.72%[0m) [0.72% of initial]
[Iter 2290/20000] Loss: 0.0017436 (Best: 0.0015345 @iter2287) ([92m↓3.80%[0m) [0.69% of initial]
Iter:2299, L1 loss=0.001577, Total loss=0.001666, Time:56
[Iter 2300/20000] Loss: 0.0019976 (Best: 0.0015345 @iter2287) ([91m↑14.57%[0m) [0.79% of initial]
[Iter 2310/20000] Loss: 0.0018548 (Best: 0.0015345 @iter2287) ([92m↓7.15%[0m) [0.74% of initial]
[Iter 2320/20000] Loss: 0.0016385 (Best: 0.0015151 @iter2320) ([92m↓11.66%[0m) [0.65% of initial]
[Iter 2330/20000] Loss: 0.0016038 (Best: 0.0014256 @iter2329) ([92m↓2.12%[0m) [0.64% of initial]
[Iter 2340/20000] Loss: 0.0016525 (Best: 0.0014067 @iter2338) ([91m↑3.03%[0m) [0.66% of initial]
[Iter 2350/20000] Loss: 0.0017706 (Best: 0.0014067 @iter2338) ([91m↑7.15%[0m) [0.70% of initial]
[Iter 2360/20000] Loss: 0.0015826 (Best: 0.0013865 @iter2359) ([92m↓10.61%[0m) [0.63% of initial]
[Iter 2370/20000] Loss: 0.0016931 (Best: 0.0013865 @iter2359) ([91m↑6.98%[0m) [0.67% of initial]
[Iter 2380/20000] Loss: 0.0018049 (Best: 0.0013865 @iter2359) ([91m↑6.60%[0m) [0.72% of initial]
[Iter 2390/20000] Loss: 0.0019281 (Best: 0.0013865 @iter2359) ([91m↑6.83%[0m) [0.77% of initial]
Iter:2399, L1 loss=0.001446, Total loss=0.001606, Time:50
[Iter 2400/20000] Loss: 0.0016404 (Best: 0.0013865 @iter2359) ([92m↓14.92%[0m) [0.65% of initial]
[Iter 2410/20000] Loss: 0.0065922 (Best: 0.0013865 @iter2359) ([91m↑301.86%[0m) [2.62% of initial]
[Iter 2420/20000] Loss: 0.0038275 (Best: 0.0013865 @iter2359) ([92m↓41.94%[0m) [1.52% of initial]
[Iter 2430/20000] Loss: 0.0028116 (Best: 0.0013865 @iter2359) ([92m↓26.54%[0m) [1.12% of initial]
[Iter 2440/20000] Loss: 0.0023828 (Best: 0.0013865 @iter2359) ([92m↓15.25%[0m) [0.95% of initial]
[Iter 2450/20000] Loss: 0.0022980 (Best: 0.0013865 @iter2359) ([92m↓3.56%[0m) [0.91% of initial]
[Iter 2460/20000] Loss: 0.0020040 (Best: 0.0013865 @iter2359) ([92m↓12.79%[0m) [0.80% of initial]
[Iter 2470/20000] Loss: 0.0019193 (Best: 0.0013865 @iter2359) ([92m↓4.22%[0m) [0.76% of initial]
[Iter 2480/20000] Loss: 0.0019017 (Best: 0.0013865 @iter2359) ([92m↓0.92%[0m) [0.76% of initial]
[Iter 2490/20000] Loss: 0.0017123 (Best: 0.0013865 @iter2359) ([92m↓9.96%[0m) [0.68% of initial]
Iter:2499, L1 loss=0.001395, Total loss=0.001503, Time:58
[Iter 2500/20000] Loss: 0.0015456 (Best: 0.0013865 @iter2359) ([92m↓9.74%[0m) [0.61% of initial]
Pruning 480 points (0.6%) from gaussian0 at iteration 2500
Pruning 487 points (0.6%) from gaussian1 at iteration 2500
[Iter 2510/20000] Loss: 0.0033474 (Best: 0.0013865 @iter2359) ([91m↑116.58%[0m) [1.33% of initial]
[Iter 2520/20000] Loss: 0.0022336 (Best: 0.0013865 @iter2359) ([92m↓33.27%[0m) [0.89% of initial]
[Iter 2530/20000] Loss: 0.0016732 (Best: 0.0013865 @iter2359) ([92m↓25.09%[0m) [0.66% of initial]
[Iter 2540/20000] Loss: 0.0015367 (Best: 0.0013865 @iter2359) ([92m↓8.16%[0m) [0.61% of initial]
[Iter 2550/20000] Loss: 0.0016108 (Best: 0.0012328 @iter2548) ([91m↑4.83%[0m) [0.64% of initial]
[Iter 2560/20000] Loss: 0.0013852 (Best: 0.0011988 @iter2557) ([92m↓14.00%[0m) [0.55% of initial]
[Iter 2570/20000] Loss: 0.0015819 (Best: 0.0011988 @iter2557) ([91m↑14.20%[0m) [0.63% of initial]
[Iter 2580/20000] Loss: 0.0014226 (Best: 0.0011446 @iter2578) ([92m↓10.07%[0m) [0.57% of initial]
[Iter 2590/20000] Loss: 0.0014990 (Best: 0.0011446 @iter2578) ([91m↑5.37%[0m) [0.60% of initial]
Iter:2599, L1 loss=0.001204, Total loss=0.001208, Time:53
[Iter 2600/20000] Loss: 0.0014143 (Best: 0.0011446 @iter2578) ([92m↓5.65%[0m) [0.56% of initial]
[Iter 2610/20000] Loss: 0.0066184 (Best: 0.0011446 @iter2578) ([91m↑367.96%[0m) [2.63% of initial]
[Iter 2620/20000] Loss: 0.0038177 (Best: 0.0011446 @iter2578) ([92m↓42.32%[0m) [1.52% of initial]
[Iter 2630/20000] Loss: 0.0024599 (Best: 0.0011446 @iter2578) ([92m↓35.56%[0m) [0.98% of initial]
[Iter 2640/20000] Loss: 0.0019596 (Best: 0.0011446 @iter2578) ([92m↓20.34%[0m) [0.78% of initial]
[Iter 2650/20000] Loss: 0.0016314 (Best: 0.0011446 @iter2578) ([92m↓16.75%[0m) [0.65% of initial]
[Iter 2660/20000] Loss: 0.0018943 (Best: 0.0011446 @iter2578) ([91m↑16.11%[0m) [0.75% of initial]
[Iter 2670/20000] Loss: 0.0020439 (Best: 0.0011446 @iter2578) ([91m↑7.90%[0m) [0.81% of initial]
[Iter 2680/20000] Loss: 0.0014859 (Best: 0.0011446 @iter2578) ([92m↓27.30%[0m) [0.59% of initial]
[Iter 2690/20000] Loss: 0.0014010 (Best: 0.0011446 @iter2578) ([92m↓5.71%[0m) [0.56% of initial]
Iter:2699, L1 loss=0.001324, Total loss=0.001369, Time:51
[Iter 2700/20000] Loss: 0.0016735 (Best: 0.0011446 @iter2578) ([91m↑19.45%[0m) [0.66% of initial]
[Iter 2710/20000] Loss: 0.0014159 (Best: 0.0011446 @iter2578) ([92m↓15.39%[0m) [0.56% of initial]
[Iter 2720/20000] Loss: 0.0012685 (Best: 0.0010969 @iter2718) ([92m↓10.41%[0m) [0.50% of initial]
[Iter 2730/20000] Loss: 0.0013024 (Best: 0.0010900 @iter2724) ([91m↑2.67%[0m) [0.52% of initial]
[Iter 2740/20000] Loss: 0.0010526 (Best: 0.0009457 @iter2740) ([92m↓19.17%[0m) [0.42% of initial]
[Iter 2750/20000] Loss: 0.0013310 (Best: 0.0009457 @iter2740) ([91m↑26.44%[0m) [0.53% of initial]
[Iter 2760/20000] Loss: 0.0014244 (Best: 0.0009457 @iter2740) ([91m↑7.02%[0m) [0.57% of initial]
[Iter 2770/20000] Loss: 0.0015317 (Best: 0.0009457 @iter2740) ([91m↑7.53%[0m) [0.61% of initial]
[Iter 2780/20000] Loss: 0.0012771 (Best: 0.0009457 @iter2740) ([92m↓16.62%[0m) [0.51% of initial]
[Iter 2790/20000] Loss: 0.0012990 (Best: 0.0009457 @iter2740) ([91m↑1.71%[0m) [0.52% of initial]
Iter:2799, L1 loss=0.001384, Total loss=0.001456, Time:50
[Iter 2800/20000] Loss: 0.0012984 (Best: 0.0009457 @iter2740) ([92m↓0.05%[0m) [0.52% of initial]
[Iter 2810/20000] Loss: 0.0055143 (Best: 0.0009457 @iter2740) ([91m↑324.70%[0m) [2.19% of initial]
[Iter 2820/20000] Loss: 0.0029857 (Best: 0.0009457 @iter2740) ([92m↓45.85%[0m) [1.19% of initial]
[Iter 2830/20000] Loss: 0.0019539 (Best: 0.0009457 @iter2740) ([92m↓34.56%[0m) [0.78% of initial]
[Iter 2840/20000] Loss: 0.0016887 (Best: 0.0009457 @iter2740) ([92m↓13.58%[0m) [0.67% of initial]
[Iter 2850/20000] Loss: 0.0014667 (Best: 0.0009457 @iter2740) ([92m↓13.14%[0m) [0.58% of initial]
[Iter 2860/20000] Loss: 0.0015935 (Best: 0.0009457 @iter2740) ([91m↑8.64%[0m) [0.63% of initial]
[Iter 2870/20000] Loss: 0.0013757 (Best: 0.0009457 @iter2740) ([92m↓13.66%[0m) [0.55% of initial]
[Iter 2880/20000] Loss: 0.0013124 (Best: 0.0009457 @iter2740) ([92m↓4.61%[0m) [0.52% of initial]
[Iter 2890/20000] Loss: 0.0012514 (Best: 0.0009457 @iter2740) ([92m↓4.65%[0m) [0.50% of initial]
Iter:2899, L1 loss=0.001017, Total loss=0.0009798, Time:69
[Iter 2900/20000] Loss: 0.0011963 (Best: 0.0009457 @iter2740) ([92m↓4.40%[0m) [0.48% of initial]
[Iter 2910/20000] Loss: 0.0013164 (Best: 0.0009457 @iter2740) ([91m↑10.03%[0m) [0.52% of initial]
[Iter 2920/20000] Loss: 0.0014403 (Best: 0.0009457 @iter2740) ([91m↑9.41%[0m) [0.57% of initial]
[Iter 2930/20000] Loss: 0.0013301 (Best: 0.0009457 @iter2740) ([92m↓7.65%[0m) [0.53% of initial]
[Iter 2940/20000] Loss: 0.0011416 (Best: 0.0009457 @iter2740) ([92m↓14.17%[0m) [0.45% of initial]
[Iter 2950/20000] Loss: 0.0010590 (Best: 0.0009031 @iter2950) ([92m↓7.24%[0m) [0.42% of initial]
[Iter 2960/20000] Loss: 0.0011487 (Best: 0.0009031 @iter2950) ([91m↑8.47%[0m) [0.46% of initial]
[Iter 2970/20000] Loss: 0.0010237 (Best: 0.0008210 @iter2969) ([92m↓10.88%[0m) [0.41% of initial]
[Iter 2980/20000] Loss: 0.0009551 (Best: 0.0008210 @iter2969) ([92m↓6.70%[0m) [0.38% of initial]
[Iter 2990/20000] Loss: 0.0009960 (Best: 0.0007745 @iter2983) ([91m↑4.28%[0m) [0.40% of initial]
Iter:2999, L1 loss=0.0008005, Total loss=0.0007686, Time:68
[Iter 3000/20000] Loss: 0.0009790 (Best: 0.0007686 @iter2999) ([92m↓1.71%[0m) [0.39% of initial]
Pruning 324 points (0.3%) from gaussian0 at iteration 3000
Pruning 387 points (0.3%) from gaussian1 at iteration 3000
[Iter 3010/20000] Loss: 0.0056403 (Best: 0.0007686 @iter2999) ([91m↑476.15%[0m) [2.24% of initial]
[Iter 3020/20000] Loss: 0.0034412 (Best: 0.0007686 @iter2999) ([92m↓38.99%[0m) [1.37% of initial]
[Iter 3030/20000] Loss: 0.0024179 (Best: 0.0007686 @iter2999) ([92m↓29.74%[0m) [0.96% of initial]
[Iter 3040/20000] Loss: 0.0018705 (Best: 0.0007686 @iter2999) ([92m↓22.64%[0m) [0.74% of initial]
[Iter 3050/20000] Loss: 0.0016751 (Best: 0.0007686 @iter2999) ([92m↓10.45%[0m) [0.67% of initial]
[Iter 3060/20000] Loss: 0.0016015 (Best: 0.0007686 @iter2999) ([92m↓4.39%[0m) [0.64% of initial]
[Iter 3070/20000] Loss: 0.0016426 (Best: 0.0007686 @iter2999) ([91m↑2.56%[0m) [0.65% of initial]
[Iter 3080/20000] Loss: 0.0014691 (Best: 0.0007686 @iter2999) ([92m↓10.56%[0m) [0.58% of initial]
[Iter 3090/20000] Loss: 0.0013428 (Best: 0.0007686 @iter2999) ([92m↓8.60%[0m) [0.53% of initial]
Iter:3099, L1 loss=0.001153, Total loss=0.001145, Time:74
[Iter 3100/20000] Loss: 0.0012858 (Best: 0.0007686 @iter2999) ([92m↓4.25%[0m) [0.51% of initial]
[Iter 3110/20000] Loss: 0.0013812 (Best: 0.0007686 @iter2999) ([91m↑7.42%[0m) [0.55% of initial]
[Iter 3120/20000] Loss: 0.0013575 (Best: 0.0007686 @iter2999) ([92m↓1.72%[0m) [0.54% of initial]
[Iter 3130/20000] Loss: 0.0011394 (Best: 0.0007686 @iter2999) ([92m↓16.07%[0m) [0.45% of initial]
[Iter 3140/20000] Loss: 0.0010854 (Best: 0.0007686 @iter2999) ([92m↓4.74%[0m) [0.43% of initial]
[Iter 3150/20000] Loss: 0.0011302 (Best: 0.0007686 @iter2999) ([91m↑4.13%[0m) [0.45% of initial]
[Iter 3160/20000] Loss: 0.0010439 (Best: 0.0007686 @iter2999) ([92m↓7.63%[0m) [0.41% of initial]
[Iter 3170/20000] Loss: 0.0010553 (Best: 0.0007686 @iter2999) ([91m↑1.10%[0m) [0.42% of initial]
[Iter 3180/20000] Loss: 0.0011247 (Best: 0.0007686 @iter2999) ([91m↑6.58%[0m) [0.45% of initial]
[Iter 3190/20000] Loss: 0.0010822 (Best: 0.0007686 @iter2999) ([92m↓3.78%[0m) [0.43% of initial]
Iter:3199, L1 loss=0.0009798, Total loss=0.0009654, Time:73
[Iter 3200/20000] Loss: 0.0010404 (Best: 0.0007686 @iter2999) ([92m↓3.86%[0m) [0.41% of initial]
[Iter 3210/20000] Loss: 0.0054382 (Best: 0.0007686 @iter2999) ([91m↑422.71%[0m) [2.16% of initial]
[Iter 3220/20000] Loss: 0.0031387 (Best: 0.0007686 @iter2999) ([92m↓42.28%[0m) [1.25% of initial]
[Iter 3230/20000] Loss: 0.0019923 (Best: 0.0007686 @iter2999) ([92m↓36.53%[0m) [0.79% of initial]
[Iter 3240/20000] Loss: 0.0017745 (Best: 0.0007686 @iter2999) ([92m↓10.93%[0m) [0.70% of initial]
[Iter 3250/20000] Loss: 0.0013360 (Best: 0.0007686 @iter2999) ([92m↓24.71%[0m) [0.53% of initial]
[Iter 3260/20000] Loss: 0.0011809 (Best: 0.0007686 @iter2999) ([92m↓11.61%[0m) [0.47% of initial]
[Iter 3270/20000] Loss: 0.0012200 (Best: 0.0007686 @iter2999) ([91m↑3.31%[0m) [0.48% of initial]
[Iter 3280/20000] Loss: 0.0012663 (Best: 0.0007686 @iter2999) ([91m↑3.79%[0m) [0.50% of initial]
[Iter 3290/20000] Loss: 0.0009605 (Best: 0.0007686 @iter2999) ([92m↓24.15%[0m) [0.38% of initial]
Iter:3299, L1 loss=0.001464, Total loss=0.001568, Time:79
[Iter 3300/20000] Loss: 0.0013396 (Best: 0.0007686 @iter2999) ([91m↑39.47%[0m) [0.53% of initial]
[Iter 3310/20000] Loss: 0.0009996 (Best: 0.0007686 @iter2999) ([92m↓25.38%[0m) [0.40% of initial]
[Iter 3320/20000] Loss: 0.0011498 (Best: 0.0007686 @iter2999) ([91m↑15.03%[0m) [0.46% of initial]
[Iter 3330/20000] Loss: 0.0012224 (Best: 0.0007686 @iter2999) ([91m↑6.32%[0m) [0.49% of initial]
[Iter 3340/20000] Loss: 0.0013206 (Best: 0.0007686 @iter2999) ([91m↑8.03%[0m) [0.52% of initial]
[Iter 3350/20000] Loss: 0.0010658 (Best: 0.0007686 @iter2999) ([92m↓19.29%[0m) [0.42% of initial]
[Iter 3360/20000] Loss: 0.0012788 (Best: 0.0007686 @iter2999) ([91m↑19.99%[0m) [0.51% of initial]
[Iter 3370/20000] Loss: 0.0009413 (Best: 0.0007686 @iter2999) ([92m↓26.40%[0m) [0.37% of initial]
[Iter 3380/20000] Loss: 0.0009153 (Best: 0.0007644 @iter3379) ([92m↓2.76%[0m) [0.36% of initial]
[Iter 3390/20000] Loss: 0.0012040 (Best: 0.0007644 @iter3379) ([91m↑31.55%[0m) [0.48% of initial]
Iter:3399, L1 loss=0.001509, Total loss=0.001524, Time:75
[Iter 3400/20000] Loss: 0.0012608 (Best: 0.0007644 @iter3379) ([91m↑4.71%[0m) [0.50% of initial]
[Iter 3410/20000] Loss: 0.0046787 (Best: 0.0007644 @iter3379) ([91m↑271.10%[0m) [1.86% of initial]
[Iter 3420/20000] Loss: 0.0024531 (Best: 0.0007644 @iter3379) ([92m↓47.57%[0m) [0.97% of initial]
[Iter 3430/20000] Loss: 0.0015893 (Best: 0.0007644 @iter3379) ([92m↓35.21%[0m) [0.63% of initial]
[Iter 3440/20000] Loss: 0.0014421 (Best: 0.0007644 @iter3379) ([92m↓9.26%[0m) [0.57% of initial]
[Iter 3450/20000] Loss: 0.0013602 (Best: 0.0007644 @iter3379) ([92m↓5.68%[0m) [0.54% of initial]
[Iter 3460/20000] Loss: 0.0012354 (Best: 0.0007644 @iter3379) ([92m↓9.18%[0m) [0.49% of initial]
[Iter 3470/20000] Loss: 0.0011683 (Best: 0.0007644 @iter3379) ([92m↓5.43%[0m) [0.46% of initial]
[Iter 3480/20000] Loss: 0.0011333 (Best: 0.0007644 @iter3379) ([92m↓3.00%[0m) [0.45% of initial]
[Iter 3490/20000] Loss: 0.0010250 (Best: 0.0007644 @iter3379) ([92m↓9.56%[0m) [0.41% of initial]
Iter:3499, L1 loss=0.0007899, Total loss=0.0007187, Time:82
[Iter 3500/20000] Loss: 0.0007955 (Best: 0.0007187 @iter3499) ([92m↓22.39%[0m) [0.32% of initial]
Pruning 282 points (0.2%) from gaussian0 at iteration 3500
Pruning 312 points (0.2%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0024659 (Best: 0.0007187 @iter3499) ([91m↑210.00%[0m) [0.98% of initial]
[Iter 3520/20000] Loss: 0.0015990 (Best: 0.0007187 @iter3499) ([92m↓35.16%[0m) [0.64% of initial]
[Iter 3530/20000] Loss: 0.0013779 (Best: 0.0007187 @iter3499) ([92m↓13.83%[0m) [0.55% of initial]
[Iter 3540/20000] Loss: 0.0013618 (Best: 0.0007187 @iter3499) ([92m↓1.17%[0m) [0.54% of initial]
[Iter 3550/20000] Loss: 0.0011667 (Best: 0.0007187 @iter3499) ([92m↓14.33%[0m) [0.46% of initial]
[Iter 3560/20000] Loss: 0.0010469 (Best: 0.0007187 @iter3499) ([92m↓10.26%[0m) [0.42% of initial]
[Iter 3570/20000] Loss: 0.0011306 (Best: 0.0007187 @iter3499) ([91m↑8.00%[0m) [0.45% of initial]
[Iter 3580/20000] Loss: 0.0008499 (Best: 0.0007187 @iter3499) ([92m↓24.83%[0m) [0.34% of initial]
[Iter 3590/20000] Loss: 0.0008496 (Best: 0.0007187 @iter3499) ([92m↓0.03%[0m) [0.34% of initial]
Iter:3599, L1 loss=0.0007745, Total loss=0.00071, Time:74
[Iter 3600/20000] Loss: 0.0008083 (Best: 0.0006716 @iter3598) ([92m↓4.86%[0m) [0.32% of initial]
[Iter 3610/20000] Loss: 0.0043977 (Best: 0.0006716 @iter3598) ([91m↑444.08%[0m) [1.75% of initial]
[Iter 3620/20000] Loss: 0.0027730 (Best: 0.0006716 @iter3598) ([92m↓36.94%[0m) [1.10% of initial]
[Iter 3630/20000] Loss: 0.0016726 (Best: 0.0006716 @iter3598) ([92m↓39.68%[0m) [0.66% of initial]
[Iter 3640/20000] Loss: 0.0012783 (Best: 0.0006716 @iter3598) ([92m↓23.57%[0m) [0.51% of initial]
[Iter 3650/20000] Loss: 0.0012615 (Best: 0.0006716 @iter3598) ([92m↓1.31%[0m) [0.50% of initial]
[Iter 3660/20000] Loss: 0.0010416 (Best: 0.0006716 @iter3598) ([92m↓17.44%[0m) [0.41% of initial]
[Iter 3670/20000] Loss: 0.0009265 (Best: 0.0006716 @iter3598) ([92m↓11.05%[0m) [0.37% of initial]
[Iter 3680/20000] Loss: 0.0011433 (Best: 0.0006716 @iter3598) ([91m↑23.41%[0m) [0.45% of initial]
[Iter 3690/20000] Loss: 0.0014093 (Best: 0.0006716 @iter3598) ([91m↑23.26%[0m) [0.56% of initial]
Iter:3699, L1 loss=0.001218, Total loss=0.001169, Time:75
[Iter 3700/20000] Loss: 0.0011972 (Best: 0.0006716 @iter3598) ([92m↓15.05%[0m) [0.48% of initial]
[Iter 3710/20000] Loss: 0.0009476 (Best: 0.0006716 @iter3598) ([92m↓20.85%[0m) [0.38% of initial]
[Iter 3720/20000] Loss: 0.0010341 (Best: 0.0006716 @iter3598) ([91m↑9.12%[0m) [0.41% of initial]
[Iter 3730/20000] Loss: 0.0008744 (Best: 0.0006716 @iter3598) ([92m↓15.44%[0m) [0.35% of initial]
[Iter 3740/20000] Loss: 0.0008867 (Best: 0.0006716 @iter3598) ([91m↑1.40%[0m) [0.35% of initial]
[Iter 3750/20000] Loss: 0.0009100 (Best: 0.0006716 @iter3598) ([91m↑2.63%[0m) [0.36% of initial]
[Iter 3760/20000] Loss: 0.0009023 (Best: 0.0006716 @iter3598) ([92m↓0.84%[0m) [0.36% of initial]
[Iter 3770/20000] Loss: 0.0008906 (Best: 0.0006716 @iter3598) ([92m↓1.31%[0m) [0.35% of initial]
[Iter 3780/20000] Loss: 0.0008159 (Best: 0.0006461 @iter3775) ([92m↓8.39%[0m) [0.32% of initial]
[Iter 3790/20000] Loss: 0.0006685 (Best: 0.0005968 @iter3790) ([92m↓18.06%[0m) [0.27% of initial]
Iter:3799, L1 loss=0.0009061, Total loss=0.0008243, Time:80
[Iter 3800/20000] Loss: 0.0008231 (Best: 0.0005968 @iter3790) ([91m↑23.12%[0m) [0.33% of initial]
[Iter 3810/20000] Loss: 0.0045613 (Best: 0.0005968 @iter3790) ([91m↑454.16%[0m) [1.81% of initial]
[Iter 3820/20000] Loss: 0.0023169 (Best: 0.0005968 @iter3790) ([92m↓49.21%[0m) [0.92% of initial]
[Iter 3830/20000] Loss: 0.0014003 (Best: 0.0005968 @iter3790) ([92m↓39.56%[0m) [0.56% of initial]
[Iter 3840/20000] Loss: 0.0015898 (Best: 0.0005968 @iter3790) ([91m↑13.53%[0m) [0.63% of initial]
[Iter 3850/20000] Loss: 0.0012115 (Best: 0.0005968 @iter3790) ([92m↓23.79%[0m) [0.48% of initial]
[Iter 3860/20000] Loss: 0.0011082 (Best: 0.0005968 @iter3790) ([92m↓8.53%[0m) [0.44% of initial]
[Iter 3870/20000] Loss: 0.0008757 (Best: 0.0005968 @iter3790) ([92m↓20.98%[0m) [0.35% of initial]
[Iter 3880/20000] Loss: 0.0009028 (Best: 0.0005968 @iter3790) ([91m↑3.09%[0m) [0.36% of initial]
[Iter 3890/20000] Loss: 0.0007402 (Best: 0.0005968 @iter3790) ([92m↓18.01%[0m) [0.29% of initial]
Iter:3899, L1 loss=0.0008587, Total loss=0.0007898, Time:71
[Iter 3900/20000] Loss: 0.0007557 (Best: 0.0005646 @iter3898) ([91m↑2.10%[0m) [0.30% of initial]
[Iter 3910/20000] Loss: 0.0009450 (Best: 0.0005646 @iter3898) ([91m↑25.05%[0m) [0.38% of initial]
[Iter 3920/20000] Loss: 0.0009403 (Best: 0.0005646 @iter3898) ([92m↓0.50%[0m) [0.37% of initial]
[Iter 3930/20000] Loss: 0.0009323 (Best: 0.0005646 @iter3898) ([92m↓0.85%[0m) [0.37% of initial]
[Iter 3940/20000] Loss: 0.0007594 (Best: 0.0005646 @iter3898) ([92m↓18.55%[0m) [0.30% of initial]
[Iter 3950/20000] Loss: 0.0008448 (Best: 0.0005646 @iter3898) ([91m↑11.25%[0m) [0.34% of initial]
[Iter 3960/20000] Loss: 0.0008784 (Best: 0.0005646 @iter3898) ([91m↑3.98%[0m) [0.35% of initial]
[Iter 3970/20000] Loss: 0.0007733 (Best: 0.0005646 @iter3898) ([92m↓11.96%[0m) [0.31% of initial]
[Iter 3980/20000] Loss: 0.0011168 (Best: 0.0005646 @iter3898) ([91m↑44.42%[0m) [0.44% of initial]
[Iter 3990/20000] Loss: 0.0008336 (Best: 0.0005646 @iter3898) ([92m↓25.36%[0m) [0.33% of initial]
Iter:3999, L1 loss=0.001014, Total loss=0.0009275, Time:71
[Iter 4000/20000] Loss: 0.0008377 (Best: 0.0005646 @iter3898) ([91m↑0.50%[0m) [0.33% of initial]
Pruning 307 points (0.2%) from gaussian0 at iteration 4000
Pruning 185 points (0.1%) from gaussian1 at iteration 4000
[Iter 4010/20000] Loss: 0.1530020 (Best: 0.0005646 @iter3898) ([91m↑18164.01%[0m) [60.79% of initial]
[Iter 4020/20000] Loss: 0.1064994 (Best: 0.0005646 @iter3898) ([92m↓30.39%[0m) [42.31% of initial]
[Iter 4030/20000] Loss: 0.0689470 (Best: 0.0005646 @iter3898) ([92m↓35.26%[0m) [27.39% of initial]
[Iter 4040/20000] Loss: 0.0385406 (Best: 0.0005646 @iter3898) ([92m↓44.10%[0m) [15.31% of initial]
[Iter 4050/20000] Loss: 0.0170682 (Best: 0.0005646 @iter3898) ([92m↓55.71%[0m) [6.78% of initial]
[Iter 4060/20000] Loss: 0.0081296 (Best: 0.0005646 @iter3898) ([92m↓52.37%[0m) [3.23% of initial]
[Iter 4070/20000] Loss: 0.0050752 (Best: 0.0005646 @iter3898) ([92m↓37.57%[0m) [2.02% of initial]
[Iter 4080/20000] Loss: 0.0036975 (Best: 0.0005646 @iter3898) ([92m↓27.14%[0m) [1.47% of initial]
[Iter 4090/20000] Loss: 0.0027615 (Best: 0.0005646 @iter3898) ([92m↓25.32%[0m) [1.10% of initial]
Iter:4099, L1 loss=0.002142, Total loss=0.002298, Time:79
[Iter 4100/20000] Loss: 0.0023429 (Best: 0.0005646 @iter3898) ([92m↓15.16%[0m) [0.93% of initial]
[Iter 4110/20000] Loss: 0.0020758 (Best: 0.0005646 @iter3898) ([92m↓11.40%[0m) [0.82% of initial]
[Iter 4120/20000] Loss: 0.0018203 (Best: 0.0005646 @iter3898) ([92m↓12.31%[0m) [0.72% of initial]
[Iter 4130/20000] Loss: 0.0018168 (Best: 0.0005646 @iter3898) ([92m↓0.19%[0m) [0.72% of initial]
[Iter 4140/20000] Loss: 0.0016344 (Best: 0.0005646 @iter3898) ([92m↓10.04%[0m) [0.65% of initial]
[Iter 4150/20000] Loss: 0.0014887 (Best: 0.0005646 @iter3898) ([92m↓8.92%[0m) [0.59% of initial]
[Iter 4160/20000] Loss: 0.0015736 (Best: 0.0005646 @iter3898) ([91m↑5.70%[0m) [0.63% of initial]
[Iter 4170/20000] Loss: 0.0014701 (Best: 0.0005646 @iter3898) ([92m↓6.57%[0m) [0.58% of initial]
[Iter 4180/20000] Loss: 0.0014674 (Best: 0.0005646 @iter3898) ([92m↓0.19%[0m) [0.58% of initial]
[Iter 4190/20000] Loss: 0.0012809 (Best: 0.0005646 @iter3898) ([92m↓12.71%[0m) [0.51% of initial]
Iter:4199, L1 loss=0.001265, Total loss=0.001242, Time:77
[Iter 4200/20000] Loss: 0.0013357 (Best: 0.0005646 @iter3898) ([91m↑4.28%[0m) [0.53% of initial]
[Iter 4210/20000] Loss: 0.0028884 (Best: 0.0005646 @iter3898) ([91m↑116.24%[0m) [1.15% of initial]
[Iter 4220/20000] Loss: 0.0020405 (Best: 0.0005646 @iter3898) ([92m↓29.35%[0m) [0.81% of initial]
[Iter 4230/20000] Loss: 0.0015536 (Best: 0.0005646 @iter3898) ([92m↓23.86%[0m) [0.62% of initial]
[Iter 4240/20000] Loss: 0.0013440 (Best: 0.0005646 @iter3898) ([92m↓13.49%[0m) [0.53% of initial]
[Iter 4250/20000] Loss: 0.0013327 (Best: 0.0005646 @iter3898) ([92m↓0.85%[0m) [0.53% of initial]
[Iter 4260/20000] Loss: 0.0014137 (Best: 0.0005646 @iter3898) ([91m↑6.08%[0m) [0.56% of initial]
[Iter 4270/20000] Loss: 0.0012866 (Best: 0.0005646 @iter3898) ([92m↓8.99%[0m) [0.51% of initial]
[Iter 4280/20000] Loss: 0.0010696 (Best: 0.0005646 @iter3898) ([92m↓16.87%[0m) [0.42% of initial]
[Iter 4290/20000] Loss: 0.0010647 (Best: 0.0005646 @iter3898) ([92m↓0.46%[0m) [0.42% of initial]
Iter:4299, L1 loss=0.001288, Total loss=0.001209, Time:78
[Iter 4300/20000] Loss: 0.0010267 (Best: 0.0005646 @iter3898) ([92m↓3.56%[0m) [0.41% of initial]
[Iter 4310/20000] Loss: 0.0009971 (Best: 0.0005646 @iter3898) ([92m↓2.89%[0m) [0.40% of initial]
[Iter 4320/20000] Loss: 0.0011565 (Best: 0.0005646 @iter3898) ([91m↑15.99%[0m) [0.46% of initial]
[Iter 4330/20000] Loss: 0.0009924 (Best: 0.0005646 @iter3898) ([92m↓14.19%[0m) [0.39% of initial]
[Iter 4340/20000] Loss: 0.0009797 (Best: 0.0005646 @iter3898) ([92m↓1.28%[0m) [0.39% of initial]
[Iter 4350/20000] Loss: 0.0009694 (Best: 0.0005646 @iter3898) ([92m↓1.05%[0m) [0.39% of initial]
[Iter 4360/20000] Loss: 0.0009347 (Best: 0.0005646 @iter3898) ([92m↓3.58%[0m) [0.37% of initial]
[Iter 4370/20000] Loss: 0.0009715 (Best: 0.0005646 @iter3898) ([91m↑3.94%[0m) [0.39% of initial]
[Iter 4380/20000] Loss: 0.0009955 (Best: 0.0005646 @iter3898) ([91m↑2.47%[0m) [0.40% of initial]
[Iter 4390/20000] Loss: 0.0009356 (Best: 0.0005646 @iter3898) ([92m↓6.01%[0m) [0.37% of initial]
Iter:4399, L1 loss=0.0008595, Total loss=0.0008333, Time:84
[Iter 4400/20000] Loss: 0.0009209 (Best: 0.0005646 @iter3898) ([92m↓1.57%[0m) [0.37% of initial]
[Iter 4410/20000] Loss: 0.0022466 (Best: 0.0005646 @iter3898) ([91m↑143.95%[0m) [0.89% of initial]
[Iter 4420/20000] Loss: 0.0014965 (Best: 0.0005646 @iter3898) ([92m↓33.39%[0m) [0.59% of initial]
[Iter 4430/20000] Loss: 0.0012591 (Best: 0.0005646 @iter3898) ([92m↓15.86%[0m) [0.50% of initial]
[Iter 4440/20000] Loss: 0.0010655 (Best: 0.0005646 @iter3898) ([92m↓15.38%[0m) [0.42% of initial]
[Iter 4450/20000] Loss: 0.0009610 (Best: 0.0005646 @iter3898) ([92m↓9.81%[0m) [0.38% of initial]
[Iter 4460/20000] Loss: 0.0009429 (Best: 0.0005646 @iter3898) ([92m↓1.89%[0m) [0.37% of initial]
[Iter 4470/20000] Loss: 0.0010309 (Best: 0.0005646 @iter3898) ([91m↑9.34%[0m) [0.41% of initial]
[Iter 4480/20000] Loss: 0.0009872 (Best: 0.0005646 @iter3898) ([92m↓4.24%[0m) [0.39% of initial]
[Iter 4490/20000] Loss: 0.0009906 (Best: 0.0005646 @iter3898) ([91m↑0.35%[0m) [0.39% of initial]
Iter:4499, L1 loss=0.001099, Total loss=0.001049, Time:78
[Iter 4500/20000] Loss: 0.0011225 (Best: 0.0005646 @iter3898) ([91m↑13.31%[0m) [0.45% of initial]
Pruning 329 points (0.2%) from gaussian0 at iteration 4500
Pruning 305 points (0.2%) from gaussian1 at iteration 4500
[Iter 4510/20000] Loss: 0.0018730 (Best: 0.0005646 @iter3898) ([91m↑66.86%[0m) [0.74% of initial]
[Iter 4520/20000] Loss: 0.0015303 (Best: 0.0005646 @iter3898) ([92m↓18.30%[0m) [0.61% of initial]
[Iter 4530/20000] Loss: 0.0014364 (Best: 0.0005646 @iter3898) ([92m↓6.14%[0m) [0.57% of initial]
[Iter 4540/20000] Loss: 0.0011643 (Best: 0.0005646 @iter3898) ([92m↓18.94%[0m) [0.46% of initial]
[Iter 4550/20000] Loss: 0.0010296 (Best: 0.0005646 @iter3898) ([92m↓11.57%[0m) [0.41% of initial]
[Iter 4560/20000] Loss: 0.0010377 (Best: 0.0005646 @iter3898) ([91m↑0.79%[0m) [0.41% of initial]
[Iter 4570/20000] Loss: 0.0009076 (Best: 0.0005646 @iter3898) ([92m↓12.54%[0m) [0.36% of initial]
[Iter 4580/20000] Loss: 0.0008837 (Best: 0.0005646 @iter3898) ([92m↓2.63%[0m) [0.35% of initial]
[Iter 4590/20000] Loss: 0.0010061 (Best: 0.0005646 @iter3898) ([91m↑13.85%[0m) [0.40% of initial]
Iter:4599, L1 loss=0.0009737, Total loss=0.0009615, Time:77
[Iter 4600/20000] Loss: 0.0009194 (Best: 0.0005646 @iter3898) ([92m↓8.62%[0m) [0.37% of initial]
[Iter 4610/20000] Loss: 0.0022901 (Best: 0.0005646 @iter3898) ([91m↑149.10%[0m) [0.91% of initial]
[Iter 4620/20000] Loss: 0.0015985 (Best: 0.0005646 @iter3898) ([92m↓30.20%[0m) [0.64% of initial]
[Iter 4630/20000] Loss: 0.0011990 (Best: 0.0005646 @iter3898) ([92m↓24.99%[0m) [0.48% of initial]
[Iter 4640/20000] Loss: 0.0010462 (Best: 0.0005646 @iter3898) ([92m↓12.74%[0m) [0.42% of initial]
[Iter 4650/20000] Loss: 0.0009447 (Best: 0.0005646 @iter3898) ([92m↓9.70%[0m) [0.38% of initial]
[Iter 4660/20000] Loss: 0.0008452 (Best: 0.0005646 @iter3898) ([92m↓10.53%[0m) [0.34% of initial]
[Iter 4670/20000] Loss: 0.0008200 (Best: 0.0005646 @iter3898) ([92m↓2.98%[0m) [0.33% of initial]
[Iter 4680/20000] Loss: 0.0008286 (Best: 0.0005646 @iter3898) ([91m↑1.05%[0m) [0.33% of initial]
[Iter 4690/20000] Loss: 0.0007957 (Best: 0.0005646 @iter3898) ([92m↓3.98%[0m) [0.32% of initial]
Iter:4699, L1 loss=0.0009583, Total loss=0.0008475, Time:78
[Iter 4700/20000] Loss: 0.0009034 (Best: 0.0005646 @iter3898) ([91m↑13.54%[0m) [0.36% of initial]
[Iter 4710/20000] Loss: 0.0007952 (Best: 0.0005646 @iter3898) ([92m↓11.98%[0m) [0.32% of initial]
[Iter 4720/20000] Loss: 0.0008444 (Best: 0.0005646 @iter3898) ([91m↑6.19%[0m) [0.34% of initial]
[Iter 4730/20000] Loss: 0.0008329 (Best: 0.0005646 @iter3898) ([92m↓1.36%[0m) [0.33% of initial]
[Iter 4740/20000] Loss: 0.0009326 (Best: 0.0005646 @iter3898) ([91m↑11.97%[0m) [0.37% of initial]
[Iter 4750/20000] Loss: 0.0008829 (Best: 0.0005646 @iter3898) ([92m↓5.33%[0m) [0.35% of initial]
[Iter 4760/20000] Loss: 0.0008194 (Best: 0.0005646 @iter3898) ([92m↓7.19%[0m) [0.33% of initial]
[Iter 4770/20000] Loss: 0.0008791 (Best: 0.0005646 @iter3898) ([91m↑7.28%[0m) [0.35% of initial]
[Iter 4780/20000] Loss: 0.0009355 (Best: 0.0005646 @iter3898) ([91m↑6.41%[0m) [0.37% of initial]
[Iter 4790/20000] Loss: 0.0008393 (Best: 0.0005646 @iter3898) ([92m↓10.28%[0m) [0.33% of initial]
Iter:4799, L1 loss=0.0008934, Total loss=0.0008204, Time:100
[Iter 4800/20000] Loss: 0.0009590 (Best: 0.0005646 @iter3898) ([91m↑14.26%[0m) [0.38% of initial]
[Iter 4810/20000] Loss: 0.0019069 (Best: 0.0005646 @iter3898) ([91m↑98.85%[0m) [0.76% of initial]
[Iter 4820/20000] Loss: 0.0013988 (Best: 0.0005646 @iter3898) ([92m↓26.65%[0m) [0.56% of initial]
[Iter 4830/20000] Loss: 0.0011480 (Best: 0.0005646 @iter3898) ([92m↓17.93%[0m) [0.46% of initial]
[Iter 4840/20000] Loss: 0.0009286 (Best: 0.0005646 @iter3898) ([92m↓19.11%[0m) [0.37% of initial]
[Iter 4850/20000] Loss: 0.0007811 (Best: 0.0005646 @iter3898) ([92m↓15.88%[0m) [0.31% of initial]
[Iter 4860/20000] Loss: 0.0008348 (Best: 0.0005646 @iter3898) ([91m↑6.86%[0m) [0.33% of initial]
[Iter 4870/20000] Loss: 0.0007616 (Best: 0.0005646 @iter3898) ([92m↓8.77%[0m) [0.30% of initial]
[Iter 4880/20000] Loss: 0.0008224 (Best: 0.0005646 @iter3898) ([91m↑7.98%[0m) [0.33% of initial]
[Iter 4890/20000] Loss: 0.0007658 (Best: 0.0005646 @iter3898) ([92m↓6.88%[0m) [0.30% of initial]
Iter:4899, L1 loss=0.0009027, Total loss=0.0008906, Time:87
[Iter 4900/20000] Loss: 0.0007742 (Best: 0.0005646 @iter3898) ([91m↑1.10%[0m) [0.31% of initial]
[Iter 4910/20000] Loss: 0.0009621 (Best: 0.0005646 @iter3898) ([91m↑24.27%[0m) [0.38% of initial]
[Iter 4920/20000] Loss: 0.0008326 (Best: 0.0005646 @iter3898) ([92m↓13.45%[0m) [0.33% of initial]
[Iter 4930/20000] Loss: 0.0007508 (Best: 0.0005646 @iter3898) ([92m↓9.83%[0m) [0.30% of initial]
[Iter 4940/20000] Loss: 0.0007781 (Best: 0.0005646 @iter3898) ([91m↑3.65%[0m) [0.31% of initial]
[Iter 4950/20000] Loss: 0.0006948 (Best: 0.0005646 @iter3898) ([92m↓10.71%[0m) [0.28% of initial]
[Iter 4960/20000] Loss: 0.0007290 (Best: 0.0005646 @iter3898) ([91m↑4.92%[0m) [0.29% of initial]
[Iter 4970/20000] Loss: 0.0007626 (Best: 0.0005646 @iter3898) ([91m↑4.61%[0m) [0.30% of initial]
[Iter 4980/20000] Loss: 0.0007793 (Best: 0.0005646 @iter3898) ([91m↑2.20%[0m) [0.31% of initial]
[Iter 4990/20000] Loss: 0.0007271 (Best: 0.0005646 @iter3898) ([92m↓6.70%[0m) [0.29% of initial]
Iter:4999, L1 loss=0.0007203, Total loss=0.0007012, Time:86
[Iter 5000/20000] Loss: 0.0006863 (Best: 0.0005646 @iter3898) ([92m↓5.61%[0m) [0.27% of initial]
Pruning 158 points (0.1%) from gaussian0 at iteration 5000
Pruning 170 points (0.1%) from gaussian1 at iteration 5000
[Iter 5010/20000] Loss: 0.0020918 (Best: 0.0005646 @iter3898) ([91m↑204.77%[0m) [0.83% of initial]
[Iter 5020/20000] Loss: 0.0014964 (Best: 0.0005646 @iter3898) ([92m↓28.46%[0m) [0.59% of initial]
[Iter 5030/20000] Loss: 0.0010452 (Best: 0.0005646 @iter3898) ([92m↓30.15%[0m) [0.42% of initial]
[Iter 5040/20000] Loss: 0.0010433 (Best: 0.0005646 @iter3898) ([92m↓0.19%[0m) [0.41% of initial]
[Iter 5050/20000] Loss: 0.0009312 (Best: 0.0005646 @iter3898) ([92m↓10.74%[0m) [0.37% of initial]
[Iter 5060/20000] Loss: 0.0007619 (Best: 0.0005646 @iter3898) ([92m↓18.19%[0m) [0.30% of initial]
[Iter 5070/20000] Loss: 0.0009294 (Best: 0.0005646 @iter3898) ([91m↑21.98%[0m) [0.37% of initial]
[Iter 5080/20000] Loss: 0.0007400 (Best: 0.0005646 @iter3898) ([92m↓20.38%[0m) [0.29% of initial]
[Iter 5090/20000] Loss: 0.0007839 (Best: 0.0005646 @iter3898) ([91m↑5.94%[0m) [0.31% of initial]
Iter:5099, L1 loss=0.0008361, Total loss=0.00076, Time:86
[Iter 5100/20000] Loss: 0.0008246 (Best: 0.0005646 @iter3898) ([91m↑5.19%[0m) [0.33% of initial]
[Iter 5110/20000] Loss: 0.0008036 (Best: 0.0005646 @iter3898) ([92m↓2.55%[0m) [0.32% of initial]
[Iter 5120/20000] Loss: 0.0008024 (Best: 0.0005646 @iter3898) ([92m↓0.14%[0m) [0.32% of initial]
[Iter 5130/20000] Loss: 0.0008117 (Best: 0.0005646 @iter3898) ([91m↑1.15%[0m) [0.32% of initial]
[Iter 5140/20000] Loss: 0.0007103 (Best: 0.0005646 @iter3898) ([92m↓12.50%[0m) [0.28% of initial]
[Iter 5150/20000] Loss: 0.0007121 (Best: 0.0005646 @iter3898) ([91m↑0.26%[0m) [0.28% of initial]
[Iter 5160/20000] Loss: 0.0007034 (Best: 0.0005646 @iter3898) ([92m↓1.23%[0m) [0.28% of initial]
[Iter 5170/20000] Loss: 0.0007634 (Best: 0.0005646 @iter3898) ([91m↑8.53%[0m) [0.30% of initial]
[Iter 5180/20000] Loss: 0.0007042 (Best: 0.0005646 @iter3898) ([92m↓7.75%[0m) [0.28% of initial]
[Iter 5190/20000] Loss: 0.0007170 (Best: 0.0005646 @iter3898) ([91m↑1.82%[0m) [0.28% of initial]
Iter:5199, L1 loss=0.0008041, Total loss=0.0007615, Time:82
[Iter 5200/20000] Loss: 0.0007010 (Best: 0.0005646 @iter3898) ([92m↓2.23%[0m) [0.28% of initial]
[Iter 5210/20000] Loss: 0.0017795 (Best: 0.0005646 @iter3898) ([91m↑153.85%[0m) [0.71% of initial]
[Iter 5220/20000] Loss: 0.0014300 (Best: 0.0005646 @iter3898) ([92m↓19.64%[0m) [0.57% of initial]
[Iter 5230/20000] Loss: 0.0010723 (Best: 0.0005646 @iter3898) ([92m↓25.01%[0m) [0.43% of initial]
[Iter 5240/20000] Loss: 0.0008172 (Best: 0.0005646 @iter3898) ([92m↓23.79%[0m) [0.32% of initial]
[Iter 5250/20000] Loss: 0.0010598 (Best: 0.0005646 @iter3898) ([91m↑29.70%[0m) [0.42% of initial]
[Iter 5260/20000] Loss: 0.0008595 (Best: 0.0005646 @iter3898) ([92m↓18.90%[0m) [0.34% of initial]
[Iter 5270/20000] Loss: 0.0007890 (Best: 0.0005646 @iter3898) ([92m↓8.21%[0m) [0.31% of initial]
[Iter 5280/20000] Loss: 0.0008473 (Best: 0.0005646 @iter3898) ([91m↑7.40%[0m) [0.34% of initial]
[Iter 5290/20000] Loss: 0.0008032 (Best: 0.0005646 @iter3898) ([92m↓5.21%[0m) [0.32% of initial]
Iter:5299, L1 loss=0.0008874, Total loss=0.0008419, Time:80
[Iter 5300/20000] Loss: 0.0008694 (Best: 0.0005646 @iter3898) ([91m↑8.25%[0m) [0.35% of initial]
[Iter 5310/20000] Loss: 0.0008713 (Best: 0.0005646 @iter3898) ([91m↑0.21%[0m) [0.35% of initial]
[Iter 5320/20000] Loss: 0.0007677 (Best: 0.0005646 @iter3898) ([92m↓11.89%[0m) [0.30% of initial]
[Iter 5330/20000] Loss: 0.0006521 (Best: 0.0005646 @iter3898) ([92m↓15.06%[0m) [0.26% of initial]
[Iter 5340/20000] Loss: 0.0006947 (Best: 0.0005646 @iter3898) ([91m↑6.54%[0m) [0.28% of initial]
[Iter 5350/20000] Loss: 0.0007040 (Best: 0.0005566 @iter5344) ([91m↑1.33%[0m) [0.28% of initial]
[Iter 5360/20000] Loss: 0.0007088 (Best: 0.0005566 @iter5344) ([91m↑0.69%[0m) [0.28% of initial]
[Iter 5370/20000] Loss: 0.0007290 (Best: 0.0005566 @iter5344) ([91m↑2.85%[0m) [0.29% of initial]
[Iter 5380/20000] Loss: 0.0007255 (Best: 0.0005566 @iter5344) ([92m↓0.48%[0m) [0.29% of initial]
[Iter 5390/20000] Loss: 0.0007391 (Best: 0.0005566 @iter5344) ([91m↑1.87%[0m) [0.29% of initial]
Iter:5399, L1 loss=0.0006957, Total loss=0.0006621, Time:81
[Iter 5400/20000] Loss: 0.0007502 (Best: 0.0005566 @iter5344) ([91m↑1.49%[0m) [0.30% of initial]
[Iter 5410/20000] Loss: 0.0015045 (Best: 0.0005566 @iter5344) ([91m↑100.56%[0m) [0.60% of initial]
[Iter 5420/20000] Loss: 0.0012113 (Best: 0.0005566 @iter5344) ([92m↓19.49%[0m) [0.48% of initial]
[Iter 5430/20000] Loss: 0.0008799 (Best: 0.0005566 @iter5344) ([92m↓27.36%[0m) [0.35% of initial]
[Iter 5440/20000] Loss: 0.0008083 (Best: 0.0005566 @iter5344) ([92m↓8.14%[0m) [0.32% of initial]
[Iter 5450/20000] Loss: 0.0010135 (Best: 0.0005566 @iter5344) ([91m↑25.38%[0m) [0.40% of initial]
[Iter 5460/20000] Loss: 0.0008382 (Best: 0.0005566 @iter5344) ([92m↓17.30%[0m) [0.33% of initial]
[Iter 5470/20000] Loss: 0.0007035 (Best: 0.0005566 @iter5344) ([92m↓16.07%[0m) [0.28% of initial]
[Iter 5480/20000] Loss: 0.0006492 (Best: 0.0005479 @iter5476) ([92m↓7.71%[0m) [0.26% of initial]
[Iter 5490/20000] Loss: 0.0006749 (Best: 0.0005479 @iter5476) ([91m↑3.96%[0m) [0.27% of initial]
Iter:5499, L1 loss=0.0007335, Total loss=0.0006862, Time:80
[Iter 5500/20000] Loss: 0.0006319 (Best: 0.0005479 @iter5476) ([92m↓6.38%[0m) [0.25% of initial]
Pruning 99 points (0.1%) from gaussian0 at iteration 5500
Pruning 108 points (0.1%) from gaussian1 at iteration 5500
[Iter 5510/20000] Loss: 0.0011555 (Best: 0.0005479 @iter5476) ([91m↑82.86%[0m) [0.46% of initial]
[Iter 5520/20000] Loss: 0.0008769 (Best: 0.0005479 @iter5476) ([92m↓24.11%[0m) [0.35% of initial]
[Iter 5530/20000] Loss: 0.0008061 (Best: 0.0005479 @iter5476) ([92m↓8.08%[0m) [0.32% of initial]
[Iter 5540/20000] Loss: 0.0007463 (Best: 0.0005479 @iter5476) ([92m↓7.42%[0m) [0.30% of initial]
[Iter 5550/20000] Loss: 0.0007186 (Best: 0.0005479 @iter5476) ([92m↓3.71%[0m) [0.29% of initial]
[Iter 5560/20000] Loss: 0.0006659 (Best: 0.0005479 @iter5476) ([92m↓7.33%[0m) [0.26% of initial]
[Iter 5570/20000] Loss: 0.0006612 (Best: 0.0005479 @iter5476) ([92m↓0.71%[0m) [0.26% of initial]
[Iter 5580/20000] Loss: 0.0007617 (Best: 0.0005479 @iter5476) ([91m↑15.19%[0m) [0.30% of initial]
[Iter 5590/20000] Loss: 0.0008267 (Best: 0.0005479 @iter5476) ([91m↑8.54%[0m) [0.33% of initial]
Iter:5599, L1 loss=0.0006736, Total loss=0.0006228, Time:89
[Iter 5600/20000] Loss: 0.0006393 (Best: 0.0005479 @iter5476) ([92m↓22.67%[0m) [0.25% of initial]
[Iter 5610/20000] Loss: 0.0016979 (Best: 0.0005479 @iter5476) ([91m↑165.60%[0m) [0.67% of initial]
[Iter 5620/20000] Loss: 0.0010588 (Best: 0.0005479 @iter5476) ([92m↓37.64%[0m) [0.42% of initial]
[Iter 5630/20000] Loss: 0.0008936 (Best: 0.0005479 @iter5476) ([92m↓15.60%[0m) [0.36% of initial]
[Iter 5640/20000] Loss: 0.0007934 (Best: 0.0005479 @iter5476) ([92m↓11.22%[0m) [0.32% of initial]
[Iter 5650/20000] Loss: 0.0006875 (Best: 0.0005479 @iter5476) ([92m↓13.35%[0m) [0.27% of initial]
[Iter 5660/20000] Loss: 0.0006762 (Best: 0.0005479 @iter5476) ([92m↓1.64%[0m) [0.27% of initial]
[Iter 5670/20000] Loss: 0.0006846 (Best: 0.0005479 @iter5476) ([91m↑1.25%[0m) [0.27% of initial]
[Iter 5680/20000] Loss: 0.0006333 (Best: 0.0005479 @iter5476) ([92m↓7.50%[0m) [0.25% of initial]
[Iter 5690/20000] Loss: 0.0006832 (Best: 0.0005479 @iter5476) ([91m↑7.87%[0m) [0.27% of initial]
Iter:5699, L1 loss=0.0006702, Total loss=0.000594, Time:90
[Iter 5700/20000] Loss: 0.0005913 (Best: 0.0005479 @iter5476) ([92m↓13.44%[0m) [0.23% of initial]
[Iter 5710/20000] Loss: 0.0007400 (Best: 0.0005157 @iter5701) ([91m↑25.14%[0m) [0.29% of initial]
[Iter 5720/20000] Loss: 0.0006636 (Best: 0.0005157 @iter5701) ([92m↓10.33%[0m) [0.26% of initial]
[Iter 5730/20000] Loss: 0.0006836 (Best: 0.0005157 @iter5701) ([91m↑3.01%[0m) [0.27% of initial]
[Iter 5740/20000] Loss: 0.0005867 (Best: 0.0005157 @iter5701) ([92m↓14.18%[0m) [0.23% of initial]
[Iter 5750/20000] Loss: 0.0005881 (Best: 0.0005157 @iter5701) ([91m↑0.24%[0m) [0.23% of initial]
[Iter 5760/20000] Loss: 0.0005990 (Best: 0.0005157 @iter5701) ([91m↑1.85%[0m) [0.24% of initial]
[Iter 5770/20000] Loss: 0.0005366 (Best: 0.0004813 @iter5770) ([92m↓10.41%[0m) [0.21% of initial]
[Iter 5780/20000] Loss: 0.0005557 (Best: 0.0004813 @iter5770) ([91m↑3.56%[0m) [0.22% of initial]
[Iter 5790/20000] Loss: 0.0005949 (Best: 0.0004813 @iter5770) ([91m↑7.05%[0m) [0.24% of initial]
Iter:5799, L1 loss=0.0006353, Total loss=0.0005876, Time:81
[Iter 5800/20000] Loss: 0.0005793 (Best: 0.0004632 @iter5797) ([92m↓2.62%[0m) [0.23% of initial]
[Iter 5810/20000] Loss: 0.0012968 (Best: 0.0004632 @iter5797) ([91m↑123.84%[0m) [0.52% of initial]
[Iter 5820/20000] Loss: 0.0010533 (Best: 0.0004632 @iter5797) ([92m↓18.78%[0m) [0.42% of initial]
[Iter 5830/20000] Loss: 0.0008061 (Best: 0.0004632 @iter5797) ([92m↓23.46%[0m) [0.32% of initial]
[Iter 5840/20000] Loss: 0.0007143 (Best: 0.0004632 @iter5797) ([92m↓11.39%[0m) [0.28% of initial]
[Iter 5850/20000] Loss: 0.0007182 (Best: 0.0004632 @iter5797) ([91m↑0.55%[0m) [0.29% of initial]
[Iter 5860/20000] Loss: 0.0005849 (Best: 0.0004632 @iter5797) ([92m↓18.57%[0m) [0.23% of initial]
[Iter 5870/20000] Loss: 0.0006989 (Best: 0.0004632 @iter5797) ([91m↑19.50%[0m) [0.28% of initial]
[Iter 5880/20000] Loss: 0.0006288 (Best: 0.0004632 @iter5797) ([92m↓10.03%[0m) [0.25% of initial]
[Iter 5890/20000] Loss: 0.0006062 (Best: 0.0004632 @iter5797) ([92m↓3.60%[0m) [0.24% of initial]
Iter:5899, L1 loss=0.0006315, Total loss=0.0005838, Time:85
[Iter 5900/20000] Loss: 0.0005844 (Best: 0.0004632 @iter5797) ([92m↓3.60%[0m) [0.23% of initial]
[Iter 5910/20000] Loss: 0.0006327 (Best: 0.0004632 @iter5797) ([91m↑8.25%[0m) [0.25% of initial]
[Iter 5920/20000] Loss: 0.0005967 (Best: 0.0004632 @iter5797) ([92m↓5.68%[0m) [0.24% of initial]
[Iter 5930/20000] Loss: 0.0005049 (Best: 0.0004632 @iter5797) ([92m↓15.38%[0m) [0.20% of initial]
[Iter 5940/20000] Loss: 0.0006717 (Best: 0.0004632 @iter5797) ([91m↑33.03%[0m) [0.27% of initial]
[Iter 5950/20000] Loss: 0.0005494 (Best: 0.0004632 @iter5797) ([92m↓18.21%[0m) [0.22% of initial]
[Iter 5960/20000] Loss: 0.0005856 (Best: 0.0004632 @iter5797) ([91m↑6.58%[0m) [0.23% of initial]
[Iter 5970/20000] Loss: 0.0006886 (Best: 0.0004632 @iter5797) ([91m↑17.60%[0m) [0.27% of initial]
[Iter 5980/20000] Loss: 0.0006176 (Best: 0.0004632 @iter5797) ([92m↓10.31%[0m) [0.25% of initial]
[Iter 5990/20000] Loss: 0.0006301 (Best: 0.0004632 @iter5797) ([91m↑2.02%[0m) [0.25% of initial]
Iter:5999, L1 loss=0.0006992, Total loss=0.0006371, Time:80
[Iter 6000/20000] Loss: 0.0006268 (Best: 0.0004632 @iter5797) ([92m↓0.52%[0m) [0.25% of initial]
Pruning 149 points (0.1%) from gaussian0 at iteration 6000
Pruning 81 points (0.0%) from gaussian1 at iteration 6000
[Iter 6010/20000] Loss: 0.0020532 (Best: 0.0004632 @iter5797) ([91m↑227.56%[0m) [0.82% of initial]
[Iter 6020/20000] Loss: 0.0013339 (Best: 0.0004632 @iter5797) ([92m↓35.03%[0m) [0.53% of initial]
[Iter 6030/20000] Loss: 0.0009293 (Best: 0.0004632 @iter5797) ([92m↓30.33%[0m) [0.37% of initial]
[Iter 6040/20000] Loss: 0.0007042 (Best: 0.0004632 @iter5797) ([92m↓24.23%[0m) [0.28% of initial]
[Iter 6050/20000] Loss: 0.0006414 (Best: 0.0004632 @iter5797) ([92m↓8.91%[0m) [0.25% of initial]
[Iter 6060/20000] Loss: 0.0006736 (Best: 0.0004632 @iter5797) ([91m↑5.01%[0m) [0.27% of initial]
[Iter 6070/20000] Loss: 0.0006743 (Best: 0.0004632 @iter5797) ([91m↑0.11%[0m) [0.27% of initial]
[Iter 6080/20000] Loss: 0.0006618 (Best: 0.0004632 @iter5797) ([92m↓1.86%[0m) [0.26% of initial]
[Iter 6090/20000] Loss: 0.0005967 (Best: 0.0004632 @iter5797) ([92m↓9.83%[0m) [0.24% of initial]
Iter:6099, L1 loss=0.0006056, Total loss=0.0005671, Time:101
[Iter 6100/20000] Loss: 0.0006021 (Best: 0.0004632 @iter5797) ([91m↑0.90%[0m) [0.24% of initial]
[Iter 6110/20000] Loss: 0.0005904 (Best: 0.0004632 @iter5797) ([92m↓1.94%[0m) [0.23% of initial]
[Iter 6120/20000] Loss: 0.0006535 (Best: 0.0004632 @iter5797) ([91m↑10.68%[0m) [0.26% of initial]
[Iter 6130/20000] Loss: 0.0006210 (Best: 0.0004632 @iter5797) ([92m↓4.97%[0m) [0.25% of initial]
[Iter 6140/20000] Loss: 0.0005412 (Best: 0.0004632 @iter5797) ([92m↓12.84%[0m) [0.22% of initial]
[Iter 6150/20000] Loss: 0.0005572 (Best: 0.0004632 @iter5797) ([91m↑2.95%[0m) [0.22% of initial]
[Iter 6160/20000] Loss: 0.0005395 (Best: 0.0004632 @iter5797) ([92m↓3.17%[0m) [0.21% of initial]
[Iter 6170/20000] Loss: 0.0005569 (Best: 0.0004632 @iter5797) ([91m↑3.23%[0m) [0.22% of initial]
[Iter 6180/20000] Loss: 0.0006338 (Best: 0.0004632 @iter5797) ([91m↑13.79%[0m) [0.25% of initial]
[Iter 6190/20000] Loss: 0.0005294 (Best: 0.0004632 @iter5797) ([92m↓16.47%[0m) [0.21% of initial]
Iter:6199, L1 loss=0.0005253, Total loss=0.0004892, Time:112
[Iter 6200/20000] Loss: 0.0005408 (Best: 0.0004632 @iter5797) ([91m↑2.15%[0m) [0.21% of initial]
[Iter 6210/20000] Loss: 0.0012947 (Best: 0.0004632 @iter5797) ([91m↑139.42%[0m) [0.51% of initial]
[Iter 6220/20000] Loss: 0.0009549 (Best: 0.0004632 @iter5797) ([92m↓26.24%[0m) [0.38% of initial]
[Iter 6230/20000] Loss: 0.0008340 (Best: 0.0004632 @iter5797) ([92m↓12.66%[0m) [0.33% of initial]
[Iter 6240/20000] Loss: 0.0006775 (Best: 0.0004632 @iter5797) ([92m↓18.76%[0m) [0.27% of initial]
[Iter 6250/20000] Loss: 0.0006078 (Best: 0.0004632 @iter5797) ([92m↓10.29%[0m) [0.24% of initial]
[Iter 6260/20000] Loss: 0.0006724 (Best: 0.0004632 @iter5797) ([91m↑10.62%[0m) [0.27% of initial]
[Iter 6270/20000] Loss: 0.0006033 (Best: 0.0004632 @iter5797) ([92m↓10.28%[0m) [0.24% of initial]
[Iter 6280/20000] Loss: 0.0006433 (Best: 0.0004632 @iter5797) ([91m↑6.64%[0m) [0.26% of initial]
[Iter 6290/20000] Loss: 0.0005759 (Best: 0.0004632 @iter5797) ([92m↓10.49%[0m) [0.23% of initial]
Iter:6299, L1 loss=0.0007192, Total loss=0.0006514, Time:101
[Iter 6300/20000] Loss: 0.0007513 (Best: 0.0004632 @iter5797) ([91m↑30.46%[0m) [0.30% of initial]
[Iter 6310/20000] Loss: 0.0006548 (Best: 0.0004632 @iter5797) ([92m↓12.85%[0m) [0.26% of initial]
[Iter 6320/20000] Loss: 0.0006648 (Best: 0.0004632 @iter5797) ([91m↑1.53%[0m) [0.26% of initial]
[Iter 6330/20000] Loss: 0.0006415 (Best: 0.0004632 @iter5797) ([92m↓3.51%[0m) [0.25% of initial]
[Iter 6340/20000] Loss: 0.0005116 (Best: 0.0004523 @iter6340) ([92m↓20.24%[0m) [0.20% of initial]
[Iter 6350/20000] Loss: 0.0005270 (Best: 0.0004523 @iter6340) ([91m↑3.02%[0m) [0.21% of initial]
[Iter 6360/20000] Loss: 0.0005993 (Best: 0.0004523 @iter6340) ([91m↑13.71%[0m) [0.24% of initial]
[Iter 6370/20000] Loss: 0.0005770 (Best: 0.0004523 @iter6340) ([92m↓3.71%[0m) [0.23% of initial]
[Iter 6380/20000] Loss: 0.0005247 (Best: 0.0004523 @iter6340) ([92m↓9.06%[0m) [0.21% of initial]
[Iter 6390/20000] Loss: 0.0005492 (Best: 0.0004483 @iter6382) ([91m↑4.66%[0m) [0.22% of initial]
Iter:6399, L1 loss=0.0005855, Total loss=0.0005163, Time:78
[Iter 6400/20000] Loss: 0.0005788 (Best: 0.0004483 @iter6382) ([91m↑5.39%[0m) [0.23% of initial]
[Iter 6410/20000] Loss: 0.0012123 (Best: 0.0004483 @iter6382) ([91m↑109.45%[0m) [0.48% of initial]
[Iter 6420/20000] Loss: 0.0010827 (Best: 0.0004483 @iter6382) ([92m↓10.69%[0m) [0.43% of initial]
[Iter 6430/20000] Loss: 0.0009081 (Best: 0.0004483 @iter6382) ([92m↓16.12%[0m) [0.36% of initial]
[Iter 6440/20000] Loss: 0.0007381 (Best: 0.0004483 @iter6382) ([92m↓18.72%[0m) [0.29% of initial]
[Iter 6450/20000] Loss: 0.0006653 (Best: 0.0004483 @iter6382) ([92m↓9.87%[0m) [0.26% of initial]
[Iter 6460/20000] Loss: 0.0005871 (Best: 0.0004483 @iter6382) ([92m↓11.75%[0m) [0.23% of initial]
[Iter 6470/20000] Loss: 0.0005645 (Best: 0.0004483 @iter6382) ([92m↓3.86%[0m) [0.22% of initial]
[Iter 6480/20000] Loss: 0.0005731 (Best: 0.0004483 @iter6382) ([91m↑1.53%[0m) [0.23% of initial]
[Iter 6490/20000] Loss: 0.0005264 (Best: 0.0004483 @iter6382) ([92m↓8.16%[0m) [0.21% of initial]
Iter:6499, L1 loss=0.0006922, Total loss=0.0006401, Time:81
[Iter 6500/20000] Loss: 0.0006273 (Best: 0.0004483 @iter6382) ([91m↑19.19%[0m) [0.25% of initial]
Pruning 70 points (0.0%) from gaussian0 at iteration 6500
Pruning 62 points (0.0%) from gaussian1 at iteration 6500
[Iter 6510/20000] Loss: 0.0013321 (Best: 0.0004483 @iter6382) ([91m↑112.33%[0m) [0.53% of initial]
[Iter 6520/20000] Loss: 0.0008546 (Best: 0.0004483 @iter6382) ([92m↓35.85%[0m) [0.34% of initial]
[Iter 6530/20000] Loss: 0.0007598 (Best: 0.0004483 @iter6382) ([92m↓11.09%[0m) [0.30% of initial]
[Iter 6540/20000] Loss: 0.0006128 (Best: 0.0004483 @iter6382) ([92m↓19.35%[0m) [0.24% of initial]
[Iter 6550/20000] Loss: 0.0005531 (Best: 0.0004483 @iter6382) ([92m↓9.73%[0m) [0.22% of initial]
[Iter 6560/20000] Loss: 0.0004771 (Best: 0.0004483 @iter6382) ([92m↓13.73%[0m) [0.19% of initial]
[Iter 6570/20000] Loss: 0.0005638 (Best: 0.0004261 @iter6568) ([91m↑18.17%[0m) [0.22% of initial]
[Iter 6580/20000] Loss: 0.0005668 (Best: 0.0004261 @iter6568) ([91m↑0.52%[0m) [0.23% of initial]
[Iter 6590/20000] Loss: 0.0004841 (Best: 0.0004261 @iter6568) ([92m↓14.59%[0m) [0.19% of initial]
Iter:6599, L1 loss=0.0005493, Total loss=0.0005054, Time:82
[Iter 6600/20000] Loss: 0.0005144 (Best: 0.0004261 @iter6568) ([91m↑6.27%[0m) [0.20% of initial]
[Iter 6610/20000] Loss: 0.0011683 (Best: 0.0004261 @iter6568) ([91m↑127.11%[0m) [0.46% of initial]
[Iter 6620/20000] Loss: 0.0008481 (Best: 0.0004261 @iter6568) ([92m↓27.41%[0m) [0.34% of initial]
[Iter 6630/20000] Loss: 0.0006374 (Best: 0.0004261 @iter6568) ([92m↓24.85%[0m) [0.25% of initial]
[Iter 6640/20000] Loss: 0.0005441 (Best: 0.0004261 @iter6568) ([92m↓14.64%[0m) [0.22% of initial]
[Iter 6650/20000] Loss: 0.0005223 (Best: 0.0004261 @iter6568) ([92m↓4.00%[0m) [0.21% of initial]
[Iter 6660/20000] Loss: 0.0005863 (Best: 0.0004261 @iter6568) ([91m↑12.26%[0m) [0.23% of initial]
[Iter 6670/20000] Loss: 0.0005743 (Best: 0.0004261 @iter6568) ([92m↓2.06%[0m) [0.23% of initial]
[Iter 6680/20000] Loss: 0.0006094 (Best: 0.0004261 @iter6568) ([91m↑6.11%[0m) [0.24% of initial]
[Iter 6690/20000] Loss: 0.0005510 (Best: 0.0004261 @iter6568) ([92m↓9.58%[0m) [0.22% of initial]
Iter:6699, L1 loss=0.0006204, Total loss=0.0005521, Time:86
[Iter 6700/20000] Loss: 0.0005257 (Best: 0.0004261 @iter6568) ([92m↓4.59%[0m) [0.21% of initial]
[Iter 6710/20000] Loss: 0.0005758 (Best: 0.0004261 @iter6568) ([91m↑9.53%[0m) [0.23% of initial]
[Iter 6720/20000] Loss: 0.0005218 (Best: 0.0004261 @iter6568) ([92m↓9.38%[0m) [0.21% of initial]
[Iter 6730/20000] Loss: 0.0004627 (Best: 0.0004261 @iter6568) ([92m↓11.32%[0m) [0.18% of initial]
[Iter 6740/20000] Loss: 0.0005017 (Best: 0.0004216 @iter6731) ([91m↑8.42%[0m) [0.20% of initial]
[Iter 6750/20000] Loss: 0.0005185 (Best: 0.0004216 @iter6731) ([91m↑3.34%[0m) [0.21% of initial]
[Iter 6760/20000] Loss: 0.0004901 (Best: 0.0004216 @iter6731) ([92m↓5.48%[0m) [0.19% of initial]
[Iter 6770/20000] Loss: 0.0004886 (Best: 0.0004216 @iter6731) ([92m↓0.30%[0m) [0.19% of initial]
[Iter 6780/20000] Loss: 0.0004505 (Best: 0.0004216 @iter6731) ([92m↓7.80%[0m) [0.18% of initial]
[Iter 6790/20000] Loss: 0.0005185 (Best: 0.0003919 @iter6781) ([91m↑15.10%[0m) [0.21% of initial]
Iter:6799, L1 loss=0.0004715, Total loss=0.0004288, Time:105
[Iter 6800/20000] Loss: 0.0004448 (Best: 0.0003919 @iter6781) ([92m↓14.21%[0m) [0.18% of initial]
[Iter 6810/20000] Loss: 0.0010444 (Best: 0.0003919 @iter6781) ([91m↑134.78%[0m) [0.41% of initial]
[Iter 6820/20000] Loss: 0.0008619 (Best: 0.0003919 @iter6781) ([92m↓17.48%[0m) [0.34% of initial]
[Iter 6830/20000] Loss: 0.0006334 (Best: 0.0003919 @iter6781) ([92m↓26.51%[0m) [0.25% of initial]
[Iter 6840/20000] Loss: 0.0005529 (Best: 0.0003919 @iter6781) ([92m↓12.71%[0m) [0.22% of initial]
[Iter 6850/20000] Loss: 0.0005362 (Best: 0.0003919 @iter6781) ([92m↓3.02%[0m) [0.21% of initial]
[Iter 6860/20000] Loss: 0.0005014 (Best: 0.0003919 @iter6781) ([92m↓6.49%[0m) [0.20% of initial]
[Iter 6870/20000] Loss: 0.0004951 (Best: 0.0003919 @iter6781) ([92m↓1.26%[0m) [0.20% of initial]
[Iter 6880/20000] Loss: 0.0004702 (Best: 0.0003919 @iter6781) ([92m↓5.03%[0m) [0.19% of initial]
[Iter 6890/20000] Loss: 0.0005523 (Best: 0.0003919 @iter6781) ([91m↑17.46%[0m) [0.22% of initial]
Iter:6899, L1 loss=0.0006247, Total loss=0.0005691, Time:102
[Iter 6900/20000] Loss: 0.0005509 (Best: 0.0003919 @iter6781) ([92m↓0.26%[0m) [0.22% of initial]
[Iter 6910/20000] Loss: 0.0005581 (Best: 0.0003919 @iter6781) ([91m↑1.31%[0m) [0.22% of initial]
[Iter 6920/20000] Loss: 0.0005075 (Best: 0.0003919 @iter6781) ([92m↓9.06%[0m) [0.20% of initial]
[Iter 6930/20000] Loss: 0.0005095 (Best: 0.0003919 @iter6781) ([91m↑0.39%[0m) [0.20% of initial]
[Iter 6940/20000] Loss: 0.0004563 (Best: 0.0003919 @iter6781) ([92m↓10.43%[0m) [0.18% of initial]
[Iter 6950/20000] Loss: 0.0004580 (Best: 0.0003919 @iter6781) ([91m↑0.36%[0m) [0.18% of initial]
[Iter 6960/20000] Loss: 0.0004401 (Best: 0.0003919 @iter6781) ([92m↓3.91%[0m) [0.17% of initial]
[Iter 6970/20000] Loss: 0.0005169 (Best: 0.0003881 @iter6961) ([91m↑17.46%[0m) [0.21% of initial]
[Iter 6980/20000] Loss: 0.0005243 (Best: 0.0003881 @iter6961) ([91m↑1.42%[0m) [0.21% of initial]
[Iter 6990/20000] Loss: 0.0004692 (Best: 0.0003881 @iter6961) ([92m↓10.51%[0m) [0.19% of initial]
Iter:6999, L1 loss=0.0006212, Total loss=0.0005596, Time:98
[Iter 7000/20000] Loss: 0.0004719 (Best: 0.0003852 @iter6997) ([91m↑0.58%[0m) [0.19% of initial]
Pruning 66 points (0.0%) from gaussian0 at iteration 7000
Pruning 48 points (0.0%) from gaussian1 at iteration 7000
[Iter 7010/20000] Loss: 0.0014039 (Best: 0.0003852 @iter6997) ([91m↑197.50%[0m) [0.56% of initial]
[Iter 7020/20000] Loss: 0.0009440 (Best: 0.0003852 @iter6997) ([92m↓32.76%[0m) [0.38% of initial]
[Iter 7030/20000] Loss: 0.0006830 (Best: 0.0003852 @iter6997) ([92m↓27.65%[0m) [0.27% of initial]
[Iter 7040/20000] Loss: 0.0005635 (Best: 0.0003852 @iter6997) ([92m↓17.50%[0m) [0.22% of initial]
[Iter 7050/20000] Loss: 0.0005347 (Best: 0.0003852 @iter6997) ([92m↓5.10%[0m) [0.21% of initial]
[Iter 7060/20000] Loss: 0.0005687 (Best: 0.0003852 @iter6997) ([91m↑6.36%[0m) [0.23% of initial]
[Iter 7070/20000] Loss: 0.0005032 (Best: 0.0003852 @iter6997) ([92m↓11.52%[0m) [0.20% of initial]
[Iter 7080/20000] Loss: 0.0005173 (Best: 0.0003852 @iter6997) ([91m↑2.80%[0m) [0.21% of initial]
[Iter 7090/20000] Loss: 0.0005387 (Best: 0.0003852 @iter6997) ([91m↑4.13%[0m) [0.21% of initial]
Iter:7099, L1 loss=0.0005161, Total loss=0.0004838, Time:81
[Iter 7100/20000] Loss: 0.0005060 (Best: 0.0003852 @iter6997) ([92m↓6.06%[0m) [0.20% of initial]
[Iter 7110/20000] Loss: 0.0005164 (Best: 0.0003852 @iter6997) ([91m↑2.06%[0m) [0.21% of initial]
[Iter 7120/20000] Loss: 0.0004799 (Best: 0.0003852 @iter6997) ([92m↓7.08%[0m) [0.19% of initial]
[Iter 7130/20000] Loss: 0.0004646 (Best: 0.0003852 @iter6997) ([92m↓3.19%[0m) [0.18% of initial]
[Iter 7140/20000] Loss: 0.0005537 (Best: 0.0003852 @iter6997) ([91m↑19.18%[0m) [0.22% of initial]
[Iter 7150/20000] Loss: 0.0004907 (Best: 0.0003852 @iter6997) ([92m↓11.38%[0m) [0.19% of initial]
[Iter 7160/20000] Loss: 0.0004909 (Best: 0.0003852 @iter6997) ([91m↑0.04%[0m) [0.20% of initial]
[Iter 7170/20000] Loss: 0.0005046 (Best: 0.0003852 @iter6997) ([91m↑2.80%[0m) [0.20% of initial]
[Iter 7180/20000] Loss: 0.0005118 (Best: 0.0003852 @iter6997) ([91m↑1.42%[0m) [0.20% of initial]
[Iter 7190/20000] Loss: 0.0004364 (Best: 0.0003852 @iter6997) ([92m↓14.73%[0m) [0.17% of initial]
Iter:7199, L1 loss=0.0005095, Total loss=0.0004551, Time:78
[Iter 7200/20000] Loss: 0.0004629 (Best: 0.0003852 @iter6997) ([91m↑6.07%[0m) [0.18% of initial]
[Iter 7210/20000] Loss: 0.0011313 (Best: 0.0003852 @iter6997) ([91m↑144.40%[0m) [0.45% of initial]
[Iter 7220/20000] Loss: 0.0009720 (Best: 0.0003852 @iter6997) ([92m↓14.08%[0m) [0.39% of initial]
[Iter 7230/20000] Loss: 0.0007362 (Best: 0.0003852 @iter6997) ([92m↓24.27%[0m) [0.29% of initial]
[Iter 7240/20000] Loss: 0.0006044 (Best: 0.0003852 @iter6997) ([92m↓17.90%[0m) [0.24% of initial]
[Iter 7250/20000] Loss: 0.0005029 (Best: 0.0003852 @iter6997) ([92m↓16.80%[0m) [0.20% of initial]
[Iter 7260/20000] Loss: 0.0004792 (Best: 0.0003852 @iter6997) ([92m↓4.70%[0m) [0.19% of initial]
[Iter 7270/20000] Loss: 0.0004447 (Best: 0.0003852 @iter6997) ([92m↓7.20%[0m) [0.18% of initial]
[Iter 7280/20000] Loss: 0.0004350 (Best: 0.0003735 @iter7276) ([92m↓2.19%[0m) [0.17% of initial]
[Iter 7290/20000] Loss: 0.0004547 (Best: 0.0003735 @iter7276) ([91m↑4.54%[0m) [0.18% of initial]
Iter:7299, L1 loss=0.0005753, Total loss=0.000523, Time:80
[Iter 7300/20000] Loss: 0.0004699 (Best: 0.0003735 @iter7276) ([91m↑3.33%[0m) [0.19% of initial]
[Iter 7310/20000] Loss: 0.0004595 (Best: 0.0003735 @iter7276) ([92m↓2.21%[0m) [0.18% of initial]
[Iter 7320/20000] Loss: 0.0005395 (Best: 0.0003735 @iter7276) ([91m↑17.40%[0m) [0.21% of initial]
[Iter 7330/20000] Loss: 0.0005086 (Best: 0.0003735 @iter7276) ([92m↓5.73%[0m) [0.20% of initial]
[Iter 7340/20000] Loss: 0.0004574 (Best: 0.0003735 @iter7276) ([92m↓10.07%[0m) [0.18% of initial]
[Iter 7350/20000] Loss: 0.0005049 (Best: 0.0003735 @iter7276) ([91m↑10.40%[0m) [0.20% of initial]
[Iter 7360/20000] Loss: 0.0005086 (Best: 0.0003735 @iter7276) ([91m↑0.72%[0m) [0.20% of initial]
[Iter 7370/20000] Loss: 0.0004473 (Best: 0.0003735 @iter7276) ([92m↓12.05%[0m) [0.18% of initial]
[Iter 7380/20000] Loss: 0.0005740 (Best: 0.0003735 @iter7276) ([91m↑28.34%[0m) [0.23% of initial]
[Iter 7390/20000] Loss: 0.0006045 (Best: 0.0003735 @iter7276) ([91m↑5.30%[0m) [0.24% of initial]
Iter:7399, L1 loss=0.0006546, Total loss=0.000552, Time:105
[Iter 7400/20000] Loss: 0.0005888 (Best: 0.0003735 @iter7276) ([92m↓2.59%[0m) [0.23% of initial]
[Iter 7410/20000] Loss: 0.0012316 (Best: 0.0003735 @iter7276) ([91m↑109.16%[0m) [0.49% of initial]
[Iter 7420/20000] Loss: 0.0008790 (Best: 0.0003735 @iter7276) ([92m↓28.63%[0m) [0.35% of initial]
[Iter 7430/20000] Loss: 0.0006913 (Best: 0.0003735 @iter7276) ([92m↓21.36%[0m) [0.27% of initial]
[Iter 7440/20000] Loss: 0.0006236 (Best: 0.0003735 @iter7276) ([92m↓9.79%[0m) [0.25% of initial]
[Iter 7450/20000] Loss: 0.0005531 (Best: 0.0003735 @iter7276) ([92m↓11.30%[0m) [0.22% of initial]
[Iter 7460/20000] Loss: 0.0005187 (Best: 0.0003735 @iter7276) ([92m↓6.23%[0m) [0.21% of initial]
[Iter 7470/20000] Loss: 0.0004957 (Best: 0.0003735 @iter7276) ([92m↓4.44%[0m) [0.20% of initial]
[Iter 7480/20000] Loss: 0.0004887 (Best: 0.0003735 @iter7276) ([92m↓1.40%[0m) [0.19% of initial]
[Iter 7490/20000] Loss: 0.0004230 (Best: 0.0003735 @iter7276) ([92m↓13.44%[0m) [0.17% of initial]
Iter:7499, L1 loss=0.0005078, Total loss=0.0004512, Time:80
[Iter 7500/20000] Loss: 0.0004675 (Best: 0.0003735 @iter7276) ([91m↑10.50%[0m) [0.19% of initial]
Pruning 85 points (0.0%) from gaussian0 at iteration 7500
Pruning 44 points (0.0%) from gaussian1 at iteration 7500
[Iter 7510/20000] Loss: 0.0011593 (Best: 0.0003735 @iter7276) ([91m↑147.99%[0m) [0.46% of initial]
[Iter 7520/20000] Loss: 0.0007617 (Best: 0.0003735 @iter7276) ([92m↓34.30%[0m) [0.30% of initial]
[Iter 7530/20000] Loss: 0.0005830 (Best: 0.0003735 @iter7276) ([92m↓23.46%[0m) [0.23% of initial]
[Iter 7540/20000] Loss: 0.0004248 (Best: 0.0003735 @iter7276) ([92m↓27.14%[0m) [0.17% of initial]
[Iter 7550/20000] Loss: 0.0004213 (Best: 0.0003735 @iter7276) ([92m↓0.81%[0m) [0.17% of initial]
[Iter 7560/20000] Loss: 0.0004168 (Best: 0.0003717 @iter7555) ([92m↓1.07%[0m) [0.17% of initial]
[Iter 7570/20000] Loss: 0.0004420 (Best: 0.0003620 @iter7561) ([91m↑6.04%[0m) [0.18% of initial]
[Iter 7580/20000] Loss: 0.0004680 (Best: 0.0003620 @iter7561) ([91m↑5.89%[0m) [0.19% of initial]
[Iter 7590/20000] Loss: 0.0004777 (Best: 0.0003620 @iter7561) ([91m↑2.08%[0m) [0.19% of initial]
Iter:7599, L1 loss=0.0004777, Total loss=0.0004139, Time:100
[Iter 7600/20000] Loss: 0.0004242 (Best: 0.0003620 @iter7561) ([92m↓11.20%[0m) [0.17% of initial]
[Iter 7610/20000] Loss: 0.0012483 (Best: 0.0003620 @iter7561) ([91m↑194.26%[0m) [0.50% of initial]
[Iter 7620/20000] Loss: 0.0008204 (Best: 0.0003620 @iter7561) ([92m↓34.28%[0m) [0.33% of initial]
[Iter 7630/20000] Loss: 0.0006678 (Best: 0.0003620 @iter7561) ([92m↓18.60%[0m) [0.27% of initial]
[Iter 7640/20000] Loss: 0.0005650 (Best: 0.0003620 @iter7561) ([92m↓15.39%[0m) [0.22% of initial]
[Iter 7650/20000] Loss: 0.0004929 (Best: 0.0003620 @iter7561) ([92m↓12.77%[0m) [0.20% of initial]
[Iter 7660/20000] Loss: 0.0004126 (Best: 0.0003620 @iter7561) ([92m↓16.29%[0m) [0.16% of initial]
[Iter 7670/20000] Loss: 0.0003893 (Best: 0.0003620 @iter7561) ([92m↓5.63%[0m) [0.15% of initial]
[Iter 7680/20000] Loss: 0.0004265 (Best: 0.0003620 @iter7561) ([91m↑9.54%[0m) [0.17% of initial]
[Iter 7690/20000] Loss: 0.0003986 (Best: 0.0003595 @iter7690) ([92m↓6.53%[0m) [0.16% of initial]
Iter:7699, L1 loss=0.0004399, Total loss=0.0003836, Time:81
[Iter 7700/20000] Loss: 0.0003955 (Best: 0.0003595 @iter7690) ([92m↓0.79%[0m) [0.16% of initial]
[Iter 7710/20000] Loss: 0.0004146 (Best: 0.0003595 @iter7690) ([91m↑4.84%[0m) [0.16% of initial]
[Iter 7720/20000] Loss: 0.0003922 (Best: 0.0003476 @iter7714) ([92m↓5.42%[0m) [0.16% of initial]
[Iter 7730/20000] Loss: 0.0003865 (Best: 0.0003421 @iter7726) ([92m↓1.43%[0m) [0.15% of initial]
[Iter 7740/20000] Loss: 0.0003876 (Best: 0.0003363 @iter7738) ([91m↑0.27%[0m) [0.15% of initial]
[Iter 7750/20000] Loss: 0.0004293 (Best: 0.0003363 @iter7738) ([91m↑10.75%[0m) [0.17% of initial]
[Iter 7760/20000] Loss: 0.0004779 (Best: 0.0003363 @iter7738) ([91m↑11.32%[0m) [0.19% of initial]
[Iter 7770/20000] Loss: 0.0004606 (Best: 0.0003363 @iter7738) ([92m↓3.62%[0m) [0.18% of initial]
[Iter 7780/20000] Loss: 0.0004555 (Best: 0.0003363 @iter7738) ([92m↓1.10%[0m) [0.18% of initial]
[Iter 7790/20000] Loss: 0.0004618 (Best: 0.0003363 @iter7738) ([91m↑1.39%[0m) [0.18% of initial]
Iter:7799, L1 loss=0.000477, Total loss=0.0004039, Time:80
[Iter 7800/20000] Loss: 0.0004597 (Best: 0.0003363 @iter7738) ([92m↓0.47%[0m) [0.18% of initial]
[Iter 7810/20000] Loss: 0.0009355 (Best: 0.0003363 @iter7738) ([91m↑103.51%[0m) [0.37% of initial]
[Iter 7820/20000] Loss: 0.0007407 (Best: 0.0003363 @iter7738) ([92m↓20.82%[0m) [0.29% of initial]
[Iter 7830/20000] Loss: 0.0006213 (Best: 0.0003363 @iter7738) ([92m↓16.13%[0m) [0.25% of initial]
[Iter 7840/20000] Loss: 0.0005413 (Best: 0.0003363 @iter7738) ([92m↓12.87%[0m) [0.22% of initial]
[Iter 7850/20000] Loss: 0.0005316 (Best: 0.0003363 @iter7738) ([92m↓1.80%[0m) [0.21% of initial]
[Iter 7860/20000] Loss: 0.0005336 (Best: 0.0003363 @iter7738) ([91m↑0.37%[0m) [0.21% of initial]
[Iter 7870/20000] Loss: 0.0004908 (Best: 0.0003363 @iter7738) ([92m↓8.01%[0m) [0.20% of initial]
[Iter 7880/20000] Loss: 0.0004395 (Best: 0.0003363 @iter7738) ([92m↓10.47%[0m) [0.17% of initial]
[Iter 7890/20000] Loss: 0.0005412 (Best: 0.0003363 @iter7738) ([91m↑23.16%[0m) [0.22% of initial]
Iter:7899, L1 loss=0.0004917, Total loss=0.0004532, Time:77
[Iter 7900/20000] Loss: 0.0004596 (Best: 0.0003363 @iter7738) ([92m↓15.08%[0m) [0.18% of initial]
[Iter 7910/20000] Loss: 0.0004578 (Best: 0.0003363 @iter7738) ([92m↓0.40%[0m) [0.18% of initial]
[Iter 7920/20000] Loss: 0.0005457 (Best: 0.0003363 @iter7738) ([91m↑19.20%[0m) [0.22% of initial]
[Iter 7930/20000] Loss: 0.0004560 (Best: 0.0003363 @iter7738) ([92m↓16.44%[0m) [0.18% of initial]
[Iter 7940/20000] Loss: 0.0004063 (Best: 0.0003363 @iter7738) ([92m↓10.90%[0m) [0.16% of initial]
[Iter 7950/20000] Loss: 0.0003949 (Best: 0.0003363 @iter7738) ([92m↓2.80%[0m) [0.16% of initial]
[Iter 7960/20000] Loss: 0.0004666 (Best: 0.0003363 @iter7738) ([91m↑18.15%[0m) [0.19% of initial]
[Iter 7970/20000] Loss: 0.0004591 (Best: 0.0003363 @iter7738) ([92m↓1.61%[0m) [0.18% of initial]
[Iter 7980/20000] Loss: 0.0004577 (Best: 0.0003363 @iter7738) ([92m↓0.30%[0m) [0.18% of initial]
[Iter 7990/20000] Loss: 0.0004103 (Best: 0.0003363 @iter7738) ([92m↓10.36%[0m) [0.16% of initial]
Iter:7999, L1 loss=0.0004659, Total loss=0.0004004, Time:81
[Iter 8000/20000] Loss: 0.0004075 (Best: 0.0003363 @iter7738) ([92m↓0.68%[0m) [0.16% of initial]
Pruning 66 points (0.0%) from gaussian0 at iteration 8000
Pruning 37 points (0.0%) from gaussian1 at iteration 8000
[Iter 8010/20000] Loss: 0.0424341 (Best: 0.0003363 @iter7738) ([91m↑10313.77%[0m) [16.86% of initial]
[Iter 8020/20000] Loss: 0.0175588 (Best: 0.0003363 @iter7738) ([92m↓58.62%[0m) [6.98% of initial]
[Iter 8030/20000] Loss: 0.0052531 (Best: 0.0003363 @iter7738) ([92m↓70.08%[0m) [2.09% of initial]
[Iter 8040/20000] Loss: 0.0040949 (Best: 0.0003363 @iter7738) ([92m↓22.05%[0m) [1.63% of initial]
[Iter 8050/20000] Loss: 0.0022531 (Best: 0.0003363 @iter7738) ([92m↓44.98%[0m) [0.90% of initial]
[Iter 8060/20000] Loss: 0.0015449 (Best: 0.0003363 @iter7738) ([92m↓31.43%[0m) [0.61% of initial]
[Iter 8070/20000] Loss: 0.0012354 (Best: 0.0003363 @iter7738) ([92m↓20.04%[0m) [0.49% of initial]
[Iter 8080/20000] Loss: 0.0009614 (Best: 0.0003363 @iter7738) ([92m↓22.18%[0m) [0.38% of initial]
[Iter 8090/20000] Loss: 0.0008007 (Best: 0.0003363 @iter7738) ([92m↓16.71%[0m) [0.32% of initial]
Iter:8099, L1 loss=0.0007377, Total loss=0.0007038, Time:107
[Iter 8100/20000] Loss: 0.0007687 (Best: 0.0003363 @iter7738) ([92m↓4.00%[0m) [0.31% of initial]
[Iter 8110/20000] Loss: 0.0006718 (Best: 0.0003363 @iter7738) ([92m↓12.60%[0m) [0.27% of initial]
[Iter 8120/20000] Loss: 0.0006027 (Best: 0.0003363 @iter7738) ([92m↓10.28%[0m) [0.24% of initial]
[Iter 8130/20000] Loss: 0.0006317 (Best: 0.0003363 @iter7738) ([91m↑4.81%[0m) [0.25% of initial]
[Iter 8140/20000] Loss: 0.0006007 (Best: 0.0003363 @iter7738) ([92m↓4.91%[0m) [0.24% of initial]
[Iter 8150/20000] Loss: 0.0005864 (Best: 0.0003363 @iter7738) ([92m↓2.37%[0m) [0.23% of initial]
[Iter 8160/20000] Loss: 0.0005860 (Best: 0.0003363 @iter7738) ([92m↓0.08%[0m) [0.23% of initial]
[Iter 8170/20000] Loss: 0.0005699 (Best: 0.0003363 @iter7738) ([92m↓2.74%[0m) [0.23% of initial]
[Iter 8180/20000] Loss: 0.0005718 (Best: 0.0003363 @iter7738) ([91m↑0.33%[0m) [0.23% of initial]
[Iter 8190/20000] Loss: 0.0005495 (Best: 0.0003363 @iter7738) ([92m↓3.90%[0m) [0.22% of initial]
Iter:8199, L1 loss=0.0006044, Total loss=0.0005573, Time:98
[Iter 8200/20000] Loss: 0.0005325 (Best: 0.0003363 @iter7738) ([92m↓3.09%[0m) [0.21% of initial]
[Iter 8210/20000] Loss: 0.0005056 (Best: 0.0003363 @iter7738) ([92m↓5.05%[0m) [0.20% of initial]
[Iter 8220/20000] Loss: 0.0005146 (Best: 0.0003363 @iter7738) ([91m↑1.78%[0m) [0.20% of initial]
[Iter 8230/20000] Loss: 0.0005243 (Best: 0.0003363 @iter7738) ([91m↑1.89%[0m) [0.21% of initial]
[Iter 8240/20000] Loss: 0.0005179 (Best: 0.0003363 @iter7738) ([92m↓1.23%[0m) [0.21% of initial]
[Iter 8250/20000] Loss: 0.0005586 (Best: 0.0003363 @iter7738) ([91m↑7.87%[0m) [0.22% of initial]
[Iter 8260/20000] Loss: 0.0005421 (Best: 0.0003363 @iter7738) ([92m↓2.95%[0m) [0.22% of initial]
[Iter 8270/20000] Loss: 0.0005470 (Best: 0.0003363 @iter7738) ([91m↑0.91%[0m) [0.22% of initial]
[Iter 8280/20000] Loss: 0.0005278 (Best: 0.0003363 @iter7738) ([92m↓3.52%[0m) [0.21% of initial]
[Iter 8290/20000] Loss: 0.0005567 (Best: 0.0003363 @iter7738) ([91m↑5.47%[0m) [0.22% of initial]
Iter:8299, L1 loss=0.0005516, Total loss=0.0005017, Time:91
[Iter 8300/20000] Loss: 0.0005393 (Best: 0.0003363 @iter7738) ([92m↓3.12%[0m) [0.21% of initial]
[Iter 8310/20000] Loss: 0.0005080 (Best: 0.0003363 @iter7738) ([92m↓5.82%[0m) [0.20% of initial]
[Iter 8320/20000] Loss: 0.0004781 (Best: 0.0003363 @iter7738) ([92m↓5.87%[0m) [0.19% of initial]
[Iter 8330/20000] Loss: 0.0004837 (Best: 0.0003363 @iter7738) ([91m↑1.15%[0m) [0.19% of initial]
[Iter 8340/20000] Loss: 0.0005035 (Best: 0.0003363 @iter7738) ([91m↑4.10%[0m) [0.20% of initial]
[Iter 8350/20000] Loss: 0.0004564 (Best: 0.0003363 @iter7738) ([92m↓9.35%[0m) [0.18% of initial]
[Iter 8360/20000] Loss: 0.0004613 (Best: 0.0003363 @iter7738) ([91m↑1.08%[0m) [0.18% of initial]
[Iter 8370/20000] Loss: 0.0004547 (Best: 0.0003363 @iter7738) ([92m↓1.44%[0m) [0.18% of initial]
[Iter 8380/20000] Loss: 0.0004728 (Best: 0.0003363 @iter7738) ([91m↑3.99%[0m) [0.19% of initial]
[Iter 8390/20000] Loss: 0.0004328 (Best: 0.0003363 @iter7738) ([92m↓8.46%[0m) [0.17% of initial]
Iter:8399, L1 loss=0.0005017, Total loss=0.0004449, Time:88
[Iter 8400/20000] Loss: 0.0004772 (Best: 0.0003363 @iter7738) ([91m↑10.25%[0m) [0.19% of initial]
[Iter 8410/20000] Loss: 0.0004574 (Best: 0.0003363 @iter7738) ([92m↓4.14%[0m) [0.18% of initial]
[Iter 8420/20000] Loss: 0.0004495 (Best: 0.0003363 @iter7738) ([92m↓1.73%[0m) [0.18% of initial]
[Iter 8430/20000] Loss: 0.0004782 (Best: 0.0003363 @iter7738) ([91m↑6.37%[0m) [0.19% of initial]
[Iter 8440/20000] Loss: 0.0004530 (Best: 0.0003363 @iter7738) ([92m↓5.27%[0m) [0.18% of initial]
[Iter 8450/20000] Loss: 0.0004866 (Best: 0.0003363 @iter7738) ([91m↑7.42%[0m) [0.19% of initial]
[Iter 8460/20000] Loss: 0.0004639 (Best: 0.0003363 @iter7738) ([92m↓4.67%[0m) [0.18% of initial]
[Iter 8470/20000] Loss: 0.0004841 (Best: 0.0003363 @iter7738) ([91m↑4.37%[0m) [0.19% of initial]
[Iter 8480/20000] Loss: 0.0004657 (Best: 0.0003363 @iter7738) ([92m↓3.81%[0m) [0.19% of initial]
[Iter 8490/20000] Loss: 0.0004832 (Best: 0.0003363 @iter7738) ([91m↑3.75%[0m) [0.19% of initial]
Iter:8499, L1 loss=0.0005621, Total loss=0.0005079, Time:89
[Iter 8500/20000] Loss: 0.0005031 (Best: 0.0003363 @iter7738) ([91m↑4.13%[0m) [0.20% of initial]
Pruning 131 points (0.1%) from gaussian0 at iteration 8500
Pruning 77 points (0.0%) from gaussian1 at iteration 8500
[Iter 8510/20000] Loss: 0.0011149 (Best: 0.0003363 @iter7738) ([91m↑121.59%[0m) [0.44% of initial]
[Iter 8520/20000] Loss: 0.0007830 (Best: 0.0003363 @iter7738) ([92m↓29.77%[0m) [0.31% of initial]
[Iter 8530/20000] Loss: 0.0006068 (Best: 0.0003363 @iter7738) ([92m↓22.50%[0m) [0.24% of initial]
[Iter 8540/20000] Loss: 0.0005501 (Best: 0.0003363 @iter7738) ([92m↓9.34%[0m) [0.22% of initial]
[Iter 8550/20000] Loss: 0.0005148 (Best: 0.0003363 @iter7738) ([92m↓6.41%[0m) [0.20% of initial]
[Iter 8560/20000] Loss: 0.0005018 (Best: 0.0003363 @iter7738) ([92m↓2.53%[0m) [0.20% of initial]
[Iter 8570/20000] Loss: 0.0004946 (Best: 0.0003363 @iter7738) ([92m↓1.43%[0m) [0.20% of initial]
[Iter 8580/20000] Loss: 0.0004886 (Best: 0.0003363 @iter7738) ([92m↓1.21%[0m) [0.19% of initial]
[Iter 8590/20000] Loss: 0.0004672 (Best: 0.0003363 @iter7738) ([92m↓4.38%[0m) [0.19% of initial]
Iter:8599, L1 loss=0.0004833, Total loss=0.0004246, Time:90
[Iter 8600/20000] Loss: 0.0004592 (Best: 0.0003363 @iter7738) ([92m↓1.72%[0m) [0.18% of initial]
[Iter 8610/20000] Loss: 0.0004804 (Best: 0.0003363 @iter7738) ([91m↑4.62%[0m) [0.19% of initial]
[Iter 8620/20000] Loss: 0.0004770 (Best: 0.0003363 @iter7738) ([92m↓0.70%[0m) [0.19% of initial]
[Iter 8630/20000] Loss: 0.0004700 (Best: 0.0003363 @iter7738) ([92m↓1.47%[0m) [0.19% of initial]
[Iter 8640/20000] Loss: 0.0004471 (Best: 0.0003363 @iter7738) ([92m↓4.88%[0m) [0.18% of initial]
[Iter 8650/20000] Loss: 0.0004624 (Best: 0.0003363 @iter7738) ([91m↑3.41%[0m) [0.18% of initial]
[Iter 8660/20000] Loss: 0.0005018 (Best: 0.0003363 @iter7738) ([91m↑8.53%[0m) [0.20% of initial]
[Iter 8670/20000] Loss: 0.0005112 (Best: 0.0003363 @iter7738) ([91m↑1.87%[0m) [0.20% of initial]
[Iter 8680/20000] Loss: 0.0004713 (Best: 0.0003363 @iter7738) ([92m↓7.79%[0m) [0.19% of initial]
[Iter 8690/20000] Loss: 0.0005586 (Best: 0.0003363 @iter7738) ([91m↑18.51%[0m) [0.22% of initial]
Iter:8699, L1 loss=0.0005495, Total loss=0.0004902, Time:91
[Iter 8700/20000] Loss: 0.0005044 (Best: 0.0003363 @iter7738) ([92m↓9.70%[0m) [0.20% of initial]
[Iter 8710/20000] Loss: 0.0004838 (Best: 0.0003363 @iter7738) ([92m↓4.08%[0m) [0.19% of initial]
[Iter 8720/20000] Loss: 0.0004665 (Best: 0.0003363 @iter7738) ([92m↓3.58%[0m) [0.19% of initial]
[Iter 8730/20000] Loss: 0.0004975 (Best: 0.0003363 @iter7738) ([91m↑6.64%[0m) [0.20% of initial]
[Iter 8740/20000] Loss: 0.0004756 (Best: 0.0003363 @iter7738) ([92m↓4.40%[0m) [0.19% of initial]
[Iter 8750/20000] Loss: 0.0005551 (Best: 0.0003363 @iter7738) ([91m↑16.72%[0m) [0.22% of initial]
[Iter 8760/20000] Loss: 0.0005248 (Best: 0.0003363 @iter7738) ([92m↓5.46%[0m) [0.21% of initial]
[Iter 8770/20000] Loss: 0.0005376 (Best: 0.0003363 @iter7738) ([91m↑2.44%[0m) [0.21% of initial]
[Iter 8780/20000] Loss: 0.0005223 (Best: 0.0003363 @iter7738) ([92m↓2.85%[0m) [0.21% of initial]
[Iter 8790/20000] Loss: 0.0005153 (Best: 0.0003363 @iter7738) ([92m↓1.34%[0m) [0.20% of initial]
Iter:8799, L1 loss=0.0005922, Total loss=0.0005418, Time:108
[Iter 8800/20000] Loss: 0.0004883 (Best: 0.0003363 @iter7738) ([92m↓5.23%[0m) [0.19% of initial]
[Iter 8810/20000] Loss: 0.0004430 (Best: 0.0003363 @iter7738) ([92m↓9.28%[0m) [0.18% of initial]
[Iter 8820/20000] Loss: 0.0005122 (Best: 0.0003363 @iter7738) ([91m↑15.61%[0m) [0.20% of initial]
[Iter 8830/20000] Loss: 0.0006260 (Best: 0.0003363 @iter7738) ([91m↑22.21%[0m) [0.25% of initial]
[Iter 8840/20000] Loss: 0.0005684 (Best: 0.0003363 @iter7738) ([92m↓9.20%[0m) [0.23% of initial]
[Iter 8850/20000] Loss: 0.0005935 (Best: 0.0003363 @iter7738) ([91m↑4.42%[0m) [0.24% of initial]
[Iter 8860/20000] Loss: 0.0005049 (Best: 0.0003363 @iter7738) ([92m↓14.93%[0m) [0.20% of initial]
[Iter 8870/20000] Loss: 0.0004766 (Best: 0.0003363 @iter7738) ([92m↓5.61%[0m) [0.19% of initial]
[Iter 8880/20000] Loss: 0.0004708 (Best: 0.0003363 @iter7738) ([92m↓1.20%[0m) [0.19% of initial]
[Iter 8890/20000] Loss: 0.0004412 (Best: 0.0003363 @iter7738) ([92m↓6.31%[0m) [0.18% of initial]
Iter:8899, L1 loss=0.0004826, Total loss=0.000444, Time:85
[Iter 8900/20000] Loss: 0.0004826 (Best: 0.0003363 @iter7738) ([91m↑9.40%[0m) [0.19% of initial]
[Iter 8910/20000] Loss: 0.0004713 (Best: 0.0003363 @iter7738) ([92m↓2.34%[0m) [0.19% of initial]
[Iter 8920/20000] Loss: 0.0004591 (Best: 0.0003363 @iter7738) ([92m↓2.59%[0m) [0.18% of initial]
[Iter 8930/20000] Loss: 0.0004714 (Best: 0.0003363 @iter7738) ([91m↑2.67%[0m) [0.19% of initial]
[Iter 8940/20000] Loss: 0.0004704 (Best: 0.0003363 @iter7738) ([92m↓0.20%[0m) [0.19% of initial]
[Iter 8950/20000] Loss: 0.0004993 (Best: 0.0003363 @iter7738) ([91m↑6.15%[0m) [0.20% of initial]
[Iter 8960/20000] Loss: 0.0005001 (Best: 0.0003363 @iter7738) ([91m↑0.16%[0m) [0.20% of initial]
[Iter 8970/20000] Loss: 0.0005736 (Best: 0.0003363 @iter7738) ([91m↑14.70%[0m) [0.23% of initial]
[Iter 8980/20000] Loss: 0.0005440 (Best: 0.0003363 @iter7738) ([92m↓5.17%[0m) [0.22% of initial]
[Iter 8990/20000] Loss: 0.0005038 (Best: 0.0003363 @iter7738) ([92m↓7.38%[0m) [0.20% of initial]
Iter:8999, L1 loss=0.0004656, Total loss=0.0004263, Time:90
[Iter 9000/20000] Loss: 0.0004635 (Best: 0.0003363 @iter7738) ([92m↓8.01%[0m) [0.18% of initial]
Pruning 52 points (0.0%) from gaussian0 at iteration 9000
Pruning 56 points (0.0%) from gaussian1 at iteration 9000
[Iter 9010/20000] Loss: 0.0008612 (Best: 0.0003363 @iter7738) ([91m↑85.82%[0m) [0.34% of initial]
[Iter 9020/20000] Loss: 0.0006632 (Best: 0.0003363 @iter7738) ([92m↓23.00%[0m) [0.26% of initial]
[Iter 9030/20000] Loss: 0.0005373 (Best: 0.0003363 @iter7738) ([92m↓18.98%[0m) [0.21% of initial]
[Iter 9040/20000] Loss: 0.0004855 (Best: 0.0003363 @iter7738) ([92m↓9.64%[0m) [0.19% of initial]
[Iter 9050/20000] Loss: 0.0004482 (Best: 0.0003363 @iter7738) ([92m↓7.67%[0m) [0.18% of initial]
[Iter 9060/20000] Loss: 0.0004682 (Best: 0.0003363 @iter7738) ([91m↑4.46%[0m) [0.19% of initial]
[Iter 9070/20000] Loss: 0.0004838 (Best: 0.0003363 @iter7738) ([91m↑3.32%[0m) [0.19% of initial]
[Iter 9080/20000] Loss: 0.0005074 (Best: 0.0003363 @iter7738) ([91m↑4.88%[0m) [0.20% of initial]
[Iter 9090/20000] Loss: 0.0004789 (Best: 0.0003363 @iter7738) ([92m↓5.61%[0m) [0.19% of initial]
Iter:9099, L1 loss=0.0005859, Total loss=0.0005215, Time:94
[Iter 9100/20000] Loss: 0.0004811 (Best: 0.0003363 @iter7738) ([91m↑0.45%[0m) [0.19% of initial]
[Iter 9110/20000] Loss: 0.0005556 (Best: 0.0003363 @iter7738) ([91m↑15.48%[0m) [0.22% of initial]
[Iter 9120/20000] Loss: 0.0004842 (Best: 0.0003363 @iter7738) ([92m↓12.85%[0m) [0.19% of initial]
[Iter 9130/20000] Loss: 0.0005486 (Best: 0.0003363 @iter7738) ([91m↑13.32%[0m) [0.22% of initial]
[Iter 9140/20000] Loss: 0.0004851 (Best: 0.0003363 @iter7738) ([92m↓11.59%[0m) [0.19% of initial]
[Iter 9150/20000] Loss: 0.0004412 (Best: 0.0003363 @iter7738) ([92m↓9.03%[0m) [0.18% of initial]
[Iter 9160/20000] Loss: 0.0004462 (Best: 0.0003363 @iter7738) ([91m↑1.12%[0m) [0.18% of initial]
[Iter 9170/20000] Loss: 0.0004219 (Best: 0.0003363 @iter7738) ([92m↓5.45%[0m) [0.17% of initial]
[Iter 9180/20000] Loss: 0.0004345 (Best: 0.0003363 @iter7738) ([91m↑3.00%[0m) [0.17% of initial]
[Iter 9190/20000] Loss: 0.0003956 (Best: 0.0003363 @iter7738) ([92m↓8.95%[0m) [0.16% of initial]
Iter:9199, L1 loss=0.0004646, Total loss=0.000415, Time:109
[Iter 9200/20000] Loss: 0.0004153 (Best: 0.0003363 @iter7738) ([91m↑4.98%[0m) [0.17% of initial]
[Iter 9210/20000] Loss: 0.0004293 (Best: 0.0003363 @iter7738) ([91m↑3.35%[0m) [0.17% of initial]
[Iter 9220/20000] Loss: 0.0004336 (Best: 0.0003363 @iter7738) ([91m↑1.00%[0m) [0.17% of initial]
[Iter 9230/20000] Loss: 0.0004315 (Best: 0.0003363 @iter7738) ([92m↓0.47%[0m) [0.17% of initial]
[Iter 9240/20000] Loss: 0.0004503 (Best: 0.0003363 @iter7738) ([91m↑4.36%[0m) [0.18% of initial]
[Iter 9250/20000] Loss: 0.0004427 (Best: 0.0003363 @iter7738) ([92m↓1.69%[0m) [0.18% of initial]
[Iter 9260/20000] Loss: 0.0004466 (Best: 0.0003363 @iter7738) ([91m↑0.88%[0m) [0.18% of initial]
[Iter 9270/20000] Loss: 0.0004893 (Best: 0.0003363 @iter7738) ([91m↑9.56%[0m) [0.19% of initial]
[Iter 9280/20000] Loss: 0.0004133 (Best: 0.0003363 @iter7738) ([92m↓15.55%[0m) [0.16% of initial]
[Iter 9290/20000] Loss: 0.0004052 (Best: 0.0003363 @iter7738) ([92m↓1.95%[0m) [0.16% of initial]
Iter:9299, L1 loss=0.0004447, Total loss=0.0003834, Time:91
[Iter 9300/20000] Loss: 0.0004338 (Best: 0.0003363 @iter7738) ([91m↑7.05%[0m) [0.17% of initial]
[Iter 9310/20000] Loss: 0.0004293 (Best: 0.0003363 @iter7738) ([92m↓1.04%[0m) [0.17% of initial]
[Iter 9320/20000] Loss: 0.0004335 (Best: 0.0003363 @iter7738) ([91m↑0.97%[0m) [0.17% of initial]
[Iter 9330/20000] Loss: 0.0004676 (Best: 0.0003363 @iter7738) ([91m↑7.87%[0m) [0.19% of initial]
[Iter 9340/20000] Loss: 0.0004576 (Best: 0.0003363 @iter7738) ([92m↓2.14%[0m) [0.18% of initial]
[Iter 9350/20000] Loss: 0.0004231 (Best: 0.0003363 @iter7738) ([92m↓7.55%[0m) [0.17% of initial]
[Iter 9360/20000] Loss: 0.0004703 (Best: 0.0003363 @iter7738) ([91m↑11.17%[0m) [0.19% of initial]
[Iter 9370/20000] Loss: 0.0004153 (Best: 0.0003363 @iter7738) ([92m↓11.69%[0m) [0.17% of initial]
[Iter 9380/20000] Loss: 0.0004560 (Best: 0.0003363 @iter7738) ([91m↑9.81%[0m) [0.18% of initial]
[Iter 9390/20000] Loss: 0.0004566 (Best: 0.0003363 @iter7738) ([91m↑0.11%[0m) [0.18% of initial]
Iter:9399, L1 loss=0.0005822, Total loss=0.0005559, Time:80
[Iter 9400/20000] Loss: 0.0004485 (Best: 0.0003363 @iter7738) ([92m↓1.76%[0m) [0.18% of initial]
[Iter 9410/20000] Loss: 0.0004378 (Best: 0.0003363 @iter7738) ([92m↓2.39%[0m) [0.17% of initial]
[Iter 9420/20000] Loss: 0.0004392 (Best: 0.0003363 @iter7738) ([91m↑0.33%[0m) [0.17% of initial]
[Iter 9430/20000] Loss: 0.0003994 (Best: 0.0003363 @iter7738) ([92m↓9.07%[0m) [0.16% of initial]
[Iter 9440/20000] Loss: 0.0004400 (Best: 0.0003363 @iter7738) ([91m↑10.15%[0m) [0.17% of initial]
[Iter 9450/20000] Loss: 0.0004261 (Best: 0.0003363 @iter7738) ([92m↓3.14%[0m) [0.17% of initial]
[Iter 9460/20000] Loss: 0.0003785 (Best: 0.0003363 @iter7738) ([92m↓11.17%[0m) [0.15% of initial]
[Iter 9470/20000] Loss: 0.0003715 (Best: 0.0003363 @iter7738) ([92m↓1.86%[0m) [0.15% of initial]
[Iter 9480/20000] Loss: 0.0004270 (Best: 0.0003363 @iter7738) ([91m↑14.95%[0m) [0.17% of initial]
[Iter 9490/20000] Loss: 0.0003880 (Best: 0.0003363 @iter7738) ([92m↓9.15%[0m) [0.15% of initial]
Iter:9499, L1 loss=0.0004797, Total loss=0.0004065, Time:88
[Iter 9500/20000] Loss: 0.0006520 (Best: 0.0003363 @iter7738) ([91m↑68.06%[0m) [0.26% of initial]
Pruning 70 points (0.0%) from gaussian0 at iteration 9500
Pruning 32 points (0.0%) from gaussian1 at iteration 9500
[Iter 9510/20000] Loss: 0.0007589 (Best: 0.0003363 @iter7738) ([91m↑16.39%[0m) [0.30% of initial]
[Iter 9520/20000] Loss: 0.0005687 (Best: 0.0003363 @iter7738) ([92m↓25.06%[0m) [0.23% of initial]
[Iter 9530/20000] Loss: 0.0005871 (Best: 0.0003363 @iter7738) ([91m↑3.24%[0m) [0.23% of initial]
[Iter 9540/20000] Loss: 0.0004618 (Best: 0.0003363 @iter7738) ([92m↓21.35%[0m) [0.18% of initial]
[Iter 9550/20000] Loss: 0.0004055 (Best: 0.0003363 @iter7738) ([92m↓12.19%[0m) [0.16% of initial]
[Iter 9560/20000] Loss: 0.0003857 (Best: 0.0003363 @iter7738) ([92m↓4.89%[0m) [0.15% of initial]
[Iter 9570/20000] Loss: 0.0003769 (Best: 0.0003363 @iter7738) ([92m↓2.28%[0m) [0.15% of initial]
[Iter 9580/20000] Loss: 0.0003611 (Best: 0.0003308 @iter9575) ([92m↓4.18%[0m) [0.14% of initial]
[Iter 9590/20000] Loss: 0.0003634 (Best: 0.0003308 @iter9575) ([91m↑0.63%[0m) [0.14% of initial]
Iter:9599, L1 loss=0.0005507, Total loss=0.0004415, Time:77
[Iter 9600/20000] Loss: 0.0003929 (Best: 0.0003308 @iter9575) ([91m↑8.10%[0m) [0.16% of initial]
[Iter 9610/20000] Loss: 0.0003829 (Best: 0.0003308 @iter9575) ([92m↓2.54%[0m) [0.15% of initial]
[Iter 9620/20000] Loss: 0.0003926 (Best: 0.0003308 @iter9575) ([91m↑2.54%[0m) [0.16% of initial]
[Iter 9630/20000] Loss: 0.0003747 (Best: 0.0003294 @iter9628) ([92m↓4.56%[0m) [0.15% of initial]
[Iter 9640/20000] Loss: 0.0003670 (Best: 0.0003294 @iter9628) ([92m↓2.07%[0m) [0.15% of initial]
[Iter 9650/20000] Loss: 0.0004178 (Best: 0.0003294 @iter9628) ([91m↑13.84%[0m) [0.17% of initial]
[Iter 9660/20000] Loss: 0.0003922 (Best: 0.0003294 @iter9628) ([92m↓6.12%[0m) [0.16% of initial]
[Iter 9670/20000] Loss: 0.0004304 (Best: 0.0003294 @iter9628) ([91m↑9.73%[0m) [0.17% of initial]
[Iter 9680/20000] Loss: 0.0004218 (Best: 0.0003294 @iter9628) ([92m↓2.00%[0m) [0.17% of initial]
[Iter 9690/20000] Loss: 0.0004788 (Best: 0.0003294 @iter9628) ([91m↑13.53%[0m) [0.19% of initial]
Iter:9699, L1 loss=0.0006398, Total loss=0.000547, Time:80
[Iter 9700/20000] Loss: 0.0004548 (Best: 0.0003294 @iter9628) ([92m↓5.02%[0m) [0.18% of initial]
[Iter 9710/20000] Loss: 0.0004451 (Best: 0.0003294 @iter9628) ([92m↓2.14%[0m) [0.18% of initial]
[Iter 9720/20000] Loss: 0.0004272 (Best: 0.0003294 @iter9628) ([92m↓4.02%[0m) [0.17% of initial]
[Iter 9730/20000] Loss: 0.0004014 (Best: 0.0003294 @iter9628) ([92m↓6.03%[0m) [0.16% of initial]
[Iter 9740/20000] Loss: 0.0004221 (Best: 0.0003294 @iter9628) ([91m↑5.15%[0m) [0.17% of initial]
[Iter 9750/20000] Loss: 0.0004151 (Best: 0.0003294 @iter9628) ([92m↓1.66%[0m) [0.16% of initial]
[Iter 9760/20000] Loss: 0.0003819 (Best: 0.0003294 @iter9628) ([92m↓8.00%[0m) [0.15% of initial]
[Iter 9770/20000] Loss: 0.0003834 (Best: 0.0003294 @iter9628) ([91m↑0.41%[0m) [0.15% of initial]
[Iter 9780/20000] Loss: 0.0003726 (Best: 0.0003294 @iter9628) ([92m↓2.83%[0m) [0.15% of initial]
[Iter 9790/20000] Loss: 0.0003716 (Best: 0.0003158 @iter9784) ([92m↓0.28%[0m) [0.15% of initial]
Iter:9799, L1 loss=0.0004301, Total loss=0.0003747, Time:87
[Iter 9800/20000] Loss: 0.0004019 (Best: 0.0003158 @iter9784) ([91m↑8.18%[0m) [0.16% of initial]
[Iter 9810/20000] Loss: 0.0003836 (Best: 0.0003158 @iter9784) ([92m↓4.56%[0m) [0.15% of initial]
[Iter 9820/20000] Loss: 0.0003614 (Best: 0.0003158 @iter9784) ([92m↓5.78%[0m) [0.14% of initial]
[Iter 9830/20000] Loss: 0.0003996 (Best: 0.0003158 @iter9784) ([91m↑10.57%[0m) [0.16% of initial]
[Iter 9840/20000] Loss: 0.0004173 (Best: 0.0003158 @iter9784) ([91m↑4.41%[0m) [0.17% of initial]
[Iter 9850/20000] Loss: 0.0003754 (Best: 0.0003158 @iter9784) ([92m↓10.03%[0m) [0.15% of initial]
[Iter 9860/20000] Loss: 0.0003789 (Best: 0.0003158 @iter9784) ([91m↑0.93%[0m) [0.15% of initial]
[Iter 9870/20000] Loss: 0.0004156 (Best: 0.0003158 @iter9784) ([91m↑9.68%[0m) [0.17% of initial]
[Iter 9880/20000] Loss: 0.0004245 (Best: 0.0003158 @iter9784) ([91m↑2.14%[0m) [0.17% of initial]
[Iter 9890/20000] Loss: 0.0005638 (Best: 0.0003158 @iter9784) ([91m↑32.83%[0m) [0.22% of initial]
Iter:9899, L1 loss=0.0005752, Total loss=0.0005257, Time:77
[Iter 9900/20000] Loss: 0.0004941 (Best: 0.0003158 @iter9784) ([92m↓12.35%[0m) [0.20% of initial]
[Iter 9910/20000] Loss: 0.0003981 (Best: 0.0003158 @iter9784) ([92m↓19.44%[0m) [0.16% of initial]
[Iter 9920/20000] Loss: 0.0003846 (Best: 0.0003158 @iter9784) ([92m↓3.39%[0m) [0.15% of initial]
[Iter 9930/20000] Loss: 0.0004053 (Best: 0.0003158 @iter9784) ([91m↑5.38%[0m) [0.16% of initial]
[Iter 9940/20000] Loss: 0.0003876 (Best: 0.0003158 @iter9784) ([92m↓4.36%[0m) [0.15% of initial]
[Iter 9950/20000] Loss: 0.0004302 (Best: 0.0003158 @iter9784) ([91m↑10.98%[0m) [0.17% of initial]
[Iter 9960/20000] Loss: 0.0004270 (Best: 0.0003158 @iter9784) ([92m↓0.75%[0m) [0.17% of initial]
[Iter 9970/20000] Loss: 0.0003968 (Best: 0.0003158 @iter9784) ([92m↓7.07%[0m) [0.16% of initial]
[Iter 9980/20000] Loss: 0.0003946 (Best: 0.0003158 @iter9784) ([92m↓0.55%[0m) [0.16% of initial]
[Iter 9990/20000] Loss: 0.0004141 (Best: 0.0003158 @iter9784) ([91m↑4.94%[0m) [0.16% of initial]
Iter:9999, L1 loss=0.0006974, Total loss=0.0005589, Time:79
[Iter 10000/20000] Loss: 0.0004912 (Best: 0.0003158 @iter9784) ([91m↑18.63%[0m) [0.20% of initial]
Pruning 29 points (0.0%) from gaussian0 at iteration 10000
Pruning 29 points (0.0%) from gaussian1 at iteration 10000
[Iter 10010/20000] Loss: 0.0007251 (Best: 0.0003158 @iter9784) ([91m↑47.62%[0m) [0.29% of initial]
[Iter 10020/20000] Loss: 0.0005774 (Best: 0.0003158 @iter9784) ([92m↓20.37%[0m) [0.23% of initial]
[Iter 10030/20000] Loss: 0.0004282 (Best: 0.0003158 @iter9784) ([92m↓25.84%[0m) [0.17% of initial]
[Iter 10040/20000] Loss: 0.0004000 (Best: 0.0003158 @iter9784) ([92m↓6.60%[0m) [0.16% of initial]
[Iter 10050/20000] Loss: 0.0003773 (Best: 0.0003158 @iter9784) ([92m↓5.67%[0m) [0.15% of initial]
[Iter 10060/20000] Loss: 0.0003418 (Best: 0.0003158 @iter9784) ([92m↓9.41%[0m) [0.14% of initial]
[Iter 10070/20000] Loss: 0.0003384 (Best: 0.0003158 @iter9784) ([92m↓1.00%[0m) [0.13% of initial]
[Iter 10080/20000] Loss: 0.0003462 (Best: 0.0003107 @iter10072) ([91m↑2.33%[0m) [0.14% of initial]
[Iter 10090/20000] Loss: 0.0003429 (Best: 0.0003107 @iter10072) ([92m↓0.97%[0m) [0.14% of initial]
Iter:10099, L1 loss=0.0003976, Total loss=0.0003509, Time:101
[Iter 10100/20000] Loss: 0.0003642 (Best: 0.0003107 @iter10072) ([91m↑6.22%[0m) [0.14% of initial]
[Iter 10110/20000] Loss: 0.0003541 (Best: 0.0003107 @iter10072) ([92m↓2.77%[0m) [0.14% of initial]
[Iter 10120/20000] Loss: 0.0003602 (Best: 0.0003107 @iter10072) ([91m↑1.71%[0m) [0.14% of initial]
[Iter 10130/20000] Loss: 0.0003596 (Best: 0.0003107 @iter10072) ([92m↓0.17%[0m) [0.14% of initial]
[Iter 10140/20000] Loss: 0.0004118 (Best: 0.0003107 @iter10072) ([91m↑14.52%[0m) [0.16% of initial]
[Iter 10150/20000] Loss: 0.0004053 (Best: 0.0003107 @iter10072) ([92m↓1.57%[0m) [0.16% of initial]
[Iter 10160/20000] Loss: 0.0004331 (Best: 0.0003107 @iter10072) ([91m↑6.86%[0m) [0.17% of initial]
[Iter 10170/20000] Loss: 0.0003938 (Best: 0.0003107 @iter10072) ([92m↓9.09%[0m) [0.16% of initial]
[Iter 10180/20000] Loss: 0.0003414 (Best: 0.0003107 @iter10072) ([92m↓13.31%[0m) [0.14% of initial]
[Iter 10190/20000] Loss: 0.0003257 (Best: 0.0003093 @iter10183) ([92m↓4.61%[0m) [0.13% of initial]
Iter:10199, L1 loss=0.0004442, Total loss=0.0003878, Time:88
[Iter 10200/20000] Loss: 0.0003669 (Best: 0.0003093 @iter10183) ([91m↑12.66%[0m) [0.15% of initial]
[Iter 10210/20000] Loss: 0.0003434 (Best: 0.0003093 @iter10183) ([92m↓6.39%[0m) [0.14% of initial]
[Iter 10220/20000] Loss: 0.0003539 (Best: 0.0003093 @iter10183) ([91m↑3.04%[0m) [0.14% of initial]
[Iter 10230/20000] Loss: 0.0003566 (Best: 0.0003093 @iter10183) ([91m↑0.76%[0m) [0.14% of initial]
[Iter 10240/20000] Loss: 0.0003484 (Best: 0.0003060 @iter10237) ([92m↓2.29%[0m) [0.14% of initial]
[Iter 10250/20000] Loss: 0.0003511 (Best: 0.0003060 @iter10237) ([91m↑0.77%[0m) [0.14% of initial]
[Iter 10260/20000] Loss: 0.0003823 (Best: 0.0003060 @iter10237) ([91m↑8.88%[0m) [0.15% of initial]
[Iter 10270/20000] Loss: 0.0003552 (Best: 0.0003060 @iter10237) ([92m↓7.10%[0m) [0.14% of initial]
[Iter 10280/20000] Loss: 0.0003575 (Best: 0.0003060 @iter10237) ([91m↑0.67%[0m) [0.14% of initial]
[Iter 10290/20000] Loss: 0.0003877 (Best: 0.0003060 @iter10237) ([91m↑8.44%[0m) [0.15% of initial]
Iter:10299, L1 loss=0.0003996, Total loss=0.0003487, Time:102
[Iter 10300/20000] Loss: 0.0003556 (Best: 0.0003060 @iter10237) ([92m↓8.27%[0m) [0.14% of initial]
[Iter 10310/20000] Loss: 0.0003706 (Best: 0.0003055 @iter10303) ([91m↑4.21%[0m) [0.15% of initial]
[Iter 10320/20000] Loss: 0.0003687 (Best: 0.0003055 @iter10303) ([92m↓0.51%[0m) [0.15% of initial]
[Iter 10330/20000] Loss: 0.0003516 (Best: 0.0003055 @iter10303) ([92m↓4.65%[0m) [0.14% of initial]
[Iter 10340/20000] Loss: 0.0003750 (Best: 0.0003055 @iter10303) ([91m↑6.68%[0m) [0.15% of initial]
[Iter 10350/20000] Loss: 0.0003625 (Best: 0.0003055 @iter10303) ([92m↓3.35%[0m) [0.14% of initial]
[Iter 10360/20000] Loss: 0.0003797 (Best: 0.0003055 @iter10303) ([91m↑4.74%[0m) [0.15% of initial]
[Iter 10370/20000] Loss: 0.0003975 (Best: 0.0003055 @iter10303) ([91m↑4.71%[0m) [0.16% of initial]
[Iter 10380/20000] Loss: 0.0003682 (Best: 0.0003055 @iter10303) ([92m↓7.38%[0m) [0.15% of initial]
[Iter 10390/20000] Loss: 0.0003910 (Best: 0.0003055 @iter10303) ([91m↑6.20%[0m) [0.16% of initial]
Iter:10399, L1 loss=0.0003963, Total loss=0.0003553, Time:89
[Iter 10400/20000] Loss: 0.0003798 (Best: 0.0003055 @iter10303) ([92m↓2.87%[0m) [0.15% of initial]
[Iter 10410/20000] Loss: 0.0003453 (Best: 0.0003055 @iter10303) ([92m↓9.09%[0m) [0.14% of initial]
[Iter 10420/20000] Loss: 0.0003559 (Best: 0.0003055 @iter10303) ([91m↑3.07%[0m) [0.14% of initial]
[Iter 10430/20000] Loss: 0.0003980 (Best: 0.0003055 @iter10303) ([91m↑11.84%[0m) [0.16% of initial]
[Iter 10440/20000] Loss: 0.0003732 (Best: 0.0003055 @iter10303) ([92m↓6.23%[0m) [0.15% of initial]
[Iter 10450/20000] Loss: 0.0003970 (Best: 0.0003055 @iter10303) ([91m↑6.36%[0m) [0.16% of initial]
[Iter 10460/20000] Loss: 0.0003347 (Best: 0.0003055 @iter10303) ([92m↓15.69%[0m) [0.13% of initial]
[Iter 10470/20000] Loss: 0.0003951 (Best: 0.0003055 @iter10303) ([91m↑18.05%[0m) [0.16% of initial]
[Iter 10480/20000] Loss: 0.0003582 (Best: 0.0003055 @iter10303) ([92m↓9.33%[0m) [0.14% of initial]
[Iter 10490/20000] Loss: 0.0003437 (Best: 0.0003055 @iter10303) ([92m↓4.06%[0m) [0.14% of initial]
Iter:10499, L1 loss=0.0003885, Total loss=0.0003309, Time:82
[Iter 10500/20000] Loss: 0.0003410 (Best: 0.0003055 @iter10303) ([92m↓0.77%[0m) [0.14% of initial]
Pruning 45 points (0.0%) from gaussian0 at iteration 10500
Pruning 27 points (0.0%) from gaussian1 at iteration 10500
[Iter 10510/20000] Loss: 0.0006297 (Best: 0.0003055 @iter10303) ([91m↑84.66%[0m) [0.25% of initial]
[Iter 10520/20000] Loss: 0.0004912 (Best: 0.0003055 @iter10303) ([92m↓21.99%[0m) [0.20% of initial]
[Iter 10530/20000] Loss: 0.0004403 (Best: 0.0003055 @iter10303) ([92m↓10.36%[0m) [0.17% of initial]
[Iter 10540/20000] Loss: 0.0004463 (Best: 0.0003055 @iter10303) ([91m↑1.36%[0m) [0.18% of initial]
[Iter 10550/20000] Loss: 0.0003549 (Best: 0.0003055 @iter10303) ([92m↓20.48%[0m) [0.14% of initial]
[Iter 10560/20000] Loss: 0.0003420 (Best: 0.0003055 @iter10303) ([92m↓3.62%[0m) [0.14% of initial]
[Iter 10570/20000] Loss: 0.0003345 (Best: 0.0003055 @iter10303) ([92m↓2.20%[0m) [0.13% of initial]
[Iter 10580/20000] Loss: 0.0003349 (Best: 0.0003055 @iter10303) ([91m↑0.11%[0m) [0.13% of initial]
[Iter 10590/20000] Loss: 0.0003359 (Best: 0.0003001 @iter10583) ([91m↑0.31%[0m) [0.13% of initial]
Iter:10599, L1 loss=0.0003758, Total loss=0.0003183, Time:80
[Iter 10600/20000] Loss: 0.0003286 (Best: 0.0003001 @iter10583) ([92m↓2.17%[0m) [0.13% of initial]
[Iter 10610/20000] Loss: 0.0003244 (Best: 0.0002883 @iter10603) ([92m↓1.27%[0m) [0.13% of initial]
[Iter 10620/20000] Loss: 0.0003182 (Best: 0.0002883 @iter10603) ([92m↓1.91%[0m) [0.13% of initial]
[Iter 10630/20000] Loss: 0.0003371 (Best: 0.0002883 @iter10603) ([91m↑5.93%[0m) [0.13% of initial]
[Iter 10640/20000] Loss: 0.0003822 (Best: 0.0002883 @iter10603) ([91m↑13.39%[0m) [0.15% of initial]
[Iter 10650/20000] Loss: 0.0004334 (Best: 0.0002883 @iter10603) ([91m↑13.38%[0m) [0.17% of initial]
[Iter 10660/20000] Loss: 0.0003652 (Best: 0.0002883 @iter10603) ([92m↓15.74%[0m) [0.15% of initial]
[Iter 10670/20000] Loss: 0.0003535 (Best: 0.0002883 @iter10603) ([92m↓3.20%[0m) [0.14% of initial]
[Iter 10680/20000] Loss: 0.0003282 (Best: 0.0002883 @iter10603) ([92m↓7.15%[0m) [0.13% of initial]
[Iter 10690/20000] Loss: 0.0003366 (Best: 0.0002883 @iter10603) ([91m↑2.55%[0m) [0.13% of initial]
Iter:10699, L1 loss=0.0004037, Total loss=0.0003579, Time:79
[Iter 10700/20000] Loss: 0.0003697 (Best: 0.0002883 @iter10603) ([91m↑9.83%[0m) [0.15% of initial]
[Iter 10710/20000] Loss: 0.0003774 (Best: 0.0002883 @iter10603) ([91m↑2.10%[0m) [0.15% of initial]
[Iter 10720/20000] Loss: 0.0004167 (Best: 0.0002883 @iter10603) ([91m↑10.41%[0m) [0.17% of initial]
[Iter 10730/20000] Loss: 0.0004105 (Best: 0.0002883 @iter10603) ([92m↓1.48%[0m) [0.16% of initial]
[Iter 10740/20000] Loss: 0.0003673 (Best: 0.0002883 @iter10603) ([92m↓10.54%[0m) [0.15% of initial]
[Iter 10750/20000] Loss: 0.0003597 (Best: 0.0002883 @iter10603) ([92m↓2.06%[0m) [0.14% of initial]
[Iter 10760/20000] Loss: 0.0003224 (Best: 0.0002883 @iter10603) ([92m↓10.35%[0m) [0.13% of initial]
[Iter 10770/20000] Loss: 0.0003144 (Best: 0.0002883 @iter10603) ([92m↓2.48%[0m) [0.12% of initial]
[Iter 10780/20000] Loss: 0.0003123 (Best: 0.0002856 @iter10774) ([92m↓0.70%[0m) [0.12% of initial]
[Iter 10790/20000] Loss: 0.0003402 (Best: 0.0002842 @iter10784) ([91m↑8.95%[0m) [0.14% of initial]
Iter:10799, L1 loss=0.0003756, Total loss=0.0003242, Time:83
[Iter 10800/20000] Loss: 0.0003594 (Best: 0.0002842 @iter10784) ([91m↑5.63%[0m) [0.14% of initial]
[Iter 10810/20000] Loss: 0.0004107 (Best: 0.0002842 @iter10784) ([91m↑14.28%[0m) [0.16% of initial]
[Iter 10820/20000] Loss: 0.0003893 (Best: 0.0002842 @iter10784) ([92m↓5.22%[0m) [0.15% of initial]
[Iter 10830/20000] Loss: 0.0003833 (Best: 0.0002842 @iter10784) ([92m↓1.52%[0m) [0.15% of initial]
[Iter 10840/20000] Loss: 0.0003398 (Best: 0.0002842 @iter10784) ([92m↓11.35%[0m) [0.14% of initial]
[Iter 10850/20000] Loss: 0.0003524 (Best: 0.0002842 @iter10784) ([91m↑3.68%[0m) [0.14% of initial]
[Iter 10860/20000] Loss: 0.0003321 (Best: 0.0002842 @iter10784) ([92m↓5.74%[0m) [0.13% of initial]
[Iter 10870/20000] Loss: 0.0003297 (Best: 0.0002842 @iter10784) ([92m↓0.73%[0m) [0.13% of initial]
[Iter 10880/20000] Loss: 0.0003258 (Best: 0.0002842 @iter10784) ([92m↓1.18%[0m) [0.13% of initial]
[Iter 10890/20000] Loss: 0.0003322 (Best: 0.0002842 @iter10784) ([91m↑1.97%[0m) [0.13% of initial]
Iter:10899, L1 loss=0.0005181, Total loss=0.0003848, Time:87
[Iter 10900/20000] Loss: 0.0003486 (Best: 0.0002842 @iter10784) ([91m↑4.91%[0m) [0.14% of initial]
[Iter 10910/20000] Loss: 0.0003402 (Best: 0.0002842 @iter10784) ([92m↓2.40%[0m) [0.14% of initial]
[Iter 10920/20000] Loss: 0.0003243 (Best: 0.0002842 @iter10784) ([92m↓4.66%[0m) [0.13% of initial]
[Iter 10930/20000] Loss: 0.0003173 (Best: 0.0002812 @iter10921) ([92m↓2.17%[0m) [0.13% of initial]
[Iter 10940/20000] Loss: 0.0003495 (Best: 0.0002812 @iter10921) ([91m↑10.13%[0m) [0.14% of initial]
[Iter 10950/20000] Loss: 0.0003213 (Best: 0.0002812 @iter10921) ([92m↓8.06%[0m) [0.13% of initial]
[Iter 10960/20000] Loss: 0.0003349 (Best: 0.0002812 @iter10921) ([91m↑4.23%[0m) [0.13% of initial]
[Iter 10970/20000] Loss: 0.0003227 (Best: 0.0002812 @iter10921) ([92m↓3.65%[0m) [0.13% of initial]
[Iter 10980/20000] Loss: 0.0003042 (Best: 0.0002812 @iter10921) ([92m↓5.71%[0m) [0.12% of initial]
[Iter 10990/20000] Loss: 0.0003194 (Best: 0.0002812 @iter10921) ([91m↑4.98%[0m) [0.13% of initial]
Iter:10999, L1 loss=0.0003742, Total loss=0.0003421, Time:80
[Iter 11000/20000] Loss: 0.0003121 (Best: 0.0002812 @iter10921) ([92m↓2.28%[0m) [0.12% of initial]
Pruning 21 points (0.0%) from gaussian0 at iteration 11000
Pruning 13 points (0.0%) from gaussian1 at iteration 11000
[Iter 11010/20000] Loss: 0.0007011 (Best: 0.0002812 @iter10921) ([91m↑124.62%[0m) [0.28% of initial]
[Iter 11020/20000] Loss: 0.0005290 (Best: 0.0002812 @iter10921) ([92m↓24.55%[0m) [0.21% of initial]
[Iter 11030/20000] Loss: 0.0003896 (Best: 0.0002812 @iter10921) ([92m↓26.36%[0m) [0.15% of initial]
[Iter 11040/20000] Loss: 0.0003400 (Best: 0.0002812 @iter10921) ([92m↓12.73%[0m) [0.14% of initial]
[Iter 11050/20000] Loss: 0.0003887 (Best: 0.0002812 @iter10921) ([91m↑14.30%[0m) [0.15% of initial]
[Iter 11060/20000] Loss: 0.0003054 (Best: 0.0002812 @iter10921) ([92m↓21.42%[0m) [0.12% of initial]
[Iter 11070/20000] Loss: 0.0003195 (Best: 0.0002812 @iter10921) ([91m↑4.60%[0m) [0.13% of initial]
[Iter 11080/20000] Loss: 0.0002996 (Best: 0.0002812 @iter10921) ([92m↓6.21%[0m) [0.12% of initial]
[Iter 11090/20000] Loss: 0.0003237 (Best: 0.0002812 @iter10921) ([91m↑8.04%[0m) [0.13% of initial]
Iter:11099, L1 loss=0.000344, Total loss=0.0002987, Time:92
[Iter 11100/20000] Loss: 0.0003351 (Best: 0.0002812 @iter10921) ([91m↑3.52%[0m) [0.13% of initial]
[Iter 11110/20000] Loss: 0.0003699 (Best: 0.0002812 @iter10921) ([91m↑10.38%[0m) [0.15% of initial]
[Iter 11120/20000] Loss: 0.0003226 (Best: 0.0002812 @iter10921) ([92m↓12.78%[0m) [0.13% of initial]
[Iter 11130/20000] Loss: 0.0003834 (Best: 0.0002812 @iter10921) ([91m↑18.84%[0m) [0.15% of initial]
[Iter 11140/20000] Loss: 0.0003388 (Best: 0.0002812 @iter10921) ([92m↓11.62%[0m) [0.13% of initial]
[Iter 11150/20000] Loss: 0.0003293 (Best: 0.0002812 @iter10921) ([92m↓2.83%[0m) [0.13% of initial]
[Iter 11160/20000] Loss: 0.0003373 (Best: 0.0002812 @iter10921) ([91m↑2.43%[0m) [0.13% of initial]
[Iter 11170/20000] Loss: 0.0003356 (Best: 0.0002812 @iter10921) ([92m↓0.49%[0m) [0.13% of initial]
[Iter 11180/20000] Loss: 0.0003225 (Best: 0.0002812 @iter10921) ([92m↓3.92%[0m) [0.13% of initial]
[Iter 11190/20000] Loss: 0.0003395 (Best: 0.0002812 @iter10921) ([91m↑5.29%[0m) [0.13% of initial]
Iter:11199, L1 loss=0.0003946, Total loss=0.000338, Time:97
[Iter 11200/20000] Loss: 0.0003302 (Best: 0.0002812 @iter10921) ([92m↓2.75%[0m) [0.13% of initial]
[Iter 11210/20000] Loss: 0.0003055 (Best: 0.0002812 @iter10921) ([92m↓7.47%[0m) [0.12% of initial]
[Iter 11220/20000] Loss: 0.0003271 (Best: 0.0002812 @iter10921) ([91m↑7.06%[0m) [0.13% of initial]
[Iter 11230/20000] Loss: 0.0003166 (Best: 0.0002769 @iter11227) ([92m↓3.22%[0m) [0.13% of initial]
[Iter 11240/20000] Loss: 0.0003187 (Best: 0.0002769 @iter11227) ([91m↑0.67%[0m) [0.13% of initial]
[Iter 11250/20000] Loss: 0.0003195 (Best: 0.0002769 @iter11227) ([91m↑0.25%[0m) [0.13% of initial]
[Iter 11260/20000] Loss: 0.0002962 (Best: 0.0002769 @iter11227) ([92m↓7.30%[0m) [0.12% of initial]
[Iter 11270/20000] Loss: 0.0002906 (Best: 0.0002711 @iter11263) ([92m↓1.88%[0m) [0.12% of initial]
[Iter 11280/20000] Loss: 0.0003042 (Best: 0.0002711 @iter11263) ([91m↑4.68%[0m) [0.12% of initial]
[Iter 11290/20000] Loss: 0.0003009 (Best: 0.0002711 @iter11263) ([92m↓1.10%[0m) [0.12% of initial]
Iter:11299, L1 loss=0.0003203, Total loss=0.0002723, Time:100
[Iter 11300/20000] Loss: 0.0003032 (Best: 0.0002711 @iter11263) ([91m↑0.77%[0m) [0.12% of initial]
[Iter 11310/20000] Loss: 0.0002799 (Best: 0.0002674 @iter11305) ([92m↓7.68%[0m) [0.11% of initial]
[Iter 11320/20000] Loss: 0.0002911 (Best: 0.0002611 @iter11315) ([91m↑4.01%[0m) [0.12% of initial]
[Iter 11330/20000] Loss: 0.0003046 (Best: 0.0002611 @iter11315) ([91m↑4.61%[0m) [0.12% of initial]
[Iter 11340/20000] Loss: 0.0003313 (Best: 0.0002611 @iter11315) ([91m↑8.79%[0m) [0.13% of initial]
[Iter 11350/20000] Loss: 0.0004246 (Best: 0.0002611 @iter11315) ([91m↑28.14%[0m) [0.17% of initial]
[Iter 11360/20000] Loss: 0.0003356 (Best: 0.0002611 @iter11315) ([92m↓20.96%[0m) [0.13% of initial]
[Iter 11370/20000] Loss: 0.0003613 (Best: 0.0002611 @iter11315) ([91m↑7.65%[0m) [0.14% of initial]
[Iter 11380/20000] Loss: 0.0003536 (Best: 0.0002611 @iter11315) ([92m↓2.14%[0m) [0.14% of initial]
[Iter 11390/20000] Loss: 0.0003549 (Best: 0.0002611 @iter11315) ([91m↑0.38%[0m) [0.14% of initial]
Iter:11399, L1 loss=0.0003928, Total loss=0.0003465, Time:96
[Iter 11400/20000] Loss: 0.0003486 (Best: 0.0002611 @iter11315) ([92m↓1.77%[0m) [0.14% of initial]
[Iter 11410/20000] Loss: 0.0003235 (Best: 0.0002611 @iter11315) ([92m↓7.19%[0m) [0.13% of initial]
[Iter 11420/20000] Loss: 0.0003033 (Best: 0.0002611 @iter11315) ([92m↓6.26%[0m) [0.12% of initial]
[Iter 11430/20000] Loss: 0.0003542 (Best: 0.0002611 @iter11315) ([91m↑16.79%[0m) [0.14% of initial]
[Iter 11440/20000] Loss: 0.0003409 (Best: 0.0002611 @iter11315) ([92m↓3.76%[0m) [0.14% of initial]
[Iter 11450/20000] Loss: 0.0003635 (Best: 0.0002611 @iter11315) ([91m↑6.64%[0m) [0.14% of initial]
[Iter 11460/20000] Loss: 0.0003294 (Best: 0.0002611 @iter11315) ([92m↓9.39%[0m) [0.13% of initial]
[Iter 11470/20000] Loss: 0.0003204 (Best: 0.0002611 @iter11315) ([92m↓2.73%[0m) [0.13% of initial]
[Iter 11480/20000] Loss: 0.0003079 (Best: 0.0002611 @iter11315) ([92m↓3.89%[0m) [0.12% of initial]
[Iter 11490/20000] Loss: 0.0003156 (Best: 0.0002611 @iter11315) ([91m↑2.49%[0m) [0.13% of initial]
Iter:11499, L1 loss=0.0004471, Total loss=0.0003875, Time:97
[Iter 11500/20000] Loss: 0.0003327 (Best: 0.0002611 @iter11315) ([91m↑5.40%[0m) [0.13% of initial]
Pruning 26 points (0.0%) from gaussian0 at iteration 11500
Pruning 21 points (0.0%) from gaussian1 at iteration 11500
[Iter 11510/20000] Loss: 0.0006186 (Best: 0.0002611 @iter11315) ([91m↑85.94%[0m) [0.25% of initial]
[Iter 11520/20000] Loss: 0.0004419 (Best: 0.0002611 @iter11315) ([92m↓28.56%[0m) [0.18% of initial]
[Iter 11530/20000] Loss: 0.0003718 (Best: 0.0002611 @iter11315) ([92m↓15.86%[0m) [0.15% of initial]
[Iter 11540/20000] Loss: 0.0003315 (Best: 0.0002611 @iter11315) ([92m↓10.84%[0m) [0.13% of initial]
[Iter 11550/20000] Loss: 0.0003225 (Best: 0.0002611 @iter11315) ([92m↓2.71%[0m) [0.13% of initial]
[Iter 11560/20000] Loss: 0.0003292 (Best: 0.0002611 @iter11315) ([91m↑2.08%[0m) [0.13% of initial]
[Iter 11570/20000] Loss: 0.0003122 (Best: 0.0002611 @iter11315) ([92m↓5.17%[0m) [0.12% of initial]
[Iter 11580/20000] Loss: 0.0003285 (Best: 0.0002611 @iter11315) ([91m↑5.24%[0m) [0.13% of initial]
[Iter 11590/20000] Loss: 0.0003098 (Best: 0.0002611 @iter11315) ([92m↓5.71%[0m) [0.12% of initial]
Iter:11599, L1 loss=0.0003337, Total loss=0.0002841, Time:77
[Iter 11600/20000] Loss: 0.0003012 (Best: 0.0002611 @iter11315) ([92m↓2.77%[0m) [0.12% of initial]
[Iter 11610/20000] Loss: 0.0002970 (Best: 0.0002611 @iter11315) ([92m↓1.40%[0m) [0.12% of initial]
[Iter 11620/20000] Loss: 0.0002903 (Best: 0.0002611 @iter11315) ([92m↓2.25%[0m) [0.12% of initial]
[Iter 11630/20000] Loss: 0.0002690 (Best: 0.0002598 @iter11630) ([92m↓7.33%[0m) [0.11% of initial]
[Iter 11640/20000] Loss: 0.0003059 (Best: 0.0002598 @iter11630) ([91m↑13.71%[0m) [0.12% of initial]
[Iter 11650/20000] Loss: 0.0003241 (Best: 0.0002598 @iter11630) ([91m↑5.96%[0m) [0.13% of initial]
[Iter 11660/20000] Loss: 0.0003167 (Best: 0.0002598 @iter11630) ([92m↓2.31%[0m) [0.13% of initial]
[Iter 11670/20000] Loss: 0.0002999 (Best: 0.0002598 @iter11630) ([92m↓5.28%[0m) [0.12% of initial]
[Iter 11680/20000] Loss: 0.0003117 (Best: 0.0002598 @iter11630) ([91m↑3.92%[0m) [0.12% of initial]
[Iter 11690/20000] Loss: 0.0003029 (Best: 0.0002598 @iter11630) ([92m↓2.82%[0m) [0.12% of initial]
Iter:11699, L1 loss=0.0003279, Total loss=0.0002801, Time:78
[Iter 11700/20000] Loss: 0.0002855 (Best: 0.0002598 @iter11630) ([92m↓5.73%[0m) [0.11% of initial]
[Iter 11710/20000] Loss: 0.0002817 (Best: 0.0002582 @iter11707) ([92m↓1.36%[0m) [0.11% of initial]
[Iter 11720/20000] Loss: 0.0002771 (Best: 0.0002504 @iter11719) ([92m↓1.63%[0m) [0.11% of initial]
[Iter 11730/20000] Loss: 0.0002939 (Best: 0.0002504 @iter11719) ([91m↑6.07%[0m) [0.12% of initial]
[Iter 11740/20000] Loss: 0.0003177 (Best: 0.0002504 @iter11719) ([91m↑8.12%[0m) [0.13% of initial]
[Iter 11750/20000] Loss: 0.0003201 (Best: 0.0002504 @iter11719) ([91m↑0.73%[0m) [0.13% of initial]
[Iter 11760/20000] Loss: 0.0003429 (Best: 0.0002504 @iter11719) ([91m↑7.12%[0m) [0.14% of initial]
[Iter 11770/20000] Loss: 0.0003054 (Best: 0.0002504 @iter11719) ([92m↓10.92%[0m) [0.12% of initial]
[Iter 11780/20000] Loss: 0.0003059 (Best: 0.0002504 @iter11719) ([91m↑0.15%[0m) [0.12% of initial]
[Iter 11790/20000] Loss: 0.0002870 (Best: 0.0002504 @iter11719) ([92m↓6.18%[0m) [0.11% of initial]
Iter:11799, L1 loss=0.0003447, Total loss=0.000306, Time:86
[Iter 11800/20000] Loss: 0.0002808 (Best: 0.0002504 @iter11719) ([92m↓2.15%[0m) [0.11% of initial]
[Iter 11810/20000] Loss: 0.0002673 (Best: 0.0002504 @iter11719) ([92m↓4.79%[0m) [0.11% of initial]
[Iter 11820/20000] Loss: 0.0002910 (Best: 0.0002504 @iter11719) ([91m↑8.86%[0m) [0.12% of initial]
[Iter 11830/20000] Loss: 0.0003233 (Best: 0.0002504 @iter11719) ([91m↑11.08%[0m) [0.13% of initial]
[Iter 11840/20000] Loss: 0.0003201 (Best: 0.0002504 @iter11719) ([92m↓0.97%[0m) [0.13% of initial]
[Iter 11850/20000] Loss: 0.0003028 (Best: 0.0002504 @iter11719) ([92m↓5.42%[0m) [0.12% of initial]
[Iter 11860/20000] Loss: 0.0002989 (Best: 0.0002504 @iter11719) ([92m↓1.29%[0m) [0.12% of initial]
[Iter 11870/20000] Loss: 0.0002889 (Best: 0.0002504 @iter11719) ([92m↓3.35%[0m) [0.11% of initial]
[Iter 11880/20000] Loss: 0.0003009 (Best: 0.0002504 @iter11719) ([91m↑4.17%[0m) [0.12% of initial]
[Iter 11890/20000] Loss: 0.0003527 (Best: 0.0002504 @iter11719) ([91m↑17.20%[0m) [0.14% of initial]
Iter:11899, L1 loss=0.0003688, Total loss=0.0003149, Time:90
[Iter 11900/20000] Loss: 0.0003252 (Best: 0.0002504 @iter11719) ([92m↓7.81%[0m) [0.13% of initial]
[Iter 11910/20000] Loss: 0.0003323 (Best: 0.0002504 @iter11719) ([91m↑2.21%[0m) [0.13% of initial]
[Iter 11920/20000] Loss: 0.0003454 (Best: 0.0002504 @iter11719) ([91m↑3.93%[0m) [0.14% of initial]
[Iter 11930/20000] Loss: 0.0003162 (Best: 0.0002504 @iter11719) ([92m↓8.45%[0m) [0.13% of initial]
[Iter 11940/20000] Loss: 0.0003061 (Best: 0.0002504 @iter11719) ([92m↓3.20%[0m) [0.12% of initial]
[Iter 11950/20000] Loss: 0.0003101 (Best: 0.0002504 @iter11719) ([91m↑1.30%[0m) [0.12% of initial]
[Iter 11960/20000] Loss: 0.0002725 (Best: 0.0002504 @iter11719) ([92m↓12.12%[0m) [0.11% of initial]
[Iter 11970/20000] Loss: 0.0003010 (Best: 0.0002504 @iter11719) ([91m↑10.44%[0m) [0.12% of initial]
[Iter 11980/20000] Loss: 0.0002830 (Best: 0.0002504 @iter11719) ([92m↓5.97%[0m) [0.11% of initial]
[Iter 11990/20000] Loss: 0.0003011 (Best: 0.0002504 @iter11719) ([91m↑6.39%[0m) [0.12% of initial]
Iter:11999, L1 loss=0.0003323, Total loss=0.000298, Time:97
[Iter 12000/20000] Loss: 0.0003384 (Best: 0.0002504 @iter11719) ([91m↑12.40%[0m) [0.13% of initial]
Pruning 18 points (0.0%) from gaussian0 at iteration 12000
Pruning 11 points (0.0%) from gaussian1 at iteration 12000
[Iter 12010/20000] Loss: 0.0218336 (Best: 0.0002504 @iter11719) ([91m↑6351.70%[0m) [8.67% of initial]
[Iter 12020/20000] Loss: 0.0059836 (Best: 0.0002504 @iter11719) ([92m↓72.59%[0m) [2.38% of initial]
[Iter 12030/20000] Loss: 0.0042216 (Best: 0.0002504 @iter11719) ([92m↓29.45%[0m) [1.68% of initial]
[Iter 12040/20000] Loss: 0.0022558 (Best: 0.0002504 @iter11719) ([92m↓46.56%[0m) [0.90% of initial]
[Iter 12050/20000] Loss: 0.0014955 (Best: 0.0002504 @iter11719) ([92m↓33.70%[0m) [0.59% of initial]
[Iter 12060/20000] Loss: 0.0010306 (Best: 0.0002504 @iter11719) ([92m↓31.09%[0m) [0.41% of initial]
[Iter 12070/20000] Loss: 0.0007902 (Best: 0.0002504 @iter11719) ([92m↓23.32%[0m) [0.31% of initial]
[Iter 12080/20000] Loss: 0.0006609 (Best: 0.0002504 @iter11719) ([92m↓16.36%[0m) [0.26% of initial]
[Iter 12090/20000] Loss: 0.0005744 (Best: 0.0002504 @iter11719) ([92m↓13.09%[0m) [0.23% of initial]
Iter:12099, L1 loss=0.0006243, Total loss=0.000567, Time:85
[Iter 12100/20000] Loss: 0.0005300 (Best: 0.0002504 @iter11719) ([92m↓7.71%[0m) [0.21% of initial]
[Iter 12110/20000] Loss: 0.0004877 (Best: 0.0002504 @iter11719) ([92m↓8.00%[0m) [0.19% of initial]
[Iter 12120/20000] Loss: 0.0004582 (Best: 0.0002504 @iter11719) ([92m↓6.05%[0m) [0.18% of initial]
[Iter 12130/20000] Loss: 0.0004283 (Best: 0.0002504 @iter11719) ([92m↓6.53%[0m) [0.17% of initial]
[Iter 12140/20000] Loss: 0.0004098 (Best: 0.0002504 @iter11719) ([92m↓4.31%[0m) [0.16% of initial]
[Iter 12150/20000] Loss: 0.0004149 (Best: 0.0002504 @iter11719) ([91m↑1.23%[0m) [0.16% of initial]
[Iter 12160/20000] Loss: 0.0003901 (Best: 0.0002504 @iter11719) ([92m↓5.97%[0m) [0.15% of initial]
[Iter 12170/20000] Loss: 0.0003749 (Best: 0.0002504 @iter11719) ([92m↓3.90%[0m) [0.15% of initial]
[Iter 12180/20000] Loss: 0.0003676 (Best: 0.0002504 @iter11719) ([92m↓1.94%[0m) [0.15% of initial]
[Iter 12190/20000] Loss: 0.0003672 (Best: 0.0002504 @iter11719) ([92m↓0.11%[0m) [0.15% of initial]
Iter:12199, L1 loss=0.0004136, Total loss=0.0003583, Time:89
[Iter 12200/20000] Loss: 0.0003508 (Best: 0.0002504 @iter11719) ([92m↓4.46%[0m) [0.14% of initial]
[Iter 12210/20000] Loss: 0.0003607 (Best: 0.0002504 @iter11719) ([91m↑2.82%[0m) [0.14% of initial]
[Iter 12220/20000] Loss: 0.0003476 (Best: 0.0002504 @iter11719) ([92m↓3.64%[0m) [0.14% of initial]
[Iter 12230/20000] Loss: 0.0003483 (Best: 0.0002504 @iter11719) ([91m↑0.20%[0m) [0.14% of initial]
[Iter 12240/20000] Loss: 0.0003617 (Best: 0.0002504 @iter11719) ([91m↑3.86%[0m) [0.14% of initial]
[Iter 12250/20000] Loss: 0.0003479 (Best: 0.0002504 @iter11719) ([92m↓3.82%[0m) [0.14% of initial]
[Iter 12260/20000] Loss: 0.0003445 (Best: 0.0002504 @iter11719) ([92m↓0.99%[0m) [0.14% of initial]
[Iter 12270/20000] Loss: 0.0003435 (Best: 0.0002504 @iter11719) ([92m↓0.27%[0m) [0.14% of initial]
[Iter 12280/20000] Loss: 0.0003533 (Best: 0.0002504 @iter11719) ([91m↑2.85%[0m) [0.14% of initial]
[Iter 12290/20000] Loss: 0.0003895 (Best: 0.0002504 @iter11719) ([91m↑10.25%[0m) [0.15% of initial]
Iter:12299, L1 loss=0.000404, Total loss=0.0003497, Time:88
[Iter 12300/20000] Loss: 0.0003534 (Best: 0.0002504 @iter11719) ([92m↓9.28%[0m) [0.14% of initial]
[Iter 12310/20000] Loss: 0.0003433 (Best: 0.0002504 @iter11719) ([92m↓2.86%[0m) [0.14% of initial]
[Iter 12320/20000] Loss: 0.0003401 (Best: 0.0002504 @iter11719) ([92m↓0.92%[0m) [0.14% of initial]
[Iter 12330/20000] Loss: 0.0003597 (Best: 0.0002504 @iter11719) ([91m↑5.76%[0m) [0.14% of initial]
[Iter 12340/20000] Loss: 0.0003532 (Best: 0.0002504 @iter11719) ([92m↓1.81%[0m) [0.14% of initial]
[Iter 12350/20000] Loss: 0.0003516 (Best: 0.0002504 @iter11719) ([92m↓0.45%[0m) [0.14% of initial]
[Iter 12360/20000] Loss: 0.0003423 (Best: 0.0002504 @iter11719) ([92m↓2.66%[0m) [0.14% of initial]
[Iter 12370/20000] Loss: 0.0003314 (Best: 0.0002504 @iter11719) ([92m↓3.18%[0m) [0.13% of initial]
[Iter 12380/20000] Loss: 0.0003366 (Best: 0.0002504 @iter11719) ([91m↑1.57%[0m) [0.13% of initial]
[Iter 12390/20000] Loss: 0.0003374 (Best: 0.0002504 @iter11719) ([91m↑0.25%[0m) [0.13% of initial]
Iter:12399, L1 loss=0.0003718, Total loss=0.0003215, Time:81
[Iter 12400/20000] Loss: 0.0003334 (Best: 0.0002504 @iter11719) ([92m↓1.18%[0m) [0.13% of initial]
[Iter 12410/20000] Loss: 0.0003482 (Best: 0.0002504 @iter11719) ([91m↑4.42%[0m) [0.14% of initial]
[Iter 12420/20000] Loss: 0.0003408 (Best: 0.0002504 @iter11719) ([92m↓2.12%[0m) [0.14% of initial]
[Iter 12430/20000] Loss: 0.0003361 (Best: 0.0002504 @iter11719) ([92m↓1.37%[0m) [0.13% of initial]
[Iter 12440/20000] Loss: 0.0003497 (Best: 0.0002504 @iter11719) ([91m↑4.02%[0m) [0.14% of initial]
[Iter 12450/20000] Loss: 0.0003460 (Best: 0.0002504 @iter11719) ([92m↓1.03%[0m) [0.14% of initial]
[Iter 12460/20000] Loss: 0.0003328 (Best: 0.0002504 @iter11719) ([92m↓3.84%[0m) [0.13% of initial]
[Iter 12470/20000] Loss: 0.0003396 (Best: 0.0002504 @iter11719) ([91m↑2.04%[0m) [0.13% of initial]
[Iter 12480/20000] Loss: 0.0003447 (Best: 0.0002504 @iter11719) ([91m↑1.52%[0m) [0.14% of initial]
[Iter 12490/20000] Loss: 0.0003412 (Best: 0.0002504 @iter11719) ([92m↓1.01%[0m) [0.14% of initial]
Iter:12499, L1 loss=0.0003976, Total loss=0.0003715, Time:80
[Iter 12500/20000] Loss: 0.0003599 (Best: 0.0002504 @iter11719) ([91m↑5.45%[0m) [0.14% of initial]
Pruning 26 points (0.0%) from gaussian0 at iteration 12500
Pruning 15 points (0.0%) from gaussian1 at iteration 12500
[Iter 12510/20000] Loss: 0.0007399 (Best: 0.0002504 @iter11719) ([91m↑105.61%[0m) [0.29% of initial]
[Iter 12520/20000] Loss: 0.0005099 (Best: 0.0002504 @iter11719) ([92m↓31.08%[0m) [0.20% of initial]
[Iter 12530/20000] Loss: 0.0003963 (Best: 0.0002504 @iter11719) ([92m↓22.28%[0m) [0.16% of initial]
[Iter 12540/20000] Loss: 0.0003631 (Best: 0.0002504 @iter11719) ([92m↓8.38%[0m) [0.14% of initial]
[Iter 12550/20000] Loss: 0.0003276 (Best: 0.0002504 @iter11719) ([92m↓9.78%[0m) [0.13% of initial]
[Iter 12560/20000] Loss: 0.0003171 (Best: 0.0002504 @iter11719) ([92m↓3.22%[0m) [0.13% of initial]
[Iter 12570/20000] Loss: 0.0003339 (Best: 0.0002504 @iter11719) ([91m↑5.33%[0m) [0.13% of initial]
[Iter 12580/20000] Loss: 0.0003520 (Best: 0.0002504 @iter11719) ([91m↑5.41%[0m) [0.14% of initial]
[Iter 12590/20000] Loss: 0.0003422 (Best: 0.0002504 @iter11719) ([92m↓2.78%[0m) [0.14% of initial]
Iter:12599, L1 loss=0.0004676, Total loss=0.0004232, Time:107
[Iter 12600/20000] Loss: 0.0003722 (Best: 0.0002504 @iter11719) ([91m↑8.77%[0m) [0.15% of initial]
[Iter 12610/20000] Loss: 0.0003600 (Best: 0.0002504 @iter11719) ([92m↓3.27%[0m) [0.14% of initial]
[Iter 12620/20000] Loss: 0.0003369 (Best: 0.0002504 @iter11719) ([92m↓6.41%[0m) [0.13% of initial]
[Iter 12630/20000] Loss: 0.0003540 (Best: 0.0002504 @iter11719) ([91m↑5.05%[0m) [0.14% of initial]
[Iter 12640/20000] Loss: 0.0003540 (Best: 0.0002504 @iter11719) ([91m↑0.00%[0m) [0.14% of initial]
[Iter 12650/20000] Loss: 0.0003427 (Best: 0.0002504 @iter11719) ([92m↓3.18%[0m) [0.14% of initial]
[Iter 12660/20000] Loss: 0.0003543 (Best: 0.0002504 @iter11719) ([91m↑3.37%[0m) [0.14% of initial]
[Iter 12670/20000] Loss: 0.0003520 (Best: 0.0002504 @iter11719) ([92m↓0.64%[0m) [0.14% of initial]
[Iter 12680/20000] Loss: 0.0003706 (Best: 0.0002504 @iter11719) ([91m↑5.29%[0m) [0.15% of initial]
[Iter 12690/20000] Loss: 0.0003536 (Best: 0.0002504 @iter11719) ([92m↓4.60%[0m) [0.14% of initial]
Iter:12699, L1 loss=0.0004341, Total loss=0.0003692, Time:102
[Iter 12700/20000] Loss: 0.0003555 (Best: 0.0002504 @iter11719) ([91m↑0.56%[0m) [0.14% of initial]
[Iter 12710/20000] Loss: 0.0003545 (Best: 0.0002504 @iter11719) ([92m↓0.31%[0m) [0.14% of initial]
[Iter 12720/20000] Loss: 0.0003444 (Best: 0.0002504 @iter11719) ([92m↓2.84%[0m) [0.14% of initial]
[Iter 12730/20000] Loss: 0.0003620 (Best: 0.0002504 @iter11719) ([91m↑5.12%[0m) [0.14% of initial]
[Iter 12740/20000] Loss: 0.0003410 (Best: 0.0002504 @iter11719) ([92m↓5.82%[0m) [0.14% of initial]
[Iter 12750/20000] Loss: 0.0003300 (Best: 0.0002504 @iter11719) ([92m↓3.21%[0m) [0.13% of initial]
[Iter 12760/20000] Loss: 0.0003339 (Best: 0.0002504 @iter11719) ([91m↑1.17%[0m) [0.13% of initial]
[Iter 12770/20000] Loss: 0.0003501 (Best: 0.0002504 @iter11719) ([91m↑4.86%[0m) [0.14% of initial]
[Iter 12780/20000] Loss: 0.0003829 (Best: 0.0002504 @iter11719) ([91m↑9.36%[0m) [0.15% of initial]
[Iter 12790/20000] Loss: 0.0003532 (Best: 0.0002504 @iter11719) ([92m↓7.76%[0m) [0.14% of initial]
Iter:12799, L1 loss=0.000403, Total loss=0.0003515, Time:78
[Iter 12800/20000] Loss: 0.0003585 (Best: 0.0002504 @iter11719) ([91m↑1.50%[0m) [0.14% of initial]
[Iter 12810/20000] Loss: 0.0004059 (Best: 0.0002504 @iter11719) ([91m↑13.22%[0m) [0.16% of initial]
[Iter 12820/20000] Loss: 0.0003890 (Best: 0.0002504 @iter11719) ([92m↓4.16%[0m) [0.15% of initial]
[Iter 12830/20000] Loss: 0.0003586 (Best: 0.0002504 @iter11719) ([92m↓7.83%[0m) [0.14% of initial]
[Iter 12840/20000] Loss: 0.0003660 (Best: 0.0002504 @iter11719) ([91m↑2.07%[0m) [0.15% of initial]
[Iter 12850/20000] Loss: 0.0003415 (Best: 0.0002504 @iter11719) ([92m↓6.67%[0m) [0.14% of initial]
[Iter 12860/20000] Loss: 0.0003289 (Best: 0.0002504 @iter11719) ([92m↓3.70%[0m) [0.13% of initial]
[Iter 12870/20000] Loss: 0.0003223 (Best: 0.0002504 @iter11719) ([92m↓2.02%[0m) [0.13% of initial]
[Iter 12880/20000] Loss: 0.0005620 (Best: 0.0002504 @iter11719) ([91m↑74.39%[0m) [0.22% of initial]
[Iter 12890/20000] Loss: 0.0003292 (Best: 0.0002504 @iter11719) ([92m↓41.43%[0m) [0.13% of initial]
Iter:12899, L1 loss=0.0003944, Total loss=0.000328, Time:80
[Iter 12900/20000] Loss: 0.0003142 (Best: 0.0002504 @iter11719) ([92m↓4.56%[0m) [0.12% of initial]
[Iter 12910/20000] Loss: 0.0003173 (Best: 0.0002504 @iter11719) ([91m↑1.01%[0m) [0.13% of initial]
[Iter 12920/20000] Loss: 0.0003427 (Best: 0.0002504 @iter11719) ([91m↑8.00%[0m) [0.14% of initial]
[Iter 12930/20000] Loss: 0.0003430 (Best: 0.0002504 @iter11719) ([91m↑0.09%[0m) [0.14% of initial]
[Iter 12940/20000] Loss: 0.0003678 (Best: 0.0002504 @iter11719) ([91m↑7.21%[0m) [0.15% of initial]
[Iter 12950/20000] Loss: 0.0003609 (Best: 0.0002504 @iter11719) ([92m↓1.88%[0m) [0.14% of initial]
[Iter 12960/20000] Loss: 0.0003731 (Best: 0.0002504 @iter11719) ([91m↑3.40%[0m) [0.15% of initial]
[Iter 12970/20000] Loss: 0.0003254 (Best: 0.0002504 @iter11719) ([92m↓12.80%[0m) [0.13% of initial]
[Iter 12980/20000] Loss: 0.0003546 (Best: 0.0002504 @iter11719) ([91m↑8.99%[0m) [0.14% of initial]
[Iter 12990/20000] Loss: 0.0003495 (Best: 0.0002504 @iter11719) ([92m↓1.44%[0m) [0.14% of initial]
Iter:12999, L1 loss=0.0003671, Total loss=0.0003219, Time:78
[Iter 13000/20000] Loss: 0.0003273 (Best: 0.0002504 @iter11719) ([92m↓6.37%[0m) [0.13% of initial]
Pruning 16 points (0.0%) from gaussian0 at iteration 13000
Pruning 9 points (0.0%) from gaussian1 at iteration 13000
[Iter 13010/20000] Loss: 0.0008679 (Best: 0.0002504 @iter11719) ([91m↑165.18%[0m) [0.34% of initial]
[Iter 13020/20000] Loss: 0.0005424 (Best: 0.0002504 @iter11719) ([92m↓37.50%[0m) [0.22% of initial]
[Iter 13030/20000] Loss: 0.0004320 (Best: 0.0002504 @iter11719) ([92m↓20.36%[0m) [0.17% of initial]
[Iter 13040/20000] Loss: 0.0003771 (Best: 0.0002504 @iter11719) ([92m↓12.71%[0m) [0.15% of initial]
[Iter 13050/20000] Loss: 0.0003302 (Best: 0.0002504 @iter11719) ([92m↓12.44%[0m) [0.13% of initial]
[Iter 13060/20000] Loss: 0.0003279 (Best: 0.0002504 @iter11719) ([92m↓0.69%[0m) [0.13% of initial]
[Iter 13070/20000] Loss: 0.0003277 (Best: 0.0002504 @iter11719) ([92m↓0.06%[0m) [0.13% of initial]
[Iter 13080/20000] Loss: 0.0003210 (Best: 0.0002504 @iter11719) ([92m↓2.04%[0m) [0.13% of initial]
[Iter 13090/20000] Loss: 0.0003327 (Best: 0.0002504 @iter11719) ([91m↑3.64%[0m) [0.13% of initial]
Iter:13099, L1 loss=0.000381, Total loss=0.0003134, Time:86
[Iter 13100/20000] Loss: 0.0003294 (Best: 0.0002504 @iter11719) ([92m↓0.99%[0m) [0.13% of initial]
[Iter 13110/20000] Loss: 0.0003294 (Best: 0.0002504 @iter11719) ([92m↓0.00%[0m) [0.13% of initial]
[Iter 13120/20000] Loss: 0.0003238 (Best: 0.0002504 @iter11719) ([92m↓1.70%[0m) [0.13% of initial]
[Iter 13130/20000] Loss: 0.0003345 (Best: 0.0002504 @iter11719) ([91m↑3.31%[0m) [0.13% of initial]
[Iter 13140/20000] Loss: 0.0003303 (Best: 0.0002504 @iter11719) ([92m↓1.26%[0m) [0.13% of initial]
[Iter 13150/20000] Loss: 0.0003147 (Best: 0.0002504 @iter11719) ([92m↓4.72%[0m) [0.13% of initial]
[Iter 13160/20000] Loss: 0.0003294 (Best: 0.0002504 @iter11719) ([91m↑4.67%[0m) [0.13% of initial]
[Iter 13170/20000] Loss: 0.0003236 (Best: 0.0002504 @iter11719) ([92m↓1.77%[0m) [0.13% of initial]
[Iter 13180/20000] Loss: 0.0003455 (Best: 0.0002504 @iter11719) ([91m↑6.79%[0m) [0.14% of initial]
[Iter 13190/20000] Loss: 0.0003314 (Best: 0.0002504 @iter11719) ([92m↓4.08%[0m) [0.13% of initial]
Iter:13199, L1 loss=0.0003825, Total loss=0.0003252, Time:81
[Iter 13200/20000] Loss: 0.0003354 (Best: 0.0002504 @iter11719) ([91m↑1.21%[0m) [0.13% of initial]
[Iter 13210/20000] Loss: 0.0003443 (Best: 0.0002504 @iter11719) ([91m↑2.63%[0m) [0.14% of initial]
[Iter 13220/20000] Loss: 0.0003082 (Best: 0.0002504 @iter11719) ([92m↓10.48%[0m) [0.12% of initial]
[Iter 13230/20000] Loss: 0.0003636 (Best: 0.0002504 @iter11719) ([91m↑17.98%[0m) [0.14% of initial]
[Iter 13240/20000] Loss: 0.0003450 (Best: 0.0002504 @iter11719) ([92m↓5.12%[0m) [0.14% of initial]
[Iter 13250/20000] Loss: 0.0003416 (Best: 0.0002504 @iter11719) ([92m↓0.99%[0m) [0.14% of initial]
[Iter 13260/20000] Loss: 0.0003226 (Best: 0.0002504 @iter11719) ([92m↓5.56%[0m) [0.13% of initial]
[Iter 13270/20000] Loss: 0.0003321 (Best: 0.0002504 @iter11719) ([91m↑2.96%[0m) [0.13% of initial]
[Iter 13280/20000] Loss: 0.0003321 (Best: 0.0002504 @iter11719) ([92m↓0.02%[0m) [0.13% of initial]
[Iter 13290/20000] Loss: 0.0003014 (Best: 0.0002504 @iter11719) ([92m↓9.25%[0m) [0.12% of initial]
Iter:13299, L1 loss=0.0003445, Total loss=0.0002942, Time:91
[Iter 13300/20000] Loss: 0.0002966 (Best: 0.0002504 @iter11719) ([92m↓1.58%[0m) [0.12% of initial]
[Iter 13310/20000] Loss: 0.0002975 (Best: 0.0002504 @iter11719) ([91m↑0.32%[0m) [0.12% of initial]
[Iter 13320/20000] Loss: 0.0003027 (Best: 0.0002504 @iter11719) ([91m↑1.74%[0m) [0.12% of initial]
[Iter 13330/20000] Loss: 0.0003089 (Best: 0.0002504 @iter11719) ([91m↑2.05%[0m) [0.12% of initial]
[Iter 13340/20000] Loss: 0.0003217 (Best: 0.0002504 @iter11719) ([91m↑4.13%[0m) [0.13% of initial]
[Iter 13350/20000] Loss: 0.0003022 (Best: 0.0002504 @iter11719) ([92m↓6.06%[0m) [0.12% of initial]
[Iter 13360/20000] Loss: 0.0003098 (Best: 0.0002504 @iter11719) ([91m↑2.52%[0m) [0.12% of initial]
[Iter 13370/20000] Loss: 0.0002911 (Best: 0.0002504 @iter11719) ([92m↓6.03%[0m) [0.12% of initial]
[Iter 13380/20000] Loss: 0.0003193 (Best: 0.0002504 @iter11719) ([91m↑9.68%[0m) [0.13% of initial]
[Iter 13390/20000] Loss: 0.0003241 (Best: 0.0002504 @iter11719) ([91m↑1.51%[0m) [0.13% of initial]
Iter:13399, L1 loss=0.0003587, Total loss=0.0003078, Time:79
[Iter 13400/20000] Loss: 0.0003227 (Best: 0.0002504 @iter11719) ([92m↓0.44%[0m) [0.13% of initial]
[Iter 13410/20000] Loss: 0.0003113 (Best: 0.0002504 @iter11719) ([92m↓3.51%[0m) [0.12% of initial]
[Iter 13420/20000] Loss: 0.0003128 (Best: 0.0002504 @iter11719) ([91m↑0.48%[0m) [0.12% of initial]
[Iter 13430/20000] Loss: 0.0002979 (Best: 0.0002504 @iter11719) ([92m↓4.78%[0m) [0.12% of initial]
[Iter 13440/20000] Loss: 0.0003092 (Best: 0.0002504 @iter11719) ([91m↑3.79%[0m) [0.12% of initial]
[Iter 13450/20000] Loss: 0.0002932 (Best: 0.0002504 @iter11719) ([92m↓5.18%[0m) [0.12% of initial]
[Iter 13460/20000] Loss: 0.0002929 (Best: 0.0002504 @iter11719) ([92m↓0.08%[0m) [0.12% of initial]
[Iter 13470/20000] Loss: 0.0003157 (Best: 0.0002504 @iter11719) ([91m↑7.78%[0m) [0.13% of initial]
[Iter 13480/20000] Loss: 0.0003111 (Best: 0.0002504 @iter11719) ([92m↓1.45%[0m) [0.12% of initial]
[Iter 13490/20000] Loss: 0.0003849 (Best: 0.0002504 @iter11719) ([91m↑23.71%[0m) [0.15% of initial]
Iter:13499, L1 loss=0.0003885, Total loss=0.0003253, Time:92
[Iter 13500/20000] Loss: 0.0003441 (Best: 0.0002504 @iter11719) ([92m↓10.60%[0m) [0.14% of initial]
Pruning 12 points (0.0%) from gaussian0 at iteration 13500
Pruning 5 points (0.0%) from gaussian1 at iteration 13500
[Iter 13510/20000] Loss: 0.0006394 (Best: 0.0002504 @iter11719) ([91m↑85.81%[0m) [0.25% of initial]
[Iter 13520/20000] Loss: 0.0004364 (Best: 0.0002504 @iter11719) ([92m↓31.75%[0m) [0.17% of initial]
[Iter 13530/20000] Loss: 0.0003704 (Best: 0.0002504 @iter11719) ([92m↓15.13%[0m) [0.15% of initial]
[Iter 13540/20000] Loss: 0.0003257 (Best: 0.0002504 @iter11719) ([92m↓12.06%[0m) [0.13% of initial]
[Iter 13550/20000] Loss: 0.0003067 (Best: 0.0002504 @iter11719) ([92m↓5.83%[0m) [0.12% of initial]
[Iter 13560/20000] Loss: 0.0003061 (Best: 0.0002504 @iter11719) ([92m↓0.21%[0m) [0.12% of initial]
[Iter 13570/20000] Loss: 0.0002928 (Best: 0.0002504 @iter11719) ([92m↓4.34%[0m) [0.12% of initial]
[Iter 13580/20000] Loss: 0.0003268 (Best: 0.0002504 @iter11719) ([91m↑11.62%[0m) [0.13% of initial]
[Iter 13590/20000] Loss: 0.0003214 (Best: 0.0002504 @iter11719) ([92m↓1.65%[0m) [0.13% of initial]
Iter:13599, L1 loss=0.0003388, Total loss=0.0002861, Time:80
[Iter 13600/20000] Loss: 0.0002848 (Best: 0.0002504 @iter11719) ([92m↓11.40%[0m) [0.11% of initial]
[Iter 13610/20000] Loss: 0.0002965 (Best: 0.0002504 @iter11719) ([91m↑4.10%[0m) [0.12% of initial]
[Iter 13620/20000] Loss: 0.0002897 (Best: 0.0002504 @iter11719) ([92m↓2.29%[0m) [0.12% of initial]
[Iter 13630/20000] Loss: 0.0002841 (Best: 0.0002504 @iter11719) ([92m↓1.92%[0m) [0.11% of initial]
[Iter 13640/20000] Loss: 0.0003389 (Best: 0.0002504 @iter11719) ([91m↑19.29%[0m) [0.13% of initial]
[Iter 13650/20000] Loss: 0.0003261 (Best: 0.0002504 @iter11719) ([92m↓3.78%[0m) [0.13% of initial]
[Iter 13660/20000] Loss: 0.0003100 (Best: 0.0002504 @iter11719) ([92m↓4.96%[0m) [0.12% of initial]
[Iter 13670/20000] Loss: 0.0003383 (Best: 0.0002504 @iter11719) ([91m↑9.16%[0m) [0.13% of initial]
[Iter 13680/20000] Loss: 0.0003223 (Best: 0.0002504 @iter11719) ([92m↓4.74%[0m) [0.13% of initial]
[Iter 13690/20000] Loss: 0.0003433 (Best: 0.0002504 @iter11719) ([91m↑6.50%[0m) [0.14% of initial]
Iter:13699, L1 loss=0.0003824, Total loss=0.000358, Time:76
[Iter 13700/20000] Loss: 0.0003253 (Best: 0.0002504 @iter11719) ([92m↓5.24%[0m) [0.13% of initial]
[Iter 13710/20000] Loss: 0.0003052 (Best: 0.0002504 @iter11719) ([92m↓6.16%[0m) [0.12% of initial]
[Iter 13720/20000] Loss: 0.0003108 (Best: 0.0002504 @iter11719) ([91m↑1.83%[0m) [0.12% of initial]
[Iter 13730/20000] Loss: 0.0003186 (Best: 0.0002504 @iter11719) ([91m↑2.51%[0m) [0.13% of initial]
[Iter 13740/20000] Loss: 0.0003266 (Best: 0.0002504 @iter11719) ([91m↑2.51%[0m) [0.13% of initial]
[Iter 13750/20000] Loss: 0.0002916 (Best: 0.0002504 @iter11719) ([92m↓10.73%[0m) [0.12% of initial]
[Iter 13760/20000] Loss: 0.0003006 (Best: 0.0002504 @iter11719) ([91m↑3.08%[0m) [0.12% of initial]
[Iter 13770/20000] Loss: 0.0003181 (Best: 0.0002504 @iter11719) ([91m↑5.82%[0m) [0.13% of initial]
[Iter 13780/20000] Loss: 0.0003184 (Best: 0.0002504 @iter11719) ([91m↑0.11%[0m) [0.13% of initial]
[Iter 13790/20000] Loss: 0.0004384 (Best: 0.0002504 @iter11719) ([91m↑37.66%[0m) [0.17% of initial]
Iter:13799, L1 loss=0.0004175, Total loss=0.0003408, Time:96
[Iter 13800/20000] Loss: 0.0003561 (Best: 0.0002504 @iter11719) ([92m↓18.76%[0m) [0.14% of initial]
[Iter 13810/20000] Loss: 0.0003408 (Best: 0.0002504 @iter11719) ([92m↓4.30%[0m) [0.14% of initial]
[Iter 13820/20000] Loss: 0.0003248 (Best: 0.0002504 @iter11719) ([92m↓4.69%[0m) [0.13% of initial]
[Iter 13830/20000] Loss: 0.0003212 (Best: 0.0002504 @iter11719) ([92m↓1.11%[0m) [0.13% of initial]
[Iter 13840/20000] Loss: 0.0003065 (Best: 0.0002504 @iter11719) ([92m↓4.60%[0m) [0.12% of initial]
[Iter 13850/20000] Loss: 0.0002873 (Best: 0.0002504 @iter11719) ([92m↓6.25%[0m) [0.11% of initial]
[Iter 13860/20000] Loss: 0.0002863 (Best: 0.0002504 @iter11719) ([92m↓0.35%[0m) [0.11% of initial]
[Iter 13870/20000] Loss: 0.0002811 (Best: 0.0002504 @iter11719) ([92m↓1.80%[0m) [0.11% of initial]
[Iter 13880/20000] Loss: 0.0002890 (Best: 0.0002504 @iter11719) ([91m↑2.78%[0m) [0.11% of initial]
[Iter 13890/20000] Loss: 0.0002958 (Best: 0.0002504 @iter11719) ([91m↑2.35%[0m) [0.12% of initial]
Iter:13899, L1 loss=0.0004116, Total loss=0.0003416, Time:77
[Iter 13900/20000] Loss: 0.0003196 (Best: 0.0002504 @iter11719) ([91m↑8.06%[0m) [0.13% of initial]
[Iter 13910/20000] Loss: 0.0003043 (Best: 0.0002504 @iter11719) ([92m↓4.80%[0m) [0.12% of initial]
[Iter 13920/20000] Loss: 0.0003138 (Best: 0.0002504 @iter11719) ([91m↑3.13%[0m) [0.12% of initial]
[Iter 13930/20000] Loss: 0.0002838 (Best: 0.0002504 @iter11719) ([92m↓9.55%[0m) [0.11% of initial]
[Iter 13940/20000] Loss: 0.0002898 (Best: 0.0002504 @iter11719) ([91m↑2.10%[0m) [0.12% of initial]
[Iter 13950/20000] Loss: 0.0003031 (Best: 0.0002504 @iter11719) ([91m↑4.59%[0m) [0.12% of initial]
[Iter 13960/20000] Loss: 0.0002806 (Best: 0.0002504 @iter11719) ([92m↓7.40%[0m) [0.11% of initial]
[Iter 13970/20000] Loss: 0.0003063 (Best: 0.0002504 @iter11719) ([91m↑9.15%[0m) [0.12% of initial]
[Iter 13980/20000] Loss: 0.0003104 (Best: 0.0002504 @iter11719) ([91m↑1.34%[0m) [0.12% of initial]
[Iter 13990/20000] Loss: 0.0003533 (Best: 0.0002504 @iter11719) ([91m↑13.82%[0m) [0.14% of initial]
Iter:13999, L1 loss=0.0003279, Total loss=0.0002803, Time:87
[Iter 14000/20000] Loss: 0.0003106 (Best: 0.0002504 @iter11719) ([92m↓12.08%[0m) [0.12% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 14000
Pruning 9 points (0.0%) from gaussian1 at iteration 14000
[Iter 14010/20000] Loss: 0.0006339 (Best: 0.0002504 @iter11719) ([91m↑104.07%[0m) [0.25% of initial]
[Iter 14020/20000] Loss: 0.0004628 (Best: 0.0002504 @iter11719) ([92m↓26.98%[0m) [0.18% of initial]
[Iter 14030/20000] Loss: 0.0003826 (Best: 0.0002504 @iter11719) ([92m↓17.34%[0m) [0.15% of initial]
[Iter 14040/20000] Loss: 0.0003318 (Best: 0.0002504 @iter11719) ([92m↓13.27%[0m) [0.13% of initial]
[Iter 14050/20000] Loss: 0.0003310 (Best: 0.0002504 @iter11719) ([92m↓0.24%[0m) [0.13% of initial]
[Iter 14060/20000] Loss: 0.0003228 (Best: 0.0002504 @iter11719) ([92m↓2.49%[0m) [0.13% of initial]
[Iter 14070/20000] Loss: 0.0003024 (Best: 0.0002504 @iter11719) ([92m↓6.30%[0m) [0.12% of initial]
[Iter 14080/20000] Loss: 0.0002908 (Best: 0.0002504 @iter11719) ([92m↓3.85%[0m) [0.12% of initial]
[Iter 14090/20000] Loss: 0.0002859 (Best: 0.0002504 @iter11719) ([92m↓1.69%[0m) [0.11% of initial]
Iter:14099, L1 loss=0.0003339, Total loss=0.0002786, Time:79
[Iter 14100/20000] Loss: 0.0002819 (Best: 0.0002504 @iter11719) ([92m↓1.41%[0m) [0.11% of initial]
[Iter 14110/20000] Loss: 0.0003061 (Best: 0.0002504 @iter11719) ([91m↑8.59%[0m) [0.12% of initial]
[Iter 14120/20000] Loss: 0.0002885 (Best: 0.0002504 @iter11719) ([92m↓5.75%[0m) [0.11% of initial]
[Iter 14130/20000] Loss: 0.0002984 (Best: 0.0002504 @iter11719) ([91m↑3.42%[0m) [0.12% of initial]
[Iter 14140/20000] Loss: 0.0002791 (Best: 0.0002504 @iter11719) ([92m↓6.46%[0m) [0.11% of initial]
[Iter 14150/20000] Loss: 0.0002800 (Best: 0.0002504 @iter11719) ([91m↑0.31%[0m) [0.11% of initial]
[Iter 14160/20000] Loss: 0.0002662 (Best: 0.0002504 @iter11719) ([92m↓4.91%[0m) [0.11% of initial]
[Iter 14170/20000] Loss: 0.0002871 (Best: 0.0002449 @iter14162) ([91m↑7.85%[0m) [0.11% of initial]
[Iter 14180/20000] Loss: 0.0002937 (Best: 0.0002449 @iter14162) ([91m↑2.30%[0m) [0.12% of initial]
[Iter 14190/20000] Loss: 0.0002870 (Best: 0.0002449 @iter14162) ([92m↓2.28%[0m) [0.11% of initial]
Iter:14199, L1 loss=0.0003182, Total loss=0.0002866, Time:77
[Iter 14200/20000] Loss: 0.0002852 (Best: 0.0002449 @iter14162) ([92m↓0.62%[0m) [0.11% of initial]
[Iter 14210/20000] Loss: 0.0002810 (Best: 0.0002449 @iter14162) ([92m↓1.47%[0m) [0.11% of initial]
[Iter 14220/20000] Loss: 0.0002845 (Best: 0.0002449 @iter14162) ([91m↑1.21%[0m) [0.11% of initial]
[Iter 14230/20000] Loss: 0.0003692 (Best: 0.0002449 @iter14162) ([91m↑29.81%[0m) [0.15% of initial]
[Iter 14240/20000] Loss: 0.0003080 (Best: 0.0002449 @iter14162) ([92m↓16.58%[0m) [0.12% of initial]
[Iter 14250/20000] Loss: 0.0003273 (Best: 0.0002449 @iter14162) ([91m↑6.26%[0m) [0.13% of initial]
[Iter 14260/20000] Loss: 0.0003114 (Best: 0.0002449 @iter14162) ([92m↓4.85%[0m) [0.12% of initial]
[Iter 14270/20000] Loss: 0.0003158 (Best: 0.0002449 @iter14162) ([91m↑1.41%[0m) [0.13% of initial]
[Iter 14280/20000] Loss: 0.0002867 (Best: 0.0002449 @iter14162) ([92m↓9.20%[0m) [0.11% of initial]
[Iter 14290/20000] Loss: 0.0002739 (Best: 0.0002449 @iter14162) ([92m↓4.49%[0m) [0.11% of initial]
Iter:14299, L1 loss=0.0003372, Total loss=0.0002797, Time:78
[Iter 14300/20000] Loss: 0.0002800 (Best: 0.0002449 @iter14162) ([91m↑2.23%[0m) [0.11% of initial]
[Iter 14310/20000] Loss: 0.0002960 (Best: 0.0002449 @iter14162) ([91m↑5.70%[0m) [0.12% of initial]
[Iter 14320/20000] Loss: 0.0002812 (Best: 0.0002449 @iter14162) ([92m↓4.98%[0m) [0.11% of initial]
[Iter 14330/20000] Loss: 0.0002901 (Best: 0.0002449 @iter14162) ([91m↑3.17%[0m) [0.12% of initial]
[Iter 14340/20000] Loss: 0.0003244 (Best: 0.0002449 @iter14162) ([91m↑11.81%[0m) [0.13% of initial]
[Iter 14350/20000] Loss: 0.0003288 (Best: 0.0002449 @iter14162) ([91m↑1.35%[0m) [0.13% of initial]
[Iter 14360/20000] Loss: 0.0003111 (Best: 0.0002449 @iter14162) ([92m↓5.36%[0m) [0.12% of initial]
[Iter 14370/20000] Loss: 0.0002957 (Best: 0.0002449 @iter14162) ([92m↓4.97%[0m) [0.12% of initial]
[Iter 14380/20000] Loss: 0.0003027 (Best: 0.0002449 @iter14162) ([91m↑2.36%[0m) [0.12% of initial]
[Iter 14390/20000] Loss: 0.0003163 (Best: 0.0002449 @iter14162) ([91m↑4.51%[0m) [0.13% of initial]
Iter:14399, L1 loss=0.0003162, Total loss=0.0002613, Time:79
[Iter 14400/20000] Loss: 0.0002857 (Best: 0.0002449 @iter14162) ([92m↓9.68%[0m) [0.11% of initial]
[Iter 14410/20000] Loss: 0.0002913 (Best: 0.0002449 @iter14162) ([91m↑1.97%[0m) [0.12% of initial]
[Iter 14420/20000] Loss: 0.0003690 (Best: 0.0002449 @iter14162) ([91m↑26.65%[0m) [0.15% of initial]
[Iter 14430/20000] Loss: 0.0003709 (Best: 0.0002449 @iter14162) ([91m↑0.53%[0m) [0.15% of initial]
[Iter 14440/20000] Loss: 0.0003728 (Best: 0.0002449 @iter14162) ([91m↑0.50%[0m) [0.15% of initial]
[Iter 14450/20000] Loss: 0.0003513 (Best: 0.0002449 @iter14162) ([92m↓5.76%[0m) [0.14% of initial]
[Iter 14460/20000] Loss: 0.0003472 (Best: 0.0002449 @iter14162) ([92m↓1.18%[0m) [0.14% of initial]
[Iter 14470/20000] Loss: 0.0003415 (Best: 0.0002449 @iter14162) ([92m↓1.63%[0m) [0.14% of initial]
[Iter 14480/20000] Loss: 0.0003182 (Best: 0.0002449 @iter14162) ([92m↓6.82%[0m) [0.13% of initial]
[Iter 14490/20000] Loss: 0.0003095 (Best: 0.0002449 @iter14162) ([92m↓2.74%[0m) [0.12% of initial]
Iter:14499, L1 loss=0.000337, Total loss=0.000308, Time:90
[Iter 14500/20000] Loss: 0.0002952 (Best: 0.0002449 @iter14162) ([92m↓4.62%[0m) [0.12% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 14500
Pruning 7 points (0.0%) from gaussian1 at iteration 14500
[Iter 14510/20000] Loss: 0.0006609 (Best: 0.0002449 @iter14162) ([91m↑123.86%[0m) [0.26% of initial]
[Iter 14520/20000] Loss: 0.0005622 (Best: 0.0002449 @iter14162) ([92m↓14.93%[0m) [0.22% of initial]
[Iter 14530/20000] Loss: 0.0004484 (Best: 0.0002449 @iter14162) ([92m↓20.24%[0m) [0.18% of initial]
[Iter 14540/20000] Loss: 0.0004095 (Best: 0.0002449 @iter14162) ([92m↓8.66%[0m) [0.16% of initial]
[Iter 14550/20000] Loss: 0.0003294 (Best: 0.0002449 @iter14162) ([92m↓19.57%[0m) [0.13% of initial]
[Iter 14560/20000] Loss: 0.0002850 (Best: 0.0002449 @iter14162) ([92m↓13.48%[0m) [0.11% of initial]
[Iter 14570/20000] Loss: 0.0002792 (Best: 0.0002449 @iter14162) ([92m↓2.04%[0m) [0.11% of initial]
[Iter 14580/20000] Loss: 0.0002683 (Best: 0.0002411 @iter14578) ([92m↓3.89%[0m) [0.11% of initial]
[Iter 14590/20000] Loss: 0.0002675 (Best: 0.0002411 @iter14578) ([92m↓0.31%[0m) [0.11% of initial]
Iter:14599, L1 loss=0.0003326, Total loss=0.0002822, Time:78
[Iter 14600/20000] Loss: 0.0002861 (Best: 0.0002411 @iter14578) ([91m↑6.98%[0m) [0.11% of initial]
[Iter 14610/20000] Loss: 0.0003211 (Best: 0.0002411 @iter14578) ([91m↑12.22%[0m) [0.13% of initial]
[Iter 14620/20000] Loss: 0.0002952 (Best: 0.0002411 @iter14578) ([92m↓8.06%[0m) [0.12% of initial]
[Iter 14630/20000] Loss: 0.0002651 (Best: 0.0002411 @iter14578) ([92m↓10.22%[0m) [0.11% of initial]
[Iter 14640/20000] Loss: 0.0002861 (Best: 0.0002411 @iter14578) ([91m↑7.92%[0m) [0.11% of initial]
[Iter 14650/20000] Loss: 0.0002900 (Best: 0.0002411 @iter14578) ([91m↑1.38%[0m) [0.12% of initial]
[Iter 14660/20000] Loss: 0.0002753 (Best: 0.0002411 @iter14578) ([92m↓5.08%[0m) [0.11% of initial]
[Iter 14670/20000] Loss: 0.0002702 (Best: 0.0002411 @iter14578) ([92m↓1.85%[0m) [0.11% of initial]
[Iter 14680/20000] Loss: 0.0002738 (Best: 0.0002411 @iter14578) ([91m↑1.36%[0m) [0.11% of initial]
[Iter 14690/20000] Loss: 0.0002632 (Best: 0.0002411 @iter14578) ([92m↓3.88%[0m) [0.10% of initial]
Iter:14699, L1 loss=0.0003338, Total loss=0.0002789, Time:79
[Iter 14700/20000] Loss: 0.0002742 (Best: 0.0002411 @iter14578) ([91m↑4.18%[0m) [0.11% of initial]
[Iter 14710/20000] Loss: 0.0002593 (Best: 0.0002411 @iter14578) ([92m↓5.45%[0m) [0.10% of initial]
[Iter 14720/20000] Loss: 0.0002671 (Best: 0.0002411 @iter14578) ([91m↑3.02%[0m) [0.11% of initial]
[Iter 14730/20000] Loss: 0.0002737 (Best: 0.0002411 @iter14578) ([91m↑2.45%[0m) [0.11% of initial]
[Iter 14740/20000] Loss: 0.0002536 (Best: 0.0002384 @iter14740) ([92m↓7.32%[0m) [0.10% of initial]
[Iter 14750/20000] Loss: 0.0002583 (Best: 0.0002384 @iter14740) ([91m↑1.86%[0m) [0.10% of initial]
[Iter 14760/20000] Loss: 0.0002784 (Best: 0.0002384 @iter14740) ([91m↑7.75%[0m) [0.11% of initial]
[Iter 14770/20000] Loss: 0.0003401 (Best: 0.0002384 @iter14740) ([91m↑22.19%[0m) [0.14% of initial]
[Iter 14780/20000] Loss: 0.0003343 (Best: 0.0002384 @iter14740) ([92m↓1.72%[0m) [0.13% of initial]
[Iter 14790/20000] Loss: 0.0003418 (Best: 0.0002384 @iter14740) ([91m↑2.27%[0m) [0.14% of initial]
Iter:14799, L1 loss=0.0004412, Total loss=0.0003613, Time:82
[Iter 14800/20000] Loss: 0.0003272 (Best: 0.0002384 @iter14740) ([92m↓4.27%[0m) [0.13% of initial]
[Iter 14810/20000] Loss: 0.0003041 (Best: 0.0002384 @iter14740) ([92m↓7.06%[0m) [0.12% of initial]
[Iter 14820/20000] Loss: 0.0002907 (Best: 0.0002384 @iter14740) ([92m↓4.42%[0m) [0.12% of initial]
[Iter 14830/20000] Loss: 0.0002835 (Best: 0.0002384 @iter14740) ([92m↓2.47%[0m) [0.11% of initial]
[Iter 14840/20000] Loss: 0.0002812 (Best: 0.0002384 @iter14740) ([92m↓0.81%[0m) [0.11% of initial]
[Iter 14850/20000] Loss: 0.0002842 (Best: 0.0002384 @iter14740) ([91m↑1.05%[0m) [0.11% of initial]
[Iter 14860/20000] Loss: 0.0002923 (Best: 0.0002384 @iter14740) ([91m↑2.83%[0m) [0.12% of initial]
[Iter 14870/20000] Loss: 0.0002857 (Best: 0.0002384 @iter14740) ([92m↓2.26%[0m) [0.11% of initial]
[Iter 14880/20000] Loss: 0.0002779 (Best: 0.0002384 @iter14740) ([92m↓2.71%[0m) [0.11% of initial]
[Iter 14890/20000] Loss: 0.0002676 (Best: 0.0002384 @iter14740) ([92m↓3.72%[0m) [0.11% of initial]
Iter:14899, L1 loss=0.0003124, Total loss=0.000272, Time:79
[Iter 14900/20000] Loss: 0.0002648 (Best: 0.0002384 @iter14740) ([92m↓1.06%[0m) [0.11% of initial]
[Iter 14910/20000] Loss: 0.0002717 (Best: 0.0002384 @iter14740) ([91m↑2.61%[0m) [0.11% of initial]
[Iter 14920/20000] Loss: 0.0002943 (Best: 0.0002384 @iter14740) ([91m↑8.34%[0m) [0.12% of initial]
[Iter 14930/20000] Loss: 0.0002776 (Best: 0.0002384 @iter14740) ([92m↓5.68%[0m) [0.11% of initial]
[Iter 14940/20000] Loss: 0.0002600 (Best: 0.0002384 @iter14740) ([92m↓6.34%[0m) [0.10% of initial]
[Iter 14950/20000] Loss: 0.0002940 (Best: 0.0002379 @iter14942) ([91m↑13.06%[0m) [0.12% of initial]
[Iter 14960/20000] Loss: 0.0002721 (Best: 0.0002379 @iter14942) ([92m↓7.42%[0m) [0.11% of initial]
[Iter 14970/20000] Loss: 0.0003370 (Best: 0.0002379 @iter14942) ([91m↑23.82%[0m) [0.13% of initial]
[Iter 14980/20000] Loss: 0.0003362 (Best: 0.0002379 @iter14942) ([92m↓0.21%[0m) [0.13% of initial]
[Iter 14990/20000] Loss: 0.0003766 (Best: 0.0002379 @iter14942) ([91m↑12.01%[0m) [0.15% of initial]
Iter:14999, L1 loss=0.0004118, Total loss=0.0003755, Time:92
[Iter 15000/20000] Loss: 0.0004440 (Best: 0.0002379 @iter14942) ([91m↑17.89%[0m) [0.18% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 15000
Pruning 10 points (0.0%) from gaussian1 at iteration 15000
[Iter 15010/20000] Loss: 0.0004882 (Best: 0.0002379 @iter14942) ([91m↑9.96%[0m) [0.19% of initial]
[Iter 15020/20000] Loss: 0.0004160 (Best: 0.0002379 @iter14942) ([92m↓14.80%[0m) [0.17% of initial]
[Iter 15030/20000] Loss: 0.0003216 (Best: 0.0002379 @iter14942) ([92m↓22.69%[0m) [0.13% of initial]
[Iter 15040/20000] Loss: 0.0002905 (Best: 0.0002379 @iter14942) ([92m↓9.68%[0m) [0.12% of initial]
[Iter 15050/20000] Loss: 0.0002717 (Best: 0.0002379 @iter14942) ([92m↓6.48%[0m) [0.11% of initial]
[Iter 15060/20000] Loss: 0.0002844 (Best: 0.0002379 @iter14942) ([91m↑4.70%[0m) [0.11% of initial]
[Iter 15070/20000] Loss: 0.0002657 (Best: 0.0002379 @iter14942) ([92m↓6.57%[0m) [0.11% of initial]
[Iter 15080/20000] Loss: 0.0002599 (Best: 0.0002379 @iter14942) ([92m↓2.21%[0m) [0.10% of initial]
[Iter 15090/20000] Loss: 0.0002577 (Best: 0.0002379 @iter14942) ([92m↓0.84%[0m) [0.10% of initial]
Iter:15099, L1 loss=0.0002834, Total loss=0.0002595, Time:88
[Iter 15100/20000] Loss: 0.0002488 (Best: 0.0002378 @iter15100) ([92m↓3.43%[0m) [0.10% of initial]
[Iter 15110/20000] Loss: 0.0002785 (Best: 0.0002378 @iter15100) ([91m↑11.92%[0m) [0.11% of initial]
[Iter 15120/20000] Loss: 0.0002821 (Best: 0.0002378 @iter15100) ([91m↑1.29%[0m) [0.11% of initial]
[Iter 15130/20000] Loss: 0.0003000 (Best: 0.0002378 @iter15100) ([91m↑6.37%[0m) [0.12% of initial]
[Iter 15140/20000] Loss: 0.0002989 (Best: 0.0002378 @iter15100) ([92m↓0.38%[0m) [0.12% of initial]
[Iter 15150/20000] Loss: 0.0003480 (Best: 0.0002378 @iter15100) ([91m↑16.42%[0m) [0.14% of initial]
[Iter 15160/20000] Loss: 0.0002931 (Best: 0.0002378 @iter15100) ([92m↓15.77%[0m) [0.12% of initial]
[Iter 15170/20000] Loss: 0.0002648 (Best: 0.0002378 @iter15100) ([92m↓9.67%[0m) [0.11% of initial]
[Iter 15180/20000] Loss: 0.0002753 (Best: 0.0002378 @iter15100) ([91m↑3.99%[0m) [0.11% of initial]
[Iter 15190/20000] Loss: 0.0002587 (Best: 0.0002378 @iter15100) ([92m↓6.05%[0m) [0.10% of initial]
Iter:15199, L1 loss=0.0003228, Total loss=0.0002787, Time:76
[Iter 15200/20000] Loss: 0.0002615 (Best: 0.0002378 @iter15100) ([91m↑1.07%[0m) [0.10% of initial]
[Iter 15210/20000] Loss: 0.0003015 (Best: 0.0002378 @iter15100) ([91m↑15.31%[0m) [0.12% of initial]
[Iter 15220/20000] Loss: 0.0003229 (Best: 0.0002378 @iter15100) ([91m↑7.09%[0m) [0.13% of initial]
[Iter 15230/20000] Loss: 0.0002843 (Best: 0.0002378 @iter15100) ([92m↓11.93%[0m) [0.11% of initial]
[Iter 15240/20000] Loss: 0.0002729 (Best: 0.0002378 @iter15100) ([92m↓4.03%[0m) [0.11% of initial]
[Iter 15250/20000] Loss: 0.0002564 (Best: 0.0002378 @iter15100) ([92m↓6.06%[0m) [0.10% of initial]
[Iter 15260/20000] Loss: 0.0002687 (Best: 0.0002378 @iter15100) ([91m↑4.83%[0m) [0.11% of initial]
[Iter 15270/20000] Loss: 0.0002617 (Best: 0.0002378 @iter15100) ([92m↓2.61%[0m) [0.10% of initial]
[Iter 15280/20000] Loss: 0.0002605 (Best: 0.0002375 @iter15277) ([92m↓0.48%[0m) [0.10% of initial]
[Iter 15290/20000] Loss: 0.0002685 (Best: 0.0002338 @iter15283) ([91m↑3.07%[0m) [0.11% of initial]
Iter:15299, L1 loss=0.0003502, Total loss=0.0002775, Time:76
[Iter 15300/20000] Loss: 0.0002817 (Best: 0.0002338 @iter15283) ([91m↑4.92%[0m) [0.11% of initial]
[Iter 15310/20000] Loss: 0.0002956 (Best: 0.0002338 @iter15283) ([91m↑4.95%[0m) [0.12% of initial]
[Iter 15320/20000] Loss: 0.0002785 (Best: 0.0002338 @iter15283) ([92m↓5.79%[0m) [0.11% of initial]
[Iter 15330/20000] Loss: 0.0002778 (Best: 0.0002338 @iter15283) ([92m↓0.27%[0m) [0.11% of initial]
[Iter 15340/20000] Loss: 0.0002733 (Best: 0.0002338 @iter15283) ([92m↓1.62%[0m) [0.11% of initial]
[Iter 15350/20000] Loss: 0.0002756 (Best: 0.0002338 @iter15283) ([91m↑0.85%[0m) [0.11% of initial]
[Iter 15360/20000] Loss: 0.0002797 (Best: 0.0002338 @iter15283) ([91m↑1.50%[0m) [0.11% of initial]
[Iter 15370/20000] Loss: 0.0002760 (Best: 0.0002338 @iter15283) ([92m↓1.32%[0m) [0.11% of initial]
[Iter 15380/20000] Loss: 0.0002692 (Best: 0.0002338 @iter15283) ([92m↓2.46%[0m) [0.11% of initial]
[Iter 15390/20000] Loss: 0.0002678 (Best: 0.0002338 @iter15283) ([92m↓0.53%[0m) [0.11% of initial]
Iter:15399, L1 loss=0.00028, Total loss=0.0002426, Time:85
[Iter 15400/20000] Loss: 0.0002440 (Best: 0.0002338 @iter15283) ([92m↓8.88%[0m) [0.10% of initial]
[Iter 15410/20000] Loss: 0.0002501 (Best: 0.0002295 @iter15409) ([91m↑2.46%[0m) [0.10% of initial]
[Iter 15420/20000] Loss: 0.0002444 (Best: 0.0002245 @iter15412) ([92m↓2.24%[0m) [0.10% of initial]
[Iter 15430/20000] Loss: 0.0002460 (Best: 0.0002245 @iter15412) ([91m↑0.65%[0m) [0.10% of initial]
[Iter 15440/20000] Loss: 0.0002504 (Best: 0.0002245 @iter15412) ([91m↑1.79%[0m) [0.10% of initial]
[Iter 15450/20000] Loss: 0.0002722 (Best: 0.0002245 @iter15412) ([91m↑8.70%[0m) [0.11% of initial]
[Iter 15460/20000] Loss: 0.0003042 (Best: 0.0002245 @iter15412) ([91m↑11.75%[0m) [0.12% of initial]
[Iter 15470/20000] Loss: 0.0003410 (Best: 0.0002245 @iter15412) ([91m↑12.10%[0m) [0.14% of initial]
[Iter 15480/20000] Loss: 0.0003075 (Best: 0.0002245 @iter15412) ([92m↓9.83%[0m) [0.12% of initial]
[Iter 15490/20000] Loss: 0.0002656 (Best: 0.0002245 @iter15412) ([92m↓13.63%[0m) [0.11% of initial]
Iter:15499, L1 loss=0.0003086, Total loss=0.0002632, Time:84
[Iter 15500/20000] Loss: 0.0002759 (Best: 0.0002245 @iter15412) ([91m↑3.89%[0m) [0.11% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 15500
Pruning 5 points (0.0%) from gaussian1 at iteration 15500
[Iter 15510/20000] Loss: 0.0005925 (Best: 0.0002245 @iter15412) ([91m↑114.74%[0m) [0.24% of initial]
[Iter 15520/20000] Loss: 0.0004171 (Best: 0.0002245 @iter15412) ([92m↓29.60%[0m) [0.17% of initial]
[Iter 15530/20000] Loss: 0.0003454 (Best: 0.0002245 @iter15412) ([92m↓17.20%[0m) [0.14% of initial]
[Iter 15540/20000] Loss: 0.0002891 (Best: 0.0002245 @iter15412) ([92m↓16.30%[0m) [0.11% of initial]
[Iter 15550/20000] Loss: 0.0002741 (Best: 0.0002245 @iter15412) ([92m↓5.17%[0m) [0.11% of initial]
[Iter 15560/20000] Loss: 0.0002844 (Best: 0.0002245 @iter15412) ([91m↑3.74%[0m) [0.11% of initial]
[Iter 15570/20000] Loss: 0.0003141 (Best: 0.0002245 @iter15412) ([91m↑10.45%[0m) [0.12% of initial]
[Iter 15580/20000] Loss: 0.0002620 (Best: 0.0002245 @iter15412) ([92m↓16.59%[0m) [0.10% of initial]
[Iter 15590/20000] Loss: 0.0002462 (Best: 0.0002245 @iter15412) ([92m↓6.04%[0m) [0.10% of initial]
Iter:15599, L1 loss=0.0002907, Total loss=0.0002431, Time:94
[Iter 15600/20000] Loss: 0.0002495 (Best: 0.0002245 @iter15412) ([91m↑1.35%[0m) [0.10% of initial]
[Iter 15610/20000] Loss: 0.0002543 (Best: 0.0002245 @iter15412) ([91m↑1.92%[0m) [0.10% of initial]
[Iter 15620/20000] Loss: 0.0002662 (Best: 0.0002245 @iter15412) ([91m↑4.71%[0m) [0.11% of initial]
[Iter 15630/20000] Loss: 0.0002757 (Best: 0.0002245 @iter15412) ([91m↑3.56%[0m) [0.11% of initial]
[Iter 15640/20000] Loss: 0.0002733 (Best: 0.0002245 @iter15412) ([92m↓0.88%[0m) [0.11% of initial]
[Iter 15650/20000] Loss: 0.0003067 (Best: 0.0002245 @iter15412) ([91m↑12.22%[0m) [0.12% of initial]
[Iter 15660/20000] Loss: 0.0002634 (Best: 0.0002245 @iter15412) ([92m↓14.12%[0m) [0.10% of initial]
[Iter 15670/20000] Loss: 0.0002704 (Best: 0.0002245 @iter15412) ([91m↑2.67%[0m) [0.11% of initial]
[Iter 15680/20000] Loss: 0.0003355 (Best: 0.0002245 @iter15412) ([91m↑24.08%[0m) [0.13% of initial]
[Iter 15690/20000] Loss: 0.0003207 (Best: 0.0002245 @iter15412) ([92m↓4.42%[0m) [0.13% of initial]
Iter:15699, L1 loss=0.000316, Total loss=0.000253, Time:96
[Iter 15700/20000] Loss: 0.0002631 (Best: 0.0002245 @iter15412) ([92m↓17.95%[0m) [0.10% of initial]
[Iter 15710/20000] Loss: 0.0002380 (Best: 0.0002245 @iter15412) ([92m↓9.55%[0m) [0.09% of initial]
[Iter 15720/20000] Loss: 0.0002530 (Best: 0.0002245 @iter15412) ([91m↑6.29%[0m) [0.10% of initial]
[Iter 15730/20000] Loss: 0.0002600 (Best: 0.0002245 @iter15412) ([91m↑2.77%[0m) [0.10% of initial]
[Iter 15740/20000] Loss: 0.0002539 (Best: 0.0002245 @iter15412) ([92m↓2.33%[0m) [0.10% of initial]
[Iter 15750/20000] Loss: 0.0002724 (Best: 0.0002245 @iter15412) ([91m↑7.26%[0m) [0.11% of initial]
[Iter 15760/20000] Loss: 0.0002978 (Best: 0.0002245 @iter15412) ([91m↑9.35%[0m) [0.12% of initial]
[Iter 15770/20000] Loss: 0.0003194 (Best: 0.0002245 @iter15412) ([91m↑7.24%[0m) [0.13% of initial]
[Iter 15780/20000] Loss: 0.0002856 (Best: 0.0002245 @iter15412) ([92m↓10.56%[0m) [0.11% of initial]
[Iter 15790/20000] Loss: 0.0002646 (Best: 0.0002245 @iter15412) ([92m↓7.37%[0m) [0.11% of initial]
Iter:15799, L1 loss=0.0002706, Total loss=0.0002378, Time:89
[Iter 15800/20000] Loss: 0.0002568 (Best: 0.0002245 @iter15412) ([92m↓2.94%[0m) [0.10% of initial]
[Iter 15810/20000] Loss: 0.0002716 (Best: 0.0002245 @iter15412) ([91m↑5.77%[0m) [0.11% of initial]
[Iter 15820/20000] Loss: 0.0002787 (Best: 0.0002245 @iter15412) ([91m↑2.59%[0m) [0.11% of initial]
[Iter 15830/20000] Loss: 0.0002763 (Best: 0.0002245 @iter15412) ([92m↓0.85%[0m) [0.11% of initial]
[Iter 15840/20000] Loss: 0.0002655 (Best: 0.0002245 @iter15412) ([92m↓3.90%[0m) [0.11% of initial]
[Iter 15850/20000] Loss: 0.0002740 (Best: 0.0002245 @iter15412) ([91m↑3.20%[0m) [0.11% of initial]
[Iter 15860/20000] Loss: 0.0002930 (Best: 0.0002245 @iter15412) ([91m↑6.93%[0m) [0.12% of initial]
[Iter 15870/20000] Loss: 0.0002852 (Best: 0.0002245 @iter15412) ([92m↓2.67%[0m) [0.11% of initial]
[Iter 15880/20000] Loss: 0.0002800 (Best: 0.0002245 @iter15412) ([92m↓1.81%[0m) [0.11% of initial]
[Iter 15890/20000] Loss: 0.0002611 (Best: 0.0002245 @iter15412) ([92m↓6.76%[0m) [0.10% of initial]
Iter:15899, L1 loss=0.0002713, Total loss=0.0002309, Time:92
[Iter 15900/20000] Loss: 0.0002342 (Best: 0.0002245 @iter15412) ([92m↓10.28%[0m) [0.09% of initial]
[Iter 15910/20000] Loss: 0.0002335 (Best: 0.0002176 @iter15902) ([92m↓0.33%[0m) [0.09% of initial]
[Iter 15920/20000] Loss: 0.0002378 (Best: 0.0002176 @iter15902) ([91m↑1.87%[0m) [0.09% of initial]
[Iter 15930/20000] Loss: 0.0002324 (Best: 0.0002176 @iter15902) ([92m↓2.29%[0m) [0.09% of initial]
[Iter 15940/20000] Loss: 0.0002233 (Best: 0.0002150 @iter15940) ([92m↓3.91%[0m) [0.09% of initial]
[Iter 15950/20000] Loss: 0.0002679 (Best: 0.0002150 @iter15940) ([91m↑19.97%[0m) [0.11% of initial]
[Iter 15960/20000] Loss: 0.0002487 (Best: 0.0002150 @iter15940) ([92m↓7.17%[0m) [0.10% of initial]
[Iter 15970/20000] Loss: 0.0002457 (Best: 0.0002150 @iter15940) ([92m↓1.23%[0m) [0.10% of initial]
[Iter 15980/20000] Loss: 0.0002383 (Best: 0.0002150 @iter15940) ([92m↓3.01%[0m) [0.09% of initial]
[Iter 15990/20000] Loss: 0.0002573 (Best: 0.0002150 @iter15940) ([91m↑7.99%[0m) [0.10% of initial]
Iter:15999, L1 loss=0.000319, Total loss=0.0002585, Time:77
[Iter 16000/20000] Loss: 0.0002604 (Best: 0.0002150 @iter15940) ([91m↑1.18%[0m) [0.10% of initial]
Pruning 10 points (0.0%) from gaussian0 at iteration 16000
Pruning 4 points (0.0%) from gaussian1 at iteration 16000
[Iter 16010/20000] Loss: 0.0133215 (Best: 0.0002150 @iter15940) ([91m↑5016.74%[0m) [5.29% of initial]
[Iter 16020/20000] Loss: 0.0054854 (Best: 0.0002150 @iter15940) ([92m↓58.82%[0m) [2.18% of initial]
[Iter 16030/20000] Loss: 0.0025231 (Best: 0.0002150 @iter15940) ([92m↓54.00%[0m) [1.00% of initial]
[Iter 16040/20000] Loss: 0.0017262 (Best: 0.0002150 @iter15940) ([92m↓31.58%[0m) [0.69% of initial]
[Iter 16050/20000] Loss: 0.0011595 (Best: 0.0002150 @iter15940) ([92m↓32.83%[0m) [0.46% of initial]
[Iter 16060/20000] Loss: 0.0008763 (Best: 0.0002150 @iter15940) ([92m↓24.43%[0m) [0.35% of initial]
[Iter 16070/20000] Loss: 0.0006996 (Best: 0.0002150 @iter15940) ([92m↓20.16%[0m) [0.28% of initial]
[Iter 16080/20000] Loss: 0.0006046 (Best: 0.0002150 @iter15940) ([92m↓13.58%[0m) [0.24% of initial]
[Iter 16090/20000] Loss: 0.0005234 (Best: 0.0002150 @iter15940) ([92m↓13.43%[0m) [0.21% of initial]
Iter:16099, L1 loss=0.0004968, Total loss=0.0004464, Time:97
[Iter 16100/20000] Loss: 0.0004619 (Best: 0.0002150 @iter15940) ([92m↓11.76%[0m) [0.18% of initial]
[Iter 16110/20000] Loss: 0.0004341 (Best: 0.0002150 @iter15940) ([92m↓6.01%[0m) [0.17% of initial]
[Iter 16120/20000] Loss: 0.0004042 (Best: 0.0002150 @iter15940) ([92m↓6.89%[0m) [0.16% of initial]
[Iter 16130/20000] Loss: 0.0003860 (Best: 0.0002150 @iter15940) ([92m↓4.51%[0m) [0.15% of initial]
[Iter 16140/20000] Loss: 0.0003625 (Best: 0.0002150 @iter15940) ([92m↓6.09%[0m) [0.14% of initial]
[Iter 16150/20000] Loss: 0.0003457 (Best: 0.0002150 @iter15940) ([92m↓4.62%[0m) [0.14% of initial]
[Iter 16160/20000] Loss: 0.0003405 (Best: 0.0002150 @iter15940) ([92m↓1.51%[0m) [0.14% of initial]
[Iter 16170/20000] Loss: 0.0003379 (Best: 0.0002150 @iter15940) ([92m↓0.76%[0m) [0.13% of initial]
[Iter 16180/20000] Loss: 0.0003334 (Best: 0.0002150 @iter15940) ([92m↓1.34%[0m) [0.13% of initial]
[Iter 16190/20000] Loss: 0.0003271 (Best: 0.0002150 @iter15940) ([92m↓1.90%[0m) [0.13% of initial]
Iter:16199, L1 loss=0.0003705, Total loss=0.0003187, Time:84
[Iter 16200/20000] Loss: 0.0003246 (Best: 0.0002150 @iter15940) ([92m↓0.76%[0m) [0.13% of initial]
[Iter 16210/20000] Loss: 0.0003342 (Best: 0.0002150 @iter15940) ([91m↑2.98%[0m) [0.13% of initial]
[Iter 16220/20000] Loss: 0.0003275 (Best: 0.0002150 @iter15940) ([92m↓2.00%[0m) [0.13% of initial]
[Iter 16230/20000] Loss: 0.0003258 (Best: 0.0002150 @iter15940) ([92m↓0.55%[0m) [0.13% of initial]
[Iter 16240/20000] Loss: 0.0003499 (Best: 0.0002150 @iter15940) ([91m↑7.41%[0m) [0.14% of initial]
[Iter 16250/20000] Loss: 0.0003218 (Best: 0.0002150 @iter15940) ([92m↓8.04%[0m) [0.13% of initial]
[Iter 16260/20000] Loss: 0.0003084 (Best: 0.0002150 @iter15940) ([92m↓4.16%[0m) [0.12% of initial]
[Iter 16270/20000] Loss: 0.0002952 (Best: 0.0002150 @iter15940) ([92m↓4.26%[0m) [0.12% of initial]
[Iter 16280/20000] Loss: 0.0002910 (Best: 0.0002150 @iter15940) ([92m↓1.41%[0m) [0.12% of initial]
[Iter 16290/20000] Loss: 0.0003009 (Best: 0.0002150 @iter15940) ([91m↑3.39%[0m) [0.12% of initial]
Iter:16299, L1 loss=0.0003774, Total loss=0.0003278, Time:81
[Iter 16300/20000] Loss: 0.0002993 (Best: 0.0002150 @iter15940) ([92m↓0.55%[0m) [0.12% of initial]
[Iter 16310/20000] Loss: 0.0003200 (Best: 0.0002150 @iter15940) ([91m↑6.93%[0m) [0.13% of initial]
[Iter 16320/20000] Loss: 0.0003201 (Best: 0.0002150 @iter15940) ([91m↑0.02%[0m) [0.13% of initial]
[Iter 16330/20000] Loss: 0.0003142 (Best: 0.0002150 @iter15940) ([92m↓1.85%[0m) [0.12% of initial]
[Iter 16340/20000] Loss: 0.0003152 (Best: 0.0002150 @iter15940) ([91m↑0.33%[0m) [0.13% of initial]
[Iter 16350/20000] Loss: 0.0003182 (Best: 0.0002150 @iter15940) ([91m↑0.94%[0m) [0.13% of initial]
[Iter 16360/20000] Loss: 0.0003076 (Best: 0.0002150 @iter15940) ([92m↓3.31%[0m) [0.12% of initial]
[Iter 16370/20000] Loss: 0.0003451 (Best: 0.0002150 @iter15940) ([91m↑12.19%[0m) [0.14% of initial]
[Iter 16380/20000] Loss: 0.0003396 (Best: 0.0002150 @iter15940) ([92m↓1.61%[0m) [0.13% of initial]
[Iter 16390/20000] Loss: 0.0003629 (Best: 0.0002150 @iter15940) ([91m↑6.88%[0m) [0.14% of initial]
Iter:16399, L1 loss=0.0003323, Total loss=0.0002995, Time:92
[Iter 16400/20000] Loss: 0.0003269 (Best: 0.0002150 @iter15940) ([92m↓9.93%[0m) [0.13% of initial]
[Iter 16410/20000] Loss: 0.0003317 (Best: 0.0002150 @iter15940) ([91m↑1.48%[0m) [0.13% of initial]
[Iter 16420/20000] Loss: 0.0003123 (Best: 0.0002150 @iter15940) ([92m↓5.84%[0m) [0.12% of initial]
[Iter 16430/20000] Loss: 0.0003017 (Best: 0.0002150 @iter15940) ([92m↓3.42%[0m) [0.12% of initial]
[Iter 16440/20000] Loss: 0.0002991 (Best: 0.0002150 @iter15940) ([92m↓0.85%[0m) [0.12% of initial]
[Iter 16450/20000] Loss: 0.0003015 (Best: 0.0002150 @iter15940) ([91m↑0.80%[0m) [0.12% of initial]
[Iter 16460/20000] Loss: 0.0002903 (Best: 0.0002150 @iter15940) ([92m↓3.70%[0m) [0.12% of initial]
[Iter 16470/20000] Loss: 0.0003004 (Best: 0.0002150 @iter15940) ([91m↑3.48%[0m) [0.12% of initial]
[Iter 16480/20000] Loss: 0.0002903 (Best: 0.0002150 @iter15940) ([92m↓3.39%[0m) [0.12% of initial]
[Iter 16490/20000] Loss: 0.0002865 (Best: 0.0002150 @iter15940) ([92m↓1.29%[0m) [0.11% of initial]
Iter:16499, L1 loss=0.0003566, Total loss=0.0003245, Time:94
[Iter 16500/20000] Loss: 0.0003330 (Best: 0.0002150 @iter15940) ([91m↑16.22%[0m) [0.13% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 16500
Pruning 5 points (0.0%) from gaussian1 at iteration 16500
[Iter 16510/20000] Loss: 0.0005367 (Best: 0.0002150 @iter15940) ([91m↑61.19%[0m) [0.21% of initial]
[Iter 16520/20000] Loss: 0.0004144 (Best: 0.0002150 @iter15940) ([92m↓22.80%[0m) [0.16% of initial]
[Iter 16530/20000] Loss: 0.0003520 (Best: 0.0002150 @iter15940) ([92m↓15.06%[0m) [0.14% of initial]
[Iter 16540/20000] Loss: 0.0003233 (Best: 0.0002150 @iter15940) ([92m↓8.14%[0m) [0.13% of initial]
[Iter 16550/20000] Loss: 0.0002968 (Best: 0.0002150 @iter15940) ([92m↓8.22%[0m) [0.12% of initial]
[Iter 16560/20000] Loss: 0.0002938 (Best: 0.0002150 @iter15940) ([92m↓1.00%[0m) [0.12% of initial]
[Iter 16570/20000] Loss: 0.0002920 (Best: 0.0002150 @iter15940) ([92m↓0.61%[0m) [0.12% of initial]
[Iter 16580/20000] Loss: 0.0002890 (Best: 0.0002150 @iter15940) ([92m↓1.04%[0m) [0.11% of initial]
[Iter 16590/20000] Loss: 0.0002953 (Best: 0.0002150 @iter15940) ([91m↑2.18%[0m) [0.12% of initial]
Iter:16599, L1 loss=0.0003381, Total loss=0.0002876, Time:91
[Iter 16600/20000] Loss: 0.0002822 (Best: 0.0002150 @iter15940) ([92m↓4.41%[0m) [0.11% of initial]
[Iter 16610/20000] Loss: 0.0002817 (Best: 0.0002150 @iter15940) ([92m↓0.18%[0m) [0.11% of initial]
[Iter 16620/20000] Loss: 0.0002918 (Best: 0.0002150 @iter15940) ([91m↑3.57%[0m) [0.12% of initial]
[Iter 16630/20000] Loss: 0.0003156 (Best: 0.0002150 @iter15940) ([91m↑8.15%[0m) [0.13% of initial]
[Iter 16640/20000] Loss: 0.0003318 (Best: 0.0002150 @iter15940) ([91m↑5.16%[0m) [0.13% of initial]
[Iter 16650/20000] Loss: 0.0003667 (Best: 0.0002150 @iter15940) ([91m↑10.50%[0m) [0.15% of initial]
[Iter 16660/20000] Loss: 0.0004287 (Best: 0.0002150 @iter15940) ([91m↑16.91%[0m) [0.17% of initial]
[Iter 16670/20000] Loss: 0.0003741 (Best: 0.0002150 @iter15940) ([92m↓12.73%[0m) [0.15% of initial]
[Iter 16680/20000] Loss: 0.0003238 (Best: 0.0002150 @iter15940) ([92m↓13.45%[0m) [0.13% of initial]
[Iter 16690/20000] Loss: 0.0002972 (Best: 0.0002150 @iter15940) ([92m↓8.23%[0m) [0.12% of initial]
Iter:16699, L1 loss=0.000358, Total loss=0.0003131, Time:91
[Iter 16700/20000] Loss: 0.0002980 (Best: 0.0002150 @iter15940) ([91m↑0.29%[0m) [0.12% of initial]
[Iter 16710/20000] Loss: 0.0002991 (Best: 0.0002150 @iter15940) ([91m↑0.37%[0m) [0.12% of initial]
[Iter 16720/20000] Loss: 0.0003151 (Best: 0.0002150 @iter15940) ([91m↑5.34%[0m) [0.13% of initial]
[Iter 16730/20000] Loss: 0.0002978 (Best: 0.0002150 @iter15940) ([92m↓5.50%[0m) [0.12% of initial]
[Iter 16740/20000] Loss: 0.0003011 (Best: 0.0002150 @iter15940) ([91m↑1.11%[0m) [0.12% of initial]
[Iter 16750/20000] Loss: 0.0002882 (Best: 0.0002150 @iter15940) ([92m↓4.28%[0m) [0.11% of initial]
[Iter 16760/20000] Loss: 0.0002841 (Best: 0.0002150 @iter15940) ([92m↓1.43%[0m) [0.11% of initial]
[Iter 16770/20000] Loss: 0.0002832 (Best: 0.0002150 @iter15940) ([92m↓0.32%[0m) [0.11% of initial]
[Iter 16780/20000] Loss: 0.0002881 (Best: 0.0002150 @iter15940) ([91m↑1.73%[0m) [0.11% of initial]
[Iter 16790/20000] Loss: 0.0003007 (Best: 0.0002150 @iter15940) ([91m↑4.38%[0m) [0.12% of initial]
Iter:16799, L1 loss=0.0003448, Total loss=0.0003235, Time:93
[Iter 16800/20000] Loss: 0.0003063 (Best: 0.0002150 @iter15940) ([91m↑1.89%[0m) [0.12% of initial]
[Iter 16810/20000] Loss: 0.0003622 (Best: 0.0002150 @iter15940) ([91m↑18.24%[0m) [0.14% of initial]
[Iter 16820/20000] Loss: 0.0003458 (Best: 0.0002150 @iter15940) ([92m↓4.55%[0m) [0.14% of initial]
[Iter 16830/20000] Loss: 0.0003374 (Best: 0.0002150 @iter15940) ([92m↓2.41%[0m) [0.13% of initial]
[Iter 16840/20000] Loss: 0.0004431 (Best: 0.0002150 @iter15940) ([91m↑31.32%[0m) [0.18% of initial]
[Iter 16850/20000] Loss: 0.0003529 (Best: 0.0002150 @iter15940) ([92m↓20.35%[0m) [0.14% of initial]
[Iter 16860/20000] Loss: 0.0003202 (Best: 0.0002150 @iter15940) ([92m↓9.28%[0m) [0.13% of initial]
[Iter 16870/20000] Loss: 0.0002942 (Best: 0.0002150 @iter15940) ([92m↓8.11%[0m) [0.12% of initial]
[Iter 16880/20000] Loss: 0.0004646 (Best: 0.0002150 @iter15940) ([91m↑57.92%[0m) [0.18% of initial]
[Iter 16890/20000] Loss: 0.0003159 (Best: 0.0002150 @iter15940) ([92m↓32.01%[0m) [0.13% of initial]
Iter:16899, L1 loss=0.0004013, Total loss=0.0003564, Time:90
[Iter 16900/20000] Loss: 0.0003033 (Best: 0.0002150 @iter15940) ([92m↓4.01%[0m) [0.12% of initial]
[Iter 16910/20000] Loss: 0.0002899 (Best: 0.0002150 @iter15940) ([92m↓4.42%[0m) [0.12% of initial]
[Iter 16920/20000] Loss: 0.0003388 (Best: 0.0002150 @iter15940) ([91m↑16.89%[0m) [0.13% of initial]
[Iter 16930/20000] Loss: 0.0003149 (Best: 0.0002150 @iter15940) ([92m↓7.07%[0m) [0.13% of initial]
[Iter 16940/20000] Loss: 0.0003407 (Best: 0.0002150 @iter15940) ([91m↑8.20%[0m) [0.14% of initial]
[Iter 16950/20000] Loss: 0.0003092 (Best: 0.0002150 @iter15940) ([92m↓9.24%[0m) [0.12% of initial]
[Iter 16960/20000] Loss: 0.0003044 (Best: 0.0002150 @iter15940) ([92m↓1.54%[0m) [0.12% of initial]
[Iter 16970/20000] Loss: 0.0003069 (Best: 0.0002150 @iter15940) ([91m↑0.80%[0m) [0.12% of initial]
[Iter 16980/20000] Loss: 0.0002908 (Best: 0.0002150 @iter15940) ([92m↓5.24%[0m) [0.12% of initial]
[Iter 16990/20000] Loss: 0.0002990 (Best: 0.0002150 @iter15940) ([91m↑2.81%[0m) [0.12% of initial]
Iter:16999, L1 loss=0.0003541, Total loss=0.0002921, Time:107
[Iter 17000/20000] Loss: 0.0002888 (Best: 0.0002150 @iter15940) ([92m↓3.41%[0m) [0.11% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 17000
Pruning 6 points (0.0%) from gaussian1 at iteration 17000
[Iter 17010/20000] Loss: 0.0005465 (Best: 0.0002150 @iter15940) ([91m↑89.26%[0m) [0.22% of initial]
[Iter 17020/20000] Loss: 0.0004008 (Best: 0.0002150 @iter15940) ([92m↓26.67%[0m) [0.16% of initial]
[Iter 17030/20000] Loss: 0.0003311 (Best: 0.0002150 @iter15940) ([92m↓17.39%[0m) [0.13% of initial]
[Iter 17040/20000] Loss: 0.0002929 (Best: 0.0002150 @iter15940) ([92m↓11.52%[0m) [0.12% of initial]
[Iter 17050/20000] Loss: 0.0002964 (Best: 0.0002150 @iter15940) ([91m↑1.19%[0m) [0.12% of initial]
[Iter 17060/20000] Loss: 0.0003479 (Best: 0.0002150 @iter15940) ([91m↑17.38%[0m) [0.14% of initial]
[Iter 17070/20000] Loss: 0.0003594 (Best: 0.0002150 @iter15940) ([91m↑3.29%[0m) [0.14% of initial]
[Iter 17080/20000] Loss: 0.0003113 (Best: 0.0002150 @iter15940) ([92m↓13.39%[0m) [0.12% of initial]
[Iter 17090/20000] Loss: 0.0002830 (Best: 0.0002150 @iter15940) ([92m↓9.07%[0m) [0.11% of initial]
Iter:17099, L1 loss=0.0002892, Total loss=0.0002539, Time:98
[Iter 17100/20000] Loss: 0.0002686 (Best: 0.0002150 @iter15940) ([92m↓5.10%[0m) [0.11% of initial]
[Iter 17110/20000] Loss: 0.0002745 (Best: 0.0002150 @iter15940) ([91m↑2.21%[0m) [0.11% of initial]
[Iter 17120/20000] Loss: 0.0002633 (Best: 0.0002150 @iter15940) ([92m↓4.09%[0m) [0.10% of initial]
[Iter 17130/20000] Loss: 0.0002707 (Best: 0.0002150 @iter15940) ([91m↑2.81%[0m) [0.11% of initial]
[Iter 17140/20000] Loss: 0.0002884 (Best: 0.0002150 @iter15940) ([91m↑6.55%[0m) [0.11% of initial]
[Iter 17150/20000] Loss: 0.0002763 (Best: 0.0002150 @iter15940) ([92m↓4.20%[0m) [0.11% of initial]
[Iter 17160/20000] Loss: 0.0002874 (Best: 0.0002150 @iter15940) ([91m↑4.01%[0m) [0.11% of initial]
[Iter 17170/20000] Loss: 0.0002925 (Best: 0.0002150 @iter15940) ([91m↑1.76%[0m) [0.12% of initial]
[Iter 17180/20000] Loss: 0.0002705 (Best: 0.0002150 @iter15940) ([92m↓7.51%[0m) [0.11% of initial]
[Iter 17190/20000] Loss: 0.0002792 (Best: 0.0002150 @iter15940) ([91m↑3.20%[0m) [0.11% of initial]
Iter:17199, L1 loss=0.000317, Total loss=0.0002626, Time:92
[Iter 17200/20000] Loss: 0.0002704 (Best: 0.0002150 @iter15940) ([92m↓3.13%[0m) [0.11% of initial]
[Iter 17210/20000] Loss: 0.0002726 (Best: 0.0002150 @iter15940) ([91m↑0.82%[0m) [0.11% of initial]
[Iter 17220/20000] Loss: 0.0002674 (Best: 0.0002150 @iter15940) ([92m↓1.93%[0m) [0.11% of initial]
[Iter 17230/20000] Loss: 0.0002655 (Best: 0.0002150 @iter15940) ([92m↓0.71%[0m) [0.11% of initial]
[Iter 17240/20000] Loss: 0.0003028 (Best: 0.0002150 @iter15940) ([91m↑14.06%[0m) [0.12% of initial]
[Iter 17250/20000] Loss: 0.0003202 (Best: 0.0002150 @iter15940) ([91m↑5.73%[0m) [0.13% of initial]
[Iter 17260/20000] Loss: 0.0002908 (Best: 0.0002150 @iter15940) ([92m↓9.17%[0m) [0.12% of initial]
[Iter 17270/20000] Loss: 0.0002994 (Best: 0.0002150 @iter15940) ([91m↑2.96%[0m) [0.12% of initial]
[Iter 17280/20000] Loss: 0.0002951 (Best: 0.0002150 @iter15940) ([92m↓1.44%[0m) [0.12% of initial]
[Iter 17290/20000] Loss: 0.0004100 (Best: 0.0002150 @iter15940) ([91m↑38.92%[0m) [0.16% of initial]
Iter:17299, L1 loss=0.0003532, Total loss=0.0003056, Time:85
[Iter 17300/20000] Loss: 0.0003233 (Best: 0.0002150 @iter15940) ([92m↓21.15%[0m) [0.13% of initial]
[Iter 17310/20000] Loss: 0.0003111 (Best: 0.0002150 @iter15940) ([92m↓3.75%[0m) [0.12% of initial]
[Iter 17320/20000] Loss: 0.0003285 (Best: 0.0002150 @iter15940) ([91m↑5.58%[0m) [0.13% of initial]
[Iter 17330/20000] Loss: 0.0002906 (Best: 0.0002150 @iter15940) ([92m↓11.55%[0m) [0.12% of initial]
[Iter 17340/20000] Loss: 0.0002770 (Best: 0.0002150 @iter15940) ([92m↓4.67%[0m) [0.11% of initial]
[Iter 17350/20000] Loss: 0.0002984 (Best: 0.0002150 @iter15940) ([91m↑7.70%[0m) [0.12% of initial]
[Iter 17360/20000] Loss: 0.0002996 (Best: 0.0002150 @iter15940) ([91m↑0.42%[0m) [0.12% of initial]
[Iter 17370/20000] Loss: 0.0002798 (Best: 0.0002150 @iter15940) ([92m↓6.60%[0m) [0.11% of initial]
[Iter 17380/20000] Loss: 0.0003073 (Best: 0.0002150 @iter15940) ([91m↑9.81%[0m) [0.12% of initial]
[Iter 17390/20000] Loss: 0.0003020 (Best: 0.0002150 @iter15940) ([92m↓1.71%[0m) [0.12% of initial]
Iter:17399, L1 loss=0.0003362, Total loss=0.0002887, Time:91
[Iter 17400/20000] Loss: 0.0002969 (Best: 0.0002150 @iter15940) ([92m↓1.71%[0m) [0.12% of initial]
[Iter 17410/20000] Loss: 0.0003001 (Best: 0.0002150 @iter15940) ([91m↑1.07%[0m) [0.12% of initial]
[Iter 17420/20000] Loss: 0.0003159 (Best: 0.0002150 @iter15940) ([91m↑5.29%[0m) [0.13% of initial]
[Iter 17430/20000] Loss: 0.0003314 (Best: 0.0002150 @iter15940) ([91m↑4.89%[0m) [0.13% of initial]
[Iter 17440/20000] Loss: 0.0003083 (Best: 0.0002150 @iter15940) ([92m↓6.97%[0m) [0.12% of initial]
[Iter 17450/20000] Loss: 0.0003001 (Best: 0.0002150 @iter15940) ([92m↓2.65%[0m) [0.12% of initial]
[Iter 17460/20000] Loss: 0.0003326 (Best: 0.0002150 @iter15940) ([91m↑10.82%[0m) [0.13% of initial]
[Iter 17470/20000] Loss: 0.0003019 (Best: 0.0002150 @iter15940) ([92m↓9.25%[0m) [0.12% of initial]
[Iter 17480/20000] Loss: 0.0003050 (Best: 0.0002150 @iter15940) ([91m↑1.04%[0m) [0.12% of initial]
[Iter 17490/20000] Loss: 0.0003058 (Best: 0.0002150 @iter15940) ([91m↑0.28%[0m) [0.12% of initial]
Iter:17499, L1 loss=0.0003565, Total loss=0.0002837, Time:83
[Iter 17500/20000] Loss: 0.0002771 (Best: 0.0002150 @iter15940) ([92m↓9.40%[0m) [0.11% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 17500
Pruning 2 points (0.0%) from gaussian1 at iteration 17500
[Iter 17510/20000] Loss: 0.0005556 (Best: 0.0002150 @iter15940) ([91m↑100.50%[0m) [0.22% of initial]
[Iter 17520/20000] Loss: 0.0004079 (Best: 0.0002150 @iter15940) ([92m↓26.57%[0m) [0.16% of initial]
[Iter 17530/20000] Loss: 0.0003155 (Best: 0.0002150 @iter15940) ([92m↓22.66%[0m) [0.13% of initial]
[Iter 17540/20000] Loss: 0.0002926 (Best: 0.0002150 @iter15940) ([92m↓7.26%[0m) [0.12% of initial]
[Iter 17550/20000] Loss: 0.0002680 (Best: 0.0002150 @iter15940) ([92m↓8.41%[0m) [0.11% of initial]
[Iter 17560/20000] Loss: 0.0002581 (Best: 0.0002150 @iter15940) ([92m↓3.68%[0m) [0.10% of initial]
[Iter 17570/20000] Loss: 0.0002838 (Best: 0.0002150 @iter15940) ([91m↑9.93%[0m) [0.11% of initial]
[Iter 17580/20000] Loss: 0.0002653 (Best: 0.0002150 @iter15940) ([92m↓6.50%[0m) [0.11% of initial]
[Iter 17590/20000] Loss: 0.0002624 (Best: 0.0002150 @iter15940) ([92m↓1.10%[0m) [0.10% of initial]
Iter:17599, L1 loss=0.0003017, Total loss=0.0002553, Time:90
[Iter 17600/20000] Loss: 0.0002863 (Best: 0.0002150 @iter15940) ([91m↑9.10%[0m) [0.11% of initial]
[Iter 17610/20000] Loss: 0.0002798 (Best: 0.0002150 @iter15940) ([92m↓2.25%[0m) [0.11% of initial]
[Iter 17620/20000] Loss: 0.0002785 (Best: 0.0002150 @iter15940) ([92m↓0.49%[0m) [0.11% of initial]
[Iter 17630/20000] Loss: 0.0002719 (Best: 0.0002150 @iter15940) ([92m↓2.36%[0m) [0.11% of initial]
[Iter 17640/20000] Loss: 0.0002775 (Best: 0.0002150 @iter15940) ([91m↑2.07%[0m) [0.11% of initial]
[Iter 17650/20000] Loss: 0.0002885 (Best: 0.0002150 @iter15940) ([91m↑3.97%[0m) [0.11% of initial]
[Iter 17660/20000] Loss: 0.0002916 (Best: 0.0002150 @iter15940) ([91m↑1.07%[0m) [0.12% of initial]
[Iter 17670/20000] Loss: 0.0002918 (Best: 0.0002150 @iter15940) ([91m↑0.08%[0m) [0.12% of initial]
[Iter 17680/20000] Loss: 0.0002923 (Best: 0.0002150 @iter15940) ([91m↑0.14%[0m) [0.12% of initial]
[Iter 17690/20000] Loss: 0.0002923 (Best: 0.0002150 @iter15940) ([92m↓0.00%[0m) [0.12% of initial]
Iter:17699, L1 loss=0.0002979, Total loss=0.0002532, Time:90
[Iter 17700/20000] Loss: 0.0002788 (Best: 0.0002150 @iter15940) ([92m↓4.62%[0m) [0.11% of initial]
[Iter 17710/20000] Loss: 0.0002648 (Best: 0.0002150 @iter15940) ([92m↓5.01%[0m) [0.11% of initial]
[Iter 17720/20000] Loss: 0.0003104 (Best: 0.0002150 @iter15940) ([91m↑17.24%[0m) [0.12% of initial]
[Iter 17730/20000] Loss: 0.0003002 (Best: 0.0002150 @iter15940) ([92m↓3.30%[0m) [0.12% of initial]
[Iter 17740/20000] Loss: 0.0002770 (Best: 0.0002150 @iter15940) ([92m↓7.74%[0m) [0.11% of initial]
[Iter 17750/20000] Loss: 0.0002703 (Best: 0.0002150 @iter15940) ([92m↓2.40%[0m) [0.11% of initial]
[Iter 17760/20000] Loss: 0.0002564 (Best: 0.0002150 @iter15940) ([92m↓5.14%[0m) [0.10% of initial]
[Iter 17770/20000] Loss: 0.0002491 (Best: 0.0002150 @iter15940) ([92m↓2.87%[0m) [0.10% of initial]
[Iter 17780/20000] Loss: 0.0002575 (Best: 0.0002150 @iter15940) ([91m↑3.39%[0m) [0.10% of initial]
[Iter 17790/20000] Loss: 0.0003060 (Best: 0.0002150 @iter15940) ([91m↑18.82%[0m) [0.12% of initial]
Iter:17799, L1 loss=0.0004286, Total loss=0.0003743, Time:82
[Iter 17800/20000] Loss: 0.0003404 (Best: 0.0002150 @iter15940) ([91m↑11.26%[0m) [0.14% of initial]
[Iter 17810/20000] Loss: 0.0003112 (Best: 0.0002150 @iter15940) ([92m↓8.57%[0m) [0.12% of initial]
[Iter 17820/20000] Loss: 0.0003152 (Best: 0.0002150 @iter15940) ([91m↑1.27%[0m) [0.13% of initial]
[Iter 17830/20000] Loss: 0.0002719 (Best: 0.0002150 @iter15940) ([92m↓13.74%[0m) [0.11% of initial]
[Iter 17840/20000] Loss: 0.0002577 (Best: 0.0002150 @iter15940) ([92m↓5.22%[0m) [0.10% of initial]
[Iter 17850/20000] Loss: 0.0002580 (Best: 0.0002150 @iter15940) ([91m↑0.14%[0m) [0.10% of initial]
[Iter 17860/20000] Loss: 0.0002540 (Best: 0.0002150 @iter15940) ([92m↓1.58%[0m) [0.10% of initial]
[Iter 17870/20000] Loss: 0.0002568 (Best: 0.0002150 @iter15940) ([91m↑1.13%[0m) [0.10% of initial]
[Iter 17880/20000] Loss: 0.0002712 (Best: 0.0002150 @iter15940) ([91m↑5.61%[0m) [0.11% of initial]
[Iter 17890/20000] Loss: 0.0002520 (Best: 0.0002150 @iter15940) ([92m↓7.10%[0m) [0.10% of initial]
Iter:17899, L1 loss=0.0003236, Total loss=0.0002443, Time:100
[Iter 17900/20000] Loss: 0.0002553 (Best: 0.0002150 @iter15940) ([91m↑1.31%[0m) [0.10% of initial]
[Iter 17910/20000] Loss: 0.0002546 (Best: 0.0002150 @iter15940) ([92m↓0.24%[0m) [0.10% of initial]
[Iter 17920/20000] Loss: 0.0002734 (Best: 0.0002150 @iter15940) ([91m↑7.35%[0m) [0.11% of initial]
[Iter 17930/20000] Loss: 0.0002579 (Best: 0.0002150 @iter15940) ([92m↓5.67%[0m) [0.10% of initial]
[Iter 17940/20000] Loss: 0.0002575 (Best: 0.0002150 @iter15940) ([92m↓0.16%[0m) [0.10% of initial]
[Iter 17950/20000] Loss: 0.0002581 (Best: 0.0002150 @iter15940) ([91m↑0.26%[0m) [0.10% of initial]
[Iter 17960/20000] Loss: 0.0002670 (Best: 0.0002150 @iter15940) ([91m↑3.43%[0m) [0.11% of initial]
[Iter 17970/20000] Loss: 0.0002628 (Best: 0.0002150 @iter15940) ([92m↓1.57%[0m) [0.10% of initial]
[Iter 17980/20000] Loss: 0.0002787 (Best: 0.0002150 @iter15940) ([91m↑6.07%[0m) [0.11% of initial]
[Iter 17990/20000] Loss: 0.0002551 (Best: 0.0002150 @iter15940) ([92m↓8.48%[0m) [0.10% of initial]
Iter:17999, L1 loss=0.0003343, Total loss=0.0002583, Time:90
[Iter 18000/20000] Loss: 0.0002515 (Best: 0.0002150 @iter15940) ([92m↓1.39%[0m) [0.10% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 18000
Pruning 3 points (0.0%) from gaussian1 at iteration 18000
[Iter 18010/20000] Loss: 0.0006977 (Best: 0.0002150 @iter15940) ([91m↑177.36%[0m) [0.28% of initial]
[Iter 18020/20000] Loss: 0.0004145 (Best: 0.0002150 @iter15940) ([92m↓40.59%[0m) [0.16% of initial]
[Iter 18030/20000] Loss: 0.0003551 (Best: 0.0002150 @iter15940) ([92m↓14.33%[0m) [0.14% of initial]
[Iter 18040/20000] Loss: 0.0002911 (Best: 0.0002150 @iter15940) ([92m↓18.02%[0m) [0.12% of initial]
[Iter 18050/20000] Loss: 0.0002679 (Best: 0.0002150 @iter15940) ([92m↓7.97%[0m) [0.11% of initial]
[Iter 18060/20000] Loss: 0.0002733 (Best: 0.0002150 @iter15940) ([91m↑2.04%[0m) [0.11% of initial]
[Iter 18070/20000] Loss: 0.0002774 (Best: 0.0002150 @iter15940) ([91m↑1.49%[0m) [0.11% of initial]
[Iter 18080/20000] Loss: 0.0002771 (Best: 0.0002150 @iter15940) ([92m↓0.11%[0m) [0.11% of initial]
[Iter 18090/20000] Loss: 0.0002862 (Best: 0.0002150 @iter15940) ([91m↑3.27%[0m) [0.11% of initial]
Iter:18099, L1 loss=0.0003582, Total loss=0.0003045, Time:80
[Iter 18100/20000] Loss: 0.0002808 (Best: 0.0002150 @iter15940) ([92m↓1.87%[0m) [0.11% of initial]
[Iter 18110/20000] Loss: 0.0002710 (Best: 0.0002150 @iter15940) ([92m↓3.50%[0m) [0.11% of initial]
[Iter 18120/20000] Loss: 0.0002669 (Best: 0.0002150 @iter15940) ([92m↓1.51%[0m) [0.11% of initial]
[Iter 18130/20000] Loss: 0.0002528 (Best: 0.0002150 @iter15940) ([92m↓5.27%[0m) [0.10% of initial]
[Iter 18140/20000] Loss: 0.0002621 (Best: 0.0002150 @iter15940) ([91m↑3.66%[0m) [0.10% of initial]
[Iter 18150/20000] Loss: 0.0002631 (Best: 0.0002150 @iter15940) ([91m↑0.40%[0m) [0.10% of initial]
[Iter 18160/20000] Loss: 0.0002522 (Best: 0.0002150 @iter15940) ([92m↓4.17%[0m) [0.10% of initial]
[Iter 18170/20000] Loss: 0.0002643 (Best: 0.0002150 @iter15940) ([91m↑4.82%[0m) [0.11% of initial]
[Iter 18180/20000] Loss: 0.0003389 (Best: 0.0002150 @iter15940) ([91m↑28.24%[0m) [0.13% of initial]
[Iter 18190/20000] Loss: 0.0003201 (Best: 0.0002150 @iter15940) ([92m↓5.55%[0m) [0.13% of initial]
Iter:18199, L1 loss=0.0003298, Total loss=0.0002979, Time:80
[Iter 18200/20000] Loss: 0.0003276 (Best: 0.0002150 @iter15940) ([91m↑2.33%[0m) [0.13% of initial]
[Iter 18210/20000] Loss: 0.0003105 (Best: 0.0002150 @iter15940) ([92m↓5.21%[0m) [0.12% of initial]
[Iter 18220/20000] Loss: 0.0004022 (Best: 0.0002150 @iter15940) ([91m↑29.52%[0m) [0.16% of initial]
[Iter 18230/20000] Loss: 0.0003162 (Best: 0.0002150 @iter15940) ([92m↓21.38%[0m) [0.13% of initial]
[Iter 18240/20000] Loss: 0.0002804 (Best: 0.0002150 @iter15940) ([92m↓11.31%[0m) [0.11% of initial]
[Iter 18250/20000] Loss: 0.0002784 (Best: 0.0002150 @iter15940) ([92m↓0.72%[0m) [0.11% of initial]
[Iter 18260/20000] Loss: 0.0002665 (Best: 0.0002150 @iter15940) ([92m↓4.28%[0m) [0.11% of initial]
[Iter 18270/20000] Loss: 0.0002643 (Best: 0.0002150 @iter15940) ([92m↓0.83%[0m) [0.10% of initial]
[Iter 18280/20000] Loss: 0.0002623 (Best: 0.0002150 @iter15940) ([92m↓0.74%[0m) [0.10% of initial]
[Iter 18290/20000] Loss: 0.0002886 (Best: 0.0002150 @iter15940) ([91m↑10.00%[0m) [0.11% of initial]
Iter:18299, L1 loss=0.0003798, Total loss=0.000327, Time:93
[Iter 18300/20000] Loss: 0.0003021 (Best: 0.0002150 @iter15940) ([91m↑4.67%[0m) [0.12% of initial]
[Iter 18310/20000] Loss: 0.0003064 (Best: 0.0002150 @iter15940) ([91m↑1.44%[0m) [0.12% of initial]
[Iter 18320/20000] Loss: 0.0003043 (Best: 0.0002150 @iter15940) ([92m↓0.68%[0m) [0.12% of initial]
[Iter 18330/20000] Loss: 0.0003763 (Best: 0.0002150 @iter15940) ([91m↑23.66%[0m) [0.15% of initial]
[Iter 18340/20000] Loss: 0.0003566 (Best: 0.0002150 @iter15940) ([92m↓5.23%[0m) [0.14% of initial]
[Iter 18350/20000] Loss: 0.0003459 (Best: 0.0002150 @iter15940) ([92m↓3.00%[0m) [0.14% of initial]
[Iter 18360/20000] Loss: 0.0004066 (Best: 0.0002150 @iter15940) ([91m↑17.54%[0m) [0.16% of initial]
[Iter 18370/20000] Loss: 0.0003049 (Best: 0.0002150 @iter15940) ([92m↓25.01%[0m) [0.12% of initial]
[Iter 18380/20000] Loss: 0.0002628 (Best: 0.0002150 @iter15940) ([92m↓13.81%[0m) [0.10% of initial]
[Iter 18390/20000] Loss: 0.0002646 (Best: 0.0002150 @iter15940) ([91m↑0.70%[0m) [0.11% of initial]
Iter:18399, L1 loss=0.0002977, Total loss=0.0002448, Time:97
[Iter 18400/20000] Loss: 0.0002402 (Best: 0.0002150 @iter15940) ([92m↓9.24%[0m) [0.10% of initial]
[Iter 18410/20000] Loss: 0.0002540 (Best: 0.0002150 @iter15940) ([91m↑5.76%[0m) [0.10% of initial]
[Iter 18420/20000] Loss: 0.0002407 (Best: 0.0002150 @iter15940) ([92m↓5.24%[0m) [0.10% of initial]
[Iter 18430/20000] Loss: 0.0002382 (Best: 0.0002150 @iter15940) ([92m↓1.02%[0m) [0.09% of initial]
[Iter 18440/20000] Loss: 0.0002774 (Best: 0.0002150 @iter15940) ([91m↑16.43%[0m) [0.11% of initial]
[Iter 18450/20000] Loss: 0.0002451 (Best: 0.0002150 @iter15940) ([92m↓11.65%[0m) [0.10% of initial]
[Iter 18460/20000] Loss: 0.0002531 (Best: 0.0002150 @iter15940) ([91m↑3.28%[0m) [0.10% of initial]
[Iter 18470/20000] Loss: 0.0002578 (Best: 0.0002150 @iter15940) ([91m↑1.88%[0m) [0.10% of initial]
[Iter 18480/20000] Loss: 0.0002422 (Best: 0.0002150 @iter15940) ([92m↓6.08%[0m) [0.10% of initial]
[Iter 18490/20000] Loss: 0.0002570 (Best: 0.0002150 @iter15940) ([91m↑6.12%[0m) [0.10% of initial]
Iter:18499, L1 loss=0.0003126, Total loss=0.0002587, Time:79
[Iter 18500/20000] Loss: 0.0002511 (Best: 0.0002150 @iter15940) ([92m↓2.30%[0m) [0.10% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 18500
Pruning 2 points (0.0%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0004717 (Best: 0.0002150 @iter15940) ([91m↑87.88%[0m) [0.19% of initial]
[Iter 18520/20000] Loss: 0.0003359 (Best: 0.0002150 @iter15940) ([92m↓28.78%[0m) [0.13% of initial]
[Iter 18530/20000] Loss: 0.0004190 (Best: 0.0002150 @iter15940) ([91m↑24.74%[0m) [0.17% of initial]
[Iter 18540/20000] Loss: 0.0002985 (Best: 0.0002150 @iter15940) ([92m↓28.77%[0m) [0.12% of initial]
[Iter 18550/20000] Loss: 0.0002777 (Best: 0.0002150 @iter15940) ([92m↓6.98%[0m) [0.11% of initial]
[Iter 18560/20000] Loss: 0.0002814 (Best: 0.0002150 @iter15940) ([91m↑1.35%[0m) [0.11% of initial]
[Iter 18570/20000] Loss: 0.0003072 (Best: 0.0002150 @iter15940) ([91m↑9.17%[0m) [0.12% of initial]
[Iter 18580/20000] Loss: 0.0002705 (Best: 0.0002150 @iter15940) ([92m↓11.94%[0m) [0.11% of initial]
[Iter 18590/20000] Loss: 0.0002682 (Best: 0.0002150 @iter15940) ([92m↓0.87%[0m) [0.11% of initial]
Iter:18599, L1 loss=0.0003438, Total loss=0.0002893, Time:77
[Iter 18600/20000] Loss: 0.0003038 (Best: 0.0002150 @iter15940) ([91m↑13.29%[0m) [0.12% of initial]
[Iter 18610/20000] Loss: 0.0002765 (Best: 0.0002150 @iter15940) ([92m↓8.99%[0m) [0.11% of initial]
[Iter 18620/20000] Loss: 0.0002572 (Best: 0.0002150 @iter15940) ([92m↓6.98%[0m) [0.10% of initial]
[Iter 18630/20000] Loss: 0.0003433 (Best: 0.0002150 @iter15940) ([91m↑33.47%[0m) [0.14% of initial]
[Iter 18640/20000] Loss: 0.0002869 (Best: 0.0002150 @iter15940) ([92m↓16.42%[0m) [0.11% of initial]
[Iter 18650/20000] Loss: 0.0002621 (Best: 0.0002150 @iter15940) ([92m↓8.67%[0m) [0.10% of initial]
[Iter 18660/20000] Loss: 0.0002548 (Best: 0.0002150 @iter15940) ([92m↓2.78%[0m) [0.10% of initial]
[Iter 18670/20000] Loss: 0.0002422 (Best: 0.0002150 @iter15940) ([92m↓4.94%[0m) [0.10% of initial]
[Iter 18680/20000] Loss: 0.0002375 (Best: 0.0002150 @iter15940) ([92m↓1.95%[0m) [0.09% of initial]
[Iter 18690/20000] Loss: 0.0002408 (Best: 0.0002131 @iter18685) ([91m↑1.41%[0m) [0.10% of initial]
Iter:18699, L1 loss=0.0002899, Total loss=0.0002382, Time:85
[Iter 18700/20000] Loss: 0.0002336 (Best: 0.0002131 @iter18685) ([92m↓2.98%[0m) [0.09% of initial]
[Iter 18710/20000] Loss: 0.0002342 (Best: 0.0002131 @iter18685) ([91m↑0.25%[0m) [0.09% of initial]
[Iter 18720/20000] Loss: 0.0002319 (Best: 0.0002131 @iter18685) ([92m↓1.00%[0m) [0.09% of initial]
[Iter 18730/20000] Loss: 0.0002385 (Best: 0.0002131 @iter18685) ([91m↑2.88%[0m) [0.09% of initial]
[Iter 18740/20000] Loss: 0.0002407 (Best: 0.0002131 @iter18685) ([91m↑0.90%[0m) [0.10% of initial]
[Iter 18750/20000] Loss: 0.0002360 (Best: 0.0002131 @iter18685) ([92m↓1.94%[0m) [0.09% of initial]
[Iter 18760/20000] Loss: 0.0002416 (Best: 0.0002131 @iter18685) ([91m↑2.38%[0m) [0.10% of initial]
[Iter 18770/20000] Loss: 0.0002592 (Best: 0.0002131 @iter18685) ([91m↑7.28%[0m) [0.10% of initial]
[Iter 18780/20000] Loss: 0.0002598 (Best: 0.0002131 @iter18685) ([91m↑0.24%[0m) [0.10% of initial]
[Iter 18790/20000] Loss: 0.0002637 (Best: 0.0002131 @iter18685) ([91m↑1.49%[0m) [0.10% of initial]
Iter:18799, L1 loss=0.0002965, Total loss=0.0002351, Time:80
[Iter 18800/20000] Loss: 0.0002484 (Best: 0.0002131 @iter18685) ([92m↓5.81%[0m) [0.10% of initial]
[Iter 18810/20000] Loss: 0.0002513 (Best: 0.0002131 @iter18685) ([91m↑1.15%[0m) [0.10% of initial]
[Iter 18820/20000] Loss: 0.0002577 (Best: 0.0002131 @iter18685) ([91m↑2.55%[0m) [0.10% of initial]
[Iter 18830/20000] Loss: 0.0002671 (Best: 0.0002131 @iter18685) ([91m↑3.67%[0m) [0.11% of initial]
[Iter 18840/20000] Loss: 0.0002588 (Best: 0.0002131 @iter18685) ([92m↓3.13%[0m) [0.10% of initial]
[Iter 18850/20000] Loss: 0.0002571 (Best: 0.0002131 @iter18685) ([92m↓0.64%[0m) [0.10% of initial]
[Iter 18860/20000] Loss: 0.0002953 (Best: 0.0002131 @iter18685) ([91m↑14.87%[0m) [0.12% of initial]
[Iter 18870/20000] Loss: 0.0002642 (Best: 0.0002131 @iter18685) ([92m↓10.55%[0m) [0.10% of initial]
[Iter 18880/20000] Loss: 0.0002521 (Best: 0.0002131 @iter18685) ([92m↓4.55%[0m) [0.10% of initial]
[Iter 18890/20000] Loss: 0.0002587 (Best: 0.0002131 @iter18685) ([91m↑2.61%[0m) [0.10% of initial]
Iter:18899, L1 loss=0.0002905, Total loss=0.0002577, Time:79
[Iter 18900/20000] Loss: 0.0002597 (Best: 0.0002131 @iter18685) ([91m↑0.38%[0m) [0.10% of initial]
[Iter 18910/20000] Loss: 0.0002625 (Best: 0.0002131 @iter18685) ([91m↑1.07%[0m) [0.10% of initial]
[Iter 18920/20000] Loss: 0.0002397 (Best: 0.0002131 @iter18685) ([92m↓8.68%[0m) [0.10% of initial]
[Iter 18930/20000] Loss: 0.0002924 (Best: 0.0002131 @iter18685) ([91m↑22.00%[0m) [0.12% of initial]
[Iter 18940/20000] Loss: 0.0002638 (Best: 0.0002131 @iter18685) ([92m↓9.78%[0m) [0.10% of initial]
[Iter 18950/20000] Loss: 0.0002772 (Best: 0.0002131 @iter18685) ([91m↑5.06%[0m) [0.11% of initial]
[Iter 18960/20000] Loss: 0.0002763 (Best: 0.0002131 @iter18685) ([92m↓0.32%[0m) [0.11% of initial]
[Iter 18970/20000] Loss: 0.0002889 (Best: 0.0002131 @iter18685) ([91m↑4.55%[0m) [0.11% of initial]
[Iter 18980/20000] Loss: 0.0002573 (Best: 0.0002131 @iter18685) ([92m↓10.91%[0m) [0.10% of initial]
[Iter 18990/20000] Loss: 0.0002542 (Best: 0.0002131 @iter18685) ([92m↓1.22%[0m) [0.10% of initial]
Iter:18999, L1 loss=0.000291, Total loss=0.0002368, Time:101
[Iter 19000/20000] Loss: 0.0002367 (Best: 0.0002131 @iter18685) ([92m↓6.88%[0m) [0.09% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 19000
Pruning 1 points (0.0%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0005603 (Best: 0.0002131 @iter18685) ([91m↑136.72%[0m) [0.22% of initial]
[Iter 19020/20000] Loss: 0.0004422 (Best: 0.0002131 @iter18685) ([92m↓21.08%[0m) [0.18% of initial]
[Iter 19030/20000] Loss: 0.0003301 (Best: 0.0002131 @iter18685) ([92m↓25.36%[0m) [0.13% of initial]
[Iter 19040/20000] Loss: 0.0002827 (Best: 0.0002131 @iter18685) ([92m↓14.34%[0m) [0.11% of initial]
[Iter 19050/20000] Loss: 0.0002656 (Best: 0.0002131 @iter18685) ([92m↓6.07%[0m) [0.11% of initial]
[Iter 19060/20000] Loss: 0.0002450 (Best: 0.0002131 @iter18685) ([92m↓7.73%[0m) [0.10% of initial]
[Iter 19070/20000] Loss: 0.0002635 (Best: 0.0002131 @iter18685) ([91m↑7.54%[0m) [0.10% of initial]
[Iter 19080/20000] Loss: 0.0002404 (Best: 0.0002131 @iter18685) ([92m↓8.80%[0m) [0.10% of initial]
[Iter 19090/20000] Loss: 0.0002419 (Best: 0.0002131 @iter18685) ([91m↑0.63%[0m) [0.10% of initial]
Iter:19099, L1 loss=0.0002885, Total loss=0.0002435, Time:71
[Iter 19100/20000] Loss: 0.0002781 (Best: 0.0002131 @iter18685) ([91m↑14.99%[0m) [0.11% of initial]
[Iter 19110/20000] Loss: 0.0002779 (Best: 0.0002131 @iter18685) ([92m↓0.08%[0m) [0.11% of initial]
[Iter 19120/20000] Loss: 0.0002491 (Best: 0.0002131 @iter18685) ([92m↓10.36%[0m) [0.10% of initial]
[Iter 19130/20000] Loss: 0.0002463 (Best: 0.0002131 @iter18685) ([92m↓1.13%[0m) [0.10% of initial]
[Iter 19140/20000] Loss: 0.0002679 (Best: 0.0002131 @iter18685) ([91m↑8.79%[0m) [0.11% of initial]
[Iter 19150/20000] Loss: 0.0002574 (Best: 0.0002131 @iter18685) ([92m↓3.91%[0m) [0.10% of initial]
[Iter 19160/20000] Loss: 0.0002632 (Best: 0.0002131 @iter18685) ([91m↑2.23%[0m) [0.10% of initial]
[Iter 19170/20000] Loss: 0.0002488 (Best: 0.0002131 @iter18685) ([92m↓5.46%[0m) [0.10% of initial]
[Iter 19180/20000] Loss: 0.0002487 (Best: 0.0002131 @iter18685) ([92m↓0.04%[0m) [0.10% of initial]
[Iter 19190/20000] Loss: 0.0002781 (Best: 0.0002131 @iter18685) ([91m↑11.82%[0m) [0.11% of initial]
Iter:19199, L1 loss=0.0003481, Total loss=0.0003487, Time:80
[Iter 19200/20000] Loss: 0.0002974 (Best: 0.0002131 @iter18685) ([91m↑6.94%[0m) [0.12% of initial]
[Iter 19210/20000] Loss: 0.0002657 (Best: 0.0002131 @iter18685) ([92m↓10.66%[0m) [0.11% of initial]
[Iter 19220/20000] Loss: 0.0005538 (Best: 0.0002131 @iter18685) ([91m↑108.41%[0m) [0.22% of initial]
[Iter 19230/20000] Loss: 0.0002622 (Best: 0.0002131 @iter18685) ([92m↓52.65%[0m) [0.10% of initial]
[Iter 19240/20000] Loss: 0.0002442 (Best: 0.0002131 @iter18685) ([92m↓6.86%[0m) [0.10% of initial]
[Iter 19250/20000] Loss: 0.0002522 (Best: 0.0002131 @iter18685) ([91m↑3.25%[0m) [0.10% of initial]
[Iter 19260/20000] Loss: 0.0002424 (Best: 0.0002131 @iter18685) ([92m↓3.89%[0m) [0.10% of initial]
[Iter 19270/20000] Loss: 0.0002524 (Best: 0.0002131 @iter18685) ([91m↑4.13%[0m) [0.10% of initial]
[Iter 19280/20000] Loss: 0.0002595 (Best: 0.0002131 @iter18685) ([91m↑2.84%[0m) [0.10% of initial]
[Iter 19290/20000] Loss: 0.0002462 (Best: 0.0002131 @iter18685) ([92m↓5.15%[0m) [0.10% of initial]
Iter:19299, L1 loss=0.0002869, Total loss=0.0002348, Time:77
[Iter 19300/20000] Loss: 0.0002390 (Best: 0.0002131 @iter18685) ([92m↓2.91%[0m) [0.09% of initial]
[Iter 19310/20000] Loss: 0.0002536 (Best: 0.0002131 @iter18685) ([91m↑6.10%[0m) [0.10% of initial]
[Iter 19320/20000] Loss: 0.0002511 (Best: 0.0002131 @iter18685) ([92m↓0.97%[0m) [0.10% of initial]
[Iter 19330/20000] Loss: 0.0002475 (Best: 0.0002131 @iter18685) ([92m↓1.44%[0m) [0.10% of initial]
[Iter 19340/20000] Loss: 0.0002907 (Best: 0.0002131 @iter18685) ([91m↑17.46%[0m) [0.12% of initial]
[Iter 19350/20000] Loss: 0.0003108 (Best: 0.0002131 @iter18685) ([91m↑6.92%[0m) [0.12% of initial]
[Iter 19360/20000] Loss: 0.0003047 (Best: 0.0002131 @iter18685) ([92m↓1.95%[0m) [0.12% of initial]
[Iter 19370/20000] Loss: 0.0003091 (Best: 0.0002131 @iter18685) ([91m↑1.44%[0m) [0.12% of initial]
[Iter 19380/20000] Loss: 0.0003161 (Best: 0.0002131 @iter18685) ([91m↑2.26%[0m) [0.13% of initial]
[Iter 19390/20000] Loss: 0.0002659 (Best: 0.0002131 @iter18685) ([92m↓15.89%[0m) [0.11% of initial]
Iter:19399, L1 loss=0.0002863, Total loss=0.0002366, Time:77
[Iter 19400/20000] Loss: 0.0002523 (Best: 0.0002131 @iter18685) ([92m↓5.10%[0m) [0.10% of initial]
[Iter 19410/20000] Loss: 0.0002301 (Best: 0.0002131 @iter18685) ([92m↓8.81%[0m) [0.09% of initial]
[Iter 19420/20000] Loss: 0.0002276 (Best: 0.0002083 @iter19417) ([92m↓1.06%[0m) [0.09% of initial]
[Iter 19430/20000] Loss: 0.0002234 (Best: 0.0002083 @iter19417) ([92m↓1.88%[0m) [0.09% of initial]
[Iter 19440/20000] Loss: 0.0002359 (Best: 0.0002083 @iter19417) ([91m↑5.60%[0m) [0.09% of initial]
[Iter 19450/20000] Loss: 0.0002411 (Best: 0.0002083 @iter19417) ([91m↑2.22%[0m) [0.10% of initial]
[Iter 19460/20000] Loss: 0.0002771 (Best: 0.0002083 @iter19417) ([91m↑14.91%[0m) [0.11% of initial]
[Iter 19470/20000] Loss: 0.0003325 (Best: 0.0002083 @iter19417) ([91m↑20.01%[0m) [0.13% of initial]
[Iter 19480/20000] Loss: 0.0003693 (Best: 0.0002083 @iter19417) ([91m↑11.07%[0m) [0.15% of initial]
[Iter 19490/20000] Loss: 0.0003412 (Best: 0.0002083 @iter19417) ([92m↓7.62%[0m) [0.14% of initial]
Iter:19499, L1 loss=0.000308, Total loss=0.0002711, Time:77
[Iter 19500/20000] Loss: 0.0003004 (Best: 0.0002083 @iter19417) ([92m↓11.96%[0m) [0.12% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 19500
Pruning 3 points (0.0%) from gaussian1 at iteration 19500
[Iter 19510/20000] Loss: 0.0005342 (Best: 0.0002083 @iter19417) ([91m↑77.87%[0m) [0.21% of initial]
[Iter 19520/20000] Loss: 0.0003608 (Best: 0.0002083 @iter19417) ([92m↓32.46%[0m) [0.14% of initial]
[Iter 19530/20000] Loss: 0.0002892 (Best: 0.0002083 @iter19417) ([92m↓19.84%[0m) [0.11% of initial]
[Iter 19540/20000] Loss: 0.0002474 (Best: 0.0002083 @iter19417) ([92m↓14.46%[0m) [0.10% of initial]
[Iter 19550/20000] Loss: 0.0002439 (Best: 0.0002083 @iter19417) ([92m↓1.41%[0m) [0.10% of initial]
[Iter 19560/20000] Loss: 0.0002402 (Best: 0.0002083 @iter19417) ([92m↓1.50%[0m) [0.10% of initial]
[Iter 19570/20000] Loss: 0.0002292 (Best: 0.0002083 @iter19417) ([92m↓4.61%[0m) [0.09% of initial]
[Iter 19580/20000] Loss: 0.0002774 (Best: 0.0002083 @iter19417) ([91m↑21.02%[0m) [0.11% of initial]
[Iter 19590/20000] Loss: 0.0002392 (Best: 0.0002083 @iter19417) ([92m↓13.77%[0m) [0.10% of initial]
Iter:19599, L1 loss=0.0002841, Total loss=0.0002399, Time:76
[Iter 19600/20000] Loss: 0.0002330 (Best: 0.0002083 @iter19417) ([92m↓2.58%[0m) [0.09% of initial]
[Iter 19610/20000] Loss: 0.0002344 (Best: 0.0002083 @iter19417) ([91m↑0.62%[0m) [0.09% of initial]
[Iter 19620/20000] Loss: 0.0002468 (Best: 0.0002083 @iter19417) ([91m↑5.29%[0m) [0.10% of initial]
[Iter 19630/20000] Loss: 0.0002598 (Best: 0.0002083 @iter19417) ([91m↑5.27%[0m) [0.10% of initial]
[Iter 19640/20000] Loss: 0.0002441 (Best: 0.0002083 @iter19417) ([92m↓6.04%[0m) [0.10% of initial]
[Iter 19650/20000] Loss: 0.0002633 (Best: 0.0002083 @iter19417) ([91m↑7.88%[0m) [0.10% of initial]
[Iter 19660/20000] Loss: 0.0002341 (Best: 0.0002083 @iter19417) ([92m↓11.10%[0m) [0.09% of initial]
[Iter 19670/20000] Loss: 0.0002256 (Best: 0.0002083 @iter19417) ([92m↓3.62%[0m) [0.09% of initial]
[Iter 19680/20000] Loss: 0.0002303 (Best: 0.0002083 @iter19417) ([91m↑2.06%[0m) [0.09% of initial]
[Iter 19690/20000] Loss: 0.0002260 (Best: 0.0002083 @iter19417) ([92m↓1.85%[0m) [0.09% of initial]
Iter:19699, L1 loss=0.0002963, Total loss=0.0002477, Time:78
[Iter 19700/20000] Loss: 0.0003205 (Best: 0.0002083 @iter19417) ([91m↑41.80%[0m) [0.13% of initial]
[Iter 19710/20000] Loss: 0.0002871 (Best: 0.0002083 @iter19417) ([92m↓10.42%[0m) [0.11% of initial]
[Iter 19720/20000] Loss: 0.0002757 (Best: 0.0002083 @iter19417) ([92m↓3.98%[0m) [0.11% of initial]
[Iter 19730/20000] Loss: 0.0002779 (Best: 0.0002083 @iter19417) ([91m↑0.81%[0m) [0.11% of initial]
[Iter 19740/20000] Loss: 0.0002531 (Best: 0.0002083 @iter19417) ([92m↓8.92%[0m) [0.10% of initial]
[Iter 19750/20000] Loss: 0.0002737 (Best: 0.0002083 @iter19417) ([91m↑8.12%[0m) [0.11% of initial]
[Iter 19760/20000] Loss: 0.0002570 (Best: 0.0002083 @iter19417) ([92m↓6.10%[0m) [0.10% of initial]
[Iter 19770/20000] Loss: 0.0002467 (Best: 0.0002083 @iter19417) ([92m↓3.99%[0m) [0.10% of initial]
[Iter 19780/20000] Loss: 0.0002610 (Best: 0.0002083 @iter19417) ([91m↑5.78%[0m) [0.10% of initial]
[Iter 19790/20000] Loss: 0.0002591 (Best: 0.0002083 @iter19417) ([92m↓0.73%[0m) [0.10% of initial]
Iter:19799, L1 loss=0.0002915, Total loss=0.0002616, Time:78
[Iter 19800/20000] Loss: 0.0002484 (Best: 0.0002083 @iter19417) ([92m↓4.15%[0m) [0.10% of initial]
[Iter 19810/20000] Loss: 0.0002629 (Best: 0.0002083 @iter19417) ([91m↑5.87%[0m) [0.10% of initial]
[Iter 19820/20000] Loss: 0.0002555 (Best: 0.0002083 @iter19417) ([92m↓2.83%[0m) [0.10% of initial]
[Iter 19830/20000] Loss: 0.0003176 (Best: 0.0002083 @iter19417) ([91m↑24.32%[0m) [0.13% of initial]
[Iter 19840/20000] Loss: 0.0003152 (Best: 0.0002083 @iter19417) ([92m↓0.75%[0m) [0.13% of initial]
[Iter 19850/20000] Loss: 0.0002869 (Best: 0.0002083 @iter19417) ([92m↓9.00%[0m) [0.11% of initial]
[Iter 19860/20000] Loss: 0.0003488 (Best: 0.0002083 @iter19417) ([91m↑21.58%[0m) [0.14% of initial]
[Iter 19870/20000] Loss: 0.0003173 (Best: 0.0002083 @iter19417) ([92m↓9.02%[0m) [0.13% of initial]
[Iter 19880/20000] Loss: 0.0003079 (Best: 0.0002083 @iter19417) ([92m↓2.99%[0m) [0.12% of initial]
[Iter 19890/20000] Loss: 0.0003316 (Best: 0.0002083 @iter19417) ([91m↑7.72%[0m) [0.13% of initial]
Iter:19899, L1 loss=0.0003104, Total loss=0.0002672, Time:77
[Iter 19900/20000] Loss: 0.0002665 (Best: 0.0002083 @iter19417) ([92m↓19.62%[0m) [0.11% of initial]
[Iter 19910/20000] Loss: 0.0002951 (Best: 0.0002083 @iter19417) ([91m↑10.70%[0m) [0.12% of initial]
[Iter 19920/20000] Loss: 0.0002836 (Best: 0.0002083 @iter19417) ([92m↓3.89%[0m) [0.11% of initial]
[Iter 19930/20000] Loss: 0.0002778 (Best: 0.0002083 @iter19417) ([92m↓2.05%[0m) [0.11% of initial]
[Iter 19940/20000] Loss: 0.0002822 (Best: 0.0002083 @iter19417) ([91m↑1.61%[0m) [0.11% of initial]
[Iter 19950/20000] Loss: 0.0002881 (Best: 0.0002083 @iter19417) ([91m↑2.08%[0m) [0.11% of initial]
[Iter 19960/20000] Loss: 0.0002542 (Best: 0.0002083 @iter19417) ([92m↓11.77%[0m) [0.10% of initial]
[Iter 19970/20000] Loss: 0.0002524 (Best: 0.0002083 @iter19417) ([92m↓0.72%[0m) [0.10% of initial]
[Iter 19980/20000] Loss: 0.0002483 (Best: 0.0002083 @iter19417) ([92m↓1.60%[0m) [0.10% of initial]
[Iter 19990/20000] Loss: 0.0002220 (Best: 0.0002083 @iter19417) ([92m↓10.62%[0m) [0.09% of initial]
Iter:19999, L1 loss=0.0002597, Total loss=0.0002207, Time:80
[Iter 20000/20000] Loss: 0.0002220 (Best: 0.0002083 @iter19417) ([92m↓0.00%[0m) [0.09% of initial]
Testing Speed: 55.307704276871874 fps
Testing Time: 0.9040331840515137 s

[ITER 20000] Evaluating test: SSIM = 0.9270310306549072, PSNR = 21.353000354766845
Testing Speed: 72.62612550214712 fps
Testing Time: 0.04130744934082031 s

[ITER 20000] Evaluating train: SSIM = 0.9999991257985432, PSNR = 65.70512390136719
Iter:20000, total_points:181290

[ITER 20000] Saving Gaussians
Pruning 2 points (0.0%) from gaussian0 at iteration 20000
Pruning 3 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 55 fps
Total time: 39.23 minutes
Test SSIM: 0.9270
Test PSNR: 21.353
Gaussian0 final points count: 181288
Gaussian1 final points count: 182924
Final loss: 0.0002220 (0.09% of initial)
Save path: 2024_11_26_16_19_37
Initial loss: 0.2517052
Best loss: 0.0002083 @iteration 19417 (0.08% of initial)
Train SSIM: 1.0000
Train PSNR: 65.705
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693032 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374908 (Best: 0.1327883 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123931 (Best: 0.1098388 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993433 (Best: 0.0965408 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936740 (Best: 0.0908499 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884561 (Best: 0.0869438 @iter70) ([92m↓5.57%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851851 (Best: 0.0831011 @iter80) ([92m↓3.70%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824238 (Best: 0.0801680 @iter88) ([92m↓3.24%[0m) [32.75% of initial]
Iter:99, L1 loss=0.05722, Total loss=0.07877, Time:39
[Iter 100/20000] Loss: 0.0786738 (Best: 0.0766329 @iter97) ([92m↓4.55%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753370 (Best: 0.0731591 @iter106) ([92m↓4.24%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714440 (Best: 0.0685886 @iter118) ([92m↓5.17%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0667098 (Best: 0.0642183 @iter130) ([92m↓6.63%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635544 (Best: 0.0613099 @iter140) ([92m↓4.73%[0m) [25.25% of initial]
[Iter 150/20000] Loss: 0.0612885 (Best: 0.0584409 @iter148) ([92m↓3.57%[0m) [24.35% of initial]
[Iter 160/20000] Loss: 0.0590784 (Best: 0.0559565 @iter157) ([92m↓3.61%[0m) [23.47% of initial]
[Iter 170/20000] Loss: 0.0563673 (Best: 0.0535432 @iter167) ([92m↓4.59%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523649 (Best: 0.0500495 @iter179) ([92m↓7.10%[0m) [20.80% of initial]
[Iter 190/20000] Loss: 0.0495153 (Best: 0.0478235 @iter188) ([92m↓5.44%[0m) [19.67% of initial]
Iter:199, L1 loss=0.03442, Total loss=0.04972, Time:40
[Iter 200/20000] Loss: 0.0478149 (Best: 0.0457194 @iter198) ([92m↓3.43%[0m) [19.00% of initial]
[Iter 210/20000] Loss: 0.0450345 (Best: 0.0428192 @iter209) ([92m↓5.81%[0m) [17.89% of initial]
[Iter 220/20000] Loss: 0.0440263 (Best: 0.0411982 @iter219) ([92m↓2.24%[0m) [17.49% of initial]
[Iter 230/20000] Loss: 0.0422917 (Best: 0.0398737 @iter227) ([92m↓3.94%[0m) [16.80% of initial]
[Iter 240/20000] Loss: 0.0401621 (Best: 0.0376720 @iter238) ([92m↓5.04%[0m) [15.96% of initial]
[Iter 250/20000] Loss: 0.0378755 (Best: 0.0362021 @iter248) ([92m↓5.69%[0m) [15.05% of initial]
[Iter 260/20000] Loss: 0.0358535 (Best: 0.0342601 @iter260) ([92m↓5.34%[0m) [14.24% of initial]
[Iter 270/20000] Loss: 0.0349533 (Best: 0.0328526 @iter269) ([92m↓2.51%[0m) [13.89% of initial]
[Iter 280/20000] Loss: 0.0346478 (Best: 0.0317921 @iter277) ([92m↓0.87%[0m) [13.77% of initial]
[Iter 290/20000] Loss: 0.0330370 (Best: 0.0304534 @iter287) ([92m↓4.65%[0m) [13.13% of initial]
Iter:299, L1 loss=0.02211, Total loss=0.03338, Time:45
[Iter 300/20000] Loss: 0.0307840 (Best: 0.0289030 @iter300) ([92m↓6.82%[0m) [12.23% of initial]
[Iter 310/20000] Loss: 0.0292828 (Best: 0.0272561 @iter310) ([92m↓4.88%[0m) [11.63% of initial]
[Iter 320/20000] Loss: 0.0278272 (Best: 0.0264116 @iter320) ([92m↓4.97%[0m) [11.06% of initial]
[Iter 330/20000] Loss: 0.0274811 (Best: 0.0256697 @iter330) ([92m↓1.24%[0m) [10.92% of initial]
[Iter 340/20000] Loss: 0.0252813 (Best: 0.0241625 @iter340) ([92m↓8.00%[0m) [10.04% of initial]
[Iter 350/20000] Loss: 0.0259646 (Best: 0.0233003 @iter349) ([91m↑2.70%[0m) [10.32% of initial]
[Iter 360/20000] Loss: 0.0245984 (Best: 0.0225925 @iter358) ([92m↓5.26%[0m) [9.77% of initial]
[Iter 370/20000] Loss: 0.0243981 (Best: 0.0219951 @iter368) ([92m↓0.81%[0m) [9.69% of initial]
[Iter 380/20000] Loss: 0.0218950 (Best: 0.0206906 @iter379) ([92m↓10.26%[0m) [8.70% of initial]
[Iter 390/20000] Loss: 0.0214165 (Best: 0.0199197 @iter385) ([92m↓2.19%[0m) [8.51% of initial]
Iter:399, L1 loss=0.01351, Total loss=0.02085, Time:50
[Iter 400/20000] Loss: 0.0203610 (Best: 0.0190017 @iter400) ([92m↓4.93%[0m) [8.09% of initial]
[Iter 410/20000] Loss: 0.0192939 (Best: 0.0182155 @iter410) ([92m↓5.24%[0m) [7.67% of initial]
[Iter 420/20000] Loss: 0.0193645 (Best: 0.0173844 @iter418) ([91m↑0.37%[0m) [7.69% of initial]
[Iter 430/20000] Loss: 0.0172811 (Best: 0.0164356 @iter430) ([92m↓10.76%[0m) [6.87% of initial]
[Iter 440/20000] Loss: 0.0177597 (Best: 0.0159908 @iter434) ([91m↑2.77%[0m) [7.06% of initial]
[Iter 450/20000] Loss: 0.0168060 (Best: 0.0150900 @iter449) ([92m↓5.37%[0m) [6.68% of initial]
[Iter 460/20000] Loss: 0.0164123 (Best: 0.0146142 @iter458) ([92m↓2.34%[0m) [6.52% of initial]
[Iter 470/20000] Loss: 0.0149849 (Best: 0.0140495 @iter470) ([92m↓8.70%[0m) [5.95% of initial]
[Iter 480/20000] Loss: 0.0149472 (Best: 0.0138497 @iter475) ([92m↓0.25%[0m) [5.94% of initial]
[Iter 490/20000] Loss: 0.0141971 (Best: 0.0131522 @iter490) ([92m↓5.02%[0m) [5.64% of initial]
Iter:499, L1 loss=0.008181, Total loss=0.01501, Time:50
[Iter 500/20000] Loss: 0.0141326 (Best: 0.0129870 @iter498) ([92m↓0.45%[0m) [5.61% of initial]
[Iter 510/20000] Loss: 0.0136114 (Best: 0.0125791 @iter508) ([92m↓3.69%[0m) [5.41% of initial]
[Iter 520/20000] Loss: 0.0127096 (Best: 0.0118691 @iter514) ([92m↓6.63%[0m) [5.05% of initial]
[Iter 530/20000] Loss: 0.0122915 (Best: 0.0113631 @iter529) ([92m↓3.29%[0m) [4.88% of initial]
[Iter 540/20000] Loss: 0.0122776 (Best: 0.0113631 @iter529) ([92m↓0.11%[0m) [4.88% of initial]
[Iter 550/20000] Loss: 0.0119621 (Best: 0.0112938 @iter548) ([92m↓2.57%[0m) [4.75% of initial]
[Iter 560/20000] Loss: 0.0121807 (Best: 0.0109577 @iter556) ([91m↑1.83%[0m) [4.84% of initial]
[Iter 570/20000] Loss: 0.0118194 (Best: 0.0106413 @iter569) ([92m↓2.97%[0m) [4.70% of initial]
[Iter 580/20000] Loss: 0.0111642 (Best: 0.0102821 @iter578) ([92m↓5.54%[0m) [4.44% of initial]
[Iter 590/20000] Loss: 0.0111953 (Best: 0.0100015 @iter583) ([91m↑0.28%[0m) [4.45% of initial]
Iter:599, L1 loss=0.00709, Total loss=0.01174, Time:39
[Iter 600/20000] Loss: 0.0108860 (Best: 0.0098201 @iter598) ([92m↓2.76%[0m) [4.32% of initial]
[Iter 610/20000] Loss: 0.0223877 (Best: 0.0098201 @iter598) ([91m↑105.66%[0m) [8.89% of initial]
[Iter 620/20000] Loss: 0.0146026 (Best: 0.0098201 @iter598) ([92m↓34.77%[0m) [5.80% of initial]
[Iter 630/20000] Loss: 0.0121734 (Best: 0.0098201 @iter598) ([92m↓16.64%[0m) [4.84% of initial]
[Iter 640/20000] Loss: 0.0104128 (Best: 0.0095409 @iter640) ([92m↓14.46%[0m) [4.14% of initial]
[Iter 650/20000] Loss: 0.0107607 (Best: 0.0094115 @iter646) ([91m↑3.34%[0m) [4.28% of initial]
[Iter 660/20000] Loss: 0.0102305 (Best: 0.0089436 @iter655) ([92m↓4.93%[0m) [4.06% of initial]
[Iter 670/20000] Loss: 0.0095429 (Best: 0.0085647 @iter667) ([92m↓6.72%[0m) [3.79% of initial]
[Iter 680/20000] Loss: 0.0089305 (Best: 0.0083665 @iter674) ([92m↓6.42%[0m) [3.55% of initial]
[Iter 690/20000] Loss: 0.0090468 (Best: 0.0078885 @iter685) ([91m↑1.30%[0m) [3.59% of initial]
Iter:699, L1 loss=0.00561, Total loss=0.009332, Time:35
[Iter 700/20000] Loss: 0.0088552 (Best: 0.0078885 @iter685) ([92m↓2.12%[0m) [3.52% of initial]
[Iter 710/20000] Loss: 0.0087021 (Best: 0.0076271 @iter703) ([92m↓1.73%[0m) [3.46% of initial]
[Iter 720/20000] Loss: 0.0086192 (Best: 0.0076271 @iter703) ([92m↓0.95%[0m) [3.42% of initial]
[Iter 730/20000] Loss: 0.0085093 (Best: 0.0072206 @iter727) ([92m↓1.28%[0m) [3.38% of initial]
[Iter 740/20000] Loss: 0.0083886 (Best: 0.0072206 @iter727) ([92m↓1.42%[0m) [3.33% of initial]
[Iter 750/20000] Loss: 0.0080324 (Best: 0.0069850 @iter748) ([92m↓4.25%[0m) [3.19% of initial]
[Iter 760/20000] Loss: 0.0074102 (Best: 0.0068761 @iter754) ([92m↓7.75%[0m) [2.94% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 770/20000] Loss: 0.0075867 (Best: 0.0068761 @iter754) ([91m↑2.38%[0m) [3.01% of initial]
[Iter 780/20000] Loss: 0.0077067 (Best: 0.0066463 @iter778) ([91m↑1.58%[0m) [3.06% of initial]
[Iter 790/20000] Loss: 0.0075043 (Best: 0.0064993 @iter787) ([92m↓2.63%[0m) [2.98% of initial]
Iter:799, L1 loss=0.00497, Total loss=0.007882, Time:42
[Iter 800/20000] Loss: 0.0072563 (Best: 0.0064968 @iter796) ([92m↓3.30%[0m) [2.88% of initial]
[Iter 810/20000] Loss: 0.0150763 (Best: 0.0064968 @iter796) ([91m↑107.77%[0m) [5.99% of initial]
[Iter 820/20000] Loss: 0.0103190 (Best: 0.0064968 @iter796) ([92m↓31.55%[0m) [4.10% of initial]
[Iter 830/20000] Loss: 0.0085776 (Best: 0.0064968 @iter796) ([92m↓16.88%[0m) [3.41% of initial]
[Iter 840/20000] Loss: 0.0078618 (Best: 0.0064968 @iter796) ([92m↓8.35%[0m) [3.12% of initial]
[Iter 850/20000] Loss: 0.0072579 (Best: 0.0064968 @iter796) ([92m↓7.68%[0m) [2.88% of initial]
[Iter 860/20000] Loss: 0.0067990 (Best: 0.0061248 @iter859) ([92m↓6.32%[0m) [2.70% of initial]
[Iter 870/20000] Loss: 0.0065827 (Best: 0.0060674 @iter862) ([92m↓3.18%[0m) [2.62% of initial]
[Iter 880/20000] Loss: 0.0065200 (Best: 0.0058244 @iter875) ([92m↓0.95%[0m) [2.59% of initial]
[Iter 890/20000] Loss: 0.0061300 (Best: 0.0056055 @iter884) ([92m↓5.98%[0m) [2.44% of initial]
Iter:899, L1 loss=0.003834, Total loss=0.005503, Time:47
[Iter 900/20000] Loss: 0.0062806 (Best: 0.0055030 @iter899) ([91m↑2.46%[0m) [2.50% of initial]
[Iter 910/20000] Loss: 0.0063309 (Best: 0.0053235 @iter907) ([91m↑0.80%[0m) [2.52% of initial]
[Iter 920/20000] Loss: 0.0057714 (Best: 0.0052292 @iter919) ([92m↓8.84%[0m) [2.29% of initial]
[Iter 930/20000] Loss: 0.0060380 (Best: 0.0051344 @iter925) ([91m↑4.62%[0m) [2.40% of initial]
[Iter 940/20000] Loss: 0.0061298 (Best: 0.0050603 @iter938) ([91m↑1.52%[0m) [2.44% of initial]
[Iter 950/20000] Loss: 0.0057759 (Best: 0.0050603 @iter938) ([92m↓5.77%[0m) [2.29% of initial]
[Iter 960/20000] Loss: 0.0057777 (Best: 0.0050603 @iter938) ([91m↑0.03%[0m) [2.30% of initial]
[Iter 970/20000] Loss: 0.0057590 (Best: 0.0050601 @iter964) ([92m↓0.32%[0m) [2.29% of initial]
[Iter 980/20000] Loss: 0.0058505 (Best: 0.0050360 @iter979) ([91m↑1.59%[0m) [2.32% of initial]
[Iter 990/20000] Loss: 0.0058486 (Best: 0.0050360 @iter979) ([92m↓0.03%[0m) [2.32% of initial]
Iter:999, L1 loss=0.004441, Total loss=0.00645, Time:49
[Iter 1000/20000] Loss: 0.0060666 (Best: 0.0050360 @iter979) ([91m↑3.73%[0m) [2.41% of initial]
[Iter 1010/20000] Loss: 0.0112978 (Best: 0.0050360 @iter979) ([91m↑86.23%[0m) [4.49% of initial]
[Iter 1020/20000] Loss: 0.0083701 (Best: 0.0050360 @iter979) ([92m↓25.91%[0m) [3.33% of initial]
[Iter 1030/20000] Loss: 0.0066402 (Best: 0.0050360 @iter979) ([92m↓20.67%[0m) [2.64% of initial]
[Iter 1040/20000] Loss: 0.0058478 (Best: 0.0050360 @iter979) ([92m↓11.93%[0m) [2.32% of initial]
[Iter 1050/20000] Loss: 0.0057408 (Best: 0.0050360 @iter979) ([92m↓1.83%[0m) [2.28% of initial]
[Iter 1060/20000] Loss: 0.0056036 (Best: 0.0048509 @iter1055) ([92m↓2.39%[0m) [2.23% of initial]
[Iter 1070/20000] Loss: 0.0053307 (Best: 0.0044166 @iter1066) ([92m↓4.87%[0m) [2.12% of initial]
[Iter 1080/20000] Loss: 0.0052271 (Best: 0.0044166 @iter1066) ([92m↓1.94%[0m) [2.08% of initial]
[Iter 1090/20000] Loss: 0.0049145 (Best: 0.0044166 @iter1066) ([92m↓5.98%[0m) [1.95% of initial]
Iter:1099, L1 loss=0.003478, Total loss=0.004877, Time:50
[Iter 1100/20000] Loss: 0.0048454 (Best: 0.0041584 @iter1093) ([92m↓1.41%[0m) [1.93% of initial]
[Iter 1110/20000] Loss: 0.0049429 (Best: 0.0041584 @iter1093) ([91m↑2.01%[0m) [1.96% of initial]
[Iter 1120/20000] Loss: 0.0048931 (Best: 0.0041001 @iter1117) ([92m↓1.01%[0m) [1.94% of initial]
[Iter 1130/20000] Loss: 0.0051260 (Best: 0.0041001 @iter1117) ([91m↑4.76%[0m) [2.04% of initial]
[Iter 1140/20000] Loss: 0.0047978 (Best: 0.0039917 @iter1135) ([92m↓6.40%[0m) [1.91% of initial]
[Iter 1150/20000] Loss: 0.0044767 (Best: 0.0039552 @iter1145) ([92m↓6.69%[0m) [1.78% of initial]
[Iter 1160/20000] Loss: 0.0050405 (Best: 0.0039552 @iter1145) ([91m↑12.59%[0m) [2.00% of initial]
[Iter 1170/20000] Loss: 0.0046500 (Best: 0.0039552 @iter1145) ([92m↓7.75%[0m) [1.85% of initial]
[Iter 1180/20000] Loss: 0.0042669 (Best: 0.0038524 @iter1180) ([92m↓8.24%[0m) [1.70% of initial]
[Iter 1190/20000] Loss: 0.0045830 (Best: 0.0038524 @iter1180) ([91m↑7.41%[0m) [1.82% of initial]
Iter:1199, L1 loss=0.00347, Total loss=0.004847, Time:45
[Iter 1200/20000] Loss: 0.0045147 (Best: 0.0037090 @iter1195) ([92m↓1.49%[0m) [1.79% of initial]
[Iter 1210/20000] Loss: 0.0106497 (Best: 0.0037090 @iter1195) ([91m↑135.89%[0m) [4.23% of initial]
[Iter 1220/20000] Loss: 0.0070518 (Best: 0.0037090 @iter1195) ([92m↓33.78%[0m) [2.80% of initial]
[Iter 1230/20000] Loss: 0.0060208 (Best: 0.0037090 @iter1195) ([92m↓14.62%[0m) [2.39% of initial]
[Iter 1240/20000] Loss: 0.0054849 (Best: 0.0037090 @iter1195) ([92m↓8.90%[0m) [2.18% of initial]
[Iter 1250/20000] Loss: 0.0047798 (Best: 0.0037090 @iter1195) ([92m↓12.85%[0m) [1.90% of initial]
[Iter 1260/20000] Loss: 0.0046264 (Best: 0.0037090 @iter1195) ([92m↓3.21%[0m) [1.84% of initial]
[Iter 1270/20000] Loss: 0.0041466 (Best: 0.0037078 @iter1269) ([92m↓10.37%[0m) [1.65% of initial]
[Iter 1280/20000] Loss: 0.0044210 (Best: 0.0033896 @iter1273) ([91m↑6.62%[0m) [1.76% of initial]
[Iter 1290/20000] Loss: 0.0042283 (Best: 0.0033796 @iter1285) ([92m↓4.36%[0m) [1.68% of initial]
Iter:1299, L1 loss=0.002732, Total loss=0.003738, Time:48
[Iter 1300/20000] Loss: 0.0040603 (Best: 0.0033796 @iter1285) ([92m↓3.97%[0m) [1.61% of initial]
[Iter 1310/20000] Loss: 0.0040893 (Best: 0.0033709 @iter1301) ([91m↑0.71%[0m) [1.62% of initial]
[Iter 1320/20000] Loss: 0.0038758 (Best: 0.0031342 @iter1319) ([92m↓5.22%[0m) [1.54% of initial]
[Iter 1330/20000] Loss: 0.0039239 (Best: 0.0030708 @iter1321) ([91m↑1.24%[0m) [1.56% of initial]
[Iter 1340/20000] Loss: 0.0036424 (Best: 0.0030708 @iter1321) ([92m↓7.17%[0m) [1.45% of initial]
[Iter 1350/20000] Loss: 0.0036604 (Best: 0.0030708 @iter1321) ([91m↑0.49%[0m) [1.45% of initial]
[Iter 1360/20000] Loss: 0.0037914 (Best: 0.0030708 @iter1321) ([91m↑3.58%[0m) [1.51% of initial]
[Iter 1370/20000] Loss: 0.0035621 (Best: 0.0030708 @iter1321) ([92m↓6.05%[0m) [1.42% of initial]
[Iter 1380/20000] Loss: 0.0039160 (Best: 0.0030708 @iter1321) ([91m↑9.93%[0m) [1.56% of initial]
[Iter 1390/20000] Loss: 0.0037132 (Best: 0.0030708 @iter1321) ([92m↓5.18%[0m) [1.48% of initial]
Iter:1399, L1 loss=0.002238, Total loss=0.002909, Time:56
[Iter 1400/20000] Loss: 0.0034235 (Best: 0.0029086 @iter1399) ([92m↓7.80%[0m) [1.36% of initial]
[Iter 1410/20000] Loss: 0.0087367 (Best: 0.0029086 @iter1399) ([91m↑155.20%[0m) [3.47% of initial]
[Iter 1420/20000] Loss: 0.0059244 (Best: 0.0029086 @iter1399) ([92m↓32.19%[0m) [2.35% of initial]
[Iter 1430/20000] Loss: 0.0048325 (Best: 0.0029086 @iter1399) ([92m↓18.43%[0m) [1.92% of initial]
[Iter 1440/20000] Loss: 0.0044068 (Best: 0.0029086 @iter1399) ([92m↓8.81%[0m) [1.75% of initial]
[Iter 1450/20000] Loss: 0.0035118 (Best: 0.0029086 @iter1399) ([92m↓20.31%[0m) [1.40% of initial]
[Iter 1460/20000] Loss: 0.0035196 (Best: 0.0029086 @iter1399) ([91m↑0.22%[0m) [1.40% of initial]
[Iter 1470/20000] Loss: 0.0033579 (Best: 0.0029086 @iter1399) ([92m↓4.59%[0m) [1.33% of initial]
[Iter 1480/20000] Loss: 0.0033409 (Best: 0.0028025 @iter1474) ([92m↓0.51%[0m) [1.33% of initial]
[Iter 1490/20000] Loss: 0.0031936 (Best: 0.0028025 @iter1474) ([92m↓4.41%[0m) [1.27% of initial]
Iter:1499, L1 loss=0.002557, Total loss=0.003337, Time:56
[Iter 1500/20000] Loss: 0.0031421 (Best: 0.0028025 @iter1474) ([92m↓1.61%[0m) [1.25% of initial]
[Iter 1510/20000] Loss: 0.0029981 (Best: 0.0025207 @iter1504) ([92m↓4.58%[0m) [1.19% of initial]
[Iter 1520/20000] Loss: 0.0029932 (Best: 0.0025207 @iter1504) ([92m↓0.16%[0m) [1.19% of initial]
[Iter 1530/20000] Loss: 0.0030715 (Best: 0.0025207 @iter1504) ([91m↑2.61%[0m) [1.22% of initial]
[Iter 1540/20000] Loss: 0.0030277 (Best: 0.0025207 @iter1504) ([92m↓1.42%[0m) [1.20% of initial]
[Iter 1550/20000] Loss: 0.0029732 (Best: 0.0025207 @iter1504) ([92m↓1.80%[0m) [1.18% of initial]
[Iter 1560/20000] Loss: 0.0032004 (Best: 0.0025207 @iter1504) ([91m↑7.64%[0m) [1.27% of initial]
[Iter 1570/20000] Loss: 0.0028086 (Best: 0.0025011 @iter1569) ([92m↓12.24%[0m) [1.12% of initial]
[Iter 1580/20000] Loss: 0.0028181 (Best: 0.0023255 @iter1573) ([91m↑0.34%[0m) [1.12% of initial]
[Iter 1590/20000] Loss: 0.0026981 (Best: 0.0023255 @iter1573) ([92m↓4.26%[0m) [1.07% of initial]
Iter:1599, L1 loss=0.002683, Total loss=0.003265, Time:48
[Iter 1600/20000] Loss: 0.0029869 (Best: 0.0023100 @iter1591) ([91m↑10.70%[0m) [1.19% of initial]
[Iter 1610/20000] Loss: 0.0080944 (Best: 0.0023100 @iter1591) ([91m↑171.00%[0m) [3.22% of initial]
[Iter 1620/20000] Loss: 0.0052623 (Best: 0.0023100 @iter1591) ([92m↓34.99%[0m) [2.09% of initial]
[Iter 1630/20000] Loss: 0.0040576 (Best: 0.0023100 @iter1591) ([92m↓22.89%[0m) [1.61% of initial]
[Iter 1640/20000] Loss: 0.0037753 (Best: 0.0023100 @iter1591) ([92m↓6.96%[0m) [1.50% of initial]
[Iter 1650/20000] Loss: 0.0033538 (Best: 0.0023100 @iter1591) ([92m↓11.16%[0m) [1.33% of initial]
[Iter 1660/20000] Loss: 0.0028601 (Best: 0.0023100 @iter1591) ([92m↓14.72%[0m) [1.14% of initial]
[Iter 1670/20000] Loss: 0.0027071 (Best: 0.0022429 @iter1669) ([92m↓5.35%[0m) [1.08% of initial]
[Iter 1680/20000] Loss: 0.0028696 (Best: 0.0022429 @iter1669) ([91m↑6.00%[0m) [1.14% of initial]
[Iter 1690/20000] Loss: 0.0030237 (Best: 0.0022429 @iter1669) ([91m↑5.37%[0m) [1.20% of initial]
Iter:1699, L1 loss=0.002498, Total loss=0.003046, Time:47
[Iter 1700/20000] Loss: 0.0027278 (Best: 0.0022429 @iter1669) ([92m↓9.78%[0m) [1.08% of initial]
[Iter 1710/20000] Loss: 0.0030733 (Best: 0.0022429 @iter1669) ([91m↑12.66%[0m) [1.22% of initial]
[Iter 1720/20000] Loss: 0.0025577 (Best: 0.0022429 @iter1669) ([92m↓16.78%[0m) [1.02% of initial]
[Iter 1730/20000] Loss: 0.0025917 (Best: 0.0022429 @iter1669) ([91m↑1.33%[0m) [1.03% of initial]
[Iter 1740/20000] Loss: 0.0025171 (Best: 0.0021477 @iter1738) ([92m↓2.88%[0m) [1.00% of initial]
[Iter 1750/20000] Loss: 0.0022403 (Best: 0.0020060 @iter1750) ([92m↓11.00%[0m) [0.89% of initial]
[Iter 1760/20000] Loss: 0.0025602 (Best: 0.0020060 @iter1750) ([91m↑14.28%[0m) [1.02% of initial]
[Iter 1770/20000] Loss: 0.0024367 (Best: 0.0020060 @iter1750) ([92m↓4.83%[0m) [0.97% of initial]
[Iter 1780/20000] Loss: 0.0024516 (Best: 0.0020060 @iter1750) ([91m↑0.61%[0m) [0.97% of initial]
[Iter 1790/20000] Loss: 0.0021487 (Best: 0.0017744 @iter1789) ([92m↓12.36%[0m) [0.85% of initial]
Iter:1799, L1 loss=0.001647, Total loss=0.00189, Time:59
[Iter 1800/20000] Loss: 0.0021794 (Best: 0.0017744 @iter1789) ([91m↑1.43%[0m) [0.87% of initial]
[Iter 1810/20000] Loss: 0.0074913 (Best: 0.0017744 @iter1789) ([91m↑243.74%[0m) [2.98% of initial]
[Iter 1820/20000] Loss: 0.0045169 (Best: 0.0017744 @iter1789) ([92m↓39.70%[0m) [1.79% of initial]
[Iter 1830/20000] Loss: 0.0038348 (Best: 0.0017744 @iter1789) ([92m↓15.10%[0m) [1.52% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 1840/20000] Loss: 0.0027107 (Best: 0.0017744 @iter1789) ([92m↓29.31%[0m) [1.08% of initial]
[Iter 1850/20000] Loss: 0.0025669 (Best: 0.0017744 @iter1789) ([92m↓5.30%[0m) [1.02% of initial]
[Iter 1860/20000] Loss: 0.0023499 (Best: 0.0017744 @iter1789) ([92m↓8.45%[0m) [0.93% of initial]
[Iter 1870/20000] Loss: 0.0021911 (Best: 0.0017744 @iter1789) ([92m↓6.76%[0m) [0.87% of initial]
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 1880/20000] Loss: 0.0020820 (Best: 0.0017744 @iter1789) ([92m↓4.98%[0m) [0.83% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693030 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 1890/20000] Loss: 0.0018650 (Best: 0.0017262 @iter1890) ([92m↓10.42%[0m) [0.74% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327878 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
Iter:1899, L1 loss=0.001663, Total loss=0.001895, Time:64
[Iter 1900/20000] Loss: 0.0019931 (Best: 0.0015903 @iter1891) ([91m↑6.87%[0m) [0.79% of initial]
[Iter 40/20000] Loss: 0.1123926 (Best: 0.1098382 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 1910/20000] Loss: 0.0020051 (Best: 0.0015903 @iter1891) ([91m↑0.60%[0m) [0.80% of initial]
[Iter 50/20000] Loss: 0.0993456 (Best: 0.0965480 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 1920/20000] Loss: 0.0020858 (Best: 0.0015903 @iter1891) ([91m↑4.02%[0m) [0.83% of initial]
[Iter 60/20000] Loss: 0.0936773 (Best: 0.0908522 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 1930/20000] Loss: 0.0017554 (Best: 0.0015903 @iter1891) ([92m↓15.84%[0m) [0.70% of initial]
[Iter 70/20000] Loss: 0.0884497 (Best: 0.0869410 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 1940/20000] Loss: 0.0019069 (Best: 0.0015711 @iter1939) ([91m↑8.64%[0m) [0.76% of initial]
[Iter 80/20000] Loss: 0.0851808 (Best: 0.0830896 @iter80) ([92m↓3.70%[0m) [33.84% of initial]
[Iter 1950/20000] Loss: 0.0020688 (Best: 0.0015711 @iter1939) ([91m↑8.49%[0m) [0.82% of initial]
[Iter 90/20000] Loss: 0.0824089 (Best: 0.0801440 @iter88) ([92m↓3.25%[0m) [32.74% of initial]
[Iter 1960/20000] Loss: 0.0018959 (Best: 0.0015711 @iter1939) ([92m↓8.36%[0m) [0.75% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:41
[Iter 100/20000] Loss: 0.0786618 (Best: 0.0766102 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 1970/20000] Loss: 0.0017233 (Best: 0.0015711 @iter1939) ([92m↓9.10%[0m) [0.68% of initial]
[Iter 110/20000] Loss: 0.0753278 (Best: 0.0731388 @iter106) ([92m↓4.24%[0m) [29.93% of initial]
[Iter 1980/20000] Loss: 0.0020297 (Best: 0.0015711 @iter1939) ([91m↑17.77%[0m) [0.81% of initial]
[Iter 120/20000] Loss: 0.0714242 (Best: 0.0685411 @iter118) ([92m↓5.18%[0m) [28.38% of initial]
[Iter 1990/20000] Loss: 0.0017631 (Best: 0.0015711 @iter1939) ([92m↓13.13%[0m) [0.70% of initial]
Iter:1999, L1 loss=0.001553, Total loss=0.001646, Time:67
[Iter 130/20000] Loss: 0.0667054 (Best: 0.0642092 @iter130) ([92m↓6.61%[0m) [26.50% of initial]
[Iter 2000/20000] Loss: 0.0018783 (Best: 0.0014274 @iter1996) ([91m↑6.54%[0m) [0.75% of initial]
Testing Speed: 86.06539346721955 fps
Testing Time: 0.5809535980224609 s

[ITER 2000] Evaluating test: SSIM = 0.8508808469772339, PSNR = 17.814831981658937
Testing Speed: 75.77967551160522 fps
Testing Time: 0.03958845138549805 s

[ITER 2000] Evaluating train: SSIM = 0.9999513824780781, PSNR = 48.905087788899735
Iter:2000, total_points:42893
[Iter 140/20000] Loss: 0.0635418 (Best: 0.0612853 @iter140) ([92m↓4.74%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612897 (Best: 0.0583922 @iter148) ([92m↓3.54%[0m) [24.35% of initial]
[Iter 2010/20000] Loss: 0.0065386 (Best: 0.0014274 @iter1996) ([91m↑248.11%[0m) [2.60% of initial]
[Iter 160/20000] Loss: 0.0590725 (Best: 0.0559629 @iter157) ([92m↓3.62%[0m) [23.47% of initial]
[Iter 2020/20000] Loss: 0.0036896 (Best: 0.0014274 @iter1996) ([92m↓43.57%[0m) [1.47% of initial]
[Iter 170/20000] Loss: 0.0563605 (Best: 0.0535138 @iter167) ([92m↓4.59%[0m) [22.39% of initial]
[Iter 2030/20000] Loss: 0.0028068 (Best: 0.0014274 @iter1996) ([92m↓23.93%[0m) [1.12% of initial]
[Iter 180/20000] Loss: 0.0523534 (Best: 0.0500291 @iter179) ([92m↓7.11%[0m) [20.80% of initial]
[Iter 2040/20000] Loss: 0.0024348 (Best: 0.0014274 @iter1996) ([92m↓13.26%[0m) [0.97% of initial]
[Iter 2050/20000] Loss: 0.0020321 (Best: 0.0014274 @iter1996) ([92m↓16.54%[0m) [0.81% of initial]
[Iter 190/20000] Loss: 0.0495331 (Best: 0.0478781 @iter188) ([92m↓5.39%[0m) [19.68% of initial]
Iter:199, L1 loss=0.03442, Total loss=0.04976, Time:51
[Iter 2060/20000] Loss: 0.0016867 (Best: 0.0014274 @iter1996) ([92m↓17.00%[0m) [0.67% of initial]
[Iter 200/20000] Loss: 0.0478017 (Best: 0.0457177 @iter198) ([92m↓3.50%[0m) [18.99% of initial]
[Iter 210/20000] Loss: 0.0450233 (Best: 0.0427954 @iter209) ([92m↓5.81%[0m) [17.89% of initial]
[Iter 2070/20000] Loss: 0.0019368 (Best: 0.0014274 @iter1996) ([91m↑14.83%[0m) [0.77% of initial]
[Iter 220/20000] Loss: 0.0440760 (Best: 0.0412340 @iter219) ([92m↓2.10%[0m) [17.51% of initial]
[Iter 2080/20000] Loss: 0.0018579 (Best: 0.0014274 @iter1996) ([92m↓4.07%[0m) [0.74% of initial]
[Iter 230/20000] Loss: 0.0423135 (Best: 0.0399170 @iter227) ([92m↓4.00%[0m) [16.81% of initial]
[Iter 2090/20000] Loss: 0.0017897 (Best: 0.0013770 @iter2089) ([92m↓3.67%[0m) [0.71% of initial]
Iter:2099, L1 loss=0.001573, Total loss=0.001682, Time:42
[Iter 2100/20000] Loss: 0.0016824 (Best: 0.0013770 @iter2089) ([92m↓5.99%[0m) [0.67% of initial]
[Iter 240/20000] Loss: 0.0402288 (Best: 0.0377802 @iter238) ([92m↓4.93%[0m) [15.98% of initial]
[Iter 2110/20000] Loss: 0.0015921 (Best: 0.0013770 @iter2089) ([92m↓5.37%[0m) [0.63% of initial]
[Iter 250/20000] Loss: 0.0379889 (Best: 0.0362704 @iter248) ([92m↓5.57%[0m) [15.09% of initial]
[Iter 260/20000] Loss: 0.0358089 (Best: 0.0342249 @iter260) ([92m↓5.74%[0m) [14.23% of initial]
[Iter 2120/20000] Loss: 0.0014069 (Best: 0.0012702 @iter2120) ([92m↓11.63%[0m) [0.56% of initial]
[Iter 270/20000] Loss: 0.0349509 (Best: 0.0329586 @iter269) ([92m↓2.40%[0m) [13.89% of initial]
[Iter 2130/20000] Loss: 0.0015883 (Best: 0.0012486 @iter2125) ([91m↑12.89%[0m) [0.63% of initial]
[Iter 280/20000] Loss: 0.0346198 (Best: 0.0317389 @iter277) ([92m↓0.95%[0m) [13.75% of initial]
[Iter 2140/20000] Loss: 0.0017108 (Best: 0.0012486 @iter2125) ([91m↑7.71%[0m) [0.68% of initial]
[Iter 290/20000] Loss: 0.0328771 (Best: 0.0301263 @iter287) ([92m↓5.03%[0m) [13.06% of initial]
[Iter 2150/20000] Loss: 0.0017620 (Best: 0.0012486 @iter2125) ([91m↑2.99%[0m) [0.70% of initial]
Iter:299, L1 loss=0.0221, Total loss=0.03338, Time:46
[Iter 300/20000] Loss: 0.0308201 (Best: 0.0289289 @iter300) ([92m↓6.26%[0m) [12.24% of initial]
[Iter 2160/20000] Loss: 0.0015911 (Best: 0.0012486 @iter2125) ([92m↓9.70%[0m) [0.63% of initial]
[Iter 310/20000] Loss: 0.0294192 (Best: 0.0274309 @iter310) ([92m↓4.55%[0m) [11.69% of initial]
[Iter 2170/20000] Loss: 0.0016334 (Best: 0.0012486 @iter2125) ([91m↑2.66%[0m) [0.65% of initial]
[Iter 320/20000] Loss: 0.0280757 (Best: 0.0266551 @iter320) ([92m↓4.57%[0m) [11.15% of initial]
[Iter 2180/20000] Loss: 0.0013661 (Best: 0.0012412 @iter2180) ([92m↓16.37%[0m) [0.54% of initial]
[Iter 330/20000] Loss: 0.0276509 (Best: 0.0257624 @iter330) ([92m↓1.51%[0m) [10.99% of initial]
[Iter 2190/20000] Loss: 0.0016445 (Best: 0.0012412 @iter2180) ([91m↑20.38%[0m) [0.65% of initial]
[Iter 340/20000] Loss: 0.0254136 (Best: 0.0242730 @iter340) ([92m↓8.09%[0m) [10.10% of initial]
Iter:2199, L1 loss=0.001429, Total loss=0.001588, Time:61
[Iter 2200/20000] Loss: 0.0016285 (Best: 0.0012412 @iter2180) ([92m↓0.97%[0m) [0.65% of initial]
[Iter 350/20000] Loss: 0.0261578 (Best: 0.0235724 @iter349) ([91m↑2.93%[0m) [10.39% of initial]
[Iter 2210/20000] Loss: 0.0075518 (Best: 0.0012412 @iter2180) ([91m↑363.73%[0m) [3.00% of initial]
[Iter 360/20000] Loss: 0.0248076 (Best: 0.0226929 @iter358) ([92m↓5.16%[0m) [9.86% of initial]
[Iter 2220/20000] Loss: 0.0041546 (Best: 0.0012412 @iter2180) ([92m↓44.99%[0m) [1.65% of initial]
[Iter 370/20000] Loss: 0.0245570 (Best: 0.0222418 @iter368) ([92m↓1.01%[0m) [9.76% of initial]
[Iter 2230/20000] Loss: 0.0025819 (Best: 0.0012412 @iter2180) ([92m↓37.85%[0m) [1.03% of initial]
[Iter 380/20000] Loss: 0.0224086 (Best: 0.0212444 @iter379) ([92m↓8.75%[0m) [8.90% of initial]
[Iter 2240/20000] Loss: 0.0022740 (Best: 0.0012412 @iter2180) ([92m↓11.93%[0m) [0.90% of initial]
[Iter 390/20000] Loss: 0.0217718 (Best: 0.0203364 @iter390) ([92m↓2.84%[0m) [8.65% of initial]
Iter:399, L1 loss=0.01361, Total loss=0.0211, Time:45
[Iter 400/20000] Loss: 0.0204244 (Best: 0.0189926 @iter400) ([92m↓6.19%[0m) [8.11% of initial]
[Iter 2250/20000] Loss: 0.0020956 (Best: 0.0012412 @iter2180) ([92m↓7.85%[0m) [0.83% of initial]
[Iter 410/20000] Loss: 0.0194825 (Best: 0.0185901 @iter410) ([92m↓4.61%[0m) [7.74% of initial]
[Iter 2260/20000] Loss: 0.0016831 (Best: 0.0012412 @iter2180) ([92m↓19.68%[0m) [0.67% of initial]
[Iter 420/20000] Loss: 0.0199494 (Best: 0.0178895 @iter418) ([91m↑2.40%[0m) [7.93% of initial]
[Iter 2270/20000] Loss: 0.0018124 (Best: 0.0012412 @iter2180) ([91m↑7.68%[0m) [0.72% of initial]
[Iter 430/20000] Loss: 0.0177563 (Best: 0.0168690 @iter430) ([92m↓10.99%[0m) [7.05% of initial]
[Iter 2280/20000] Loss: 0.0014637 (Best: 0.0012412 @iter2180) ([92m↓19.24%[0m) [0.58% of initial]
[Iter 440/20000] Loss: 0.0181224 (Best: 0.0164545 @iter434) ([91m↑2.06%[0m) [7.20% of initial]
[Iter 2290/20000] Loss: 0.0014053 (Best: 0.0012034 @iter2285) ([92m↓3.99%[0m) [0.56% of initial]
[Iter 450/20000] Loss: 0.0171587 (Best: 0.0152379 @iter449) ([92m↓5.32%[0m) [6.82% of initial]
Iter:2299, L1 loss=0.001283, Total loss=0.001402, Time:53
[Iter 2300/20000] Loss: 0.0016842 (Best: 0.0012034 @iter2285) ([91m↑19.84%[0m) [0.67% of initial]
[Iter 460/20000] Loss: 0.0165552 (Best: 0.0146009 @iter458) ([92m↓3.52%[0m) [6.58% of initial]
[Iter 2310/20000] Loss: 0.0015501 (Best: 0.0012034 @iter2285) ([92m↓7.96%[0m) [0.62% of initial]
[Iter 470/20000] Loss: 0.0153172 (Best: 0.0144048 @iter463) ([92m↓7.48%[0m) [6.09% of initial]
[Iter 2320/20000] Loss: 0.0013223 (Best: 0.0011850 @iter2320) ([92m↓14.70%[0m) [0.53% of initial]
[Iter 480/20000] Loss: 0.0146913 (Best: 0.0134526 @iter479) ([92m↓4.09%[0m) [5.84% of initial]
[Iter 2330/20000] Loss: 0.0013087 (Best: 0.0011457 @iter2329) ([92m↓1.03%[0m) [0.52% of initial]
[Iter 490/20000] Loss: 0.0140323 (Best: 0.0130874 @iter490) ([92m↓4.49%[0m) [5.57% of initial]
[Iter 2340/20000] Loss: 0.0013715 (Best: 0.0010948 @iter2338) ([91m↑4.80%[0m) [0.54% of initial]
Iter:499, L1 loss=0.008766, Total loss=0.01489, Time:59
[Iter 500/20000] Loss: 0.0138588 (Best: 0.0128482 @iter493) ([92m↓1.24%[0m) [5.51% of initial]
[Iter 2350/20000] Loss: 0.0014862 (Best: 0.0010948 @iter2338) ([91m↑8.36%[0m) [0.59% of initial]
[Iter 510/20000] Loss: 0.0135561 (Best: 0.0122229 @iter507) ([92m↓2.18%[0m) [5.39% of initial]
[Iter 2360/20000] Loss: 0.0013142 (Best: 0.0010948 @iter2338) ([92m↓11.58%[0m) [0.52% of initial]
[Iter 520/20000] Loss: 0.0128986 (Best: 0.0117904 @iter511) ([92m↓4.85%[0m) [5.12% of initial]
[Iter 2370/20000] Loss: 0.0014201 (Best: 0.0010948 @iter2338) ([91m↑8.06%[0m) [0.56% of initial]
[Iter 530/20000] Loss: 0.0128633 (Best: 0.0116191 @iter523) ([92m↓0.27%[0m) [5.11% of initial]
[Iter 2380/20000] Loss: 0.0015250 (Best: 0.0010948 @iter2338) ([91m↑7.38%[0m) [0.61% of initial]
[Iter 540/20000] Loss: 0.0127399 (Best: 0.0113829 @iter538) ([92m↓0.96%[0m) [5.06% of initial]
[Iter 550/20000] Loss: 0.0121493 (Best: 0.0110064 @iter548) ([92m↓4.64%[0m) [4.83% of initial]
[Iter 2390/20000] Loss: 0.0015919 (Best: 0.0010948 @iter2338) ([91m↑4.39%[0m) [0.63% of initial]
Iter:2399, L1 loss=0.00121, Total loss=0.001305, Time:63
[Iter 560/20000] Loss: 0.0122771 (Best: 0.0108890 @iter556) ([91m↑1.05%[0m) [4.88% of initial]
[Iter 2400/20000] Loss: 0.0013387 (Best: 0.0010948 @iter2338) ([92m↓15.91%[0m) [0.53% of initial]
[Iter 570/20000] Loss: 0.0117757 (Best: 0.0104917 @iter569) ([92m↓4.08%[0m) [4.68% of initial]
[Iter 2410/20000] Loss: 0.0059725 (Best: 0.0010948 @iter2338) ([91m↑346.15%[0m) [2.37% of initial]
[Iter 580/20000] Loss: 0.0111862 (Best: 0.0102007 @iter578) ([92m↓5.01%[0m) [4.44% of initial]
[Iter 2420/20000] Loss: 0.0034588 (Best: 0.0010948 @iter2338) ([92m↓42.09%[0m) [1.37% of initial]
[Iter 590/20000] Loss: 0.0114202 (Best: 0.0102007 @iter578) ([91m↑2.09%[0m) [4.54% of initial]
[Iter 2430/20000] Loss: 0.0025824 (Best: 0.0010948 @iter2338) ([92m↓25.34%[0m) [1.03% of initial]
Iter:599, L1 loss=0.007125, Total loss=0.01194, Time:44
[Iter 600/20000] Loss: 0.0109746 (Best: 0.0097719 @iter598) ([92m↓3.90%[0m) [4.36% of initial]
[Iter 2440/20000] Loss: 0.0020614 (Best: 0.0010948 @iter2338) ([92m↓20.17%[0m) [0.82% of initial]
[Iter 610/20000] Loss: 0.0204526 (Best: 0.0097719 @iter598) ([91m↑86.36%[0m) [8.13% of initial]
[Iter 2450/20000] Loss: 0.0020395 (Best: 0.0010948 @iter2338) ([92m↓1.06%[0m) [0.81% of initial]
[Iter 620/20000] Loss: 0.0138458 (Best: 0.0097719 @iter598) ([92m↓32.30%[0m) [5.50% of initial]
[Iter 2460/20000] Loss: 0.0017060 (Best: 0.0010948 @iter2338) ([92m↓16.35%[0m) [0.68% of initial]
[Iter 630/20000] Loss: 0.0116824 (Best: 0.0097719 @iter598) ([92m↓15.62%[0m) [4.64% of initial]
[Iter 2470/20000] Loss: 0.0016791 (Best: 0.0010948 @iter2338) ([92m↓1.58%[0m) [0.67% of initial]
[Iter 640/20000] Loss: 0.0100227 (Best: 0.0091347 @iter640) ([92m↓14.21%[0m) [3.98% of initial]
[Iter 2480/20000] Loss: 0.0016806 (Best: 0.0010948 @iter2338) ([91m↑0.09%[0m) [0.67% of initial]
[Iter 650/20000] Loss: 0.0103581 (Best: 0.0091218 @iter646) ([91m↑3.35%[0m) [4.12% of initial]
[Iter 2490/20000] Loss: 0.0014803 (Best: 0.0010948 @iter2338) ([92m↓11.92%[0m) [0.59% of initial]
[Iter 660/20000] Loss: 0.0100497 (Best: 0.0086066 @iter655) ([92m↓2.98%[0m) [3.99% of initial]
Iter:2499, L1 loss=0.001282, Total loss=0.001258, Time:54
[Iter 2500/20000] Loss: 0.0013377 (Best: 0.0010948 @iter2338) ([92m↓9.64%[0m) [0.53% of initial]
[Iter 670/20000] Loss: 0.0095803 (Best: 0.0084572 @iter667) ([92m↓4.67%[0m) [3.81% of initial]
[Iter 2510/20000] Loss: 0.0013885 (Best: 0.0010585 @iter2504) ([91m↑3.80%[0m) [0.55% of initial]
[Iter 680/20000] Loss: 0.0087136 (Best: 0.0079625 @iter680) ([92m↓9.05%[0m) [3.46% of initial]
[Iter 690/20000] Loss: 0.0090100 (Best: 0.0076547 @iter685) ([91m↑3.40%[0m) [3.58% of initial]
[Iter 2520/20000] Loss: 0.0012366 (Best: 0.0010585 @iter2504) ([92m↓10.94%[0m) [0.49% of initial]
Iter:699, L1 loss=0.00566, Total loss=0.009431, Time:43
[Iter 700/20000] Loss: 0.0087695 (Best: 0.0076547 @iter685) ([92m↓2.67%[0m) [3.48% of initial]
[Iter 2530/20000] Loss: 0.0011153 (Best: 0.0010016 @iter2530) ([92m↓9.81%[0m) [0.44% of initial]
[Iter 710/20000] Loss: 0.0081527 (Best: 0.0073533 @iter703) ([92m↓7.03%[0m) [3.24% of initial]
[Iter 2540/20000] Loss: 0.0012108 (Best: 0.0010016 @iter2530) ([91m↑8.56%[0m) [0.48% of initial]
[Iter 720/20000] Loss: 0.0083572 (Best: 0.0073533 @iter703) ([91m↑2.51%[0m) [3.32% of initial]
[Iter 2550/20000] Loss: 0.0014471 (Best: 0.0010016 @iter2530) ([91m↑19.52%[0m) [0.57% of initial]
[Iter 730/20000] Loss: 0.0083592 (Best: 0.0073111 @iter727) ([91m↑0.02%[0m) [3.32% of initial]
[Iter 2560/20000] Loss: 0.0012022 (Best: 0.0009788 @iter2557) ([92m↓16.93%[0m) [0.48% of initial]
[Iter 740/20000] Loss: 0.0084497 (Best: 0.0072270 @iter733) ([91m↑1.08%[0m) [3.36% of initial]
[Iter 2570/20000] Loss: 0.0014190 (Best: 0.0009788 @iter2557) ([91m↑18.03%[0m) [0.56% of initial]
[Iter 750/20000] Loss: 0.0080417 (Best: 0.0068608 @iter748) ([92m↓4.83%[0m) [3.19% of initial]
[Iter 2580/20000] Loss: 0.0012499 (Best: 0.0009718 @iter2578) ([92m↓11.92%[0m) [0.50% of initial]
[Iter 760/20000] Loss: 0.0073377 (Best: 0.0068053 @iter751) ([92m↓8.75%[0m) [2.92% of initial]
[Iter 2590/20000] Loss: 0.0013226 (Best: 0.0009553 @iter2584) ([91m↑5.82%[0m) [0.53% of initial]
[Iter 770/20000] Loss: 0.0075481 (Best: 0.0068053 @iter751) ([91m↑2.87%[0m) [3.00% of initial]
Iter:2599, L1 loss=0.001062, Total loss=0.001046, Time:65
[Iter 2600/20000] Loss: 0.0012191 (Best: 0.0009553 @iter2584) ([92m↓7.83%[0m) [0.48% of initial]
[Iter 780/20000] Loss: 0.0077756 (Best: 0.0066359 @iter778) ([91m↑3.01%[0m) [3.09% of initial]
[Iter 790/20000] Loss: 0.0074799 (Best: 0.0064242 @iter787) ([92m↓3.80%[0m) [2.97% of initial]
[Iter 2610/20000] Loss: 0.0059127 (Best: 0.0009553 @iter2584) ([91m↑385.01%[0m) [2.35% of initial]
Iter:799, L1 loss=0.004982, Total loss=0.008072, Time:59
[Iter 800/20000] Loss: 0.0072815 (Best: 0.0064242 @iter787) ([92m↓2.65%[0m) [2.89% of initial]
[Iter 2620/20000] Loss: 0.0032331 (Best: 0.0009553 @iter2584) ([92m↓45.32%[0m) [1.28% of initial]
[Iter 2630/20000] Loss: 0.0022221 (Best: 0.0009553 @iter2584) ([92m↓31.27%[0m) [0.88% of initial]
[Iter 810/20000] Loss: 0.0153563 (Best: 0.0064242 @iter787) ([91m↑110.89%[0m) [6.10% of initial]
[Iter 2640/20000] Loss: 0.0017494 (Best: 0.0009553 @iter2584) ([92m↓21.27%[0m) [0.70% of initial]
[Iter 820/20000] Loss: 0.0106257 (Best: 0.0064242 @iter787) ([92m↓30.81%[0m) [4.22% of initial]
[Iter 2650/20000] Loss: 0.0014684 (Best: 0.0009553 @iter2584) ([92m↓16.06%[0m) [0.58% of initial]
[Iter 830/20000] Loss: 0.0087061 (Best: 0.0064242 @iter787) ([92m↓18.07%[0m) [3.46% of initial]
[Iter 2660/20000] Loss: 0.0016993 (Best: 0.0009553 @iter2584) ([91m↑15.72%[0m) [0.68% of initial]
[Iter 840/20000] Loss: 0.0079449 (Best: 0.0064242 @iter787) ([92m↓8.74%[0m) [3.16% of initial]
[Iter 850/20000] Loss: 0.0073228 (Best: 0.0064242 @iter787) ([92m↓7.83%[0m) [2.91% of initial]
[Iter 2670/20000] Loss: 0.0018540 (Best: 0.0009553 @iter2584) ([91m↑9.10%[0m) [0.74% of initial]
[Iter 860/20000] Loss: 0.0069095 (Best: 0.0062027 @iter856) ([92m↓5.64%[0m) [2.75% of initial]
[Iter 2680/20000] Loss: 0.0013265 (Best: 0.0009553 @iter2584) ([92m↓28.45%[0m) [0.53% of initial]
[Iter 870/20000] Loss: 0.0065932 (Best: 0.0060311 @iter862) ([92m↓4.58%[0m) [2.62% of initial]
[Iter 2690/20000] Loss: 0.0012437 (Best: 0.0009553 @iter2584) ([92m↓6.24%[0m) [0.49% of initial]
[Iter 880/20000] Loss: 0.0065723 (Best: 0.0058327 @iter875) ([92m↓0.32%[0m) [2.61% of initial]
Iter:2699, L1 loss=0.001131, Total loss=0.001202, Time:45
[Iter 2700/20000] Loss: 0.0015327 (Best: 0.0009553 @iter2584) ([91m↑23.24%[0m) [0.61% of initial]
[Iter 890/20000] Loss: 0.0061779 (Best: 0.0055624 @iter884) ([92m↓6.00%[0m) [2.45% of initial]
[Iter 2710/20000] Loss: 0.0013034 (Best: 0.0009553 @iter2584) ([92m↓14.96%[0m) [0.52% of initial]
Iter:899, L1 loss=0.003752, Total loss=0.005626, Time:64
[Iter 900/20000] Loss: 0.0063654 (Best: 0.0055624 @iter884) ([91m↑3.04%[0m) [2.53% of initial]
[Iter 2720/20000] Loss: 0.0011308 (Best: 0.0009553 @iter2584) ([92m↓13.24%[0m) [0.45% of initial]
[Iter 910/20000] Loss: 0.0064605 (Best: 0.0053997 @iter907) ([91m↑1.49%[0m) [2.57% of initial]
[Iter 2730/20000] Loss: 0.0011299 (Best: 0.0009315 @iter2724) ([92m↓0.08%[0m) [0.45% of initial]
[Iter 920/20000] Loss: 0.0058306 (Best: 0.0052427 @iter916) ([92m↓9.75%[0m) [2.32% of initial]
[Iter 2740/20000] Loss: 0.0009254 (Best: 0.0008264 @iter2740) ([92m↓18.10%[0m) [0.37% of initial]
[Iter 930/20000] Loss: 0.0061456 (Best: 0.0051889 @iter925) ([91m↑5.40%[0m) [2.44% of initial]
[Iter 2750/20000] Loss: 0.0011720 (Best: 0.0008264 @iter2740) ([91m↑26.64%[0m) [0.47% of initial]
[Iter 940/20000] Loss: 0.0062022 (Best: 0.0051202 @iter938) ([91m↑0.92%[0m) [2.46% of initial]
[Iter 2760/20000] Loss: 0.0012313 (Best: 0.0008264 @iter2740) ([91m↑5.06%[0m) [0.49% of initial]
[Iter 950/20000] Loss: 0.0057102 (Best: 0.0051169 @iter946) ([92m↓7.93%[0m) [2.27% of initial]
[Iter 2770/20000] Loss: 0.0013460 (Best: 0.0008264 @iter2740) ([91m↑9.32%[0m) [0.53% of initial]
[Iter 960/20000] Loss: 0.0058172 (Best: 0.0051169 @iter946) ([91m↑1.87%[0m) [2.31% of initial]
[Iter 2780/20000] Loss: 0.0011435 (Best: 0.0008264 @iter2740) ([92m↓15.05%[0m) [0.45% of initial]
[Iter 970/20000] Loss: 0.0057212 (Best: 0.0050064 @iter964) ([92m↓1.65%[0m) [2.27% of initial]
[Iter 2790/20000] Loss: 0.0011631 (Best: 0.0008264 @iter2740) ([91m↑1.72%[0m) [0.46% of initial]
[Iter 980/20000] Loss: 0.0059010 (Best: 0.0049831 @iter974) ([91m↑3.14%[0m) [2.34% of initial]
Iter:2799, L1 loss=0.001222, Total loss=0.001345, Time:55
[Iter 2800/20000] Loss: 0.0011543 (Best: 0.0008264 @iter2740) ([92m↓0.76%[0m) [0.46% of initial]
[Iter 990/20000] Loss: 0.0059835 (Best: 0.0049831 @iter974) ([91m↑1.40%[0m) [2.38% of initial]
Iter:999, L1 loss=0.004375, Total loss=0.006562, Time:62
[Iter 1000/20000] Loss: 0.0061715 (Best: 0.0049831 @iter974) ([91m↑3.14%[0m) [2.45% of initial]
[Iter 2810/20000] Loss: 0.0049992 (Best: 0.0008264 @iter2740) ([91m↑333.11%[0m) [1.99% of initial]
Pruning 980 points (7.1%) from gaussian0 at iteration 1000
Pruning 971 points (7.0%) from gaussian1 at iteration 1000
[Iter 2820/20000] Loss: 0.0027603 (Best: 0.0008264 @iter2740) ([92m↓44.78%[0m) [1.10% of initial]
[Iter 1010/20000] Loss: 0.0134394 (Best: 0.0049831 @iter974) ([91m↑117.76%[0m) [5.34% of initial]
[Iter 2830/20000] Loss: 0.0018251 (Best: 0.0008264 @iter2740) ([92m↓33.88%[0m) [0.73% of initial]
[Iter 1020/20000] Loss: 0.0094193 (Best: 0.0049831 @iter974) ([92m↓29.91%[0m) [3.74% of initial]
[Iter 2840/20000] Loss: 0.0015856 (Best: 0.0008264 @iter2740) ([92m↓13.12%[0m) [0.63% of initial]
[Iter 1030/20000] Loss: 0.0077076 (Best: 0.0049831 @iter974) ([92m↓18.17%[0m) [3.06% of initial]
[Iter 2850/20000] Loss: 0.0013547 (Best: 0.0008264 @iter2740) ([92m↓14.56%[0m) [0.54% of initial]
[Iter 1040/20000] Loss: 0.0069352 (Best: 0.0049831 @iter974) ([92m↓10.02%[0m) [2.76% of initial]
[Iter 2860/20000] Loss: 0.0014897 (Best: 0.0008264 @iter2740) ([91m↑9.96%[0m) [0.59% of initial]
[Iter 1050/20000] Loss: 0.0066340 (Best: 0.0049831 @iter974) ([92m↓4.34%[0m) [2.64% of initial]
[Iter 2870/20000] Loss: 0.0012506 (Best: 0.0008264 @iter2740) ([92m↓16.05%[0m) [0.50% of initial]
[Iter 1060/20000] Loss: 0.0063765 (Best: 0.0049831 @iter974) ([92m↓3.88%[0m) [2.53% of initial]
[Iter 1070/20000] Loss: 0.0061480 (Best: 0.0049831 @iter974) ([92m↓3.58%[0m) [2.44% of initial]
[Iter 2880/20000] Loss: 0.0011912 (Best: 0.0008264 @iter2740) ([92m↓4.75%[0m) [0.47% of initial]
[Iter 1080/20000] Loss: 0.0062041 (Best: 0.0049831 @iter974) ([91m↑0.91%[0m) [2.46% of initial]
[Iter 2890/20000] Loss: 0.0011642 (Best: 0.0008264 @iter2740) ([92m↓2.27%[0m) [0.46% of initial]
[Iter 1090/20000] Loss: 0.0059366 (Best: 0.0049831 @iter974) ([92m↓4.31%[0m) [2.36% of initial]
Iter:2899, L1 loss=0.0009091, Total loss=0.00087, Time:51
[Iter 2900/20000] Loss: 0.0010950 (Best: 0.0008264 @iter2740) ([92m↓5.94%[0m) [0.44% of initial]
Iter:1099, L1 loss=0.003847, Total loss=0.00585, Time:47
[Iter 1100/20000] Loss: 0.0057214 (Best: 0.0049831 @iter974) ([92m↓3.63%[0m) [2.27% of initial]
[Iter 2910/20000] Loss: 0.0011773 (Best: 0.0008264 @iter2740) ([91m↑7.51%[0m) [0.47% of initial]
[Iter 1110/20000] Loss: 0.0056566 (Best: 0.0049831 @iter974) ([92m↓1.13%[0m) [2.25% of initial]
[Iter 2920/20000] Loss: 0.0011724 (Best: 0.0008264 @iter2740) ([92m↓0.42%[0m) [0.47% of initial]
[Iter 1120/20000] Loss: 0.0058102 (Best: 0.0049831 @iter974) ([91m↑2.71%[0m) [2.31% of initial]
[Iter 2930/20000] Loss: 0.0011588 (Best: 0.0008264 @iter2740) ([92m↓1.16%[0m) [0.46% of initial]
[Iter 1130/20000] Loss: 0.0058453 (Best: 0.0049831 @iter974) ([91m↑0.60%[0m) [2.32% of initial]
[Iter 2940/20000] Loss: 0.0010187 (Best: 0.0008234 @iter2932) ([92m↓12.09%[0m) [0.40% of initial]
[Iter 1140/20000] Loss: 0.0054681 (Best: 0.0049167 @iter1135) ([92m↓6.45%[0m) [2.17% of initial]
[Iter 2950/20000] Loss: 0.0009560 (Best: 0.0008093 @iter2950) ([92m↓6.15%[0m) [0.38% of initial]
[Iter 1150/20000] Loss: 0.0050266 (Best: 0.0046805 @iter1150) ([92m↓8.07%[0m) [2.00% of initial]
[Iter 2960/20000] Loss: 0.0010362 (Best: 0.0008093 @iter2950) ([91m↑8.39%[0m) [0.41% of initial]
[Iter 1160/20000] Loss: 0.0055619 (Best: 0.0046805 @iter1150) ([91m↑10.65%[0m) [2.21% of initial]
[Iter 2970/20000] Loss: 0.0009278 (Best: 0.0007222 @iter2969) ([92m↓10.46%[0m) [0.37% of initial]
[Iter 1170/20000] Loss: 0.0052330 (Best: 0.0046692 @iter1166) ([92m↓5.91%[0m) [2.08% of initial]
[Iter 2980/20000] Loss: 0.0008788 (Best: 0.0007222 @iter2969) ([92m↓5.28%[0m) [0.35% of initial]
[Iter 1180/20000] Loss: 0.0049356 (Best: 0.0046227 @iter1180) ([92m↓5.68%[0m) [1.96% of initial]
[Iter 2990/20000] Loss: 0.0008878 (Best: 0.0006901 @iter2983) ([91m↑1.03%[0m) [0.35% of initial]
[Iter 1190/20000] Loss: 0.0052236 (Best: 0.0046227 @iter1180) ([91m↑5.84%[0m) [2.08% of initial]
Iter:2999, L1 loss=0.0006953, Total loss=0.000666, Time:56
[Iter 3000/20000] Loss: 0.0008707 (Best: 0.0006660 @iter2999) ([92m↓1.93%[0m) [0.35% of initial]
Iter:1199, L1 loss=0.003727, Total loss=0.00541, Time:39
[Iter 1200/20000] Loss: 0.0051831 (Best: 0.0044903 @iter1195) ([92m↓0.78%[0m) [2.06% of initial]
[Iter 3010/20000] Loss: 0.0045866 (Best: 0.0006660 @iter2999) ([91m↑426.79%[0m) [1.82% of initial]
[Iter 1210/20000] Loss: 0.0121329 (Best: 0.0044903 @iter1195) ([91m↑134.09%[0m) [4.82% of initial]
[Iter 3020/20000] Loss: 0.0026729 (Best: 0.0006660 @iter2999) ([92m↓41.72%[0m) [1.06% of initial]
[Iter 1220/20000] Loss: 0.0079172 (Best: 0.0044903 @iter1195) ([92m↓34.75%[0m) [3.15% of initial]
[Iter 3030/20000] Loss: 0.0020728 (Best: 0.0006660 @iter2999) ([92m↓22.45%[0m) [0.82% of initial]
[Iter 1230/20000] Loss: 0.0065706 (Best: 0.0044903 @iter1195) ([92m↓17.01%[0m) [2.61% of initial]
[Iter 3040/20000] Loss: 0.0016925 (Best: 0.0006660 @iter2999) ([92m↓18.35%[0m) [0.67% of initial]
[Iter 1240/20000] Loss: 0.0059901 (Best: 0.0044903 @iter1195) ([92m↓8.83%[0m) [2.38% of initial]
[Iter 3050/20000] Loss: 0.0014457 (Best: 0.0006660 @iter2999) ([92m↓14.58%[0m) [0.57% of initial]
[Iter 1250/20000] Loss: 0.0053261 (Best: 0.0044903 @iter1195) ([92m↓11.08%[0m) [2.12% of initial]
[Iter 3060/20000] Loss: 0.0014047 (Best: 0.0006660 @iter2999) ([92m↓2.84%[0m) [0.56% of initial]
[Iter 1260/20000] Loss: 0.0051325 (Best: 0.0043917 @iter1258) ([92m↓3.63%[0m) [2.04% of initial]
[Iter 3070/20000] Loss: 0.0013521 (Best: 0.0006660 @iter2999) ([92m↓3.74%[0m) [0.54% of initial]
[Iter 1270/20000] Loss: 0.0047384 (Best: 0.0043917 @iter1258) ([92m↓7.68%[0m) [1.88% of initial]
[Iter 3080/20000] Loss: 0.0011975 (Best: 0.0006660 @iter2999) ([92m↓11.43%[0m) [0.48% of initial]
[Iter 1280/20000] Loss: 0.0049157 (Best: 0.0040987 @iter1273) ([91m↑3.74%[0m) [1.95% of initial]
[Iter 3090/20000] Loss: 0.0011138 (Best: 0.0006660 @iter2999) ([92m↓6.99%[0m) [0.44% of initial]
[Iter 1290/20000] Loss: 0.0047838 (Best: 0.0039693 @iter1288) ([92m↓2.68%[0m) [1.90% of initial]
Iter:3099, L1 loss=0.0009036, Total loss=0.000898, Time:62
Iter:1299, L1 loss=0.003001, Total loss=0.004283, Time:46
[Iter 3100/20000] Loss: 0.0010381 (Best: 0.0006660 @iter2999) ([92m↓6.80%[0m) [0.41% of initial]
[Iter 1300/20000] Loss: 0.0045468 (Best: 0.0039693 @iter1288) ([92m↓4.95%[0m) [1.81% of initial]
[Iter 1310/20000] Loss: 0.0045802 (Best: 0.0039693 @iter1288) ([91m↑0.73%[0m) [1.82% of initial]
[Iter 3110/20000] Loss: 0.0010993 (Best: 0.0006660 @iter2999) ([91m↑5.89%[0m) [0.44% of initial]
[Iter 1320/20000] Loss: 0.0044240 (Best: 0.0038014 @iter1319) ([92m↓3.41%[0m) [1.76% of initial]
[Iter 3120/20000] Loss: 0.0010662 (Best: 0.0006660 @iter2999) ([92m↓3.01%[0m) [0.42% of initial]
[Iter 1330/20000] Loss: 0.0043937 (Best: 0.0037066 @iter1321) ([92m↓0.68%[0m) [1.75% of initial]
[Iter 3130/20000] Loss: 0.0008737 (Best: 0.0006660 @iter2999) ([92m↓18.05%[0m) [0.35% of initial]
[Iter 1340/20000] Loss: 0.0041805 (Best: 0.0037066 @iter1321) ([92m↓4.85%[0m) [1.66% of initial]
[Iter 3140/20000] Loss: 0.0008630 (Best: 0.0006660 @iter2999) ([92m↓1.23%[0m) [0.34% of initial]
[Iter 1350/20000] Loss: 0.0042483 (Best: 0.0037066 @iter1321) ([91m↑1.62%[0m) [1.69% of initial]
[Iter 3150/20000] Loss: 0.0008916 (Best: 0.0006660 @iter2999) ([91m↑3.32%[0m) [0.35% of initial]
[Iter 1360/20000] Loss: 0.0042471 (Best: 0.0037066 @iter1321) ([92m↓0.03%[0m) [1.69% of initial]
[Iter 3160/20000] Loss: 0.0008307 (Best: 0.0006660 @iter2999) ([92m↓6.84%[0m) [0.33% of initial]
[Iter 1370/20000] Loss: 0.0040330 (Best: 0.0036958 @iter1370) ([92m↓5.04%[0m) [1.60% of initial]
[Iter 3170/20000] Loss: 0.0008571 (Best: 0.0006660 @iter2999) ([91m↑3.19%[0m) [0.34% of initial]
[Iter 1380/20000] Loss: 0.0043011 (Best: 0.0035457 @iter1375) ([91m↑6.65%[0m) [1.71% of initial]
[Iter 3180/20000] Loss: 0.0008909 (Best: 0.0006660 @iter2999) ([91m↑3.94%[0m) [0.35% of initial]
[Iter 1390/20000] Loss: 0.0041340 (Best: 0.0035457 @iter1375) ([92m↓3.89%[0m) [1.64% of initial]
[Iter 3190/20000] Loss: 0.0008680 (Best: 0.0006660 @iter2999) ([92m↓2.56%[0m) [0.34% of initial]
Iter:1399, L1 loss=0.002469, Total loss=0.003392, Time:50
[Iter 1400/20000] Loss: 0.0038422 (Best: 0.0033918 @iter1399) ([92m↓7.06%[0m) [1.53% of initial]
Iter:3199, L1 loss=0.0007783, Total loss=0.0007272, Time:62
[Iter 3200/20000] Loss: 0.0008247 (Best: 0.0006326 @iter3196) ([92m↓4.99%[0m) [0.33% of initial]
[Iter 1410/20000] Loss: 0.0095045 (Best: 0.0033918 @iter1399) ([91m↑147.37%[0m) [3.78% of initial]
[Iter 3210/20000] Loss: 0.0052881 (Best: 0.0006326 @iter3196) ([91m↑541.21%[0m) [2.10% of initial]
[Iter 1420/20000] Loss: 0.0065675 (Best: 0.0033918 @iter1399) ([92m↓30.90%[0m) [2.61% of initial]
[Iter 3220/20000] Loss: 0.0028859 (Best: 0.0006326 @iter3196) ([92m↓45.43%[0m) [1.15% of initial]
[Iter 1430/20000] Loss: 0.0052949 (Best: 0.0033918 @iter1399) ([92m↓19.38%[0m) [2.10% of initial]
[Iter 3230/20000] Loss: 0.0017140 (Best: 0.0006326 @iter3196) ([92m↓40.61%[0m) [0.68% of initial]
[Iter 1440/20000] Loss: 0.0048005 (Best: 0.0033918 @iter1399) ([92m↓9.34%[0m) [1.91% of initial]
[Iter 3240/20000] Loss: 0.0015081 (Best: 0.0006326 @iter3196) ([92m↓12.01%[0m) [0.60% of initial]
[Iter 1450/20000] Loss: 0.0039709 (Best: 0.0033918 @iter1399) ([92m↓17.28%[0m) [1.58% of initial]
[Iter 1460/20000] Loss: 0.0038809 (Best: 0.0033252 @iter1459) ([92m↓2.27%[0m) [1.54% of initial]
[Iter 3250/20000] Loss: 0.0011154 (Best: 0.0006326 @iter3196) ([92m↓26.04%[0m) [0.44% of initial]
[Iter 1470/20000] Loss: 0.0037929 (Best: 0.0033252 @iter1459) ([92m↓2.27%[0m) [1.51% of initial]
[Iter 3260/20000] Loss: 0.0009944 (Best: 0.0006326 @iter3196) ([92m↓10.85%[0m) [0.40% of initial]
[Iter 1480/20000] Loss: 0.0035565 (Best: 0.0030607 @iter1480) ([92m↓6.23%[0m) [1.41% of initial]
[Iter 3270/20000] Loss: 0.0010206 (Best: 0.0006326 @iter3196) ([91m↑2.64%[0m) [0.41% of initial]
[Iter 1490/20000] Loss: 0.0035427 (Best: 0.0030607 @iter1480) ([92m↓0.39%[0m) [1.41% of initial]
[Iter 3280/20000] Loss: 0.0010262 (Best: 0.0006326 @iter3196) ([91m↑0.55%[0m) [0.41% of initial]
Iter:1499, L1 loss=0.002799, Total loss=0.003735, Time:57
[Iter 1500/20000] Loss: 0.0035447 (Best: 0.0030607 @iter1480) ([91m↑0.06%[0m) [1.41% of initial]
Pruning 734 points (3.0%) from gaussian0 at iteration 1500
Pruning 678 points (2.7%) from gaussian1 at iteration 1500
[Iter 3290/20000] Loss: 0.0008066 (Best: 0.0006326 @iter3196) ([92m↓21.40%[0m) [0.32% of initial]
[Iter 1510/20000] Loss: 0.0048410 (Best: 0.0030607 @iter1480) ([91m↑36.57%[0m) [1.92% of initial]
Iter:3299, L1 loss=0.001237, Total loss=0.001303, Time:60
[Iter 3300/20000] Loss: 0.0010997 (Best: 0.0006326 @iter3196) ([91m↑36.33%[0m) [0.44% of initial]
[Iter 1520/20000] Loss: 0.0040795 (Best: 0.0030607 @iter1480) ([92m↓15.73%[0m) [1.62% of initial]
[Iter 3310/20000] Loss: 0.0008329 (Best: 0.0006326 @iter3196) ([92m↓24.27%[0m) [0.33% of initial]
[Iter 1530/20000] Loss: 0.0038428 (Best: 0.0030607 @iter1480) ([92m↓5.80%[0m) [1.53% of initial]
[Iter 3320/20000] Loss: 0.0009715 (Best: 0.0006326 @iter3196) ([91m↑16.64%[0m) [0.39% of initial]
[Iter 1540/20000] Loss: 0.0036869 (Best: 0.0030607 @iter1480) ([92m↓4.06%[0m) [1.46% of initial]
[Iter 3330/20000] Loss: 0.0010129 (Best: 0.0006326 @iter3196) ([91m↑4.26%[0m) [0.40% of initial]
[Iter 1550/20000] Loss: 0.0033725 (Best: 0.0030281 @iter1543) ([92m↓8.53%[0m) [1.34% of initial]
[Iter 3340/20000] Loss: 0.0010842 (Best: 0.0006326 @iter3196) ([91m↑7.04%[0m) [0.43% of initial]
[Iter 1560/20000] Loss: 0.0036172 (Best: 0.0028967 @iter1558) ([91m↑7.26%[0m) [1.44% of initial]
[Iter 3350/20000] Loss: 0.0008653 (Best: 0.0006326 @iter3196) ([92m↓20.19%[0m) [0.34% of initial]
[Iter 1570/20000] Loss: 0.0032201 (Best: 0.0028967 @iter1558) ([92m↓10.98%[0m) [1.28% of initial]
[Iter 3360/20000] Loss: 0.0010310 (Best: 0.0006326 @iter3196) ([91m↑19.15%[0m) [0.41% of initial]
[Iter 1580/20000] Loss: 0.0033157 (Best: 0.0027453 @iter1573) ([91m↑2.97%[0m) [1.32% of initial]
[Iter 3370/20000] Loss: 0.0007812 (Best: 0.0006326 @iter3196) ([92m↓24.23%[0m) [0.31% of initial]
[Iter 1590/20000] Loss: 0.0031611 (Best: 0.0027453 @iter1573) ([92m↓4.66%[0m) [1.26% of initial]
[Iter 3380/20000] Loss: 0.0007929 (Best: 0.0006239 @iter3379) ([91m↑1.50%[0m) [0.32% of initial]
Iter:1599, L1 loss=0.002901, Total loss=0.003737, Time:71
[Iter 1600/20000] Loss: 0.0034346 (Best: 0.0027453 @iter1573) ([91m↑8.65%[0m) [1.36% of initial]
[Iter 3390/20000] Loss: 0.0009856 (Best: 0.0006239 @iter3379) ([91m↑24.29%[0m) [0.39% of initial]
[Iter 1610/20000] Loss: 0.0095117 (Best: 0.0027453 @iter1573) ([91m↑176.94%[0m) [3.78% of initial]
Iter:3399, L1 loss=0.001254, Total loss=0.001221, Time:60
[Iter 3400/20000] Loss: 0.0010323 (Best: 0.0006239 @iter3379) ([91m↑4.74%[0m) [0.41% of initial]
[Iter 1620/20000] Loss: 0.0063455 (Best: 0.0027453 @iter1573) ([92m↓33.29%[0m) [2.52% of initial]
[Iter 3410/20000] Loss: 0.0044793 (Best: 0.0006239 @iter3379) ([91m↑333.92%[0m) [1.78% of initial]
[Iter 1630/20000] Loss: 0.0047346 (Best: 0.0027453 @iter1573) ([92m↓25.39%[0m) [1.88% of initial]
[Iter 3420/20000] Loss: 0.0023620 (Best: 0.0006239 @iter3379) ([92m↓47.27%[0m) [0.94% of initial]
[Iter 1640/20000] Loss: 0.0041165 (Best: 0.0027453 @iter1573) ([92m↓13.06%[0m) [1.64% of initial]
[Iter 1650/20000] Loss: 0.0036732 (Best: 0.0027453 @iter1573) ([92m↓10.77%[0m) [1.46% of initial]
[Iter 3430/20000] Loss: 0.0015222 (Best: 0.0006239 @iter3379) ([92m↓35.55%[0m) [0.60% of initial]
[Iter 1660/20000] Loss: 0.0032574 (Best: 0.0027453 @iter1573) ([92m↓11.32%[0m) [1.29% of initial]
[Iter 3440/20000] Loss: 0.0013393 (Best: 0.0006239 @iter3379) ([92m↓12.01%[0m) [0.53% of initial]
[Iter 1670/20000] Loss: 0.0031199 (Best: 0.0026210 @iter1669) ([92m↓4.22%[0m) [1.24% of initial]
[Iter 3450/20000] Loss: 0.0012270 (Best: 0.0006239 @iter3379) ([92m↓8.39%[0m) [0.49% of initial]
[Iter 1680/20000] Loss: 0.0031744 (Best: 0.0026210 @iter1669) ([91m↑1.75%[0m) [1.26% of initial]
[Iter 3460/20000] Loss: 0.0011120 (Best: 0.0006239 @iter3379) ([92m↓9.37%[0m) [0.44% of initial]
[Iter 1690/20000] Loss: 0.0032705 (Best: 0.0026210 @iter1669) ([91m↑3.03%[0m) [1.30% of initial]
[Iter 3470/20000] Loss: 0.0010134 (Best: 0.0006239 @iter3379) ([92m↓8.87%[0m) [0.40% of initial]
Iter:1699, L1 loss=0.00264, Total loss=0.003279, Time:47
[Iter 1700/20000] Loss: 0.0029567 (Best: 0.0026193 @iter1700) ([92m↓9.59%[0m) [1.17% of initial]
[Iter 3480/20000] Loss: 0.0010253 (Best: 0.0006239 @iter3379) ([91m↑1.18%[0m) [0.41% of initial]
[Iter 1710/20000] Loss: 0.0032044 (Best: 0.0026193 @iter1700) ([91m↑8.37%[0m) [1.27% of initial]
[Iter 3490/20000] Loss: 0.0009086 (Best: 0.0006239 @iter3379) ([92m↓11.39%[0m) [0.36% of initial]
[Iter 1720/20000] Loss: 0.0027056 (Best: 0.0024872 @iter1720) ([92m↓15.57%[0m) [1.07% of initial]
Iter:3499, L1 loss=0.0006624, Total loss=0.0006194, Time:58
[Iter 3500/20000] Loss: 0.0006812 (Best: 0.0006194 @iter3499) ([92m↓25.03%[0m) [0.27% of initial]
[Iter 1730/20000] Loss: 0.0028622 (Best: 0.0024872 @iter1720) ([91m↑5.79%[0m) [1.14% of initial]
[Iter 1740/20000] Loss: 0.0028057 (Best: 0.0024872 @iter1720) ([92m↓1.97%[0m) [1.11% of initial]
[Iter 3510/20000] Loss: 0.0007578 (Best: 0.0006194 @iter3499) ([91m↑11.25%[0m) [0.30% of initial]
[Iter 1750/20000] Loss: 0.0025687 (Best: 0.0023322 @iter1750) ([92m↓8.45%[0m) [1.02% of initial]
[Iter 3520/20000] Loss: 0.0007854 (Best: 0.0005878 @iter3517) ([91m↑3.63%[0m) [0.31% of initial]
[Iter 1760/20000] Loss: 0.0028521 (Best: 0.0023322 @iter1750) ([91m↑11.04%[0m) [1.13% of initial]
[Iter 3530/20000] Loss: 0.0009568 (Best: 0.0005878 @iter3517) ([91m↑21.82%[0m) [0.38% of initial]
[Iter 1770/20000] Loss: 0.0026849 (Best: 0.0023322 @iter1750) ([92m↓5.86%[0m) [1.07% of initial]
[Iter 3540/20000] Loss: 0.0011225 (Best: 0.0005878 @iter3517) ([91m↑17.33%[0m) [0.45% of initial]
[Iter 1780/20000] Loss: 0.0027169 (Best: 0.0023322 @iter1750) ([91m↑1.19%[0m) [1.08% of initial]
[Iter 3550/20000] Loss: 0.0010205 (Best: 0.0005878 @iter3517) ([92m↓9.09%[0m) [0.41% of initial]
[Iter 1790/20000] Loss: 0.0024621 (Best: 0.0020494 @iter1789) ([92m↓9.38%[0m) [0.98% of initial]
[Iter 3560/20000] Loss: 0.0009316 (Best: 0.0005878 @iter3517) ([92m↓8.71%[0m) [0.37% of initial]
Iter:1799, L1 loss=0.001928, Total loss=0.002216, Time:53
[Iter 3570/20000] Loss: 0.0009962 (Best: 0.0005878 @iter3517) ([91m↑6.94%[0m) [0.40% of initial]
[Iter 3580/20000] Loss: 0.0007331 (Best: 0.0005878 @iter3517) ([92m↓26.41%[0m) [0.29% of initial]
[Iter 1800/20000] Loss: 0.0024863 (Best: 0.0020494 @iter1789) ([91m↑0.99%[0m) [0.99% of initial]
[Iter 3590/20000] Loss: 0.0007332 (Best: 0.0005878 @iter3517) ([91m↑0.01%[0m) [0.29% of initial]
[Iter 1810/20000] Loss: 0.0082935 (Best: 0.0020494 @iter1789) ([91m↑233.56%[0m) [3.29% of initial]
Iter:3599, L1 loss=0.0006195, Total loss=0.0005927, Time:68
[Iter 3600/20000] Loss: 0.0007152 (Best: 0.0005757 @iter3598) ([92m↓2.46%[0m) [0.28% of initial]
[Iter 1820/20000] Loss: 0.0049148 (Best: 0.0020494 @iter1789) ([92m↓40.74%[0m) [1.95% of initial]
[Iter 1830/20000] Loss: 0.0042207 (Best: 0.0020494 @iter1789) ([92m↓14.12%[0m) [1.68% of initial]
[Iter 3610/20000] Loss: 0.0046598 (Best: 0.0005757 @iter3598) ([91m↑551.52%[0m) [1.85% of initial]
[Iter 1840/20000] Loss: 0.0030709 (Best: 0.0020494 @iter1789) ([92m↓27.24%[0m) [1.22% of initial]
[Iter 3620/20000] Loss: 0.0025667 (Best: 0.0005757 @iter3598) ([92m↓44.92%[0m) [1.02% of initial]
[Iter 1850/20000] Loss: 0.0029167 (Best: 0.0020494 @iter1789) ([92m↓5.02%[0m) [1.16% of initial]
[Iter 3630/20000] Loss: 0.0015658 (Best: 0.0005757 @iter3598) ([92m↓38.99%[0m) [0.62% of initial]
[Iter 1860/20000] Loss: 0.0026730 (Best: 0.0020494 @iter1789) ([92m↓8.35%[0m) [1.06% of initial]
[Iter 3640/20000] Loss: 0.0011700 (Best: 0.0005757 @iter3598) ([92m↓25.28%[0m) [0.46% of initial]
[Iter 1870/20000] Loss: 0.0024783 (Best: 0.0020494 @iter1789) ([92m↓7.28%[0m) [0.98% of initial]
[Iter 3650/20000] Loss: 0.0011057 (Best: 0.0005757 @iter3598) ([92m↓5.50%[0m) [0.44% of initial]
[Iter 1880/20000] Loss: 0.0023398 (Best: 0.0020494 @iter1789) ([92m↓5.59%[0m) [0.93% of initial]
[Iter 3660/20000] Loss: 0.0009249 (Best: 0.0005757 @iter3598) ([92m↓16.35%[0m) [0.37% of initial]
[Iter 1890/20000] Loss: 0.0021519 (Best: 0.0019754 @iter1890) ([92m↓8.03%[0m) [0.85% of initial]
Iter:1899, L1 loss=0.001898, Total loss=0.002138, Time:53
[Iter 3670/20000] Loss: 0.0007935 (Best: 0.0005757 @iter3598) ([92m↓14.21%[0m) [0.32% of initial]
[Iter 1900/20000] Loss: 0.0022485 (Best: 0.0018532 @iter1891) ([91m↑4.49%[0m) [0.89% of initial]
[Iter 1910/20000] Loss: 0.0022607 (Best: 0.0018532 @iter1891) ([91m↑0.54%[0m) [0.90% of initial]
[Iter 3680/20000] Loss: 0.0010087 (Best: 0.0005757 @iter3598) ([91m↑27.12%[0m) [0.40% of initial]
[Iter 1920/20000] Loss: 0.0023351 (Best: 0.0018532 @iter1891) ([91m↑3.29%[0m) [0.93% of initial]
[Iter 3690/20000] Loss: 0.0011660 (Best: 0.0005757 @iter3598) ([91m↑15.60%[0m) [0.46% of initial]
[Iter 1930/20000] Loss: 0.0019666 (Best: 0.0017717 @iter1930) ([92m↓15.78%[0m) [0.78% of initial]
Iter:3699, L1 loss=0.001016, Total loss=0.000965, Time:71
[Iter 3700/20000] Loss: 0.0010035 (Best: 0.0005757 @iter3598) ([92m↓13.94%[0m) [0.40% of initial]
[Iter 1940/20000] Loss: 0.0021074 (Best: 0.0017174 @iter1939) ([91m↑7.16%[0m) [0.84% of initial]
[Iter 3710/20000] Loss: 0.0008259 (Best: 0.0005757 @iter3598) ([92m↓17.70%[0m) [0.33% of initial]
[Iter 1950/20000] Loss: 0.0022540 (Best: 0.0017174 @iter1939) ([91m↑6.96%[0m) [0.90% of initial]
[Iter 3720/20000] Loss: 0.0008586 (Best: 0.0005757 @iter3598) ([91m↑3.96%[0m) [0.34% of initial]
[Iter 1960/20000] Loss: 0.0021029 (Best: 0.0017174 @iter1939) ([92m↓6.71%[0m) [0.84% of initial]
[Iter 3730/20000] Loss: 0.0007453 (Best: 0.0005757 @iter3598) ([92m↓13.20%[0m) [0.30% of initial]
[Iter 1970/20000] Loss: 0.0019792 (Best: 0.0017174 @iter1939) ([92m↓5.88%[0m) [0.79% of initial]
[Iter 3740/20000] Loss: 0.0007557 (Best: 0.0005757 @iter3598) ([91m↑1.41%[0m) [0.30% of initial]
[Iter 1980/20000] Loss: 0.0022184 (Best: 0.0017174 @iter1939) ([91m↑12.08%[0m) [0.88% of initial]
[Iter 3750/20000] Loss: 0.0007829 (Best: 0.0005757 @iter3598) ([91m↑3.59%[0m) [0.31% of initial]
[Iter 1990/20000] Loss: 0.0020134 (Best: 0.0017174 @iter1939) ([92m↓9.24%[0m) [0.80% of initial]
[Iter 3760/20000] Loss: 0.0007790 (Best: 0.0005757 @iter3598) ([92m↓0.49%[0m) [0.31% of initial]
Iter:1999, L1 loss=0.001653, Total loss=0.001881, Time:63
[Iter 2000/20000] Loss: 0.0020787 (Best: 0.0016368 @iter1996) ([91m↑3.24%[0m) [0.83% of initial]
Testing Speed: 84.81178365625125 fps
Testing Time: 0.5895407199859619 s

[ITER 2000] Evaluating test: SSIM = 0.8697752058506012, PSNR = 18.135814323425294
Testing Speed: 119.14282467901374 fps
Testing Time: 0.02517986297607422 s

[ITER 2000] Evaluating train: SSIM = 0.999955395857493, PSNR = 48.969086964925125
Iter:2000, total_points:43024
[Iter 3770/20000] Loss: 0.0007438 (Best: 0.0005757 @iter3598) ([92m↓4.53%[0m) [0.30% of initial]
Pruning 702 points (1.3%) from gaussian0 at iteration 2000
Pruning 729 points (1.3%) from gaussian1 at iteration 2000
[Iter 3780/20000] Loss: 0.0006995 (Best: 0.0005349 @iter3775) ([92m↓5.95%[0m) [0.28% of initial]
[Iter 2010/20000] Loss: 0.0082455 (Best: 0.0016368 @iter1996) ([91m↑296.66%[0m) [3.28% of initial]
[Iter 3790/20000] Loss: 0.0005660 (Best: 0.0004968 @iter3790) ([92m↓19.08%[0m) [0.22% of initial]
[Iter 2020/20000] Loss: 0.0051040 (Best: 0.0016368 @iter1996) ([92m↓38.10%[0m) [2.03% of initial]
Iter:3799, L1 loss=0.0007653, Total loss=0.0006928, Time:69
[Iter 2030/20000] Loss: 0.0039306 (Best: 0.0016368 @iter1996) ([92m↓22.99%[0m) [1.56% of initial]
[Iter 3800/20000] Loss: 0.0006849 (Best: 0.0004968 @iter3790) ([91m↑21.01%[0m) [0.27% of initial]
[Iter 2040/20000] Loss: 0.0033127 (Best: 0.0016368 @iter1996) ([92m↓15.72%[0m) [1.32% of initial]
[Iter 3810/20000] Loss: 0.0049686 (Best: 0.0004968 @iter3790) ([91m↑625.40%[0m) [1.97% of initial]
[Iter 2050/20000] Loss: 0.0028185 (Best: 0.0016368 @iter1996) ([92m↓14.92%[0m) [1.12% of initial]
[Iter 3820/20000] Loss: 0.0023387 (Best: 0.0004968 @iter3790) ([92m↓52.93%[0m) [0.93% of initial]
[Iter 2060/20000] Loss: 0.0024082 (Best: 0.0016368 @iter1996) ([92m↓14.56%[0m) [0.96% of initial]
[Iter 2070/20000] Loss: 0.0025157 (Best: 0.0016368 @iter1996) ([91m↑4.46%[0m) [1.00% of initial]
[Iter 3830/20000] Loss: 0.0013770 (Best: 0.0004968 @iter3790) ([92m↓41.12%[0m) [0.55% of initial]
[Iter 2080/20000] Loss: 0.0024054 (Best: 0.0016368 @iter1996) ([92m↓4.38%[0m) [0.96% of initial]
[Iter 3840/20000] Loss: 0.0013856 (Best: 0.0004968 @iter3790) ([91m↑0.63%[0m) [0.55% of initial]
[Iter 2090/20000] Loss: 0.0023236 (Best: 0.0016368 @iter1996) ([92m↓3.40%[0m) [0.92% of initial]
[Iter 3850/20000] Loss: 0.0010422 (Best: 0.0004968 @iter3790) ([92m↓24.79%[0m) [0.41% of initial]
Iter:2099, L1 loss=0.001955, Total loss=0.002203, Time:65
[Iter 2100/20000] Loss: 0.0022058 (Best: 0.0016368 @iter1996) ([92m↓5.07%[0m) [0.88% of initial]
[Iter 3860/20000] Loss: 0.0009601 (Best: 0.0004968 @iter3790) ([92m↓7.88%[0m) [0.38% of initial]
[Iter 2110/20000] Loss: 0.0021120 (Best: 0.0016368 @iter1996) ([92m↓4.25%[0m) [0.84% of initial]
[Iter 3870/20000] Loss: 0.0007782 (Best: 0.0004968 @iter3790) ([92m↓18.94%[0m) [0.31% of initial]
[Iter 2120/20000] Loss: 0.0019001 (Best: 0.0016368 @iter1996) ([92m↓10.03%[0m) [0.75% of initial]
[Iter 3880/20000] Loss: 0.0008077 (Best: 0.0004968 @iter3790) ([91m↑3.79%[0m) [0.32% of initial]
[Iter 2130/20000] Loss: 0.0020391 (Best: 0.0016368 @iter1996) ([91m↑7.32%[0m) [0.81% of initial]
[Iter 3890/20000] Loss: 0.0006622 (Best: 0.0004968 @iter3790) ([92m↓18.01%[0m) [0.26% of initial]
[Iter 2140/20000] Loss: 0.0021350 (Best: 0.0016368 @iter1996) ([91m↑4.70%[0m) [0.85% of initial]
[Iter 2150/20000] Loss: 0.0021511 (Best: 0.0016368 @iter1996) ([91m↑0.75%[0m) [0.85% of initial]
Iter:3899, L1 loss=0.0007114, Total loss=0.0006675, Time:76
[Iter 3900/20000] Loss: 0.0006762 (Best: 0.0004968 @iter3790) ([91m↑2.12%[0m) [0.27% of initial]
[Iter 2160/20000] Loss: 0.0020055 (Best: 0.0016368 @iter1996) ([92m↓6.77%[0m) [0.80% of initial]
[Iter 3910/20000] Loss: 0.0007899 (Best: 0.0004968 @iter3790) ([91m↑16.81%[0m) [0.31% of initial]
[Iter 2170/20000] Loss: 0.0020290 (Best: 0.0016368 @iter1996) ([91m↑1.17%[0m) [0.81% of initial]
[Iter 3920/20000] Loss: 0.0008386 (Best: 0.0004968 @iter3790) ([91m↑6.16%[0m) [0.33% of initial]
[Iter 2180/20000] Loss: 0.0017612 (Best: 0.0016368 @iter1996) ([92m↓13.20%[0m) [0.70% of initial]
[Iter 3930/20000] Loss: 0.0008007 (Best: 0.0004968 @iter3790) ([92m↓4.52%[0m) [0.32% of initial]
[Iter 2190/20000] Loss: 0.0020003 (Best: 0.0016368 @iter1996) ([91m↑13.57%[0m) [0.79% of initial]
[Iter 3940/20000] Loss: 0.0006555 (Best: 0.0004968 @iter3790) ([92m↓18.13%[0m) [0.26% of initial]
Iter:2199, L1 loss=0.001855, Total loss=0.001957, Time:64
[Iter 2200/20000] Loss: 0.0019865 (Best: 0.0016305 @iter2191) ([92m↓0.69%[0m) [0.79% of initial]
[Iter 3950/20000] Loss: 0.0007260 (Best: 0.0004968 @iter3790) ([91m↑10.76%[0m) [0.29% of initial]
[Iter 2210/20000] Loss: 0.0086622 (Best: 0.0016305 @iter2191) ([91m↑336.05%[0m) [3.44% of initial]
[Iter 3960/20000] Loss: 0.0007556 (Best: 0.0004968 @iter3790) ([91m↑4.07%[0m) [0.30% of initial]
[Iter 2220/20000] Loss: 0.0050995 (Best: 0.0016305 @iter2191) ([92m↓41.13%[0m) [2.03% of initial]
[Iter 3970/20000] Loss: 0.0006695 (Best: 0.0004968 @iter3790) ([92m↓11.39%[0m) [0.27% of initial]
[Iter 2230/20000] Loss: 0.0032265 (Best: 0.0016305 @iter2191) ([92m↓36.73%[0m) [1.28% of initial]
[Iter 3980/20000] Loss: 0.0008548 (Best: 0.0004968 @iter3790) ([91m↑27.67%[0m) [0.34% of initial]
[Iter 2240/20000] Loss: 0.0027689 (Best: 0.0016305 @iter2191) ([92m↓14.18%[0m) [1.10% of initial]
[Iter 3990/20000] Loss: 0.0007057 (Best: 0.0004968 @iter3790) ([92m↓17.44%[0m) [0.28% of initial]
[Iter 2250/20000] Loss: 0.0025959 (Best: 0.0016305 @iter2191) ([92m↓6.25%[0m) [1.03% of initial]
[Iter 2260/20000] Loss: 0.0021494 (Best: 0.0016305 @iter2191) ([92m↓17.20%[0m) [0.85% of initial]
Iter:3999, L1 loss=0.0008332, Total loss=0.0008057, Time:101
[Iter 4000/20000] Loss: 0.0007249 (Best: 0.0004968 @iter3790) ([91m↑2.72%[0m) [0.29% of initial]
[Iter 2270/20000] Loss: 0.0021690 (Best: 0.0016305 @iter2191) ([91m↑0.91%[0m) [0.86% of initial]
[Iter 4010/20000] Loss: 0.0853929 (Best: 0.0004968 @iter3790) ([91m↑11679.55%[0m) [33.93% of initial]
[Iter 2280/20000] Loss: 0.0018239 (Best: 0.0016305 @iter2191) ([92m↓15.91%[0m) [0.72% of initial]
[Iter 2290/20000] Loss: 0.0017532 (Best: 0.0015166 @iter2287) ([92m↓3.88%[0m) [0.70% of initial]
[Iter 4020/20000] Loss: 0.0184014 (Best: 0.0004968 @iter3790) ([92m↓78.45%[0m) [7.31% of initial]
Iter:2299, L1 loss=0.001591, Total loss=0.00171, Time:59
[Iter 2300/20000] Loss: 0.0020199 (Best: 0.0015166 @iter2287) ([91m↑15.21%[0m) [0.80% of initial]
[Iter 4030/20000] Loss: 0.0079936 (Best: 0.0004968 @iter3790) ([92m↓56.56%[0m) [3.18% of initial]
[Iter 2310/20000] Loss: 0.0019052 (Best: 0.0015166 @iter2287) ([92m↓5.68%[0m) [0.76% of initial]
[Iter 4040/20000] Loss: 0.0043286 (Best: 0.0004968 @iter3790) ([92m↓45.85%[0m) [1.72% of initial]
[Iter 2320/20000] Loss: 0.0016353 (Best: 0.0014804 @iter2320) ([92m↓14.17%[0m) [0.65% of initial]
[Iter 4050/20000] Loss: 0.0028378 (Best: 0.0004968 @iter3790) ([92m↓34.44%[0m) [1.13% of initial]
[Iter 2330/20000] Loss: 0.0016552 (Best: 0.0014572 @iter2327) ([91m↑1.21%[0m) [0.66% of initial]
[Iter 4060/20000] Loss: 0.0019373 (Best: 0.0004968 @iter3790) ([92m↓31.73%[0m) [0.77% of initial]
[Iter 2340/20000] Loss: 0.0016972 (Best: 0.0014271 @iter2338) ([91m↑2.54%[0m) [0.67% of initial]
[Iter 2350/20000] Loss: 0.0017791 (Best: 0.0014271 @iter2338) ([91m↑4.82%[0m) [0.71% of initial]
[Iter 4070/20000] Loss: 0.0015319 (Best: 0.0004968 @iter3790) ([92m↓20.93%[0m) [0.61% of initial]
[Iter 2360/20000] Loss: 0.0015877 (Best: 0.0013927 @iter2359) ([92m↓10.76%[0m) [0.63% of initial]
[Iter 4080/20000] Loss: 0.0014440 (Best: 0.0004968 @iter3790) ([92m↓5.73%[0m) [0.57% of initial]
[Iter 2370/20000] Loss: 0.0017091 (Best: 0.0013927 @iter2359) ([91m↑7.65%[0m) [0.68% of initial]
[Iter 4090/20000] Loss: 0.0011410 (Best: 0.0004968 @iter3790) ([92m↓20.98%[0m) [0.45% of initial]
[Iter 2380/20000] Loss: 0.0018315 (Best: 0.0013927 @iter2359) ([91m↑7.17%[0m) [0.73% of initial]
Iter:4099, L1 loss=0.0009721, Total loss=0.0009421, Time:97
[Iter 4100/20000] Loss: 0.0009787 (Best: 0.0004968 @iter3790) ([92m↓14.23%[0m) [0.39% of initial]
[Iter 2390/20000] Loss: 0.0019339 (Best: 0.0013927 @iter2359) ([91m↑5.59%[0m) [0.77% of initial]
[Iter 4110/20000] Loss: 0.0010752 (Best: 0.0004968 @iter3790) ([91m↑9.87%[0m) [0.43% of initial]
Iter:2399, L1 loss=0.001463, Total loss=0.001598, Time:45
[Iter 2400/20000] Loss: 0.0016976 (Best: 0.0013927 @iter2359) ([92m↓12.22%[0m) [0.67% of initial]
[Iter 4120/20000] Loss: 0.0010005 (Best: 0.0004968 @iter3790) ([92m↓6.95%[0m) [0.40% of initial]
[Iter 2410/20000] Loss: 0.0069113 (Best: 0.0013927 @iter2359) ([91m↑307.11%[0m) [2.75% of initial]
[Iter 4130/20000] Loss: 0.0011417 (Best: 0.0004968 @iter3790) ([91m↑14.11%[0m) [0.45% of initial]
[Iter 2420/20000] Loss: 0.0040517 (Best: 0.0013927 @iter2359) ([92m↓41.38%[0m) [1.61% of initial]
[Iter 4140/20000] Loss: 0.0010259 (Best: 0.0004968 @iter3790) ([92m↓10.14%[0m) [0.41% of initial]
[Iter 2430/20000] Loss: 0.0029002 (Best: 0.0013927 @iter2359) ([92m↓28.42%[0m) [1.15% of initial]
[Iter 2440/20000] Loss: 0.0023226 (Best: 0.0013927 @iter2359) ([92m↓19.91%[0m) [0.92% of initial]
[Iter 4150/20000] Loss: 0.0008865 (Best: 0.0004968 @iter3790) ([92m↓13.59%[0m) [0.35% of initial]
[Iter 2450/20000] Loss: 0.0022015 (Best: 0.0013927 @iter2359) ([92m↓5.21%[0m) [0.87% of initial]
[Iter 4160/20000] Loss: 0.0009846 (Best: 0.0004968 @iter3790) ([91m↑11.07%[0m) [0.39% of initial]
[Iter 2460/20000] Loss: 0.0019461 (Best: 0.0013927 @iter2359) ([92m↓11.60%[0m) [0.77% of initial]
[Iter 4170/20000] Loss: 0.0008746 (Best: 0.0004968 @iter3790) ([92m↓11.18%[0m) [0.35% of initial]
[Iter 2470/20000] Loss: 0.0018529 (Best: 0.0013927 @iter2359) ([92m↓4.79%[0m) [0.74% of initial]
[Iter 4180/20000] Loss: 0.0008953 (Best: 0.0004968 @iter3790) ([91m↑2.38%[0m) [0.36% of initial]
[Iter 2480/20000] Loss: 0.0019162 (Best: 0.0013927 @iter2359) ([91m↑3.41%[0m) [0.76% of initial]
[Iter 4190/20000] Loss: 0.0008528 (Best: 0.0004968 @iter3790) ([92m↓4.75%[0m) [0.34% of initial]
[Iter 2490/20000] Loss: 0.0017140 (Best: 0.0013927 @iter2359) ([92m↓10.56%[0m) [0.68% of initial]
Iter:2499, L1 loss=0.001401, Total loss=0.001475, Time:63
Iter:4199, L1 loss=0.0007974, Total loss=0.0007516, Time:97
[Iter 2500/20000] Loss: 0.0015395 (Best: 0.0013927 @iter2359) ([92m↓10.18%[0m) [0.61% of initial]
[Iter 4200/20000] Loss: 0.0008506 (Best: 0.0004968 @iter3790) ([92m↓0.27%[0m) [0.34% of initial]
Pruning 451 points (0.5%) from gaussian0 at iteration 2500
Pruning 500 points (0.6%) from gaussian1 at iteration 2500
[Iter 4210/20000] Loss: 0.0032367 (Best: 0.0004968 @iter3790) ([91m↑280.54%[0m) [1.29% of initial]
[Iter 2510/20000] Loss: 0.0035877 (Best: 0.0013927 @iter2359) ([91m↑133.05%[0m) [1.43% of initial]
[Iter 2520/20000] Loss: 0.0023128 (Best: 0.0013927 @iter2359) ([92m↓35.54%[0m) [0.92% of initial]
[Iter 4220/20000] Loss: 0.0017612 (Best: 0.0004968 @iter3790) ([92m↓45.59%[0m) [0.70% of initial]
[Iter 2530/20000] Loss: 0.0017066 (Best: 0.0013927 @iter2359) ([92m↓26.21%[0m) [0.68% of initial]
[Iter 4230/20000] Loss: 0.0012475 (Best: 0.0004968 @iter3790) ([92m↓29.17%[0m) [0.50% of initial]
[Iter 2540/20000] Loss: 0.0015546 (Best: 0.0013927 @iter2359) ([92m↓8.91%[0m) [0.62% of initial]
[Iter 4240/20000] Loss: 0.0009905 (Best: 0.0004968 @iter3790) ([92m↓20.60%[0m) [0.39% of initial]
[Iter 2550/20000] Loss: 0.0016034 (Best: 0.0012555 @iter2548) ([91m↑3.14%[0m) [0.64% of initial]
[Iter 4250/20000] Loss: 0.0009327 (Best: 0.0004968 @iter3790) ([92m↓5.84%[0m) [0.37% of initial]
[Iter 2560/20000] Loss: 0.0013714 (Best: 0.0012109 @iter2558) ([92m↓14.47%[0m) [0.54% of initial]
[Iter 4260/20000] Loss: 0.0009946 (Best: 0.0004968 @iter3790) ([91m↑6.63%[0m) [0.40% of initial]
[Iter 2570/20000] Loss: 0.0015738 (Best: 0.0012109 @iter2558) ([91m↑14.76%[0m) [0.63% of initial]
[Iter 2580/20000] Loss: 0.0014266 (Best: 0.0011273 @iter2578) ([92m↓9.35%[0m) [0.57% of initial]
[Iter 4270/20000] Loss: 0.0009061 (Best: 0.0004968 @iter3790) ([92m↓8.89%[0m) [0.36% of initial]
[Iter 2590/20000] Loss: 0.0015252 (Best: 0.0011273 @iter2578) ([91m↑6.91%[0m) [0.61% of initial]
[Iter 4280/20000] Loss: 0.0007080 (Best: 0.0004968 @iter3790) ([92m↓21.87%[0m) [0.28% of initial]
Iter:2599, L1 loss=0.00121, Total loss=0.001245, Time:57
[Iter 2600/20000] Loss: 0.0014143 (Best: 0.0011273 @iter2578) ([92m↓7.27%[0m) [0.56% of initial]
[Iter 4290/20000] Loss: 0.0007038 (Best: 0.0004968 @iter3790) ([92m↓0.60%[0m) [0.28% of initial]
[Iter 2610/20000] Loss: 0.0067817 (Best: 0.0011273 @iter2578) ([91m↑379.50%[0m) [2.69% of initial]
Iter:4299, L1 loss=0.000835, Total loss=0.0007979, Time:92
[Iter 4300/20000] Loss: 0.0006887 (Best: 0.0004968 @iter3790) ([92m↓2.14%[0m) [0.27% of initial]
[Iter 2620/20000] Loss: 0.0038623 (Best: 0.0011273 @iter2578) ([92m↓43.05%[0m) [1.53% of initial]
[Iter 4310/20000] Loss: 0.0006475 (Best: 0.0004968 @iter3790) ([92m↓5.99%[0m) [0.26% of initial]
[Iter 2630/20000] Loss: 0.0024949 (Best: 0.0011273 @iter2578) ([92m↓35.40%[0m) [0.99% of initial]
[Iter 4320/20000] Loss: 0.0007903 (Best: 0.0004968 @iter3790) ([91m↑22.06%[0m) [0.31% of initial]
[Iter 2640/20000] Loss: 0.0020416 (Best: 0.0011273 @iter2578) ([92m↓18.17%[0m) [0.81% of initial]
[Iter 4330/20000] Loss: 0.0006645 (Best: 0.0004968 @iter3790) ([92m↓15.92%[0m) [0.26% of initial]
[Iter 2650/20000] Loss: 0.0016536 (Best: 0.0011273 @iter2578) ([92m↓19.01%[0m) [0.66% of initial]
[Iter 2660/20000] Loss: 0.0018722 (Best: 0.0011273 @iter2578) ([91m↑13.22%[0m) [0.74% of initial]
[Iter 4340/20000] Loss: 0.0006349 (Best: 0.0004968 @iter3790) ([92m↓4.46%[0m) [0.25% of initial]
[Iter 2670/20000] Loss: 0.0020070 (Best: 0.0011273 @iter2578) ([91m↑7.20%[0m) [0.80% of initial]
[Iter 4350/20000] Loss: 0.0006245 (Best: 0.0004968 @iter3790) ([92m↓1.63%[0m) [0.25% of initial]
[Iter 2680/20000] Loss: 0.0014904 (Best: 0.0011273 @iter2578) ([92m↓25.74%[0m) [0.59% of initial]
[Iter 4360/20000] Loss: 0.0006221 (Best: 0.0004968 @iter3790) ([92m↓0.39%[0m) [0.25% of initial]
[Iter 2690/20000] Loss: 0.0014140 (Best: 0.0011273 @iter2578) ([92m↓5.12%[0m) [0.56% of initial]
[Iter 4370/20000] Loss: 0.0006229 (Best: 0.0004968 @iter3790) ([91m↑0.13%[0m) [0.25% of initial]
Iter:2699, L1 loss=0.001328, Total loss=0.001376, Time:55
[Iter 2700/20000] Loss: 0.0016854 (Best: 0.0011273 @iter2578) ([91m↑19.19%[0m) [0.67% of initial]
[Iter 4380/20000] Loss: 0.0006700 (Best: 0.0004968 @iter3790) ([91m↑7.57%[0m) [0.27% of initial]
[Iter 2710/20000] Loss: 0.0014221 (Best: 0.0011273 @iter2578) ([92m↓15.62%[0m) [0.56% of initial]
[Iter 2720/20000] Loss: 0.0012587 (Best: 0.0011273 @iter2578) ([92m↓11.49%[0m) [0.50% of initial]
[Iter 4390/20000] Loss: 0.0006120 (Best: 0.0004968 @iter3790) ([92m↓8.65%[0m) [0.24% of initial]
[Iter 2730/20000] Loss: 0.0012891 (Best: 0.0010802 @iter2724) ([91m↑2.41%[0m) [0.51% of initial]
Iter:4399, L1 loss=0.0005954, Total loss=0.0005329, Time:97
[Iter 4400/20000] Loss: 0.0005961 (Best: 0.0004968 @iter3790) ([92m↓2.60%[0m) [0.24% of initial]
[Iter 2740/20000] Loss: 0.0010692 (Best: 0.0009715 @iter2740) ([92m↓17.06%[0m) [0.42% of initial]
[Iter 4410/20000] Loss: 0.0030136 (Best: 0.0004968 @iter3790) ([91m↑405.54%[0m) [1.20% of initial]
[Iter 2750/20000] Loss: 0.0013151 (Best: 0.0009715 @iter2740) ([91m↑23.00%[0m) [0.52% of initial]
[Iter 2760/20000] Loss: 0.0014477 (Best: 0.0009715 @iter2740) ([91m↑10.08%[0m) [0.58% of initial]
[Iter 4420/20000] Loss: 0.0014928 (Best: 0.0004968 @iter3790) ([92m↓50.46%[0m) [0.59% of initial]
[Iter 2770/20000] Loss: 0.0015592 (Best: 0.0009715 @iter2740) ([91m↑7.70%[0m) [0.62% of initial]
[Iter 4430/20000] Loss: 0.0010887 (Best: 0.0004968 @iter3790) ([92m↓27.07%[0m) [0.43% of initial]
[Iter 2780/20000] Loss: 0.0012882 (Best: 0.0009715 @iter2740) ([92m↓17.38%[0m) [0.51% of initial]
[Iter 4440/20000] Loss: 0.0008391 (Best: 0.0004968 @iter3790) ([92m↓22.93%[0m) [0.33% of initial]
[Iter 2790/20000] Loss: 0.0013060 (Best: 0.0009685 @iter2782) ([91m↑1.39%[0m) [0.52% of initial]
[Iter 4450/20000] Loss: 0.0007305 (Best: 0.0004968 @iter3790) ([92m↓12.95%[0m) [0.29% of initial]
Iter:2799, L1 loss=0.001395, Total loss=0.001471, Time:73
[Iter 2800/20000] Loss: 0.0013053 (Best: 0.0009685 @iter2782) ([92m↓0.06%[0m) [0.52% of initial]
[Iter 4460/20000] Loss: 0.0006724 (Best: 0.0004968 @iter3790) ([92m↓7.95%[0m) [0.27% of initial]
[Iter 2810/20000] Loss: 0.0057216 (Best: 0.0009685 @iter2782) ([91m↑338.34%[0m) [2.27% of initial]
[Iter 4470/20000] Loss: 0.0007152 (Best: 0.0004968 @iter3790) ([91m↑6.36%[0m) [0.28% of initial]
[Iter 2820/20000] Loss: 0.0030505 (Best: 0.0009685 @iter2782) ([92m↓46.69%[0m) [1.21% of initial]
[Iter 4480/20000] Loss: 0.0006782 (Best: 0.0004968 @iter3790) ([92m↓5.18%[0m) [0.27% of initial]
[Iter 2830/20000] Loss: 0.0019607 (Best: 0.0009685 @iter2782) ([92m↓35.72%[0m) [0.78% of initial]
[Iter 4490/20000] Loss: 0.0006658 (Best: 0.0004968 @iter3790) ([92m↓1.83%[0m) [0.26% of initial]
[Iter 2840/20000] Loss: 0.0016898 (Best: 0.0009685 @iter2782) ([92m↓13.82%[0m) [0.67% of initial]
Iter:4499, L1 loss=0.0007923, Total loss=0.0007192, Time:98
[Iter 4500/20000] Loss: 0.0007551 (Best: 0.0004968 @iter3790) ([91m↑13.43%[0m) [0.30% of initial]
[Iter 2850/20000] Loss: 0.0014631 (Best: 0.0009685 @iter2782) ([92m↓13.41%[0m) [0.58% of initial]
[Iter 2860/20000] Loss: 0.0015751 (Best: 0.0009685 @iter2782) ([91m↑7.65%[0m) [0.63% of initial]
[Iter 4510/20000] Loss: 0.0005737 (Best: 0.0004968 @iter3790) ([92m↓24.02%[0m) [0.23% of initial]
[Iter 2870/20000] Loss: 0.0013520 (Best: 0.0009685 @iter2782) ([92m↓14.16%[0m) [0.54% of initial]
[Iter 4520/20000] Loss: 0.0005799 (Best: 0.0004968 @iter3790) ([91m↑1.08%[0m) [0.23% of initial]
[Iter 2880/20000] Loss: 0.0013197 (Best: 0.0009685 @iter2782) ([92m↓2.39%[0m) [0.52% of initial]
[Iter 4530/20000] Loss: 0.0006493 (Best: 0.0004968 @iter3790) ([91m↑11.96%[0m) [0.26% of initial]
[Iter 2890/20000] Loss: 0.0012294 (Best: 0.0009685 @iter2782) ([92m↓6.84%[0m) [0.49% of initial]
[Iter 4540/20000] Loss: 0.0005826 (Best: 0.0004968 @iter3790) ([92m↓10.27%[0m) [0.23% of initial]
Iter:2899, L1 loss=0.0009828, Total loss=0.000979, Time:78
[Iter 2900/20000] Loss: 0.0011842 (Best: 0.0009685 @iter2782) ([92m↓3.68%[0m) [0.47% of initial]
[Iter 4550/20000] Loss: 0.0006094 (Best: 0.0004878 @iter4546) ([91m↑4.61%[0m) [0.24% of initial]
[Iter 2910/20000] Loss: 0.0013384 (Best: 0.0009685 @iter2782) ([91m↑13.02%[0m) [0.53% of initial]
[Iter 4560/20000] Loss: 0.0006549 (Best: 0.0004878 @iter4546) ([91m↑7.46%[0m) [0.26% of initial]
[Iter 2920/20000] Loss: 0.0013987 (Best: 0.0009685 @iter2782) ([91m↑4.51%[0m) [0.56% of initial]
[Iter 4570/20000] Loss: 0.0005786 (Best: 0.0004878 @iter4546) ([92m↓11.64%[0m) [0.23% of initial]
[Iter 2930/20000] Loss: 0.0013135 (Best: 0.0009685 @iter2782) ([92m↓6.10%[0m) [0.52% of initial]
[Iter 2940/20000] Loss: 0.0011390 (Best: 0.0009685 @iter2782) ([92m↓13.29%[0m) [0.45% of initial]
[Iter 4580/20000] Loss: 0.0005688 (Best: 0.0004878 @iter4546) ([92m↓1.70%[0m) [0.23% of initial]
[Iter 2950/20000] Loss: 0.0010520 (Best: 0.0008985 @iter2950) ([92m↓7.63%[0m) [0.42% of initial]
[Iter 4590/20000] Loss: 0.0006193 (Best: 0.0004878 @iter4546) ([91m↑8.88%[0m) [0.25% of initial]
[Iter 2960/20000] Loss: 0.0011552 (Best: 0.0008985 @iter2950) ([91m↑9.81%[0m) [0.46% of initial]
Iter:4599, L1 loss=0.00068, Total loss=0.000599, Time:121
[Iter 4600/20000] Loss: 0.0005983 (Best: 0.0004878 @iter4546) ([92m↓3.38%[0m) [0.24% of initial]
[Iter 2970/20000] Loss: 0.0010143 (Best: 0.0008273 @iter2969) ([92m↓12.19%[0m) [0.40% of initial]
[Iter 4610/20000] Loss: 0.0025692 (Best: 0.0004878 @iter4546) ([91m↑329.39%[0m) [1.02% of initial]
[Iter 2980/20000] Loss: 0.0009494 (Best: 0.0008273 @iter2969) ([92m↓6.40%[0m) [0.38% of initial]
[Iter 2990/20000] Loss: 0.0009901 (Best: 0.0007811 @iter2983) ([91m↑4.29%[0m) [0.39% of initial]
[Iter 4620/20000] Loss: 0.0014409 (Best: 0.0004878 @iter4546) ([92m↓43.92%[0m) [0.57% of initial]
Iter:2999, L1 loss=0.0008038, Total loss=0.000772, Time:79
[Iter 3000/20000] Loss: 0.0009672 (Best: 0.0007720 @iter2999) ([92m↓2.31%[0m) [0.38% of initial]
[Iter 4630/20000] Loss: 0.0009972 (Best: 0.0004878 @iter4546) ([92m↓30.80%[0m) [0.40% of initial]
Pruning 429 points (0.4%) from gaussian0 at iteration 3000
Pruning 502 points (0.4%) from gaussian1 at iteration 3000
[Iter 4640/20000] Loss: 0.0008076 (Best: 0.0004878 @iter4546) ([92m↓19.01%[0m) [0.32% of initial]
[Iter 3010/20000] Loss: 0.0056924 (Best: 0.0007720 @iter2999) ([91m↑488.52%[0m) [2.26% of initial]
[Iter 4650/20000] Loss: 0.0006861 (Best: 0.0004878 @iter4546) ([92m↓15.05%[0m) [0.27% of initial]
[Iter 3020/20000] Loss: 0.0034971 (Best: 0.0007720 @iter2999) ([92m↓38.57%[0m) [1.39% of initial]
[Iter 4660/20000] Loss: 0.0005828 (Best: 0.0004878 @iter4546) ([92m↓15.06%[0m) [0.23% of initial]
[Iter 3030/20000] Loss: 0.0024548 (Best: 0.0007720 @iter2999) ([92m↓29.80%[0m) [0.98% of initial]
[Iter 4670/20000] Loss: 0.0005564 (Best: 0.0004878 @iter4546) ([92m↓4.52%[0m) [0.22% of initial]
[Iter 3040/20000] Loss: 0.0019079 (Best: 0.0007720 @iter2999) ([92m↓22.28%[0m) [0.76% of initial]
[Iter 4680/20000] Loss: 0.0005459 (Best: 0.0004747 @iter4672) ([92m↓1.88%[0m) [0.22% of initial]
[Iter 3050/20000] Loss: 0.0016996 (Best: 0.0007720 @iter2999) ([92m↓10.91%[0m) [0.68% of initial]
[Iter 3060/20000] Loss: 0.0016107 (Best: 0.0007720 @iter2999) ([92m↓5.23%[0m) [0.64% of initial]
[Iter 4690/20000] Loss: 0.0005142 (Best: 0.0004714 @iter4681) ([92m↓5.82%[0m) [0.20% of initial]
[Iter 3070/20000] Loss: 0.0016234 (Best: 0.0007720 @iter2999) ([91m↑0.79%[0m) [0.64% of initial]
Iter:4699, L1 loss=0.0006356, Total loss=0.0005703, Time:98
[Iter 4700/20000] Loss: 0.0005893 (Best: 0.0004714 @iter4681) ([91m↑14.61%[0m) [0.23% of initial]
[Iter 3080/20000] Loss: 0.0014275 (Best: 0.0007720 @iter2999) ([92m↓12.07%[0m) [0.57% of initial]
[Iter 4710/20000] Loss: 0.0005192 (Best: 0.0004714 @iter4681) ([92m↓11.89%[0m) [0.21% of initial]
[Iter 3090/20000] Loss: 0.0013609 (Best: 0.0007720 @iter2999) ([92m↓4.67%[0m) [0.54% of initial]
[Iter 4720/20000] Loss: 0.0005806 (Best: 0.0004391 @iter4711) ([91m↑11.83%[0m) [0.23% of initial]
Iter:3099, L1 loss=0.001159, Total loss=0.001135, Time:93
[Iter 3100/20000] Loss: 0.0012456 (Best: 0.0007720 @iter2999) ([92m↓8.47%[0m) [0.49% of initial]
[Iter 4730/20000] Loss: 0.0005547 (Best: 0.0004391 @iter4711) ([92m↓4.47%[0m) [0.22% of initial]
[Iter 3110/20000] Loss: 0.0013883 (Best: 0.0007720 @iter2999) ([91m↑11.46%[0m) [0.55% of initial]
[Iter 4740/20000] Loss: 0.0006088 (Best: 0.0004391 @iter4711) ([91m↑9.76%[0m) [0.24% of initial]
[Iter 3120/20000] Loss: 0.0013300 (Best: 0.0007720 @iter2999) ([92m↓4.20%[0m) [0.53% of initial]
[Iter 4750/20000] Loss: 0.0005799 (Best: 0.0004391 @iter4711) ([92m↓4.76%[0m) [0.23% of initial]
[Iter 3130/20000] Loss: 0.0011236 (Best: 0.0007720 @iter2999) ([92m↓15.52%[0m) [0.45% of initial]
[Iter 3140/20000] Loss: 0.0010575 (Best: 0.0007720 @iter2999) ([92m↓5.88%[0m) [0.42% of initial]
[Iter 4760/20000] Loss: 0.0005196 (Best: 0.0004391 @iter4711) ([92m↓10.40%[0m) [0.21% of initial]
[Iter 3150/20000] Loss: 0.0011142 (Best: 0.0007720 @iter2999) ([91m↑5.36%[0m) [0.44% of initial]
[Iter 4770/20000] Loss: 0.0005739 (Best: 0.0004391 @iter4711) ([91m↑10.45%[0m) [0.23% of initial]
[Iter 3160/20000] Loss: 0.0010442 (Best: 0.0007720 @iter2999) ([92m↓6.28%[0m) [0.41% of initial]
[Iter 4780/20000] Loss: 0.0006041 (Best: 0.0004391 @iter4711) ([91m↑5.28%[0m) [0.24% of initial]
[Iter 3170/20000] Loss: 0.0010443 (Best: 0.0007720 @iter2999) ([91m↑0.01%[0m) [0.41% of initial]
[Iter 4790/20000] Loss: 0.0005433 (Best: 0.0004391 @iter4711) ([92m↓10.07%[0m) [0.22% of initial]
[Iter 3180/20000] Loss: 0.0011314 (Best: 0.0007720 @iter2999) ([91m↑8.34%[0m) [0.45% of initial]
Iter:4799, L1 loss=0.0006041, Total loss=0.0005375, Time:96
[Iter 4800/20000] Loss: 0.0006125 (Best: 0.0004391 @iter4711) ([91m↑12.74%[0m) [0.24% of initial]
[Iter 3190/20000] Loss: 0.0011047 (Best: 0.0007720 @iter2999) ([92m↓2.36%[0m) [0.44% of initial]
Iter:3199, L1 loss=0.0009935, Total loss=0.0009946, Time:72
[Iter 3200/20000] Loss: 0.0010396 (Best: 0.0007720 @iter2999) ([92m↓5.90%[0m) [0.41% of initial]
[Iter 4810/20000] Loss: 0.0022225 (Best: 0.0004391 @iter4711) ([91m↑262.84%[0m) [0.88% of initial]
[Iter 4820/20000] Loss: 0.0012857 (Best: 0.0004391 @iter4711) ([92m↓42.15%[0m) [0.51% of initial]
[Iter 3210/20000] Loss: 0.0056182 (Best: 0.0007720 @iter2999) ([91m↑440.44%[0m) [2.23% of initial]
[Iter 4830/20000] Loss: 0.0009851 (Best: 0.0004391 @iter4711) ([92m↓23.38%[0m) [0.39% of initial]
[Iter 3220/20000] Loss: 0.0032437 (Best: 0.0007720 @iter2999) ([92m↓42.26%[0m) [1.29% of initial]
[Iter 3230/20000] Loss: 0.0020315 (Best: 0.0007720 @iter2999) ([92m↓37.37%[0m) [0.81% of initial]
[Iter 4840/20000] Loss: 0.0007223 (Best: 0.0004391 @iter4711) ([92m↓26.68%[0m) [0.29% of initial]
[Iter 3240/20000] Loss: 0.0017950 (Best: 0.0007720 @iter2999) ([92m↓11.64%[0m) [0.71% of initial]
[Iter 4850/20000] Loss: 0.0005703 (Best: 0.0004391 @iter4711) ([92m↓21.04%[0m) [0.23% of initial]
[Iter 3250/20000] Loss: 0.0013636 (Best: 0.0007720 @iter2999) ([92m↓24.04%[0m) [0.54% of initial]
[Iter 4860/20000] Loss: 0.0005772 (Best: 0.0004391 @iter4711) ([91m↑1.21%[0m) [0.23% of initial]
[Iter 3260/20000] Loss: 0.0012420 (Best: 0.0007720 @iter2999) ([92m↓8.91%[0m) [0.49% of initial]
[Iter 4870/20000] Loss: 0.0005142 (Best: 0.0004391 @iter4711) ([92m↓10.92%[0m) [0.20% of initial]
[Iter 3270/20000] Loss: 0.0012684 (Best: 0.0007720 @iter2999) ([91m↑2.12%[0m) [0.50% of initial]
[Iter 4880/20000] Loss: 0.0005540 (Best: 0.0004391 @iter4711) ([91m↑7.74%[0m) [0.22% of initial]
[Iter 3280/20000] Loss: 0.0013105 (Best: 0.0007720 @iter2999) ([91m↑3.32%[0m) [0.52% of initial]
[Iter 4890/20000] Loss: 0.0005059 (Best: 0.0004391 @iter4711) ([92m↓8.68%[0m) [0.20% of initial]
[Iter 3290/20000] Loss: 0.0009899 (Best: 0.0007720 @iter2999) ([92m↓24.47%[0m) [0.39% of initial]
Iter:4899, L1 loss=0.0006394, Total loss=0.0005902, Time:102
[Iter 4900/20000] Loss: 0.0005057 (Best: 0.0004279 @iter4892) ([92m↓0.04%[0m) [0.20% of initial]
Iter:3299, L1 loss=0.00143, Total loss=0.001559, Time:84
[Iter 3300/20000] Loss: 0.0013244 (Best: 0.0007720 @iter2999) ([91m↑33.79%[0m) [0.53% of initial]
[Iter 4910/20000] Loss: 0.0006433 (Best: 0.0004279 @iter4892) ([91m↑27.21%[0m) [0.26% of initial]
[Iter 3310/20000] Loss: 0.0009956 (Best: 0.0007720 @iter2999) ([92m↓24.82%[0m) [0.40% of initial]
[Iter 3320/20000] Loss: 0.0011396 (Best: 0.0007720 @iter2999) ([91m↑14.46%[0m) [0.45% of initial]
[Iter 4920/20000] Loss: 0.0005543 (Best: 0.0004279 @iter4892) ([92m↓13.84%[0m) [0.22% of initial]
[Iter 3330/20000] Loss: 0.0012391 (Best: 0.0007720 @iter2999) ([91m↑8.73%[0m) [0.49% of initial]
[Iter 4930/20000] Loss: 0.0004958 (Best: 0.0004279 @iter4892) ([92m↓10.56%[0m) [0.20% of initial]
[Iter 3340/20000] Loss: 0.0013434 (Best: 0.0007720 @iter2999) ([91m↑8.42%[0m) [0.53% of initial]
[Iter 4940/20000] Loss: 0.0005144 (Best: 0.0004279 @iter4892) ([91m↑3.76%[0m) [0.20% of initial]
[Iter 3350/20000] Loss: 0.0010906 (Best: 0.0007720 @iter2999) ([92m↓18.82%[0m) [0.43% of initial]
[Iter 4950/20000] Loss: 0.0004491 (Best: 0.0004023 @iter4949) ([92m↓12.69%[0m) [0.18% of initial]
[Iter 3360/20000] Loss: 0.0013330 (Best: 0.0007720 @iter2999) ([91m↑22.23%[0m) [0.53% of initial]
[Iter 4960/20000] Loss: 0.0004801 (Best: 0.0003948 @iter4957) ([91m↑6.90%[0m) [0.19% of initial]
[Iter 3370/20000] Loss: 0.0009666 (Best: 0.0007720 @iter2999) ([92m↓27.49%[0m) [0.38% of initial]
[Iter 4970/20000] Loss: 0.0005090 (Best: 0.0003948 @iter4957) ([91m↑6.02%[0m) [0.20% of initial]
[Iter 3380/20000] Loss: 0.0009282 (Best: 0.0007720 @iter2999) ([92m↓3.97%[0m) [0.37% of initial]
[Iter 4980/20000] Loss: 0.0005065 (Best: 0.0003948 @iter4957) ([92m↓0.50%[0m) [0.20% of initial]
[Iter 3390/20000] Loss: 0.0012527 (Best: 0.0007720 @iter2999) ([91m↑34.96%[0m) [0.50% of initial]
Iter:3399, L1 loss=0.001434, Total loss=0.001572, Time:88
[Iter 3400/20000] Loss: 0.0013271 (Best: 0.0007720 @iter2999) ([91m↑5.94%[0m) [0.53% of initial]
[Iter 4990/20000] Loss: 0.0004699 (Best: 0.0003948 @iter4957) ([92m↓7.21%[0m) [0.19% of initial]
Iter:4999, L1 loss=0.0005122, Total loss=0.000442, Time:93
[Iter 5000/20000] Loss: 0.0004482 (Best: 0.0003948 @iter4957) ([92m↓4.63%[0m) [0.18% of initial]
[Iter 3410/20000] Loss: 0.0048987 (Best: 0.0007720 @iter2999) ([91m↑269.14%[0m) [1.95% of initial]
[Iter 3420/20000] Loss: 0.0025989 (Best: 0.0007720 @iter2999) ([92m↓46.95%[0m) [1.03% of initial]
[Iter 5010/20000] Loss: 0.0020521 (Best: 0.0003948 @iter4957) ([91m↑357.87%[0m) [0.82% of initial]
[Iter 3430/20000] Loss: 0.0016685 (Best: 0.0007720 @iter2999) ([92m↓35.80%[0m) [0.66% of initial]
[Iter 5020/20000] Loss: 0.0012334 (Best: 0.0003948 @iter4957) ([92m↓39.90%[0m) [0.49% of initial]
[Iter 3440/20000] Loss: 0.0014869 (Best: 0.0007720 @iter2999) ([92m↓10.89%[0m) [0.59% of initial]
[Iter 5030/20000] Loss: 0.0007892 (Best: 0.0003948 @iter4957) ([92m↓36.02%[0m) [0.31% of initial]
[Iter 3450/20000] Loss: 0.0014279 (Best: 0.0007720 @iter2999) ([92m↓3.97%[0m) [0.57% of initial]
[Iter 5040/20000] Loss: 0.0007750 (Best: 0.0003948 @iter4957) ([92m↓1.79%[0m) [0.31% of initial]
[Iter 3460/20000] Loss: 0.0012743 (Best: 0.0007720 @iter2999) ([92m↓10.75%[0m) [0.51% of initial]
[Iter 5050/20000] Loss: 0.0006716 (Best: 0.0003948 @iter4957) ([92m↓13.35%[0m) [0.27% of initial]
[Iter 3470/20000] Loss: 0.0012030 (Best: 0.0007720 @iter2999) ([92m↓5.60%[0m) [0.48% of initial]
[Iter 5060/20000] Loss: 0.0005098 (Best: 0.0003948 @iter4957) ([92m↓24.09%[0m) [0.20% of initial]
[Iter 3480/20000] Loss: 0.0011728 (Best: 0.0007720 @iter2999) ([92m↓2.51%[0m) [0.47% of initial]
[Iter 5070/20000] Loss: 0.0006331 (Best: 0.0003948 @iter4957) ([91m↑24.17%[0m) [0.25% of initial]
[Iter 3490/20000] Loss: 0.0010458 (Best: 0.0007720 @iter2999) ([92m↓10.83%[0m) [0.42% of initial]
[Iter 5080/20000] Loss: 0.0004965 (Best: 0.0003948 @iter4957) ([92m↓21.57%[0m) [0.20% of initial]
Iter:3499, L1 loss=0.000767, Total loss=0.0007597, Time:77
[Iter 3500/20000] Loss: 0.0008157 (Best: 0.0007597 @iter3499) ([92m↓22.00%[0m) [0.32% of initial]
Pruning 357 points (0.2%) from gaussian0 at iteration 3500
Pruning 332 points (0.2%) from gaussian1 at iteration 3500
[Iter 5090/20000] Loss: 0.0005175 (Best: 0.0003948 @iter4957) ([91m↑4.21%[0m) [0.21% of initial]
[Iter 3510/20000] Loss: 0.0025946 (Best: 0.0007597 @iter3499) ([91m↑218.08%[0m) [1.03% of initial]
Iter:5099, L1 loss=0.0005867, Total loss=0.0005159, Time:99
[Iter 5100/20000] Loss: 0.0005437 (Best: 0.0003948 @iter4957) ([91m↑5.07%[0m) [0.22% of initial]
[Iter 3520/20000] Loss: 0.0016119 (Best: 0.0007597 @iter3499) ([92m↓37.88%[0m) [0.64% of initial]
[Iter 5110/20000] Loss: 0.0005301 (Best: 0.0003948 @iter4957) ([92m↓2.50%[0m) [0.21% of initial]
[Iter 3530/20000] Loss: 0.0014066 (Best: 0.0007597 @iter3499) ([92m↓12.73%[0m) [0.56% of initial]
[Iter 5120/20000] Loss: 0.0005149 (Best: 0.0003948 @iter4957) ([92m↓2.86%[0m) [0.20% of initial]
[Iter 3540/20000] Loss: 0.0014391 (Best: 0.0007597 @iter3499) ([91m↑2.31%[0m) [0.57% of initial]
[Iter 5130/20000] Loss: 0.0005331 (Best: 0.0003948 @iter4957) ([91m↑3.53%[0m) [0.21% of initial]
[Iter 3550/20000] Loss: 0.0012718 (Best: 0.0007597 @iter3499) ([92m↓11.63%[0m) [0.51% of initial]
[Iter 5140/20000] Loss: 0.0004613 (Best: 0.0003948 @iter4957) ([92m↓13.47%[0m) [0.18% of initial]
[Iter 3560/20000] Loss: 0.0010854 (Best: 0.0007597 @iter3499) ([92m↓14.65%[0m) [0.43% of initial]
[Iter 5150/20000] Loss: 0.0004583 (Best: 0.0003948 @iter4957) ([92m↓0.64%[0m) [0.18% of initial]
[Iter 3570/20000] Loss: 0.0011431 (Best: 0.0007597 @iter3499) ([91m↑5.31%[0m) [0.45% of initial]
[Iter 5160/20000] Loss: 0.0004444 (Best: 0.0003833 @iter5158) ([92m↓3.05%[0m) [0.18% of initial]
[Iter 3580/20000] Loss: 0.0008855 (Best: 0.0007597 @iter3499) ([92m↓22.53%[0m) [0.35% of initial]
[Iter 3590/20000] Loss: 0.0008747 (Best: 0.0007597 @iter3499) ([92m↓1.22%[0m) [0.35% of initial]
[Iter 5170/20000] Loss: 0.0004853 (Best: 0.0003833 @iter5158) ([91m↑9.20%[0m) [0.19% of initial]
Iter:3599, L1 loss=0.0007698, Total loss=0.0007361, Time:92
[Iter 3600/20000] Loss: 0.0008405 (Best: 0.0007108 @iter3598) ([92m↓3.91%[0m) [0.33% of initial]
[Iter 5180/20000] Loss: 0.0004536 (Best: 0.0003833 @iter5158) ([92m↓6.53%[0m) [0.18% of initial]
[Iter 5190/20000] Loss: 0.0004551 (Best: 0.0003833 @iter5158) ([91m↑0.33%[0m) [0.18% of initial]
[Iter 3610/20000] Loss: 0.0046392 (Best: 0.0007108 @iter3598) ([91m↑451.95%[0m) [1.84% of initial]
Iter:5199, L1 loss=0.0005435, Total loss=0.0004788, Time:98
[Iter 5200/20000] Loss: 0.0004427 (Best: 0.0003833 @iter5158) ([92m↓2.71%[0m) [0.18% of initial]
[Iter 3620/20000] Loss: 0.0029001 (Best: 0.0007108 @iter3598) ([92m↓37.49%[0m) [1.15% of initial]
[Iter 3630/20000] Loss: 0.0018347 (Best: 0.0007108 @iter3598) ([92m↓36.74%[0m) [0.73% of initial]
[Iter 5210/20000] Loss: 0.0021859 (Best: 0.0003833 @iter5158) ([91m↑393.71%[0m) [0.87% of initial]
[Iter 3640/20000] Loss: 0.0013725 (Best: 0.0007108 @iter3598) ([92m↓25.19%[0m) [0.55% of initial]
[Iter 5220/20000] Loss: 0.0011744 (Best: 0.0003833 @iter5158) ([92m↓46.27%[0m) [0.47% of initial]
[Iter 3650/20000] Loss: 0.0013365 (Best: 0.0007108 @iter3598) ([92m↓2.62%[0m) [0.53% of initial]
[Iter 5230/20000] Loss: 0.0007908 (Best: 0.0003833 @iter5158) ([92m↓32.67%[0m) [0.31% of initial]
[Iter 3660/20000] Loss: 0.0011169 (Best: 0.0007108 @iter3598) ([92m↓16.43%[0m) [0.44% of initial]
[Iter 5240/20000] Loss: 0.0006148 (Best: 0.0003833 @iter5158) ([92m↓22.26%[0m) [0.24% of initial]
[Iter 3670/20000] Loss: 0.0009662 (Best: 0.0007108 @iter3598) ([92m↓13.50%[0m) [0.38% of initial]
[Iter 5250/20000] Loss: 0.0007525 (Best: 0.0003833 @iter5158) ([91m↑22.40%[0m) [0.30% of initial]
[Iter 3680/20000] Loss: 0.0012146 (Best: 0.0007108 @iter3598) ([91m↑25.71%[0m) [0.48% of initial]
[Iter 5260/20000] Loss: 0.0005882 (Best: 0.0003833 @iter5158) ([92m↓21.84%[0m) [0.23% of initial]
[Iter 3690/20000] Loss: 0.0014701 (Best: 0.0007108 @iter3598) ([91m↑21.04%[0m) [0.58% of initial]
Iter:3699, L1 loss=0.001174, Total loss=0.001237, Time:100
[Iter 5270/20000] Loss: 0.0005230 (Best: 0.0003833 @iter5158) ([92m↓11.07%[0m) [0.21% of initial]
[Iter 3700/20000] Loss: 0.0012584 (Best: 0.0007108 @iter3598) ([92m↓14.40%[0m) [0.50% of initial]
[Iter 5280/20000] Loss: 0.0005702 (Best: 0.0003833 @iter5158) ([91m↑9.01%[0m) [0.23% of initial]
[Iter 3710/20000] Loss: 0.0009768 (Best: 0.0007108 @iter3598) ([92m↓22.38%[0m) [0.39% of initial]
[Iter 5290/20000] Loss: 0.0005125 (Best: 0.0003833 @iter5158) ([92m↓10.11%[0m) [0.20% of initial]
[Iter 3720/20000] Loss: 0.0010675 (Best: 0.0007108 @iter3598) ([91m↑9.28%[0m) [0.42% of initial]
Iter:5299, L1 loss=0.000596, Total loss=0.0005364, Time:124
[Iter 3730/20000] Loss: 0.0009036 (Best: 0.0007108 @iter3598) ([92m↓15.36%[0m) [0.36% of initial]
[Iter 5300/20000] Loss: 0.0005857 (Best: 0.0003833 @iter5158) ([91m↑14.29%[0m) [0.23% of initial]
[Iter 3740/20000] Loss: 0.0009187 (Best: 0.0007108 @iter3598) ([91m↑1.67%[0m) [0.36% of initial]
[Iter 5310/20000] Loss: 0.0005594 (Best: 0.0003833 @iter5158) ([92m↓4.51%[0m) [0.22% of initial]
[Iter 3750/20000] Loss: 0.0009640 (Best: 0.0007108 @iter3598) ([91m↑4.94%[0m) [0.38% of initial]
[Iter 5320/20000] Loss: 0.0004977 (Best: 0.0003833 @iter5158) ([92m↓11.02%[0m) [0.20% of initial]
[Iter 3760/20000] Loss: 0.0009447 (Best: 0.0007108 @iter3598) ([92m↓2.01%[0m) [0.38% of initial]
[Iter 5330/20000] Loss: 0.0004335 (Best: 0.0003833 @iter5158) ([92m↓12.91%[0m) [0.17% of initial]
[Iter 3770/20000] Loss: 0.0009177 (Best: 0.0007108 @iter3598) ([92m↓2.86%[0m) [0.36% of initial]
[Iter 5340/20000] Loss: 0.0004639 (Best: 0.0003833 @iter5158) ([91m↑7.02%[0m) [0.18% of initial]
[Iter 3780/20000] Loss: 0.0008448 (Best: 0.0006661 @iter3775) ([92m↓7.94%[0m) [0.34% of initial]
[Iter 5350/20000] Loss: 0.0004912 (Best: 0.0003700 @iter5344) ([91m↑5.90%[0m) [0.20% of initial]
[Iter 3790/20000] Loss: 0.0006855 (Best: 0.0006064 @iter3790) ([92m↓18.85%[0m) [0.27% of initial]
[Iter 5360/20000] Loss: 0.0004725 (Best: 0.0003700 @iter5344) ([92m↓3.82%[0m) [0.19% of initial]
Iter:3799, L1 loss=0.0008819, Total loss=0.0008549, Time:110
[Iter 3800/20000] Loss: 0.0008471 (Best: 0.0006064 @iter3790) ([91m↑23.57%[0m) [0.34% of initial]
[Iter 5370/20000] Loss: 0.0004997 (Best: 0.0003700 @iter5344) ([91m↑5.77%[0m) [0.20% of initial]
[Iter 3810/20000] Loss: 0.0046422 (Best: 0.0006064 @iter3790) ([91m↑448.01%[0m) [1.84% of initial]
[Iter 5380/20000] Loss: 0.0004944 (Best: 0.0003700 @iter5344) ([92m↓1.06%[0m) [0.20% of initial]
[Iter 3820/20000] Loss: 0.0023494 (Best: 0.0006064 @iter3790) ([92m↓49.39%[0m) [0.93% of initial]
[Iter 5390/20000] Loss: 0.0005364 (Best: 0.0003700 @iter5344) ([91m↑8.48%[0m) [0.21% of initial]
[Iter 3830/20000] Loss: 0.0014207 (Best: 0.0006064 @iter3790) ([92m↓39.53%[0m) [0.56% of initial]
Iter:5399, L1 loss=0.000494, Total loss=0.0004482, Time:117
[Iter 5400/20000] Loss: 0.0004995 (Best: 0.0003700 @iter5344) ([92m↓6.87%[0m) [0.20% of initial]
[Iter 3840/20000] Loss: 0.0015502 (Best: 0.0006064 @iter3790) ([91m↑9.11%[0m) [0.62% of initial]
[Iter 5410/20000] Loss: 0.0018809 (Best: 0.0003700 @iter5344) ([91m↑276.54%[0m) [0.75% of initial]
[Iter 3850/20000] Loss: 0.0011875 (Best: 0.0006064 @iter3790) ([92m↓23.40%[0m) [0.47% of initial]
[Iter 5420/20000] Loss: 0.0012938 (Best: 0.0003700 @iter5344) ([92m↓31.21%[0m) [0.51% of initial]
[Iter 3860/20000] Loss: 0.0011405 (Best: 0.0006064 @iter3790) ([92m↓3.96%[0m) [0.45% of initial]
[Iter 3870/20000] Loss: 0.0008912 (Best: 0.0006064 @iter3790) ([92m↓21.86%[0m) [0.35% of initial]
[Iter 5430/20000] Loss: 0.0007422 (Best: 0.0003700 @iter5344) ([92m↓42.64%[0m) [0.29% of initial]
[Iter 3880/20000] Loss: 0.0009286 (Best: 0.0006064 @iter3790) ([91m↑4.20%[0m) [0.37% of initial]
[Iter 5440/20000] Loss: 0.0006456 (Best: 0.0003700 @iter5344) ([92m↓13.01%[0m) [0.26% of initial]
[Iter 3890/20000] Loss: 0.0007678 (Best: 0.0006064 @iter3790) ([92m↓17.31%[0m) [0.31% of initial]
[Iter 5450/20000] Loss: 0.0007457 (Best: 0.0003700 @iter5344) ([91m↑15.50%[0m) [0.30% of initial]
Iter:3899, L1 loss=0.0008556, Total loss=0.0008347, Time:103
[Iter 3900/20000] Loss: 0.0007781 (Best: 0.0006046 @iter3898) ([91m↑1.34%[0m) [0.31% of initial]
[Iter 5460/20000] Loss: 0.0005784 (Best: 0.0003700 @iter5344) ([92m↓22.42%[0m) [0.23% of initial]
[Iter 3910/20000] Loss: 0.0009613 (Best: 0.0006046 @iter3898) ([91m↑23.54%[0m) [0.38% of initial]
[Iter 5470/20000] Loss: 0.0004723 (Best: 0.0003700 @iter5344) ([92m↓18.35%[0m) [0.19% of initial]
[Iter 3920/20000] Loss: 0.0009615 (Best: 0.0006046 @iter3898) ([91m↑0.02%[0m) [0.38% of initial]
[Iter 5480/20000] Loss: 0.0004456 (Best: 0.0003700 @iter5344) ([92m↓5.66%[0m) [0.18% of initial]
[Iter 3930/20000] Loss: 0.0009596 (Best: 0.0006046 @iter3898) ([92m↓0.20%[0m) [0.38% of initial]
[Iter 5490/20000] Loss: 0.0004558 (Best: 0.0003700 @iter5344) ([91m↑2.29%[0m) [0.18% of initial]
[Iter 3940/20000] Loss: 0.0007985 (Best: 0.0006046 @iter3898) ([92m↓16.78%[0m) [0.32% of initial]
Iter:5499, L1 loss=0.0005346, Total loss=0.0004606, Time:134
[Iter 5500/20000] Loss: 0.0004179 (Best: 0.0003700 @iter5344) ([92m↓8.31%[0m) [0.17% of initial]
[Iter 3950/20000] Loss: 0.0008631 (Best: 0.0006046 @iter3898) ([91m↑8.08%[0m) [0.34% of initial]
[Iter 5510/20000] Loss: 0.0004424 (Best: 0.0003700 @iter5344) ([91m↑5.88%[0m) [0.18% of initial]
[Iter 3960/20000] Loss: 0.0009137 (Best: 0.0006046 @iter3898) ([91m↑5.87%[0m) [0.36% of initial]
[Iter 5520/20000] Loss: 0.0004193 (Best: 0.0003700 @iter5344) ([92m↓5.22%[0m) [0.17% of initial]
[Iter 3970/20000] Loss: 0.0008047 (Best: 0.0006046 @iter3898) ([92m↓11.93%[0m) [0.32% of initial]
[Iter 5530/20000] Loss: 0.0004554 (Best: 0.0003694 @iter5521) ([91m↑8.60%[0m) [0.18% of initial]
[Iter 3980/20000] Loss: 0.0011153 (Best: 0.0006046 @iter3898) ([91m↑38.60%[0m) [0.44% of initial]
[Iter 5540/20000] Loss: 0.0004593 (Best: 0.0003694 @iter5521) ([91m↑0.87%[0m) [0.18% of initial]
[Iter 3990/20000] Loss: 0.0008345 (Best: 0.0006046 @iter3898) ([92m↓25.18%[0m) [0.33% of initial]
[Iter 5550/20000] Loss: 0.0004703 (Best: 0.0003694 @iter5521) ([91m↑2.38%[0m) [0.19% of initial]
Iter:3999, L1 loss=0.000933, Total loss=0.0009038, Time:98
[Iter 4000/20000] Loss: 0.0008189 (Best: 0.0006046 @iter3898) ([92m↓1.86%[0m) [0.33% of initial]
Pruning 306 points (0.2%) from gaussian0 at iteration 4000
Pruning 285 points (0.2%) from gaussian1 at iteration 4000
[Iter 5560/20000] Loss: 0.0004346 (Best: 0.0003694 @iter5521) ([92m↓7.59%[0m) [0.17% of initial]
[Iter 4010/20000] Loss: 0.1494781 (Best: 0.0006046 @iter3898) ([91m↑18152.78%[0m) [59.39% of initial]
[Iter 5570/20000] Loss: 0.0004319 (Best: 0.0003694 @iter5521) ([92m↓0.61%[0m) [0.17% of initial]
[Iter 4020/20000] Loss: 0.1020887 (Best: 0.0006046 @iter3898) ([92m↓31.70%[0m) [40.56% of initial]
[Iter 5580/20000] Loss: 0.0005094 (Best: 0.0003694 @iter5521) ([91m↑17.94%[0m) [0.20% of initial]
[Iter 4030/20000] Loss: 0.0649986 (Best: 0.0006046 @iter3898) ([92m↓36.33%[0m) [25.82% of initial]
[Iter 5590/20000] Loss: 0.0005599 (Best: 0.0003694 @iter5521) ([91m↑9.91%[0m) [0.22% of initial]
[Iter 4040/20000] Loss: 0.0358273 (Best: 0.0006046 @iter3898) ([92m↓44.88%[0m) [14.23% of initial]
Iter:5599, L1 loss=0.000477, Total loss=0.0004113, Time:120
[Iter 5600/20000] Loss: 0.0004314 (Best: 0.0003694 @iter5521) ([92m↓22.95%[0m) [0.17% of initial]
[Iter 4050/20000] Loss: 0.0163240 (Best: 0.0006046 @iter3898) ([92m↓54.44%[0m) [6.49% of initial]
[Iter 5610/20000] Loss: 0.0021442 (Best: 0.0003694 @iter5521) ([91m↑397.01%[0m) [0.85% of initial]
[Iter 4060/20000] Loss: 0.0079521 (Best: 0.0006046 @iter3898) ([92m↓51.29%[0m) [3.16% of initial]
[Iter 5620/20000] Loss: 0.0010655 (Best: 0.0003694 @iter5521) ([92m↓50.31%[0m) [0.42% of initial]
[Iter 4070/20000] Loss: 0.0050439 (Best: 0.0006046 @iter3898) ([92m↓36.57%[0m) [2.00% of initial]
[Iter 5630/20000] Loss: 0.0007784 (Best: 0.0003694 @iter5521) ([92m↓26.95%[0m) [0.31% of initial]
[Iter 4080/20000] Loss: 0.0036972 (Best: 0.0006046 @iter3898) ([92m↓26.70%[0m) [1.47% of initial]
[Iter 5640/20000] Loss: 0.0006334 (Best: 0.0003694 @iter5521) ([92m↓18.63%[0m) [0.25% of initial]
[Iter 4090/20000] Loss: 0.0027672 (Best: 0.0006046 @iter3898) ([92m↓25.15%[0m) [1.10% of initial]
[Iter 5650/20000] Loss: 0.0005321 (Best: 0.0003694 @iter5521) ([92m↓15.98%[0m) [0.21% of initial]
Iter:4099, L1 loss=0.002014, Total loss=0.002246, Time:136
[Iter 4100/20000] Loss: 0.0023539 (Best: 0.0006046 @iter3898) ([92m↓14.93%[0m) [0.94% of initial]
[Iter 5660/20000] Loss: 0.0004929 (Best: 0.0003694 @iter5521) ([92m↓7.37%[0m) [0.20% of initial]
[Iter 4110/20000] Loss: 0.0020717 (Best: 0.0006046 @iter3898) ([92m↓11.99%[0m) [0.82% of initial]
[Iter 5670/20000] Loss: 0.0004905 (Best: 0.0003694 @iter5521) ([92m↓0.49%[0m) [0.19% of initial]
[Iter 4120/20000] Loss: 0.0018288 (Best: 0.0006046 @iter3898) ([92m↓11.72%[0m) [0.73% of initial]
[Iter 5680/20000] Loss: 0.0004409 (Best: 0.0003694 @iter5521) ([92m↓10.11%[0m) [0.18% of initial]
[Iter 4130/20000] Loss: 0.0017708 (Best: 0.0006046 @iter3898) ([92m↓3.17%[0m) [0.70% of initial]
[Iter 5690/20000] Loss: 0.0004833 (Best: 0.0003694 @iter5521) ([91m↑9.62%[0m) [0.19% of initial]
[Iter 4140/20000] Loss: 0.0016279 (Best: 0.0006046 @iter3898) ([92m↓8.07%[0m) [0.65% of initial]
Iter:5699, L1 loss=0.000485, Total loss=0.0004266, Time:111
[Iter 5700/20000] Loss: 0.0004020 (Best: 0.0003694 @iter5521) ([92m↓16.82%[0m) [0.16% of initial]
[Iter 4150/20000] Loss: 0.0014616 (Best: 0.0006046 @iter3898) ([92m↓10.21%[0m) [0.58% of initial]
[Iter 5710/20000] Loss: 0.0005057 (Best: 0.0003607 @iter5701) ([91m↑25.79%[0m) [0.20% of initial]
[Iter 4160/20000] Loss: 0.0015231 (Best: 0.0006046 @iter3898) ([91m↑4.20%[0m) [0.61% of initial]
[Iter 5720/20000] Loss: 0.0004385 (Best: 0.0003607 @iter5701) ([92m↓13.28%[0m) [0.17% of initial]
[Iter 4170/20000] Loss: 0.0014361 (Best: 0.0006046 @iter3898) ([92m↓5.71%[0m) [0.57% of initial]
[Iter 4180/20000] Loss: 0.0014270 (Best: 0.0006046 @iter3898) ([92m↓0.63%[0m) [0.57% of initial]
[Iter 5730/20000] Loss: 0.0004713 (Best: 0.0003607 @iter5701) ([91m↑7.47%[0m) [0.19% of initial]
[Iter 4190/20000] Loss: 0.0012548 (Best: 0.0006046 @iter3898) ([92m↓12.07%[0m) [0.50% of initial]
[Iter 5740/20000] Loss: 0.0004073 (Best: 0.0003607 @iter5701) ([92m↓13.57%[0m) [0.16% of initial]
Iter:4199, L1 loss=0.001211, Total loss=0.001228, Time:108
[Iter 4200/20000] Loss: 0.0013178 (Best: 0.0006046 @iter3898) ([91m↑5.02%[0m) [0.52% of initial]
[Iter 5750/20000] Loss: 0.0004285 (Best: 0.0003607 @iter5701) ([91m↑5.19%[0m) [0.17% of initial]
[Iter 5760/20000] Loss: 0.0004199 (Best: 0.0003559 @iter5755) ([92m↓2.00%[0m) [0.17% of initial]
[Iter 4210/20000] Loss: 0.0031871 (Best: 0.0006046 @iter3898) ([91m↑141.85%[0m) [1.27% of initial]
[Iter 5770/20000] Loss: 0.0003750 (Best: 0.0003398 @iter5770) ([92m↓10.71%[0m) [0.15% of initial]
[Iter 4220/20000] Loss: 0.0021386 (Best: 0.0006046 @iter3898) ([92m↓32.90%[0m) [0.85% of initial]
[Iter 5780/20000] Loss: 0.0003740 (Best: 0.0003398 @iter5770) ([92m↓0.26%[0m) [0.15% of initial]
[Iter 4230/20000] Loss: 0.0016028 (Best: 0.0006046 @iter3898) ([92m↓25.05%[0m) [0.64% of initial]
[Iter 5790/20000] Loss: 0.0004023 (Best: 0.0003263 @iter5788) ([91m↑7.57%[0m) [0.16% of initial]
[Iter 4240/20000] Loss: 0.0013661 (Best: 0.0006046 @iter3898) ([92m↓14.77%[0m) [0.54% of initial]
Iter:5799, L1 loss=0.000446, Total loss=0.0003992, Time:110
[Iter 5800/20000] Loss: 0.0003962 (Best: 0.0003160 @iter5797) ([92m↓1.52%[0m) [0.16% of initial]
[Iter 4250/20000] Loss: 0.0013297 (Best: 0.0006046 @iter3898) ([92m↓2.67%[0m) [0.53% of initial]
[Iter 4260/20000] Loss: 0.0013721 (Best: 0.0006046 @iter3898) ([91m↑3.19%[0m) [0.55% of initial]
[Iter 5810/20000] Loss: 0.0017550 (Best: 0.0003160 @iter5797) ([91m↑343.00%[0m) [0.70% of initial]
[Iter 4270/20000] Loss: 0.0012784 (Best: 0.0006046 @iter3898) ([92m↓6.83%[0m) [0.51% of initial]
[Iter 5820/20000] Loss: 0.0010459 (Best: 0.0003160 @iter5797) ([92m↓40.41%[0m) [0.42% of initial]
[Iter 4280/20000] Loss: 0.0010741 (Best: 0.0006046 @iter3898) ([92m↓15.98%[0m) [0.43% of initial]
[Iter 5830/20000] Loss: 0.0006891 (Best: 0.0003160 @iter5797) ([92m↓34.11%[0m) [0.27% of initial]
[Iter 4290/20000] Loss: 0.0010752 (Best: 0.0006046 @iter3898) ([91m↑0.10%[0m) [0.43% of initial]
[Iter 5840/20000] Loss: 0.0005716 (Best: 0.0003160 @iter5797) ([92m↓17.06%[0m) [0.23% of initial]
Iter:4299, L1 loss=0.001217, Total loss=0.001196, Time:101
[Iter 4300/20000] Loss: 0.0010345 (Best: 0.0006046 @iter3898) ([92m↓3.79%[0m) [0.41% of initial]
[Iter 5850/20000] Loss: 0.0005441 (Best: 0.0003160 @iter5797) ([92m↓4.80%[0m) [0.22% of initial]
[Iter 4310/20000] Loss: 0.0009989 (Best: 0.0006046 @iter3898) ([92m↓3.44%[0m) [0.40% of initial]
[Iter 5860/20000] Loss: 0.0004359 (Best: 0.0003160 @iter5797) ([92m↓19.89%[0m) [0.17% of initial]
[Iter 4320/20000] Loss: 0.0011578 (Best: 0.0006046 @iter3898) ([91m↑15.91%[0m) [0.46% of initial]
[Iter 5870/20000] Loss: 0.0004952 (Best: 0.0003160 @iter5797) ([91m↑13.61%[0m) [0.20% of initial]
[Iter 4330/20000] Loss: 0.0009944 (Best: 0.0006046 @iter3898) ([92m↓14.11%[0m) [0.40% of initial]
[Iter 5880/20000] Loss: 0.0004481 (Best: 0.0003160 @iter5797) ([92m↓9.53%[0m) [0.18% of initial]
[Iter 4340/20000] Loss: 0.0009718 (Best: 0.0006046 @iter3898) ([92m↓2.28%[0m) [0.39% of initial]
[Iter 5890/20000] Loss: 0.0004128 (Best: 0.0003160 @iter5797) ([92m↓7.86%[0m) [0.16% of initial]
[Iter 4350/20000] Loss: 0.0009730 (Best: 0.0006046 @iter3898) ([91m↑0.12%[0m) [0.39% of initial]
Iter:5899, L1 loss=0.0004656, Total loss=0.0004124, Time:120
[Iter 5900/20000] Loss: 0.0004174 (Best: 0.0003160 @iter5797) ([91m↑1.12%[0m) [0.17% of initial]
[Iter 4360/20000] Loss: 0.0009423 (Best: 0.0006046 @iter3898) ([92m↓3.15%[0m) [0.37% of initial]
[Iter 5910/20000] Loss: 0.0004370 (Best: 0.0003160 @iter5797) ([91m↑4.69%[0m) [0.17% of initial]
[Iter 4370/20000] Loss: 0.0009631 (Best: 0.0006046 @iter3898) ([91m↑2.21%[0m) [0.38% of initial]
[Iter 5920/20000] Loss: 0.0004249 (Best: 0.0003160 @iter5797) ([92m↓2.77%[0m) [0.17% of initial]
[Iter 4380/20000] Loss: 0.0009821 (Best: 0.0006046 @iter3898) ([91m↑1.97%[0m) [0.39% of initial]
[Iter 5930/20000] Loss: 0.0003587 (Best: 0.0003160 @iter5797) ([92m↓15.58%[0m) [0.14% of initial]
[Iter 4390/20000] Loss: 0.0009209 (Best: 0.0006046 @iter3898) ([92m↓6.23%[0m) [0.37% of initial]
[Iter 5940/20000] Loss: 0.0004655 (Best: 0.0003160 @iter5797) ([91m↑29.77%[0m) [0.18% of initial]
Iter:4399, L1 loss=0.0008505, Total loss=0.0008229, Time:107
[Iter 4400/20000] Loss: 0.0009122 (Best: 0.0006046 @iter3898) ([92m↓0.95%[0m) [0.36% of initial]
[Iter 5950/20000] Loss: 0.0003810 (Best: 0.0003160 @iter5797) ([92m↓18.15%[0m) [0.15% of initial]
[Iter 4410/20000] Loss: 0.0022955 (Best: 0.0006046 @iter3898) ([91m↑151.65%[0m) [0.91% of initial]
[Iter 5960/20000] Loss: 0.0004168 (Best: 0.0003160 @iter5797) ([91m↑9.38%[0m) [0.17% of initial]
[Iter 4420/20000] Loss: 0.0014505 (Best: 0.0006046 @iter3898) ([92m↓36.81%[0m) [0.58% of initial]
[Iter 5970/20000] Loss: 0.0004722 (Best: 0.0003160 @iter5797) ([91m↑13.29%[0m) [0.19% of initial]
[Iter 4430/20000] Loss: 0.0012468 (Best: 0.0006046 @iter3898) ([92m↓14.04%[0m) [0.50% of initial]
[Iter 5980/20000] Loss: 0.0004189 (Best: 0.0003160 @iter5797) ([92m↓11.29%[0m) [0.17% of initial]
[Iter 4440/20000] Loss: 0.0010757 (Best: 0.0006046 @iter3898) ([92m↓13.72%[0m) [0.43% of initial]
[Iter 5990/20000] Loss: 0.0004287 (Best: 0.0003160 @iter5797) ([91m↑2.35%[0m) [0.17% of initial]
[Iter 4450/20000] Loss: 0.0009736 (Best: 0.0006046 @iter3898) ([92m↓9.50%[0m) [0.39% of initial]
Iter:5999, L1 loss=0.000491, Total loss=0.0004324, Time:133
[Iter 6000/20000] Loss: 0.0004451 (Best: 0.0003160 @iter5797) ([91m↑3.82%[0m) [0.18% of initial]
[Iter 4460/20000] Loss: 0.0009553 (Best: 0.0006046 @iter3898) ([92m↓1.88%[0m) [0.38% of initial]
[Iter 6010/20000] Loss: 0.0016777 (Best: 0.0003160 @iter5797) ([91m↑276.94%[0m) [0.67% of initial]
[Iter 4470/20000] Loss: 0.0010578 (Best: 0.0006046 @iter3898) ([91m↑10.73%[0m) [0.42% of initial]
[Iter 6020/20000] Loss: 0.0010762 (Best: 0.0003160 @iter5797) ([92m↓35.86%[0m) [0.43% of initial]
[Iter 4480/20000] Loss: 0.0010072 (Best: 0.0006046 @iter3898) ([92m↓4.78%[0m) [0.40% of initial]
[Iter 6030/20000] Loss: 0.0007487 (Best: 0.0003160 @iter5797) ([92m↓30.43%[0m) [0.30% of initial]
[Iter 4490/20000] Loss: 0.0009969 (Best: 0.0006046 @iter3898) ([92m↓1.03%[0m) [0.40% of initial]
[Iter 6040/20000] Loss: 0.0005308 (Best: 0.0003160 @iter5797) ([92m↓29.10%[0m) [0.21% of initial]
Iter:4499, L1 loss=0.001058, Total loss=0.001049, Time:111
[Iter 4500/20000] Loss: 0.0011168 (Best: 0.0006046 @iter3898) ([91m↑12.03%[0m) [0.44% of initial]
Pruning 284 points (0.2%) from gaussian0 at iteration 4500
Pruning 304 points (0.2%) from gaussian1 at iteration 4500
[Iter 6050/20000] Loss: 0.0004806 (Best: 0.0003160 @iter5797) ([92m↓9.46%[0m) [0.19% of initial]
[Iter 4510/20000] Loss: 0.0018685 (Best: 0.0006046 @iter3898) ([91m↑67.31%[0m) [0.74% of initial]
[Iter 6060/20000] Loss: 0.0004913 (Best: 0.0003160 @iter5797) ([91m↑2.22%[0m) [0.20% of initial]
[Iter 4520/20000] Loss: 0.0014895 (Best: 0.0006046 @iter3898) ([92m↓20.28%[0m) [0.59% of initial]
[Iter 6070/20000] Loss: 0.0004859 (Best: 0.0003160 @iter5797) ([92m↓1.10%[0m) [0.19% of initial]
[Iter 4530/20000] Loss: 0.0014423 (Best: 0.0006046 @iter3898) ([92m↓3.17%[0m) [0.57% of initial]
[Iter 6080/20000] Loss: 0.0004659 (Best: 0.0003160 @iter5797) ([92m↓4.12%[0m) [0.19% of initial]
[Iter 4540/20000] Loss: 0.0011567 (Best: 0.0006046 @iter3898) ([92m↓19.80%[0m) [0.46% of initial]
[Iter 6090/20000] Loss: 0.0004161 (Best: 0.0003160 @iter5797) ([92m↓10.68%[0m) [0.17% of initial]
[Iter 4550/20000] Loss: 0.0010101 (Best: 0.0006046 @iter3898) ([92m↓12.67%[0m) [0.40% of initial]
Iter:6099, L1 loss=0.0004516, Total loss=0.0003958, Time:127
[Iter 6100/20000] Loss: 0.0004199 (Best: 0.0003160 @iter5797) ([91m↑0.92%[0m) [0.17% of initial]
[Iter 4560/20000] Loss: 0.0010120 (Best: 0.0006046 @iter3898) ([91m↑0.19%[0m) [0.40% of initial]
[Iter 6110/20000] Loss: 0.0004049 (Best: 0.0003160 @iter5797) ([92m↓3.57%[0m) [0.16% of initial]
[Iter 4570/20000] Loss: 0.0008886 (Best: 0.0006046 @iter3898) ([92m↓12.20%[0m) [0.35% of initial]
[Iter 6120/20000] Loss: 0.0004760 (Best: 0.0003160 @iter5797) ([91m↑17.56%[0m) [0.19% of initial]
[Iter 4580/20000] Loss: 0.0008658 (Best: 0.0006046 @iter3898) ([92m↓2.56%[0m) [0.34% of initial]
[Iter 6130/20000] Loss: 0.0004471 (Best: 0.0003160 @iter5797) ([92m↓6.07%[0m) [0.18% of initial]
[Iter 4590/20000] Loss: 0.0009619 (Best: 0.0006046 @iter3898) ([91m↑11.09%[0m) [0.38% of initial]
[Iter 6140/20000] Loss: 0.0003795 (Best: 0.0003160 @iter5797) ([92m↓15.13%[0m) [0.15% of initial]
Iter:4599, L1 loss=0.0009573, Total loss=0.0009238, Time:114
[Iter 4600/20000] Loss: 0.0008909 (Best: 0.0006046 @iter3898) ([92m↓7.38%[0m) [0.35% of initial]
[Iter 6150/20000] Loss: 0.0003855 (Best: 0.0003160 @iter5797) ([91m↑1.60%[0m) [0.15% of initial]
[Iter 4610/20000] Loss: 0.0023481 (Best: 0.0006046 @iter3898) ([91m↑163.58%[0m) [0.93% of initial]
[Iter 6160/20000] Loss: 0.0003685 (Best: 0.0003160 @iter5797) ([92m↓4.42%[0m) [0.15% of initial]
[Iter 4620/20000] Loss: 0.0016915 (Best: 0.0006046 @iter3898) ([92m↓27.96%[0m) [0.67% of initial]
[Iter 6170/20000] Loss: 0.0003759 (Best: 0.0003160 @iter5797) ([91m↑2.02%[0m) [0.15% of initial]
[Iter 4630/20000] Loss: 0.0012549 (Best: 0.0006046 @iter3898) ([92m↓25.81%[0m) [0.50% of initial]
[Iter 6180/20000] Loss: 0.0004414 (Best: 0.0003160 @iter5797) ([91m↑17.42%[0m) [0.18% of initial]
[Iter 4640/20000] Loss: 0.0010841 (Best: 0.0006046 @iter3898) ([92m↓13.61%[0m) [0.43% of initial]
[Iter 6190/20000] Loss: 0.0003744 (Best: 0.0003160 @iter5797) ([92m↓15.20%[0m) [0.15% of initial]
[Iter 4650/20000] Loss: 0.0009535 (Best: 0.0006046 @iter3898) ([92m↓12.05%[0m) [0.38% of initial]
Iter:6199, L1 loss=0.0003837, Total loss=0.0003306, Time:120
[Iter 6200/20000] Loss: 0.0003723 (Best: 0.0003160 @iter5797) ([92m↓0.55%[0m) [0.15% of initial]
[Iter 4660/20000] Loss: 0.0008453 (Best: 0.0006046 @iter3898) ([92m↓11.35%[0m) [0.34% of initial]
[Iter 6210/20000] Loss: 0.0017704 (Best: 0.0003160 @iter5797) ([91m↑375.53%[0m) [0.70% of initial]
[Iter 4670/20000] Loss: 0.0008369 (Best: 0.0006046 @iter3898) ([92m↓0.99%[0m) [0.33% of initial]
[Iter 6220/20000] Loss: 0.0008911 (Best: 0.0003160 @iter5797) ([92m↓49.67%[0m) [0.35% of initial]
[Iter 4680/20000] Loss: 0.0008157 (Best: 0.0006046 @iter3898) ([92m↓2.53%[0m) [0.32% of initial]
[Iter 6230/20000] Loss: 0.0007164 (Best: 0.0003160 @iter5797) ([92m↓19.60%[0m) [0.28% of initial]
[Iter 4690/20000] Loss: 0.0007873 (Best: 0.0006046 @iter3898) ([92m↓3.49%[0m) [0.31% of initial]
[Iter 6240/20000] Loss: 0.0005303 (Best: 0.0003160 @iter5797) ([92m↓25.98%[0m) [0.21% of initial]
Iter:4699, L1 loss=0.0009154, Total loss=0.0008596, Time:121
[Iter 4700/20000] Loss: 0.0009115 (Best: 0.0006046 @iter3898) ([91m↑15.78%[0m) [0.36% of initial]
[Iter 6250/20000] Loss: 0.0004610 (Best: 0.0003160 @iter5797) ([92m↓13.07%[0m) [0.18% of initial]
[Iter 4710/20000] Loss: 0.0007948 (Best: 0.0006046 @iter3898) ([92m↓12.80%[0m) [0.32% of initial]
[Iter 6260/20000] Loss: 0.0004924 (Best: 0.0003160 @iter5797) ([91m↑6.81%[0m) [0.20% of initial]
[Iter 4720/20000] Loss: 0.0008511 (Best: 0.0006046 @iter3898) ([91m↑7.08%[0m) [0.34% of initial]
[Iter 6270/20000] Loss: 0.0004372 (Best: 0.0003160 @iter5797) ([92m↓11.21%[0m) [0.17% of initial]
[Iter 4730/20000] Loss: 0.0008219 (Best: 0.0006046 @iter3898) ([92m↓3.43%[0m) [0.33% of initial]
[Iter 6280/20000] Loss: 0.0004544 (Best: 0.0003160 @iter5797) ([91m↑3.93%[0m) [0.18% of initial]
[Iter 4740/20000] Loss: 0.0009130 (Best: 0.0006046 @iter3898) ([91m↑11.08%[0m) [0.36% of initial]
[Iter 6290/20000] Loss: 0.0004139 (Best: 0.0003160 @iter5797) ([92m↓8.91%[0m) [0.16% of initial]
[Iter 4750/20000] Loss: 0.0008854 (Best: 0.0006046 @iter3898) ([92m↓3.02%[0m) [0.35% of initial]
Iter:6299, L1 loss=0.0005176, Total loss=0.0004544, Time:127
[Iter 6300/20000] Loss: 0.0005437 (Best: 0.0003160 @iter5797) ([91m↑31.36%[0m) [0.22% of initial]
[Iter 4760/20000] Loss: 0.0008007 (Best: 0.0006046 @iter3898) ([92m↓9.57%[0m) [0.32% of initial]
[Iter 6310/20000] Loss: 0.0004500 (Best: 0.0003160 @iter5797) ([92m↓17.23%[0m) [0.18% of initial]
[Iter 4770/20000] Loss: 0.0008674 (Best: 0.0006046 @iter3898) ([91m↑8.33%[0m) [0.34% of initial]
[Iter 6320/20000] Loss: 0.0004566 (Best: 0.0003160 @iter5797) ([91m↑1.45%[0m) [0.18% of initial]
[Iter 4780/20000] Loss: 0.0009294 (Best: 0.0006046 @iter3898) ([91m↑7.15%[0m) [0.37% of initial]
[Iter 6330/20000] Loss: 0.0004470 (Best: 0.0003160 @iter5797) ([92m↓2.09%[0m) [0.18% of initial]
[Iter 4790/20000] Loss: 0.0008227 (Best: 0.0006046 @iter3898) ([92m↓11.48%[0m) [0.33% of initial]
[Iter 6340/20000] Loss: 0.0003656 (Best: 0.0003160 @iter5797) ([92m↓18.23%[0m) [0.15% of initial]
Iter:4799, L1 loss=0.0008854, Total loss=0.0008084, Time:137
[Iter 4800/20000] Loss: 0.0009351 (Best: 0.0006046 @iter3898) ([91m↑13.66%[0m) [0.37% of initial]
[Iter 6350/20000] Loss: 0.0003648 (Best: 0.0003160 @iter5797) ([92m↓0.21%[0m) [0.14% of initial]
[Iter 4810/20000] Loss: 0.0019771 (Best: 0.0006046 @iter3898) ([91m↑111.44%[0m) [0.79% of initial]
[Iter 6360/20000] Loss: 0.0004224 (Best: 0.0003160 @iter5797) ([91m↑15.79%[0m) [0.17% of initial]
[Iter 4820/20000] Loss: 0.0014100 (Best: 0.0006046 @iter3898) ([92m↓28.68%[0m) [0.56% of initial]
[Iter 6370/20000] Loss: 0.0004252 (Best: 0.0003160 @iter5797) ([91m↑0.67%[0m) [0.17% of initial]
[Iter 4830/20000] Loss: 0.0011814 (Best: 0.0006046 @iter3898) ([92m↓16.22%[0m) [0.47% of initial]
[Iter 6380/20000] Loss: 0.0003782 (Best: 0.0003160 @iter5797) ([92m↓11.05%[0m) [0.15% of initial]
[Iter 4840/20000] Loss: 0.0009390 (Best: 0.0006046 @iter3898) ([92m↓20.52%[0m) [0.37% of initial]
[Iter 6390/20000] Loss: 0.0004000 (Best: 0.0003160 @iter5797) ([91m↑5.77%[0m) [0.16% of initial]
[Iter 4850/20000] Loss: 0.0008009 (Best: 0.0006046 @iter3898) ([92m↓14.70%[0m) [0.32% of initial]
Iter:6399, L1 loss=0.000439, Total loss=0.0003847, Time:151
[Iter 6400/20000] Loss: 0.0004213 (Best: 0.0003160 @iter5797) ([91m↑5.31%[0m) [0.17% of initial]
[Iter 4860/20000] Loss: 0.0008448 (Best: 0.0006046 @iter3898) ([91m↑5.48%[0m) [0.34% of initial]
[Iter 6410/20000] Loss: 0.0017762 (Best: 0.0003160 @iter5797) ([91m↑321.61%[0m) [0.71% of initial]
[Iter 4870/20000] Loss: 0.0007751 (Best: 0.0006046 @iter3898) ([92m↓8.25%[0m) [0.31% of initial]
[Iter 6420/20000] Loss: 0.0011380 (Best: 0.0003160 @iter5797) ([92m↓35.93%[0m) [0.45% of initial]
[Iter 4880/20000] Loss: 0.0008298 (Best: 0.0006046 @iter3898) ([91m↑7.05%[0m) [0.33% of initial]
[Iter 6430/20000] Loss: 0.0008978 (Best: 0.0003160 @iter5797) ([92m↓21.11%[0m) [0.36% of initial]
[Iter 4890/20000] Loss: 0.0007634 (Best: 0.0006046 @iter3898) ([92m↓8.00%[0m) [0.30% of initial]
[Iter 6440/20000] Loss: 0.0006452 (Best: 0.0003160 @iter5797) ([92m↓28.14%[0m) [0.26% of initial]
Iter:4899, L1 loss=0.0009013, Total loss=0.0008662, Time:125
[Iter 4900/20000] Loss: 0.0007717 (Best: 0.0006046 @iter3898) ([91m↑1.09%[0m) [0.31% of initial]
[Iter 6450/20000] Loss: 0.0005309 (Best: 0.0003160 @iter5797) ([92m↓17.71%[0m) [0.21% of initial]
[Iter 4910/20000] Loss: 0.0009662 (Best: 0.0006046 @iter3898) ([91m↑25.20%[0m) [0.38% of initial]
[Iter 6460/20000] Loss: 0.0004323 (Best: 0.0003160 @iter5797) ([92m↓18.58%[0m) [0.17% of initial]
[Iter 4920/20000] Loss: 0.0008205 (Best: 0.0006046 @iter3898) ([92m↓15.08%[0m) [0.33% of initial]
[Iter 6470/20000] Loss: 0.0004053 (Best: 0.0003160 @iter5797) ([92m↓6.25%[0m) [0.16% of initial]
[Iter 4930/20000] Loss: 0.0007461 (Best: 0.0006046 @iter3898) ([92m↓9.07%[0m) [0.30% of initial]
[Iter 6480/20000] Loss: 0.0004036 (Best: 0.0003160 @iter5797) ([92m↓0.43%[0m) [0.16% of initial]
[Iter 4940/20000] Loss: 0.0007712 (Best: 0.0006046 @iter3898) ([91m↑3.37%[0m) [0.31% of initial]
[Iter 6490/20000] Loss: 0.0003785 (Best: 0.0003160 @iter5797) ([92m↓6.21%[0m) [0.15% of initial]
[Iter 4950/20000] Loss: 0.0006795 (Best: 0.0006046 @iter3898) ([92m↓11.89%[0m) [0.27% of initial]
Iter:6499, L1 loss=0.0005156, Total loss=0.0004335, Time:144
[Iter 6500/20000] Loss: 0.0004438 (Best: 0.0003160 @iter5797) ([91m↑17.25%[0m) [0.18% of initial]
[Iter 4960/20000] Loss: 0.0007173 (Best: 0.0005947 @iter4957) ([91m↑5.56%[0m) [0.28% of initial]
[Iter 6510/20000] Loss: 0.0005580 (Best: 0.0003160 @iter5797) ([91m↑25.73%[0m) [0.22% of initial]
[Iter 4970/20000] Loss: 0.0007475 (Best: 0.0005947 @iter4957) ([91m↑4.22%[0m) [0.30% of initial]
[Iter 6520/20000] Loss: 0.0004532 (Best: 0.0003160 @iter5797) ([92m↓18.78%[0m) [0.18% of initial]
[Iter 4980/20000] Loss: 0.0007659 (Best: 0.0005947 @iter4957) ([91m↑2.46%[0m) [0.30% of initial]
[Iter 6530/20000] Loss: 0.0004796 (Best: 0.0003160 @iter5797) ([91m↑5.82%[0m) [0.19% of initial]
[Iter 4990/20000] Loss: 0.0007073 (Best: 0.0005947 @iter4957) ([92m↓7.65%[0m) [0.28% of initial]
[Iter 6540/20000] Loss: 0.0004193 (Best: 0.0003160 @iter5797) ([92m↓12.58%[0m) [0.17% of initial]
Iter:4999, L1 loss=0.0007219, Total loss=0.0006602, Time:94
[Iter 5000/20000] Loss: 0.0006634 (Best: 0.0005947 @iter4957) ([92m↓6.21%[0m) [0.26% of initial]
Pruning 163 points (0.1%) from gaussian0 at iteration 5000
Pruning 171 points (0.1%) from gaussian1 at iteration 5000
[Iter 6550/20000] Loss: 0.0004052 (Best: 0.0003160 @iter5797) ([92m↓3.35%[0m) [0.16% of initial]
[Iter 5010/20000] Loss: 0.0021900 (Best: 0.0005947 @iter4957) ([91m↑230.11%[0m) [0.87% of initial]
[Iter 6560/20000] Loss: 0.0003417 (Best: 0.0003160 @iter5797) ([92m↓15.68%[0m) [0.14% of initial]
[Iter 5020/20000] Loss: 0.0015237 (Best: 0.0005947 @iter4957) ([92m↓30.43%[0m) [0.61% of initial]
[Iter 6570/20000] Loss: 0.0003969 (Best: 0.0003108 @iter6568) ([91m↑16.17%[0m) [0.16% of initial]
[Iter 5030/20000] Loss: 0.0010641 (Best: 0.0005947 @iter4957) ([92m↓30.16%[0m) [0.42% of initial]
[Iter 6580/20000] Loss: 0.0004148 (Best: 0.0003108 @iter6568) ([91m↑4.51%[0m) [0.16% of initial]
[Iter 5040/20000] Loss: 0.0010578 (Best: 0.0005947 @iter4957) ([92m↓0.59%[0m) [0.42% of initial]
[Iter 6590/20000] Loss: 0.0003460 (Best: 0.0003108 @iter6568) ([92m↓16.58%[0m) [0.14% of initial]
Iter:6599, L1 loss=0.0004101, Total loss=0.0003613, Time:123
[Iter 5050/20000] Loss: 0.0009117 (Best: 0.0005947 @iter4957) ([92m↓13.81%[0m) [0.36% of initial]
[Iter 6600/20000] Loss: 0.0003633 (Best: 0.0003108 @iter6568) ([91m↑4.99%[0m) [0.14% of initial]
[Iter 5060/20000] Loss: 0.0007467 (Best: 0.0005947 @iter4957) ([92m↓18.10%[0m) [0.30% of initial]
[Iter 6610/20000] Loss: 0.0015845 (Best: 0.0003108 @iter6568) ([91m↑336.15%[0m) [0.63% of initial]
[Iter 5070/20000] Loss: 0.0009337 (Best: 0.0005947 @iter4957) ([91m↑25.03%[0m) [0.37% of initial]
[Iter 6620/20000] Loss: 0.0008259 (Best: 0.0003108 @iter6568) ([92m↓47.88%[0m) [0.33% of initial]
[Iter 5080/20000] Loss: 0.0007441 (Best: 0.0005947 @iter4957) ([92m↓20.30%[0m) [0.30% of initial]
[Iter 6630/20000] Loss: 0.0005983 (Best: 0.0003108 @iter6568) ([92m↓27.56%[0m) [0.24% of initial]
[Iter 5090/20000] Loss: 0.0007773 (Best: 0.0005947 @iter4957) ([91m↑4.45%[0m) [0.31% of initial]
[Iter 6640/20000] Loss: 0.0004553 (Best: 0.0003108 @iter6568) ([92m↓23.90%[0m) [0.18% of initial]
Iter:5099, L1 loss=0.0008174, Total loss=0.0007586, Time:150
[Iter 5100/20000] Loss: 0.0008125 (Best: 0.0005947 @iter4957) ([91m↑4.54%[0m) [0.32% of initial]
[Iter 6650/20000] Loss: 0.0004139 (Best: 0.0003108 @iter6568) ([92m↓9.08%[0m) [0.16% of initial]
[Iter 5110/20000] Loss: 0.0007768 (Best: 0.0005947 @iter4957) ([92m↓4.41%[0m) [0.31% of initial]
[Iter 6660/20000] Loss: 0.0004586 (Best: 0.0003108 @iter6568) ([91m↑10.80%[0m) [0.18% of initial]
[Iter 5120/20000] Loss: 0.0007910 (Best: 0.0005947 @iter4957) ([91m↑1.84%[0m) [0.31% of initial]
[Iter 6670/20000] Loss: 0.0004435 (Best: 0.0003108 @iter6568) ([92m↓3.29%[0m) [0.18% of initial]
[Iter 5130/20000] Loss: 0.0008018 (Best: 0.0005947 @iter4957) ([91m↑1.37%[0m) [0.32% of initial]
[Iter 6680/20000] Loss: 0.0004844 (Best: 0.0003108 @iter6568) ([91m↑9.22%[0m) [0.19% of initial]
[Iter 5140/20000] Loss: 0.0006955 (Best: 0.0005947 @iter4957) ([92m↓13.26%[0m) [0.28% of initial]
[Iter 6690/20000] Loss: 0.0004225 (Best: 0.0003108 @iter6568) ([92m↓12.78%[0m) [0.17% of initial]
[Iter 5150/20000] Loss: 0.0007146 (Best: 0.0005947 @iter4957) ([91m↑2.76%[0m) [0.28% of initial]
Iter:6699, L1 loss=0.0004775, Total loss=0.0004302, Time:142
[Iter 6700/20000] Loss: 0.0003988 (Best: 0.0003108 @iter6568) ([92m↓5.61%[0m) [0.16% of initial]
[Iter 5160/20000] Loss: 0.0007092 (Best: 0.0005913 @iter5159) ([92m↓0.76%[0m) [0.28% of initial]
[Iter 6710/20000] Loss: 0.0004409 (Best: 0.0003108 @iter6568) ([91m↑10.56%[0m) [0.18% of initial]
[Iter 5170/20000] Loss: 0.0007655 (Best: 0.0005913 @iter5159) ([91m↑7.93%[0m) [0.30% of initial]
[Iter 6720/20000] Loss: 0.0003900 (Best: 0.0003108 @iter6568) ([92m↓11.55%[0m) [0.15% of initial]
[Iter 5180/20000] Loss: 0.0007086 (Best: 0.0005913 @iter5159) ([92m↓7.43%[0m) [0.28% of initial]
[Iter 6730/20000] Loss: 0.0003439 (Best: 0.0003108 @iter6568) ([92m↓11.83%[0m) [0.14% of initial]
[Iter 5190/20000] Loss: 0.0007310 (Best: 0.0005913 @iter5159) ([91m↑3.17%[0m) [0.29% of initial]
[Iter 6740/20000] Loss: 0.0003722 (Best: 0.0003108 @iter6568) ([91m↑8.23%[0m) [0.15% of initial]
Iter:5199, L1 loss=0.0007808, Total loss=0.0007591, Time:149
[Iter 5200/20000] Loss: 0.0006983 (Best: 0.0005913 @iter5159) ([92m↓4.48%[0m) [0.28% of initial]
[Iter 6750/20000] Loss: 0.0003874 (Best: 0.0003108 @iter6568) ([91m↑4.08%[0m) [0.15% of initial]
[Iter 6760/20000] Loss: 0.0003723 (Best: 0.0003108 @iter6568) ([92m↓3.88%[0m) [0.15% of initial]
[Iter 5210/20000] Loss: 0.0019647 (Best: 0.0005913 @iter5159) ([91m↑181.35%[0m) [0.78% of initial]
[Iter 6770/20000] Loss: 0.0003568 (Best: 0.0003108 @iter6568) ([92m↓4.16%[0m) [0.14% of initial]
[Iter 5220/20000] Loss: 0.0014940 (Best: 0.0005913 @iter5159) ([92m↓23.96%[0m) [0.59% of initial]
[Iter 6780/20000] Loss: 0.0003245 (Best: 0.0003035 @iter6778) ([92m↓9.06%[0m) [0.13% of initial]
[Iter 5230/20000] Loss: 0.0010850 (Best: 0.0005913 @iter5159) ([92m↓27.38%[0m) [0.43% of initial]
[Iter 6790/20000] Loss: 0.0003787 (Best: 0.0002862 @iter6781) ([91m↑16.71%[0m) [0.15% of initial]
[Iter 5240/20000] Loss: 0.0008452 (Best: 0.0005913 @iter5159) ([92m↓22.10%[0m) [0.34% of initial]
Iter:6799, L1 loss=0.0003488, Total loss=0.0002996, Time:154
[Iter 6800/20000] Loss: 0.0003206 (Best: 0.0002862 @iter6781) ([92m↓15.33%[0m) [0.13% of initial]
[Iter 5250/20000] Loss: 0.0010947 (Best: 0.0005913 @iter5159) ([91m↑29.52%[0m) [0.43% of initial]
[Iter 5260/20000] Loss: 0.0008710 (Best: 0.0005913 @iter5159) ([92m↓20.43%[0m) [0.35% of initial]
[Iter 6810/20000] Loss: 0.0014246 (Best: 0.0002862 @iter6781) ([91m↑344.27%[0m) [0.57% of initial]
[Iter 5270/20000] Loss: 0.0007996 (Best: 0.0005913 @iter5159) ([92m↓8.19%[0m) [0.32% of initial]
[Iter 6820/20000] Loss: 0.0010267 (Best: 0.0002862 @iter6781) ([92m↓27.93%[0m) [0.41% of initial]
[Iter 5280/20000] Loss: 0.0008511 (Best: 0.0005913 @iter5159) ([91m↑6.43%[0m) [0.34% of initial]
[Iter 6830/20000] Loss: 0.0006169 (Best: 0.0002862 @iter6781) ([92m↓39.92%[0m) [0.25% of initial]
[Iter 5290/20000] Loss: 0.0008034 (Best: 0.0005913 @iter5159) ([92m↓5.60%[0m) [0.32% of initial]
[Iter 6840/20000] Loss: 0.0004852 (Best: 0.0002862 @iter6781) ([92m↓21.34%[0m) [0.19% of initial]
Iter:5299, L1 loss=0.0008524, Total loss=0.0008113, Time:147
[Iter 5300/20000] Loss: 0.0008789 (Best: 0.0005913 @iter5159) ([91m↑9.40%[0m) [0.35% of initial]
[Iter 6850/20000] Loss: 0.0004331 (Best: 0.0002862 @iter6781) ([92m↓10.75%[0m) [0.17% of initial]
[Iter 5310/20000] Loss: 0.0008600 (Best: 0.0005913 @iter5159) ([92m↓2.15%[0m) [0.34% of initial]
[Iter 6860/20000] Loss: 0.0003912 (Best: 0.0002862 @iter6781) ([92m↓9.67%[0m) [0.16% of initial]
[Iter 5320/20000] Loss: 0.0007574 (Best: 0.0005913 @iter5159) ([92m↓11.93%[0m) [0.30% of initial]
[Iter 6870/20000] Loss: 0.0003770 (Best: 0.0002862 @iter6781) ([92m↓3.64%[0m) [0.15% of initial]
[Iter 5330/20000] Loss: 0.0006529 (Best: 0.0005913 @iter5159) ([92m↓13.80%[0m) [0.26% of initial]
[Iter 6880/20000] Loss: 0.0003479 (Best: 0.0002862 @iter6781) ([92m↓7.70%[0m) [0.14% of initial]
[Iter 5340/20000] Loss: 0.0006849 (Best: 0.0005913 @iter5159) ([91m↑4.91%[0m) [0.27% of initial]
[Iter 6890/20000] Loss: 0.0004303 (Best: 0.0002862 @iter6781) ([91m↑23.69%[0m) [0.17% of initial]
[Iter 5350/20000] Loss: 0.0006993 (Best: 0.0005568 @iter5344) ([91m↑2.10%[0m) [0.28% of initial]
Iter:6899, L1 loss=0.000483, Total loss=0.0004304, Time:135
[Iter 6900/20000] Loss: 0.0004243 (Best: 0.0002862 @iter6781) ([92m↓1.40%[0m) [0.17% of initial]
[Iter 5360/20000] Loss: 0.0007125 (Best: 0.0005568 @iter5344) ([91m↑1.89%[0m) [0.28% of initial]
[Iter 6910/20000] Loss: 0.0004231 (Best: 0.0002862 @iter6781) ([92m↓0.29%[0m) [0.17% of initial]
[Iter 5370/20000] Loss: 0.0007186 (Best: 0.0005568 @iter5344) ([91m↑0.85%[0m) [0.29% of initial]
[Iter 6920/20000] Loss: 0.0003738 (Best: 0.0002862 @iter6781) ([92m↓11.65%[0m) [0.15% of initial]
[Iter 5380/20000] Loss: 0.0007271 (Best: 0.0005568 @iter5344) ([91m↑1.19%[0m) [0.29% of initial]
[Iter 6930/20000] Loss: 0.0003766 (Best: 0.0002862 @iter6781) ([91m↑0.75%[0m) [0.15% of initial]
[Iter 5390/20000] Loss: 0.0007292 (Best: 0.0005568 @iter5344) ([91m↑0.28%[0m) [0.29% of initial]
[Iter 6940/20000] Loss: 0.0003338 (Best: 0.0002862 @iter6781) ([92m↓11.35%[0m) [0.13% of initial]
Iter:5399, L1 loss=0.0006746, Total loss=0.000646, Time:140
[Iter 5400/20000] Loss: 0.0007346 (Best: 0.0005568 @iter5344) ([91m↑0.75%[0m) [0.29% of initial]
[Iter 6950/20000] Loss: 0.0003301 (Best: 0.0002862 @iter6781) ([92m↓1.12%[0m) [0.13% of initial]
[Iter 6960/20000] Loss: 0.0003235 (Best: 0.0002856 @iter6959) ([92m↓2.00%[0m) [0.13% of initial]
[Iter 5410/20000] Loss: 0.0016002 (Best: 0.0005568 @iter5344) ([91m↑117.83%[0m) [0.64% of initial]
[Iter 6970/20000] Loss: 0.0003869 (Best: 0.0002850 @iter6961) ([91m↑19.60%[0m) [0.15% of initial]
[Iter 5420/20000] Loss: 0.0012676 (Best: 0.0005568 @iter5344) ([92m↓20.79%[0m) [0.50% of initial]
[Iter 6980/20000] Loss: 0.0003910 (Best: 0.0002850 @iter6961) ([91m↑1.07%[0m) [0.16% of initial]
[Iter 5430/20000] Loss: 0.0009043 (Best: 0.0005568 @iter5344) ([92m↓28.67%[0m) [0.36% of initial]
[Iter 6990/20000] Loss: 0.0003454 (Best: 0.0002850 @iter6961) ([92m↓11.68%[0m) [0.14% of initial]
[Iter 5440/20000] Loss: 0.0008244 (Best: 0.0005568 @iter5344) ([92m↓8.83%[0m) [0.33% of initial]
Iter:6999, L1 loss=0.0004806, Total loss=0.0004056, Time:158
[Iter 7000/20000] Loss: 0.0003429 (Best: 0.0002850 @iter6961) ([92m↓0.71%[0m) [0.14% of initial]
[Iter 5450/20000] Loss: 0.0010178 (Best: 0.0005568 @iter5344) ([91m↑23.46%[0m) [0.40% of initial]
[Iter 5460/20000] Loss: 0.0008133 (Best: 0.0005568 @iter5344) ([92m↓20.09%[0m) [0.32% of initial]
[Iter 7010/20000] Loss: 0.0013576 (Best: 0.0002850 @iter6961) ([91m↑295.89%[0m) [0.54% of initial]
[Iter 5470/20000] Loss: 0.0006786 (Best: 0.0005568 @iter5344) ([92m↓16.57%[0m) [0.27% of initial]
[Iter 7020/20000] Loss: 0.0008237 (Best: 0.0002850 @iter6961) ([92m↓39.33%[0m) [0.33% of initial]
[Iter 5480/20000] Loss: 0.0006394 (Best: 0.0005497 @iter5476) ([92m↓5.77%[0m) [0.25% of initial]
[Iter 7030/20000] Loss: 0.0005808 (Best: 0.0002850 @iter6961) ([92m↓29.49%[0m) [0.23% of initial]
[Iter 5490/20000] Loss: 0.0006657 (Best: 0.0005497 @iter5476) ([91m↑4.11%[0m) [0.26% of initial]
[Iter 7040/20000] Loss: 0.0004526 (Best: 0.0002850 @iter6961) ([92m↓22.07%[0m) [0.18% of initial]
Iter:5499, L1 loss=0.0007255, Total loss=0.000683, Time:157
[Iter 5500/20000] Loss: 0.0006209 (Best: 0.0005497 @iter5476) ([92m↓6.72%[0m) [0.25% of initial]
[Iter 7050/20000] Loss: 0.0004209 (Best: 0.0002850 @iter6961) ([92m↓6.99%[0m) [0.17% of initial]
Pruning 120 points (0.1%) from gaussian0 at iteration 5500
Pruning 111 points (0.1%) from gaussian1 at iteration 5500
[Iter 7060/20000] Loss: 0.0004513 (Best: 0.0002850 @iter6961) ([91m↑7.21%[0m) [0.18% of initial]
[Iter 5510/20000] Loss: 0.0011624 (Best: 0.0005497 @iter5476) ([91m↑87.20%[0m) [0.46% of initial]
[Iter 7070/20000] Loss: 0.0003865 (Best: 0.0002850 @iter6961) ([92m↓14.37%[0m) [0.15% of initial]
[Iter 5520/20000] Loss: 0.0008796 (Best: 0.0005497 @iter5476) ([92m↓24.33%[0m) [0.35% of initial]
[Iter 7080/20000] Loss: 0.0004013 (Best: 0.0002850 @iter6961) ([91m↑3.85%[0m) [0.16% of initial]
[Iter 5530/20000] Loss: 0.0008018 (Best: 0.0005497 @iter5476) ([92m↓8.84%[0m) [0.32% of initial]
[Iter 7090/20000] Loss: 0.0004327 (Best: 0.0002850 @iter6961) ([91m↑7.82%[0m) [0.17% of initial]
[Iter 5540/20000] Loss: 0.0007396 (Best: 0.0005497 @iter5476) ([92m↓7.76%[0m) [0.29% of initial]
Iter:7099, L1 loss=0.000434, Total loss=0.0003736, Time:153
[Iter 7100/20000] Loss: 0.0003937 (Best: 0.0002850 @iter6961) ([92m↓9.03%[0m) [0.16% of initial]
[Iter 5550/20000] Loss: 0.0007114 (Best: 0.0005497 @iter5476) ([92m↓3.80%[0m) [0.28% of initial]
[Iter 7110/20000] Loss: 0.0003950 (Best: 0.0002850 @iter6961) ([91m↑0.34%[0m) [0.16% of initial]
[Iter 5560/20000] Loss: 0.0006643 (Best: 0.0005497 @iter5476) ([92m↓6.62%[0m) [0.26% of initial]
[Iter 7120/20000] Loss: 0.0003607 (Best: 0.0002850 @iter6961) ([92m↓8.68%[0m) [0.14% of initial]
[Iter 5570/20000] Loss: 0.0006558 (Best: 0.0005497 @iter5476) ([92m↓1.28%[0m) [0.26% of initial]
[Iter 7130/20000] Loss: 0.0003361 (Best: 0.0002850 @iter6961) ([92m↓6.82%[0m) [0.13% of initial]
[Iter 5580/20000] Loss: 0.0007629 (Best: 0.0005497 @iter5476) ([91m↑16.32%[0m) [0.30% of initial]
[Iter 7140/20000] Loss: 0.0004173 (Best: 0.0002850 @iter6961) ([91m↑24.14%[0m) [0.17% of initial]
[Iter 5590/20000] Loss: 0.0008167 (Best: 0.0005497 @iter5476) ([91m↑7.06%[0m) [0.32% of initial]
[Iter 7150/20000] Loss: 0.0003642 (Best: 0.0002850 @iter6961) ([92m↓12.71%[0m) [0.14% of initial]
Iter:5599, L1 loss=0.0006651, Total loss=0.0006154, Time:126
[Iter 5600/20000] Loss: 0.0006404 (Best: 0.0005497 @iter5476) ([92m↓21.59%[0m) [0.25% of initial]
[Iter 7160/20000] Loss: 0.0003628 (Best: 0.0002850 @iter6961) ([92m↓0.38%[0m) [0.14% of initial]
[Iter 5610/20000] Loss: 0.0017651 (Best: 0.0005497 @iter5476) ([91m↑175.62%[0m) [0.70% of initial]
[Iter 7170/20000] Loss: 0.0003758 (Best: 0.0002850 @iter6961) ([91m↑3.57%[0m) [0.15% of initial]
[Iter 5620/20000] Loss: 0.0011338 (Best: 0.0005497 @iter5476) ([92m↓35.77%[0m) [0.45% of initial]
[Iter 7180/20000] Loss: 0.0003775 (Best: 0.0002850 @iter6961) ([91m↑0.46%[0m) [0.15% of initial]
[Iter 5630/20000] Loss: 0.0009109 (Best: 0.0005497 @iter5476) ([92m↓19.66%[0m) [0.36% of initial]
[Iter 7190/20000] Loss: 0.0003227 (Best: 0.0002850 @iter6961) ([92m↓14.53%[0m) [0.13% of initial]
[Iter 5640/20000] Loss: 0.0008160 (Best: 0.0005497 @iter5476) ([92m↓10.42%[0m) [0.32% of initial]
Iter:7199, L1 loss=0.0003797, Total loss=0.0003279, Time:148
[Iter 7200/20000] Loss: 0.0003389 (Best: 0.0002803 @iter7198) ([91m↑5.04%[0m) [0.13% of initial]
[Iter 5650/20000] Loss: 0.0007016 (Best: 0.0005497 @iter5476) ([92m↓14.02%[0m) [0.28% of initial]
[Iter 7210/20000] Loss: 0.0016156 (Best: 0.0002803 @iter7198) ([91m↑376.68%[0m) [0.64% of initial]
[Iter 5660/20000] Loss: 0.0006809 (Best: 0.0005497 @iter5476) ([92m↓2.95%[0m) [0.27% of initial]
[Iter 7220/20000] Loss: 0.0009711 (Best: 0.0002803 @iter7198) ([92m↓39.89%[0m) [0.39% of initial]
[Iter 5670/20000] Loss: 0.0007005 (Best: 0.0005497 @iter5476) ([91m↑2.88%[0m) [0.28% of initial]
[Iter 7230/20000] Loss: 0.0006835 (Best: 0.0002803 @iter7198) ([92m↓29.62%[0m) [0.27% of initial]
[Iter 5680/20000] Loss: 0.0006352 (Best: 0.0005497 @iter5476) ([92m↓9.31%[0m) [0.25% of initial]
[Iter 7240/20000] Loss: 0.0005011 (Best: 0.0002803 @iter7198) ([92m↓26.68%[0m) [0.20% of initial]
[Iter 5690/20000] Loss: 0.0006818 (Best: 0.0005497 @iter5476) ([91m↑7.33%[0m) [0.27% of initial]
[Iter 7250/20000] Loss: 0.0003916 (Best: 0.0002803 @iter7198) ([92m↓21.87%[0m) [0.16% of initial]
Iter:5699, L1 loss=0.0006505, Total loss=0.0006, Time:198
[Iter 5700/20000] Loss: 0.0005861 (Best: 0.0005497 @iter5476) ([92m↓14.04%[0m) [0.23% of initial]
[Iter 7260/20000] Loss: 0.0003752 (Best: 0.0002803 @iter7198) ([92m↓4.19%[0m) [0.15% of initial]
[Iter 5710/20000] Loss: 0.0007187 (Best: 0.0005136 @iter5701) ([91m↑22.62%[0m) [0.29% of initial]
[Iter 7270/20000] Loss: 0.0003412 (Best: 0.0002803 @iter7198) ([92m↓9.06%[0m) [0.14% of initial]
[Iter 5720/20000] Loss: 0.0006567 (Best: 0.0005136 @iter5701) ([92m↓8.62%[0m) [0.26% of initial]
[Iter 7280/20000] Loss: 0.0003170 (Best: 0.0002799 @iter7276) ([92m↓7.08%[0m) [0.13% of initial]
[Iter 5730/20000] Loss: 0.0006799 (Best: 0.0005136 @iter5701) ([91m↑3.53%[0m) [0.27% of initial]
[Iter 7290/20000] Loss: 0.0003315 (Best: 0.0002755 @iter7288) ([91m↑4.56%[0m) [0.13% of initial]
[Iter 5740/20000] Loss: 0.0005882 (Best: 0.0005136 @iter5701) ([92m↓13.48%[0m) [0.23% of initial]
Iter:7299, L1 loss=0.0004313, Total loss=0.0003807, Time:187
[Iter 7300/20000] Loss: 0.0003607 (Best: 0.0002755 @iter7288) ([91m↑8.81%[0m) [0.14% of initial]
[Iter 5750/20000] Loss: 0.0005952 (Best: 0.0005136 @iter5701) ([91m↑1.18%[0m) [0.24% of initial]
[Iter 7310/20000] Loss: 0.0003412 (Best: 0.0002755 @iter7288) ([92m↓5.40%[0m) [0.14% of initial]
[Iter 5760/20000] Loss: 0.0005960 (Best: 0.0005136 @iter5701) ([91m↑0.14%[0m) [0.24% of initial]
[Iter 7320/20000] Loss: 0.0004038 (Best: 0.0002755 @iter7288) ([91m↑18.35%[0m) [0.16% of initial]
[Iter 5770/20000] Loss: 0.0005338 (Best: 0.0004820 @iter5770) ([92m↓10.44%[0m) [0.21% of initial]
[Iter 7330/20000] Loss: 0.0003708 (Best: 0.0002755 @iter7288) ([92m↓8.19%[0m) [0.15% of initial]
[Iter 5780/20000] Loss: 0.0005547 (Best: 0.0004820 @iter5770) ([91m↑3.91%[0m) [0.22% of initial]
[Iter 7340/20000] Loss: 0.0003377 (Best: 0.0002755 @iter7288) ([92m↓8.93%[0m) [0.13% of initial]
[Iter 5790/20000] Loss: 0.0005913 (Best: 0.0004787 @iter5788) ([91m↑6.61%[0m) [0.23% of initial]
[Iter 7350/20000] Loss: 0.0003884 (Best: 0.0002755 @iter7288) ([91m↑15.02%[0m) [0.15% of initial]
Iter:5799, L1 loss=0.0006306, Total loss=0.0005802, Time:207
[Iter 5800/20000] Loss: 0.0005716 (Best: 0.0004618 @iter5797) ([92m↓3.33%[0m) [0.23% of initial]
[Iter 7360/20000] Loss: 0.0004051 (Best: 0.0002755 @iter7288) ([91m↑4.31%[0m) [0.16% of initial]
[Iter 5810/20000] Loss: 0.0013810 (Best: 0.0004618 @iter5797) ([91m↑141.58%[0m) [0.55% of initial]
[Iter 7370/20000] Loss: 0.0003533 (Best: 0.0002755 @iter7288) ([92m↓12.80%[0m) [0.14% of initial]
[Iter 5820/20000] Loss: 0.0010883 (Best: 0.0004618 @iter5797) ([92m↓21.19%[0m) [0.43% of initial]
[Iter 7380/20000] Loss: 0.0004541 (Best: 0.0002755 @iter7288) ([91m↑28.53%[0m) [0.18% of initial]
[Iter 5830/20000] Loss: 0.0008219 (Best: 0.0004618 @iter5797) ([92m↓24.48%[0m) [0.33% of initial]
[Iter 7390/20000] Loss: 0.0004895 (Best: 0.0002755 @iter7288) ([91m↑7.82%[0m) [0.19% of initial]
[Iter 5840/20000] Loss: 0.0007221 (Best: 0.0004618 @iter5797) ([92m↓12.15%[0m) [0.29% of initial]
Iter:7399, L1 loss=0.0005358, Total loss=0.0004526, Time:202
[Iter 7400/20000] Loss: 0.0004610 (Best: 0.0002755 @iter7288) ([92m↓5.82%[0m) [0.18% of initial]
[Iter 5850/20000] Loss: 0.0007238 (Best: 0.0004618 @iter5797) ([91m↑0.24%[0m) [0.29% of initial]
[Iter 7410/20000] Loss: 0.0014225 (Best: 0.0002755 @iter7288) ([91m↑208.54%[0m) [0.57% of initial]
[Iter 5860/20000] Loss: 0.0005889 (Best: 0.0004618 @iter5797) ([92m↓18.64%[0m) [0.23% of initial]
[Iter 7420/20000] Loss: 0.0009094 (Best: 0.0002755 @iter7288) ([92m↓36.07%[0m) [0.36% of initial]
[Iter 5870/20000] Loss: 0.0006688 (Best: 0.0004618 @iter5797) ([91m↑13.57%[0m) [0.27% of initial]
[Iter 7430/20000] Loss: 0.0006374 (Best: 0.0002755 @iter7288) ([92m↓29.92%[0m) [0.25% of initial]
[Iter 5880/20000] Loss: 0.0006270 (Best: 0.0004618 @iter5797) ([92m↓6.25%[0m) [0.25% of initial]
[Iter 7440/20000] Loss: 0.0005336 (Best: 0.0002755 @iter7288) ([92m↓16.28%[0m) [0.21% of initial]
[Iter 5890/20000] Loss: 0.0005932 (Best: 0.0004618 @iter5797) ([92m↓5.39%[0m) [0.24% of initial]
[Iter 7450/20000] Loss: 0.0004643 (Best: 0.0002755 @iter7288) ([92m↓12.99%[0m) [0.18% of initial]
Iter:5899, L1 loss=0.000624, Total loss=0.0005717, Time:190
[Iter 5900/20000] Loss: 0.0005838 (Best: 0.0004618 @iter5797) ([92m↓1.59%[0m) [0.23% of initial]
[Iter 7460/20000] Loss: 0.0004326 (Best: 0.0002755 @iter7288) ([92m↓6.83%[0m) [0.17% of initial]
[Iter 5910/20000] Loss: 0.0006211 (Best: 0.0004618 @iter5797) ([91m↑6.39%[0m) [0.25% of initial]
[Iter 7470/20000] Loss: 0.0004059 (Best: 0.0002755 @iter7288) ([92m↓6.18%[0m) [0.16% of initial]
[Iter 5920/20000] Loss: 0.0005875 (Best: 0.0004618 @iter5797) ([92m↓5.41%[0m) [0.23% of initial]
[Iter 7480/20000] Loss: 0.0003981 (Best: 0.0002755 @iter7288) ([92m↓1.92%[0m) [0.16% of initial]
[Iter 5930/20000] Loss: 0.0005034 (Best: 0.0004618 @iter5797) ([92m↓14.31%[0m) [0.20% of initial]
[Iter 7490/20000] Loss: 0.0003245 (Best: 0.0002755 @iter7288) ([92m↓18.49%[0m) [0.13% of initial]
[Iter 5940/20000] Loss: 0.0006584 (Best: 0.0004618 @iter5797) ([91m↑30.79%[0m) [0.26% of initial]
Iter:7499, L1 loss=0.0004019, Total loss=0.0003557, Time:201
[Iter 7500/20000] Loss: 0.0003630 (Best: 0.0002755 @iter7288) ([91m↑11.88%[0m) [0.14% of initial]
[Iter 5950/20000] Loss: 0.0005341 (Best: 0.0004618 @iter5797) ([92m↓18.89%[0m) [0.21% of initial]
[Iter 7510/20000] Loss: 0.0004215 (Best: 0.0002755 @iter7288) ([91m↑16.10%[0m) [0.17% of initial]
[Iter 5960/20000] Loss: 0.0005744 (Best: 0.0004618 @iter5797) ([91m↑7.55%[0m) [0.23% of initial]
[Iter 7520/20000] Loss: 0.0003647 (Best: 0.0002755 @iter7288) ([92m↓13.48%[0m) [0.14% of initial]
[Iter 5970/20000] Loss: 0.0006771 (Best: 0.0004618 @iter5797) ([91m↑17.88%[0m) [0.27% of initial]
[Iter 7530/20000] Loss: 0.0003310 (Best: 0.0002755 @iter7288) ([92m↓9.24%[0m) [0.13% of initial]
[Iter 5980/20000] Loss: 0.0005985 (Best: 0.0004618 @iter5797) ([92m↓11.61%[0m) [0.24% of initial]
[Iter 7540/20000] Loss: 0.0002772 (Best: 0.0002530 @iter7540) ([92m↓16.26%[0m) [0.11% of initial]
[Iter 5990/20000] Loss: 0.0005990 (Best: 0.0004618 @iter5797) ([91m↑0.09%[0m) [0.24% of initial]
[Iter 7550/20000] Loss: 0.0003035 (Best: 0.0002530 @iter7540) ([91m↑9.50%[0m) [0.12% of initial]
Iter:5999, L1 loss=0.000684, Total loss=0.0006067, Time:154
[Iter 6000/20000] Loss: 0.0006120 (Best: 0.0004618 @iter5797) ([91m↑2.17%[0m) [0.24% of initial]
[Iter 7560/20000] Loss: 0.0003041 (Best: 0.0002530 @iter7540) ([91m↑0.19%[0m) [0.12% of initial]
Pruning 91 points (0.0%) from gaussian0 at iteration 6000
Pruning 96 points (0.1%) from gaussian1 at iteration 6000
[Iter 7570/20000] Loss: 0.0003369 (Best: 0.0002530 @iter7540) ([91m↑10.81%[0m) [0.13% of initial]
[Iter 6010/20000] Loss: 0.0019784 (Best: 0.0004618 @iter5797) ([91m↑223.26%[0m) [0.79% of initial]
[Iter 7580/20000] Loss: 0.0003737 (Best: 0.0002530 @iter7540) ([91m↑10.90%[0m) [0.15% of initial]
[Iter 6020/20000] Loss: 0.0013010 (Best: 0.0004618 @iter5797) ([92m↓34.24%[0m) [0.52% of initial]
[Iter 7590/20000] Loss: 0.0003679 (Best: 0.0002530 @iter7540) ([92m↓1.53%[0m) [0.15% of initial]
[Iter 6030/20000] Loss: 0.0008911 (Best: 0.0004618 @iter5797) ([92m↓31.50%[0m) [0.35% of initial]
Iter:7599, L1 loss=0.0003653, Total loss=0.0003121, Time:184
[Iter 7600/20000] Loss: 0.0003239 (Best: 0.0002530 @iter7540) ([92m↓11.97%[0m) [0.13% of initial]
[Iter 6040/20000] Loss: 0.0006966 (Best: 0.0004618 @iter5797) ([92m↓21.83%[0m) [0.28% of initial]
[Iter 7610/20000] Loss: 0.0014927 (Best: 0.0002530 @iter7540) ([91m↑360.86%[0m) [0.59% of initial]
[Iter 6050/20000] Loss: 0.0006334 (Best: 0.0004618 @iter5797) ([92m↓9.08%[0m) [0.25% of initial]
[Iter 7620/20000] Loss: 0.0008456 (Best: 0.0002530 @iter7540) ([92m↓43.35%[0m) [0.34% of initial]
[Iter 6060/20000] Loss: 0.0006621 (Best: 0.0004618 @iter5797) ([91m↑4.54%[0m) [0.26% of initial]
[Iter 7630/20000] Loss: 0.0006213 (Best: 0.0002530 @iter7540) ([92m↓26.53%[0m) [0.25% of initial]
[Iter 6070/20000] Loss: 0.0006533 (Best: 0.0004618 @iter5797) ([92m↓1.33%[0m) [0.26% of initial]
[Iter 7640/20000] Loss: 0.0004761 (Best: 0.0002530 @iter7540) ([92m↓23.37%[0m) [0.19% of initial]
[Iter 6080/20000] Loss: 0.0006509 (Best: 0.0004618 @iter5797) ([92m↓0.36%[0m) [0.26% of initial]
[Iter 7650/20000] Loss: 0.0003930 (Best: 0.0002530 @iter7540) ([92m↓17.45%[0m) [0.16% of initial]
[Iter 6090/20000] Loss: 0.0005851 (Best: 0.0004618 @iter5797) ([92m↓10.12%[0m) [0.23% of initial]
Iter:6099, L1 loss=0.0005905, Total loss=0.0005522, Time:160
[Iter 7660/20000] Loss: 0.0003168 (Best: 0.0002530 @iter7540) ([92m↓19.39%[0m) [0.13% of initial]
[Iter 6100/20000] Loss: 0.0005834 (Best: 0.0004618 @iter5797) ([92m↓0.29%[0m) [0.23% of initial]
[Iter 7670/20000] Loss: 0.0002931 (Best: 0.0002530 @iter7540) ([92m↓7.50%[0m) [0.12% of initial]
[Iter 6110/20000] Loss: 0.0005775 (Best: 0.0004618 @iter5797) ([92m↓1.02%[0m) [0.23% of initial]
[Iter 7680/20000] Loss: 0.0003262 (Best: 0.0002530 @iter7540) ([91m↑11.32%[0m) [0.13% of initial]
[Iter 6120/20000] Loss: 0.0006479 (Best: 0.0004618 @iter5797) ([91m↑12.20%[0m) [0.26% of initial]
[Iter 7690/20000] Loss: 0.0003084 (Best: 0.0002530 @iter7540) ([92m↓5.45%[0m) [0.12% of initial]
[Iter 6130/20000] Loss: 0.0006164 (Best: 0.0004618 @iter5797) ([92m↓4.85%[0m) [0.24% of initial]
Iter:7699, L1 loss=0.0003326, Total loss=0.0002839, Time:119
[Iter 7700/20000] Loss: 0.0002986 (Best: 0.0002530 @iter7540) ([92m↓3.19%[0m) [0.12% of initial]
[Iter 6140/20000] Loss: 0.0005300 (Best: 0.0004618 @iter5797) ([92m↓14.02%[0m) [0.21% of initial]
[Iter 7710/20000] Loss: 0.0003160 (Best: 0.0002530 @iter7540) ([91m↑5.81%[0m) [0.13% of initial]
[Iter 6150/20000] Loss: 0.0005531 (Best: 0.0004618 @iter5797) ([91m↑4.36%[0m) [0.22% of initial]
[Iter 7720/20000] Loss: 0.0002914 (Best: 0.0002530 @iter7540) ([92m↓7.79%[0m) [0.12% of initial]
[Iter 6160/20000] Loss: 0.0005272 (Best: 0.0004618 @iter5797) ([92m↓4.68%[0m) [0.21% of initial]
[Iter 7730/20000] Loss: 0.0002838 (Best: 0.0002530 @iter7540) ([92m↓2.60%[0m) [0.11% of initial]
[Iter 6170/20000] Loss: 0.0005482 (Best: 0.0004618 @iter5797) ([91m↑3.99%[0m) [0.22% of initial]
[Iter 6180/20000] Loss: 0.0006162 (Best: 0.0004618 @iter5797) ([91m↑12.40%[0m) [0.24% of initial]
[Iter 7740/20000] Loss: 0.0002866 (Best: 0.0002530 @iter7540) ([91m↑1.01%[0m) [0.11% of initial]
[Iter 6190/20000] Loss: 0.0005223 (Best: 0.0004618 @iter5797) ([92m↓15.24%[0m) [0.21% of initial]
[Iter 7750/20000] Loss: 0.0003250 (Best: 0.0002530 @iter7540) ([91m↑13.38%[0m) [0.13% of initial]
Iter:6199, L1 loss=0.0005275, Total loss=0.0004744, Time:141
[Iter 6200/20000] Loss: 0.0005255 (Best: 0.0004618 @iter5797) ([91m↑0.62%[0m) [0.21% of initial]
[Iter 7760/20000] Loss: 0.0003590 (Best: 0.0002530 @iter7540) ([91m↑10.47%[0m) [0.14% of initial]
[Iter 7770/20000] Loss: 0.0003454 (Best: 0.0002530 @iter7540) ([92m↓3.80%[0m) [0.14% of initial]
[Iter 6210/20000] Loss: 0.0013322 (Best: 0.0004618 @iter5797) ([91m↑153.48%[0m) [0.53% of initial]
[Iter 7780/20000] Loss: 0.0003345 (Best: 0.0002530 @iter7540) ([92m↓3.16%[0m) [0.13% of initial]
[Iter 6220/20000] Loss: 0.0009614 (Best: 0.0004618 @iter5797) ([92m↓27.83%[0m) [0.38% of initial]
[Iter 7790/20000] Loss: 0.0003489 (Best: 0.0002530 @iter7540) ([91m↑4.31%[0m) [0.14% of initial]
[Iter 6230/20000] Loss: 0.0008346 (Best: 0.0004618 @iter5797) ([92m↓13.19%[0m) [0.33% of initial]
Iter:7799, L1 loss=0.000356, Total loss=0.0002988, Time:171
[Iter 7800/20000] Loss: 0.0003388 (Best: 0.0002530 @iter7540) ([92m↓2.90%[0m) [0.13% of initial]
[Iter 6240/20000] Loss: 0.0006770 (Best: 0.0004618 @iter5797) ([92m↓18.89%[0m) [0.27% of initial]
[Iter 6250/20000] Loss: 0.0006117 (Best: 0.0004618 @iter5797) ([92m↓9.65%[0m) [0.24% of initial]
[Iter 7810/20000] Loss: 0.0013628 (Best: 0.0002530 @iter7540) ([91m↑302.23%[0m) [0.54% of initial]
[Iter 6260/20000] Loss: 0.0006891 (Best: 0.0004618 @iter5797) ([91m↑12.65%[0m) [0.27% of initial]
[Iter 7820/20000] Loss: 0.0008072 (Best: 0.0002530 @iter7540) ([92m↓40.76%[0m) [0.32% of initial]
[Iter 6270/20000] Loss: 0.0006148 (Best: 0.0004618 @iter5797) ([92m↓10.78%[0m) [0.24% of initial]
[Iter 7830/20000] Loss: 0.0005916 (Best: 0.0002530 @iter7540) ([92m↓26.72%[0m) [0.24% of initial]
[Iter 6280/20000] Loss: 0.0006514 (Best: 0.0004618 @iter5797) ([91m↑5.94%[0m) [0.26% of initial]
[Iter 7840/20000] Loss: 0.0004616 (Best: 0.0002530 @iter7540) ([92m↓21.97%[0m) [0.18% of initial]
[Iter 6290/20000] Loss: 0.0005814 (Best: 0.0004618 @iter5797) ([92m↓10.75%[0m) [0.23% of initial]
[Iter 7850/20000] Loss: 0.0004395 (Best: 0.0002530 @iter7540) ([92m↓4.78%[0m) [0.17% of initial]
Iter:6299, L1 loss=0.000729, Total loss=0.000656, Time:154
[Iter 6300/20000] Loss: 0.0007666 (Best: 0.0004618 @iter5797) ([91m↑31.86%[0m) [0.30% of initial]
[Iter 7860/20000] Loss: 0.0004370 (Best: 0.0002530 @iter7540) ([92m↓0.58%[0m) [0.17% of initial]
[Iter 6310/20000] Loss: 0.0006499 (Best: 0.0004618 @iter5797) ([92m↓15.23%[0m) [0.26% of initial]
[Iter 7870/20000] Loss: 0.0003992 (Best: 0.0002530 @iter7540) ([92m↓8.64%[0m) [0.16% of initial]
[Iter 6320/20000] Loss: 0.0006495 (Best: 0.0004618 @iter5797) ([92m↓0.06%[0m) [0.26% of initial]
[Iter 7880/20000] Loss: 0.0003527 (Best: 0.0002530 @iter7540) ([92m↓11.64%[0m) [0.14% of initial]
[Iter 6330/20000] Loss: 0.0006222 (Best: 0.0004618 @iter5797) ([92m↓4.20%[0m) [0.25% of initial]
[Iter 7890/20000] Loss: 0.0004389 (Best: 0.0002530 @iter7540) ([91m↑24.42%[0m) [0.17% of initial]
[Iter 6340/20000] Loss: 0.0005059 (Best: 0.0004518 @iter6340) ([92m↓18.69%[0m) [0.20% of initial]
Iter:7899, L1 loss=0.0004194, Total loss=0.0003577, Time:182
[Iter 7900/20000] Loss: 0.0003617 (Best: 0.0002530 @iter7540) ([92m↓17.58%[0m) [0.14% of initial]
[Iter 6350/20000] Loss: 0.0005133 (Best: 0.0004518 @iter6340) ([91m↑1.45%[0m) [0.20% of initial]
[Iter 7910/20000] Loss: 0.0003659 (Best: 0.0002530 @iter7540) ([91m↑1.16%[0m) [0.15% of initial]
[Iter 6360/20000] Loss: 0.0005915 (Best: 0.0004518 @iter6340) ([91m↑15.25%[0m) [0.24% of initial]
[Iter 7920/20000] Loss: 0.0004480 (Best: 0.0002530 @iter7540) ([91m↑22.42%[0m) [0.18% of initial]
[Iter 6370/20000] Loss: 0.0005664 (Best: 0.0004518 @iter6340) ([92m↓4.25%[0m) [0.23% of initial]
[Iter 7930/20000] Loss: 0.0003668 (Best: 0.0002530 @iter7540) ([92m↓18.13%[0m) [0.15% of initial]
[Iter 6380/20000] Loss: 0.0005233 (Best: 0.0004518 @iter6340) ([92m↓7.61%[0m) [0.21% of initial]
[Iter 7940/20000] Loss: 0.0003221 (Best: 0.0002530 @iter7540) ([92m↓12.16%[0m) [0.13% of initial]
[Iter 6390/20000] Loss: 0.0005441 (Best: 0.0004467 @iter6382) ([91m↑3.98%[0m) [0.22% of initial]
[Iter 7950/20000] Loss: 0.0003120 (Best: 0.0002530 @iter7540) ([92m↓3.16%[0m) [0.12% of initial]
Iter:6399, L1 loss=0.000577, Total loss=0.0005171, Time:135
[Iter 6400/20000] Loss: 0.0005833 (Best: 0.0004467 @iter6382) ([91m↑7.20%[0m) [0.23% of initial]
[Iter 7960/20000] Loss: 0.0003779 (Best: 0.0002530 @iter7540) ([91m↑21.14%[0m) [0.15% of initial]
[Iter 6410/20000] Loss: 0.0013583 (Best: 0.0004467 @iter6382) ([91m↑132.85%[0m) [0.54% of initial]
[Iter 7970/20000] Loss: 0.0003634 (Best: 0.0002530 @iter7540) ([92m↓3.84%[0m) [0.14% of initial]
[Iter 6420/20000] Loss: 0.0011411 (Best: 0.0004467 @iter6382) ([92m↓15.99%[0m) [0.45% of initial]
[Iter 7980/20000] Loss: 0.0003711 (Best: 0.0002530 @iter7540) ([91m↑2.11%[0m) [0.15% of initial]
[Iter 6430/20000] Loss: 0.0009551 (Best: 0.0004467 @iter6382) ([92m↓16.30%[0m) [0.38% of initial]
[Iter 7990/20000] Loss: 0.0003243 (Best: 0.0002530 @iter7540) ([92m↓12.61%[0m) [0.13% of initial]
[Iter 6440/20000] Loss: 0.0007543 (Best: 0.0004467 @iter6382) ([92m↓21.03%[0m) [0.30% of initial]
Iter:7999, L1 loss=0.0003601, Total loss=0.0003082, Time:144
[Iter 8000/20000] Loss: 0.0003251 (Best: 0.0002530 @iter7540) ([91m↑0.25%[0m) [0.13% of initial]
[Iter 8010/20000] Loss: 0.0185550 (Best: 0.0002530 @iter7540) ([91m↑5607.66%[0m) [7.37% of initial]
[Iter 6450/20000] Loss: 0.0006610 (Best: 0.0004467 @iter6382) ([92m↓12.36%[0m) [0.26% of initial]
[Iter 8020/20000] Loss: 0.0087902 (Best: 0.0002530 @iter7540) ([92m↓52.63%[0m) [3.49% of initial]
[Iter 8030/20000] Loss: 0.0040960 (Best: 0.0002530 @iter7540) ([92m↓53.40%[0m) [1.63% of initial]
[Iter 6460/20000] Loss: 0.0005775 (Best: 0.0004467 @iter6382) ([92m↓12.63%[0m) [0.23% of initial]
[Iter 8040/20000] Loss: 0.0024137 (Best: 0.0002530 @iter7540) ([92m↓41.07%[0m) [0.96% of initial]
[Iter 6470/20000] Loss: 0.0005568 (Best: 0.0004467 @iter6382) ([92m↓3.58%[0m) [0.22% of initial]
[Iter 8050/20000] Loss: 0.0014834 (Best: 0.0002530 @iter7540) ([92m↓38.54%[0m) [0.59% of initial]
[Iter 8060/20000] Loss: 0.0010860 (Best: 0.0002530 @iter7540) ([92m↓26.79%[0m) [0.43% of initial]
[Iter 6480/20000] Loss: 0.0005550 (Best: 0.0004467 @iter6382) ([92m↓0.33%[0m) [0.22% of initial]
[Iter 8070/20000] Loss: 0.0007928 (Best: 0.0002530 @iter7540) ([92m↓27.00%[0m) [0.31% of initial]
[Iter 6490/20000] Loss: 0.0005089 (Best: 0.0004467 @iter6382) ([92m↓8.31%[0m) [0.20% of initial]
[Iter 8080/20000] Loss: 0.0006310 (Best: 0.0002530 @iter7540) ([92m↓20.40%[0m) [0.25% of initial]
[Iter 8090/20000] Loss: 0.0005228 (Best: 0.0002530 @iter7540) ([92m↓17.15%[0m) [0.21% of initial]
Iter:6499, L1 loss=0.0006705, Total loss=0.0006345, Time:183
[Iter 6500/20000] Loss: 0.0006017 (Best: 0.0004467 @iter6382) ([91m↑18.24%[0m) [0.24% of initial]
Iter:8099, L1 loss=0.0005288, Total loss=0.0004804, Time:169
[Iter 8100/20000] Loss: 0.0005233 (Best: 0.0002530 @iter7540) ([91m↑0.10%[0m) [0.21% of initial]
Pruning 53 points (0.0%) from gaussian0 at iteration 6500
Pruning 81 points (0.0%) from gaussian1 at iteration 6500
[Iter 8110/20000] Loss: 0.0004695 (Best: 0.0002530 @iter7540) ([92m↓10.28%[0m) [0.19% of initial]
[Iter 6510/20000] Loss: 0.0013225 (Best: 0.0004467 @iter6382) ([91m↑119.79%[0m) [0.53% of initial]
[Iter 8120/20000] Loss: 0.0004283 (Best: 0.0002530 @iter7540) ([92m↓8.78%[0m) [0.17% of initial]
[Iter 8130/20000] Loss: 0.0004987 (Best: 0.0002530 @iter7540) ([91m↑16.45%[0m) [0.20% of initial]
[Iter 6520/20000] Loss: 0.0008518 (Best: 0.0004467 @iter6382) ([92m↓35.59%[0m) [0.34% of initial]
[Iter 8140/20000] Loss: 0.0004460 (Best: 0.0002530 @iter7540) ([92m↓10.57%[0m) [0.18% of initial]
[Iter 8150/20000] Loss: 0.0004440 (Best: 0.0002530 @iter7540) ([92m↓0.46%[0m) [0.18% of initial]
[Iter 6530/20000] Loss: 0.0007812 (Best: 0.0004467 @iter6382) ([92m↓8.29%[0m) [0.31% of initial]
[Iter 8160/20000] Loss: 0.0004269 (Best: 0.0002530 @iter7540) ([92m↓3.85%[0m) [0.17% of initial]
[Iter 6540/20000] Loss: 0.0006193 (Best: 0.0004467 @iter6382) ([92m↓20.74%[0m) [0.25% of initial]
[Iter 8170/20000] Loss: 0.0004169 (Best: 0.0002530 @iter7540) ([92m↓2.34%[0m) [0.17% of initial]
[Iter 8180/20000] Loss: 0.0004245 (Best: 0.0002530 @iter7540) ([91m↑1.82%[0m) [0.17% of initial]
[Iter 6550/20000] Loss: 0.0005510 (Best: 0.0004467 @iter6382) ([92m↓11.02%[0m) [0.22% of initial]
[Iter 8190/20000] Loss: 0.0004110 (Best: 0.0002530 @iter7540) ([92m↓3.17%[0m) [0.16% of initial]
Iter:8199, L1 loss=0.0004888, Total loss=0.0004392, Time:203
[Iter 6560/20000] Loss: 0.0004728 (Best: 0.0004412 @iter6559) ([92m↓14.20%[0m) [0.19% of initial]
[Iter 8200/20000] Loss: 0.0004037 (Best: 0.0002530 @iter7540) ([92m↓1.78%[0m) [0.16% of initial]
[Iter 8210/20000] Loss: 0.0003789 (Best: 0.0002530 @iter7540) ([92m↓6.14%[0m) [0.15% of initial]
[Iter 6570/20000] Loss: 0.0005553 (Best: 0.0004261 @iter6568) ([91m↑17.45%[0m) [0.22% of initial]
[Iter 8220/20000] Loss: 0.0003851 (Best: 0.0002530 @iter7540) ([91m↑1.63%[0m) [0.15% of initial]
[Iter 8230/20000] Loss: 0.0003861 (Best: 0.0002530 @iter7540) ([91m↑0.26%[0m) [0.15% of initial]
[Iter 6580/20000] Loss: 0.0005493 (Best: 0.0004261 @iter6568) ([92m↓1.07%[0m) [0.22% of initial]
[Iter 8240/20000] Loss: 0.0003883 (Best: 0.0002530 @iter7540) ([91m↑0.57%[0m) [0.15% of initial]
[Iter 6590/20000] Loss: 0.0004774 (Best: 0.0004261 @iter6568) ([92m↓13.08%[0m) [0.19% of initial]
[Iter 8250/20000] Loss: 0.0004288 (Best: 0.0002530 @iter7540) ([91m↑10.43%[0m) [0.17% of initial]
[Iter 8260/20000] Loss: 0.0004003 (Best: 0.0002530 @iter7540) ([92m↓6.65%[0m) [0.16% of initial]
Iter:6599, L1 loss=0.0005446, Total loss=0.0004853, Time:160
[Iter 6600/20000] Loss: 0.0005013 (Best: 0.0004261 @iter6568) ([91m↑5.00%[0m) [0.20% of initial]
[Iter 8270/20000] Loss: 0.0004103 (Best: 0.0002530 @iter7540) ([91m↑2.50%[0m) [0.16% of initial]
[Iter 8280/20000] Loss: 0.0003961 (Best: 0.0002530 @iter7540) ([92m↓3.46%[0m) [0.16% of initial]
[Iter 6610/20000] Loss: 0.0012656 (Best: 0.0004261 @iter6568) ([91m↑152.45%[0m) [0.50% of initial]
[Iter 8290/20000] Loss: 0.0004190 (Best: 0.0002530 @iter7540) ([91m↑5.78%[0m) [0.17% of initial]
Iter:8299, L1 loss=0.0004464, Total loss=0.0003818, Time:195
[Iter 8300/20000] Loss: 0.0004018 (Best: 0.0002530 @iter7540) ([92m↓4.12%[0m) [0.16% of initial]
[Iter 6620/20000] Loss: 0.0008998 (Best: 0.0004261 @iter6568) ([92m↓28.90%[0m) [0.36% of initial]
[Iter 8310/20000] Loss: 0.0003904 (Best: 0.0002530 @iter7540) ([92m↓2.83%[0m) [0.16% of initial]
[Iter 6630/20000] Loss: 0.0006685 (Best: 0.0004261 @iter6568) ([92m↓25.70%[0m) [0.27% of initial]
[Iter 8320/20000] Loss: 0.0003486 (Best: 0.0002530 @iter7540) ([92m↓10.71%[0m) [0.14% of initial]
[Iter 8330/20000] Loss: 0.0003432 (Best: 0.0002530 @iter7540) ([92m↓1.53%[0m) [0.14% of initial]
[Iter 6640/20000] Loss: 0.0005632 (Best: 0.0004261 @iter6568) ([92m↓15.76%[0m) [0.22% of initial]
[Iter 8340/20000] Loss: 0.0003594 (Best: 0.0002530 @iter7540) ([91m↑4.72%[0m) [0.14% of initial]
[Iter 6650/20000] Loss: 0.0005350 (Best: 0.0004261 @iter6568) ([92m↓5.00%[0m) [0.21% of initial]
[Iter 8350/20000] Loss: 0.0003137 (Best: 0.0002530 @iter7540) ([92m↓12.72%[0m) [0.12% of initial]
[Iter 8360/20000] Loss: 0.0003177 (Best: 0.0002530 @iter7540) ([91m↑1.27%[0m) [0.13% of initial]
[Iter 6660/20000] Loss: 0.0005900 (Best: 0.0004261 @iter6568) ([91m↑10.27%[0m) [0.23% of initial]
[Iter 8370/20000] Loss: 0.0003089 (Best: 0.0002530 @iter7540) ([92m↓2.78%[0m) [0.12% of initial]
[Iter 8380/20000] Loss: 0.0003227 (Best: 0.0002530 @iter7540) ([91m↑4.48%[0m) [0.13% of initial]
[Iter 6670/20000] Loss: 0.0005726 (Best: 0.0004261 @iter6568) ([92m↓2.94%[0m) [0.23% of initial]
[Iter 8390/20000] Loss: 0.0002876 (Best: 0.0002530 @iter7540) ([92m↓10.90%[0m) [0.11% of initial]
[Iter 6680/20000] Loss: 0.0005999 (Best: 0.0004261 @iter6568) ([91m↑4.76%[0m) [0.24% of initial]
Iter:8399, L1 loss=0.0003502, Total loss=0.0003049, Time:186
[Iter 8400/20000] Loss: 0.0003302 (Best: 0.0002530 @iter7540) ([91m↑14.83%[0m) [0.13% of initial]
[Iter 8410/20000] Loss: 0.0003121 (Best: 0.0002530 @iter7540) ([92m↓5.48%[0m) [0.12% of initial]
[Iter 6690/20000] Loss: 0.0005481 (Best: 0.0004261 @iter6568) ([92m↓8.63%[0m) [0.22% of initial]
[Iter 8420/20000] Loss: 0.0003101 (Best: 0.0002530 @iter7540) ([92m↓0.64%[0m) [0.12% of initial]
Iter:6699, L1 loss=0.0006154, Total loss=0.0005624, Time:151
[Iter 6700/20000] Loss: 0.0005270 (Best: 0.0004261 @iter6568) ([92m↓3.85%[0m) [0.21% of initial]
[Iter 8430/20000] Loss: 0.0003402 (Best: 0.0002530 @iter7540) ([91m↑9.69%[0m) [0.14% of initial]
[Iter 8440/20000] Loss: 0.0003167 (Best: 0.0002530 @iter7540) ([92m↓6.89%[0m) [0.13% of initial]
[Iter 6710/20000] Loss: 0.0005800 (Best: 0.0004261 @iter6568) ([91m↑10.05%[0m) [0.23% of initial]
[Iter 8450/20000] Loss: 0.0003449 (Best: 0.0002530 @iter7540) ([91m↑8.90%[0m) [0.14% of initial]
[Iter 8460/20000] Loss: 0.0003224 (Best: 0.0002530 @iter7540) ([92m↓6.53%[0m) [0.13% of initial]
[Iter 6720/20000] Loss: 0.0005225 (Best: 0.0004261 @iter6568) ([92m↓9.91%[0m) [0.21% of initial]
[Iter 8470/20000] Loss: 0.0003360 (Best: 0.0002530 @iter7540) ([91m↑4.22%[0m) [0.13% of initial]
[Iter 6730/20000] Loss: 0.0004682 (Best: 0.0004261 @iter6568) ([92m↓10.39%[0m) [0.19% of initial]
[Iter 8480/20000] Loss: 0.0003149 (Best: 0.0002530 @iter7540) ([92m↓6.29%[0m) [0.13% of initial]
[Iter 8490/20000] Loss: 0.0003360 (Best: 0.0002530 @iter7540) ([91m↑6.72%[0m) [0.13% of initial]
[Iter 6740/20000] Loss: 0.0005055 (Best: 0.0004238 @iter6731) ([91m↑7.98%[0m) [0.20% of initial]
Iter:8499, L1 loss=0.0004188, Total loss=0.0003786, Time:171
[Iter 8500/20000] Loss: 0.0003743 (Best: 0.0002530 @iter7540) ([91m↑11.38%[0m) [0.15% of initial]
[Iter 8510/20000] Loss: 0.0003640 (Best: 0.0002530 @iter7540) ([92m↓2.75%[0m) [0.14% of initial]
[Iter 6750/20000] Loss: 0.0005111 (Best: 0.0004238 @iter6731) ([91m↑1.09%[0m) [0.20% of initial]
[Iter 8520/20000] Loss: 0.0003628 (Best: 0.0002530 @iter7540) ([92m↓0.32%[0m) [0.14% of initial]
[Iter 6760/20000] Loss: 0.0004771 (Best: 0.0004208 @iter6757) ([92m↓6.64%[0m) [0.19% of initial]
[Iter 8530/20000] Loss: 0.0003167 (Best: 0.0002530 @iter7540) ([92m↓12.71%[0m) [0.13% of initial]
[Iter 8540/20000] Loss: 0.0003209 (Best: 0.0002530 @iter7540) ([91m↑1.32%[0m) [0.13% of initial]
[Iter 6770/20000] Loss: 0.0004717 (Best: 0.0004208 @iter6757) ([92m↓1.14%[0m) [0.19% of initial]
[Iter 8550/20000] Loss: 0.0003139 (Best: 0.0002530 @iter7540) ([92m↓2.18%[0m) [0.12% of initial]
[Iter 6780/20000] Loss: 0.0004380 (Best: 0.0004191 @iter6780) ([92m↓7.15%[0m) [0.17% of initial]
[Iter 8560/20000] Loss: 0.0003180 (Best: 0.0002530 @iter7540) ([91m↑1.29%[0m) [0.13% of initial]
[Iter 8570/20000] Loss: 0.0003266 (Best: 0.0002530 @iter7540) ([91m↑2.70%[0m) [0.13% of initial]
[Iter 6790/20000] Loss: 0.0004944 (Best: 0.0003819 @iter6781) ([91m↑12.88%[0m) [0.20% of initial]
[Iter 8580/20000] Loss: 0.0003173 (Best: 0.0002530 @iter7540) ([92m↓2.84%[0m) [0.13% of initial]
Iter:6799, L1 loss=0.0004636, Total loss=0.0004188, Time:156
[Iter 8590/20000] Loss: 0.0003027 (Best: 0.0002530 @iter7540) ([92m↓4.60%[0m) [0.12% of initial]
[Iter 6800/20000] Loss: 0.0004339 (Best: 0.0003819 @iter6781) ([92m↓12.24%[0m) [0.17% of initial]
Iter:8599, L1 loss=0.0003085, Total loss=0.0002633, Time:191
[Iter 8600/20000] Loss: 0.0002907 (Best: 0.0002530 @iter7540) ([92m↓3.96%[0m) [0.12% of initial]
[Iter 8610/20000] Loss: 0.0003042 (Best: 0.0002530 @iter7540) ([91m↑4.65%[0m) [0.12% of initial]
[Iter 6810/20000] Loss: 0.0013053 (Best: 0.0003819 @iter6781) ([91m↑200.86%[0m) [0.52% of initial]
[Iter 8620/20000] Loss: 0.0003000 (Best: 0.0002530 @iter7540) ([92m↓1.39%[0m) [0.12% of initial]
[Iter 6820/20000] Loss: 0.0009680 (Best: 0.0003819 @iter6781) ([92m↓25.84%[0m) [0.38% of initial]
[Iter 8630/20000] Loss: 0.0002996 (Best: 0.0002530 @iter7540) ([92m↓0.12%[0m) [0.12% of initial]
[Iter 8640/20000] Loss: 0.0002821 (Best: 0.0002530 @iter7540) ([92m↓5.84%[0m) [0.11% of initial]
[Iter 6830/20000] Loss: 0.0006818 (Best: 0.0003819 @iter6781) ([92m↓29.57%[0m) [0.27% of initial]
[Iter 8650/20000] Loss: 0.0002811 (Best: 0.0002476 @iter8644) ([92m↓0.37%[0m) [0.11% of initial]
[Iter 8660/20000] Loss: 0.0003319 (Best: 0.0002476 @iter8644) ([91m↑18.09%[0m) [0.13% of initial]
[Iter 6840/20000] Loss: 0.0005818 (Best: 0.0003819 @iter6781) ([92m↓14.66%[0m) [0.23% of initial]
[Iter 8670/20000] Loss: 0.0003299 (Best: 0.0002476 @iter8644) ([92m↓0.62%[0m) [0.13% of initial]
[Iter 6850/20000] Loss: 0.0005587 (Best: 0.0003819 @iter6781) ([92m↓3.98%[0m) [0.22% of initial]
[Iter 8680/20000] Loss: 0.0003043 (Best: 0.0002476 @iter8644) ([92m↓7.76%[0m) [0.12% of initial]
[Iter 8690/20000] Loss: 0.0003718 (Best: 0.0002476 @iter8644) ([91m↑22.19%[0m) [0.15% of initial]
[Iter 6860/20000] Loss: 0.0005207 (Best: 0.0003819 @iter6781) ([92m↓6.80%[0m) [0.21% of initial]
Iter:8699, L1 loss=0.0003667, Total loss=0.0003197, Time:183
[Iter 8700/20000] Loss: 0.0003269 (Best: 0.0002476 @iter8644) ([92m↓12.06%[0m) [0.13% of initial]
[Iter 8710/20000] Loss: 0.0003106 (Best: 0.0002476 @iter8644) ([92m↓5.01%[0m) [0.12% of initial]
[Iter 6870/20000] Loss: 0.0005050 (Best: 0.0003819 @iter6781) ([92m↓3.02%[0m) [0.20% of initial]
[Iter 8720/20000] Loss: 0.0003015 (Best: 0.0002476 @iter8644) ([92m↓2.90%[0m) [0.12% of initial]
[Iter 6880/20000] Loss: 0.0004814 (Best: 0.0003819 @iter6781) ([92m↓4.67%[0m) [0.19% of initial]
[Iter 8730/20000] Loss: 0.0003240 (Best: 0.0002476 @iter8644) ([91m↑7.44%[0m) [0.13% of initial]
[Iter 8740/20000] Loss: 0.0002985 (Best: 0.0002476 @iter8644) ([92m↓7.87%[0m) [0.12% of initial]
[Iter 6890/20000] Loss: 0.0005657 (Best: 0.0003819 @iter6781) ([91m↑17.52%[0m) [0.22% of initial]
[Iter 8750/20000] Loss: 0.0003672 (Best: 0.0002476 @iter8644) ([91m↑23.03%[0m) [0.15% of initial]
Iter:6899, L1 loss=0.0006178, Total loss=0.0005793, Time:183
[Iter 6900/20000] Loss: 0.0005692 (Best: 0.0003819 @iter6781) ([91m↑0.62%[0m) [0.23% of initial]
[Iter 8760/20000] Loss: 0.0003319 (Best: 0.0002476 @iter8644) ([92m↓9.63%[0m) [0.13% of initial]
[Iter 8770/20000] Loss: 0.0003378 (Best: 0.0002476 @iter8644) ([91m↑1.78%[0m) [0.13% of initial]
[Iter 6910/20000] Loss: 0.0005816 (Best: 0.0003819 @iter6781) ([91m↑2.17%[0m) [0.23% of initial]
[Iter 8780/20000] Loss: 0.0003353 (Best: 0.0002476 @iter8644) ([92m↓0.72%[0m) [0.13% of initial]
[Iter 8790/20000] Loss: 0.0003301 (Best: 0.0002476 @iter8644) ([92m↓1.56%[0m) [0.13% of initial]
[Iter 6920/20000] Loss: 0.0005131 (Best: 0.0003819 @iter6781) ([92m↓11.78%[0m) [0.20% of initial]
Iter:8799, L1 loss=0.0004091, Total loss=0.000365, Time:145
[Iter 8800/20000] Loss: 0.0003282 (Best: 0.0002476 @iter8644) ([92m↓0.59%[0m) [0.13% of initial]
[Iter 6930/20000] Loss: 0.0005128 (Best: 0.0003819 @iter6781) ([92m↓0.05%[0m) [0.20% of initial]
[Iter 8810/20000] Loss: 0.0002859 (Best: 0.0002476 @iter8644) ([92m↓12.86%[0m) [0.11% of initial]
[Iter 8820/20000] Loss: 0.0003503 (Best: 0.0002476 @iter8644) ([91m↑22.50%[0m) [0.14% of initial]
[Iter 6940/20000] Loss: 0.0004547 (Best: 0.0003819 @iter6781) ([92m↓11.33%[0m) [0.18% of initial]
[Iter 8830/20000] Loss: 0.0004200 (Best: 0.0002476 @iter8644) ([91m↑19.90%[0m) [0.17% of initial]
[Iter 8840/20000] Loss: 0.0003846 (Best: 0.0002476 @iter8644) ([92m↓8.42%[0m) [0.15% of initial]
[Iter 6950/20000] Loss: 0.0004519 (Best: 0.0003819 @iter6781) ([92m↓0.62%[0m) [0.18% of initial]
[Iter 8850/20000] Loss: 0.0003950 (Best: 0.0002476 @iter8644) ([91m↑2.69%[0m) [0.16% of initial]
[Iter 6960/20000] Loss: 0.0004325 (Best: 0.0003819 @iter6781) ([92m↓4.30%[0m) [0.17% of initial]
[Iter 8860/20000] Loss: 0.0003209 (Best: 0.0002476 @iter8644) ([92m↓18.75%[0m) [0.13% of initial]
[Iter 8870/20000] Loss: 0.0002965 (Best: 0.0002476 @iter8644) ([92m↓7.62%[0m) [0.12% of initial]
[Iter 6970/20000] Loss: 0.0005165 (Best: 0.0003819 @iter6781) ([91m↑19.43%[0m) [0.21% of initial]
[Iter 8880/20000] Loss: 0.0002985 (Best: 0.0002476 @iter8644) ([91m↑0.70%[0m) [0.12% of initial]
[Iter 6980/20000] Loss: 0.0005274 (Best: 0.0003819 @iter6781) ([91m↑2.10%[0m) [0.21% of initial]
[Iter 8890/20000] Loss: 0.0002828 (Best: 0.0002476 @iter8644) ([92m↓5.26%[0m) [0.11% of initial]
Iter:8899, L1 loss=0.0003286, Total loss=0.0002797, Time:192
[Iter 8900/20000] Loss: 0.0003112 (Best: 0.0002476 @iter8644) ([91m↑10.03%[0m) [0.12% of initial]
[Iter 6990/20000] Loss: 0.0004759 (Best: 0.0003819 @iter6781) ([92m↓9.76%[0m) [0.19% of initial]
[Iter 8910/20000] Loss: 0.0003177 (Best: 0.0002476 @iter8644) ([91m↑2.11%[0m) [0.13% of initial]
Iter:6999, L1 loss=0.0006042, Total loss=0.0005618, Time:168
[Iter 8920/20000] Loss: 0.0003023 (Best: 0.0002476 @iter8644) ([92m↓4.87%[0m) [0.12% of initial]
[Iter 7000/20000] Loss: 0.0004705 (Best: 0.0003819 @iter6781) ([92m↓1.13%[0m) [0.19% of initial]
[Iter 8930/20000] Loss: 0.0003125 (Best: 0.0002476 @iter8644) ([91m↑3.37%[0m) [0.12% of initial]
Pruning 61 points (0.0%) from gaussian0 at iteration 7000
Pruning 76 points (0.0%) from gaussian1 at iteration 7000
[Iter 8940/20000] Loss: 0.0003102 (Best: 0.0002476 @iter8644) ([92m↓0.72%[0m) [0.12% of initial]
[Iter 8950/20000] Loss: 0.0003423 (Best: 0.0002476 @iter8644) ([91m↑10.35%[0m) [0.14% of initial]
[Iter 7010/20000] Loss: 0.0014724 (Best: 0.0003819 @iter6781) ([91m↑212.92%[0m) [0.58% of initial]
[Iter 8960/20000] Loss: 0.0003365 (Best: 0.0002476 @iter8644) ([92m↓1.71%[0m) [0.13% of initial]
[Iter 7020/20000] Loss: 0.0009736 (Best: 0.0003819 @iter6781) ([92m↓33.88%[0m) [0.39% of initial]
[Iter 8970/20000] Loss: 0.0003837 (Best: 0.0002476 @iter8644) ([91m↑14.04%[0m) [0.15% of initial]
[Iter 8980/20000] Loss: 0.0003586 (Best: 0.0002476 @iter8644) ([92m↓6.54%[0m) [0.14% of initial]
[Iter 7030/20000] Loss: 0.0007003 (Best: 0.0003819 @iter6781) ([92m↓28.07%[0m) [0.28% of initial]
[Iter 8990/20000] Loss: 0.0003239 (Best: 0.0002476 @iter8644) ([92m↓9.68%[0m) [0.13% of initial]
Iter:8999, L1 loss=0.0003159, Total loss=0.0002719, Time:193
[Iter 9000/20000] Loss: 0.0003002 (Best: 0.0002476 @iter8644) ([92m↓7.31%[0m) [0.12% of initial]
[Iter 7040/20000] Loss: 0.0005652 (Best: 0.0003819 @iter6781) ([92m↓19.29%[0m) [0.22% of initial]
[Iter 9010/20000] Loss: 0.0003232 (Best: 0.0002476 @iter8644) ([91m↑7.66%[0m) [0.13% of initial]
[Iter 7050/20000] Loss: 0.0005374 (Best: 0.0003819 @iter6781) ([92m↓4.92%[0m) [0.21% of initial]
[Iter 9020/20000] Loss: 0.0003179 (Best: 0.0002476 @iter8644) ([92m↓1.64%[0m) [0.13% of initial]
[Iter 9030/20000] Loss: 0.0003027 (Best: 0.0002476 @iter8644) ([92m↓4.78%[0m) [0.12% of initial]
[Iter 7060/20000] Loss: 0.0005622 (Best: 0.0003819 @iter6781) ([91m↑4.63%[0m) [0.22% of initial]
[Iter 9040/20000] Loss: 0.0002949 (Best: 0.0002476 @iter8644) ([92m↓2.57%[0m) [0.12% of initial]
[Iter 9050/20000] Loss: 0.0002932 (Best: 0.0002476 @iter8644) ([92m↓0.58%[0m) [0.12% of initial]
[Iter 7070/20000] Loss: 0.0005067 (Best: 0.0003819 @iter6781) ([92m↓9.88%[0m) [0.20% of initial]
[Iter 9060/20000] Loss: 0.0003157 (Best: 0.0002476 @iter8644) ([91m↑7.66%[0m) [0.13% of initial]
[Iter 7080/20000] Loss: 0.0005174 (Best: 0.0003819 @iter6781) ([91m↑2.11%[0m) [0.21% of initial]
[Iter 9070/20000] Loss: 0.0003438 (Best: 0.0002476 @iter8644) ([91m↑8.91%[0m) [0.14% of initial]
[Iter 9080/20000] Loss: 0.0003626 (Best: 0.0002476 @iter8644) ([91m↑5.48%[0m) [0.14% of initial]
[Iter 7090/20000] Loss: 0.0005465 (Best: 0.0003819 @iter6781) ([91m↑5.62%[0m) [0.22% of initial]
[Iter 9090/20000] Loss: 0.0003357 (Best: 0.0002476 @iter8644) ([92m↓7.41%[0m) [0.13% of initial]
Iter:7099, L1 loss=0.0005125, Total loss=0.0004701, Time:167
Iter:9099, L1 loss=0.0004444, Total loss=0.0003877, Time:176
[Iter 7100/20000] Loss: 0.0004978 (Best: 0.0003819 @iter6781) ([92m↓8.90%[0m) [0.20% of initial]
[Iter 9100/20000] Loss: 0.0003433 (Best: 0.0002476 @iter8644) ([91m↑2.26%[0m) [0.14% of initial]
[Iter 9110/20000] Loss: 0.0003895 (Best: 0.0002476 @iter8644) ([91m↑13.46%[0m) [0.15% of initial]
[Iter 7110/20000] Loss: 0.0005121 (Best: 0.0003819 @iter6781) ([91m↑2.86%[0m) [0.20% of initial]
[Iter 9120/20000] Loss: 0.0003330 (Best: 0.0002476 @iter8644) ([92m↓14.51%[0m) [0.13% of initial]
[Iter 9130/20000] Loss: 0.0003831 (Best: 0.0002476 @iter8644) ([91m↑15.04%[0m) [0.15% of initial]
[Iter 7120/20000] Loss: 0.0004814 (Best: 0.0003819 @iter6781) ([92m↓5.99%[0m) [0.19% of initial]
[Iter 9140/20000] Loss: 0.0003419 (Best: 0.0002476 @iter8644) ([92m↓10.75%[0m) [0.14% of initial]
[Iter 7130/20000] Loss: 0.0004686 (Best: 0.0003819 @iter6781) ([92m↓2.65%[0m) [0.19% of initial]
[Iter 9150/20000] Loss: 0.0003085 (Best: 0.0002476 @iter8644) ([92m↓9.78%[0m) [0.12% of initial]
[Iter 9160/20000] Loss: 0.0003117 (Best: 0.0002476 @iter8644) ([91m↑1.05%[0m) [0.12% of initial]
[Iter 7140/20000] Loss: 0.0005449 (Best: 0.0003819 @iter6781) ([91m↑16.29%[0m) [0.22% of initial]
[Iter 9170/20000] Loss: 0.0002917 (Best: 0.0002476 @iter8644) ([92m↓6.42%[0m) [0.12% of initial]
[Iter 7150/20000] Loss: 0.0004987 (Best: 0.0003819 @iter6781) ([92m↓8.48%[0m) [0.20% of initial]
[Iter 9180/20000] Loss: 0.0003070 (Best: 0.0002476 @iter8644) ([91m↑5.24%[0m) [0.12% of initial]
[Iter 9190/20000] Loss: 0.0002638 (Best: 0.0002476 @iter8644) ([92m↓14.07%[0m) [0.10% of initial]
[Iter 7160/20000] Loss: 0.0004906 (Best: 0.0003819 @iter6781) ([92m↓1.64%[0m) [0.19% of initial]
Iter:9199, L1 loss=0.0003296, Total loss=0.0002899, Time:154
[Iter 9200/20000] Loss: 0.0002927 (Best: 0.0002476 @iter8644) ([91m↑10.95%[0m) [0.12% of initial]
[Iter 9210/20000] Loss: 0.0003000 (Best: 0.0002476 @iter8644) ([91m↑2.50%[0m) [0.12% of initial]
[Iter 7170/20000] Loss: 0.0005010 (Best: 0.0003819 @iter6781) ([91m↑2.13%[0m) [0.20% of initial]
[Iter 9220/20000] Loss: 0.0003037 (Best: 0.0002476 @iter8644) ([91m↑1.24%[0m) [0.12% of initial]
[Iter 7180/20000] Loss: 0.0005108 (Best: 0.0003819 @iter6781) ([91m↑1.95%[0m) [0.20% of initial]
[Iter 9230/20000] Loss: 0.0003009 (Best: 0.0002476 @iter8644) ([92m↓0.92%[0m) [0.12% of initial]
[Iter 9240/20000] Loss: 0.0003023 (Best: 0.0002476 @iter8644) ([91m↑0.46%[0m) [0.12% of initial]
[Iter 7190/20000] Loss: 0.0004376 (Best: 0.0003819 @iter6781) ([92m↓14.33%[0m) [0.17% of initial]
[Iter 9250/20000] Loss: 0.0002999 (Best: 0.0002476 @iter8644) ([92m↓0.80%[0m) [0.12% of initial]
Iter:7199, L1 loss=0.0004956, Total loss=0.0004595, Time:173
[Iter 9260/20000] Loss: 0.0003033 (Best: 0.0002476 @iter8644) ([91m↑1.14%[0m) [0.12% of initial]
[Iter 7200/20000] Loss: 0.0004657 (Best: 0.0003819 @iter6781) ([91m↑6.41%[0m) [0.19% of initial]
[Iter 9270/20000] Loss: 0.0003271 (Best: 0.0002476 @iter8644) ([91m↑7.87%[0m) [0.13% of initial]
[Iter 9280/20000] Loss: 0.0002766 (Best: 0.0002476 @iter8644) ([92m↓15.46%[0m) [0.11% of initial]
[Iter 7210/20000] Loss: 0.0012967 (Best: 0.0003819 @iter6781) ([91m↑178.46%[0m) [0.52% of initial]
[Iter 9290/20000] Loss: 0.0002718 (Best: 0.0002399 @iter9289) ([92m↓1.74%[0m) [0.11% of initial]
[Iter 7220/20000] Loss: 0.0010151 (Best: 0.0003819 @iter6781) ([92m↓21.71%[0m) [0.40% of initial]
Iter:9299, L1 loss=0.000305, Total loss=0.0002552, Time:221
[Iter 9300/20000] Loss: 0.0002926 (Best: 0.0002399 @iter9289) ([91m↑7.65%[0m) [0.12% of initial]
[Iter 9310/20000] Loss: 0.0003029 (Best: 0.0002399 @iter9289) ([91m↑3.53%[0m) [0.12% of initial]
[Iter 7230/20000] Loss: 0.0007589 (Best: 0.0003819 @iter6781) ([92m↓25.24%[0m) [0.30% of initial]
[Iter 9320/20000] Loss: 0.0003099 (Best: 0.0002399 @iter9289) ([91m↑2.30%[0m) [0.12% of initial]
[Iter 9330/20000] Loss: 0.0003529 (Best: 0.0002399 @iter9289) ([91m↑13.90%[0m) [0.14% of initial]
[Iter 7240/20000] Loss: 0.0006095 (Best: 0.0003819 @iter6781) ([92m↓19.68%[0m) [0.24% of initial]
[Iter 9340/20000] Loss: 0.0003551 (Best: 0.0002399 @iter9289) ([91m↑0.62%[0m) [0.14% of initial]
[Iter 7250/20000] Loss: 0.0005145 (Best: 0.0003819 @iter6781) ([92m↓15.59%[0m) [0.20% of initial]
[Iter 9350/20000] Loss: 0.0003134 (Best: 0.0002399 @iter9289) ([92m↓11.76%[0m) [0.12% of initial]
[Iter 9360/20000] Loss: 0.0003370 (Best: 0.0002399 @iter9289) ([91m↑7.55%[0m) [0.13% of initial]
[Iter 7260/20000] Loss: 0.0004790 (Best: 0.0003819 @iter6781) ([92m↓6.89%[0m) [0.19% of initial]
[Iter 9370/20000] Loss: 0.0002911 (Best: 0.0002399 @iter9289) ([92m↓13.63%[0m) [0.12% of initial]
[Iter 7270/20000] Loss: 0.0004497 (Best: 0.0003819 @iter6781) ([92m↓6.13%[0m) [0.18% of initial]
[Iter 9380/20000] Loss: 0.0003118 (Best: 0.0002399 @iter9289) ([91m↑7.11%[0m) [0.12% of initial]
[Iter 9390/20000] Loss: 0.0003116 (Best: 0.0002399 @iter9289) ([92m↓0.07%[0m) [0.12% of initial]
[Iter 7280/20000] Loss: 0.0004333 (Best: 0.0003730 @iter7276) ([92m↓3.64%[0m) [0.17% of initial]
Iter:9399, L1 loss=0.0004216, Total loss=0.000386, Time:216
[Iter 9400/20000] Loss: 0.0003119 (Best: 0.0002399 @iter9289) ([91m↑0.10%[0m) [0.12% of initial]
[Iter 9410/20000] Loss: 0.0003086 (Best: 0.0002399 @iter9289) ([92m↓1.05%[0m) [0.12% of initial]
[Iter 7290/20000] Loss: 0.0004565 (Best: 0.0003730 @iter7276) ([91m↑5.37%[0m) [0.18% of initial]
[Iter 9420/20000] Loss: 0.0003159 (Best: 0.0002399 @iter9289) ([91m↑2.38%[0m) [0.13% of initial]
Iter:7299, L1 loss=0.0005684, Total loss=0.0005381, Time:181
[Iter 7300/20000] Loss: 0.0004750 (Best: 0.0003730 @iter7276) ([91m↑4.05%[0m) [0.19% of initial]
[Iter 9430/20000] Loss: 0.0002750 (Best: 0.0002399 @iter9289) ([92m↓12.95%[0m) [0.11% of initial]
[Iter 9440/20000] Loss: 0.0003133 (Best: 0.0002399 @iter9289) ([91m↑13.92%[0m) [0.12% of initial]
[Iter 7310/20000] Loss: 0.0004605 (Best: 0.0003730 @iter7276) ([92m↓3.05%[0m) [0.18% of initial]
[Iter 9450/20000] Loss: 0.0002920 (Best: 0.0002399 @iter9289) ([92m↓6.80%[0m) [0.12% of initial]
[Iter 9460/20000] Loss: 0.0002505 (Best: 0.0002341 @iter9457) ([92m↓14.22%[0m) [0.10% of initial]
[Iter 7320/20000] Loss: 0.0005401 (Best: 0.0003730 @iter7276) ([91m↑17.27%[0m) [0.21% of initial]
[Iter 9470/20000] Loss: 0.0002486 (Best: 0.0002315 @iter9466) ([92m↓0.73%[0m) [0.10% of initial]
[Iter 7330/20000] Loss: 0.0005171 (Best: 0.0003730 @iter7276) ([92m↓4.25%[0m) [0.21% of initial]
[Iter 9480/20000] Loss: 0.0003177 (Best: 0.0002315 @iter9466) ([91m↑27.80%[0m) [0.13% of initial]
[Iter 9490/20000] Loss: 0.0002774 (Best: 0.0002315 @iter9466) ([92m↓12.69%[0m) [0.11% of initial]
[Iter 7340/20000] Loss: 0.0004675 (Best: 0.0003730 @iter7276) ([92m↓9.61%[0m) [0.19% of initial]
Iter:9499, L1 loss=0.000332, Total loss=0.0002822, Time:201
[Iter 9500/20000] Loss: 0.0004657 (Best: 0.0002315 @iter9466) ([91m↑67.87%[0m) [0.19% of initial]
[Iter 7350/20000] Loss: 0.0005184 (Best: 0.0003730 @iter7276) ([91m↑10.91%[0m) [0.21% of initial]
[Iter 9510/20000] Loss: 0.0003160 (Best: 0.0002315 @iter9466) ([92m↓32.14%[0m) [0.13% of initial]
[Iter 9520/20000] Loss: 0.0003044 (Best: 0.0002315 @iter9466) ([92m↓3.68%[0m) [0.12% of initial]
[Iter 7360/20000] Loss: 0.0005112 (Best: 0.0003730 @iter7276) ([92m↓1.39%[0m) [0.20% of initial]
[Iter 9530/20000] Loss: 0.0004364 (Best: 0.0002315 @iter9466) ([91m↑43.38%[0m) [0.17% of initial]
[Iter 9540/20000] Loss: 0.0003473 (Best: 0.0002315 @iter9466) ([92m↓20.41%[0m) [0.14% of initial]
[Iter 7370/20000] Loss: 0.0004490 (Best: 0.0003730 @iter7276) ([92m↓12.17%[0m) [0.18% of initial]
[Iter 9550/20000] Loss: 0.0002934 (Best: 0.0002315 @iter9466) ([92m↓15.53%[0m) [0.12% of initial]
[Iter 7380/20000] Loss: 0.0005884 (Best: 0.0003730 @iter7276) ([91m↑31.04%[0m) [0.23% of initial]
[Iter 9560/20000] Loss: 0.0002797 (Best: 0.0002315 @iter9466) ([92m↓4.68%[0m) [0.11% of initial]
[Iter 9570/20000] Loss: 0.0002722 (Best: 0.0002315 @iter9466) ([92m↓2.67%[0m) [0.11% of initial]
[Iter 7390/20000] Loss: 0.0006180 (Best: 0.0003730 @iter7276) ([91m↑5.03%[0m) [0.25% of initial]
[Iter 9580/20000] Loss: 0.0002593 (Best: 0.0002315 @iter9466) ([92m↓4.73%[0m) [0.10% of initial]
Iter:7399, L1 loss=0.0006319, Total loss=0.000544, Time:201
[Iter 7400/20000] Loss: 0.0005924 (Best: 0.0003730 @iter7276) ([92m↓4.14%[0m) [0.24% of initial]
[Iter 9590/20000] Loss: 0.0002540 (Best: 0.0002304 @iter9589) ([92m↓2.05%[0m) [0.10% of initial]
Iter:9599, L1 loss=0.0004194, Total loss=0.0003394, Time:224
[Iter 9600/20000] Loss: 0.0002904 (Best: 0.0002304 @iter9589) ([91m↑14.34%[0m) [0.12% of initial]
[Iter 9610/20000] Loss: 0.0002778 (Best: 0.0002304 @iter9589) ([92m↓4.34%[0m) [0.11% of initial]
[Iter 7410/20000] Loss: 0.0013457 (Best: 0.0003730 @iter7276) ([91m↑127.16%[0m) [0.53% of initial]
[Iter 9620/20000] Loss: 0.0002948 (Best: 0.0002304 @iter9589) ([91m↑6.11%[0m) [0.12% of initial]
[Iter 7420/20000] Loss: 0.0008834 (Best: 0.0003730 @iter7276) ([92m↓34.35%[0m) [0.35% of initial]
[Iter 9630/20000] Loss: 0.0002631 (Best: 0.0002241 @iter9628) ([92m↓10.74%[0m) [0.10% of initial]
[Iter 9640/20000] Loss: 0.0002495 (Best: 0.0002198 @iter9638) ([92m↓5.16%[0m) [0.10% of initial]
[Iter 7430/20000] Loss: 0.0007082 (Best: 0.0003730 @iter7276) ([92m↓19.83%[0m) [0.28% of initial]
[Iter 9650/20000] Loss: 0.0002996 (Best: 0.0002198 @iter9638) ([91m↑20.06%[0m) [0.12% of initial]
[Iter 9660/20000] Loss: 0.0002708 (Best: 0.0002198 @iter9638) ([92m↓9.61%[0m) [0.11% of initial]
[Iter 7440/20000] Loss: 0.0006299 (Best: 0.0003730 @iter7276) ([92m↓11.05%[0m) [0.25% of initial]
[Iter 9670/20000] Loss: 0.0003144 (Best: 0.0002198 @iter9638) ([91m↑16.11%[0m) [0.12% of initial]
[Iter 7450/20000] Loss: 0.0005635 (Best: 0.0003730 @iter7276) ([92m↓10.54%[0m) [0.22% of initial]
[Iter 9680/20000] Loss: 0.0003124 (Best: 0.0002198 @iter9638) ([92m↓0.65%[0m) [0.12% of initial]
[Iter 9690/20000] Loss: 0.0003472 (Best: 0.0002198 @iter9638) ([91m↑11.16%[0m) [0.14% of initial]
[Iter 7460/20000] Loss: 0.0005303 (Best: 0.0003730 @iter7276) ([92m↓5.90%[0m) [0.21% of initial]
Iter:9699, L1 loss=0.0004631, Total loss=0.0003983, Time:188
[Iter 9700/20000] Loss: 0.0003293 (Best: 0.0002198 @iter9638) ([92m↓5.17%[0m) [0.13% of initial]
[Iter 7470/20000] Loss: 0.0004858 (Best: 0.0003730 @iter7276) ([92m↓8.40%[0m) [0.19% of initial]
[Iter 9710/20000] Loss: 0.0003213 (Best: 0.0002198 @iter9638) ([92m↓2.44%[0m) [0.13% of initial]
[Iter 9720/20000] Loss: 0.0002888 (Best: 0.0002198 @iter9638) ([92m↓10.11%[0m) [0.11% of initial]
[Iter 7480/20000] Loss: 0.0004814 (Best: 0.0003730 @iter7276) ([92m↓0.91%[0m) [0.19% of initial]
[Iter 9730/20000] Loss: 0.0002726 (Best: 0.0002198 @iter9638) ([92m↓5.58%[0m) [0.11% of initial]
[Iter 9740/20000] Loss: 0.0002847 (Best: 0.0002198 @iter9638) ([91m↑4.44%[0m) [0.11% of initial]
[Iter 7490/20000] Loss: 0.0004175 (Best: 0.0003730 @iter7276) ([92m↓13.28%[0m) [0.17% of initial]
[Iter 9750/20000] Loss: 0.0002875 (Best: 0.0002198 @iter9638) ([91m↑0.98%[0m) [0.11% of initial]
Iter:7499, L1 loss=0.0005014, Total loss=0.000439, Time:211
[Iter 7500/20000] Loss: 0.0004587 (Best: 0.0003730 @iter7276) ([91m↑9.87%[0m) [0.18% of initial]
[Iter 9760/20000] Loss: 0.0002580 (Best: 0.0002198 @iter9638) ([92m↓10.29%[0m) [0.10% of initial]
Pruning 53 points (0.0%) from gaussian0 at iteration 7500
Pruning 41 points (0.0%) from gaussian1 at iteration 7500
[Iter 9770/20000] Loss: 0.0002617 (Best: 0.0002198 @iter9638) ([91m↑1.46%[0m) [0.10% of initial]
[Iter 9780/20000] Loss: 0.0002529 (Best: 0.0002198 @iter9638) ([92m↓3.36%[0m) [0.10% of initial]
[Iter 7510/20000] Loss: 0.0011685 (Best: 0.0003730 @iter7276) ([91m↑154.76%[0m) [0.46% of initial]
[Iter 9790/20000] Loss: 0.0002503 (Best: 0.0002157 @iter9784) ([92m↓1.03%[0m) [0.10% of initial]
Iter:9799, L1 loss=0.0003025, Total loss=0.0002514, Time:193
[Iter 7520/20000] Loss: 0.0007729 (Best: 0.0003730 @iter7276) ([92m↓33.86%[0m) [0.31% of initial]
[Iter 9800/20000] Loss: 0.0002764 (Best: 0.0002157 @iter9784) ([91m↑10.41%[0m) [0.11% of initial]
[Iter 9810/20000] Loss: 0.0002614 (Best: 0.0002157 @iter9784) ([92m↓5.44%[0m) [0.10% of initial]
[Iter 7530/20000] Loss: 0.0005885 (Best: 0.0003730 @iter7276) ([92m↓23.85%[0m) [0.23% of initial]
[Iter 9820/20000] Loss: 0.0002420 (Best: 0.0002157 @iter9784) ([92m↓7.42%[0m) [0.10% of initial]
[Iter 9830/20000] Loss: 0.0002603 (Best: 0.0002157 @iter9784) ([91m↑7.57%[0m) [0.10% of initial]
[Iter 7540/20000] Loss: 0.0004306 (Best: 0.0003730 @iter7276) ([92m↓26.83%[0m) [0.17% of initial]
[Iter 9840/20000] Loss: 0.0002727 (Best: 0.0002157 @iter9784) ([91m↑4.78%[0m) [0.11% of initial]
[Iter 7550/20000] Loss: 0.0004296 (Best: 0.0003730 @iter7276) ([92m↓0.23%[0m) [0.17% of initial]
[Iter 9850/20000] Loss: 0.0002473 (Best: 0.0002157 @iter9784) ([92m↓9.31%[0m) [0.10% of initial]
[Iter 9860/20000] Loss: 0.0002508 (Best: 0.0002157 @iter9784) ([91m↑1.40%[0m) [0.10% of initial]
[Iter 7560/20000] Loss: 0.0004169 (Best: 0.0003677 @iter7555) ([92m↓2.95%[0m) [0.17% of initial]
[Iter 9870/20000] Loss: 0.0002818 (Best: 0.0002157 @iter9784) ([91m↑12.37%[0m) [0.11% of initial]
[Iter 9880/20000] Loss: 0.0002893 (Best: 0.0002157 @iter9784) ([91m↑2.65%[0m) [0.11% of initial]
[Iter 7570/20000] Loss: 0.0004353 (Best: 0.0003637 @iter7561) ([91m↑4.41%[0m) [0.17% of initial]
[Iter 9890/20000] Loss: 0.0004201 (Best: 0.0002157 @iter9784) ([91m↑45.22%[0m) [0.17% of initial]
[Iter 7580/20000] Loss: 0.0004633 (Best: 0.0003637 @iter7561) ([91m↑6.44%[0m) [0.18% of initial]
Iter:9899, L1 loss=0.0004409, Total loss=0.000367, Time:183
[Iter 9900/20000] Loss: 0.0003531 (Best: 0.0002157 @iter9784) ([92m↓15.95%[0m) [0.14% of initial]
[Iter 9910/20000] Loss: 0.0002701 (Best: 0.0002157 @iter9784) ([92m↓23.49%[0m) [0.11% of initial]
[Iter 7590/20000] Loss: 0.0004803 (Best: 0.0003637 @iter7561) ([91m↑3.66%[0m) [0.19% of initial]
[Iter 9920/20000] Loss: 0.0002707 (Best: 0.0002157 @iter9784) ([91m↑0.21%[0m) [0.11% of initial]
Iter:7599, L1 loss=0.0004626, Total loss=0.0004091, Time:157
[Iter 7600/20000] Loss: 0.0004200 (Best: 0.0003637 @iter7561) ([92m↓12.55%[0m) [0.17% of initial]
[Iter 9930/20000] Loss: 0.0002853 (Best: 0.0002157 @iter9784) ([91m↑5.40%[0m) [0.11% of initial]
[Iter 9940/20000] Loss: 0.0002820 (Best: 0.0002157 @iter9784) ([92m↓1.17%[0m) [0.11% of initial]
[Iter 9950/20000] Loss: 0.0003241 (Best: 0.0002157 @iter9784) ([91m↑14.95%[0m) [0.13% of initial]
[Iter 7610/20000] Loss: 0.0013636 (Best: 0.0003637 @iter7561) ([91m↑224.69%[0m) [0.54% of initial]
[Iter 9960/20000] Loss: 0.0003295 (Best: 0.0002157 @iter9784) ([91m↑1.65%[0m) [0.13% of initial]
[Iter 7620/20000] Loss: 0.0008928 (Best: 0.0003637 @iter7561) ([92m↓34.52%[0m) [0.35% of initial]
[Iter 9970/20000] Loss: 0.0002930 (Best: 0.0002157 @iter9784) ([92m↓11.07%[0m) [0.12% of initial]
[Iter 9980/20000] Loss: 0.0002712 (Best: 0.0002157 @iter9784) ([92m↓7.44%[0m) [0.11% of initial]
[Iter 7630/20000] Loss: 0.0007409 (Best: 0.0003637 @iter7561) ([92m↓17.02%[0m) [0.29% of initial]
[Iter 9990/20000] Loss: 0.0002900 (Best: 0.0002157 @iter9784) ([91m↑6.94%[0m) [0.12% of initial]
Iter:9999, L1 loss=0.0004805, Total loss=0.0003875, Time:241
[Iter 10000/20000] Loss: 0.0003438 (Best: 0.0002157 @iter9784) ([91m↑18.52%[0m) [0.14% of initial]
[Iter 7640/20000] Loss: 0.0005957 (Best: 0.0003637 @iter7561) ([92m↓19.59%[0m) [0.24% of initial]
[Iter 10010/20000] Loss: 0.0003309 (Best: 0.0002157 @iter9784) ([92m↓3.74%[0m) [0.13% of initial]
[Iter 7650/20000] Loss: 0.0005250 (Best: 0.0003637 @iter7561) ([92m↓11.88%[0m) [0.21% of initial]
[Iter 10020/20000] Loss: 0.0003087 (Best: 0.0002157 @iter9784) ([92m↓6.72%[0m) [0.12% of initial]
[Iter 10030/20000] Loss: 0.0002728 (Best: 0.0002157 @iter9784) ([92m↓11.61%[0m) [0.11% of initial]
[Iter 7660/20000] Loss: 0.0004305 (Best: 0.0003637 @iter7561) ([92m↓18.00%[0m) [0.17% of initial]
[Iter 10040/20000] Loss: 0.0002748 (Best: 0.0002157 @iter9784) ([91m↑0.73%[0m) [0.11% of initial]
[Iter 7670/20000] Loss: 0.0004049 (Best: 0.0003637 @iter7561) ([92m↓5.95%[0m) [0.16% of initial]
[Iter 10050/20000] Loss: 0.0002655 (Best: 0.0002157 @iter9784) ([92m↓3.40%[0m) [0.11% of initial]
[Iter 10060/20000] Loss: 0.0002390 (Best: 0.0002157 @iter9784) ([92m↓9.97%[0m) [0.09% of initial]
[Iter 7680/20000] Loss: 0.0004364 (Best: 0.0003637 @iter7561) ([91m↑7.78%[0m) [0.17% of initial]
[Iter 10070/20000] Loss: 0.0002479 (Best: 0.0002157 @iter9784) ([91m↑3.71%[0m) [0.10% of initial]
[Iter 10080/20000] Loss: 0.0002529 (Best: 0.0002157 @iter9784) ([91m↑2.04%[0m) [0.10% of initial]
[Iter 7690/20000] Loss: 0.0004008 (Best: 0.0003590 @iter7690) ([92m↓8.16%[0m) [0.16% of initial]
[Iter 10090/20000] Loss: 0.0002482 (Best: 0.0002157 @iter9784) ([92m↓1.88%[0m) [0.10% of initial]
Iter:7699, L1 loss=0.0004165, Total loss=0.0003885, Time:155
[Iter 7700/20000] Loss: 0.0004100 (Best: 0.0003590 @iter7690) ([91m↑2.30%[0m) [0.16% of initial]
Iter:10099, L1 loss=0.0002984, Total loss=0.0002591, Time:161
[Iter 10100/20000] Loss: 0.0002772 (Best: 0.0002157 @iter9784) ([91m↑11.70%[0m) [0.11% of initial]
[Iter 10110/20000] Loss: 0.0002636 (Best: 0.0002157 @iter9784) ([92m↓4.90%[0m) [0.10% of initial]
[Iter 7710/20000] Loss: 0.0004226 (Best: 0.0003590 @iter7690) ([91m↑3.06%[0m) [0.17% of initial]
[Iter 10120/20000] Loss: 0.0002562 (Best: 0.0002157 @iter9784) ([92m↓2.81%[0m) [0.10% of initial]
[Iter 7720/20000] Loss: 0.0003969 (Best: 0.0003498 @iter7714) ([92m↓6.06%[0m) [0.16% of initial]
[Iter 10130/20000] Loss: 0.0002570 (Best: 0.0002157 @iter9784) ([91m↑0.31%[0m) [0.10% of initial]
[Iter 10140/20000] Loss: 0.0003059 (Best: 0.0002157 @iter9784) ([91m↑19.03%[0m) [0.12% of initial]
[Iter 7730/20000] Loss: 0.0003921 (Best: 0.0003428 @iter7726) ([92m↓1.22%[0m) [0.16% of initial]
[Iter 10150/20000] Loss: 0.0003010 (Best: 0.0002157 @iter9784) ([92m↓1.60%[0m) [0.12% of initial]
[Iter 10160/20000] Loss: 0.0003301 (Best: 0.0002157 @iter9784) ([91m↑9.65%[0m) [0.13% of initial]
[Iter 7740/20000] Loss: 0.0003888 (Best: 0.0003342 @iter7738) ([92m↓0.84%[0m) [0.15% of initial]
[Iter 10170/20000] Loss: 0.0002856 (Best: 0.0002157 @iter9784) ([92m↓13.48%[0m) [0.11% of initial]
[Iter 7750/20000] Loss: 0.0004283 (Best: 0.0003342 @iter7738) ([91m↑10.17%[0m) [0.17% of initial]
[Iter 10180/20000] Loss: 0.0002412 (Best: 0.0002157 @iter9784) ([92m↓15.53%[0m) [0.10% of initial]
[Iter 10190/20000] Loss: 0.0002232 (Best: 0.0002052 @iter10183) ([92m↓7.45%[0m) [0.09% of initial]
[Iter 7760/20000] Loss: 0.0004649 (Best: 0.0003342 @iter7738) ([91m↑8.55%[0m) [0.18% of initial]
Iter:10199, L1 loss=0.0003335, Total loss=0.000282, Time:218
[Iter 10200/20000] Loss: 0.0002572 (Best: 0.0002052 @iter10183) ([91m↑15.20%[0m) [0.10% of initial]
[Iter 10210/20000] Loss: 0.0002448 (Best: 0.0002052 @iter10183) ([92m↓4.81%[0m) [0.10% of initial]
[Iter 7770/20000] Loss: 0.0004455 (Best: 0.0003342 @iter7738) ([92m↓4.17%[0m) [0.18% of initial]
[Iter 10220/20000] Loss: 0.0002554 (Best: 0.0002052 @iter10183) ([91m↑4.34%[0m) [0.10% of initial]
[Iter 7780/20000] Loss: 0.0004370 (Best: 0.0003342 @iter7738) ([92m↓1.92%[0m) [0.17% of initial]
[Iter 10230/20000] Loss: 0.0002556 (Best: 0.0002052 @iter10183) ([91m↑0.07%[0m) [0.10% of initial]
[Iter 10240/20000] Loss: 0.0002390 (Best: 0.0002052 @iter10183) ([92m↓6.50%[0m) [0.09% of initial]
[Iter 7790/20000] Loss: 0.0004517 (Best: 0.0003342 @iter7738) ([91m↑3.37%[0m) [0.18% of initial]
[Iter 10250/20000] Loss: 0.0002508 (Best: 0.0002052 @iter10183) ([91m↑4.94%[0m) [0.10% of initial]
Iter:7799, L1 loss=0.0004393, Total loss=0.0003964, Time:178
[Iter 7800/20000] Loss: 0.0004525 (Best: 0.0003342 @iter7738) ([91m↑0.19%[0m) [0.18% of initial]
[Iter 10260/20000] Loss: 0.0002765 (Best: 0.0002052 @iter10183) ([91m↑10.26%[0m) [0.11% of initial]
[Iter 10270/20000] Loss: 0.0002518 (Best: 0.0002052 @iter10183) ([92m↓8.94%[0m) [0.10% of initial]
[Iter 10280/20000] Loss: 0.0002539 (Best: 0.0002052 @iter10183) ([91m↑0.85%[0m) [0.10% of initial]
[Iter 7810/20000] Loss: 0.0009983 (Best: 0.0003342 @iter7738) ([91m↑120.60%[0m) [0.40% of initial]
[Iter 10290/20000] Loss: 0.0002843 (Best: 0.0002052 @iter10183) ([91m↑11.96%[0m) [0.11% of initial]
[Iter 7820/20000] Loss: 0.0007566 (Best: 0.0003342 @iter7738) ([92m↓24.21%[0m) [0.30% of initial]
Iter:10299, L1 loss=0.0002805, Total loss=0.0002368, Time:219
[Iter 10300/20000] Loss: 0.0002503 (Best: 0.0002052 @iter10183) ([92m↓11.98%[0m) [0.10% of initial]
[Iter 10310/20000] Loss: 0.0002614 (Best: 0.0002052 @iter10183) ([91m↑4.44%[0m) [0.10% of initial]
[Iter 7830/20000] Loss: 0.0006452 (Best: 0.0003342 @iter7738) ([92m↓14.73%[0m) [0.26% of initial]
[Iter 10320/20000] Loss: 0.0002641 (Best: 0.0002052 @iter10183) ([91m↑1.05%[0m) [0.10% of initial]
[Iter 7840/20000] Loss: 0.0005537 (Best: 0.0003342 @iter7738) ([92m↓14.18%[0m) [0.22% of initial]
[Iter 10330/20000] Loss: 0.0002502 (Best: 0.0002052 @iter10183) ([92m↓5.26%[0m) [0.10% of initial]
[Iter 10340/20000] Loss: 0.0002636 (Best: 0.0002052 @iter10183) ([91m↑5.35%[0m) [0.10% of initial]
[Iter 7850/20000] Loss: 0.0005272 (Best: 0.0003342 @iter7738) ([92m↓4.78%[0m) [0.21% of initial]
[Iter 10350/20000] Loss: 0.0002456 (Best: 0.0002052 @iter10183) ([92m↓6.83%[0m) [0.10% of initial]
[Iter 10360/20000] Loss: 0.0002641 (Best: 0.0002052 @iter10183) ([91m↑7.53%[0m) [0.10% of initial]
[Iter 7860/20000] Loss: 0.0005341 (Best: 0.0003342 @iter7738) ([91m↑1.31%[0m) [0.21% of initial]
[Iter 10370/20000] Loss: 0.0002810 (Best: 0.0002052 @iter10183) ([91m↑6.38%[0m) [0.11% of initial]
[Iter 7870/20000] Loss: 0.0004897 (Best: 0.0003342 @iter7738) ([92m↓8.31%[0m) [0.19% of initial]
[Iter 10380/20000] Loss: 0.0002610 (Best: 0.0002052 @iter10183) ([92m↓7.10%[0m) [0.10% of initial]
[Iter 10390/20000] Loss: 0.0002873 (Best: 0.0002052 @iter10183) ([91m↑10.06%[0m) [0.11% of initial]
[Iter 7880/20000] Loss: 0.0004300 (Best: 0.0003342 @iter7738) ([92m↓12.20%[0m) [0.17% of initial]
Iter:10399, L1 loss=0.0002836, Total loss=0.0002366, Time:213
[Iter 10400/20000] Loss: 0.0002644 (Best: 0.0002052 @iter10183) ([92m↓7.94%[0m) [0.11% of initial]
[Iter 7890/20000] Loss: 0.0005159 (Best: 0.0003342 @iter7738) ([91m↑19.99%[0m) [0.20% of initial]
[Iter 10410/20000] Loss: 0.0002399 (Best: 0.0002052 @iter10183) ([92m↓9.29%[0m) [0.10% of initial]
[Iter 10420/20000] Loss: 0.0002427 (Best: 0.0002052 @iter10183) ([91m↑1.19%[0m) [0.10% of initial]
Iter:7899, L1 loss=0.0005162, Total loss=0.0004376, Time:183
[Iter 7900/20000] Loss: 0.0004455 (Best: 0.0003342 @iter7738) ([92m↓13.65%[0m) [0.18% of initial]
[Iter 10430/20000] Loss: 0.0002917 (Best: 0.0002052 @iter10183) ([91m↑20.18%[0m) [0.12% of initial]
[Iter 10440/20000] Loss: 0.0002768 (Best: 0.0002052 @iter10183) ([92m↓5.10%[0m) [0.11% of initial]
[Iter 7910/20000] Loss: 0.0004433 (Best: 0.0003342 @iter7738) ([92m↓0.49%[0m) [0.18% of initial]
[Iter 10450/20000] Loss: 0.0002979 (Best: 0.0002052 @iter10183) ([91m↑7.61%[0m) [0.12% of initial]
[Iter 7920/20000] Loss: 0.0005193 (Best: 0.0003342 @iter7738) ([91m↑17.15%[0m) [0.21% of initial]
[Iter 10460/20000] Loss: 0.0002401 (Best: 0.0002052 @iter10183) ([92m↓19.41%[0m) [0.10% of initial]
[Iter 10470/20000] Loss: 0.0003227 (Best: 0.0002052 @iter10183) ([91m↑34.42%[0m) [0.13% of initial]
[Iter 7930/20000] Loss: 0.0004468 (Best: 0.0003342 @iter7738) ([92m↓13.97%[0m) [0.18% of initial]
[Iter 10480/20000] Loss: 0.0002750 (Best: 0.0002052 @iter10183) ([92m↓14.80%[0m) [0.11% of initial]
[Iter 10490/20000] Loss: 0.0002487 (Best: 0.0002052 @iter10183) ([92m↓9.54%[0m) [0.10% of initial]
[Iter 7940/20000] Loss: 0.0004039 (Best: 0.0003342 @iter7738) ([92m↓9.61%[0m) [0.16% of initial]
Iter:10499, L1 loss=0.0002914, Total loss=0.0002484, Time:193
[Iter 10500/20000] Loss: 0.0002503 (Best: 0.0002052 @iter10183) ([91m↑0.62%[0m) [0.10% of initial]
[Iter 7950/20000] Loss: 0.0003945 (Best: 0.0003342 @iter7738) ([92m↓2.31%[0m) [0.16% of initial]
[Iter 10510/20000] Loss: 0.0002427 (Best: 0.0002052 @iter10183) ([92m↓3.04%[0m) [0.10% of initial]
[Iter 10520/20000] Loss: 0.0002464 (Best: 0.0002052 @iter10183) ([91m↑1.53%[0m) [0.10% of initial]
[Iter 7960/20000] Loss: 0.0004676 (Best: 0.0003342 @iter7738) ([91m↑18.53%[0m) [0.19% of initial]
[Iter 10530/20000] Loss: 0.0002694 (Best: 0.0002052 @iter10183) ([91m↑9.33%[0m) [0.11% of initial]
[Iter 7970/20000] Loss: 0.0004610 (Best: 0.0003342 @iter7738) ([92m↓1.41%[0m) [0.18% of initial]
[Iter 10540/20000] Loss: 0.0003262 (Best: 0.0002052 @iter10183) ([91m↑21.11%[0m) [0.13% of initial]
[Iter 10550/20000] Loss: 0.0002598 (Best: 0.0002052 @iter10183) ([92m↓20.35%[0m) [0.10% of initial]
[Iter 7980/20000] Loss: 0.0004716 (Best: 0.0003342 @iter7738) ([91m↑2.29%[0m) [0.19% of initial]
[Iter 10560/20000] Loss: 0.0002522 (Best: 0.0002052 @iter10183) ([92m↓2.93%[0m) [0.10% of initial]
[Iter 7990/20000] Loss: 0.0004143 (Best: 0.0003342 @iter7738) ([92m↓12.15%[0m) [0.16% of initial]
[Iter 10570/20000] Loss: 0.0002586 (Best: 0.0002052 @iter10183) ([91m↑2.54%[0m) [0.10% of initial]
[Iter 10580/20000] Loss: 0.0002545 (Best: 0.0002052 @iter10183) ([92m↓1.61%[0m) [0.10% of initial]
Iter:7999, L1 loss=0.0004518, Total loss=0.0004215, Time:189
[Iter 8000/20000] Loss: 0.0004128 (Best: 0.0003342 @iter7738) ([92m↓0.37%[0m) [0.16% of initial]
[Iter 10590/20000] Loss: 0.0002509 (Best: 0.0002052 @iter10183) ([92m↓1.42%[0m) [0.10% of initial]
Pruning 57 points (0.0%) from gaussian0 at iteration 8000
Pruning 52 points (0.0%) from gaussian1 at iteration 8000
Iter:10599, L1 loss=0.000268, Total loss=0.0002299, Time:201
[Iter 10600/20000] Loss: 0.0002417 (Best: 0.0002052 @iter10183) ([92m↓3.64%[0m) [0.10% of initial]
[Iter 8010/20000] Loss: 0.0409552 (Best: 0.0003342 @iter7738) ([91m↑9821.47%[0m) [16.27% of initial]
[Iter 10610/20000] Loss: 0.0002302 (Best: 0.0002013 @iter10607) ([92m↓4.76%[0m) [0.09% of initial]
[Iter 8020/20000] Loss: 0.0165079 (Best: 0.0003342 @iter7738) ([92m↓59.69%[0m) [6.56% of initial]
[Iter 8030/20000] Loss: 0.0050872 (Best: 0.0003342 @iter7738) ([92m↓69.18%[0m) [2.02% of initial]
[Iter 10620/20000] Loss: 0.0002288 (Best: 0.0002013 @iter10607) ([92m↓0.62%[0m) [0.09% of initial]
[Iter 8040/20000] Loss: 0.0039363 (Best: 0.0003342 @iter7738) ([92m↓22.62%[0m) [1.56% of initial]
[Iter 10630/20000] Loss: 0.0002358 (Best: 0.0002013 @iter10607) ([91m↑3.04%[0m) [0.09% of initial]
[Iter 8050/20000] Loss: 0.0022448 (Best: 0.0003342 @iter7738) ([92m↓42.97%[0m) [0.89% of initial]
[Iter 10640/20000] Loss: 0.0002809 (Best: 0.0002013 @iter10607) ([91m↑19.14%[0m) [0.11% of initial]
[Iter 8060/20000] Loss: 0.0015149 (Best: 0.0003342 @iter7738) ([92m↓32.52%[0m) [0.60% of initial]
[Iter 10650/20000] Loss: 0.0003152 (Best: 0.0002013 @iter10607) ([91m↑12.23%[0m) [0.13% of initial]
[Iter 8070/20000] Loss: 0.0012039 (Best: 0.0003342 @iter7738) ([92m↓20.53%[0m) [0.48% of initial]
[Iter 10660/20000] Loss: 0.0002609 (Best: 0.0002013 @iter10607) ([92m↓17.25%[0m) [0.10% of initial]
[Iter 8080/20000] Loss: 0.0009466 (Best: 0.0003342 @iter7738) ([92m↓21.37%[0m) [0.38% of initial]
[Iter 10670/20000] Loss: 0.0002488 (Best: 0.0002013 @iter10607) ([92m↓4.62%[0m) [0.10% of initial]
[Iter 8090/20000] Loss: 0.0007896 (Best: 0.0003342 @iter7738) ([92m↓16.59%[0m) [0.31% of initial]
[Iter 10680/20000] Loss: 0.0002277 (Best: 0.0002013 @iter10607) ([92m↓8.48%[0m) [0.09% of initial]
Iter:8099, L1 loss=0.0007328, Total loss=0.0007011, Time:191
[Iter 8100/20000] Loss: 0.0007595 (Best: 0.0003342 @iter7738) ([92m↓3.81%[0m) [0.30% of initial]
[Iter 10690/20000] Loss: 0.0002337 (Best: 0.0001992 @iter10681) ([91m↑2.63%[0m) [0.09% of initial]
[Iter 8110/20000] Loss: 0.0006623 (Best: 0.0003342 @iter7738) ([92m↓12.79%[0m) [0.26% of initial]
Iter:10699, L1 loss=0.0003095, Total loss=0.0002567, Time:187
[Iter 10700/20000] Loss: 0.0002740 (Best: 0.0001992 @iter10681) ([91m↑17.26%[0m) [0.11% of initial]
[Iter 8120/20000] Loss: 0.0006039 (Best: 0.0003342 @iter7738) ([92m↓8.83%[0m) [0.24% of initial]
[Iter 10710/20000] Loss: 0.0002631 (Best: 0.0001992 @iter10681) ([92m↓3.98%[0m) [0.10% of initial]
[Iter 8130/20000] Loss: 0.0006354 (Best: 0.0003342 @iter7738) ([91m↑5.22%[0m) [0.25% of initial]
[Iter 10720/20000] Loss: 0.0002819 (Best: 0.0001992 @iter10681) ([91m↑7.13%[0m) [0.11% of initial]
[Iter 8140/20000] Loss: 0.0005981 (Best: 0.0003342 @iter7738) ([92m↓5.88%[0m) [0.24% of initial]
[Iter 10730/20000] Loss: 0.0003018 (Best: 0.0001992 @iter10681) ([91m↑7.08%[0m) [0.12% of initial]
[Iter 8150/20000] Loss: 0.0005853 (Best: 0.0003342 @iter7738) ([92m↓2.12%[0m) [0.23% of initial]
[Iter 10740/20000] Loss: 0.0002632 (Best: 0.0001992 @iter10681) ([92m↓12.81%[0m) [0.10% of initial]
[Iter 8160/20000] Loss: 0.0005858 (Best: 0.0003342 @iter7738) ([91m↑0.07%[0m) [0.23% of initial]
[Iter 8170/20000] Loss: 0.0005703 (Best: 0.0003342 @iter7738) ([92m↓2.64%[0m) [0.23% of initial]
[Iter 10750/20000] Loss: 0.0002698 (Best: 0.0001992 @iter10681) ([91m↑2.51%[0m) [0.11% of initial]
[Iter 8180/20000] Loss: 0.0005699 (Best: 0.0003342 @iter7738) ([92m↓0.06%[0m) [0.23% of initial]
[Iter 10760/20000] Loss: 0.0002318 (Best: 0.0001992 @iter10681) ([92m↓14.09%[0m) [0.09% of initial]
[Iter 8190/20000] Loss: 0.0005467 (Best: 0.0003342 @iter7738) ([92m↓4.08%[0m) [0.22% of initial]
[Iter 10770/20000] Loss: 0.0002234 (Best: 0.0001992 @iter10681) ([92m↓3.60%[0m) [0.09% of initial]
Iter:8199, L1 loss=0.0006046, Total loss=0.0005488, Time:191
[Iter 8200/20000] Loss: 0.0005256 (Best: 0.0003342 @iter7738) ([92m↓3.85%[0m) [0.21% of initial]
[Iter 10780/20000] Loss: 0.0002197 (Best: 0.0001992 @iter10681) ([92m↓1.65%[0m) [0.09% of initial]
[Iter 8210/20000] Loss: 0.0005014 (Best: 0.0003342 @iter7738) ([92m↓4.61%[0m) [0.20% of initial]
[Iter 10790/20000] Loss: 0.0002437 (Best: 0.0001992 @iter10681) ([91m↑10.88%[0m) [0.10% of initial]
[Iter 8220/20000] Loss: 0.0005148 (Best: 0.0003342 @iter7738) ([91m↑2.69%[0m) [0.20% of initial]
Iter:10799, L1 loss=0.0002804, Total loss=0.0002365, Time:190
[Iter 10800/20000] Loss: 0.0002716 (Best: 0.0001992 @iter10681) ([91m↑11.46%[0m) [0.11% of initial]
[Iter 8230/20000] Loss: 0.0005190 (Best: 0.0003342 @iter7738) ([91m↑0.81%[0m) [0.21% of initial]
[Iter 10810/20000] Loss: 0.0003132 (Best: 0.0001992 @iter10681) ([91m↑15.34%[0m) [0.12% of initial]
[Iter 8240/20000] Loss: 0.0005182 (Best: 0.0003342 @iter7738) ([92m↓0.16%[0m) [0.21% of initial]
[Iter 10820/20000] Loss: 0.0002711 (Best: 0.0001992 @iter10681) ([92m↓13.47%[0m) [0.11% of initial]
[Iter 8250/20000] Loss: 0.0005473 (Best: 0.0003342 @iter7738) ([91m↑5.62%[0m) [0.22% of initial]
[Iter 10830/20000] Loss: 0.0002748 (Best: 0.0001992 @iter10681) ([91m↑1.40%[0m) [0.11% of initial]
[Iter 8260/20000] Loss: 0.0005348 (Best: 0.0003342 @iter7738) ([92m↓2.27%[0m) [0.21% of initial]
[Iter 10840/20000] Loss: 0.0002431 (Best: 0.0001992 @iter10681) ([92m↓11.56%[0m) [0.10% of initial]
[Iter 8270/20000] Loss: 0.0005409 (Best: 0.0003342 @iter7738) ([91m↑1.14%[0m) [0.21% of initial]
[Iter 10850/20000] Loss: 0.0002605 (Best: 0.0001992 @iter10681) ([91m↑7.17%[0m) [0.10% of initial]
[Iter 8280/20000] Loss: 0.0005223 (Best: 0.0003342 @iter7738) ([92m↓3.44%[0m) [0.21% of initial]
[Iter 10860/20000] Loss: 0.0002402 (Best: 0.0001992 @iter10681) ([92m↓7.77%[0m) [0.10% of initial]
[Iter 8290/20000] Loss: 0.0005532 (Best: 0.0003342 @iter7738) ([91m↑5.91%[0m) [0.22% of initial]
[Iter 10870/20000] Loss: 0.0002456 (Best: 0.0001992 @iter10681) ([91m↑2.21%[0m) [0.10% of initial]
Iter:8299, L1 loss=0.0005442, Total loss=0.0004944, Time:176
[Iter 8300/20000] Loss: 0.0005429 (Best: 0.0003342 @iter7738) ([92m↓1.87%[0m) [0.22% of initial]
[Iter 10880/20000] Loss: 0.0002348 (Best: 0.0001992 @iter10681) ([92m↓4.39%[0m) [0.09% of initial]
[Iter 8310/20000] Loss: 0.0005024 (Best: 0.0003342 @iter7738) ([92m↓7.46%[0m) [0.20% of initial]
[Iter 10890/20000] Loss: 0.0002541 (Best: 0.0001992 @iter10681) ([91m↑8.23%[0m) [0.10% of initial]
[Iter 8320/20000] Loss: 0.0004749 (Best: 0.0003342 @iter7738) ([92m↓5.48%[0m) [0.19% of initial]
Iter:10899, L1 loss=0.0003504, Total loss=0.0003086, Time:190
[Iter 10900/20000] Loss: 0.0002723 (Best: 0.0001992 @iter10681) ([91m↑7.17%[0m) [0.11% of initial]
[Iter 8330/20000] Loss: 0.0004799 (Best: 0.0003342 @iter7738) ([91m↑1.06%[0m) [0.19% of initial]
[Iter 8340/20000] Loss: 0.0004950 (Best: 0.0003342 @iter7738) ([91m↑3.14%[0m) [0.20% of initial]
[Iter 10910/20000] Loss: 0.0002629 (Best: 0.0001992 @iter10681) ([92m↓3.46%[0m) [0.10% of initial]
[Iter 8350/20000] Loss: 0.0004540 (Best: 0.0003342 @iter7738) ([92m↓8.29%[0m) [0.18% of initial]
[Iter 10920/20000] Loss: 0.0002489 (Best: 0.0001992 @iter10681) ([92m↓5.33%[0m) [0.10% of initial]
[Iter 8360/20000] Loss: 0.0004560 (Best: 0.0003342 @iter7738) ([91m↑0.46%[0m) [0.18% of initial]
[Iter 10930/20000] Loss: 0.0002409 (Best: 0.0001992 @iter10681) ([92m↓3.21%[0m) [0.10% of initial]
[Iter 8370/20000] Loss: 0.0004521 (Best: 0.0003342 @iter7738) ([92m↓0.86%[0m) [0.18% of initial]
[Iter 10940/20000] Loss: 0.0002637 (Best: 0.0001992 @iter10681) ([91m↑9.50%[0m) [0.10% of initial]
[Iter 8380/20000] Loss: 0.0004629 (Best: 0.0003342 @iter7738) ([91m↑2.38%[0m) [0.18% of initial]
[Iter 10950/20000] Loss: 0.0002471 (Best: 0.0001992 @iter10681) ([92m↓6.31%[0m) [0.10% of initial]
[Iter 8390/20000] Loss: 0.0004283 (Best: 0.0003342 @iter7738) ([92m↓7.47%[0m) [0.17% of initial]
[Iter 10960/20000] Loss: 0.0002431 (Best: 0.0001992 @iter10681) ([92m↓1.63%[0m) [0.10% of initial]
Iter:8399, L1 loss=0.0004914, Total loss=0.0004446, Time:160
[Iter 8400/20000] Loss: 0.0004786 (Best: 0.0003342 @iter7738) ([91m↑11.75%[0m) [0.19% of initial]
[Iter 10970/20000] Loss: 0.0002265 (Best: 0.0001992 @iter10681) ([92m↓6.83%[0m) [0.09% of initial]
[Iter 8410/20000] Loss: 0.0004589 (Best: 0.0003342 @iter7738) ([92m↓4.12%[0m) [0.18% of initial]
[Iter 10980/20000] Loss: 0.0002136 (Best: 0.0001921 @iter10976) ([92m↓5.69%[0m) [0.08% of initial]
[Iter 8420/20000] Loss: 0.0004504 (Best: 0.0003342 @iter7738) ([92m↓1.84%[0m) [0.18% of initial]
[Iter 10990/20000] Loss: 0.0002282 (Best: 0.0001921 @iter10976) ([91m↑6.86%[0m) [0.09% of initial]
[Iter 8430/20000] Loss: 0.0004693 (Best: 0.0003342 @iter7738) ([91m↑4.18%[0m) [0.19% of initial]
Iter:10999, L1 loss=0.000295, Total loss=0.0002505, Time:176
[Iter 11000/20000] Loss: 0.0002246 (Best: 0.0001921 @iter10976) ([92m↓1.61%[0m) [0.09% of initial]
[Iter 8440/20000] Loss: 0.0004509 (Best: 0.0003342 @iter7738) ([92m↓3.92%[0m) [0.18% of initial]
[Iter 11010/20000] Loss: 0.0002326 (Best: 0.0001921 @iter10976) ([91m↑3.57%[0m) [0.09% of initial]
[Iter 8450/20000] Loss: 0.0004862 (Best: 0.0003342 @iter7738) ([91m↑7.83%[0m) [0.19% of initial]
[Iter 11020/20000] Loss: 0.0002400 (Best: 0.0001921 @iter10976) ([91m↑3.16%[0m) [0.10% of initial]
[Iter 8460/20000] Loss: 0.0004669 (Best: 0.0003342 @iter7738) ([92m↓3.97%[0m) [0.19% of initial]
[Iter 11030/20000] Loss: 0.0002155 (Best: 0.0001919 @iter11027) ([92m↓10.18%[0m) [0.09% of initial]
[Iter 8470/20000] Loss: 0.0004810 (Best: 0.0003342 @iter7738) ([91m↑3.03%[0m) [0.19% of initial]
[Iter 11040/20000] Loss: 0.0002269 (Best: 0.0001919 @iter11027) ([91m↑5.30%[0m) [0.09% of initial]
[Iter 8480/20000] Loss: 0.0004601 (Best: 0.0003342 @iter7738) ([92m↓4.34%[0m) [0.18% of initial]
[Iter 11050/20000] Loss: 0.0003073 (Best: 0.0001919 @iter11027) ([91m↑35.40%[0m) [0.12% of initial]
[Iter 8490/20000] Loss: 0.0004764 (Best: 0.0003342 @iter7738) ([91m↑3.54%[0m) [0.19% of initial]
Iter:8499, L1 loss=0.000554, Total loss=0.0004936, Time:210
[Iter 11060/20000] Loss: 0.0002381 (Best: 0.0001919 @iter11027) ([92m↓22.50%[0m) [0.09% of initial]
[Iter 8500/20000] Loss: 0.0004932 (Best: 0.0003342 @iter7738) ([91m↑3.53%[0m) [0.20% of initial]
Pruning 55 points (0.0%) from gaussian0 at iteration 8500
Pruning 72 points (0.0%) from gaussian1 at iteration 8500
[Iter 11070/20000] Loss: 0.0002596 (Best: 0.0001919 @iter11027) ([91m↑9.01%[0m) [0.10% of initial]
[Iter 8510/20000] Loss: 0.0010513 (Best: 0.0003342 @iter7738) ([91m↑113.15%[0m) [0.42% of initial]
[Iter 11080/20000] Loss: 0.0002374 (Best: 0.0001919 @iter11027) ([92m↓8.56%[0m) [0.09% of initial]
[Iter 8520/20000] Loss: 0.0007514 (Best: 0.0003342 @iter7738) ([92m↓28.52%[0m) [0.30% of initial]
[Iter 11090/20000] Loss: 0.0002616 (Best: 0.0001919 @iter11027) ([91m↑10.21%[0m) [0.10% of initial]
[Iter 8530/20000] Loss: 0.0005947 (Best: 0.0003342 @iter7738) ([92m↓20.85%[0m) [0.24% of initial]
Iter:11099, L1 loss=0.000278, Total loss=0.0002282, Time:221
[Iter 11100/20000] Loss: 0.0002656 (Best: 0.0001919 @iter11027) ([91m↑1.54%[0m) [0.11% of initial]
[Iter 8540/20000] Loss: 0.0005384 (Best: 0.0003342 @iter7738) ([92m↓9.47%[0m) [0.21% of initial]
[Iter 11110/20000] Loss: 0.0003017 (Best: 0.0001919 @iter11027) ([91m↑13.57%[0m) [0.12% of initial]
[Iter 8550/20000] Loss: 0.0005169 (Best: 0.0003342 @iter7738) ([92m↓3.99%[0m) [0.21% of initial]
[Iter 11120/20000] Loss: 0.0002538 (Best: 0.0001919 @iter11027) ([92m↓15.87%[0m) [0.10% of initial]
[Iter 8560/20000] Loss: 0.0004970 (Best: 0.0003342 @iter7738) ([92m↓3.86%[0m) [0.20% of initial]
[Iter 11130/20000] Loss: 0.0003083 (Best: 0.0001919 @iter11027) ([91m↑21.50%[0m) [0.12% of initial]
[Iter 8570/20000] Loss: 0.0004920 (Best: 0.0003342 @iter7738) ([92m↓1.01%[0m) [0.20% of initial]
[Iter 11140/20000] Loss: 0.0002653 (Best: 0.0001919 @iter11027) ([92m↓13.95%[0m) [0.11% of initial]
[Iter 8580/20000] Loss: 0.0004869 (Best: 0.0003342 @iter7738) ([92m↓1.02%[0m) [0.19% of initial]
[Iter 11150/20000] Loss: 0.0002647 (Best: 0.0001919 @iter11027) ([92m↓0.26%[0m) [0.11% of initial]
[Iter 8590/20000] Loss: 0.0004625 (Best: 0.0003342 @iter7738) ([92m↓5.01%[0m) [0.18% of initial]
[Iter 11160/20000] Loss: 0.0002855 (Best: 0.0001919 @iter11027) ([91m↑7.86%[0m) [0.11% of initial]
Iter:8599, L1 loss=0.0004761, Total loss=0.000424, Time:189
[Iter 8600/20000] Loss: 0.0004565 (Best: 0.0003342 @iter7738) ([92m↓1.30%[0m) [0.18% of initial]
[Iter 11170/20000] Loss: 0.0002775 (Best: 0.0001919 @iter11027) ([92m↓2.79%[0m) [0.11% of initial]
[Iter 8610/20000] Loss: 0.0004821 (Best: 0.0003342 @iter7738) ([91m↑5.62%[0m) [0.19% of initial]
[Iter 11180/20000] Loss: 0.0002584 (Best: 0.0001919 @iter11027) ([92m↓6.89%[0m) [0.10% of initial]
[Iter 8620/20000] Loss: 0.0004745 (Best: 0.0003342 @iter7738) ([92m↓1.58%[0m) [0.19% of initial]
[Iter 11190/20000] Loss: 0.0002731 (Best: 0.0001919 @iter11027) ([91m↑5.69%[0m) [0.11% of initial]
[Iter 8630/20000] Loss: 0.0004644 (Best: 0.0003342 @iter7738) ([92m↓2.13%[0m) [0.18% of initial]
Iter:11199, L1 loss=0.000315, Total loss=0.0002751, Time:209
[Iter 11200/20000] Loss: 0.0002657 (Best: 0.0001919 @iter11027) ([92m↓2.70%[0m) [0.11% of initial]
[Iter 8640/20000] Loss: 0.0004443 (Best: 0.0003342 @iter7738) ([92m↓4.32%[0m) [0.18% of initial]
[Iter 11210/20000] Loss: 0.0002401 (Best: 0.0001919 @iter11027) ([92m↓9.65%[0m) [0.10% of initial]
[Iter 8650/20000] Loss: 0.0004572 (Best: 0.0003342 @iter7738) ([91m↑2.89%[0m) [0.18% of initial]
[Iter 11220/20000] Loss: 0.0002580 (Best: 0.0001919 @iter11027) ([91m↑7.46%[0m) [0.10% of initial]
[Iter 8660/20000] Loss: 0.0004961 (Best: 0.0003342 @iter7738) ([91m↑8.52%[0m) [0.20% of initial]
[Iter 8670/20000] Loss: 0.0004982 (Best: 0.0003342 @iter7738) ([91m↑0.41%[0m) [0.20% of initial]
[Iter 11230/20000] Loss: 0.0002448 (Best: 0.0001919 @iter11027) ([92m↓5.12%[0m) [0.10% of initial]
[Iter 8680/20000] Loss: 0.0004803 (Best: 0.0003342 @iter7738) ([92m↓3.60%[0m) [0.19% of initial]
[Iter 11240/20000] Loss: 0.0002478 (Best: 0.0001919 @iter11027) ([91m↑1.23%[0m) [0.10% of initial]
[Iter 8690/20000] Loss: 0.0005594 (Best: 0.0003342 @iter7738) ([91m↑16.47%[0m) [0.22% of initial]
[Iter 11250/20000] Loss: 0.0002469 (Best: 0.0001919 @iter11027) ([92m↓0.37%[0m) [0.10% of initial]
Iter:8699, L1 loss=0.0005486, Total loss=0.0004777, Time:203
[Iter 8700/20000] Loss: 0.0005019 (Best: 0.0003342 @iter7738) ([92m↓10.28%[0m) [0.20% of initial]
[Iter 11260/20000] Loss: 0.0002294 (Best: 0.0001919 @iter11027) ([92m↓7.08%[0m) [0.09% of initial]
[Iter 8710/20000] Loss: 0.0004896 (Best: 0.0003342 @iter7738) ([92m↓2.45%[0m) [0.19% of initial]
[Iter 11270/20000] Loss: 0.0002220 (Best: 0.0001919 @iter11027) ([92m↓3.21%[0m) [0.09% of initial]
[Iter 8720/20000] Loss: 0.0004675 (Best: 0.0003342 @iter7738) ([92m↓4.51%[0m) [0.19% of initial]
[Iter 11280/20000] Loss: 0.0002294 (Best: 0.0001919 @iter11027) ([91m↑3.34%[0m) [0.09% of initial]
[Iter 8730/20000] Loss: 0.0005071 (Best: 0.0003342 @iter7738) ([91m↑8.48%[0m) [0.20% of initial]
[Iter 11290/20000] Loss: 0.0002266 (Best: 0.0001919 @iter11027) ([92m↓1.24%[0m) [0.09% of initial]
[Iter 8740/20000] Loss: 0.0004849 (Best: 0.0003342 @iter7738) ([92m↓4.38%[0m) [0.19% of initial]
Iter:11299, L1 loss=0.0002388, Total loss=0.000206, Time:208
[Iter 11300/20000] Loss: 0.0002230 (Best: 0.0001919 @iter11027) ([92m↓1.58%[0m) [0.09% of initial]
[Iter 8750/20000] Loss: 0.0005522 (Best: 0.0003342 @iter7738) ([91m↑13.88%[0m) [0.22% of initial]
[Iter 11310/20000] Loss: 0.0001962 (Best: 0.0001907 @iter11305) ([92m↓12.02%[0m) [0.08% of initial]
[Iter 8760/20000] Loss: 0.0005088 (Best: 0.0003342 @iter7738) ([92m↓7.87%[0m) [0.20% of initial]
[Iter 11320/20000] Loss: 0.0002074 (Best: 0.0001812 @iter11314) ([91m↑5.69%[0m) [0.08% of initial]
[Iter 8770/20000] Loss: 0.0005289 (Best: 0.0003342 @iter7738) ([91m↑3.96%[0m) [0.21% of initial]
[Iter 11330/20000] Loss: 0.0002184 (Best: 0.0001812 @iter11314) ([91m↑5.33%[0m) [0.09% of initial]
[Iter 8780/20000] Loss: 0.0005232 (Best: 0.0003342 @iter7738) ([92m↓1.08%[0m) [0.21% of initial]
[Iter 11340/20000] Loss: 0.0002440 (Best: 0.0001812 @iter11314) ([91m↑11.71%[0m) [0.10% of initial]
[Iter 8790/20000] Loss: 0.0005173 (Best: 0.0003342 @iter7738) ([92m↓1.11%[0m) [0.21% of initial]
[Iter 11350/20000] Loss: 0.0003095 (Best: 0.0001812 @iter11314) ([91m↑26.85%[0m) [0.12% of initial]
Iter:8799, L1 loss=0.0005861, Total loss=0.0005654, Time:188
[Iter 8800/20000] Loss: 0.0004933 (Best: 0.0003342 @iter7738) ([92m↓4.65%[0m) [0.20% of initial]
[Iter 11360/20000] Loss: 0.0002372 (Best: 0.0001812 @iter11314) ([92m↓23.35%[0m) [0.09% of initial]
[Iter 8810/20000] Loss: 0.0004414 (Best: 0.0003342 @iter7738) ([92m↓10.53%[0m) [0.18% of initial]
[Iter 11370/20000] Loss: 0.0002708 (Best: 0.0001812 @iter11314) ([91m↑14.17%[0m) [0.11% of initial]
[Iter 8820/20000] Loss: 0.0005138 (Best: 0.0003342 @iter7738) ([91m↑16.42%[0m) [0.20% of initial]
[Iter 11380/20000] Loss: 0.0002774 (Best: 0.0001812 @iter11314) ([91m↑2.42%[0m) [0.11% of initial]
[Iter 8830/20000] Loss: 0.0006353 (Best: 0.0003342 @iter7738) ([91m↑23.65%[0m) [0.25% of initial]
[Iter 8840/20000] Loss: 0.0005715 (Best: 0.0003342 @iter7738) ([92m↓10.05%[0m) [0.23% of initial]
[Iter 11390/20000] Loss: 0.0002773 (Best: 0.0001812 @iter11314) ([92m↓0.03%[0m) [0.11% of initial]
[Iter 8850/20000] Loss: 0.0005949 (Best: 0.0003342 @iter7738) ([91m↑4.10%[0m) [0.24% of initial]
Iter:11399, L1 loss=0.0003337, Total loss=0.0002811, Time:167
[Iter 11400/20000] Loss: 0.0002716 (Best: 0.0001812 @iter11314) ([92m↓2.07%[0m) [0.11% of initial]
[Iter 8860/20000] Loss: 0.0004961 (Best: 0.0003342 @iter7738) ([92m↓16.61%[0m) [0.20% of initial]
[Iter 11410/20000] Loss: 0.0002505 (Best: 0.0001812 @iter11314) ([92m↓7.77%[0m) [0.10% of initial]
[Iter 8870/20000] Loss: 0.0004652 (Best: 0.0003342 @iter7738) ([92m↓6.21%[0m) [0.18% of initial]
[Iter 11420/20000] Loss: 0.0002334 (Best: 0.0001812 @iter11314) ([92m↓6.83%[0m) [0.09% of initial]
[Iter 8880/20000] Loss: 0.0004627 (Best: 0.0003342 @iter7738) ([92m↓0.56%[0m) [0.18% of initial]
[Iter 11430/20000] Loss: 0.0002654 (Best: 0.0001812 @iter11314) ([91m↑13.72%[0m) [0.11% of initial]
[Iter 8890/20000] Loss: 0.0004356 (Best: 0.0003342 @iter7738) ([92m↓5.84%[0m) [0.17% of initial]
[Iter 11440/20000] Loss: 0.0002622 (Best: 0.0001812 @iter11314) ([92m↓1.19%[0m) [0.10% of initial]
Iter:8899, L1 loss=0.0004716, Total loss=0.0004306, Time:201
[Iter 8900/20000] Loss: 0.0004654 (Best: 0.0003342 @iter7738) ([91m↑6.83%[0m) [0.18% of initial]
[Iter 11450/20000] Loss: 0.0002757 (Best: 0.0001812 @iter11314) ([91m↑5.15%[0m) [0.11% of initial]
[Iter 8910/20000] Loss: 0.0004608 (Best: 0.0003342 @iter7738) ([92m↓0.99%[0m) [0.18% of initial]
[Iter 11460/20000] Loss: 0.0002414 (Best: 0.0001812 @iter11314) ([92m↓12.45%[0m) [0.10% of initial]
[Iter 8920/20000] Loss: 0.0004413 (Best: 0.0003342 @iter7738) ([92m↓4.22%[0m) [0.18% of initial]
[Iter 11470/20000] Loss: 0.0002437 (Best: 0.0001812 @iter11314) ([91m↑0.97%[0m) [0.10% of initial]
[Iter 8930/20000] Loss: 0.0004472 (Best: 0.0003342 @iter7738) ([91m↑1.32%[0m) [0.18% of initial]
[Iter 11480/20000] Loss: 0.0002332 (Best: 0.0001812 @iter11314) ([92m↓4.34%[0m) [0.09% of initial]
[Iter 8940/20000] Loss: 0.0004521 (Best: 0.0003342 @iter7738) ([91m↑1.11%[0m) [0.18% of initial]
[Iter 11490/20000] Loss: 0.0002408 (Best: 0.0001812 @iter11314) ([91m↑3.28%[0m) [0.10% of initial]
[Iter 8950/20000] Loss: 0.0004826 (Best: 0.0003342 @iter7738) ([91m↑6.75%[0m) [0.19% of initial]
Iter:11499, L1 loss=0.0003567, Total loss=0.0003037, Time:212
[Iter 11500/20000] Loss: 0.0002617 (Best: 0.0001812 @iter11314) ([91m↑8.69%[0m) [0.10% of initial]
[Iter 8960/20000] Loss: 0.0004766 (Best: 0.0003342 @iter7738) ([92m↓1.26%[0m) [0.19% of initial]
[Iter 11510/20000] Loss: 0.0002412 (Best: 0.0001812 @iter11314) ([92m↓7.84%[0m) [0.10% of initial]
[Iter 8970/20000] Loss: 0.0005268 (Best: 0.0003342 @iter7738) ([91m↑10.55%[0m) [0.21% of initial]
[Iter 11520/20000] Loss: 0.0002231 (Best: 0.0001812 @iter11314) ([92m↓7.52%[0m) [0.09% of initial]
[Iter 8980/20000] Loss: 0.0005228 (Best: 0.0003342 @iter7738) ([92m↓0.77%[0m) [0.21% of initial]
[Iter 11530/20000] Loss: 0.0002197 (Best: 0.0001812 @iter11314) ([92m↓1.50%[0m) [0.09% of initial]
[Iter 8990/20000] Loss: 0.0004723 (Best: 0.0003342 @iter7738) ([92m↓9.66%[0m) [0.19% of initial]
Iter:8999, L1 loss=0.0004767, Total loss=0.0004196, Time:195
[Iter 9000/20000] Loss: 0.0004536 (Best: 0.0003342 @iter7738) ([92m↓3.95%[0m) [0.18% of initial]
[Iter 11540/20000] Loss: 0.0002300 (Best: 0.0001812 @iter11314) ([91m↑4.67%[0m) [0.09% of initial]
Pruning 37 points (0.0%) from gaussian0 at iteration 9000
Pruning 44 points (0.0%) from gaussian1 at iteration 9000
[Iter 11550/20000] Loss: 0.0002434 (Best: 0.0001812 @iter11314) ([91m↑5.81%[0m) [0.10% of initial]
[Iter 9010/20000] Loss: 0.0008891 (Best: 0.0003342 @iter7738) ([91m↑96.00%[0m) [0.35% of initial]
[Iter 11560/20000] Loss: 0.0002514 (Best: 0.0001812 @iter11314) ([91m↑3.29%[0m) [0.10% of initial]
[Iter 9020/20000] Loss: 0.0006622 (Best: 0.0003342 @iter7738) ([92m↓25.52%[0m) [0.26% of initial]
[Iter 11570/20000] Loss: 0.0002423 (Best: 0.0001812 @iter11314) ([92m↓3.59%[0m) [0.10% of initial]
[Iter 9030/20000] Loss: 0.0005372 (Best: 0.0003342 @iter7738) ([92m↓18.88%[0m) [0.21% of initial]
[Iter 11580/20000] Loss: 0.0002643 (Best: 0.0001812 @iter11314) ([91m↑9.05%[0m) [0.10% of initial]
[Iter 9040/20000] Loss: 0.0004845 (Best: 0.0003342 @iter7738) ([92m↓9.81%[0m) [0.19% of initial]
[Iter 11590/20000] Loss: 0.0002416 (Best: 0.0001812 @iter11314) ([92m↓8.56%[0m) [0.10% of initial]
[Iter 9050/20000] Loss: 0.0004557 (Best: 0.0003342 @iter7738) ([92m↓5.94%[0m) [0.18% of initial]
Iter:11599, L1 loss=0.0002791, Total loss=0.0002198, Time:215
[Iter 11600/20000] Loss: 0.0002355 (Best: 0.0001812 @iter11314) ([92m↓2.55%[0m) [0.09% of initial]
[Iter 9060/20000] Loss: 0.0004703 (Best: 0.0003342 @iter7738) ([91m↑3.20%[0m) [0.19% of initial]
[Iter 11610/20000] Loss: 0.0002260 (Best: 0.0001812 @iter11314) ([92m↓4.01%[0m) [0.09% of initial]
[Iter 9070/20000] Loss: 0.0004750 (Best: 0.0003342 @iter7738) ([91m↑0.99%[0m) [0.19% of initial]
[Iter 11620/20000] Loss: 0.0002227 (Best: 0.0001812 @iter11314) ([92m↓1.47%[0m) [0.09% of initial]
[Iter 9080/20000] Loss: 0.0004992 (Best: 0.0003342 @iter7738) ([91m↑5.12%[0m) [0.20% of initial]
[Iter 11630/20000] Loss: 0.0001950 (Best: 0.0001812 @iter11314) ([92m↓12.46%[0m) [0.08% of initial]
[Iter 9090/20000] Loss: 0.0004785 (Best: 0.0003342 @iter7738) ([92m↓4.15%[0m) [0.19% of initial]
[Iter 11640/20000] Loss: 0.0002414 (Best: 0.0001812 @iter11314) ([91m↑23.84%[0m) [0.10% of initial]
Iter:9099, L1 loss=0.0005833, Total loss=0.0005277, Time:212
[Iter 9100/20000] Loss: 0.0004780 (Best: 0.0003342 @iter7738) ([92m↓0.11%[0m) [0.19% of initial]
[Iter 11650/20000] Loss: 0.0002433 (Best: 0.0001812 @iter11314) ([91m↑0.78%[0m) [0.10% of initial]
[Iter 9110/20000] Loss: 0.0005302 (Best: 0.0003342 @iter7738) ([91m↑10.92%[0m) [0.21% of initial]
[Iter 11660/20000] Loss: 0.0002470 (Best: 0.0001812 @iter11314) ([91m↑1.51%[0m) [0.10% of initial]
[Iter 9120/20000] Loss: 0.0004624 (Best: 0.0003342 @iter7738) ([92m↓12.78%[0m) [0.18% of initial]
[Iter 11670/20000] Loss: 0.0002279 (Best: 0.0001812 @iter11314) ([92m↓7.73%[0m) [0.09% of initial]
[Iter 9130/20000] Loss: 0.0005423 (Best: 0.0003342 @iter7738) ([91m↑17.26%[0m) [0.22% of initial]
[Iter 11680/20000] Loss: 0.0002356 (Best: 0.0001812 @iter11314) ([91m↑3.38%[0m) [0.09% of initial]
[Iter 9140/20000] Loss: 0.0004732 (Best: 0.0003342 @iter7738) ([92m↓12.74%[0m) [0.19% of initial]
[Iter 11690/20000] Loss: 0.0002287 (Best: 0.0001812 @iter11314) ([92m↓2.93%[0m) [0.09% of initial]
[Iter 9150/20000] Loss: 0.0004346 (Best: 0.0003342 @iter7738) ([92m↓8.15%[0m) [0.17% of initial]
Iter:11699, L1 loss=0.000247, Total loss=0.000201, Time:209
[Iter 9160/20000] Loss: 0.0004505 (Best: 0.0003342 @iter7738) ([91m↑3.67%[0m) [0.18% of initial]
[Iter 11700/20000] Loss: 0.0002056 (Best: 0.0001812 @iter11314) ([92m↓10.12%[0m) [0.08% of initial]
[Iter 9170/20000] Loss: 0.0004161 (Best: 0.0003342 @iter7738) ([92m↓7.64%[0m) [0.17% of initial]
[Iter 11710/20000] Loss: 0.0002037 (Best: 0.0001808 @iter11707) ([92m↓0.91%[0m) [0.08% of initial]
[Iter 9180/20000] Loss: 0.0004357 (Best: 0.0003342 @iter7738) ([91m↑4.72%[0m) [0.17% of initial]
[Iter 11720/20000] Loss: 0.0002031 (Best: 0.0001774 @iter11719) ([92m↓0.31%[0m) [0.08% of initial]
[Iter 9190/20000] Loss: 0.0003991 (Best: 0.0003342 @iter7738) ([92m↓8.41%[0m) [0.16% of initial]
[Iter 11730/20000] Loss: 0.0002217 (Best: 0.0001774 @iter11719) ([91m↑9.21%[0m) [0.09% of initial]
Iter:9199, L1 loss=0.0004672, Total loss=0.0004199, Time:197
[Iter 9200/20000] Loss: 0.0004154 (Best: 0.0003342 @iter7738) ([91m↑4.07%[0m) [0.17% of initial]
[Iter 11740/20000] Loss: 0.0002511 (Best: 0.0001774 @iter11719) ([91m↑13.25%[0m) [0.10% of initial]
[Iter 9210/20000] Loss: 0.0004249 (Best: 0.0003342 @iter7738) ([91m↑2.31%[0m) [0.17% of initial]
[Iter 11750/20000] Loss: 0.0002514 (Best: 0.0001774 @iter11719) ([91m↑0.12%[0m) [0.10% of initial]
[Iter 9220/20000] Loss: 0.0004292 (Best: 0.0003342 @iter7738) ([91m↑1.00%[0m) [0.17% of initial]
[Iter 11760/20000] Loss: 0.0002818 (Best: 0.0001774 @iter11719) ([91m↑12.11%[0m) [0.11% of initial]
[Iter 9230/20000] Loss: 0.0004197 (Best: 0.0003342 @iter7738) ([92m↓2.22%[0m) [0.17% of initial]
[Iter 11770/20000] Loss: 0.0002290 (Best: 0.0001774 @iter11719) ([92m↓18.75%[0m) [0.09% of initial]
[Iter 9240/20000] Loss: 0.0004377 (Best: 0.0003342 @iter7738) ([91m↑4.30%[0m) [0.17% of initial]
[Iter 11780/20000] Loss: 0.0002312 (Best: 0.0001774 @iter11719) ([91m↑0.94%[0m) [0.09% of initial]
[Iter 9250/20000] Loss: 0.0004314 (Best: 0.0003342 @iter7738) ([92m↓1.44%[0m) [0.17% of initial]
[Iter 11790/20000] Loss: 0.0002085 (Best: 0.0001774 @iter11719) ([92m↓9.81%[0m) [0.08% of initial]
[Iter 9260/20000] Loss: 0.0004353 (Best: 0.0003342 @iter7738) ([91m↑0.91%[0m) [0.17% of initial]
Iter:11799, L1 loss=0.0002602, Total loss=0.0002196, Time:211
[Iter 11800/20000] Loss: 0.0001999 (Best: 0.0001774 @iter11719) ([92m↓4.12%[0m) [0.08% of initial]
[Iter 9270/20000] Loss: 0.0004749 (Best: 0.0003342 @iter7738) ([91m↑9.09%[0m) [0.19% of initial]
[Iter 11810/20000] Loss: 0.0001854 (Best: 0.0001763 @iter11810) ([92m↓7.27%[0m) [0.07% of initial]
[Iter 9280/20000] Loss: 0.0004168 (Best: 0.0003342 @iter7738) ([92m↓12.22%[0m) [0.17% of initial]
[Iter 11820/20000] Loss: 0.0002121 (Best: 0.0001763 @iter11810) ([91m↑14.42%[0m) [0.08% of initial]
[Iter 9290/20000] Loss: 0.0004081 (Best: 0.0003342 @iter7738) ([92m↓2.10%[0m) [0.16% of initial]
[Iter 11830/20000] Loss: 0.0002384 (Best: 0.0001763 @iter11810) ([91m↑12.43%[0m) [0.09% of initial]
Iter:9299, L1 loss=0.0004299, Total loss=0.0003845, Time:167
[Iter 9300/20000] Loss: 0.0004348 (Best: 0.0003342 @iter7738) ([91m↑6.54%[0m) [0.17% of initial]
[Iter 11840/20000] Loss: 0.0002334 (Best: 0.0001763 @iter11810) ([92m↓2.13%[0m) [0.09% of initial]
[Iter 9310/20000] Loss: 0.0004320 (Best: 0.0003342 @iter7738) ([92m↓0.63%[0m) [0.17% of initial]
[Iter 11850/20000] Loss: 0.0002216 (Best: 0.0001763 @iter11810) ([92m↓5.06%[0m) [0.09% of initial]
[Iter 9320/20000] Loss: 0.0004393 (Best: 0.0003342 @iter7738) ([91m↑1.69%[0m) [0.17% of initial]
[Iter 9330/20000] Loss: 0.0004723 (Best: 0.0003342 @iter7738) ([91m↑7.50%[0m) [0.19% of initial]
[Iter 11860/20000] Loss: 0.0002215 (Best: 0.0001763 @iter11810) ([92m↓0.03%[0m) [0.09% of initial]
[Iter 9340/20000] Loss: 0.0004669 (Best: 0.0003342 @iter7738) ([92m↓1.15%[0m) [0.19% of initial]
[Iter 11870/20000] Loss: 0.0002140 (Best: 0.0001763 @iter11810) ([92m↓3.40%[0m) [0.09% of initial]
[Iter 9350/20000] Loss: 0.0004244 (Best: 0.0003342 @iter7738) ([92m↓9.09%[0m) [0.17% of initial]
[Iter 11880/20000] Loss: 0.0002211 (Best: 0.0001763 @iter11810) ([91m↑3.33%[0m) [0.09% of initial]
[Iter 9360/20000] Loss: 0.0004814 (Best: 0.0003342 @iter7738) ([91m↑13.42%[0m) [0.19% of initial]
[Iter 11890/20000] Loss: 0.0002762 (Best: 0.0001763 @iter11810) ([91m↑24.92%[0m) [0.11% of initial]
[Iter 9370/20000] Loss: 0.0004147 (Best: 0.0003342 @iter7738) ([92m↓13.85%[0m) [0.16% of initial]
Iter:11899, L1 loss=0.0002715, Total loss=0.0002314, Time:214
[Iter 11900/20000] Loss: 0.0002385 (Best: 0.0001763 @iter11810) ([92m↓13.63%[0m) [0.09% of initial]
[Iter 9380/20000] Loss: 0.0004443 (Best: 0.0003342 @iter7738) ([91m↑7.14%[0m) [0.18% of initial]
[Iter 11910/20000] Loss: 0.0002466 (Best: 0.0001763 @iter11810) ([91m↑3.40%[0m) [0.10% of initial]
[Iter 9390/20000] Loss: 0.0004551 (Best: 0.0003342 @iter7738) ([91m↑2.42%[0m) [0.18% of initial]
[Iter 11920/20000] Loss: 0.0002633 (Best: 0.0001763 @iter11810) ([91m↑6.74%[0m) [0.10% of initial]
Iter:9399, L1 loss=0.0005745, Total loss=0.0005505, Time:158
[Iter 9400/20000] Loss: 0.0004494 (Best: 0.0003342 @iter7738) ([92m↓1.25%[0m) [0.18% of initial]
[Iter 11930/20000] Loss: 0.0002396 (Best: 0.0001763 @iter11810) ([92m↓8.99%[0m) [0.10% of initial]
[Iter 9410/20000] Loss: 0.0004424 (Best: 0.0003342 @iter7738) ([92m↓1.55%[0m) [0.18% of initial]
[Iter 11940/20000] Loss: 0.0002272 (Best: 0.0001763 @iter11810) ([92m↓5.18%[0m) [0.09% of initial]
[Iter 9420/20000] Loss: 0.0004478 (Best: 0.0003342 @iter7738) ([91m↑1.22%[0m) [0.18% of initial]
[Iter 11950/20000] Loss: 0.0002308 (Best: 0.0001763 @iter11810) ([91m↑1.59%[0m) [0.09% of initial]
[Iter 9430/20000] Loss: 0.0003940 (Best: 0.0003342 @iter7738) ([92m↓12.01%[0m) [0.16% of initial]
[Iter 11960/20000] Loss: 0.0001931 (Best: 0.0001763 @iter11810) ([92m↓16.37%[0m) [0.08% of initial]
[Iter 9440/20000] Loss: 0.0004271 (Best: 0.0003342 @iter7738) ([91m↑8.38%[0m) [0.17% of initial]
[Iter 11970/20000] Loss: 0.0002125 (Best: 0.0001763 @iter11810) ([91m↑10.05%[0m) [0.08% of initial]
[Iter 9450/20000] Loss: 0.0004221 (Best: 0.0003342 @iter7738) ([92m↓1.15%[0m) [0.17% of initial]
[Iter 11980/20000] Loss: 0.0001991 (Best: 0.0001763 @iter11810) ([92m↓6.27%[0m) [0.08% of initial]
[Iter 9460/20000] Loss: 0.0003752 (Best: 0.0003342 @iter7738) ([92m↓11.13%[0m) [0.15% of initial]
[Iter 11990/20000] Loss: 0.0002118 (Best: 0.0001763 @iter11810) ([91m↑6.35%[0m) [0.08% of initial]
[Iter 9470/20000] Loss: 0.0003755 (Best: 0.0003342 @iter7738) ([91m↑0.08%[0m) [0.15% of initial]
Iter:11999, L1 loss=0.0002473, Total loss=0.0002048, Time:218
[Iter 12000/20000] Loss: 0.0002387 (Best: 0.0001763 @iter11810) ([91m↑12.71%[0m) [0.09% of initial]
[Iter 9480/20000] Loss: 0.0004631 (Best: 0.0003342 @iter7738) ([91m↑23.35%[0m) [0.18% of initial]
[Iter 12010/20000] Loss: 0.0122958 (Best: 0.0001763 @iter11810) ([91m↑5051.22%[0m) [4.88% of initial]
[Iter 9490/20000] Loss: 0.0004264 (Best: 0.0003342 @iter7738) ([92m↓7.92%[0m) [0.17% of initial]
Iter:9499, L1 loss=0.00046, Total loss=0.000439, Time:214
[Iter 9500/20000] Loss: 0.0006923 (Best: 0.0003342 @iter7738) ([91m↑62.34%[0m) [0.28% of initial]
[Iter 12020/20000] Loss: 0.0063681 (Best: 0.0001763 @iter11810) ([92m↓48.21%[0m) [2.53% of initial]
Pruning 42 points (0.0%) from gaussian0 at iteration 9500
Pruning 33 points (0.0%) from gaussian1 at iteration 9500
[Iter 12030/20000] Loss: 0.0029152 (Best: 0.0001763 @iter11810) ([92m↓54.22%[0m) [1.16% of initial]
[Iter 9510/20000] Loss: 0.0007388 (Best: 0.0003342 @iter7738) ([91m↑6.72%[0m) [0.29% of initial]
[Iter 12040/20000] Loss: 0.0016631 (Best: 0.0001763 @iter11810) ([92m↓42.95%[0m) [0.66% of initial]
[Iter 9520/20000] Loss: 0.0005709 (Best: 0.0003342 @iter7738) ([92m↓22.73%[0m) [0.23% of initial]
[Iter 12050/20000] Loss: 0.0009766 (Best: 0.0001763 @iter11810) ([92m↓41.28%[0m) [0.39% of initial]
[Iter 9530/20000] Loss: 0.0005835 (Best: 0.0003342 @iter7738) ([91m↑2.21%[0m) [0.23% of initial]
[Iter 12060/20000] Loss: 0.0007819 (Best: 0.0001763 @iter11810) ([92m↓19.93%[0m) [0.31% of initial]
[Iter 9540/20000] Loss: 0.0004566 (Best: 0.0003342 @iter7738) ([92m↓21.74%[0m) [0.18% of initial]
[Iter 12070/20000] Loss: 0.0005559 (Best: 0.0001763 @iter11810) ([92m↓28.90%[0m) [0.22% of initial]
[Iter 9550/20000] Loss: 0.0004009 (Best: 0.0003342 @iter7738) ([92m↓12.19%[0m) [0.16% of initial]
[Iter 9560/20000] Loss: 0.0003820 (Best: 0.0003342 @iter7738) ([92m↓4.73%[0m) [0.15% of initial]
[Iter 12080/20000] Loss: 0.0004359 (Best: 0.0001763 @iter11810) ([92m↓21.60%[0m) [0.17% of initial]
[Iter 9570/20000] Loss: 0.0003763 (Best: 0.0003342 @iter7738) ([92m↓1.49%[0m) [0.15% of initial]
[Iter 12090/20000] Loss: 0.0004048 (Best: 0.0001763 @iter11810) ([92m↓7.12%[0m) [0.16% of initial]
[Iter 9580/20000] Loss: 0.0003624 (Best: 0.0003292 @iter9575) ([92m↓3.70%[0m) [0.14% of initial]
Iter:12099, L1 loss=0.0005316, Total loss=0.0004496, Time:242
[Iter 12100/20000] Loss: 0.0003832 (Best: 0.0001763 @iter11810) ([92m↓5.34%[0m) [0.15% of initial]
[Iter 9590/20000] Loss: 0.0003628 (Best: 0.0003292 @iter9575) ([91m↑0.11%[0m) [0.14% of initial]
[Iter 12110/20000] Loss: 0.0003523 (Best: 0.0001763 @iter11810) ([92m↓8.07%[0m) [0.14% of initial]
Iter:9599, L1 loss=0.0005116, Total loss=0.0004538, Time:159
[Iter 9600/20000] Loss: 0.0003946 (Best: 0.0003292 @iter9575) ([91m↑8.78%[0m) [0.16% of initial]
[Iter 12120/20000] Loss: 0.0003176 (Best: 0.0001763 @iter11810) ([92m↓9.85%[0m) [0.13% of initial]
[Iter 9610/20000] Loss: 0.0003819 (Best: 0.0003292 @iter9575) ([92m↓3.24%[0m) [0.15% of initial]
[Iter 12130/20000] Loss: 0.0003036 (Best: 0.0001763 @iter11810) ([92m↓4.39%[0m) [0.12% of initial]
[Iter 9620/20000] Loss: 0.0003943 (Best: 0.0003292 @iter9575) ([91m↑3.26%[0m) [0.16% of initial]
[Iter 12140/20000] Loss: 0.0003141 (Best: 0.0001763 @iter11810) ([91m↑3.44%[0m) [0.12% of initial]
[Iter 9630/20000] Loss: 0.0003733 (Best: 0.0003202 @iter9628) ([92m↓5.32%[0m) [0.15% of initial]
[Iter 12150/20000] Loss: 0.0003130 (Best: 0.0001763 @iter11810) ([92m↓0.35%[0m) [0.12% of initial]
[Iter 9640/20000] Loss: 0.0003610 (Best: 0.0003202 @iter9628) ([92m↓3.31%[0m) [0.14% of initial]
[Iter 12160/20000] Loss: 0.0002805 (Best: 0.0001763 @iter11810) ([92m↓10.39%[0m) [0.11% of initial]
[Iter 9650/20000] Loss: 0.0004122 (Best: 0.0003202 @iter9628) ([91m↑14.19%[0m) [0.16% of initial]
[Iter 9660/20000] Loss: 0.0003862 (Best: 0.0003202 @iter9628) ([92m↓6.31%[0m) [0.15% of initial]
[Iter 12170/20000] Loss: 0.0002566 (Best: 0.0001763 @iter11810) ([92m↓8.50%[0m) [0.10% of initial]
[Iter 9670/20000] Loss: 0.0004330 (Best: 0.0003202 @iter9628) ([91m↑12.13%[0m) [0.17% of initial]
[Iter 12180/20000] Loss: 0.0002615 (Best: 0.0001763 @iter11810) ([91m↑1.89%[0m) [0.10% of initial]
[Iter 9680/20000] Loss: 0.0004293 (Best: 0.0003202 @iter9628) ([92m↓0.86%[0m) [0.17% of initial]
[Iter 12190/20000] Loss: 0.0002683 (Best: 0.0001763 @iter11810) ([91m↑2.63%[0m) [0.11% of initial]
[Iter 9690/20000] Loss: 0.0004869 (Best: 0.0003202 @iter9628) ([91m↑13.40%[0m) [0.19% of initial]
Iter:12199, L1 loss=0.0003559, Total loss=0.0002956, Time:198
[Iter 12200/20000] Loss: 0.0002643 (Best: 0.0001763 @iter11810) ([92m↓1.53%[0m) [0.10% of initial]
Iter:9699, L1 loss=0.0006254, Total loss=0.0005748, Time:185
[Iter 9700/20000] Loss: 0.0004701 (Best: 0.0003202 @iter9628) ([92m↓3.43%[0m) [0.19% of initial]
[Iter 12210/20000] Loss: 0.0002785 (Best: 0.0001763 @iter11810) ([91m↑5.40%[0m) [0.11% of initial]
[Iter 9710/20000] Loss: 0.0004569 (Best: 0.0003202 @iter9628) ([92m↓2.83%[0m) [0.18% of initial]
[Iter 12220/20000] Loss: 0.0002695 (Best: 0.0001763 @iter11810) ([92m↓3.24%[0m) [0.11% of initial]
[Iter 9720/20000] Loss: 0.0004255 (Best: 0.0003202 @iter9628) ([92m↓6.87%[0m) [0.17% of initial]
[Iter 12230/20000] Loss: 0.0002492 (Best: 0.0001763 @iter11810) ([92m↓7.51%[0m) [0.10% of initial]
[Iter 9730/20000] Loss: 0.0004053 (Best: 0.0003202 @iter9628) ([92m↓4.73%[0m) [0.16% of initial]
[Iter 12240/20000] Loss: 0.0002748 (Best: 0.0001763 @iter11810) ([91m↑10.27%[0m) [0.11% of initial]
[Iter 9740/20000] Loss: 0.0004444 (Best: 0.0003202 @iter9628) ([91m↑9.64%[0m) [0.18% of initial]
[Iter 9750/20000] Loss: 0.0004375 (Best: 0.0003202 @iter9628) ([92m↓1.56%[0m) [0.17% of initial]
[Iter 12250/20000] Loss: 0.0002643 (Best: 0.0001763 @iter11810) ([92m↓3.84%[0m) [0.11% of initial]
[Iter 9760/20000] Loss: 0.0003973 (Best: 0.0003202 @iter9628) ([92m↓9.18%[0m) [0.16% of initial]
[Iter 12260/20000] Loss: 0.0002551 (Best: 0.0001763 @iter11810) ([92m↓3.47%[0m) [0.10% of initial]
[Iter 9770/20000] Loss: 0.0003960 (Best: 0.0003202 @iter9628) ([92m↓0.32%[0m) [0.16% of initial]
[Iter 12270/20000] Loss: 0.0002482 (Best: 0.0001763 @iter11810) ([92m↓2.70%[0m) [0.10% of initial]
[Iter 9780/20000] Loss: 0.0003811 (Best: 0.0003202 @iter9628) ([92m↓3.77%[0m) [0.15% of initial]
[Iter 12280/20000] Loss: 0.0002682 (Best: 0.0001763 @iter11810) ([91m↑8.04%[0m) [0.11% of initial]
[Iter 9790/20000] Loss: 0.0003728 (Best: 0.0003202 @iter9628) ([92m↓2.18%[0m) [0.15% of initial]
[Iter 12290/20000] Loss: 0.0003341 (Best: 0.0001763 @iter11810) ([91m↑24.58%[0m) [0.13% of initial]
Iter:9799, L1 loss=0.0004226, Total loss=0.0003786, Time:147
[Iter 9800/20000] Loss: 0.0004044 (Best: 0.0003202 @iter9628) ([91m↑8.48%[0m) [0.16% of initial]
Iter:12299, L1 loss=0.0003636, Total loss=0.000324, Time:168
[Iter 12300/20000] Loss: 0.0003003 (Best: 0.0001763 @iter11810) ([92m↓10.10%[0m) [0.12% of initial]
[Iter 9810/20000] Loss: 0.0003824 (Best: 0.0003202 @iter9628) ([92m↓5.44%[0m) [0.15% of initial]
[Iter 12310/20000] Loss: 0.0002636 (Best: 0.0001763 @iter11810) ([92m↓12.25%[0m) [0.10% of initial]
[Iter 9820/20000] Loss: 0.0003563 (Best: 0.0003202 @iter9628) ([92m↓6.84%[0m) [0.14% of initial]
[Iter 12320/20000] Loss: 0.0002441 (Best: 0.0001763 @iter11810) ([92m↓7.36%[0m) [0.10% of initial]
[Iter 9830/20000] Loss: 0.0003796 (Best: 0.0003202 @iter9628) ([91m↑6.55%[0m) [0.15% of initial]
[Iter 12330/20000] Loss: 0.0002708 (Best: 0.0001763 @iter11810) ([91m↑10.91%[0m) [0.11% of initial]
[Iter 9840/20000] Loss: 0.0003910 (Best: 0.0003202 @iter9628) ([91m↑3.00%[0m) [0.16% of initial]
[Iter 9850/20000] Loss: 0.0003626 (Best: 0.0003202 @iter9628) ([92m↓7.27%[0m) [0.14% of initial]
[Iter 12340/20000] Loss: 0.0002761 (Best: 0.0001763 @iter11810) ([91m↑1.97%[0m) [0.11% of initial]
[Iter 9860/20000] Loss: 0.0003676 (Best: 0.0003202 @iter9628) ([91m↑1.40%[0m) [0.15% of initial]
[Iter 12350/20000] Loss: 0.0002644 (Best: 0.0001763 @iter11810) ([92m↓4.25%[0m) [0.11% of initial]
[Iter 9870/20000] Loss: 0.0004004 (Best: 0.0003202 @iter9628) ([91m↑8.90%[0m) [0.16% of initial]
[Iter 12360/20000] Loss: 0.0002403 (Best: 0.0001763 @iter11810) ([92m↓9.12%[0m) [0.10% of initial]
[Iter 9880/20000] Loss: 0.0004106 (Best: 0.0003202 @iter9628) ([91m↑2.56%[0m) [0.16% of initial]
[Iter 12370/20000] Loss: 0.0002303 (Best: 0.0001763 @iter11810) ([92m↓4.15%[0m) [0.09% of initial]
[Iter 9890/20000] Loss: 0.0005043 (Best: 0.0003202 @iter9628) ([91m↑22.81%[0m) [0.20% of initial]
[Iter 12380/20000] Loss: 0.0002310 (Best: 0.0001763 @iter11810) ([91m↑0.31%[0m) [0.09% of initial]
Iter:9899, L1 loss=0.0005727, Total loss=0.000496, Time:184
[Iter 9900/20000] Loss: 0.0004526 (Best: 0.0003202 @iter9628) ([92m↓10.25%[0m) [0.18% of initial]
[Iter 12390/20000] Loss: 0.0002323 (Best: 0.0001763 @iter11810) ([91m↑0.56%[0m) [0.09% of initial]
[Iter 9910/20000] Loss: 0.0003735 (Best: 0.0003202 @iter9628) ([92m↓17.48%[0m) [0.15% of initial]
Iter:12399, L1 loss=0.0002498, Total loss=0.0002175, Time:189
[Iter 12400/20000] Loss: 0.0002282 (Best: 0.0001763 @iter11810) ([92m↓1.77%[0m) [0.09% of initial]
[Iter 9920/20000] Loss: 0.0003699 (Best: 0.0003202 @iter9628) ([92m↓0.96%[0m) [0.15% of initial]
[Iter 12410/20000] Loss: 0.0002521 (Best: 0.0001763 @iter11810) ([91m↑10.47%[0m) [0.10% of initial]
[Iter 9930/20000] Loss: 0.0003907 (Best: 0.0003202 @iter9628) ([91m↑5.62%[0m) [0.16% of initial]
[Iter 9940/20000] Loss: 0.0003766 (Best: 0.0003202 @iter9628) ([92m↓3.61%[0m) [0.15% of initial]
[Iter 12420/20000] Loss: 0.0002385 (Best: 0.0001763 @iter11810) ([92m↓5.38%[0m) [0.09% of initial]
[Iter 9950/20000] Loss: 0.0004193 (Best: 0.0003202 @iter9628) ([91m↑11.34%[0m) [0.17% of initial]
[Iter 12430/20000] Loss: 0.0002284 (Best: 0.0001763 @iter11810) ([92m↓4.24%[0m) [0.09% of initial]
[Iter 9960/20000] Loss: 0.0004231 (Best: 0.0003202 @iter9628) ([91m↑0.91%[0m) [0.17% of initial]
[Iter 12440/20000] Loss: 0.0002444 (Best: 0.0001763 @iter11810) ([91m↑6.99%[0m) [0.10% of initial]
[Iter 9970/20000] Loss: 0.0003966 (Best: 0.0003202 @iter9628) ([92m↓6.26%[0m) [0.16% of initial]
[Iter 12450/20000] Loss: 0.0002373 (Best: 0.0001763 @iter11810) ([92m↓2.90%[0m) [0.09% of initial]
[Iter 9980/20000] Loss: 0.0003958 (Best: 0.0003202 @iter9628) ([92m↓0.19%[0m) [0.16% of initial]
[Iter 12460/20000] Loss: 0.0002201 (Best: 0.0001763 @iter11810) ([92m↓7.24%[0m) [0.09% of initial]
[Iter 9990/20000] Loss: 0.0004035 (Best: 0.0003202 @iter9628) ([91m↑1.93%[0m) [0.16% of initial]
[Iter 12470/20000] Loss: 0.0002367 (Best: 0.0001763 @iter11810) ([91m↑7.55%[0m) [0.09% of initial]
Iter:9999, L1 loss=0.000534, Total loss=0.0005769, Time:135
[Iter 10000/20000] Loss: 0.0004925 (Best: 0.0003202 @iter9628) ([91m↑22.07%[0m) [0.20% of initial]
Pruning 22 points (0.0%) from gaussian0 at iteration 10000
[Iter 12480/20000] Loss: 0.0002407 (Best: 0.0001763 @iter11810) ([91m↑1.69%[0m) [0.10% of initial]
Pruning 21 points (0.0%) from gaussian1 at iteration 10000
[Iter 12490/20000] Loss: 0.0002440 (Best: 0.0001763 @iter11810) ([91m↑1.36%[0m) [0.10% of initial]
[Iter 10010/20000] Loss: 0.0007128 (Best: 0.0003202 @iter9628) ([91m↑44.72%[0m) [0.28% of initial]
Iter:12499, L1 loss=0.0002962, Total loss=0.0002687, Time:176
[Iter 10020/20000] Loss: 0.0005956 (Best: 0.0003202 @iter9628) ([92m↓16.44%[0m) [0.24% of initial]
[Iter 12500/20000] Loss: 0.0002488 (Best: 0.0001763 @iter11810) ([91m↑1.97%[0m) [0.10% of initial]
[Iter 10030/20000] Loss: 0.0004368 (Best: 0.0003202 @iter9628) ([92m↓26.66%[0m) [0.17% of initial]
[Iter 12510/20000] Loss: 0.0002498 (Best: 0.0001763 @iter11810) ([91m↑0.39%[0m) [0.10% of initial]
[Iter 10040/20000] Loss: 0.0003945 (Best: 0.0003202 @iter9628) ([92m↓9.68%[0m) [0.16% of initial]
[Iter 12520/20000] Loss: 0.0002323 (Best: 0.0001763 @iter11810) ([92m↓6.99%[0m) [0.09% of initial]
[Iter 10050/20000] Loss: 0.0003755 (Best: 0.0003202 @iter9628) ([92m↓4.81%[0m) [0.15% of initial]
[Iter 12530/20000] Loss: 0.0002166 (Best: 0.0001763 @iter11810) ([92m↓6.78%[0m) [0.09% of initial]
[Iter 10060/20000] Loss: 0.0003382 (Best: 0.0003153 @iter10057) ([92m↓9.94%[0m) [0.13% of initial]
[Iter 12540/20000] Loss: 0.0002188 (Best: 0.0001763 @iter11810) ([91m↑1.05%[0m) [0.09% of initial]
[Iter 10070/20000] Loss: 0.0003354 (Best: 0.0003153 @iter10057) ([92m↓0.82%[0m) [0.13% of initial]
[Iter 12550/20000] Loss: 0.0001973 (Best: 0.0001763 @iter11810) ([92m↓9.82%[0m) [0.08% of initial]
[Iter 10080/20000] Loss: 0.0003499 (Best: 0.0003106 @iter10072) ([91m↑4.32%[0m) [0.14% of initial]
[Iter 12560/20000] Loss: 0.0002052 (Best: 0.0001763 @iter11810) ([91m↑3.99%[0m) [0.08% of initial]
[Iter 10090/20000] Loss: 0.0003436 (Best: 0.0003106 @iter10072) ([92m↓1.81%[0m) [0.14% of initial]
[Iter 12570/20000] Loss: 0.0002251 (Best: 0.0001763 @iter11810) ([91m↑9.68%[0m) [0.09% of initial]
Iter:10099, L1 loss=0.0003943, Total loss=0.0003474, Time:143
[Iter 10100/20000] Loss: 0.0003567 (Best: 0.0003106 @iter10072) ([91m↑3.82%[0m) [0.14% of initial]
[Iter 10110/20000] Loss: 0.0003598 (Best: 0.0003106 @iter10072) ([91m↑0.86%[0m) [0.14% of initial]
[Iter 12580/20000] Loss: 0.0002414 (Best: 0.0001763 @iter11810) ([91m↑7.24%[0m) [0.10% of initial]
[Iter 10120/20000] Loss: 0.0003572 (Best: 0.0003106 @iter10072) ([92m↓0.70%[0m) [0.14% of initial]
[Iter 12590/20000] Loss: 0.0002193 (Best: 0.0001763 @iter11810) ([92m↓9.14%[0m) [0.09% of initial]
[Iter 10130/20000] Loss: 0.0003604 (Best: 0.0003106 @iter10072) ([91m↑0.90%[0m) [0.14% of initial]
Iter:12599, L1 loss=0.0003596, Total loss=0.0003039, Time:171
[Iter 12600/20000] Loss: 0.0002524 (Best: 0.0001763 @iter11810) ([91m↑15.10%[0m) [0.10% of initial]
[Iter 10140/20000] Loss: 0.0004129 (Best: 0.0003106 @iter10072) ([91m↑14.55%[0m) [0.16% of initial]
[Iter 12610/20000] Loss: 0.0002343 (Best: 0.0001763 @iter11810) ([92m↓7.19%[0m) [0.09% of initial]
[Iter 10150/20000] Loss: 0.0004130 (Best: 0.0003106 @iter10072) ([91m↑0.02%[0m) [0.16% of initial]
[Iter 12620/20000] Loss: 0.0002136 (Best: 0.0001763 @iter11810) ([92m↓8.82%[0m) [0.08% of initial]
[Iter 10160/20000] Loss: 0.0004415 (Best: 0.0003106 @iter10072) ([91m↑6.91%[0m) [0.18% of initial]
[Iter 12630/20000] Loss: 0.0002334 (Best: 0.0001763 @iter11810) ([91m↑9.27%[0m) [0.09% of initial]
[Iter 10170/20000] Loss: 0.0003977 (Best: 0.0003106 @iter10072) ([92m↓9.92%[0m) [0.16% of initial]
[Iter 12640/20000] Loss: 0.0002278 (Best: 0.0001763 @iter11810) ([92m↓2.43%[0m) [0.09% of initial]
[Iter 10180/20000] Loss: 0.0003484 (Best: 0.0003106 @iter10072) ([92m↓12.41%[0m) [0.14% of initial]
[Iter 12650/20000] Loss: 0.0002279 (Best: 0.0001763 @iter11810) ([91m↑0.08%[0m) [0.09% of initial]
[Iter 10190/20000] Loss: 0.0003273 (Best: 0.0003081 @iter10183) ([92m↓6.06%[0m) [0.13% of initial]
Iter:10199, L1 loss=0.0004381, Total loss=0.000384, Time:146
[Iter 10200/20000] Loss: 0.0003593 (Best: 0.0003081 @iter10183) ([91m↑9.79%[0m) [0.14% of initial]
[Iter 12660/20000] Loss: 0.0002465 (Best: 0.0001763 @iter11810) ([91m↑8.14%[0m) [0.10% of initial]
[Iter 10210/20000] Loss: 0.0003467 (Best: 0.0003081 @iter10183) ([92m↓3.50%[0m) [0.14% of initial]
[Iter 12670/20000] Loss: 0.0002438 (Best: 0.0001763 @iter11810) ([92m↓1.08%[0m) [0.10% of initial]
[Iter 10220/20000] Loss: 0.0003607 (Best: 0.0003081 @iter10183) ([91m↑4.04%[0m) [0.14% of initial]
[Iter 12680/20000] Loss: 0.0002880 (Best: 0.0001763 @iter11810) ([91m↑18.10%[0m) [0.11% of initial]
[Iter 10230/20000] Loss: 0.0003597 (Best: 0.0003081 @iter10183) ([92m↓0.30%[0m) [0.14% of initial]
[Iter 12690/20000] Loss: 0.0002532 (Best: 0.0001763 @iter11810) ([92m↓12.07%[0m) [0.10% of initial]
[Iter 10240/20000] Loss: 0.0003444 (Best: 0.0003022 @iter10237) ([92m↓4.23%[0m) [0.14% of initial]
Iter:12699, L1 loss=0.0003041, Total loss=0.0002648, Time:120
[Iter 12700/20000] Loss: 0.0002537 (Best: 0.0001763 @iter11810) ([91m↑0.20%[0m) [0.10% of initial]
[Iter 10250/20000] Loss: 0.0003449 (Best: 0.0003022 @iter10237) ([91m↑0.15%[0m) [0.14% of initial]
[Iter 12710/20000] Loss: 0.0002401 (Best: 0.0001763 @iter11810) ([92m↓5.39%[0m) [0.10% of initial]
[Iter 10260/20000] Loss: 0.0003753 (Best: 0.0003022 @iter10237) ([91m↑8.80%[0m) [0.15% of initial]
[Iter 12720/20000] Loss: 0.0002302 (Best: 0.0001763 @iter11810) ([92m↓4.13%[0m) [0.09% of initial]
[Iter 10270/20000] Loss: 0.0003518 (Best: 0.0003022 @iter10237) ([92m↓6.26%[0m) [0.14% of initial]
[Iter 12730/20000] Loss: 0.0002549 (Best: 0.0001763 @iter11810) ([91m↑10.75%[0m) [0.10% of initial]
[Iter 10280/20000] Loss: 0.0003480 (Best: 0.0003022 @iter10237) ([92m↓1.08%[0m) [0.14% of initial]
[Iter 10290/20000] Loss: 0.0003860 (Best: 0.0003022 @iter10237) ([91m↑10.91%[0m) [0.15% of initial]
[Iter 12740/20000] Loss: 0.0002335 (Best: 0.0001763 @iter11810) ([92m↓8.39%[0m) [0.09% of initial]
Iter:10299, L1 loss=0.0003963, Total loss=0.000348, Time:114
[Iter 10300/20000] Loss: 0.0003559 (Best: 0.0003022 @iter10237) ([92m↓7.79%[0m) [0.14% of initial]
[Iter 12750/20000] Loss: 0.0002157 (Best: 0.0001763 @iter11810) ([92m↓7.63%[0m) [0.09% of initial]
[Iter 10310/20000] Loss: 0.0003666 (Best: 0.0003022 @iter10237) ([91m↑3.00%[0m) [0.15% of initial]
[Iter 12760/20000] Loss: 0.0002161 (Best: 0.0001763 @iter11810) ([91m↑0.19%[0m) [0.09% of initial]
[Iter 10320/20000] Loss: 0.0003705 (Best: 0.0003022 @iter10237) ([91m↑1.06%[0m) [0.15% of initial]
[Iter 12770/20000] Loss: 0.0002181 (Best: 0.0001763 @iter11810) ([91m↑0.93%[0m) [0.09% of initial]
[Iter 10330/20000] Loss: 0.0003510 (Best: 0.0003022 @iter10237) ([92m↓5.27%[0m) [0.14% of initial]
[Iter 12780/20000] Loss: 0.0002476 (Best: 0.0001763 @iter11810) ([91m↑13.53%[0m) [0.10% of initial]
[Iter 10340/20000] Loss: 0.0003675 (Best: 0.0003022 @iter10237) ([91m↑4.71%[0m) [0.15% of initial]
[Iter 12790/20000] Loss: 0.0002292 (Best: 0.0001763 @iter11810) ([92m↓7.45%[0m) [0.09% of initial]
[Iter 10350/20000] Loss: 0.0003517 (Best: 0.0003022 @iter10237) ([92m↓4.32%[0m) [0.14% of initial]
Iter:12799, L1 loss=0.0002518, Total loss=0.0002248, Time:162
[Iter 12800/20000] Loss: 0.0002332 (Best: 0.0001763 @iter11810) ([91m↑1.76%[0m) [0.09% of initial]
[Iter 10360/20000] Loss: 0.0003846 (Best: 0.0003022 @iter10237) ([91m↑9.36%[0m) [0.15% of initial]
[Iter 12810/20000] Loss: 0.0002613 (Best: 0.0001763 @iter11810) ([91m↑12.03%[0m) [0.10% of initial]
[Iter 10370/20000] Loss: 0.0003940 (Best: 0.0003022 @iter10237) ([91m↑2.45%[0m) [0.16% of initial]
[Iter 10380/20000] Loss: 0.0003681 (Best: 0.0003022 @iter10237) ([92m↓6.57%[0m) [0.15% of initial]
[Iter 12820/20000] Loss: 0.0002304 (Best: 0.0001763 @iter11810) ([92m↓11.80%[0m) [0.09% of initial]
[Iter 10390/20000] Loss: 0.0003890 (Best: 0.0003022 @iter10237) ([91m↑5.68%[0m) [0.15% of initial]
[Iter 12830/20000] Loss: 0.0002246 (Best: 0.0001763 @iter11810) ([92m↓2.52%[0m) [0.09% of initial]
Iter:10399, L1 loss=0.0003907, Total loss=0.0003501, Time:146
[Iter 10400/20000] Loss: 0.0003827 (Best: 0.0003022 @iter10237) ([92m↓1.62%[0m) [0.15% of initial]
[Iter 12840/20000] Loss: 0.0002356 (Best: 0.0001763 @iter11810) ([91m↑4.91%[0m) [0.09% of initial]
[Iter 10410/20000] Loss: 0.0003470 (Best: 0.0003022 @iter10237) ([92m↓9.34%[0m) [0.14% of initial]
[Iter 12850/20000] Loss: 0.0002167 (Best: 0.0001763 @iter11810) ([92m↓8.02%[0m) [0.09% of initial]
[Iter 10420/20000] Loss: 0.0003485 (Best: 0.0003022 @iter10237) ([91m↑0.45%[0m) [0.14% of initial]
[Iter 12860/20000] Loss: 0.0002127 (Best: 0.0001763 @iter11810) ([92m↓1.86%[0m) [0.08% of initial]
[Iter 10430/20000] Loss: 0.0003985 (Best: 0.0003022 @iter10237) ([91m↑14.33%[0m) [0.16% of initial]
[Iter 12870/20000] Loss: 0.0002047 (Best: 0.0001763 @iter11810) ([92m↓3.77%[0m) [0.08% of initial]
[Iter 10440/20000] Loss: 0.0003745 (Best: 0.0003022 @iter10237) ([92m↓6.02%[0m) [0.15% of initial]
[Iter 12880/20000] Loss: 0.0003698 (Best: 0.0001763 @iter11810) ([91m↑80.67%[0m) [0.15% of initial]
[Iter 10450/20000] Loss: 0.0003890 (Best: 0.0003022 @iter10237) ([91m↑3.89%[0m) [0.15% of initial]
[Iter 10460/20000] Loss: 0.0003318 (Best: 0.0003022 @iter10237) ([92m↓14.72%[0m) [0.13% of initial]
[Iter 12890/20000] Loss: 0.0002244 (Best: 0.0001763 @iter11810) ([92m↓39.31%[0m) [0.09% of initial]
[Iter 10470/20000] Loss: 0.0003855 (Best: 0.0003022 @iter10237) ([91m↑16.18%[0m) [0.15% of initial]
Iter:12899, L1 loss=0.0002578, Total loss=0.0002151, Time:156
[Iter 12900/20000] Loss: 0.0002016 (Best: 0.0001763 @iter11810) ([92m↓10.19%[0m) [0.08% of initial]
[Iter 10480/20000] Loss: 0.0003540 (Best: 0.0003022 @iter10237) ([92m↓8.16%[0m) [0.14% of initial]
[Iter 12910/20000] Loss: 0.0002006 (Best: 0.0001763 @iter11810) ([92m↓0.49%[0m) [0.08% of initial]
[Iter 10490/20000] Loss: 0.0003418 (Best: 0.0003022 @iter10237) ([92m↓3.46%[0m) [0.14% of initial]
[Iter 12920/20000] Loss: 0.0002209 (Best: 0.0001763 @iter11810) ([91m↑10.15%[0m) [0.09% of initial]
Iter:10499, L1 loss=0.0003827, Total loss=0.0003355, Time:140
[Iter 10500/20000] Loss: 0.0003509 (Best: 0.0003022 @iter10237) ([91m↑2.68%[0m) [0.14% of initial]
[Iter 12930/20000] Loss: 0.0002330 (Best: 0.0001763 @iter11810) ([91m↑5.47%[0m) [0.09% of initial]
Pruning 27 points (0.0%) from gaussian0 at iteration 10500
Pruning 25 points (0.0%) from gaussian1 at iteration 10500
[Iter 12940/20000] Loss: 0.0002583 (Best: 0.0001763 @iter11810) ([91m↑10.86%[0m) [0.10% of initial]
[Iter 10510/20000] Loss: 0.0006240 (Best: 0.0003022 @iter10237) ([91m↑77.83%[0m) [0.25% of initial]
[Iter 12950/20000] Loss: 0.0002633 (Best: 0.0001763 @iter11810) ([91m↑1.91%[0m) [0.10% of initial]
[Iter 10520/20000] Loss: 0.0005030 (Best: 0.0003022 @iter10237) ([92m↓19.40%[0m) [0.20% of initial]
[Iter 10530/20000] Loss: 0.0004369 (Best: 0.0003022 @iter10237) ([92m↓13.13%[0m) [0.17% of initial]
[Iter 12960/20000] Loss: 0.0002844 (Best: 0.0001763 @iter11810) ([91m↑8.03%[0m) [0.11% of initial]
[Iter 10540/20000] Loss: 0.0004475 (Best: 0.0003022 @iter10237) ([91m↑2.41%[0m) [0.18% of initial]
[Iter 12970/20000] Loss: 0.0002176 (Best: 0.0001763 @iter11810) ([92m↓23.48%[0m) [0.09% of initial]
[Iter 10550/20000] Loss: 0.0003529 (Best: 0.0003022 @iter10237) ([92m↓21.14%[0m) [0.14% of initial]
[Iter 12980/20000] Loss: 0.0002434 (Best: 0.0001763 @iter11810) ([91m↑11.86%[0m) [0.10% of initial]
[Iter 10560/20000] Loss: 0.0003357 (Best: 0.0003022 @iter10237) ([92m↓4.87%[0m) [0.13% of initial]
[Iter 12990/20000] Loss: 0.0002330 (Best: 0.0001763 @iter11810) ([92m↓4.29%[0m) [0.09% of initial]
[Iter 10570/20000] Loss: 0.0003297 (Best: 0.0003022 @iter10237) ([92m↓1.78%[0m) [0.13% of initial]
Iter:12999, L1 loss=0.0002332, Total loss=0.0001984, Time:172
[Iter 13000/20000] Loss: 0.0002107 (Best: 0.0001763 @iter11810) ([92m↓9.59%[0m) [0.08% of initial]
[Iter 10580/20000] Loss: 0.0003347 (Best: 0.0003022 @iter10237) ([91m↑1.51%[0m) [0.13% of initial]
[Iter 13010/20000] Loss: 0.0002451 (Best: 0.0001763 @iter11810) ([91m↑16.33%[0m) [0.10% of initial]
[Iter 10590/20000] Loss: 0.0003361 (Best: 0.0002998 @iter10588) ([91m↑0.41%[0m) [0.13% of initial]
[Iter 13020/20000] Loss: 0.0002388 (Best: 0.0001763 @iter11810) ([92m↓2.57%[0m) [0.09% of initial]
Iter:10599, L1 loss=0.000371, Total loss=0.0003165, Time:108
[Iter 10600/20000] Loss: 0.0003288 (Best: 0.0002926 @iter10591) ([92m↓2.17%[0m) [0.13% of initial]
[Iter 13030/20000] Loss: 0.0002232 (Best: 0.0001763 @iter11810) ([92m↓6.52%[0m) [0.09% of initial]
[Iter 10610/20000] Loss: 0.0003220 (Best: 0.0002881 @iter10603) ([92m↓2.07%[0m) [0.13% of initial]
[Iter 13040/20000] Loss: 0.0002742 (Best: 0.0001763 @iter11810) ([91m↑22.86%[0m) [0.11% of initial]
[Iter 10620/20000] Loss: 0.0003228 (Best: 0.0002881 @iter10603) ([91m↑0.25%[0m) [0.13% of initial]
[Iter 10630/20000] Loss: 0.0003399 (Best: 0.0002881 @iter10603) ([91m↑5.29%[0m) [0.14% of initial]
[Iter 13050/20000] Loss: 0.0002258 (Best: 0.0001763 @iter11810) ([92m↓17.67%[0m) [0.09% of initial]
[Iter 10640/20000] Loss: 0.0003930 (Best: 0.0002881 @iter10603) ([91m↑15.63%[0m) [0.16% of initial]
[Iter 13060/20000] Loss: 0.0002215 (Best: 0.0001763 @iter11810) ([92m↓1.91%[0m) [0.09% of initial]
[Iter 10650/20000] Loss: 0.0004413 (Best: 0.0002881 @iter10603) ([91m↑12.29%[0m) [0.18% of initial]
[Iter 13070/20000] Loss: 0.0002441 (Best: 0.0001763 @iter11810) ([91m↑10.24%[0m) [0.10% of initial]
[Iter 10660/20000] Loss: 0.0003754 (Best: 0.0002881 @iter10603) ([92m↓14.92%[0m) [0.15% of initial]
[Iter 13080/20000] Loss: 0.0002316 (Best: 0.0001763 @iter11810) ([92m↓5.12%[0m) [0.09% of initial]
[Iter 10670/20000] Loss: 0.0003586 (Best: 0.0002881 @iter10603) ([92m↓4.48%[0m) [0.14% of initial]
[Iter 13090/20000] Loss: 0.0002388 (Best: 0.0001763 @iter11810) ([91m↑3.10%[0m) [0.09% of initial]
[Iter 10680/20000] Loss: 0.0003353 (Best: 0.0002881 @iter10603) ([92m↓6.49%[0m) [0.13% of initial]
Iter:13099, L1 loss=0.0002665, Total loss=0.0002123, Time:170
[Iter 13100/20000] Loss: 0.0002300 (Best: 0.0001763 @iter11810) ([92m↓3.70%[0m) [0.09% of initial]
[Iter 10690/20000] Loss: 0.0003384 (Best: 0.0002881 @iter10603) ([91m↑0.93%[0m) [0.13% of initial]
[Iter 13110/20000] Loss: 0.0002422 (Best: 0.0001763 @iter11810) ([91m↑5.31%[0m) [0.10% of initial]
Iter:10699, L1 loss=0.0004076, Total loss=0.0003546, Time:143
[Iter 10700/20000] Loss: 0.0003728 (Best: 0.0002881 @iter10603) ([91m↑10.17%[0m) [0.15% of initial]
[Iter 10710/20000] Loss: 0.0003628 (Best: 0.0002881 @iter10603) ([92m↓2.69%[0m) [0.14% of initial]
[Iter 13120/20000] Loss: 0.0002381 (Best: 0.0001763 @iter11810) ([92m↓1.71%[0m) [0.09% of initial]
[Iter 10720/20000] Loss: 0.0003806 (Best: 0.0002881 @iter10603) ([91m↑4.90%[0m) [0.15% of initial]
[Iter 13130/20000] Loss: 0.0002433 (Best: 0.0001763 @iter11810) ([91m↑2.18%[0m) [0.10% of initial]
[Iter 10730/20000] Loss: 0.0003926 (Best: 0.0002881 @iter10603) ([91m↑3.15%[0m) [0.16% of initial]
[Iter 13140/20000] Loss: 0.0002303 (Best: 0.0001763 @iter11810) ([92m↓5.31%[0m) [0.09% of initial]
[Iter 10740/20000] Loss: 0.0003539 (Best: 0.0002881 @iter10603) ([92m↓9.86%[0m) [0.14% of initial]
[Iter 13150/20000] Loss: 0.0002086 (Best: 0.0001763 @iter11810) ([92m↓9.45%[0m) [0.08% of initial]
[Iter 10750/20000] Loss: 0.0003536 (Best: 0.0002881 @iter10603) ([92m↓0.07%[0m) [0.14% of initial]
[Iter 13160/20000] Loss: 0.0002267 (Best: 0.0001763 @iter11810) ([91m↑8.69%[0m) [0.09% of initial]
[Iter 10760/20000] Loss: 0.0003199 (Best: 0.0002881 @iter10603) ([92m↓9.52%[0m) [0.13% of initial]
[Iter 13170/20000] Loss: 0.0002219 (Best: 0.0001763 @iter11810) ([92m↓2.12%[0m) [0.09% of initial]
[Iter 10770/20000] Loss: 0.0003102 (Best: 0.0002881 @iter10603) ([92m↓3.04%[0m) [0.12% of initial]
[Iter 13180/20000] Loss: 0.0002418 (Best: 0.0001763 @iter11810) ([91m↑8.98%[0m) [0.10% of initial]
[Iter 10780/20000] Loss: 0.0003073 (Best: 0.0002850 @iter10774) ([92m↓0.93%[0m) [0.12% of initial]
[Iter 13190/20000] Loss: 0.0002310 (Best: 0.0001763 @iter11810) ([92m↓4.48%[0m) [0.09% of initial]
[Iter 10790/20000] Loss: 0.0003365 (Best: 0.0002838 @iter10784) ([91m↑9.49%[0m) [0.13% of initial]
Iter:10799, L1 loss=0.0003617, Total loss=0.0003284, Time:98
[Iter 10800/20000] Loss: 0.0003602 (Best: 0.0002838 @iter10784) ([91m↑7.05%[0m) [0.14% of initial]
Iter:13199, L1 loss=0.0002662, Total loss=0.0002239, Time:124
[Iter 13200/20000] Loss: 0.0002339 (Best: 0.0001763 @iter11810) ([91m↑1.24%[0m) [0.09% of initial]
[Iter 10810/20000] Loss: 0.0003998 (Best: 0.0002838 @iter10784) ([91m↑10.98%[0m) [0.16% of initial]
[Iter 13210/20000] Loss: 0.0002369 (Best: 0.0001763 @iter11810) ([91m↑1.30%[0m) [0.09% of initial]
[Iter 10820/20000] Loss: 0.0003749 (Best: 0.0002838 @iter10784) ([92m↓6.22%[0m) [0.15% of initial]
[Iter 13220/20000] Loss: 0.0001964 (Best: 0.0001763 @iter11810) ([92m↓17.11%[0m) [0.08% of initial]
[Iter 10830/20000] Loss: 0.0003757 (Best: 0.0002838 @iter10784) ([91m↑0.21%[0m) [0.15% of initial]
[Iter 13230/20000] Loss: 0.0002410 (Best: 0.0001763 @iter11810) ([91m↑22.76%[0m) [0.10% of initial]
[Iter 10840/20000] Loss: 0.0003373 (Best: 0.0002838 @iter10784) ([92m↓10.22%[0m) [0.13% of initial]
[Iter 13240/20000] Loss: 0.0002127 (Best: 0.0001763 @iter11810) ([92m↓11.77%[0m) [0.08% of initial]
[Iter 10850/20000] Loss: 0.0003572 (Best: 0.0002838 @iter10784) ([91m↑5.90%[0m) [0.14% of initial]
[Iter 13250/20000] Loss: 0.0002154 (Best: 0.0001763 @iter11810) ([91m↑1.29%[0m) [0.09% of initial]
[Iter 10860/20000] Loss: 0.0003310 (Best: 0.0002838 @iter10784) ([92m↓7.35%[0m) [0.13% of initial]
[Iter 13260/20000] Loss: 0.0002057 (Best: 0.0001763 @iter11810) ([92m↓4.52%[0m) [0.08% of initial]
[Iter 10870/20000] Loss: 0.0003373 (Best: 0.0002838 @iter10784) ([91m↑1.91%[0m) [0.13% of initial]
[Iter 10880/20000] Loss: 0.0003290 (Best: 0.0002838 @iter10784) ([92m↓2.44%[0m) [0.13% of initial]
[Iter 13270/20000] Loss: 0.0002134 (Best: 0.0001763 @iter11810) ([91m↑3.75%[0m) [0.08% of initial]
[Iter 10890/20000] Loss: 0.0003429 (Best: 0.0002838 @iter10784) ([91m↑4.22%[0m) [0.14% of initial]
[Iter 13280/20000] Loss: 0.0002227 (Best: 0.0001763 @iter11810) ([91m↑4.38%[0m) [0.09% of initial]
Iter:10899, L1 loss=0.0006095, Total loss=0.000381, Time:137
[Iter 10900/20000] Loss: 0.0003586 (Best: 0.0002838 @iter10784) ([91m↑4.58%[0m) [0.14% of initial]
[Iter 13290/20000] Loss: 0.0001968 (Best: 0.0001763 @iter11810) ([92m↓11.66%[0m) [0.08% of initial]
[Iter 10910/20000] Loss: 0.0003431 (Best: 0.0002838 @iter10784) ([92m↓4.34%[0m) [0.14% of initial]
Iter:13299, L1 loss=0.0002314, Total loss=0.0001924, Time:156
[Iter 13300/20000] Loss: 0.0001951 (Best: 0.0001746 @iter13291) ([92m↓0.84%[0m) [0.08% of initial]
[Iter 10920/20000] Loss: 0.0003251 (Best: 0.0002791 @iter10915) ([92m↓5.23%[0m) [0.13% of initial]
[Iter 13310/20000] Loss: 0.0002039 (Best: 0.0001746 @iter13291) ([91m↑4.52%[0m) [0.08% of initial]
[Iter 10930/20000] Loss: 0.0003205 (Best: 0.0002791 @iter10915) ([92m↓1.41%[0m) [0.13% of initial]
[Iter 13320/20000] Loss: 0.0002031 (Best: 0.0001746 @iter13291) ([92m↓0.40%[0m) [0.08% of initial]
[Iter 10940/20000] Loss: 0.0003502 (Best: 0.0002791 @iter10915) ([91m↑9.27%[0m) [0.14% of initial]
[Iter 13330/20000] Loss: 0.0002012 (Best: 0.0001746 @iter13291) ([92m↓0.93%[0m) [0.08% of initial]
[Iter 10950/20000] Loss: 0.0003226 (Best: 0.0002791 @iter10915) ([92m↓7.88%[0m) [0.13% of initial]
[Iter 10960/20000] Loss: 0.0003266 (Best: 0.0002791 @iter10915) ([91m↑1.22%[0m) [0.13% of initial]
[Iter 13340/20000] Loss: 0.0002082 (Best: 0.0001746 @iter13291) ([91m↑3.46%[0m) [0.08% of initial]
[Iter 10970/20000] Loss: 0.0003135 (Best: 0.0002791 @iter10915) ([92m↓4.00%[0m) [0.12% of initial]
[Iter 13350/20000] Loss: 0.0001928 (Best: 0.0001676 @iter13345) ([92m↓7.38%[0m) [0.08% of initial]
[Iter 10980/20000] Loss: 0.0002992 (Best: 0.0002791 @iter10915) ([92m↓4.58%[0m) [0.12% of initial]
[Iter 13360/20000] Loss: 0.0002023 (Best: 0.0001676 @iter13345) ([91m↑4.91%[0m) [0.08% of initial]
[Iter 10990/20000] Loss: 0.0003159 (Best: 0.0002791 @iter10915) ([91m↑5.59%[0m) [0.13% of initial]
[Iter 13370/20000] Loss: 0.0001786 (Best: 0.0001661 @iter13370) ([92m↓11.72%[0m) [0.07% of initial]
Iter:10999, L1 loss=0.000368, Total loss=0.000334, Time:139
[Iter 11000/20000] Loss: 0.0003096 (Best: 0.0002791 @iter10915) ([92m↓2.01%[0m) [0.12% of initial]
[Iter 13380/20000] Loss: 0.0002133 (Best: 0.0001661 @iter13370) ([91m↑19.46%[0m) [0.08% of initial]
Pruning 21 points (0.0%) from gaussian0 at iteration 11000
Pruning 19 points (0.0%) from gaussian1 at iteration 11000
[Iter 13390/20000] Loss: 0.0002079 (Best: 0.0001661 @iter13370) ([92m↓2.53%[0m) [0.08% of initial]
[Iter 11010/20000] Loss: 0.0006918 (Best: 0.0002791 @iter10915) ([91m↑123.48%[0m) [0.27% of initial]
Iter:13399, L1 loss=0.0002242, Total loss=0.0001833, Time:159
[Iter 13400/20000] Loss: 0.0001987 (Best: 0.0001661 @iter13370) ([92m↓4.43%[0m) [0.08% of initial]
[Iter 11020/20000] Loss: 0.0005199 (Best: 0.0002791 @iter10915) ([92m↓24.84%[0m) [0.21% of initial]
[Iter 13410/20000] Loss: 0.0001990 (Best: 0.0001661 @iter13370) ([91m↑0.12%[0m) [0.08% of initial]
[Iter 11030/20000] Loss: 0.0003885 (Best: 0.0002791 @iter10915) ([92m↓25.28%[0m) [0.15% of initial]
[Iter 11040/20000] Loss: 0.0003401 (Best: 0.0002791 @iter10915) ([92m↓12.46%[0m) [0.14% of initial]
[Iter 13420/20000] Loss: 0.0002054 (Best: 0.0001661 @iter13370) ([91m↑3.26%[0m) [0.08% of initial]
[Iter 11050/20000] Loss: 0.0003963 (Best: 0.0002791 @iter10915) ([91m↑16.52%[0m) [0.16% of initial]
[Iter 13430/20000] Loss: 0.0001868 (Best: 0.0001661 @iter13370) ([92m↓9.08%[0m) [0.07% of initial]
[Iter 11060/20000] Loss: 0.0003058 (Best: 0.0002791 @iter10915) ([92m↓22.84%[0m) [0.12% of initial]
[Iter 13440/20000] Loss: 0.0001969 (Best: 0.0001661 @iter13370) ([91m↑5.44%[0m) [0.08% of initial]
[Iter 11070/20000] Loss: 0.0003238 (Best: 0.0002791 @iter10915) ([91m↑5.90%[0m) [0.13% of initial]
[Iter 13450/20000] Loss: 0.0001856 (Best: 0.0001661 @iter13370) ([92m↓5.78%[0m) [0.07% of initial]
[Iter 11080/20000] Loss: 0.0003012 (Best: 0.0002791 @iter10915) ([92m↓7.00%[0m) [0.12% of initial]
[Iter 13460/20000] Loss: 0.0001841 (Best: 0.0001661 @iter13370) ([92m↓0.79%[0m) [0.07% of initial]
[Iter 11090/20000] Loss: 0.0003233 (Best: 0.0002791 @iter10915) ([91m↑7.36%[0m) [0.13% of initial]
[Iter 13470/20000] Loss: 0.0002067 (Best: 0.0001661 @iter13370) ([91m↑12.29%[0m) [0.08% of initial]
Iter:11099, L1 loss=0.0003463, Total loss=0.0002982, Time:118
[Iter 11100/20000] Loss: 0.0003267 (Best: 0.0002791 @iter10915) ([91m↑1.04%[0m) [0.13% of initial]
[Iter 13480/20000] Loss: 0.0002001 (Best: 0.0001661 @iter13370) ([92m↓3.18%[0m) [0.08% of initial]
[Iter 11110/20000] Loss: 0.0003622 (Best: 0.0002791 @iter10915) ([91m↑10.86%[0m) [0.14% of initial]
[Iter 13490/20000] Loss: 0.0002729 (Best: 0.0001661 @iter13370) ([91m↑36.35%[0m) [0.11% of initial]
[Iter 11120/20000] Loss: 0.0003201 (Best: 0.0002791 @iter10915) ([92m↓11.60%[0m) [0.13% of initial]
Iter:13499, L1 loss=0.000265, Total loss=0.0002355, Time:175
[Iter 11130/20000] Loss: 0.0003720 (Best: 0.0002791 @iter10915) ([91m↑16.20%[0m) [0.15% of initial]
[Iter 13500/20000] Loss: 0.0002391 (Best: 0.0001661 @iter13370) ([92m↓12.38%[0m) [0.09% of initial]
[Iter 11140/20000] Loss: 0.0003333 (Best: 0.0002791 @iter10915) ([92m↓10.40%[0m) [0.13% of initial]
[Iter 13510/20000] Loss: 0.0002557 (Best: 0.0001661 @iter13370) ([91m↑6.96%[0m) [0.10% of initial]
[Iter 11150/20000] Loss: 0.0003284 (Best: 0.0002791 @iter10915) ([92m↓1.47%[0m) [0.13% of initial]
[Iter 13520/20000] Loss: 0.0002160 (Best: 0.0001661 @iter13370) ([92m↓15.54%[0m) [0.09% of initial]
[Iter 11160/20000] Loss: 0.0003409 (Best: 0.0002791 @iter10915) ([91m↑3.82%[0m) [0.14% of initial]
[Iter 13530/20000] Loss: 0.0002165 (Best: 0.0001661 @iter13370) ([91m↑0.24%[0m) [0.09% of initial]
[Iter 11170/20000] Loss: 0.0003571 (Best: 0.0002791 @iter10915) ([91m↑4.75%[0m) [0.14% of initial]
[Iter 13540/20000] Loss: 0.0001975 (Best: 0.0001661 @iter13370) ([92m↓8.80%[0m) [0.08% of initial]
[Iter 11180/20000] Loss: 0.0003358 (Best: 0.0002791 @iter10915) ([92m↓5.97%[0m) [0.13% of initial]
[Iter 13550/20000] Loss: 0.0002229 (Best: 0.0001661 @iter13370) ([91m↑12.90%[0m) [0.09% of initial]
[Iter 11190/20000] Loss: 0.0003582 (Best: 0.0002791 @iter10915) ([91m↑6.68%[0m) [0.14% of initial]
Iter:11199, L1 loss=0.0004014, Total loss=0.0003481, Time:164
[Iter 11200/20000] Loss: 0.0003478 (Best: 0.0002791 @iter10915) ([92m↓2.92%[0m) [0.14% of initial]
[Iter 13560/20000] Loss: 0.0002272 (Best: 0.0001661 @iter13370) ([91m↑1.89%[0m) [0.09% of initial]
[Iter 11210/20000] Loss: 0.0003145 (Best: 0.0002791 @iter10915) ([92m↓9.56%[0m) [0.12% of initial]
[Iter 13570/20000] Loss: 0.0001985 (Best: 0.0001661 @iter13370) ([92m↓12.64%[0m) [0.08% of initial]
[Iter 11220/20000] Loss: 0.0003262 (Best: 0.0002791 @iter10915) ([91m↑3.71%[0m) [0.13% of initial]
[Iter 13580/20000] Loss: 0.0002432 (Best: 0.0001661 @iter13370) ([91m↑22.55%[0m) [0.10% of initial]
[Iter 11230/20000] Loss: 0.0003157 (Best: 0.0002777 @iter11227) ([92m↓3.21%[0m) [0.13% of initial]
[Iter 13590/20000] Loss: 0.0002413 (Best: 0.0001661 @iter13370) ([92m↓0.78%[0m) [0.10% of initial]
[Iter 11240/20000] Loss: 0.0003113 (Best: 0.0002777 @iter11227) ([92m↓1.39%[0m) [0.12% of initial]
Iter:13599, L1 loss=0.0002453, Total loss=0.0002047, Time:149
[Iter 13600/20000] Loss: 0.0001999 (Best: 0.0001661 @iter13370) ([92m↓17.15%[0m) [0.08% of initial]
[Iter 11250/20000] Loss: 0.0003136 (Best: 0.0002750 @iter11242) ([91m↑0.72%[0m) [0.12% of initial]
[Iter 13610/20000] Loss: 0.0002094 (Best: 0.0001661 @iter13370) ([91m↑4.75%[0m) [0.08% of initial]
[Iter 11260/20000] Loss: 0.0002915 (Best: 0.0002750 @iter11242) ([92m↓7.05%[0m) [0.12% of initial]
[Iter 13620/20000] Loss: 0.0001893 (Best: 0.0001661 @iter13370) ([92m↓9.61%[0m) [0.08% of initial]
[Iter 11270/20000] Loss: 0.0002853 (Best: 0.0002700 @iter11263) ([92m↓2.13%[0m) [0.11% of initial]
[Iter 11280/20000] Loss: 0.0003135 (Best: 0.0002700 @iter11263) ([91m↑9.88%[0m) [0.12% of initial]
[Iter 13630/20000] Loss: 0.0001833 (Best: 0.0001661 @iter13370) ([92m↓3.16%[0m) [0.07% of initial]
[Iter 11290/20000] Loss: 0.0003075 (Best: 0.0002700 @iter11263) ([92m↓1.89%[0m) [0.12% of initial]
[Iter 13640/20000] Loss: 0.0002341 (Best: 0.0001661 @iter13370) ([91m↑27.72%[0m) [0.09% of initial]
Iter:11299, L1 loss=0.0003251, Total loss=0.0003007, Time:121
[Iter 11300/20000] Loss: 0.0003203 (Best: 0.0002700 @iter11263) ([91m↑4.15%[0m) [0.13% of initial]
[Iter 13650/20000] Loss: 0.0002188 (Best: 0.0001661 @iter13370) ([92m↓6.53%[0m) [0.09% of initial]
[Iter 11310/20000] Loss: 0.0002874 (Best: 0.0002700 @iter11263) ([92m↓10.26%[0m) [0.11% of initial]
[Iter 13660/20000] Loss: 0.0002012 (Best: 0.0001661 @iter13370) ([92m↓8.04%[0m) [0.08% of initial]
[Iter 11320/20000] Loss: 0.0003043 (Best: 0.0002646 @iter11315) ([91m↑5.86%[0m) [0.12% of initial]
[Iter 13670/20000] Loss: 0.0002355 (Best: 0.0001661 @iter13370) ([91m↑17.01%[0m) [0.09% of initial]
[Iter 11330/20000] Loss: 0.0003091 (Best: 0.0002646 @iter11315) ([91m↑1.59%[0m) [0.12% of initial]
[Iter 13680/20000] Loss: 0.0002213 (Best: 0.0001661 @iter13370) ([92m↓6.02%[0m) [0.09% of initial]
[Iter 11340/20000] Loss: 0.0003320 (Best: 0.0002646 @iter11315) ([91m↑7.40%[0m) [0.13% of initial]
[Iter 11350/20000] Loss: 0.0004007 (Best: 0.0002646 @iter11315) ([91m↑20.69%[0m) [0.16% of initial]
[Iter 13690/20000] Loss: 0.0002454 (Best: 0.0001661 @iter13370) ([91m↑10.87%[0m) [0.10% of initial]
[Iter 11360/20000] Loss: 0.0003080 (Best: 0.0002646 @iter11315) ([92m↓23.14%[0m) [0.12% of initial]
Iter:13699, L1 loss=0.0002863, Total loss=0.0002356, Time:169
[Iter 13700/20000] Loss: 0.0002234 (Best: 0.0001661 @iter13370) ([92m↓8.94%[0m) [0.09% of initial]
[Iter 11370/20000] Loss: 0.0003469 (Best: 0.0002646 @iter11315) ([91m↑12.64%[0m) [0.14% of initial]
[Iter 13710/20000] Loss: 0.0002028 (Best: 0.0001661 @iter13370) ([92m↓9.23%[0m) [0.08% of initial]
[Iter 11380/20000] Loss: 0.0003593 (Best: 0.0002646 @iter11315) ([91m↑3.58%[0m) [0.14% of initial]
[Iter 13720/20000] Loss: 0.0002185 (Best: 0.0001661 @iter13370) ([91m↑7.73%[0m) [0.09% of initial]
[Iter 11390/20000] Loss: 0.0003696 (Best: 0.0002646 @iter11315) ([91m↑2.85%[0m) [0.15% of initial]
[Iter 13730/20000] Loss: 0.0002209 (Best: 0.0001661 @iter13370) ([91m↑1.07%[0m) [0.09% of initial]
Iter:11399, L1 loss=0.0003994, Total loss=0.000354, Time:121
[Iter 11400/20000] Loss: 0.0003593 (Best: 0.0002646 @iter11315) ([92m↓2.79%[0m) [0.14% of initial]
[Iter 13740/20000] Loss: 0.0002192 (Best: 0.0001661 @iter13370) ([92m↓0.75%[0m) [0.09% of initial]
[Iter 11410/20000] Loss: 0.0003322 (Best: 0.0002646 @iter11315) ([92m↓7.55%[0m) [0.13% of initial]
[Iter 11420/20000] Loss: 0.0003024 (Best: 0.0002646 @iter11315) ([92m↓8.97%[0m) [0.12% of initial]
[Iter 13750/20000] Loss: 0.0001970 (Best: 0.0001661 @iter13370) ([92m↓10.15%[0m) [0.08% of initial]
[Iter 11430/20000] Loss: 0.0003479 (Best: 0.0002646 @iter11315) ([91m↑15.06%[0m) [0.14% of initial]
[Iter 13760/20000] Loss: 0.0002092 (Best: 0.0001661 @iter13370) ([91m↑6.21%[0m) [0.08% of initial]
[Iter 11440/20000] Loss: 0.0003441 (Best: 0.0002646 @iter11315) ([92m↓1.10%[0m) [0.14% of initial]
[Iter 13770/20000] Loss: 0.0002244 (Best: 0.0001661 @iter13370) ([91m↑7.27%[0m) [0.09% of initial]
[Iter 11450/20000] Loss: 0.0003567 (Best: 0.0002646 @iter11315) ([91m↑3.66%[0m) [0.14% of initial]
[Iter 13780/20000] Loss: 0.0002249 (Best: 0.0001661 @iter13370) ([91m↑0.24%[0m) [0.09% of initial]
[Iter 11460/20000] Loss: 0.0003178 (Best: 0.0002646 @iter11315) ([92m↓10.90%[0m) [0.13% of initial]
[Iter 13790/20000] Loss: 0.0002704 (Best: 0.0001661 @iter13370) ([91m↑20.24%[0m) [0.11% of initial]
[Iter 11470/20000] Loss: 0.0003094 (Best: 0.0002646 @iter11315) ([92m↓2.65%[0m) [0.12% of initial]
Iter:13799, L1 loss=0.0002665, Total loss=0.0002289, Time:194
[Iter 13800/20000] Loss: 0.0002161 (Best: 0.0001661 @iter13370) ([92m↓20.11%[0m) [0.09% of initial]
[Iter 11480/20000] Loss: 0.0003033 (Best: 0.0002646 @iter11315) ([92m↓1.95%[0m) [0.12% of initial]
[Iter 11490/20000] Loss: 0.0003136 (Best: 0.0002646 @iter11315) ([91m↑3.38%[0m) [0.12% of initial]
[Iter 13810/20000] Loss: 0.0002229 (Best: 0.0001661 @iter13370) ([91m↑3.14%[0m) [0.09% of initial]
Iter:11499, L1 loss=0.0004436, Total loss=0.0003728, Time:159
[Iter 11500/20000] Loss: 0.0003241 (Best: 0.0002646 @iter11315) ([91m↑3.35%[0m) [0.13% of initial]
[Iter 13820/20000] Loss: 0.0002221 (Best: 0.0001661 @iter13370) ([92m↓0.32%[0m) [0.09% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 11500
Pruning 18 points (0.0%) from gaussian1 at iteration 11500
[Iter 13830/20000] Loss: 0.0002228 (Best: 0.0001661 @iter13370) ([91m↑0.30%[0m) [0.09% of initial]
[Iter 11510/20000] Loss: 0.0006101 (Best: 0.0002646 @iter11315) ([91m↑88.24%[0m) [0.24% of initial]
[Iter 13840/20000] Loss: 0.0002131 (Best: 0.0001661 @iter13370) ([92m↓4.36%[0m) [0.08% of initial]
[Iter 11520/20000] Loss: 0.0004357 (Best: 0.0002646 @iter11315) ([92m↓28.58%[0m) [0.17% of initial]
[Iter 13850/20000] Loss: 0.0001979 (Best: 0.0001661 @iter13370) ([92m↓7.14%[0m) [0.08% of initial]
[Iter 11530/20000] Loss: 0.0003630 (Best: 0.0002646 @iter11315) ([92m↓16.70%[0m) [0.14% of initial]
[Iter 13860/20000] Loss: 0.0001935 (Best: 0.0001661 @iter13370) ([92m↓2.20%[0m) [0.08% of initial]
[Iter 11540/20000] Loss: 0.0003303 (Best: 0.0002646 @iter11315) ([92m↓9.01%[0m) [0.13% of initial]
[Iter 13870/20000] Loss: 0.0001918 (Best: 0.0001661 @iter13370) ([92m↓0.88%[0m) [0.08% of initial]
[Iter 11550/20000] Loss: 0.0003243 (Best: 0.0002646 @iter11315) ([92m↓1.83%[0m) [0.13% of initial]
[Iter 11560/20000] Loss: 0.0003230 (Best: 0.0002646 @iter11315) ([92m↓0.37%[0m) [0.13% of initial]
[Iter 13880/20000] Loss: 0.0002039 (Best: 0.0001661 @iter13370) ([91m↑6.28%[0m) [0.08% of initial]
[Iter 11570/20000] Loss: 0.0003153 (Best: 0.0002646 @iter11315) ([92m↓2.39%[0m) [0.13% of initial]
[Iter 13890/20000] Loss: 0.0002050 (Best: 0.0001661 @iter13370) ([91m↑0.56%[0m) [0.08% of initial]
[Iter 11580/20000] Loss: 0.0003330 (Best: 0.0002646 @iter11315) ([91m↑5.61%[0m) [0.13% of initial]
Iter:13899, L1 loss=0.000296, Total loss=0.0002461, Time:180
[Iter 13900/20000] Loss: 0.0002210 (Best: 0.0001661 @iter13370) ([91m↑7.78%[0m) [0.09% of initial]
[Iter 11590/20000] Loss: 0.0003112 (Best: 0.0002646 @iter11315) ([92m↓6.54%[0m) [0.12% of initial]
[Iter 13910/20000] Loss: 0.0002077 (Best: 0.0001661 @iter13370) ([92m↓6.02%[0m) [0.08% of initial]
Iter:11599, L1 loss=0.0003252, Total loss=0.0002993, Time:155
[Iter 11600/20000] Loss: 0.0003065 (Best: 0.0002646 @iter11315) ([92m↓1.51%[0m) [0.12% of initial]
[Iter 13920/20000] Loss: 0.0002198 (Best: 0.0001661 @iter13370) ([91m↑5.84%[0m) [0.09% of initial]
[Iter 11610/20000] Loss: 0.0003055 (Best: 0.0002646 @iter11315) ([92m↓0.33%[0m) [0.12% of initial]
[Iter 13930/20000] Loss: 0.0001938 (Best: 0.0001661 @iter13370) ([92m↓11.83%[0m) [0.08% of initial]
[Iter 11620/20000] Loss: 0.0003037 (Best: 0.0002646 @iter11315) ([92m↓0.59%[0m) [0.12% of initial]
[Iter 11630/20000] Loss: 0.0002693 (Best: 0.0002579 @iter11630) ([92m↓11.32%[0m) [0.11% of initial]
[Iter 13940/20000] Loss: 0.0001992 (Best: 0.0001661 @iter13370) ([91m↑2.82%[0m) [0.08% of initial]
[Iter 11640/20000] Loss: 0.0003148 (Best: 0.0002579 @iter11630) ([91m↑16.86%[0m) [0.13% of initial]
[Iter 13950/20000] Loss: 0.0002062 (Best: 0.0001661 @iter13370) ([91m↑3.49%[0m) [0.08% of initial]
[Iter 11650/20000] Loss: 0.0003203 (Best: 0.0002579 @iter11630) ([91m↑1.77%[0m) [0.13% of initial]
[Iter 13960/20000] Loss: 0.0001820 (Best: 0.0001661 @iter13370) ([92m↓11.75%[0m) [0.07% of initial]
[Iter 11660/20000] Loss: 0.0003195 (Best: 0.0002579 @iter11630) ([92m↓0.26%[0m) [0.13% of initial]
[Iter 13970/20000] Loss: 0.0002052 (Best: 0.0001661 @iter13370) ([91m↑12.77%[0m) [0.08% of initial]
[Iter 11670/20000] Loss: 0.0002996 (Best: 0.0002579 @iter11630) ([92m↓6.23%[0m) [0.12% of initial]
[Iter 13980/20000] Loss: 0.0002102 (Best: 0.0001661 @iter13370) ([91m↑2.41%[0m) [0.08% of initial]
[Iter 11680/20000] Loss: 0.0003155 (Best: 0.0002579 @iter11630) ([91m↑5.30%[0m) [0.13% of initial]
[Iter 13990/20000] Loss: 0.0002679 (Best: 0.0001661 @iter13370) ([91m↑27.48%[0m) [0.11% of initial]
[Iter 11690/20000] Loss: 0.0003029 (Best: 0.0002579 @iter11630) ([92m↓3.99%[0m) [0.12% of initial]
Iter:11699, L1 loss=0.0003253, Total loss=0.0002778, Time:137
Iter:13999, L1 loss=0.0002336, Total loss=0.000191, Time:159
[Iter 11700/20000] Loss: 0.0002825 (Best: 0.0002579 @iter11630) ([92m↓6.74%[0m) [0.11% of initial]
[Iter 14000/20000] Loss: 0.0002129 (Best: 0.0001661 @iter13370) ([92m↓20.54%[0m) [0.08% of initial]
[Iter 11710/20000] Loss: 0.0002846 (Best: 0.0002579 @iter11630) ([91m↑0.74%[0m) [0.11% of initial]
[Iter 14010/20000] Loss: 0.0002267 (Best: 0.0001661 @iter13370) ([91m↑6.52%[0m) [0.09% of initial]
[Iter 11720/20000] Loss: 0.0002813 (Best: 0.0002546 @iter11716) ([92m↓1.15%[0m) [0.11% of initial]
[Iter 14020/20000] Loss: 0.0002154 (Best: 0.0001661 @iter13370) ([92m↓5.01%[0m) [0.09% of initial]
[Iter 11730/20000] Loss: 0.0002997 (Best: 0.0002546 @iter11716) ([91m↑6.55%[0m) [0.12% of initial]
[Iter 14030/20000] Loss: 0.0002200 (Best: 0.0001661 @iter13370) ([91m↑2.17%[0m) [0.09% of initial]
[Iter 11740/20000] Loss: 0.0003233 (Best: 0.0002546 @iter11716) ([91m↑7.86%[0m) [0.13% of initial]
[Iter 14040/20000] Loss: 0.0002169 (Best: 0.0001661 @iter13370) ([92m↓1.44%[0m) [0.09% of initial]
[Iter 11750/20000] Loss: 0.0003307 (Best: 0.0002546 @iter11716) ([91m↑2.30%[0m) [0.13% of initial]
[Iter 14050/20000] Loss: 0.0002544 (Best: 0.0001661 @iter13370) ([91m↑17.29%[0m) [0.10% of initial]
[Iter 11760/20000] Loss: 0.0003582 (Best: 0.0002546 @iter11716) ([91m↑8.33%[0m) [0.14% of initial]
[Iter 11770/20000] Loss: 0.0003065 (Best: 0.0002546 @iter11716) ([92m↓14.43%[0m) [0.12% of initial]
[Iter 14060/20000] Loss: 0.0002714 (Best: 0.0001661 @iter13370) ([91m↑6.68%[0m) [0.11% of initial]
[Iter 11780/20000] Loss: 0.0003105 (Best: 0.0002546 @iter11716) ([91m↑1.30%[0m) [0.12% of initial]
[Iter 14070/20000] Loss: 0.0002431 (Best: 0.0001661 @iter13370) ([92m↓10.43%[0m) [0.10% of initial]
[Iter 11790/20000] Loss: 0.0002897 (Best: 0.0002546 @iter11716) ([92m↓6.71%[0m) [0.12% of initial]
[Iter 14080/20000] Loss: 0.0002136 (Best: 0.0001661 @iter13370) ([92m↓12.13%[0m) [0.08% of initial]
Iter:11799, L1 loss=0.0003439, Total loss=0.0003014, Time:135
[Iter 11800/20000] Loss: 0.0002815 (Best: 0.0002546 @iter11716) ([92m↓2.82%[0m) [0.11% of initial]
[Iter 14090/20000] Loss: 0.0002202 (Best: 0.0001661 @iter13370) ([91m↑3.11%[0m) [0.09% of initial]
[Iter 11810/20000] Loss: 0.0002659 (Best: 0.0002546 @iter11716) ([92m↓5.54%[0m) [0.11% of initial]
Iter:14099, L1 loss=0.0002617, Total loss=0.0002225, Time:141
[Iter 14100/20000] Loss: 0.0002178 (Best: 0.0001661 @iter13370) ([92m↓1.12%[0m) [0.09% of initial]
[Iter 11820/20000] Loss: 0.0002895 (Best: 0.0002546 @iter11716) ([91m↑8.87%[0m) [0.12% of initial]
[Iter 14110/20000] Loss: 0.0002596 (Best: 0.0001661 @iter13370) ([91m↑19.19%[0m) [0.10% of initial]
[Iter 11830/20000] Loss: 0.0003213 (Best: 0.0002546 @iter11716) ([91m↑11.00%[0m) [0.13% of initial]
[Iter 11840/20000] Loss: 0.0003118 (Best: 0.0002546 @iter11716) ([92m↓2.97%[0m) [0.12% of initial]
[Iter 14120/20000] Loss: 0.0002285 (Best: 0.0001661 @iter13370) ([92m↓11.96%[0m) [0.09% of initial]
[Iter 11850/20000] Loss: 0.0003009 (Best: 0.0002546 @iter11716) ([92m↓3.49%[0m) [0.12% of initial]
[Iter 14130/20000] Loss: 0.0002276 (Best: 0.0001661 @iter13370) ([92m↓0.42%[0m) [0.09% of initial]
[Iter 11860/20000] Loss: 0.0002948 (Best: 0.0002546 @iter11716) ([92m↓2.03%[0m) [0.12% of initial]
[Iter 14140/20000] Loss: 0.0002014 (Best: 0.0001661 @iter13370) ([92m↓11.51%[0m) [0.08% of initial]
[Iter 11870/20000] Loss: 0.0002820 (Best: 0.0002546 @iter11716) ([92m↓4.35%[0m) [0.11% of initial]
[Iter 14150/20000] Loss: 0.0001978 (Best: 0.0001661 @iter13370) ([92m↓1.79%[0m) [0.08% of initial]
[Iter 11880/20000] Loss: 0.0002895 (Best: 0.0002546 @iter11716) ([91m↑2.68%[0m) [0.12% of initial]
[Iter 14160/20000] Loss: 0.0001782 (Best: 0.0001645 @iter14160) ([92m↓9.92%[0m) [0.07% of initial]
[Iter 11890/20000] Loss: 0.0003434 (Best: 0.0002546 @iter11716) ([91m↑18.61%[0m) [0.14% of initial]
[Iter 14170/20000] Loss: 0.0002319 (Best: 0.0001590 @iter14162) ([91m↑30.18%[0m) [0.09% of initial]
Iter:11899, L1 loss=0.0003839, Total loss=0.0003159, Time:139
[Iter 11900/20000] Loss: 0.0003150 (Best: 0.0002546 @iter11716) ([92m↓8.27%[0m) [0.13% of initial]
[Iter 14180/20000] Loss: 0.0002003 (Best: 0.0001590 @iter14162) ([92m↓13.63%[0m) [0.08% of initial]
[Iter 11910/20000] Loss: 0.0003283 (Best: 0.0002546 @iter11716) ([91m↑4.21%[0m) [0.13% of initial]
[Iter 11920/20000] Loss: 0.0003562 (Best: 0.0002546 @iter11716) ([91m↑8.50%[0m) [0.14% of initial]
[Iter 14190/20000] Loss: 0.0002002 (Best: 0.0001590 @iter14162) ([92m↓0.05%[0m) [0.08% of initial]
[Iter 11930/20000] Loss: 0.0003240 (Best: 0.0002546 @iter11716) ([92m↓9.05%[0m) [0.13% of initial]
Iter:14199, L1 loss=0.0002277, Total loss=0.0001842, Time:203
[Iter 14200/20000] Loss: 0.0001891 (Best: 0.0001590 @iter14162) ([92m↓5.54%[0m) [0.08% of initial]
[Iter 11940/20000] Loss: 0.0003072 (Best: 0.0002546 @iter11716) ([92m↓5.19%[0m) [0.12% of initial]
[Iter 14210/20000] Loss: 0.0001750 (Best: 0.0001582 @iter14206) ([92m↓7.46%[0m) [0.07% of initial]
[Iter 11950/20000] Loss: 0.0003161 (Best: 0.0002546 @iter11716) ([91m↑2.89%[0m) [0.13% of initial]
[Iter 14220/20000] Loss: 0.0001849 (Best: 0.0001582 @iter14206) ([91m↑5.63%[0m) [0.07% of initial]
[Iter 11960/20000] Loss: 0.0002742 (Best: 0.0002546 @iter11716) ([92m↓13.24%[0m) [0.11% of initial]
[Iter 14230/20000] Loss: 0.0002652 (Best: 0.0001582 @iter14206) ([91m↑43.44%[0m) [0.11% of initial]
[Iter 11970/20000] Loss: 0.0003046 (Best: 0.0002546 @iter11716) ([91m↑11.08%[0m) [0.12% of initial]
[Iter 14240/20000] Loss: 0.0002044 (Best: 0.0001582 @iter14206) ([92m↓22.93%[0m) [0.08% of initial]
[Iter 11980/20000] Loss: 0.0002819 (Best: 0.0002546 @iter11716) ([92m↓7.47%[0m) [0.11% of initial]
[Iter 11990/20000] Loss: 0.0002860 (Best: 0.0002511 @iter11986) ([91m↑1.46%[0m) [0.11% of initial]
[Iter 14250/20000] Loss: 0.0002293 (Best: 0.0001582 @iter14206) ([91m↑12.18%[0m) [0.09% of initial]
Iter:11999, L1 loss=0.0003161, Total loss=0.0002841, Time:167
[Iter 12000/20000] Loss: 0.0003277 (Best: 0.0002511 @iter11986) ([91m↑14.59%[0m) [0.13% of initial]
[Iter 14260/20000] Loss: 0.0002174 (Best: 0.0001582 @iter14206) ([92m↓5.16%[0m) [0.09% of initial]
Pruning 15 points (0.0%) from gaussian0 at iteration 12000
Pruning 8 points (0.0%) from gaussian1 at iteration 12000
[Iter 14270/20000] Loss: 0.0002254 (Best: 0.0001582 @iter14206) ([91m↑3.64%[0m) [0.09% of initial]
[Iter 12010/20000] Loss: 0.0212274 (Best: 0.0002511 @iter11986) ([91m↑6377.55%[0m) [8.43% of initial]
[Iter 14280/20000] Loss: 0.0001944 (Best: 0.0001582 @iter14206) ([92m↓13.75%[0m) [0.08% of initial]
[Iter 12020/20000] Loss: 0.0058936 (Best: 0.0002511 @iter11986) ([92m↓72.24%[0m) [2.34% of initial]
[Iter 14290/20000] Loss: 0.0001858 (Best: 0.0001582 @iter14206) ([92m↓4.44%[0m) [0.07% of initial]
[Iter 12030/20000] Loss: 0.0039889 (Best: 0.0002511 @iter11986) ([92m↓32.32%[0m) [1.58% of initial]
Iter:14299, L1 loss=0.0002287, Total loss=0.0001881, Time:184
[Iter 14300/20000] Loss: 0.0001897 (Best: 0.0001582 @iter14206) ([91m↑2.15%[0m) [0.08% of initial]
[Iter 12040/20000] Loss: 0.0021480 (Best: 0.0002511 @iter11986) ([92m↓46.15%[0m) [0.85% of initial]
[Iter 14310/20000] Loss: 0.0002206 (Best: 0.0001582 @iter14206) ([91m↑16.27%[0m) [0.09% of initial]
[Iter 12050/20000] Loss: 0.0014302 (Best: 0.0002511 @iter11986) ([92m↓33.42%[0m) [0.57% of initial]
[Iter 14320/20000] Loss: 0.0001940 (Best: 0.0001582 @iter14206) ([92m↓12.06%[0m) [0.08% of initial]
[Iter 12060/20000] Loss: 0.0010082 (Best: 0.0002511 @iter11986) ([92m↓29.51%[0m) [0.40% of initial]
[Iter 12070/20000] Loss: 0.0007713 (Best: 0.0002511 @iter11986) ([92m↓23.50%[0m) [0.31% of initial]
[Iter 14330/20000] Loss: 0.0002010 (Best: 0.0001582 @iter14206) ([91m↑3.64%[0m) [0.08% of initial]
[Iter 12080/20000] Loss: 0.0006486 (Best: 0.0002511 @iter11986) ([92m↓15.91%[0m) [0.26% of initial]
[Iter 14340/20000] Loss: 0.0002411 (Best: 0.0001582 @iter14206) ([91m↑19.93%[0m) [0.10% of initial]
[Iter 12090/20000] Loss: 0.0005672 (Best: 0.0002511 @iter11986) ([92m↓12.56%[0m) [0.23% of initial]
[Iter 14350/20000] Loss: 0.0002325 (Best: 0.0001582 @iter14206) ([92m↓3.57%[0m) [0.09% of initial]
Iter:12099, L1 loss=0.0006159, Total loss=0.0005679, Time:173
[Iter 12100/20000] Loss: 0.0005280 (Best: 0.0002511 @iter11986) ([92m↓6.91%[0m) [0.21% of initial]
[Iter 14360/20000] Loss: 0.0002118 (Best: 0.0001582 @iter14206) ([92m↓8.92%[0m) [0.08% of initial]
[Iter 12110/20000] Loss: 0.0004897 (Best: 0.0002511 @iter11986) ([92m↓7.25%[0m) [0.19% of initial]
[Iter 14370/20000] Loss: 0.0001990 (Best: 0.0001582 @iter14206) ([92m↓6.01%[0m) [0.08% of initial]
[Iter 12120/20000] Loss: 0.0004638 (Best: 0.0002511 @iter11986) ([92m↓5.29%[0m) [0.18% of initial]
[Iter 14380/20000] Loss: 0.0002040 (Best: 0.0001582 @iter14206) ([91m↑2.50%[0m) [0.08% of initial]
[Iter 12130/20000] Loss: 0.0004315 (Best: 0.0002511 @iter11986) ([92m↓6.96%[0m) [0.17% of initial]
[Iter 14390/20000] Loss: 0.0002194 (Best: 0.0001582 @iter14206) ([91m↑7.55%[0m) [0.09% of initial]
[Iter 12140/20000] Loss: 0.0004154 (Best: 0.0002511 @iter11986) ([92m↓3.73%[0m) [0.17% of initial]
Iter:14399, L1 loss=0.0002078, Total loss=0.0001723, Time:176
[Iter 14400/20000] Loss: 0.0001938 (Best: 0.0001582 @iter14206) ([92m↓11.70%[0m) [0.08% of initial]
[Iter 12150/20000] Loss: 0.0004215 (Best: 0.0002511 @iter11986) ([91m↑1.46%[0m) [0.17% of initial]
[Iter 14410/20000] Loss: 0.0002062 (Best: 0.0001582 @iter14206) ([91m↑6.42%[0m) [0.08% of initial]
[Iter 12160/20000] Loss: 0.0003925 (Best: 0.0002511 @iter11986) ([92m↓6.88%[0m) [0.16% of initial]
[Iter 14420/20000] Loss: 0.0002849 (Best: 0.0001582 @iter14206) ([91m↑38.19%[0m) [0.11% of initial]
[Iter 12170/20000] Loss: 0.0003740 (Best: 0.0002511 @iter11986) ([92m↓4.72%[0m) [0.15% of initial]
[Iter 14430/20000] Loss: 0.0002629 (Best: 0.0001582 @iter14206) ([92m↓7.73%[0m) [0.10% of initial]
[Iter 12180/20000] Loss: 0.0003682 (Best: 0.0002511 @iter11986) ([92m↓1.53%[0m) [0.15% of initial]
[Iter 12190/20000] Loss: 0.0003645 (Best: 0.0002511 @iter11986) ([92m↓1.02%[0m) [0.14% of initial]
[Iter 14440/20000] Loss: 0.0002611 (Best: 0.0001582 @iter14206) ([92m↓0.69%[0m) [0.10% of initial]
Iter:12199, L1 loss=0.0004098, Total loss=0.0003664, Time:167
[Iter 12200/20000] Loss: 0.0003503 (Best: 0.0002511 @iter11986) ([92m↓3.90%[0m) [0.14% of initial]
[Iter 14450/20000] Loss: 0.0002394 (Best: 0.0001582 @iter14206) ([92m↓8.31%[0m) [0.10% of initial]
[Iter 12210/20000] Loss: 0.0003683 (Best: 0.0002511 @iter11986) ([91m↑5.15%[0m) [0.15% of initial]
[Iter 14460/20000] Loss: 0.0002521 (Best: 0.0001582 @iter14206) ([91m↑5.28%[0m) [0.10% of initial]
[Iter 12220/20000] Loss: 0.0003516 (Best: 0.0002511 @iter11986) ([92m↓4.53%[0m) [0.14% of initial]
[Iter 14470/20000] Loss: 0.0002301 (Best: 0.0001582 @iter14206) ([92m↓8.72%[0m) [0.09% of initial]
[Iter 12230/20000] Loss: 0.0003526 (Best: 0.0002511 @iter11986) ([91m↑0.28%[0m) [0.14% of initial]
[Iter 14480/20000] Loss: 0.0002220 (Best: 0.0001582 @iter14206) ([92m↓3.52%[0m) [0.09% of initial]
[Iter 12240/20000] Loss: 0.0003616 (Best: 0.0002511 @iter11986) ([91m↑2.56%[0m) [0.14% of initial]
[Iter 14490/20000] Loss: 0.0002123 (Best: 0.0001582 @iter14206) ([92m↓4.35%[0m) [0.08% of initial]
[Iter 12250/20000] Loss: 0.0003410 (Best: 0.0002511 @iter11986) ([92m↓5.72%[0m) [0.14% of initial]
Iter:14499, L1 loss=0.0002563, Total loss=0.0002043, Time:156
[Iter 14500/20000] Loss: 0.0001987 (Best: 0.0001582 @iter14206) ([92m↓6.44%[0m) [0.08% of initial]
[Iter 12260/20000] Loss: 0.0003384 (Best: 0.0002511 @iter11986) ([92m↓0.76%[0m) [0.13% of initial]
[Iter 14510/20000] Loss: 0.0002340 (Best: 0.0001582 @iter14206) ([91m↑17.81%[0m) [0.09% of initial]
[Iter 12270/20000] Loss: 0.0003364 (Best: 0.0002511 @iter11986) ([92m↓0.57%[0m) [0.13% of initial]
[Iter 14520/20000] Loss: 0.0002073 (Best: 0.0001582 @iter14206) ([92m↓11.44%[0m) [0.08% of initial]
[Iter 12280/20000] Loss: 0.0003482 (Best: 0.0002511 @iter11986) ([91m↑3.50%[0m) [0.14% of initial]
[Iter 14530/20000] Loss: 0.0001955 (Best: 0.0001582 @iter14206) ([92m↓5.67%[0m) [0.08% of initial]
[Iter 12290/20000] Loss: 0.0003967 (Best: 0.0002511 @iter11986) ([91m↑13.92%[0m) [0.16% of initial]
Iter:12299, L1 loss=0.0004085, Total loss=0.00035, Time:129
[Iter 12300/20000] Loss: 0.0003510 (Best: 0.0002511 @iter11986) ([92m↓11.51%[0m) [0.14% of initial]
[Iter 14540/20000] Loss: 0.0002688 (Best: 0.0001582 @iter14206) ([91m↑37.51%[0m) [0.11% of initial]
[Iter 12310/20000] Loss: 0.0003370 (Best: 0.0002511 @iter11986) ([92m↓4.00%[0m) [0.13% of initial]
[Iter 14550/20000] Loss: 0.0002401 (Best: 0.0001582 @iter14206) ([92m↓10.69%[0m) [0.10% of initial]
[Iter 12320/20000] Loss: 0.0003308 (Best: 0.0002511 @iter11986) ([92m↓1.84%[0m) [0.13% of initial]
[Iter 14560/20000] Loss: 0.0002037 (Best: 0.0001582 @iter14206) ([92m↓15.16%[0m) [0.08% of initial]
[Iter 12330/20000] Loss: 0.0003549 (Best: 0.0002511 @iter11986) ([91m↑7.29%[0m) [0.14% of initial]
[Iter 14570/20000] Loss: 0.0002109 (Best: 0.0001582 @iter14206) ([91m↑3.52%[0m) [0.08% of initial]
[Iter 12340/20000] Loss: 0.0003497 (Best: 0.0002511 @iter11986) ([92m↓1.46%[0m) [0.14% of initial]
[Iter 14580/20000] Loss: 0.0001903 (Best: 0.0001582 @iter14206) ([92m↓9.74%[0m) [0.08% of initial]
[Iter 12350/20000] Loss: 0.0003474 (Best: 0.0002511 @iter11986) ([92m↓0.67%[0m) [0.14% of initial]
[Iter 14590/20000] Loss: 0.0002077 (Best: 0.0001582 @iter14206) ([91m↑9.11%[0m) [0.08% of initial]
[Iter 12360/20000] Loss: 0.0003436 (Best: 0.0002511 @iter11986) ([92m↓1.08%[0m) [0.14% of initial]
Iter:14599, L1 loss=0.0002588, Total loss=0.0002107, Time:181
[Iter 14600/20000] Loss: 0.0002271 (Best: 0.0001582 @iter14206) ([91m↑9.37%[0m) [0.09% of initial]
[Iter 12370/20000] Loss: 0.0003253 (Best: 0.0002511 @iter11986) ([92m↓5.33%[0m) [0.13% of initial]
[Iter 14610/20000] Loss: 0.0002670 (Best: 0.0001582 @iter14206) ([91m↑17.55%[0m) [0.11% of initial]
[Iter 12380/20000] Loss: 0.0003268 (Best: 0.0002511 @iter11986) ([91m↑0.47%[0m) [0.13% of initial]
[Iter 14620/20000] Loss: 0.0002280 (Best: 0.0001582 @iter14206) ([92m↓14.59%[0m) [0.09% of initial]
[Iter 12390/20000] Loss: 0.0003315 (Best: 0.0002511 @iter11986) ([91m↑1.43%[0m) [0.13% of initial]
[Iter 14630/20000] Loss: 0.0001930 (Best: 0.0001582 @iter14206) ([92m↓15.37%[0m) [0.08% of initial]
Iter:12399, L1 loss=0.0003651, Total loss=0.0003176, Time:143
[Iter 12400/20000] Loss: 0.0003305 (Best: 0.0002511 @iter11986) ([92m↓0.30%[0m) [0.13% of initial]
[Iter 14640/20000] Loss: 0.0002057 (Best: 0.0001582 @iter14206) ([91m↑6.59%[0m) [0.08% of initial]
[Iter 12410/20000] Loss: 0.0003447 (Best: 0.0002511 @iter11986) ([91m↑4.29%[0m) [0.14% of initial]
[Iter 14650/20000] Loss: 0.0002301 (Best: 0.0001582 @iter14206) ([91m↑11.84%[0m) [0.09% of initial]
[Iter 12420/20000] Loss: 0.0003329 (Best: 0.0002511 @iter11986) ([92m↓3.43%[0m) [0.13% of initial]
[Iter 12430/20000] Loss: 0.0003313 (Best: 0.0002511 @iter11986) ([92m↓0.47%[0m) [0.13% of initial]
[Iter 14660/20000] Loss: 0.0002127 (Best: 0.0001582 @iter14206) ([92m↓7.53%[0m) [0.08% of initial]
[Iter 12440/20000] Loss: 0.0003394 (Best: 0.0002511 @iter11986) ([91m↑2.45%[0m) [0.13% of initial]
[Iter 14670/20000] Loss: 0.0002050 (Best: 0.0001582 @iter14206) ([92m↓3.65%[0m) [0.08% of initial]
[Iter 12450/20000] Loss: 0.0003417 (Best: 0.0002511 @iter11986) ([91m↑0.65%[0m) [0.14% of initial]
[Iter 14680/20000] Loss: 0.0002022 (Best: 0.0001582 @iter14206) ([92m↓1.34%[0m) [0.08% of initial]
[Iter 12460/20000] Loss: 0.0003289 (Best: 0.0002511 @iter11986) ([92m↓3.73%[0m) [0.13% of initial]
[Iter 14690/20000] Loss: 0.0001816 (Best: 0.0001582 @iter14206) ([92m↓10.21%[0m) [0.07% of initial]
[Iter 12470/20000] Loss: 0.0003331 (Best: 0.0002511 @iter11986) ([91m↑1.28%[0m) [0.13% of initial]
Iter:14699, L1 loss=0.0002284, Total loss=0.0002126, Time:172
[Iter 14700/20000] Loss: 0.0001995 (Best: 0.0001582 @iter14206) ([91m↑9.86%[0m) [0.08% of initial]
[Iter 12480/20000] Loss: 0.0003378 (Best: 0.0002511 @iter11986) ([91m↑1.40%[0m) [0.13% of initial]
[Iter 14710/20000] Loss: 0.0001803 (Best: 0.0001582 @iter14206) ([92m↓9.59%[0m) [0.07% of initial]
[Iter 12490/20000] Loss: 0.0003348 (Best: 0.0002511 @iter11986) ([92m↓0.88%[0m) [0.13% of initial]
[Iter 14720/20000] Loss: 0.0001854 (Best: 0.0001582 @iter14206) ([91m↑2.82%[0m) [0.07% of initial]
Iter:12499, L1 loss=0.0003925, Total loss=0.0003377, Time:117
[Iter 12500/20000] Loss: 0.0003393 (Best: 0.0002511 @iter11986) ([91m↑1.32%[0m) [0.13% of initial]
[Iter 14730/20000] Loss: 0.0001904 (Best: 0.0001582 @iter14206) ([91m↑2.69%[0m) [0.08% of initial]
Pruning 17 points (0.0%) from gaussian0 at iteration 12500
Pruning 19 points (0.0%) from gaussian1 at iteration 12500
[Iter 14740/20000] Loss: 0.0001683 (Best: 0.0001563 @iter14740) ([92m↓11.58%[0m) [0.07% of initial]
[Iter 12510/20000] Loss: 0.0006425 (Best: 0.0002511 @iter11986) ([91m↑89.38%[0m) [0.26% of initial]
[Iter 14750/20000] Loss: 0.0001719 (Best: 0.0001563 @iter14740) ([91m↑2.10%[0m) [0.07% of initial]
[Iter 12520/20000] Loss: 0.0004706 (Best: 0.0002511 @iter11986) ([92m↓26.76%[0m) [0.19% of initial]
[Iter 14760/20000] Loss: 0.0001803 (Best: 0.0001511 @iter14752) ([91m↑4.89%[0m) [0.07% of initial]
[Iter 12530/20000] Loss: 0.0003784 (Best: 0.0002511 @iter11986) ([92m↓19.58%[0m) [0.15% of initial]
[Iter 14770/20000] Loss: 0.0002322 (Best: 0.0001511 @iter14752) ([91m↑28.82%[0m) [0.09% of initial]
[Iter 12540/20000] Loss: 0.0003523 (Best: 0.0002511 @iter11986) ([92m↓6.92%[0m) [0.14% of initial]
[Iter 12550/20000] Loss: 0.0003225 (Best: 0.0002511 @iter11986) ([92m↓8.45%[0m) [0.13% of initial]
[Iter 14780/20000] Loss: 0.0002393 (Best: 0.0001511 @iter14752) ([91m↑3.03%[0m) [0.10% of initial]
[Iter 12560/20000] Loss: 0.0003265 (Best: 0.0002511 @iter11986) ([91m↑1.23%[0m) [0.13% of initial]
[Iter 14790/20000] Loss: 0.0002512 (Best: 0.0001511 @iter14752) ([91m↑4.99%[0m) [0.10% of initial]
[Iter 12570/20000] Loss: 0.0003347 (Best: 0.0002511 @iter11986) ([91m↑2.52%[0m) [0.13% of initial]
Iter:14799, L1 loss=0.0003585, Total loss=0.0002588, Time:124
[Iter 14800/20000] Loss: 0.0002361 (Best: 0.0001511 @iter14752) ([92m↓6.01%[0m) [0.09% of initial]
[Iter 12580/20000] Loss: 0.0003580 (Best: 0.0002511 @iter11986) ([91m↑6.97%[0m) [0.14% of initial]
[Iter 14810/20000] Loss: 0.0002195 (Best: 0.0001511 @iter14752) ([92m↓7.05%[0m) [0.09% of initial]
[Iter 12590/20000] Loss: 0.0003466 (Best: 0.0002511 @iter11986) ([92m↓3.18%[0m) [0.14% of initial]
[Iter 14820/20000] Loss: 0.0002041 (Best: 0.0001511 @iter14752) ([92m↓7.01%[0m) [0.08% of initial]
Iter:12599, L1 loss=0.0004641, Total loss=0.0004126, Time:137
[Iter 12600/20000] Loss: 0.0003763 (Best: 0.0002511 @iter11986) ([91m↑8.55%[0m) [0.15% of initial]
[Iter 14830/20000] Loss: 0.0002018 (Best: 0.0001511 @iter14752) ([92m↓1.11%[0m) [0.08% of initial]
[Iter 12610/20000] Loss: 0.0003740 (Best: 0.0002511 @iter11986) ([92m↓0.61%[0m) [0.15% of initial]
[Iter 14840/20000] Loss: 0.0002020 (Best: 0.0001511 @iter14752) ([91m↑0.07%[0m) [0.08% of initial]
[Iter 12620/20000] Loss: 0.0003514 (Best: 0.0002511 @iter11986) ([92m↓6.04%[0m) [0.14% of initial]
[Iter 14850/20000] Loss: 0.0002053 (Best: 0.0001511 @iter14752) ([91m↑1.66%[0m) [0.08% of initial]
[Iter 12630/20000] Loss: 0.0003641 (Best: 0.0002511 @iter11986) ([91m↑3.62%[0m) [0.14% of initial]
[Iter 14860/20000] Loss: 0.0002057 (Best: 0.0001511 @iter14752) ([91m↑0.17%[0m) [0.08% of initial]
[Iter 12640/20000] Loss: 0.0003584 (Best: 0.0002511 @iter11986) ([92m↓1.56%[0m) [0.14% of initial]
[Iter 14870/20000] Loss: 0.0001913 (Best: 0.0001511 @iter14752) ([92m↓7.00%[0m) [0.08% of initial]
[Iter 12650/20000] Loss: 0.0003629 (Best: 0.0002511 @iter11986) ([91m↑1.25%[0m) [0.14% of initial]
[Iter 14880/20000] Loss: 0.0001834 (Best: 0.0001511 @iter14752) ([92m↓4.11%[0m) [0.07% of initial]
[Iter 12660/20000] Loss: 0.0003697 (Best: 0.0002511 @iter11986) ([91m↑1.88%[0m) [0.15% of initial]
[Iter 12670/20000] Loss: 0.0003716 (Best: 0.0002511 @iter11986) ([91m↑0.50%[0m) [0.15% of initial]
[Iter 14890/20000] Loss: 0.0001710 (Best: 0.0001511 @iter14752) ([92m↓6.75%[0m) [0.07% of initial]
[Iter 12680/20000] Loss: 0.0004030 (Best: 0.0002511 @iter11986) ([91m↑8.46%[0m) [0.16% of initial]
Iter:14899, L1 loss=0.0002162, Total loss=0.0001706, Time:167
[Iter 14900/20000] Loss: 0.0001674 (Best: 0.0001511 @iter14752) ([92m↓2.09%[0m) [0.07% of initial]
[Iter 12690/20000] Loss: 0.0003631 (Best: 0.0002511 @iter11986) ([92m↓9.92%[0m) [0.14% of initial]
[Iter 14910/20000] Loss: 0.0001785 (Best: 0.0001511 @iter14752) ([91m↑6.60%[0m) [0.07% of initial]
Iter:12699, L1 loss=0.000444, Total loss=0.0003824, Time:119
[Iter 12700/20000] Loss: 0.0003652 (Best: 0.0002511 @iter11986) ([91m↑0.59%[0m) [0.15% of initial]
[Iter 14920/20000] Loss: 0.0001854 (Best: 0.0001511 @iter14752) ([91m↑3.85%[0m) [0.07% of initial]
[Iter 12710/20000] Loss: 0.0003551 (Best: 0.0002511 @iter11986) ([92m↓2.76%[0m) [0.14% of initial]
[Iter 14930/20000] Loss: 0.0001827 (Best: 0.0001511 @iter14752) ([92m↓1.46%[0m) [0.07% of initial]
[Iter 12720/20000] Loss: 0.0003491 (Best: 0.0002511 @iter11986) ([92m↓1.70%[0m) [0.14% of initial]
[Iter 14940/20000] Loss: 0.0001719 (Best: 0.0001511 @iter14752) ([92m↓5.91%[0m) [0.07% of initial]
[Iter 12730/20000] Loss: 0.0003666 (Best: 0.0002511 @iter11986) ([91m↑5.02%[0m) [0.15% of initial]
[Iter 14950/20000] Loss: 0.0001899 (Best: 0.0001511 @iter14752) ([91m↑10.52%[0m) [0.08% of initial]
[Iter 12740/20000] Loss: 0.0003396 (Best: 0.0002511 @iter11986) ([92m↓7.36%[0m) [0.13% of initial]
[Iter 14960/20000] Loss: 0.0001675 (Best: 0.0001511 @iter14752) ([92m↓11.81%[0m) [0.07% of initial]
[Iter 12750/20000] Loss: 0.0003256 (Best: 0.0002511 @iter11986) ([92m↓4.11%[0m) [0.13% of initial]
[Iter 14970/20000] Loss: 0.0002117 (Best: 0.0001511 @iter14752) ([91m↑26.37%[0m) [0.08% of initial]
[Iter 12760/20000] Loss: 0.0003302 (Best: 0.0002511 @iter11986) ([91m↑1.40%[0m) [0.13% of initial]
[Iter 14980/20000] Loss: 0.0002228 (Best: 0.0001511 @iter14752) ([91m↑5.24%[0m) [0.09% of initial]
[Iter 12770/20000] Loss: 0.0003423 (Best: 0.0002511 @iter11986) ([91m↑3.66%[0m) [0.14% of initial]
[Iter 12780/20000] Loss: 0.0003590 (Best: 0.0002511 @iter11986) ([91m↑4.87%[0m) [0.14% of initial]
[Iter 14990/20000] Loss: 0.0002729 (Best: 0.0001511 @iter14752) ([91m↑22.49%[0m) [0.11% of initial]
[Iter 12790/20000] Loss: 0.0003334 (Best: 0.0002511 @iter11986) ([92m↓7.11%[0m) [0.13% of initial]
Iter:14999, L1 loss=0.000313, Total loss=0.0002515, Time:106
[Iter 15000/20000] Loss: 0.0002980 (Best: 0.0001511 @iter14752) ([91m↑9.20%[0m) [0.12% of initial]
Iter:12799, L1 loss=0.0003701, Total loss=0.0003302, Time:106
[Iter 12800/20000] Loss: 0.0003392 (Best: 0.0002511 @iter11986) ([91m↑1.74%[0m) [0.13% of initial]
[Iter 15010/20000] Loss: 0.0002275 (Best: 0.0001511 @iter14752) ([92m↓23.68%[0m) [0.09% of initial]
[Iter 12810/20000] Loss: 0.0003758 (Best: 0.0002511 @iter11986) ([91m↑10.79%[0m) [0.15% of initial]
[Iter 15020/20000] Loss: 0.0002349 (Best: 0.0001511 @iter14752) ([91m↑3.27%[0m) [0.09% of initial]
[Iter 12820/20000] Loss: 0.0003576 (Best: 0.0002511 @iter11986) ([92m↓4.85%[0m) [0.14% of initial]
[Iter 15030/20000] Loss: 0.0002139 (Best: 0.0001511 @iter14752) ([92m↓8.93%[0m) [0.08% of initial]
[Iter 12830/20000] Loss: 0.0003459 (Best: 0.0002511 @iter11986) ([92m↓3.27%[0m) [0.14% of initial]
[Iter 15040/20000] Loss: 0.0001968 (Best: 0.0001511 @iter14752) ([92m↓8.03%[0m) [0.08% of initial]
[Iter 12840/20000] Loss: 0.0003502 (Best: 0.0002511 @iter11986) ([91m↑1.25%[0m) [0.14% of initial]
[Iter 15050/20000] Loss: 0.0001865 (Best: 0.0001511 @iter14752) ([92m↓5.19%[0m) [0.07% of initial]
[Iter 12850/20000] Loss: 0.0003300 (Best: 0.0002511 @iter11986) ([92m↓5.77%[0m) [0.13% of initial]
[Iter 15060/20000] Loss: 0.0002180 (Best: 0.0001511 @iter14752) ([91m↑16.87%[0m) [0.09% of initial]
[Iter 12860/20000] Loss: 0.0003221 (Best: 0.0002511 @iter11986) ([92m↓2.39%[0m) [0.13% of initial]
[Iter 15070/20000] Loss: 0.0001920 (Best: 0.0001511 @iter14752) ([92m↓11.95%[0m) [0.08% of initial]
[Iter 12870/20000] Loss: 0.0003158 (Best: 0.0002511 @iter11986) ([92m↓1.97%[0m) [0.13% of initial]
[Iter 15080/20000] Loss: 0.0001783 (Best: 0.0001511 @iter14752) ([92m↓7.11%[0m) [0.07% of initial]
[Iter 12880/20000] Loss: 0.0005506 (Best: 0.0002511 @iter11986) ([91m↑74.37%[0m) [0.22% of initial]
[Iter 12890/20000] Loss: 0.0003351 (Best: 0.0002511 @iter11986) ([92m↓39.15%[0m) [0.13% of initial]
[Iter 15090/20000] Loss: 0.0001742 (Best: 0.0001511 @iter14752) ([92m↓2.29%[0m) [0.07% of initial]
Iter:12899, L1 loss=0.000373, Total loss=0.0003225, Time:138
[Iter 12900/20000] Loss: 0.0003107 (Best: 0.0002511 @iter11986) ([92m↓7.26%[0m) [0.12% of initial]
Iter:15099, L1 loss=0.0001902, Total loss=0.000161, Time:158
[Iter 15100/20000] Loss: 0.0001605 (Best: 0.0001511 @iter14752) ([92m↓7.91%[0m) [0.06% of initial]
[Iter 12910/20000] Loss: 0.0003121 (Best: 0.0002511 @iter11986) ([91m↑0.45%[0m) [0.12% of initial]
[Iter 15110/20000] Loss: 0.0001856 (Best: 0.0001511 @iter14752) ([91m↑15.68%[0m) [0.07% of initial]
[Iter 12920/20000] Loss: 0.0003298 (Best: 0.0002511 @iter11986) ([91m↑5.65%[0m) [0.13% of initial]
[Iter 15120/20000] Loss: 0.0001908 (Best: 0.0001511 @iter14752) ([91m↑2.79%[0m) [0.08% of initial]
[Iter 12930/20000] Loss: 0.0003382 (Best: 0.0002511 @iter11986) ([91m↑2.56%[0m) [0.13% of initial]
[Iter 15130/20000] Loss: 0.0001976 (Best: 0.0001511 @iter14752) ([91m↑3.59%[0m) [0.08% of initial]
[Iter 12940/20000] Loss: 0.0003567 (Best: 0.0002511 @iter11986) ([91m↑5.47%[0m) [0.14% of initial]
[Iter 15140/20000] Loss: 0.0001754 (Best: 0.0001511 @iter14752) ([92m↓11.27%[0m) [0.07% of initial]
[Iter 12950/20000] Loss: 0.0003713 (Best: 0.0002511 @iter11986) ([91m↑4.11%[0m) [0.15% of initial]
[Iter 15150/20000] Loss: 0.0002110 (Best: 0.0001511 @iter14752) ([91m↑20.31%[0m) [0.08% of initial]
[Iter 12960/20000] Loss: 0.0003900 (Best: 0.0002511 @iter11986) ([91m↑5.02%[0m) [0.15% of initial]
[Iter 15160/20000] Loss: 0.0001815 (Best: 0.0001511 @iter14752) ([92m↓13.96%[0m) [0.07% of initial]
[Iter 12970/20000] Loss: 0.0003283 (Best: 0.0002511 @iter11986) ([92m↓15.82%[0m) [0.13% of initial]
[Iter 15170/20000] Loss: 0.0001727 (Best: 0.0001511 @iter14752) ([92m↓4.86%[0m) [0.07% of initial]
[Iter 12980/20000] Loss: 0.0003519 (Best: 0.0002511 @iter11986) ([91m↑7.18%[0m) [0.14% of initial]
[Iter 15180/20000] Loss: 0.0001900 (Best: 0.0001511 @iter14752) ([91m↑10.00%[0m) [0.08% of initial]
[Iter 12990/20000] Loss: 0.0003353 (Best: 0.0002511 @iter11986) ([92m↓4.71%[0m) [0.13% of initial]
Iter:12999, L1 loss=0.0003566, Total loss=0.0003094, Time:105
[Iter 13000/20000] Loss: 0.0003168 (Best: 0.0002511 @iter11986) ([92m↓5.52%[0m) [0.13% of initial]
[Iter 15190/20000] Loss: 0.0001776 (Best: 0.0001511 @iter14752) ([92m↓6.51%[0m) [0.07% of initial]
Pruning 10 points (0.0%) from gaussian0 at iteration 13000
Pruning 12 points (0.0%) from gaussian1 at iteration 13000
Iter:15199, L1 loss=0.000211, Total loss=0.0001823, Time:155
[Iter 15200/20000] Loss: 0.0001739 (Best: 0.0001511 @iter14752) ([92m↓2.10%[0m) [0.07% of initial]
[Iter 13010/20000] Loss: 0.0007553 (Best: 0.0002511 @iter11986) ([91m↑138.43%[0m) [0.30% of initial]
[Iter 15210/20000] Loss: 0.0002281 (Best: 0.0001511 @iter14752) ([91m↑31.17%[0m) [0.09% of initial]
[Iter 13020/20000] Loss: 0.0004923 (Best: 0.0002511 @iter11986) ([92m↓34.82%[0m) [0.20% of initial]
[Iter 15220/20000] Loss: 0.0002287 (Best: 0.0001511 @iter14752) ([91m↑0.27%[0m) [0.09% of initial]
[Iter 13030/20000] Loss: 0.0004042 (Best: 0.0002511 @iter11986) ([92m↓17.90%[0m) [0.16% of initial]
[Iter 15230/20000] Loss: 0.0001923 (Best: 0.0001511 @iter14752) ([92m↓15.91%[0m) [0.08% of initial]
[Iter 13040/20000] Loss: 0.0003723 (Best: 0.0002511 @iter11986) ([92m↓7.90%[0m) [0.15% of initial]
[Iter 15240/20000] Loss: 0.0001837 (Best: 0.0001511 @iter14752) ([92m↓4.46%[0m) [0.07% of initial]
[Iter 13050/20000] Loss: 0.0003383 (Best: 0.0002511 @iter11986) ([92m↓9.11%[0m) [0.13% of initial]
[Iter 15250/20000] Loss: 0.0001652 (Best: 0.0001503 @iter15250) ([92m↓10.10%[0m) [0.07% of initial]
[Iter 13060/20000] Loss: 0.0003285 (Best: 0.0002511 @iter11986) ([92m↓2.92%[0m) [0.13% of initial]
[Iter 15260/20000] Loss: 0.0001803 (Best: 0.0001503 @iter15250) ([91m↑9.17%[0m) [0.07% of initial]
[Iter 13070/20000] Loss: 0.0003284 (Best: 0.0002511 @iter11986) ([92m↓0.02%[0m) [0.13% of initial]
[Iter 15270/20000] Loss: 0.0001715 (Best: 0.0001503 @iter15250) ([92m↓4.91%[0m) [0.07% of initial]
[Iter 13080/20000] Loss: 0.0003176 (Best: 0.0002511 @iter11986) ([92m↓3.28%[0m) [0.13% of initial]
[Iter 15280/20000] Loss: 0.0001664 (Best: 0.0001503 @iter15250) ([92m↓2.94%[0m) [0.07% of initial]
[Iter 13090/20000] Loss: 0.0003436 (Best: 0.0002511 @iter11986) ([91m↑8.16%[0m) [0.14% of initial]
Iter:13099, L1 loss=0.0003521, Total loss=0.0003407, Time:145
[Iter 13100/20000] Loss: 0.0003611 (Best: 0.0002511 @iter11986) ([91m↑5.12%[0m) [0.14% of initial]
[Iter 15290/20000] Loss: 0.0001789 (Best: 0.0001498 @iter15283) ([91m↑7.52%[0m) [0.07% of initial]
[Iter 13110/20000] Loss: 0.0003489 (Best: 0.0002511 @iter11986) ([92m↓3.38%[0m) [0.14% of initial]
Iter:15299, L1 loss=0.0002419, Total loss=0.0001888, Time:159
[Iter 15300/20000] Loss: 0.0001903 (Best: 0.0001498 @iter15283) ([91m↑6.35%[0m) [0.08% of initial]
[Iter 13120/20000] Loss: 0.0003343 (Best: 0.0002511 @iter11986) ([92m↓4.18%[0m) [0.13% of initial]
[Iter 15310/20000] Loss: 0.0002049 (Best: 0.0001498 @iter15283) ([91m↑7.71%[0m) [0.08% of initial]
[Iter 13130/20000] Loss: 0.0003459 (Best: 0.0002511 @iter11986) ([91m↑3.46%[0m) [0.14% of initial]
[Iter 15320/20000] Loss: 0.0001934 (Best: 0.0001498 @iter15283) ([92m↓5.64%[0m) [0.08% of initial]
[Iter 13140/20000] Loss: 0.0003262 (Best: 0.0002511 @iter11986) ([92m↓5.70%[0m) [0.13% of initial]
[Iter 15330/20000] Loss: 0.0001917 (Best: 0.0001498 @iter15283) ([92m↓0.89%[0m) [0.08% of initial]
[Iter 13150/20000] Loss: 0.0003130 (Best: 0.0002511 @iter11986) ([92m↓4.05%[0m) [0.12% of initial]
[Iter 15340/20000] Loss: 0.0001879 (Best: 0.0001498 @iter15283) ([92m↓1.98%[0m) [0.07% of initial]
[Iter 13160/20000] Loss: 0.0003281 (Best: 0.0002511 @iter11986) ([91m↑4.83%[0m) [0.13% of initial]
[Iter 15350/20000] Loss: 0.0001884 (Best: 0.0001498 @iter15283) ([91m↑0.29%[0m) [0.07% of initial]
[Iter 13170/20000] Loss: 0.0003198 (Best: 0.0002511 @iter11986) ([92m↓2.53%[0m) [0.13% of initial]
[Iter 15360/20000] Loss: 0.0002131 (Best: 0.0001498 @iter15283) ([91m↑13.09%[0m) [0.08% of initial]
[Iter 13180/20000] Loss: 0.0003482 (Best: 0.0002511 @iter11986) ([91m↑8.89%[0m) [0.14% of initial]
[Iter 15370/20000] Loss: 0.0002200 (Best: 0.0001498 @iter15283) ([91m↑3.24%[0m) [0.09% of initial]
[Iter 13190/20000] Loss: 0.0003471 (Best: 0.0002511 @iter11986) ([92m↓0.34%[0m) [0.14% of initial]
Iter:13199, L1 loss=0.0003732, Total loss=0.0003312, Time:149
[Iter 13200/20000] Loss: 0.0003412 (Best: 0.0002511 @iter11986) ([92m↓1.68%[0m) [0.14% of initial]
[Iter 15380/20000] Loss: 0.0001983 (Best: 0.0001498 @iter15283) ([92m↓9.85%[0m) [0.08% of initial]
[Iter 13210/20000] Loss: 0.0003551 (Best: 0.0002511 @iter11986) ([91m↑4.07%[0m) [0.14% of initial]
[Iter 15390/20000] Loss: 0.0001831 (Best: 0.0001498 @iter15283) ([92m↓7.66%[0m) [0.07% of initial]
[Iter 13220/20000] Loss: 0.0003085 (Best: 0.0002511 @iter11986) ([92m↓13.12%[0m) [0.12% of initial]
Iter:15399, L1 loss=0.0001843, Total loss=0.0001576, Time:160
[Iter 15400/20000] Loss: 0.0001608 (Best: 0.0001498 @iter15283) ([92m↓12.22%[0m) [0.06% of initial]
[Iter 13230/20000] Loss: 0.0003447 (Best: 0.0002511 @iter11986) ([91m↑11.72%[0m) [0.14% of initial]
[Iter 15410/20000] Loss: 0.0001591 (Best: 0.0001435 @iter15409) ([92m↓1.03%[0m) [0.06% of initial]
[Iter 13240/20000] Loss: 0.0003237 (Best: 0.0002511 @iter11986) ([92m↓6.09%[0m) [0.13% of initial]
[Iter 15420/20000] Loss: 0.0001644 (Best: 0.0001435 @iter15409) ([91m↑3.32%[0m) [0.07% of initial]
[Iter 13250/20000] Loss: 0.0003165 (Best: 0.0002511 @iter11986) ([92m↓2.22%[0m) [0.13% of initial]
[Iter 15430/20000] Loss: 0.0001620 (Best: 0.0001435 @iter15409) ([92m↓1.49%[0m) [0.06% of initial]
[Iter 13260/20000] Loss: 0.0003085 (Best: 0.0002511 @iter11986) ([92m↓2.52%[0m) [0.12% of initial]
[Iter 15440/20000] Loss: 0.0001712 (Best: 0.0001435 @iter15409) ([91m↑5.73%[0m) [0.07% of initial]
[Iter 13270/20000] Loss: 0.0003171 (Best: 0.0002511 @iter11986) ([91m↑2.78%[0m) [0.13% of initial]
[Iter 15450/20000] Loss: 0.0001958 (Best: 0.0001435 @iter15409) ([91m↑14.34%[0m) [0.08% of initial]
[Iter 13280/20000] Loss: 0.0003188 (Best: 0.0002511 @iter11986) ([91m↑0.55%[0m) [0.13% of initial]
[Iter 15460/20000] Loss: 0.0002228 (Best: 0.0001435 @iter15409) ([91m↑13.81%[0m) [0.09% of initial]
[Iter 13290/20000] Loss: 0.0002953 (Best: 0.0002511 @iter11986) ([92m↓7.40%[0m) [0.12% of initial]
Iter:13299, L1 loss=0.0003428, Total loss=0.0002887, Time:102
[Iter 13300/20000] Loss: 0.0002918 (Best: 0.0002511 @iter11986) ([92m↓1.18%[0m) [0.12% of initial]
[Iter 15470/20000] Loss: 0.0002415 (Best: 0.0001435 @iter15409) ([91m↑8.37%[0m) [0.10% of initial]
[Iter 13310/20000] Loss: 0.0002979 (Best: 0.0002511 @iter11986) ([91m↑2.11%[0m) [0.12% of initial]
[Iter 15480/20000] Loss: 0.0002152 (Best: 0.0001435 @iter15409) ([92m↓10.87%[0m) [0.09% of initial]
[Iter 13320/20000] Loss: 0.0003047 (Best: 0.0002511 @iter11986) ([91m↑2.27%[0m) [0.12% of initial]
[Iter 15490/20000] Loss: 0.0001825 (Best: 0.0001435 @iter15409) ([92m↓15.21%[0m) [0.07% of initial]
[Iter 13330/20000] Loss: 0.0003090 (Best: 0.0002511 @iter11986) ([91m↑1.43%[0m) [0.12% of initial]
Iter:15499, L1 loss=0.0002211, Total loss=0.0001835, Time:163
[Iter 15500/20000] Loss: 0.0001880 (Best: 0.0001435 @iter15409) ([91m↑3.04%[0m) [0.07% of initial]
[Iter 13340/20000] Loss: 0.0003185 (Best: 0.0002511 @iter11986) ([91m↑3.07%[0m) [0.13% of initial]
[Iter 15510/20000] Loss: 0.0001970 (Best: 0.0001435 @iter15409) ([91m↑4.78%[0m) [0.08% of initial]
[Iter 13350/20000] Loss: 0.0002995 (Best: 0.0002511 @iter11986) ([92m↓5.95%[0m) [0.12% of initial]
[Iter 15520/20000] Loss: 0.0001903 (Best: 0.0001435 @iter15409) ([92m↓3.39%[0m) [0.08% of initial]
[Iter 13360/20000] Loss: 0.0003077 (Best: 0.0002511 @iter11986) ([91m↑2.74%[0m) [0.12% of initial]
[Iter 15530/20000] Loss: 0.0001922 (Best: 0.0001435 @iter15409) ([91m↑0.96%[0m) [0.08% of initial]
[Iter 13370/20000] Loss: 0.0002870 (Best: 0.0002511 @iter11986) ([92m↓6.75%[0m) [0.11% of initial]
[Iter 15540/20000] Loss: 0.0001709 (Best: 0.0001435 @iter15409) ([92m↓11.07%[0m) [0.07% of initial]
[Iter 13380/20000] Loss: 0.0003146 (Best: 0.0002511 @iter11986) ([91m↑9.63%[0m) [0.12% of initial]
[Iter 15550/20000] Loss: 0.0001945 (Best: 0.0001435 @iter15409) ([91m↑13.79%[0m) [0.08% of initial]
[Iter 13390/20000] Loss: 0.0003185 (Best: 0.0002511 @iter11986) ([91m↑1.25%[0m) [0.13% of initial]
Iter:13399, L1 loss=0.0003637, Total loss=0.0002974, Time:148
[Iter 15560/20000] Loss: 0.0002510 (Best: 0.0001435 @iter15409) ([91m↑29.06%[0m) [0.10% of initial]
[Iter 13400/20000] Loss: 0.0003145 (Best: 0.0002511 @iter11986) ([92m↓1.26%[0m) [0.12% of initial]
[Iter 13410/20000] Loss: 0.0003066 (Best: 0.0002511 @iter11986) ([92m↓2.50%[0m) [0.12% of initial]
[Iter 15570/20000] Loss: 0.0002793 (Best: 0.0001435 @iter15409) ([91m↑11.30%[0m) [0.11% of initial]
[Iter 13420/20000] Loss: 0.0003100 (Best: 0.0002511 @iter11986) ([91m↑1.10%[0m) [0.12% of initial]
[Iter 15580/20000] Loss: 0.0002035 (Best: 0.0001435 @iter15409) ([92m↓27.16%[0m) [0.08% of initial]
[Iter 13430/20000] Loss: 0.0002924 (Best: 0.0002511 @iter11986) ([92m↓5.69%[0m) [0.12% of initial]
[Iter 15590/20000] Loss: 0.0001899 (Best: 0.0001435 @iter15409) ([92m↓6.66%[0m) [0.08% of initial]
[Iter 13440/20000] Loss: 0.0003011 (Best: 0.0002511 @iter11986) ([91m↑2.98%[0m) [0.12% of initial]
Iter:15599, L1 loss=0.0002068, Total loss=0.0001719, Time:166
[Iter 15600/20000] Loss: 0.0001831 (Best: 0.0001435 @iter15409) ([92m↓3.62%[0m) [0.07% of initial]
[Iter 13450/20000] Loss: 0.0002840 (Best: 0.0002511 @iter11986) ([92m↓5.68%[0m) [0.11% of initial]
[Iter 15610/20000] Loss: 0.0001940 (Best: 0.0001435 @iter15409) ([91m↑5.98%[0m) [0.08% of initial]
[Iter 13460/20000] Loss: 0.0002882 (Best: 0.0002511 @iter11986) ([91m↑1.50%[0m) [0.11% of initial]
[Iter 15620/20000] Loss: 0.0001783 (Best: 0.0001435 @iter15409) ([92m↓8.08%[0m) [0.07% of initial]
[Iter 13470/20000] Loss: 0.0003168 (Best: 0.0002511 @iter11986) ([91m↑9.92%[0m) [0.13% of initial]
[Iter 15630/20000] Loss: 0.0001966 (Best: 0.0001435 @iter15409) ([91m↑10.24%[0m) [0.08% of initial]
[Iter 13480/20000] Loss: 0.0003077 (Best: 0.0002511 @iter11986) ([92m↓2.87%[0m) [0.12% of initial]
[Iter 15640/20000] Loss: 0.0001880 (Best: 0.0001435 @iter15409) ([92m↓4.38%[0m) [0.07% of initial]
[Iter 13490/20000] Loss: 0.0003797 (Best: 0.0002511 @iter11986) ([91m↑23.39%[0m) [0.15% of initial]
Iter:13499, L1 loss=0.0003654, Total loss=0.0003275, Time:147
[Iter 15650/20000] Loss: 0.0002235 (Best: 0.0001435 @iter15409) ([91m↑18.89%[0m) [0.09% of initial]
[Iter 13500/20000] Loss: 0.0003453 (Best: 0.0002511 @iter11986) ([92m↓9.06%[0m) [0.14% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 13500
Pruning 9 points (0.0%) from gaussian1 at iteration 13500
[Iter 15660/20000] Loss: 0.0001837 (Best: 0.0001435 @iter15409) ([92m↓17.82%[0m) [0.07% of initial]
[Iter 13510/20000] Loss: 0.0006318 (Best: 0.0002511 @iter11986) ([91m↑82.96%[0m) [0.25% of initial]
[Iter 15670/20000] Loss: 0.0001900 (Best: 0.0001435 @iter15409) ([91m↑3.47%[0m) [0.08% of initial]
[Iter 13520/20000] Loss: 0.0004512 (Best: 0.0002511 @iter11986) ([92m↓28.57%[0m) [0.18% of initial]
[Iter 15680/20000] Loss: 0.0002769 (Best: 0.0001435 @iter15409) ([91m↑45.68%[0m) [0.11% of initial]
[Iter 13530/20000] Loss: 0.0003861 (Best: 0.0002511 @iter11986) ([92m↓14.43%[0m) [0.15% of initial]
[Iter 15690/20000] Loss: 0.0002311 (Best: 0.0001435 @iter15409) ([92m↓16.54%[0m) [0.09% of initial]
[Iter 13540/20000] Loss: 0.0003338 (Best: 0.0002511 @iter11986) ([92m↓13.54%[0m) [0.13% of initial]
Iter:15699, L1 loss=0.0002215, Total loss=0.0001889, Time:165
[Iter 15700/20000] Loss: 0.0001870 (Best: 0.0001435 @iter15409) ([92m↓19.06%[0m) [0.07% of initial]
[Iter 13550/20000] Loss: 0.0003108 (Best: 0.0002511 @iter11986) ([92m↓6.89%[0m) [0.12% of initial]
[Iter 15710/20000] Loss: 0.0001570 (Best: 0.0001435 @iter15409) ([92m↓16.02%[0m) [0.06% of initial]
[Iter 13560/20000] Loss: 0.0003008 (Best: 0.0002511 @iter11986) ([92m↓3.22%[0m) [0.12% of initial]
[Iter 15720/20000] Loss: 0.0001746 (Best: 0.0001435 @iter15409) ([91m↑11.20%[0m) [0.07% of initial]
[Iter 13570/20000] Loss: 0.0002822 (Best: 0.0002511 @iter11986) ([92m↓6.18%[0m) [0.11% of initial]
[Iter 15730/20000] Loss: 0.0001791 (Best: 0.0001435 @iter15409) ([91m↑2.58%[0m) [0.07% of initial]
[Iter 13580/20000] Loss: 0.0003007 (Best: 0.0002511 @iter11986) ([91m↑6.55%[0m) [0.12% of initial]
[Iter 13590/20000] Loss: 0.0003128 (Best: 0.0002511 @iter11986) ([91m↑4.02%[0m) [0.12% of initial]
[Iter 15740/20000] Loss: 0.0001786 (Best: 0.0001435 @iter15409) ([92m↓0.28%[0m) [0.07% of initial]
Iter:13599, L1 loss=0.0003345, Total loss=0.0002822, Time:152
[Iter 13600/20000] Loss: 0.0002790 (Best: 0.0002511 @iter11986) ([92m↓10.82%[0m) [0.11% of initial]
[Iter 15750/20000] Loss: 0.0001910 (Best: 0.0001435 @iter15409) ([91m↑6.93%[0m) [0.08% of initial]
[Iter 13610/20000] Loss: 0.0002890 (Best: 0.0002511 @iter11986) ([91m↑3.57%[0m) [0.11% of initial]
[Iter 15760/20000] Loss: 0.0002057 (Best: 0.0001435 @iter15409) ([91m↑7.70%[0m) [0.08% of initial]
[Iter 13620/20000] Loss: 0.0002798 (Best: 0.0002511 @iter11986) ([92m↓3.17%[0m) [0.11% of initial]
[Iter 15770/20000] Loss: 0.0002257 (Best: 0.0001435 @iter15409) ([91m↑9.70%[0m) [0.09% of initial]
[Iter 13630/20000] Loss: 0.0002730 (Best: 0.0002511 @iter11986) ([92m↓2.45%[0m) [0.11% of initial]
[Iter 15780/20000] Loss: 0.0001885 (Best: 0.0001435 @iter15409) ([92m↓16.46%[0m) [0.07% of initial]
[Iter 13640/20000] Loss: 0.0003151 (Best: 0.0002511 @iter11986) ([91m↑15.44%[0m) [0.13% of initial]
[Iter 15790/20000] Loss: 0.0001801 (Best: 0.0001435 @iter15409) ([92m↓4.47%[0m) [0.07% of initial]
[Iter 13650/20000] Loss: 0.0003215 (Best: 0.0002511 @iter11986) ([91m↑2.02%[0m) [0.13% of initial]
Iter:15799, L1 loss=0.0001884, Total loss=0.0001529, Time:121
[Iter 15800/20000] Loss: 0.0001716 (Best: 0.0001435 @iter15409) ([92m↓4.73%[0m) [0.07% of initial]
[Iter 13660/20000] Loss: 0.0003165 (Best: 0.0002511 @iter11986) ([92m↓1.55%[0m) [0.13% of initial]
[Iter 15810/20000] Loss: 0.0001800 (Best: 0.0001435 @iter15409) ([91m↑4.92%[0m) [0.07% of initial]
[Iter 13670/20000] Loss: 0.0003421 (Best: 0.0002511 @iter11986) ([91m↑8.10%[0m) [0.14% of initial]
[Iter 15820/20000] Loss: 0.0001919 (Best: 0.0001435 @iter15409) ([91m↑6.62%[0m) [0.08% of initial]
[Iter 13680/20000] Loss: 0.0003299 (Best: 0.0002511 @iter11986) ([92m↓3.55%[0m) [0.13% of initial]
[Iter 15830/20000] Loss: 0.0002151 (Best: 0.0001435 @iter15409) ([91m↑12.09%[0m) [0.09% of initial]
[Iter 13690/20000] Loss: 0.0003591 (Best: 0.0002511 @iter11986) ([91m↑8.83%[0m) [0.14% of initial]
Iter:13699, L1 loss=0.0003868, Total loss=0.0003797, Time:108
[Iter 13700/20000] Loss: 0.0003491 (Best: 0.0002511 @iter11986) ([92m↓2.77%[0m) [0.14% of initial]
[Iter 15840/20000] Loss: 0.0001926 (Best: 0.0001435 @iter15409) ([92m↓10.48%[0m) [0.08% of initial]
[Iter 13710/20000] Loss: 0.0003216 (Best: 0.0002511 @iter11986) ([92m↓7.88%[0m) [0.13% of initial]
[Iter 15850/20000] Loss: 0.0001902 (Best: 0.0001435 @iter15409) ([92m↓1.25%[0m) [0.08% of initial]
[Iter 13720/20000] Loss: 0.0003103 (Best: 0.0002511 @iter11986) ([92m↓3.51%[0m) [0.12% of initial]
[Iter 15860/20000] Loss: 0.0001970 (Best: 0.0001435 @iter15409) ([91m↑3.59%[0m) [0.08% of initial]
[Iter 13730/20000] Loss: 0.0003207 (Best: 0.0002511 @iter11986) ([91m↑3.35%[0m) [0.13% of initial]
[Iter 15870/20000] Loss: 0.0002046 (Best: 0.0001435 @iter15409) ([91m↑3.87%[0m) [0.08% of initial]
[Iter 13740/20000] Loss: 0.0003244 (Best: 0.0002511 @iter11986) ([91m↑1.14%[0m) [0.13% of initial]
[Iter 15880/20000] Loss: 0.0001955 (Best: 0.0001435 @iter15409) ([92m↓4.43%[0m) [0.08% of initial]
[Iter 13750/20000] Loss: 0.0002920 (Best: 0.0002511 @iter11986) ([92m↓9.99%[0m) [0.12% of initial]
[Iter 15890/20000] Loss: 0.0001742 (Best: 0.0001435 @iter15409) ([92m↓10.91%[0m) [0.07% of initial]
[Iter 13760/20000] Loss: 0.0003165 (Best: 0.0002511 @iter11986) ([91m↑8.40%[0m) [0.13% of initial]
Iter:15899, L1 loss=0.0001763, Total loss=0.0001473, Time:109
[Iter 15900/20000] Loss: 0.0001589 (Best: 0.0001435 @iter15409) ([92m↓8.76%[0m) [0.06% of initial]
[Iter 13770/20000] Loss: 0.0003266 (Best: 0.0002511 @iter11986) ([91m↑3.17%[0m) [0.13% of initial]
[Iter 15910/20000] Loss: 0.0001609 (Best: 0.0001412 @iter15907) ([91m↑1.23%[0m) [0.06% of initial]
[Iter 13780/20000] Loss: 0.0003312 (Best: 0.0002511 @iter11986) ([91m↑1.42%[0m) [0.13% of initial]
[Iter 13790/20000] Loss: 0.0004032 (Best: 0.0002511 @iter11986) ([91m↑21.73%[0m) [0.16% of initial]
[Iter 15920/20000] Loss: 0.0001650 (Best: 0.0001412 @iter15907) ([91m↑2.54%[0m) [0.07% of initial]
Iter:13799, L1 loss=0.000402, Total loss=0.0003314, Time:104
[Iter 13800/20000] Loss: 0.0003212 (Best: 0.0002511 @iter11986) ([92m↓20.32%[0m) [0.13% of initial]
[Iter 15930/20000] Loss: 0.0001537 (Best: 0.0001412 @iter15926) ([92m↓6.84%[0m) [0.06% of initial]
[Iter 13810/20000] Loss: 0.0003240 (Best: 0.0002511 @iter11986) ([91m↑0.85%[0m) [0.13% of initial]
[Iter 15940/20000] Loss: 0.0001463 (Best: 0.0001389 @iter15940) ([92m↓4.79%[0m) [0.06% of initial]
[Iter 13820/20000] Loss: 0.0003177 (Best: 0.0002511 @iter11986) ([92m↓1.93%[0m) [0.13% of initial]
[Iter 15950/20000] Loss: 0.0001865 (Best: 0.0001389 @iter15940) ([91m↑27.43%[0m) [0.07% of initial]
[Iter 13830/20000] Loss: 0.0003208 (Best: 0.0002511 @iter11986) ([91m↑0.98%[0m) [0.13% of initial]
[Iter 15960/20000] Loss: 0.0001719 (Best: 0.0001389 @iter15940) ([92m↓7.78%[0m) [0.07% of initial]
[Iter 13840/20000] Loss: 0.0003081 (Best: 0.0002511 @iter11986) ([92m↓3.96%[0m) [0.12% of initial]
[Iter 15970/20000] Loss: 0.0001624 (Best: 0.0001389 @iter15940) ([92m↓5.53%[0m) [0.06% of initial]
[Iter 13850/20000] Loss: 0.0002851 (Best: 0.0002511 @iter11986) ([92m↓7.47%[0m) [0.11% of initial]
[Iter 15980/20000] Loss: 0.0001555 (Best: 0.0001389 @iter15940) ([92m↓4.26%[0m) [0.06% of initial]
[Iter 13860/20000] Loss: 0.0002840 (Best: 0.0002511 @iter11986) ([92m↓0.39%[0m) [0.11% of initial]
[Iter 15990/20000] Loss: 0.0001755 (Best: 0.0001389 @iter15940) ([91m↑12.87%[0m) [0.07% of initial]
[Iter 13870/20000] Loss: 0.0002793 (Best: 0.0002511 @iter11986) ([92m↓1.67%[0m) [0.11% of initial]
Iter:15999, L1 loss=0.0002204, Total loss=0.0001716, Time:171
[Iter 16000/20000] Loss: 0.0001863 (Best: 0.0001389 @iter15940) ([91m↑6.13%[0m) [0.07% of initial]
[Iter 13880/20000] Loss: 0.0002895 (Best: 0.0002511 @iter11986) ([91m↑3.66%[0m) [0.12% of initial]
[Iter 13890/20000] Loss: 0.0002914 (Best: 0.0002511 @iter11986) ([91m↑0.64%[0m) [0.12% of initial]
[Iter 16010/20000] Loss: 0.0101734 (Best: 0.0001389 @iter15940) ([91m↑5360.64%[0m) [4.04% of initial]
Iter:13899, L1 loss=0.0003807, Total loss=0.0003328, Time:145
[Iter 13900/20000] Loss: 0.0003165 (Best: 0.0002511 @iter11986) ([91m↑8.63%[0m) [0.13% of initial]
[Iter 16020/20000] Loss: 0.0051183 (Best: 0.0001389 @iter15940) ([92m↓49.69%[0m) [2.03% of initial]
[Iter 13910/20000] Loss: 0.0002973 (Best: 0.0002511 @iter11986) ([92m↓6.07%[0m) [0.12% of initial]
[Iter 16030/20000] Loss: 0.0024766 (Best: 0.0001389 @iter15940) ([92m↓51.61%[0m) [0.98% of initial]
[Iter 13920/20000] Loss: 0.0003048 (Best: 0.0002511 @iter11986) ([91m↑2.54%[0m) [0.12% of initial]
[Iter 16040/20000] Loss: 0.0013232 (Best: 0.0001389 @iter15940) ([92m↓46.57%[0m) [0.53% of initial]
[Iter 13930/20000] Loss: 0.0002794 (Best: 0.0002511 @iter11986) ([92m↓8.33%[0m) [0.11% of initial]
[Iter 16050/20000] Loss: 0.0008499 (Best: 0.0001389 @iter15940) ([92m↓35.77%[0m) [0.34% of initial]
[Iter 13940/20000] Loss: 0.0002888 (Best: 0.0002511 @iter11986) ([91m↑3.36%[0m) [0.11% of initial]
[Iter 16060/20000] Loss: 0.0005625 (Best: 0.0001389 @iter15940) ([92m↓33.81%[0m) [0.22% of initial]
[Iter 13950/20000] Loss: 0.0003029 (Best: 0.0002511 @iter11986) ([91m↑4.86%[0m) [0.12% of initial]
[Iter 16070/20000] Loss: 0.0004432 (Best: 0.0001389 @iter15940) ([92m↓21.22%[0m) [0.18% of initial]
[Iter 13960/20000] Loss: 0.0002824 (Best: 0.0002511 @iter11986) ([92m↓6.74%[0m) [0.11% of initial]
[Iter 13970/20000] Loss: 0.0002934 (Best: 0.0002511 @iter11986) ([91m↑3.87%[0m) [0.12% of initial]
[Iter 16080/20000] Loss: 0.0003745 (Best: 0.0001389 @iter15940) ([92m↓15.50%[0m) [0.15% of initial]
[Iter 13980/20000] Loss: 0.0002960 (Best: 0.0002511 @iter11986) ([91m↑0.89%[0m) [0.12% of initial]
[Iter 16090/20000] Loss: 0.0003428 (Best: 0.0001389 @iter15940) ([92m↓8.45%[0m) [0.14% of initial]
[Iter 13990/20000] Loss: 0.0003287 (Best: 0.0002511 @iter11986) ([91m↑11.05%[0m) [0.13% of initial]
Iter:16099, L1 loss=0.0003098, Total loss=0.0002657, Time:181
[Iter 16100/20000] Loss: 0.0002835 (Best: 0.0001389 @iter15940) ([92m↓17.31%[0m) [0.11% of initial]
Iter:13999, L1 loss=0.0003232, Total loss=0.0002716, Time:167
[Iter 14000/20000] Loss: 0.0002982 (Best: 0.0002511 @iter11986) ([92m↓9.26%[0m) [0.12% of initial]
[Iter 16110/20000] Loss: 0.0002937 (Best: 0.0001389 @iter15940) ([91m↑3.59%[0m) [0.12% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 14000
Pruning 9 points (0.0%) from gaussian1 at iteration 14000
[Iter 16120/20000] Loss: 0.0002525 (Best: 0.0001389 @iter15940) ([92m↓14.01%[0m) [0.10% of initial]
[Iter 14010/20000] Loss: 0.0006133 (Best: 0.0002511 @iter11986) ([91m↑105.64%[0m) [0.24% of initial]
[Iter 16130/20000] Loss: 0.0002402 (Best: 0.0001389 @iter15940) ([92m↓4.89%[0m) [0.10% of initial]
[Iter 14020/20000] Loss: 0.0004216 (Best: 0.0002511 @iter11986) ([92m↓31.26%[0m) [0.17% of initial]
[Iter 16140/20000] Loss: 0.0002270 (Best: 0.0001389 @iter15940) ([92m↓5.49%[0m) [0.09% of initial]
[Iter 14030/20000] Loss: 0.0003535 (Best: 0.0002511 @iter11986) ([92m↓16.15%[0m) [0.14% of initial]
[Iter 16150/20000] Loss: 0.0002366 (Best: 0.0001389 @iter15940) ([91m↑4.24%[0m) [0.09% of initial]
[Iter 14040/20000] Loss: 0.0003119 (Best: 0.0002511 @iter11986) ([92m↓11.75%[0m) [0.12% of initial]
[Iter 14050/20000] Loss: 0.0003221 (Best: 0.0002511 @iter11986) ([91m↑3.25%[0m) [0.13% of initial]
[Iter 16160/20000] Loss: 0.0002298 (Best: 0.0001389 @iter15940) ([92m↓2.88%[0m) [0.09% of initial]
[Iter 14060/20000] Loss: 0.0003207 (Best: 0.0002511 @iter11986) ([92m↓0.42%[0m) [0.13% of initial]
[Iter 16170/20000] Loss: 0.0002656 (Best: 0.0001389 @iter15940) ([91m↑15.57%[0m) [0.11% of initial]
[Iter 14070/20000] Loss: 0.0002997 (Best: 0.0002511 @iter11986) ([92m↓6.55%[0m) [0.12% of initial]
[Iter 16180/20000] Loss: 0.0002481 (Best: 0.0001389 @iter15940) ([92m↓6.60%[0m) [0.10% of initial]
[Iter 14080/20000] Loss: 0.0002874 (Best: 0.0002511 @iter11986) ([92m↓4.10%[0m) [0.11% of initial]
[Iter 16190/20000] Loss: 0.0002424 (Best: 0.0001389 @iter15940) ([92m↓2.29%[0m) [0.10% of initial]
[Iter 14090/20000] Loss: 0.0002874 (Best: 0.0002511 @iter11986) ([91m↑0.01%[0m) [0.11% of initial]
Iter:16199, L1 loss=0.0002802, Total loss=0.000244, Time:158
[Iter 16200/20000] Loss: 0.0002559 (Best: 0.0001389 @iter15940) ([91m↑5.59%[0m) [0.10% of initial]
Iter:14099, L1 loss=0.0003139, Total loss=0.0002776, Time:144
[Iter 14100/20000] Loss: 0.0002793 (Best: 0.0002511 @iter11986) ([92m↓2.85%[0m) [0.11% of initial]
[Iter 16210/20000] Loss: 0.0002902 (Best: 0.0001389 @iter15940) ([91m↑13.41%[0m) [0.12% of initial]
[Iter 14110/20000] Loss: 0.0003026 (Best: 0.0002511 @iter11986) ([91m↑8.36%[0m) [0.12% of initial]
[Iter 14120/20000] Loss: 0.0002902 (Best: 0.0002511 @iter11986) ([92m↓4.09%[0m) [0.12% of initial]
[Iter 16220/20000] Loss: 0.0002697 (Best: 0.0001389 @iter15940) ([92m↓7.08%[0m) [0.11% of initial]
[Iter 14130/20000] Loss: 0.0003053 (Best: 0.0002511 @iter11986) ([91m↑5.19%[0m) [0.12% of initial]
[Iter 16230/20000] Loss: 0.0002532 (Best: 0.0001389 @iter15940) ([92m↓6.13%[0m) [0.10% of initial]
[Iter 14140/20000] Loss: 0.0002885 (Best: 0.0002511 @iter11986) ([92m↓5.49%[0m) [0.11% of initial]
[Iter 16240/20000] Loss: 0.0003069 (Best: 0.0001389 @iter15940) ([91m↑21.20%[0m) [0.12% of initial]
[Iter 14150/20000] Loss: 0.0002850 (Best: 0.0002511 @iter11986) ([92m↓1.22%[0m) [0.11% of initial]
[Iter 16250/20000] Loss: 0.0002560 (Best: 0.0001389 @iter15940) ([92m↓16.57%[0m) [0.10% of initial]
[Iter 14160/20000] Loss: 0.0002678 (Best: 0.0002511 @iter11986) ([92m↓6.03%[0m) [0.11% of initial]
[Iter 16260/20000] Loss: 0.0002203 (Best: 0.0001389 @iter15940) ([92m↓13.93%[0m) [0.09% of initial]
[Iter 14170/20000] Loss: 0.0002857 (Best: 0.0002508 @iter14162) ([91m↑6.67%[0m) [0.11% of initial]
[Iter 16270/20000] Loss: 0.0002007 (Best: 0.0001389 @iter15940) ([92m↓8.90%[0m) [0.08% of initial]
[Iter 14180/20000] Loss: 0.0002838 (Best: 0.0002508 @iter14162) ([92m↓0.67%[0m) [0.11% of initial]
[Iter 16280/20000] Loss: 0.0001888 (Best: 0.0001389 @iter15940) ([92m↓5.95%[0m) [0.08% of initial]
[Iter 14190/20000] Loss: 0.0002892 (Best: 0.0002508 @iter14162) ([91m↑1.91%[0m) [0.11% of initial]
Iter:14199, L1 loss=0.0003263, Total loss=0.0002738, Time:141
[Iter 14200/20000] Loss: 0.0002787 (Best: 0.0002508 @iter14162) ([92m↓3.62%[0m) [0.11% of initial]
[Iter 16290/20000] Loss: 0.0002005 (Best: 0.0001389 @iter15940) ([91m↑6.20%[0m) [0.08% of initial]
[Iter 14210/20000] Loss: 0.0002676 (Best: 0.0002468 @iter14206) ([92m↓4.01%[0m) [0.11% of initial]
Iter:16299, L1 loss=0.0003031, Total loss=0.0002536, Time:154
[Iter 16300/20000] Loss: 0.0002089 (Best: 0.0001389 @iter15940) ([91m↑4.20%[0m) [0.08% of initial]
[Iter 14220/20000] Loss: 0.0002705 (Best: 0.0002468 @iter14206) ([91m↑1.11%[0m) [0.11% of initial]
[Iter 16310/20000] Loss: 0.0002432 (Best: 0.0001389 @iter15940) ([91m↑16.38%[0m) [0.10% of initial]
[Iter 14230/20000] Loss: 0.0003438 (Best: 0.0002468 @iter14206) ([91m↑27.10%[0m) [0.14% of initial]
[Iter 16320/20000] Loss: 0.0002360 (Best: 0.0001389 @iter15940) ([92m↓2.96%[0m) [0.09% of initial]
[Iter 14240/20000] Loss: 0.0002916 (Best: 0.0002468 @iter14206) ([92m↓15.20%[0m) [0.12% of initial]
[Iter 16330/20000] Loss: 0.0002332 (Best: 0.0001389 @iter15940) ([92m↓1.19%[0m) [0.09% of initial]
[Iter 14250/20000] Loss: 0.0003037 (Best: 0.0002468 @iter14206) ([91m↑4.16%[0m) [0.12% of initial]
[Iter 16340/20000] Loss: 0.0002176 (Best: 0.0001389 @iter15940) ([92m↓6.68%[0m) [0.09% of initial]
[Iter 14260/20000] Loss: 0.0002887 (Best: 0.0002468 @iter14206) ([92m↓4.95%[0m) [0.11% of initial]
[Iter 14270/20000] Loss: 0.0003022 (Best: 0.0002468 @iter14206) ([91m↑4.66%[0m) [0.12% of initial]
[Iter 16350/20000] Loss: 0.0002190 (Best: 0.0001389 @iter15940) ([91m↑0.64%[0m) [0.09% of initial]
[Iter 14280/20000] Loss: 0.0002873 (Best: 0.0002468 @iter14206) ([92m↓4.91%[0m) [0.11% of initial]
[Iter 16360/20000] Loss: 0.0002077 (Best: 0.0001389 @iter15940) ([92m↓5.15%[0m) [0.08% of initial]
[Iter 14290/20000] Loss: 0.0002706 (Best: 0.0002468 @iter14206) ([92m↓5.83%[0m) [0.11% of initial]
[Iter 16370/20000] Loss: 0.0002613 (Best: 0.0001389 @iter15940) ([91m↑25.82%[0m) [0.10% of initial]
Iter:14299, L1 loss=0.0003339, Total loss=0.000276, Time:112
[Iter 14300/20000] Loss: 0.0002774 (Best: 0.0002468 @iter14206) ([91m↑2.51%[0m) [0.11% of initial]
[Iter 16380/20000] Loss: 0.0002512 (Best: 0.0001389 @iter15940) ([92m↓3.87%[0m) [0.10% of initial]
[Iter 14310/20000] Loss: 0.0003025 (Best: 0.0002468 @iter14206) ([91m↑9.08%[0m) [0.12% of initial]
[Iter 16390/20000] Loss: 0.0002491 (Best: 0.0001389 @iter15940) ([92m↓0.86%[0m) [0.10% of initial]
[Iter 14320/20000] Loss: 0.0002856 (Best: 0.0002468 @iter14206) ([92m↓5.59%[0m) [0.11% of initial]
Iter:16399, L1 loss=0.0002205, Total loss=0.0001866, Time:135
[Iter 16400/20000] Loss: 0.0002121 (Best: 0.0001389 @iter15940) ([92m↓14.84%[0m) [0.08% of initial]
[Iter 14330/20000] Loss: 0.0002949 (Best: 0.0002468 @iter14206) ([91m↑3.25%[0m) [0.12% of initial]
[Iter 14340/20000] Loss: 0.0003398 (Best: 0.0002468 @iter14206) ([91m↑15.22%[0m) [0.13% of initial]
[Iter 16410/20000] Loss: 0.0002037 (Best: 0.0001389 @iter15940) ([92m↓3.94%[0m) [0.08% of initial]
[Iter 14350/20000] Loss: 0.0003282 (Best: 0.0002468 @iter14206) ([92m↓3.41%[0m) [0.13% of initial]
[Iter 16420/20000] Loss: 0.0001883 (Best: 0.0001389 @iter15940) ([92m↓7.56%[0m) [0.07% of initial]
[Iter 14360/20000] Loss: 0.0003072 (Best: 0.0002468 @iter14206) ([92m↓6.40%[0m) [0.12% of initial]
[Iter 16430/20000] Loss: 0.0001807 (Best: 0.0001389 @iter15940) ([92m↓4.08%[0m) [0.07% of initial]
[Iter 14370/20000] Loss: 0.0002915 (Best: 0.0002468 @iter14206) ([92m↓5.10%[0m) [0.12% of initial]
[Iter 16440/20000] Loss: 0.0001859 (Best: 0.0001389 @iter15940) ([91m↑2.91%[0m) [0.07% of initial]
[Iter 14380/20000] Loss: 0.0002994 (Best: 0.0002468 @iter14206) ([91m↑2.71%[0m) [0.12% of initial]
[Iter 16450/20000] Loss: 0.0001904 (Best: 0.0001389 @iter15940) ([91m↑2.41%[0m) [0.08% of initial]
[Iter 14390/20000] Loss: 0.0003176 (Best: 0.0002468 @iter14206) ([91m↑6.07%[0m) [0.13% of initial]
Iter:14399, L1 loss=0.0002968, Total loss=0.0002743, Time:136
[Iter 16460/20000] Loss: 0.0001819 (Best: 0.0001389 @iter15940) ([92m↓4.45%[0m) [0.07% of initial]
[Iter 14400/20000] Loss: 0.0002913 (Best: 0.0002468 @iter14206) ([92m↓8.27%[0m) [0.12% of initial]
[Iter 14410/20000] Loss: 0.0003068 (Best: 0.0002468 @iter14206) ([91m↑5.29%[0m) [0.12% of initial]
[Iter 16470/20000] Loss: 0.0001982 (Best: 0.0001389 @iter15940) ([91m↑8.96%[0m) [0.08% of initial]
[Iter 14420/20000] Loss: 0.0004134 (Best: 0.0002468 @iter14206) ([91m↑34.77%[0m) [0.16% of initial]
[Iter 16480/20000] Loss: 0.0001889 (Best: 0.0001389 @iter15940) ([92m↓4.70%[0m) [0.08% of initial]
[Iter 14430/20000] Loss: 0.0004249 (Best: 0.0002468 @iter14206) ([91m↑2.78%[0m) [0.17% of initial]
[Iter 16490/20000] Loss: 0.0001806 (Best: 0.0001389 @iter15940) ([92m↓4.42%[0m) [0.07% of initial]
[Iter 14440/20000] Loss: 0.0004182 (Best: 0.0002468 @iter14206) ([92m↓1.58%[0m) [0.17% of initial]
Iter:16499, L1 loss=0.0002596, Total loss=0.0002098, Time:171
[Iter 16500/20000] Loss: 0.0002259 (Best: 0.0001389 @iter15940) ([91m↑25.12%[0m) [0.09% of initial]
[Iter 14450/20000] Loss: 0.0003608 (Best: 0.0002468 @iter14206) ([92m↓13.72%[0m) [0.14% of initial]
[Iter 16510/20000] Loss: 0.0001818 (Best: 0.0001389 @iter15940) ([92m↓19.52%[0m) [0.07% of initial]
[Iter 14460/20000] Loss: 0.0003502 (Best: 0.0002468 @iter14206) ([92m↓2.94%[0m) [0.14% of initial]
[Iter 16520/20000] Loss: 0.0001736 (Best: 0.0001389 @iter15940) ([92m↓4.54%[0m) [0.07% of initial]
[Iter 14470/20000] Loss: 0.0003247 (Best: 0.0002468 @iter14206) ([92m↓7.30%[0m) [0.13% of initial]
[Iter 14480/20000] Loss: 0.0003007 (Best: 0.0002468 @iter14206) ([92m↓7.39%[0m) [0.12% of initial]
[Iter 16530/20000] Loss: 0.0001716 (Best: 0.0001389 @iter15940) ([92m↓1.13%[0m) [0.07% of initial]
[Iter 14490/20000] Loss: 0.0002898 (Best: 0.0002468 @iter14206) ([92m↓3.62%[0m) [0.12% of initial]
[Iter 16540/20000] Loss: 0.0001864 (Best: 0.0001389 @iter15940) ([91m↑8.64%[0m) [0.07% of initial]
Iter:14499, L1 loss=0.0003348, Total loss=0.0002804, Time:133
[Iter 14500/20000] Loss: 0.0002817 (Best: 0.0002468 @iter14206) ([92m↓2.79%[0m) [0.11% of initial]
[Iter 16550/20000] Loss: 0.0001928 (Best: 0.0001389 @iter15940) ([91m↑3.43%[0m) [0.08% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 14500
Pruning 6 points (0.0%) from gaussian1 at iteration 14500
[Iter 16560/20000] Loss: 0.0001963 (Best: 0.0001389 @iter15940) ([91m↑1.82%[0m) [0.08% of initial]
[Iter 14510/20000] Loss: 0.0006652 (Best: 0.0002468 @iter14206) ([91m↑136.14%[0m) [0.26% of initial]
[Iter 16570/20000] Loss: 0.0001978 (Best: 0.0001389 @iter15940) ([91m↑0.75%[0m) [0.08% of initial]
[Iter 14520/20000] Loss: 0.0005623 (Best: 0.0002468 @iter14206) ([92m↓15.47%[0m) [0.22% of initial]
[Iter 16580/20000] Loss: 0.0001910 (Best: 0.0001389 @iter15940) ([92m↓3.44%[0m) [0.08% of initial]
[Iter 14530/20000] Loss: 0.0004465 (Best: 0.0002468 @iter14206) ([92m↓20.58%[0m) [0.18% of initial]
[Iter 14540/20000] Loss: 0.0004075 (Best: 0.0002468 @iter14206) ([92m↓8.73%[0m) [0.16% of initial]
[Iter 16590/20000] Loss: 0.0001858 (Best: 0.0001389 @iter15940) ([92m↓2.71%[0m) [0.07% of initial]
[Iter 14550/20000] Loss: 0.0003184 (Best: 0.0002468 @iter14206) ([92m↓21.88%[0m) [0.13% of initial]
Iter:16599, L1 loss=0.0002262, Total loss=0.000191, Time:160
[Iter 16600/20000] Loss: 0.0001749 (Best: 0.0001389 @iter15940) ([92m↓5.87%[0m) [0.07% of initial]
[Iter 14560/20000] Loss: 0.0002789 (Best: 0.0002468 @iter14206) ([92m↓12.41%[0m) [0.11% of initial]
[Iter 16610/20000] Loss: 0.0001690 (Best: 0.0001389 @iter15940) ([92m↓3.38%[0m) [0.07% of initial]
[Iter 14570/20000] Loss: 0.0002720 (Best: 0.0002468 @iter14206) ([92m↓2.46%[0m) [0.11% of initial]
[Iter 16620/20000] Loss: 0.0001744 (Best: 0.0001389 @iter15940) ([91m↑3.21%[0m) [0.07% of initial]
[Iter 14580/20000] Loss: 0.0002603 (Best: 0.0002435 @iter14578) ([92m↓4.31%[0m) [0.10% of initial]
[Iter 16630/20000] Loss: 0.0001954 (Best: 0.0001389 @iter15940) ([91m↑12.00%[0m) [0.08% of initial]
[Iter 14590/20000] Loss: 0.0002748 (Best: 0.0002435 @iter14578) ([91m↑5.57%[0m) [0.11% of initial]
[Iter 16640/20000] Loss: 0.0002119 (Best: 0.0001389 @iter15940) ([91m↑8.47%[0m) [0.08% of initial]
Iter:14599, L1 loss=0.0003269, Total loss=0.0002929, Time:121
[Iter 14600/20000] Loss: 0.0002887 (Best: 0.0002435 @iter14578) ([91m↑5.08%[0m) [0.11% of initial]
[Iter 16650/20000] Loss: 0.0002464 (Best: 0.0001389 @iter15940) ([91m↑16.26%[0m) [0.10% of initial]
[Iter 14610/20000] Loss: 0.0003591 (Best: 0.0002435 @iter14578) ([91m↑24.37%[0m) [0.14% of initial]
[Iter 14620/20000] Loss: 0.0003067 (Best: 0.0002435 @iter14578) ([92m↓14.59%[0m) [0.12% of initial]
[Iter 16660/20000] Loss: 0.0002668 (Best: 0.0001389 @iter15940) ([91m↑8.26%[0m) [0.11% of initial]
[Iter 14630/20000] Loss: 0.0002675 (Best: 0.0002435 @iter14578) ([92m↓12.80%[0m) [0.11% of initial]
[Iter 16670/20000] Loss: 0.0002661 (Best: 0.0001389 @iter15940) ([92m↓0.23%[0m) [0.11% of initial]
[Iter 14640/20000] Loss: 0.0002760 (Best: 0.0002435 @iter14578) ([91m↑3.20%[0m) [0.11% of initial]
[Iter 16680/20000] Loss: 0.0002091 (Best: 0.0001389 @iter15940) ([92m↓21.43%[0m) [0.08% of initial]
[Iter 14650/20000] Loss: 0.0002957 (Best: 0.0002435 @iter14578) ([91m↑7.13%[0m) [0.12% of initial]
[Iter 16690/20000] Loss: 0.0001857 (Best: 0.0001389 @iter15940) ([92m↓11.18%[0m) [0.07% of initial]
[Iter 14660/20000] Loss: 0.0002847 (Best: 0.0002435 @iter14578) ([92m↓3.74%[0m) [0.11% of initial]
Iter:16699, L1 loss=0.0002341, Total loss=0.0001946, Time:166
[Iter 16700/20000] Loss: 0.0001881 (Best: 0.0001389 @iter15940) ([91m↑1.29%[0m) [0.07% of initial]
[Iter 14670/20000] Loss: 0.0002803 (Best: 0.0002435 @iter14578) ([92m↓1.54%[0m) [0.11% of initial]
[Iter 16710/20000] Loss: 0.0001859 (Best: 0.0001389 @iter15940) ([92m↓1.16%[0m) [0.07% of initial]
[Iter 14680/20000] Loss: 0.0002792 (Best: 0.0002435 @iter14578) ([92m↓0.40%[0m) [0.11% of initial]
[Iter 16720/20000] Loss: 0.0002059 (Best: 0.0001389 @iter15940) ([91m↑10.72%[0m) [0.08% of initial]
[Iter 14690/20000] Loss: 0.0002561 (Best: 0.0002435 @iter14578) ([92m↓8.26%[0m) [0.10% of initial]
Iter:14699, L1 loss=0.0003248, Total loss=0.0002863, Time:142
[Iter 14700/20000] Loss: 0.0002695 (Best: 0.0002435 @iter14578) ([91m↑5.24%[0m) [0.11% of initial]
[Iter 16730/20000] Loss: 0.0001834 (Best: 0.0001389 @iter15940) ([92m↓10.89%[0m) [0.07% of initial]
[Iter 14710/20000] Loss: 0.0002547 (Best: 0.0002421 @iter14710) ([92m↓5.48%[0m) [0.10% of initial]
[Iter 16740/20000] Loss: 0.0002035 (Best: 0.0001389 @iter15940) ([91m↑10.93%[0m) [0.08% of initial]
[Iter 14720/20000] Loss: 0.0002630 (Best: 0.0002374 @iter14716) ([91m↑3.25%[0m) [0.10% of initial]
[Iter 16750/20000] Loss: 0.0001876 (Best: 0.0001389 @iter15940) ([92m↓7.80%[0m) [0.07% of initial]
[Iter 14730/20000] Loss: 0.0002634 (Best: 0.0002374 @iter14716) ([91m↑0.15%[0m) [0.10% of initial]
[Iter 16760/20000] Loss: 0.0001809 (Best: 0.0001389 @iter15940) ([92m↓3.59%[0m) [0.07% of initial]
[Iter 14740/20000] Loss: 0.0002511 (Best: 0.0002374 @iter14716) ([92m↓4.65%[0m) [0.10% of initial]
[Iter 16770/20000] Loss: 0.0001814 (Best: 0.0001389 @iter15940) ([91m↑0.29%[0m) [0.07% of initial]
[Iter 14750/20000] Loss: 0.0002469 (Best: 0.0002371 @iter14750) ([92m↓1.69%[0m) [0.10% of initial]
[Iter 16780/20000] Loss: 0.0001831 (Best: 0.0001389 @iter15940) ([91m↑0.96%[0m) [0.07% of initial]
[Iter 14760/20000] Loss: 0.0002523 (Best: 0.0002274 @iter14752) ([91m↑2.20%[0m) [0.10% of initial]
[Iter 14770/20000] Loss: 0.0003000 (Best: 0.0002274 @iter14752) ([91m↑18.89%[0m) [0.12% of initial]
[Iter 16790/20000] Loss: 0.0002054 (Best: 0.0001389 @iter15940) ([91m↑12.16%[0m) [0.08% of initial]
[Iter 14780/20000] Loss: 0.0003137 (Best: 0.0002274 @iter14752) ([91m↑4.57%[0m) [0.12% of initial]
Iter:16799, L1 loss=0.0002559, Total loss=0.000213, Time:116
[Iter 16800/20000] Loss: 0.0002013 (Best: 0.0001389 @iter15940) ([92m↓1.99%[0m) [0.08% of initial]
[Iter 14790/20000] Loss: 0.0003229 (Best: 0.0002274 @iter14752) ([91m↑2.93%[0m) [0.13% of initial]
[Iter 16810/20000] Loss: 0.0002141 (Best: 0.0001389 @iter15940) ([91m↑6.37%[0m) [0.09% of initial]
Iter:14799, L1 loss=0.0004034, Total loss=0.0003756, Time:101
[Iter 14800/20000] Loss: 0.0003226 (Best: 0.0002274 @iter14752) ([92m↓0.10%[0m) [0.13% of initial]
[Iter 16820/20000] Loss: 0.0001959 (Best: 0.0001389 @iter15940) ([92m↓8.51%[0m) [0.08% of initial]
[Iter 14810/20000] Loss: 0.0003030 (Best: 0.0002274 @iter14752) ([92m↓6.07%[0m) [0.12% of initial]
[Iter 16830/20000] Loss: 0.0002029 (Best: 0.0001389 @iter15940) ([91m↑3.57%[0m) [0.08% of initial]
[Iter 14820/20000] Loss: 0.0002828 (Best: 0.0002274 @iter14752) ([92m↓6.67%[0m) [0.11% of initial]
[Iter 16840/20000] Loss: 0.0002580 (Best: 0.0001389 @iter15940) ([91m↑27.15%[0m) [0.10% of initial]
[Iter 14830/20000] Loss: 0.0002764 (Best: 0.0002274 @iter14752) ([92m↓2.26%[0m) [0.11% of initial]
[Iter 16850/20000] Loss: 0.0002138 (Best: 0.0001389 @iter15940) ([92m↓17.13%[0m) [0.08% of initial]
[Iter 14840/20000] Loss: 0.0002772 (Best: 0.0002274 @iter14752) ([91m↑0.28%[0m) [0.11% of initial]
[Iter 14850/20000] Loss: 0.0002893 (Best: 0.0002274 @iter14752) ([91m↑4.40%[0m) [0.11% of initial]
[Iter 16860/20000] Loss: 0.0001905 (Best: 0.0001389 @iter15940) ([92m↓10.91%[0m) [0.08% of initial]
[Iter 14860/20000] Loss: 0.0002932 (Best: 0.0002274 @iter14752) ([91m↑1.34%[0m) [0.12% of initial]
[Iter 16870/20000] Loss: 0.0001794 (Best: 0.0001389 @iter15940) ([92m↓5.82%[0m) [0.07% of initial]
[Iter 14870/20000] Loss: 0.0002832 (Best: 0.0002274 @iter14752) ([92m↓3.43%[0m) [0.11% of initial]
[Iter 16880/20000] Loss: 0.0002923 (Best: 0.0001389 @iter15940) ([91m↑62.95%[0m) [0.12% of initial]
[Iter 14880/20000] Loss: 0.0002728 (Best: 0.0002274 @iter14752) ([92m↓3.67%[0m) [0.11% of initial]
[Iter 16890/20000] Loss: 0.0002103 (Best: 0.0001389 @iter15940) ([92m↓28.04%[0m) [0.08% of initial]
[Iter 14890/20000] Loss: 0.0002638 (Best: 0.0002274 @iter14752) ([92m↓3.28%[0m) [0.10% of initial]
Iter:16899, L1 loss=0.0002549, Total loss=0.0002157, Time:174
[Iter 16900/20000] Loss: 0.0001952 (Best: 0.0001389 @iter15940) ([92m↓7.19%[0m) [0.08% of initial]
Iter:14899, L1 loss=0.0003172, Total loss=0.000269, Time:148
[Iter 14900/20000] Loss: 0.0002647 (Best: 0.0002274 @iter14752) ([91m↑0.33%[0m) [0.11% of initial]
[Iter 16910/20000] Loss: 0.0001820 (Best: 0.0001389 @iter15940) ([92m↓6.77%[0m) [0.07% of initial]
[Iter 14910/20000] Loss: 0.0002663 (Best: 0.0002274 @iter14752) ([91m↑0.59%[0m) [0.11% of initial]
[Iter 14920/20000] Loss: 0.0002715 (Best: 0.0002274 @iter14752) ([91m↑1.95%[0m) [0.11% of initial]
[Iter 16920/20000] Loss: 0.0002122 (Best: 0.0001389 @iter15940) ([91m↑16.58%[0m) [0.08% of initial]
[Iter 14930/20000] Loss: 0.0002647 (Best: 0.0002274 @iter14752) ([92m↓2.49%[0m) [0.11% of initial]
[Iter 16930/20000] Loss: 0.0001942 (Best: 0.0001389 @iter15940) ([92m↓8.46%[0m) [0.08% of initial]
[Iter 14940/20000] Loss: 0.0002545 (Best: 0.0002274 @iter14752) ([92m↓3.86%[0m) [0.10% of initial]
[Iter 16940/20000] Loss: 0.0002245 (Best: 0.0001389 @iter15940) ([91m↑15.59%[0m) [0.09% of initial]
[Iter 14950/20000] Loss: 0.0002787 (Best: 0.0002274 @iter14752) ([91m↑9.53%[0m) [0.11% of initial]
[Iter 16950/20000] Loss: 0.0002068 (Best: 0.0001389 @iter15940) ([92m↓7.89%[0m) [0.08% of initial]
[Iter 14960/20000] Loss: 0.0002573 (Best: 0.0002274 @iter14752) ([92m↓7.70%[0m) [0.10% of initial]
[Iter 16960/20000] Loss: 0.0001967 (Best: 0.0001389 @iter15940) ([92m↓4.90%[0m) [0.08% of initial]
[Iter 14970/20000] Loss: 0.0003019 (Best: 0.0002274 @iter14752) ([91m↑17.33%[0m) [0.12% of initial]
[Iter 16970/20000] Loss: 0.0001965 (Best: 0.0001389 @iter15940) ([92m↓0.10%[0m) [0.08% of initial]
[Iter 14980/20000] Loss: 0.0003311 (Best: 0.0002274 @iter14752) ([91m↑9.69%[0m) [0.13% of initial]
[Iter 16980/20000] Loss: 0.0001812 (Best: 0.0001389 @iter15940) ([92m↓7.79%[0m) [0.07% of initial]
[Iter 14990/20000] Loss: 0.0003673 (Best: 0.0002274 @iter14752) ([91m↑10.92%[0m) [0.15% of initial]
Iter:14999, L1 loss=0.0004427, Total loss=0.0003553, Time:138
[Iter 15000/20000] Loss: 0.0004275 (Best: 0.0002274 @iter14752) ([91m↑16.39%[0m) [0.17% of initial]
[Iter 16990/20000] Loss: 0.0001995 (Best: 0.0001389 @iter15940) ([91m↑10.10%[0m) [0.08% of initial]
Iter:16999, L1 loss=0.0002121, Total loss=0.000183, Time:150
Pruning 8 points (0.0%) from gaussian0 at iteration 15000
[Iter 17000/20000] Loss: 0.0001891 (Best: 0.0001389 @iter15940) ([92m↓5.20%[0m) [0.08% of initial]
Pruning 2 points (0.0%) from gaussian1 at iteration 15000
[Iter 15010/20000] Loss: 0.0004789 (Best: 0.0002274 @iter14752) ([91m↑12.03%[0m) [0.19% of initial]
[Iter 17010/20000] Loss: 0.0002283 (Best: 0.0001389 @iter15940) ([91m↑20.74%[0m) [0.09% of initial]
[Iter 15020/20000] Loss: 0.0004014 (Best: 0.0002274 @iter14752) ([92m↓16.18%[0m) [0.16% of initial]
[Iter 17020/20000] Loss: 0.0001967 (Best: 0.0001389 @iter15940) ([92m↓13.85%[0m) [0.08% of initial]
[Iter 15030/20000] Loss: 0.0003091 (Best: 0.0002274 @iter14752) ([92m↓22.99%[0m) [0.12% of initial]
[Iter 17030/20000] Loss: 0.0001926 (Best: 0.0001389 @iter15940) ([92m↓2.09%[0m) [0.08% of initial]
[Iter 15040/20000] Loss: 0.0002817 (Best: 0.0002274 @iter14752) ([92m↓8.86%[0m) [0.11% of initial]
[Iter 17040/20000] Loss: 0.0001866 (Best: 0.0001389 @iter15940) ([92m↓3.14%[0m) [0.07% of initial]
[Iter 15050/20000] Loss: 0.0002610 (Best: 0.0002274 @iter14752) ([92m↓7.34%[0m) [0.10% of initial]
[Iter 17050/20000] Loss: 0.0002181 (Best: 0.0001389 @iter15940) ([91m↑16.90%[0m) [0.09% of initial]
[Iter 15060/20000] Loss: 0.0002854 (Best: 0.0002274 @iter14752) ([91m↑9.36%[0m) [0.11% of initial]
[Iter 17060/20000] Loss: 0.0002818 (Best: 0.0001389 @iter15940) ([91m↑29.21%[0m) [0.11% of initial]
[Iter 15070/20000] Loss: 0.0002671 (Best: 0.0002274 @iter14752) ([92m↓6.43%[0m) [0.11% of initial]
[Iter 17070/20000] Loss: 0.0002705 (Best: 0.0001389 @iter15940) ([92m↓4.00%[0m) [0.11% of initial]
[Iter 15080/20000] Loss: 0.0002577 (Best: 0.0002274 @iter14752) ([92m↓3.50%[0m) [0.10% of initial]
[Iter 15090/20000] Loss: 0.0002549 (Best: 0.0002274 @iter14752) ([92m↓1.08%[0m) [0.10% of initial]
[Iter 17080/20000] Loss: 0.0002127 (Best: 0.0001389 @iter15940) ([92m↓21.36%[0m) [0.08% of initial]
Iter:15099, L1 loss=0.0002841, Total loss=0.0002507, Time:137
[Iter 15100/20000] Loss: 0.0002434 (Best: 0.0002274 @iter14752) ([92m↓4.52%[0m) [0.10% of initial]
[Iter 17090/20000] Loss: 0.0001821 (Best: 0.0001389 @iter15940) ([92m↓14.39%[0m) [0.07% of initial]
[Iter 15110/20000] Loss: 0.0002681 (Best: 0.0002274 @iter14752) ([91m↑10.13%[0m) [0.11% of initial]
Iter:17099, L1 loss=0.0002129, Total loss=0.0001674, Time:173
[Iter 17100/20000] Loss: 0.0001714 (Best: 0.0001389 @iter15940) ([92m↓5.88%[0m) [0.07% of initial]
[Iter 15120/20000] Loss: 0.0002738 (Best: 0.0002274 @iter14752) ([91m↑2.12%[0m) [0.11% of initial]
[Iter 17110/20000] Loss: 0.0001785 (Best: 0.0001389 @iter15940) ([91m↑4.12%[0m) [0.07% of initial]
[Iter 15130/20000] Loss: 0.0002864 (Best: 0.0002274 @iter14752) ([91m↑4.63%[0m) [0.11% of initial]
[Iter 17120/20000] Loss: 0.0001639 (Best: 0.0001389 @iter15940) ([92m↓8.19%[0m) [0.07% of initial]
[Iter 15140/20000] Loss: 0.0002641 (Best: 0.0002274 @iter14752) ([92m↓7.78%[0m) [0.10% of initial]
[Iter 17130/20000] Loss: 0.0001760 (Best: 0.0001389 @iter15940) ([91m↑7.39%[0m) [0.07% of initial]
[Iter 15150/20000] Loss: 0.0002976 (Best: 0.0002274 @iter14752) ([91m↑12.67%[0m) [0.12% of initial]
[Iter 15160/20000] Loss: 0.0002609 (Best: 0.0002274 @iter14752) ([92m↓12.32%[0m) [0.10% of initial]
[Iter 17140/20000] Loss: 0.0001868 (Best: 0.0001389 @iter15940) ([91m↑6.14%[0m) [0.07% of initial]
[Iter 15170/20000] Loss: 0.0002528 (Best: 0.0002274 @iter14752) ([92m↓3.13%[0m) [0.10% of initial]
[Iter 17150/20000] Loss: 0.0001727 (Best: 0.0001389 @iter15940) ([92m↓7.56%[0m) [0.07% of initial]
[Iter 15180/20000] Loss: 0.0002704 (Best: 0.0002274 @iter14752) ([91m↑6.96%[0m) [0.11% of initial]
[Iter 17160/20000] Loss: 0.0001911 (Best: 0.0001389 @iter15940) ([91m↑10.66%[0m) [0.08% of initial]
[Iter 15190/20000] Loss: 0.0002583 (Best: 0.0002274 @iter14752) ([92m↓4.45%[0m) [0.10% of initial]
[Iter 17170/20000] Loss: 0.0002096 (Best: 0.0001389 @iter15940) ([91m↑9.68%[0m) [0.08% of initial]
Iter:15199, L1 loss=0.0003112, Total loss=0.0002726, Time:149
[Iter 15200/20000] Loss: 0.0002625 (Best: 0.0002274 @iter14752) ([91m↑1.60%[0m) [0.10% of initial]
[Iter 17180/20000] Loss: 0.0001764 (Best: 0.0001389 @iter15940) ([92m↓15.83%[0m) [0.07% of initial]
[Iter 15210/20000] Loss: 0.0003144 (Best: 0.0002274 @iter14752) ([91m↑19.78%[0m) [0.12% of initial]
[Iter 17190/20000] Loss: 0.0001828 (Best: 0.0001389 @iter15940) ([91m↑3.61%[0m) [0.07% of initial]
[Iter 15220/20000] Loss: 0.0003249 (Best: 0.0002274 @iter14752) ([91m↑3.34%[0m) [0.13% of initial]
Iter:17199, L1 loss=0.000194, Total loss=0.000163, Time:162
[Iter 17200/20000] Loss: 0.0001681 (Best: 0.0001389 @iter15940) ([92m↓8.02%[0m) [0.07% of initial]
[Iter 15230/20000] Loss: 0.0002865 (Best: 0.0002274 @iter14752) ([92m↓11.80%[0m) [0.11% of initial]
[Iter 15240/20000] Loss: 0.0002662 (Best: 0.0002274 @iter14752) ([92m↓7.08%[0m) [0.11% of initial]
[Iter 17210/20000] Loss: 0.0001590 (Best: 0.0001389 @iter15940) ([92m↓5.40%[0m) [0.06% of initial]
[Iter 15250/20000] Loss: 0.0002459 (Best: 0.0002274 @iter14752) ([92m↓7.63%[0m) [0.10% of initial]
[Iter 17220/20000] Loss: 0.0001557 (Best: 0.0001389 @iter15940) ([92m↓2.12%[0m) [0.06% of initial]
[Iter 15260/20000] Loss: 0.0002591 (Best: 0.0002274 @iter14752) ([91m↑5.35%[0m) [0.10% of initial]
[Iter 17230/20000] Loss: 0.0001558 (Best: 0.0001389 @iter15940) ([91m↑0.11%[0m) [0.06% of initial]
[Iter 15270/20000] Loss: 0.0002566 (Best: 0.0002274 @iter14752) ([92m↓0.97%[0m) [0.10% of initial]
[Iter 17240/20000] Loss: 0.0001876 (Best: 0.0001389 @iter15940) ([91m↑20.37%[0m) [0.07% of initial]
[Iter 15280/20000] Loss: 0.0002570 (Best: 0.0002274 @iter14752) ([91m↑0.17%[0m) [0.10% of initial]
[Iter 17250/20000] Loss: 0.0001908 (Best: 0.0001389 @iter15940) ([91m↑1.69%[0m) [0.08% of initial]
[Iter 15290/20000] Loss: 0.0002667 (Best: 0.0002274 @iter14752) ([91m↑3.78%[0m) [0.11% of initial]
Iter:15299, L1 loss=0.0003091, Total loss=0.0002738, Time:139
[Iter 17260/20000] Loss: 0.0001705 (Best: 0.0001389 @iter15940) ([92m↓10.62%[0m) [0.07% of initial]
[Iter 15300/20000] Loss: 0.0002812 (Best: 0.0002274 @iter14752) ([91m↑5.42%[0m) [0.11% of initial]
[Iter 15310/20000] Loss: 0.0002942 (Best: 0.0002274 @iter14752) ([91m↑4.63%[0m) [0.12% of initial]
[Iter 17270/20000] Loss: 0.0001888 (Best: 0.0001389 @iter15940) ([91m↑10.73%[0m) [0.08% of initial]
[Iter 15320/20000] Loss: 0.0002887 (Best: 0.0002274 @iter14752) ([92m↓1.86%[0m) [0.11% of initial]
[Iter 17280/20000] Loss: 0.0001815 (Best: 0.0001389 @iter15940) ([92m↓3.87%[0m) [0.07% of initial]
[Iter 15330/20000] Loss: 0.0002852 (Best: 0.0002274 @iter14752) ([92m↓1.22%[0m) [0.11% of initial]
[Iter 17290/20000] Loss: 0.0002730 (Best: 0.0001389 @iter15940) ([91m↑50.45%[0m) [0.11% of initial]
[Iter 15340/20000] Loss: 0.0002716 (Best: 0.0002274 @iter14752) ([92m↓4.76%[0m) [0.11% of initial]
Iter:17299, L1 loss=0.0002276, Total loss=0.0001802, Time:119
[Iter 17300/20000] Loss: 0.0001966 (Best: 0.0001389 @iter15940) ([92m↓27.98%[0m) [0.08% of initial]
[Iter 15350/20000] Loss: 0.0002696 (Best: 0.0002274 @iter14752) ([92m↓0.75%[0m) [0.11% of initial]
[Iter 17310/20000] Loss: 0.0001878 (Best: 0.0001389 @iter15940) ([92m↓4.48%[0m) [0.07% of initial]
[Iter 15360/20000] Loss: 0.0002948 (Best: 0.0002274 @iter14752) ([91m↑9.36%[0m) [0.12% of initial]
[Iter 17320/20000] Loss: 0.0002160 (Best: 0.0001389 @iter15940) ([91m↑15.01%[0m) [0.09% of initial]
[Iter 15370/20000] Loss: 0.0003041 (Best: 0.0002274 @iter14752) ([91m↑3.16%[0m) [0.12% of initial]
[Iter 15380/20000] Loss: 0.0002909 (Best: 0.0002274 @iter14752) ([92m↓4.34%[0m) [0.12% of initial]
[Iter 17330/20000] Loss: 0.0001787 (Best: 0.0001389 @iter15940) ([92m↓17.30%[0m) [0.07% of initial]
[Iter 15390/20000] Loss: 0.0002658 (Best: 0.0002274 @iter14752) ([92m↓8.63%[0m) [0.11% of initial]
[Iter 17340/20000] Loss: 0.0001604 (Best: 0.0001389 @iter15940) ([92m↓10.25%[0m) [0.06% of initial]
Iter:15399, L1 loss=0.0002821, Total loss=0.0002473, Time:107
[Iter 15400/20000] Loss: 0.0002455 (Best: 0.0002274 @iter14752) ([92m↓7.63%[0m) [0.10% of initial]
[Iter 17350/20000] Loss: 0.0001873 (Best: 0.0001389 @iter15940) ([91m↑16.80%[0m) [0.07% of initial]
[Iter 15410/20000] Loss: 0.0002455 (Best: 0.0002259 @iter15409) ([91m↑0.00%[0m) [0.10% of initial]
[Iter 17360/20000] Loss: 0.0001815 (Best: 0.0001389 @iter15940) ([92m↓3.09%[0m) [0.07% of initial]
[Iter 15420/20000] Loss: 0.0002473 (Best: 0.0002238 @iter15415) ([91m↑0.72%[0m) [0.10% of initial]
[Iter 17370/20000] Loss: 0.0001660 (Best: 0.0001389 @iter15940) ([92m↓8.56%[0m) [0.07% of initial]
[Iter 15430/20000] Loss: 0.0002388 (Best: 0.0002238 @iter15415) ([92m↓3.44%[0m) [0.09% of initial]
[Iter 17380/20000] Loss: 0.0001873 (Best: 0.0001389 @iter15940) ([91m↑12.82%[0m) [0.07% of initial]
[Iter 15440/20000] Loss: 0.0002436 (Best: 0.0002238 @iter15415) ([91m↑2.02%[0m) [0.10% of initial]
[Iter 15450/20000] Loss: 0.0002665 (Best: 0.0002238 @iter15415) ([91m↑9.42%[0m) [0.11% of initial]
[Iter 17390/20000] Loss: 0.0001823 (Best: 0.0001389 @iter15940) ([92m↓2.65%[0m) [0.07% of initial]
[Iter 15460/20000] Loss: 0.0002924 (Best: 0.0002238 @iter15415) ([91m↑9.69%[0m) [0.12% of initial]
Iter:17399, L1 loss=0.0002045, Total loss=0.0001721, Time:164
[Iter 17400/20000] Loss: 0.0001775 (Best: 0.0001389 @iter15940) ([92m↓2.60%[0m) [0.07% of initial]
[Iter 15470/20000] Loss: 0.0003375 (Best: 0.0002238 @iter15415) ([91m↑15.44%[0m) [0.13% of initial]
[Iter 17410/20000] Loss: 0.0001778 (Best: 0.0001389 @iter15940) ([91m↑0.17%[0m) [0.07% of initial]
[Iter 15480/20000] Loss: 0.0003063 (Best: 0.0002238 @iter15415) ([92m↓9.24%[0m) [0.12% of initial]
[Iter 17420/20000] Loss: 0.0001887 (Best: 0.0001389 @iter15940) ([91m↑6.12%[0m) [0.07% of initial]
[Iter 15490/20000] Loss: 0.0002644 (Best: 0.0002238 @iter15415) ([92m↓13.70%[0m) [0.11% of initial]
[Iter 17430/20000] Loss: 0.0001847 (Best: 0.0001389 @iter15940) ([92m↓2.12%[0m) [0.07% of initial]
Iter:15499, L1 loss=0.0003088, Total loss=0.0002573, Time:108
[Iter 15500/20000] Loss: 0.0002665 (Best: 0.0002238 @iter15415) ([91m↑0.79%[0m) [0.11% of initial]
[Iter 17440/20000] Loss: 0.0001672 (Best: 0.0001389 @iter15940) ([92m↓9.50%[0m) [0.07% of initial]
Pruning 6 points (0.0%) from gaussian0 at iteration 15500
Pruning 6 points (0.0%) from gaussian1 at iteration 15500
[Iter 17450/20000] Loss: 0.0001806 (Best: 0.0001389 @iter15940) ([91m↑8.05%[0m) [0.07% of initial]
[Iter 15510/20000] Loss: 0.0005930 (Best: 0.0002238 @iter15415) ([91m↑122.56%[0m) [0.24% of initial]
[Iter 17460/20000] Loss: 0.0002022 (Best: 0.0001389 @iter15940) ([91m↑11.92%[0m) [0.08% of initial]
[Iter 15520/20000] Loss: 0.0004141 (Best: 0.0002238 @iter15415) ([92m↓30.17%[0m) [0.16% of initial]
[Iter 17470/20000] Loss: 0.0001786 (Best: 0.0001389 @iter15940) ([92m↓11.66%[0m) [0.07% of initial]
[Iter 15530/20000] Loss: 0.0003398 (Best: 0.0002238 @iter15415) ([92m↓17.96%[0m) [0.13% of initial]
[Iter 17480/20000] Loss: 0.0001698 (Best: 0.0001389 @iter15940) ([92m↓4.89%[0m) [0.07% of initial]
[Iter 15540/20000] Loss: 0.0002816 (Best: 0.0002238 @iter15415) ([92m↓17.11%[0m) [0.11% of initial]
[Iter 15550/20000] Loss: 0.0002640 (Best: 0.0002238 @iter15415) ([92m↓6.26%[0m) [0.10% of initial]
[Iter 17490/20000] Loss: 0.0001983 (Best: 0.0001389 @iter15940) ([91m↑16.75%[0m) [0.08% of initial]
[Iter 15560/20000] Loss: 0.0002738 (Best: 0.0002238 @iter15415) ([91m↑3.73%[0m) [0.11% of initial]
Iter:17499, L1 loss=0.0002016, Total loss=0.0001644, Time:165
[Iter 17500/20000] Loss: 0.0001625 (Best: 0.0001389 @iter15940) ([92m↓18.07%[0m) [0.06% of initial]
[Iter 15570/20000] Loss: 0.0002872 (Best: 0.0002238 @iter15415) ([91m↑4.90%[0m) [0.11% of initial]
[Iter 17510/20000] Loss: 0.0001642 (Best: 0.0001389 @iter15940) ([91m↑1.07%[0m) [0.07% of initial]
[Iter 15580/20000] Loss: 0.0002532 (Best: 0.0002238 @iter15415) ([92m↓11.87%[0m) [0.10% of initial]
[Iter 17520/20000] Loss: 0.0001675 (Best: 0.0001389 @iter15940) ([91m↑2.03%[0m) [0.07% of initial]
[Iter 15590/20000] Loss: 0.0002426 (Best: 0.0002238 @iter15415) ([92m↓4.18%[0m) [0.10% of initial]
[Iter 17530/20000] Loss: 0.0001583 (Best: 0.0001389 @iter15940) ([92m↓5.50%[0m) [0.06% of initial]
Iter:15599, L1 loss=0.0002824, Total loss=0.0002428, Time:139
[Iter 15600/20000] Loss: 0.0002469 (Best: 0.0002238 @iter15415) ([91m↑1.78%[0m) [0.10% of initial]
[Iter 17540/20000] Loss: 0.0001599 (Best: 0.0001389 @iter15940) ([91m↑1.03%[0m) [0.06% of initial]
[Iter 15610/20000] Loss: 0.0002624 (Best: 0.0002238 @iter15415) ([91m↑6.28%[0m) [0.10% of initial]
[Iter 15620/20000] Loss: 0.0002668 (Best: 0.0002238 @iter15415) ([91m↑1.68%[0m) [0.11% of initial]
[Iter 17550/20000] Loss: 0.0001572 (Best: 0.0001389 @iter15940) ([92m↓1.73%[0m) [0.06% of initial]
[Iter 15630/20000] Loss: 0.0002753 (Best: 0.0002238 @iter15415) ([91m↑3.21%[0m) [0.11% of initial]
[Iter 17560/20000] Loss: 0.0001609 (Best: 0.0001389 @iter15940) ([91m↑2.34%[0m) [0.06% of initial]
[Iter 15640/20000] Loss: 0.0002555 (Best: 0.0002238 @iter15415) ([92m↓7.20%[0m) [0.10% of initial]
[Iter 17570/20000] Loss: 0.0001977 (Best: 0.0001389 @iter15940) ([91m↑22.92%[0m) [0.08% of initial]
[Iter 15650/20000] Loss: 0.0002966 (Best: 0.0002238 @iter15415) ([91m↑16.06%[0m) [0.12% of initial]
[Iter 17580/20000] Loss: 0.0001771 (Best: 0.0001389 @iter15940) ([92m↓10.43%[0m) [0.07% of initial]
[Iter 15660/20000] Loss: 0.0002735 (Best: 0.0002238 @iter15415) ([92m↓7.78%[0m) [0.11% of initial]
[Iter 17590/20000] Loss: 0.0001676 (Best: 0.0001389 @iter15940) ([92m↓5.34%[0m) [0.07% of initial]
[Iter 15670/20000] Loss: 0.0002845 (Best: 0.0002238 @iter15415) ([91m↑4.01%[0m) [0.11% of initial]
Iter:17599, L1 loss=0.0002152, Total loss=0.0001614, Time:135
[Iter 17600/20000] Loss: 0.0001932 (Best: 0.0001389 @iter15940) ([91m↑15.25%[0m) [0.08% of initial]
[Iter 15680/20000] Loss: 0.0003798 (Best: 0.0002238 @iter15415) ([91m↑33.50%[0m) [0.15% of initial]
[Iter 15690/20000] Loss: 0.0003496 (Best: 0.0002238 @iter15415) ([92m↓7.95%[0m) [0.14% of initial]
[Iter 17610/20000] Loss: 0.0001757 (Best: 0.0001389 @iter15940) ([92m↓9.04%[0m) [0.07% of initial]
Iter:15699, L1 loss=0.0003153, Total loss=0.0002878, Time:131
[Iter 15700/20000] Loss: 0.0002856 (Best: 0.0002238 @iter15415) ([92m↓18.29%[0m) [0.11% of initial]
[Iter 17620/20000] Loss: 0.0001855 (Best: 0.0001389 @iter15940) ([91m↑5.55%[0m) [0.07% of initial]
[Iter 15710/20000] Loss: 0.0002495 (Best: 0.0002238 @iter15415) ([92m↓12.66%[0m) [0.10% of initial]
[Iter 17630/20000] Loss: 0.0001789 (Best: 0.0001389 @iter15940) ([92m↓3.55%[0m) [0.07% of initial]
[Iter 15720/20000] Loss: 0.0002571 (Best: 0.0002238 @iter15415) ([91m↑3.06%[0m) [0.10% of initial]
[Iter 17640/20000] Loss: 0.0001773 (Best: 0.0001389 @iter15940) ([92m↓0.89%[0m) [0.07% of initial]
[Iter 15730/20000] Loss: 0.0002603 (Best: 0.0002238 @iter15415) ([91m↑1.24%[0m) [0.10% of initial]
[Iter 17650/20000] Loss: 0.0001868 (Best: 0.0001389 @iter15940) ([91m↑5.36%[0m) [0.07% of initial]
[Iter 15740/20000] Loss: 0.0002551 (Best: 0.0002238 @iter15415) ([92m↓2.00%[0m) [0.10% of initial]
[Iter 17660/20000] Loss: 0.0001804 (Best: 0.0001389 @iter15940) ([92m↓3.44%[0m) [0.07% of initial]
[Iter 15750/20000] Loss: 0.0002685 (Best: 0.0002238 @iter15415) ([91m↑5.24%[0m) [0.11% of initial]
[Iter 17670/20000] Loss: 0.0001936 (Best: 0.0001389 @iter15940) ([91m↑7.34%[0m) [0.08% of initial]
[Iter 15760/20000] Loss: 0.0002832 (Best: 0.0002238 @iter15415) ([91m↑5.47%[0m) [0.11% of initial]
[Iter 15770/20000] Loss: 0.0003091 (Best: 0.0002238 @iter15415) ([91m↑9.17%[0m) [0.12% of initial]
[Iter 17680/20000] Loss: 0.0001862 (Best: 0.0001389 @iter15940) ([92m↓3.83%[0m) [0.07% of initial]
[Iter 15780/20000] Loss: 0.0002659 (Best: 0.0002238 @iter15415) ([92m↓13.99%[0m) [0.11% of initial]
[Iter 17690/20000] Loss: 0.0001959 (Best: 0.0001389 @iter15940) ([91m↑5.18%[0m) [0.08% of initial]
[Iter 15790/20000] Loss: 0.0002510 (Best: 0.0002238 @iter15415) ([92m↓5.60%[0m) [0.10% of initial]
Iter:17699, L1 loss=0.0001904, Total loss=0.0001543, Time:157
[Iter 17700/20000] Loss: 0.0001731 (Best: 0.0001389 @iter15940) ([92m↓11.61%[0m) [0.07% of initial]
Iter:15799, L1 loss=0.000275, Total loss=0.0002249, Time:135
[Iter 15800/20000] Loss: 0.0002412 (Best: 0.0002214 @iter15797) ([92m↓3.88%[0m) [0.10% of initial]
[Iter 17710/20000] Loss: 0.0001633 (Best: 0.0001389 @iter15940) ([92m↓5.65%[0m) [0.06% of initial]
[Iter 15810/20000] Loss: 0.0002475 (Best: 0.0002205 @iter15806) ([91m↑2.62%[0m) [0.10% of initial]
[Iter 17720/20000] Loss: 0.0002147 (Best: 0.0001389 @iter15940) ([91m↑31.43%[0m) [0.09% of initial]
[Iter 15820/20000] Loss: 0.0002558 (Best: 0.0002205 @iter15806) ([91m↑3.34%[0m) [0.10% of initial]
[Iter 17730/20000] Loss: 0.0001952 (Best: 0.0001389 @iter15940) ([92m↓9.06%[0m) [0.08% of initial]
[Iter 15830/20000] Loss: 0.0002640 (Best: 0.0002205 @iter15806) ([91m↑3.18%[0m) [0.10% of initial]
[Iter 15840/20000] Loss: 0.0002694 (Best: 0.0002205 @iter15806) ([91m↑2.06%[0m) [0.11% of initial]
[Iter 17740/20000] Loss: 0.0001767 (Best: 0.0001389 @iter15940) ([92m↓9.52%[0m) [0.07% of initial]
[Iter 15850/20000] Loss: 0.0002799 (Best: 0.0002205 @iter15806) ([91m↑3.89%[0m) [0.11% of initial]
[Iter 17750/20000] Loss: 0.0001751 (Best: 0.0001389 @iter15940) ([92m↓0.90%[0m) [0.07% of initial]
[Iter 15860/20000] Loss: 0.0002906 (Best: 0.0002205 @iter15806) ([91m↑3.83%[0m) [0.12% of initial]
[Iter 17760/20000] Loss: 0.0001543 (Best: 0.0001389 @iter15940) ([92m↓11.88%[0m) [0.06% of initial]
[Iter 15870/20000] Loss: 0.0002848 (Best: 0.0002205 @iter15806) ([92m↓1.99%[0m) [0.11% of initial]
[Iter 17770/20000] Loss: 0.0001503 (Best: 0.0001389 @iter15940) ([92m↓2.56%[0m) [0.06% of initial]
[Iter 15880/20000] Loss: 0.0002721 (Best: 0.0002205 @iter15806) ([92m↓4.46%[0m) [0.11% of initial]
[Iter 17780/20000] Loss: 0.0001528 (Best: 0.0001333 @iter17779) ([91m↑1.66%[0m) [0.06% of initial]
[Iter 15890/20000] Loss: 0.0002595 (Best: 0.0002205 @iter15806) ([92m↓4.62%[0m) [0.10% of initial]
Iter:15899, L1 loss=0.0002602, Total loss=0.0002214, Time:91
[Iter 17790/20000] Loss: 0.0002048 (Best: 0.0001333 @iter17779) ([91m↑34.00%[0m) [0.08% of initial]
[Iter 15900/20000] Loss: 0.0002321 (Best: 0.0002205 @iter15806) ([92m↓10.56%[0m) [0.09% of initial]
[Iter 15910/20000] Loss: 0.0002286 (Best: 0.0002162 @iter15901) ([92m↓1.50%[0m) [0.09% of initial]
Iter:17799, L1 loss=0.0003243, Total loss=0.0002797, Time:123
[Iter 17800/20000] Loss: 0.0002327 (Best: 0.0001333 @iter17779) ([91m↑13.64%[0m) [0.09% of initial]
[Iter 15920/20000] Loss: 0.0002337 (Best: 0.0002160 @iter15916) ([91m↑2.19%[0m) [0.09% of initial]
[Iter 17810/20000] Loss: 0.0002090 (Best: 0.0001333 @iter17779) ([92m↓10.19%[0m) [0.08% of initial]
[Iter 15930/20000] Loss: 0.0002268 (Best: 0.0002160 @iter15916) ([92m↓2.91%[0m) [0.09% of initial]
[Iter 17820/20000] Loss: 0.0001974 (Best: 0.0001333 @iter17779) ([92m↓5.53%[0m) [0.08% of initial]
[Iter 15940/20000] Loss: 0.0002205 (Best: 0.0002128 @iter15940) ([92m↓2.80%[0m) [0.09% of initial]
[Iter 17830/20000] Loss: 0.0001711 (Best: 0.0001333 @iter17779) ([92m↓13.31%[0m) [0.07% of initial]
[Iter 15950/20000] Loss: 0.0002527 (Best: 0.0002128 @iter15940) ([91m↑14.59%[0m) [0.10% of initial]
[Iter 17840/20000] Loss: 0.0001564 (Best: 0.0001333 @iter17779) ([92m↓8.64%[0m) [0.06% of initial]
[Iter 15960/20000] Loss: 0.0002403 (Best: 0.0002128 @iter15940) ([92m↓4.88%[0m) [0.10% of initial]
[Iter 17850/20000] Loss: 0.0001563 (Best: 0.0001333 @iter17779) ([92m↓0.05%[0m) [0.06% of initial]
[Iter 15970/20000] Loss: 0.0002373 (Best: 0.0002128 @iter15940) ([92m↓1.26%[0m) [0.09% of initial]
[Iter 15980/20000] Loss: 0.0002354 (Best: 0.0002128 @iter15940) ([92m↓0.81%[0m) [0.09% of initial]
[Iter 17860/20000] Loss: 0.0001533 (Best: 0.0001333 @iter17779) ([92m↓1.93%[0m) [0.06% of initial]
[Iter 15990/20000] Loss: 0.0002637 (Best: 0.0002128 @iter15940) ([91m↑12.05%[0m) [0.10% of initial]
[Iter 17870/20000] Loss: 0.0001586 (Best: 0.0001333 @iter17779) ([91m↑3.47%[0m) [0.06% of initial]
Iter:15999, L1 loss=0.0003092, Total loss=0.0002571, Time:100
[Iter 16000/20000] Loss: 0.0002725 (Best: 0.0002128 @iter15940) ([91m↑3.33%[0m) [0.11% of initial]
[Iter 17880/20000] Loss: 0.0001840 (Best: 0.0001333 @iter17779) ([91m↑16.04%[0m) [0.07% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 16000
Pruning 6 points (0.0%) from gaussian1 at iteration 16000
[Iter 17890/20000] Loss: 0.0001525 (Best: 0.0001333 @iter17779) ([92m↓17.14%[0m) [0.06% of initial]
[Iter 16010/20000] Loss: 0.0131777 (Best: 0.0002128 @iter15940) ([91m↑4735.48%[0m) [5.24% of initial]
Iter:17899, L1 loss=0.0001896, Total loss=0.0001502, Time:160
[Iter 17900/20000] Loss: 0.0001546 (Best: 0.0001333 @iter17779) ([91m↑1.38%[0m) [0.06% of initial]
[Iter 16020/20000] Loss: 0.0054725 (Best: 0.0002128 @iter15940) ([92m↓58.47%[0m) [2.17% of initial]
[Iter 17910/20000] Loss: 0.0001555 (Best: 0.0001333 @iter17779) ([91m↑0.56%[0m) [0.06% of initial]
[Iter 16030/20000] Loss: 0.0025917 (Best: 0.0002128 @iter15940) ([92m↓52.64%[0m) [1.03% of initial]
[Iter 17920/20000] Loss: 0.0001782 (Best: 0.0001333 @iter17779) ([91m↑14.67%[0m) [0.07% of initial]
[Iter 16040/20000] Loss: 0.0017004 (Best: 0.0002128 @iter15940) ([92m↓34.39%[0m) [0.68% of initial]
[Iter 16050/20000] Loss: 0.0011091 (Best: 0.0002128 @iter15940) ([92m↓34.78%[0m) [0.44% of initial]
[Iter 17930/20000] Loss: 0.0001648 (Best: 0.0001333 @iter17779) ([92m↓7.53%[0m) [0.07% of initial]
[Iter 16060/20000] Loss: 0.0008439 (Best: 0.0002128 @iter15940) ([92m↓23.91%[0m) [0.34% of initial]
[Iter 17940/20000] Loss: 0.0001576 (Best: 0.0001333 @iter17779) ([92m↓4.41%[0m) [0.06% of initial]
[Iter 16070/20000] Loss: 0.0006720 (Best: 0.0002128 @iter15940) ([92m↓20.37%[0m) [0.27% of initial]
[Iter 17950/20000] Loss: 0.0001623 (Best: 0.0001333 @iter17779) ([91m↑2.99%[0m) [0.06% of initial]
[Iter 16080/20000] Loss: 0.0005926 (Best: 0.0002128 @iter15940) ([92m↓11.82%[0m) [0.24% of initial]
[Iter 17960/20000] Loss: 0.0001635 (Best: 0.0001333 @iter17779) ([91m↑0.76%[0m) [0.06% of initial]
[Iter 16090/20000] Loss: 0.0005138 (Best: 0.0002128 @iter15940) ([92m↓13.30%[0m) [0.20% of initial]
[Iter 17970/20000] Loss: 0.0001585 (Best: 0.0001333 @iter17779) ([92m↓3.06%[0m) [0.06% of initial]
Iter:16099, L1 loss=0.0004708, Total loss=0.0004428, Time:151
[Iter 16100/20000] Loss: 0.0004558 (Best: 0.0002128 @iter15940) ([92m↓11.29%[0m) [0.18% of initial]
[Iter 17980/20000] Loss: 0.0001692 (Best: 0.0001333 @iter17779) ([91m↑6.75%[0m) [0.07% of initial]
[Iter 16110/20000] Loss: 0.0004313 (Best: 0.0002128 @iter15940) ([92m↓5.38%[0m) [0.17% of initial]
[Iter 17990/20000] Loss: 0.0001521 (Best: 0.0001333 @iter17779) ([92m↓10.13%[0m) [0.06% of initial]
[Iter 16120/20000] Loss: 0.0003999 (Best: 0.0002128 @iter15940) ([92m↓7.29%[0m) [0.16% of initial]
Iter:17999, L1 loss=0.0001861, Total loss=0.0001519, Time:115
[Iter 18000/20000] Loss: 0.0001480 (Best: 0.0001333 @iter17779) ([92m↓2.66%[0m) [0.06% of initial]
[Iter 16130/20000] Loss: 0.0003825 (Best: 0.0002128 @iter15940) ([92m↓4.35%[0m) [0.15% of initial]
[Iter 18010/20000] Loss: 0.0001563 (Best: 0.0001321 @iter18004) ([91m↑5.57%[0m) [0.06% of initial]
[Iter 16140/20000] Loss: 0.0003598 (Best: 0.0002128 @iter15940) ([92m↓5.92%[0m) [0.14% of initial]
[Iter 16150/20000] Loss: 0.0003465 (Best: 0.0002128 @iter15940) ([92m↓3.69%[0m) [0.14% of initial]
[Iter 18020/20000] Loss: 0.0001815 (Best: 0.0001321 @iter18004) ([91m↑16.13%[0m) [0.07% of initial]
[Iter 16160/20000] Loss: 0.0003394 (Best: 0.0002128 @iter15940) ([92m↓2.06%[0m) [0.13% of initial]
[Iter 18030/20000] Loss: 0.0002115 (Best: 0.0001321 @iter18004) ([91m↑16.54%[0m) [0.08% of initial]
[Iter 16170/20000] Loss: 0.0003378 (Best: 0.0002128 @iter15940) ([92m↓0.46%[0m) [0.13% of initial]
[Iter 18040/20000] Loss: 0.0001890 (Best: 0.0001321 @iter18004) ([92m↓10.64%[0m) [0.08% of initial]
[Iter 16180/20000] Loss: 0.0003316 (Best: 0.0002128 @iter15940) ([92m↓1.85%[0m) [0.13% of initial]
[Iter 18050/20000] Loss: 0.0001845 (Best: 0.0001321 @iter18004) ([92m↓2.39%[0m) [0.07% of initial]
[Iter 16190/20000] Loss: 0.0003226 (Best: 0.0002128 @iter15940) ([92m↓2.69%[0m) [0.13% of initial]
[Iter 18060/20000] Loss: 0.0001956 (Best: 0.0001321 @iter18004) ([91m↑6.01%[0m) [0.08% of initial]
Iter:16199, L1 loss=0.0003576, Total loss=0.0003185, Time:141
[Iter 16200/20000] Loss: 0.0003229 (Best: 0.0002128 @iter15940) ([91m↑0.08%[0m) [0.13% of initial]
[Iter 18070/20000] Loss: 0.0001959 (Best: 0.0001321 @iter18004) ([91m↑0.16%[0m) [0.08% of initial]
[Iter 16210/20000] Loss: 0.0003291 (Best: 0.0002128 @iter15940) ([91m↑1.91%[0m) [0.13% of initial]
[Iter 18080/20000] Loss: 0.0001952 (Best: 0.0001321 @iter18004) ([92m↓0.33%[0m) [0.08% of initial]
[Iter 16220/20000] Loss: 0.0003236 (Best: 0.0002128 @iter15940) ([92m↓1.65%[0m) [0.13% of initial]
[Iter 18090/20000] Loss: 0.0002156 (Best: 0.0001321 @iter18004) ([91m↑10.44%[0m) [0.09% of initial]
[Iter 16230/20000] Loss: 0.0003235 (Best: 0.0002128 @iter15940) ([92m↓0.03%[0m) [0.13% of initial]
Iter:18099, L1 loss=0.000287, Total loss=0.0002341, Time:158
[Iter 18100/20000] Loss: 0.0001968 (Best: 0.0001321 @iter18004) ([92m↓8.74%[0m) [0.08% of initial]
[Iter 16240/20000] Loss: 0.0003547 (Best: 0.0002128 @iter15940) ([91m↑9.63%[0m) [0.14% of initial]
[Iter 16250/20000] Loss: 0.0003205 (Best: 0.0002128 @iter15940) ([92m↓9.64%[0m) [0.13% of initial]
[Iter 18110/20000] Loss: 0.0001850 (Best: 0.0001321 @iter18004) ([92m↓5.96%[0m) [0.07% of initial]
[Iter 16260/20000] Loss: 0.0003074 (Best: 0.0002128 @iter15940) ([92m↓4.09%[0m) [0.12% of initial]
[Iter 18120/20000] Loss: 0.0001867 (Best: 0.0001321 @iter18004) ([91m↑0.89%[0m) [0.07% of initial]
[Iter 16270/20000] Loss: 0.0002948 (Best: 0.0002128 @iter15940) ([92m↓4.09%[0m) [0.12% of initial]
[Iter 18130/20000] Loss: 0.0001676 (Best: 0.0001321 @iter18004) ([92m↓10.21%[0m) [0.07% of initial]
[Iter 16280/20000] Loss: 0.0002852 (Best: 0.0002128 @iter15940) ([92m↓3.26%[0m) [0.11% of initial]
[Iter 18140/20000] Loss: 0.0001797 (Best: 0.0001321 @iter18004) ([91m↑7.19%[0m) [0.07% of initial]
[Iter 16290/20000] Loss: 0.0002937 (Best: 0.0002128 @iter15940) ([91m↑2.96%[0m) [0.12% of initial]
[Iter 18150/20000] Loss: 0.0001855 (Best: 0.0001321 @iter18004) ([91m↑3.25%[0m) [0.07% of initial]
Iter:16299, L1 loss=0.0003679, Total loss=0.0003195, Time:160
[Iter 16300/20000] Loss: 0.0002868 (Best: 0.0002128 @iter15940) ([92m↓2.35%[0m) [0.11% of initial]
[Iter 18160/20000] Loss: 0.0001694 (Best: 0.0001321 @iter18004) ([92m↓8.71%[0m) [0.07% of initial]
[Iter 16310/20000] Loss: 0.0003120 (Best: 0.0002128 @iter15940) ([91m↑8.79%[0m) [0.12% of initial]
[Iter 18170/20000] Loss: 0.0001674 (Best: 0.0001321 @iter18004) ([92m↓1.14%[0m) [0.07% of initial]
[Iter 16320/20000] Loss: 0.0003191 (Best: 0.0002128 @iter15940) ([91m↑2.29%[0m) [0.13% of initial]
[Iter 18180/20000] Loss: 0.0002309 (Best: 0.0001321 @iter18004) ([91m↑37.90%[0m) [0.09% of initial]
[Iter 16330/20000] Loss: 0.0003231 (Best: 0.0002128 @iter15940) ([91m↑1.23%[0m) [0.13% of initial]
[Iter 18190/20000] Loss: 0.0002103 (Best: 0.0001321 @iter18004) ([92m↓8.92%[0m) [0.08% of initial]
[Iter 16340/20000] Loss: 0.0003173 (Best: 0.0002128 @iter15940) ([92m↓1.79%[0m) [0.13% of initial]
Iter:18199, L1 loss=0.0002106, Total loss=0.0001791, Time:179
[Iter 18200/20000] Loss: 0.0002113 (Best: 0.0001321 @iter18004) ([91m↑0.48%[0m) [0.08% of initial]
[Iter 16350/20000] Loss: 0.0003106 (Best: 0.0002128 @iter15940) ([92m↓2.09%[0m) [0.12% of initial]
[Iter 16360/20000] Loss: 0.0003011 (Best: 0.0002128 @iter15940) ([92m↓3.08%[0m) [0.12% of initial]
[Iter 18210/20000] Loss: 0.0001958 (Best: 0.0001321 @iter18004) ([92m↓7.33%[0m) [0.08% of initial]
[Iter 16370/20000] Loss: 0.0003390 (Best: 0.0002128 @iter15940) ([91m↑12.59%[0m) [0.13% of initial]
[Iter 18220/20000] Loss: 0.0002612 (Best: 0.0001321 @iter18004) ([91m↑33.37%[0m) [0.10% of initial]
[Iter 16380/20000] Loss: 0.0003350 (Best: 0.0002128 @iter15940) ([92m↓1.18%[0m) [0.13% of initial]
[Iter 18230/20000] Loss: 0.0002174 (Best: 0.0001321 @iter18004) ([92m↓16.75%[0m) [0.09% of initial]
[Iter 16390/20000] Loss: 0.0003361 (Best: 0.0002128 @iter15940) ([91m↑0.34%[0m) [0.13% of initial]
[Iter 18240/20000] Loss: 0.0001961 (Best: 0.0001321 @iter18004) ([92m↓9.81%[0m) [0.08% of initial]
Iter:16399, L1 loss=0.0003221, Total loss=0.0002817, Time:125
[Iter 16400/20000] Loss: 0.0003112 (Best: 0.0002128 @iter15940) ([92m↓7.43%[0m) [0.12% of initial]
[Iter 18250/20000] Loss: 0.0001860 (Best: 0.0001321 @iter18004) ([92m↓5.17%[0m) [0.07% of initial]
[Iter 16410/20000] Loss: 0.0003007 (Best: 0.0002128 @iter15940) ([92m↓3.37%[0m) [0.12% of initial]
[Iter 18260/20000] Loss: 0.0001730 (Best: 0.0001321 @iter18004) ([92m↓6.99%[0m) [0.07% of initial]
[Iter 16420/20000] Loss: 0.0002839 (Best: 0.0002128 @iter15940) ([92m↓5.58%[0m) [0.11% of initial]
[Iter 18270/20000] Loss: 0.0001666 (Best: 0.0001321 @iter18004) ([92m↓3.68%[0m) [0.07% of initial]
[Iter 16430/20000] Loss: 0.0002813 (Best: 0.0002128 @iter15940) ([92m↓0.94%[0m) [0.11% of initial]
[Iter 16440/20000] Loss: 0.0002815 (Best: 0.0002128 @iter15940) ([91m↑0.07%[0m) [0.11% of initial]
[Iter 18280/20000] Loss: 0.0001715 (Best: 0.0001321 @iter18004) ([91m↑2.96%[0m) [0.07% of initial]
[Iter 16450/20000] Loss: 0.0002812 (Best: 0.0002128 @iter15940) ([92m↓0.11%[0m) [0.11% of initial]
[Iter 18290/20000] Loss: 0.0002060 (Best: 0.0001321 @iter18004) ([91m↑20.10%[0m) [0.08% of initial]
[Iter 16460/20000] Loss: 0.0002807 (Best: 0.0002128 @iter15940) ([92m↓0.15%[0m) [0.11% of initial]
Iter:18299, L1 loss=0.0002559, Total loss=0.0002122, Time:188
[Iter 18300/20000] Loss: 0.0002020 (Best: 0.0001321 @iter18004) ([92m↓1.97%[0m) [0.08% of initial]
[Iter 16470/20000] Loss: 0.0002973 (Best: 0.0002128 @iter15940) ([91m↑5.92%[0m) [0.12% of initial]
[Iter 18310/20000] Loss: 0.0002056 (Best: 0.0001321 @iter18004) ([91m↑1.78%[0m) [0.08% of initial]
[Iter 16480/20000] Loss: 0.0002867 (Best: 0.0002128 @iter15940) ([92m↓3.56%[0m) [0.11% of initial]
[Iter 18320/20000] Loss: 0.0002158 (Best: 0.0001321 @iter18004) ([91m↑4.97%[0m) [0.09% of initial]
[Iter 16490/20000] Loss: 0.0002860 (Best: 0.0002128 @iter15940) ([92m↓0.26%[0m) [0.11% of initial]
[Iter 18330/20000] Loss: 0.0002515 (Best: 0.0001321 @iter18004) ([91m↑16.55%[0m) [0.10% of initial]
Iter:16499, L1 loss=0.0003482, Total loss=0.0002925, Time:122
[Iter 16500/20000] Loss: 0.0003311 (Best: 0.0002128 @iter15940) ([91m↑15.78%[0m) [0.13% of initial]
[Iter 18340/20000] Loss: 0.0002614 (Best: 0.0001321 @iter18004) ([91m↑3.93%[0m) [0.10% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 16500
Pruning 8 points (0.0%) from gaussian1 at iteration 16500
[Iter 18350/20000] Loss: 0.0002399 (Best: 0.0001321 @iter18004) ([92m↓8.21%[0m) [0.10% of initial]
[Iter 16510/20000] Loss: 0.0005434 (Best: 0.0002128 @iter15940) ([91m↑64.11%[0m) [0.22% of initial]
[Iter 18360/20000] Loss: 0.0003042 (Best: 0.0001321 @iter18004) ([91m↑26.78%[0m) [0.12% of initial]
[Iter 16520/20000] Loss: 0.0004155 (Best: 0.0002128 @iter15940) ([92m↓23.54%[0m) [0.17% of initial]
[Iter 18370/20000] Loss: 0.0002105 (Best: 0.0001321 @iter18004) ([92m↓30.79%[0m) [0.08% of initial]
[Iter 16530/20000] Loss: 0.0003394 (Best: 0.0002128 @iter15940) ([92m↓18.30%[0m) [0.13% of initial]
[Iter 16540/20000] Loss: 0.0003172 (Best: 0.0002128 @iter15940) ([92m↓6.56%[0m) [0.13% of initial]
[Iter 18380/20000] Loss: 0.0001758 (Best: 0.0001321 @iter18004) ([92m↓16.51%[0m) [0.07% of initial]
[Iter 16550/20000] Loss: 0.0002880 (Best: 0.0002128 @iter15940) ([92m↓9.20%[0m) [0.11% of initial]
[Iter 18390/20000] Loss: 0.0001784 (Best: 0.0001321 @iter18004) ([91m↑1.53%[0m) [0.07% of initial]
[Iter 16560/20000] Loss: 0.0002837 (Best: 0.0002128 @iter15940) ([92m↓1.47%[0m) [0.11% of initial]
Iter:18399, L1 loss=0.0001882, Total loss=0.0001543, Time:180
[Iter 18400/20000] Loss: 0.0001508 (Best: 0.0001321 @iter18004) ([92m↓15.50%[0m) [0.06% of initial]
[Iter 16570/20000] Loss: 0.0002731 (Best: 0.0002128 @iter15940) ([92m↓3.74%[0m) [0.11% of initial]
[Iter 18410/20000] Loss: 0.0001715 (Best: 0.0001321 @iter18004) ([91m↑13.77%[0m) [0.07% of initial]
[Iter 16580/20000] Loss: 0.0002815 (Best: 0.0002128 @iter15940) ([91m↑3.06%[0m) [0.11% of initial]
[Iter 18420/20000] Loss: 0.0001524 (Best: 0.0001321 @iter18004) ([92m↓11.16%[0m) [0.06% of initial]
[Iter 16590/20000] Loss: 0.0002905 (Best: 0.0002128 @iter15940) ([91m↑3.18%[0m) [0.12% of initial]
[Iter 18430/20000] Loss: 0.0001515 (Best: 0.0001321 @iter18004) ([92m↓0.60%[0m) [0.06% of initial]
Iter:16599, L1 loss=0.000333, Total loss=0.0002904, Time:157
[Iter 16600/20000] Loss: 0.0002797 (Best: 0.0002128 @iter15940) ([92m↓3.71%[0m) [0.11% of initial]
[Iter 18440/20000] Loss: 0.0001750 (Best: 0.0001321 @iter18004) ([91m↑15.55%[0m) [0.07% of initial]
[Iter 16610/20000] Loss: 0.0002794 (Best: 0.0002128 @iter15940) ([92m↓0.09%[0m) [0.11% of initial]
[Iter 18450/20000] Loss: 0.0001658 (Best: 0.0001321 @iter18004) ([92m↓5.25%[0m) [0.07% of initial]
[Iter 16620/20000] Loss: 0.0002893 (Best: 0.0002128 @iter15940) ([91m↑3.54%[0m) [0.11% of initial]
[Iter 16630/20000] Loss: 0.0003098 (Best: 0.0002128 @iter15940) ([91m↑7.06%[0m) [0.12% of initial]
[Iter 18460/20000] Loss: 0.0001775 (Best: 0.0001321 @iter18004) ([91m↑7.04%[0m) [0.07% of initial]
[Iter 16640/20000] Loss: 0.0003421 (Best: 0.0002128 @iter15940) ([91m↑10.45%[0m) [0.14% of initial]
[Iter 18470/20000] Loss: 0.0001726 (Best: 0.0001321 @iter18004) ([92m↓2.79%[0m) [0.07% of initial]
[Iter 16650/20000] Loss: 0.0003710 (Best: 0.0002128 @iter15940) ([91m↑8.44%[0m) [0.15% of initial]
[Iter 18480/20000] Loss: 0.0001564 (Best: 0.0001321 @iter18004) ([92m↓9.39%[0m) [0.06% of initial]
[Iter 16660/20000] Loss: 0.0004143 (Best: 0.0002128 @iter15940) ([91m↑11.66%[0m) [0.16% of initial]
[Iter 18490/20000] Loss: 0.0001721 (Best: 0.0001321 @iter18004) ([91m↑10.05%[0m) [0.07% of initial]
[Iter 16670/20000] Loss: 0.0003726 (Best: 0.0002128 @iter15940) ([92m↓10.06%[0m) [0.15% of initial]
Iter:18499, L1 loss=0.0002008, Total loss=0.0001691, Time:190
[Iter 18500/20000] Loss: 0.0001640 (Best: 0.0001321 @iter18004) ([92m↓4.67%[0m) [0.07% of initial]
[Iter 16680/20000] Loss: 0.0003220 (Best: 0.0002128 @iter15940) ([92m↓13.58%[0m) [0.13% of initial]
[Iter 18510/20000] Loss: 0.0002019 (Best: 0.0001321 @iter18004) ([91m↑23.07%[0m) [0.08% of initial]
[Iter 16690/20000] Loss: 0.0002947 (Best: 0.0002128 @iter15940) ([92m↓8.49%[0m) [0.12% of initial]
[Iter 18520/20000] Loss: 0.0001653 (Best: 0.0001321 @iter18004) ([92m↓18.13%[0m) [0.07% of initial]
Iter:16699, L1 loss=0.0003413, Total loss=0.0003009, Time:169
[Iter 16700/20000] Loss: 0.0002946 (Best: 0.0002128 @iter15940) ([92m↓0.01%[0m) [0.12% of initial]
[Iter 18530/20000] Loss: 0.0002631 (Best: 0.0001321 @iter18004) ([91m↑59.17%[0m) [0.10% of initial]
[Iter 16710/20000] Loss: 0.0002932 (Best: 0.0002128 @iter15940) ([92m↓0.48%[0m) [0.12% of initial]
[Iter 16720/20000] Loss: 0.0003066 (Best: 0.0002128 @iter15940) ([91m↑4.56%[0m) [0.12% of initial]
[Iter 18540/20000] Loss: 0.0001983 (Best: 0.0001321 @iter18004) ([92m↓24.61%[0m) [0.08% of initial]
[Iter 16730/20000] Loss: 0.0002851 (Best: 0.0002128 @iter15940) ([92m↓7.02%[0m) [0.11% of initial]
[Iter 18550/20000] Loss: 0.0001964 (Best: 0.0001321 @iter18004) ([92m↓0.97%[0m) [0.08% of initial]
[Iter 16740/20000] Loss: 0.0003054 (Best: 0.0002128 @iter15940) ([91m↑7.14%[0m) [0.12% of initial]
[Iter 18560/20000] Loss: 0.0002054 (Best: 0.0001321 @iter18004) ([91m↑4.60%[0m) [0.08% of initial]
[Iter 16750/20000] Loss: 0.0002916 (Best: 0.0002128 @iter15940) ([92m↓4.53%[0m) [0.12% of initial]
[Iter 18570/20000] Loss: 0.0002195 (Best: 0.0001321 @iter18004) ([91m↑6.83%[0m) [0.09% of initial]
[Iter 16760/20000] Loss: 0.0002920 (Best: 0.0002128 @iter15940) ([91m↑0.14%[0m) [0.12% of initial]
[Iter 18580/20000] Loss: 0.0001849 (Best: 0.0001321 @iter18004) ([92m↓15.76%[0m) [0.07% of initial]
[Iter 16770/20000] Loss: 0.0002917 (Best: 0.0002128 @iter15940) ([92m↓0.09%[0m) [0.12% of initial]
[Iter 18590/20000] Loss: 0.0001712 (Best: 0.0001321 @iter18004) ([92m↓7.41%[0m) [0.07% of initial]
[Iter 16780/20000] Loss: 0.0002965 (Best: 0.0002128 @iter15940) ([91m↑1.64%[0m) [0.12% of initial]
Iter:18599, L1 loss=0.0002541, Total loss=0.0001691, Time:184
[Iter 18600/20000] Loss: 0.0001850 (Best: 0.0001321 @iter18004) ([91m↑8.09%[0m) [0.07% of initial]
[Iter 16790/20000] Loss: 0.0003091 (Best: 0.0002128 @iter15940) ([91m↑4.27%[0m) [0.12% of initial]
[Iter 18610/20000] Loss: 0.0001765 (Best: 0.0001321 @iter18004) ([92m↓4.62%[0m) [0.07% of initial]
Iter:16799, L1 loss=0.0003493, Total loss=0.0003125, Time:112
[Iter 16800/20000] Loss: 0.0003008 (Best: 0.0002128 @iter15940) ([92m↓2.69%[0m) [0.12% of initial]
[Iter 18620/20000] Loss: 0.0001625 (Best: 0.0001321 @iter18004) ([92m↓7.89%[0m) [0.06% of initial]
[Iter 16810/20000] Loss: 0.0003250 (Best: 0.0002128 @iter15940) ([91m↑8.02%[0m) [0.13% of initial]
[Iter 16820/20000] Loss: 0.0003001 (Best: 0.0002128 @iter15940) ([92m↓7.66%[0m) [0.12% of initial]
[Iter 18630/20000] Loss: 0.0002237 (Best: 0.0001321 @iter18004) ([91m↑37.63%[0m) [0.09% of initial]
[Iter 16830/20000] Loss: 0.0003017 (Best: 0.0002128 @iter15940) ([91m↑0.55%[0m) [0.12% of initial]
[Iter 18640/20000] Loss: 0.0001859 (Best: 0.0001321 @iter18004) ([92m↓16.92%[0m) [0.07% of initial]
[Iter 16840/20000] Loss: 0.0003659 (Best: 0.0002128 @iter15940) ([91m↑21.28%[0m) [0.15% of initial]
[Iter 18650/20000] Loss: 0.0001656 (Best: 0.0001321 @iter18004) ([92m↓10.92%[0m) [0.07% of initial]
[Iter 16850/20000] Loss: 0.0003315 (Best: 0.0002128 @iter15940) ([92m↓9.40%[0m) [0.13% of initial]
[Iter 18660/20000] Loss: 0.0001611 (Best: 0.0001321 @iter18004) ([92m↓2.70%[0m) [0.06% of initial]
[Iter 16860/20000] Loss: 0.0003111 (Best: 0.0002128 @iter15940) ([92m↓6.15%[0m) [0.12% of initial]
[Iter 18670/20000] Loss: 0.0001478 (Best: 0.0001321 @iter18004) ([92m↓8.25%[0m) [0.06% of initial]
[Iter 16870/20000] Loss: 0.0002902 (Best: 0.0002128 @iter15940) ([92m↓6.73%[0m) [0.12% of initial]
[Iter 18680/20000] Loss: 0.0001497 (Best: 0.0001321 @iter18004) ([91m↑1.25%[0m) [0.06% of initial]
[Iter 16880/20000] Loss: 0.0004560 (Best: 0.0002128 @iter15940) ([91m↑57.12%[0m) [0.18% of initial]
[Iter 18690/20000] Loss: 0.0001497 (Best: 0.0001290 @iter18688) ([91m↑0.00%[0m) [0.06% of initial]
[Iter 16890/20000] Loss: 0.0003207 (Best: 0.0002128 @iter15940) ([92m↓29.66%[0m) [0.13% of initial]
Iter:18699, L1 loss=0.0001826, Total loss=0.0001454, Time:137
[Iter 18700/20000] Loss: 0.0001420 (Best: 0.0001290 @iter18688) ([92m↓5.10%[0m) [0.06% of initial]
Iter:16899, L1 loss=0.0003792, Total loss=0.0003254, Time:125
[Iter 16900/20000] Loss: 0.0002977 (Best: 0.0002128 @iter15940) ([92m↓7.18%[0m) [0.12% of initial]
[Iter 18710/20000] Loss: 0.0001484 (Best: 0.0001290 @iter18688) ([91m↑4.46%[0m) [0.06% of initial]
[Iter 16910/20000] Loss: 0.0002893 (Best: 0.0002128 @iter15940) ([92m↓2.82%[0m) [0.11% of initial]
[Iter 16920/20000] Loss: 0.0003270 (Best: 0.0002128 @iter15940) ([91m↑13.05%[0m) [0.13% of initial]
[Iter 18720/20000] Loss: 0.0001443 (Best: 0.0001290 @iter18688) ([92m↓2.73%[0m) [0.06% of initial]
[Iter 16930/20000] Loss: 0.0002995 (Best: 0.0002128 @iter15940) ([92m↓8.41%[0m) [0.12% of initial]
[Iter 18730/20000] Loss: 0.0001510 (Best: 0.0001290 @iter18688) ([91m↑4.62%[0m) [0.06% of initial]
[Iter 16940/20000] Loss: 0.0003474 (Best: 0.0002128 @iter15940) ([91m↑15.97%[0m) [0.14% of initial]
[Iter 18740/20000] Loss: 0.0001615 (Best: 0.0001290 @iter18688) ([91m↑7.00%[0m) [0.06% of initial]
[Iter 16950/20000] Loss: 0.0003243 (Best: 0.0002128 @iter15940) ([92m↓6.63%[0m) [0.13% of initial]
[Iter 18750/20000] Loss: 0.0001486 (Best: 0.0001290 @iter18688) ([92m↓8.00%[0m) [0.06% of initial]
[Iter 16960/20000] Loss: 0.0003105 (Best: 0.0002128 @iter15940) ([92m↓4.26%[0m) [0.12% of initial]
[Iter 18760/20000] Loss: 0.0001515 (Best: 0.0001290 @iter18688) ([91m↑1.91%[0m) [0.06% of initial]
[Iter 16970/20000] Loss: 0.0003032 (Best: 0.0002128 @iter15940) ([92m↓2.35%[0m) [0.12% of initial]
[Iter 18770/20000] Loss: 0.0001671 (Best: 0.0001290 @iter18688) ([91m↑10.35%[0m) [0.07% of initial]
[Iter 16980/20000] Loss: 0.0002888 (Best: 0.0002128 @iter15940) ([92m↓4.77%[0m) [0.11% of initial]
[Iter 18780/20000] Loss: 0.0001604 (Best: 0.0001290 @iter18688) ([92m↓4.01%[0m) [0.06% of initial]
[Iter 16990/20000] Loss: 0.0003072 (Best: 0.0002128 @iter15940) ([91m↑6.38%[0m) [0.12% of initial]
Iter:16999, L1 loss=0.0003368, Total loss=0.0002979, Time:114
[Iter 18790/20000] Loss: 0.0001632 (Best: 0.0001290 @iter18688) ([91m↑1.73%[0m) [0.06% of initial]
[Iter 17000/20000] Loss: 0.0002944 (Best: 0.0002128 @iter15940) ([92m↓4.16%[0m) [0.12% of initial]
Iter:18799, L1 loss=0.0001814, Total loss=0.0001386, Time:105
[Iter 18800/20000] Loss: 0.0001541 (Best: 0.0001290 @iter18688) ([92m↓5.59%[0m) [0.06% of initial]
Pruning 6 points (0.0%) from gaussian0 at iteration 17000
Pruning 4 points (0.0%) from gaussian1 at iteration 17000
[Iter 18810/20000] Loss: 0.0001576 (Best: 0.0001290 @iter18688) ([91m↑2.25%[0m) [0.06% of initial]
[Iter 17010/20000] Loss: 0.0005589 (Best: 0.0002128 @iter15940) ([91m↑89.82%[0m) [0.22% of initial]
[Iter 18820/20000] Loss: 0.0001712 (Best: 0.0001290 @iter18688) ([91m↑8.68%[0m) [0.07% of initial]
[Iter 17020/20000] Loss: 0.0003934 (Best: 0.0002128 @iter15940) ([92m↓29.60%[0m) [0.16% of initial]
[Iter 17030/20000] Loss: 0.0003341 (Best: 0.0002128 @iter15940) ([92m↓15.07%[0m) [0.13% of initial]
[Iter 18830/20000] Loss: 0.0001855 (Best: 0.0001290 @iter18688) ([91m↑8.31%[0m) [0.07% of initial]
[Iter 17040/20000] Loss: 0.0002992 (Best: 0.0002128 @iter15940) ([92m↓10.46%[0m) [0.12% of initial]
[Iter 18840/20000] Loss: 0.0001645 (Best: 0.0001290 @iter18688) ([92m↓11.32%[0m) [0.07% of initial]
[Iter 17050/20000] Loss: 0.0002931 (Best: 0.0002128 @iter15940) ([92m↓2.03%[0m) [0.12% of initial]
[Iter 18850/20000] Loss: 0.0001664 (Best: 0.0001290 @iter18688) ([91m↑1.16%[0m) [0.07% of initial]
[Iter 17060/20000] Loss: 0.0003216 (Best: 0.0002128 @iter15940) ([91m↑9.72%[0m) [0.13% of initial]
[Iter 18860/20000] Loss: 0.0001896 (Best: 0.0001290 @iter18688) ([91m↑13.95%[0m) [0.08% of initial]
[Iter 17070/20000] Loss: 0.0003097 (Best: 0.0002128 @iter15940) ([92m↓3.71%[0m) [0.12% of initial]
[Iter 18870/20000] Loss: 0.0001586 (Best: 0.0001290 @iter18688) ([92m↓16.34%[0m) [0.06% of initial]
[Iter 17080/20000] Loss: 0.0002770 (Best: 0.0002128 @iter15940) ([92m↓10.55%[0m) [0.11% of initial]
[Iter 18880/20000] Loss: 0.0001546 (Best: 0.0001290 @iter18688) ([92m↓2.54%[0m) [0.06% of initial]
[Iter 17090/20000] Loss: 0.0002675 (Best: 0.0002128 @iter15940) ([92m↓3.42%[0m) [0.11% of initial]
[Iter 18890/20000] Loss: 0.0001742 (Best: 0.0001290 @iter18688) ([91m↑12.73%[0m) [0.07% of initial]
Iter:17099, L1 loss=0.0002952, Total loss=0.0002499, Time:120
[Iter 17100/20000] Loss: 0.0002632 (Best: 0.0002128 @iter15940) ([92m↓1.63%[0m) [0.10% of initial]
Iter:18899, L1 loss=0.0001994, Total loss=0.0001677, Time:133
[Iter 18900/20000] Loss: 0.0001664 (Best: 0.0001290 @iter18688) ([92m↓4.50%[0m) [0.07% of initial]
[Iter 17110/20000] Loss: 0.0002776 (Best: 0.0002128 @iter15940) ([91m↑5.46%[0m) [0.11% of initial]
[Iter 17120/20000] Loss: 0.0002665 (Best: 0.0002128 @iter15940) ([92m↓3.99%[0m) [0.11% of initial]
[Iter 18910/20000] Loss: 0.0001717 (Best: 0.0001290 @iter18688) ([91m↑3.20%[0m) [0.07% of initial]
[Iter 17130/20000] Loss: 0.0002686 (Best: 0.0002128 @iter15940) ([91m↑0.78%[0m) [0.11% of initial]
[Iter 18920/20000] Loss: 0.0001492 (Best: 0.0001290 @iter18688) ([92m↓13.10%[0m) [0.06% of initial]
[Iter 17140/20000] Loss: 0.0002803 (Best: 0.0002128 @iter15940) ([91m↑4.38%[0m) [0.11% of initial]
[Iter 18930/20000] Loss: 0.0001848 (Best: 0.0001290 @iter18688) ([91m↑23.82%[0m) [0.07% of initial]
[Iter 17150/20000] Loss: 0.0002795 (Best: 0.0002128 @iter15940) ([92m↓0.29%[0m) [0.11% of initial]
[Iter 18940/20000] Loss: 0.0001576 (Best: 0.0001290 @iter18688) ([92m↓14.71%[0m) [0.06% of initial]
[Iter 17160/20000] Loss: 0.0002934 (Best: 0.0002128 @iter15940) ([91m↑4.95%[0m) [0.12% of initial]
[Iter 18950/20000] Loss: 0.0001704 (Best: 0.0001290 @iter18688) ([91m↑8.10%[0m) [0.07% of initial]
[Iter 17170/20000] Loss: 0.0003188 (Best: 0.0002128 @iter15940) ([91m↑8.66%[0m) [0.13% of initial]
[Iter 18960/20000] Loss: 0.0001774 (Best: 0.0001290 @iter18688) ([91m↑4.16%[0m) [0.07% of initial]
[Iter 17180/20000] Loss: 0.0002933 (Best: 0.0002128 @iter15940) ([92m↓7.98%[0m) [0.12% of initial]
[Iter 18970/20000] Loss: 0.0001778 (Best: 0.0001290 @iter18688) ([91m↑0.23%[0m) [0.07% of initial]
[Iter 17190/20000] Loss: 0.0002918 (Best: 0.0002128 @iter15940) ([92m↓0.50%[0m) [0.12% of initial]
Iter:17199, L1 loss=0.0003084, Total loss=0.0002671, Time:107
[Iter 18980/20000] Loss: 0.0001508 (Best: 0.0001290 @iter18688) ([92m↓15.22%[0m) [0.06% of initial]
[Iter 17200/20000] Loss: 0.0002735 (Best: 0.0002128 @iter15940) ([92m↓6.28%[0m) [0.11% of initial]
[Iter 17210/20000] Loss: 0.0002802 (Best: 0.0002128 @iter15940) ([91m↑2.46%[0m) [0.11% of initial]
[Iter 18990/20000] Loss: 0.0001459 (Best: 0.0001290 @iter18688) ([92m↓3.22%[0m) [0.06% of initial]
[Iter 17220/20000] Loss: 0.0002703 (Best: 0.0002128 @iter15940) ([92m↓3.55%[0m) [0.11% of initial]
Iter:18999, L1 loss=0.0001695, Total loss=0.0001392, Time:111
[Iter 19000/20000] Loss: 0.0001376 (Best: 0.0001290 @iter18688) ([92m↓5.68%[0m) [0.05% of initial]
[Iter 17230/20000] Loss: 0.0002670 (Best: 0.0002128 @iter15940) ([92m↓1.21%[0m) [0.11% of initial]
[Iter 19010/20000] Loss: 0.0001523 (Best: 0.0001290 @iter18688) ([91m↑10.65%[0m) [0.06% of initial]
[Iter 17240/20000] Loss: 0.0003061 (Best: 0.0002128 @iter15940) ([91m↑14.61%[0m) [0.12% of initial]
[Iter 19020/20000] Loss: 0.0001671 (Best: 0.0001290 @iter18688) ([91m↑9.72%[0m) [0.07% of initial]
[Iter 17250/20000] Loss: 0.0003146 (Best: 0.0002128 @iter15940) ([91m↑2.79%[0m) [0.12% of initial]
[Iter 19030/20000] Loss: 0.0001632 (Best: 0.0001290 @iter18688) ([92m↓2.35%[0m) [0.06% of initial]
[Iter 17260/20000] Loss: 0.0002956 (Best: 0.0002128 @iter15940) ([92m↓6.03%[0m) [0.12% of initial]
[Iter 19040/20000] Loss: 0.0001475 (Best: 0.0001290 @iter18688) ([92m↓9.64%[0m) [0.06% of initial]
[Iter 17270/20000] Loss: 0.0003072 (Best: 0.0002128 @iter15940) ([91m↑3.89%[0m) [0.12% of initial]
[Iter 19050/20000] Loss: 0.0001646 (Best: 0.0001290 @iter18688) ([91m↑11.65%[0m) [0.07% of initial]
[Iter 17280/20000] Loss: 0.0003030 (Best: 0.0002128 @iter15940) ([92m↓1.34%[0m) [0.12% of initial]
[Iter 19060/20000] Loss: 0.0001618 (Best: 0.0001290 @iter18688) ([92m↓1.75%[0m) [0.06% of initial]
[Iter 17290/20000] Loss: 0.0003852 (Best: 0.0002128 @iter15940) ([91m↑27.11%[0m) [0.15% of initial]
Iter:17299, L1 loss=0.0003486, Total loss=0.0003012, Time:103
[Iter 17300/20000] Loss: 0.0003178 (Best: 0.0002128 @iter15940) ([92m↓17.50%[0m) [0.13% of initial]
[Iter 19070/20000] Loss: 0.0001888 (Best: 0.0001290 @iter18688) ([91m↑16.75%[0m) [0.08% of initial]
[Iter 17310/20000] Loss: 0.0003025 (Best: 0.0002128 @iter15940) ([92m↓4.81%[0m) [0.12% of initial]
[Iter 19080/20000] Loss: 0.0001635 (Best: 0.0001290 @iter18688) ([92m↓13.41%[0m) [0.06% of initial]
[Iter 17320/20000] Loss: 0.0003120 (Best: 0.0002128 @iter15940) ([91m↑3.14%[0m) [0.12% of initial]
[Iter 19090/20000] Loss: 0.0001631 (Best: 0.0001290 @iter18688) ([92m↓0.28%[0m) [0.06% of initial]
[Iter 17330/20000] Loss: 0.0002796 (Best: 0.0002128 @iter15940) ([92m↓10.38%[0m) [0.11% of initial]
Iter:19099, L1 loss=0.0002016, Total loss=0.000162, Time:118
[Iter 19100/20000] Loss: 0.0001992 (Best: 0.0001290 @iter18688) ([91m↑22.16%[0m) [0.08% of initial]
[Iter 17340/20000] Loss: 0.0002697 (Best: 0.0002128 @iter15940) ([92m↓3.54%[0m) [0.11% of initial]
[Iter 19110/20000] Loss: 0.0002034 (Best: 0.0001290 @iter18688) ([91m↑2.12%[0m) [0.08% of initial]
[Iter 17350/20000] Loss: 0.0002964 (Best: 0.0002128 @iter15940) ([91m↑9.88%[0m) [0.12% of initial]
[Iter 19120/20000] Loss: 0.0001714 (Best: 0.0001290 @iter18688) ([92m↓15.74%[0m) [0.07% of initial]
[Iter 17360/20000] Loss: 0.0003167 (Best: 0.0002128 @iter15940) ([91m↑6.87%[0m) [0.13% of initial]
[Iter 19130/20000] Loss: 0.0001628 (Best: 0.0001290 @iter18688) ([92m↓5.03%[0m) [0.06% of initial]
[Iter 17370/20000] Loss: 0.0002838 (Best: 0.0002128 @iter15940) ([92m↓10.39%[0m) [0.11% of initial]
[Iter 17380/20000] Loss: 0.0003228 (Best: 0.0002128 @iter15940) ([91m↑13.76%[0m) [0.13% of initial]
[Iter 19140/20000] Loss: 0.0001887 (Best: 0.0001290 @iter18688) ([91m↑15.90%[0m) [0.07% of initial]
[Iter 17390/20000] Loss: 0.0003054 (Best: 0.0002128 @iter15940) ([92m↓5.39%[0m) [0.12% of initial]
[Iter 19150/20000] Loss: 0.0001664 (Best: 0.0001290 @iter18688) ([92m↓11.78%[0m) [0.07% of initial]
Iter:17399, L1 loss=0.0003067, Total loss=0.0002725, Time:102
[Iter 17400/20000] Loss: 0.0002901 (Best: 0.0002128 @iter15940) ([92m↓5.00%[0m) [0.12% of initial]
[Iter 19160/20000] Loss: 0.0001760 (Best: 0.0001290 @iter18688) ([91m↑5.78%[0m) [0.07% of initial]
[Iter 17410/20000] Loss: 0.0002850 (Best: 0.0002128 @iter15940) ([92m↓1.76%[0m) [0.11% of initial]
[Iter 19170/20000] Loss: 0.0001627 (Best: 0.0001290 @iter18688) ([92m↓7.59%[0m) [0.06% of initial]
[Iter 17420/20000] Loss: 0.0002995 (Best: 0.0002128 @iter15940) ([91m↑5.07%[0m) [0.12% of initial]
[Iter 19180/20000] Loss: 0.0001579 (Best: 0.0001290 @iter18688) ([92m↓2.97%[0m) [0.06% of initial]
[Iter 17430/20000] Loss: 0.0002975 (Best: 0.0002128 @iter15940) ([92m↓0.66%[0m) [0.12% of initial]
[Iter 19190/20000] Loss: 0.0001808 (Best: 0.0001290 @iter18688) ([91m↑14.54%[0m) [0.07% of initial]
[Iter 17440/20000] Loss: 0.0002750 (Best: 0.0002128 @iter15940) ([92m↓7.57%[0m) [0.11% of initial]
Iter:19199, L1 loss=0.000238, Total loss=0.0002063, Time:129
[Iter 19200/20000] Loss: 0.0001886 (Best: 0.0001290 @iter18688) ([91m↑4.29%[0m) [0.07% of initial]
[Iter 17450/20000] Loss: 0.0002793 (Best: 0.0002128 @iter15940) ([91m↑1.58%[0m) [0.11% of initial]
[Iter 19210/20000] Loss: 0.0001653 (Best: 0.0001290 @iter18688) ([92m↓12.33%[0m) [0.07% of initial]
[Iter 17460/20000] Loss: 0.0003256 (Best: 0.0002128 @iter15940) ([91m↑16.55%[0m) [0.13% of initial]
[Iter 17470/20000] Loss: 0.0002958 (Best: 0.0002128 @iter15940) ([92m↓9.15%[0m) [0.12% of initial]
[Iter 19220/20000] Loss: 0.0003507 (Best: 0.0001290 @iter18688) ([91m↑112.17%[0m) [0.14% of initial]
[Iter 17480/20000] Loss: 0.0002977 (Best: 0.0002128 @iter15940) ([91m↑0.64%[0m) [0.12% of initial]
[Iter 19230/20000] Loss: 0.0001620 (Best: 0.0001290 @iter18688) ([92m↓53.81%[0m) [0.06% of initial]
[Iter 17490/20000] Loss: 0.0002924 (Best: 0.0002128 @iter15940) ([92m↓1.79%[0m) [0.12% of initial]
[Iter 19240/20000] Loss: 0.0001496 (Best: 0.0001290 @iter18688) ([92m↓7.63%[0m) [0.06% of initial]
Iter:17499, L1 loss=0.0003266, Total loss=0.0002729, Time:113
[Iter 17500/20000] Loss: 0.0002639 (Best: 0.0002128 @iter15940) ([92m↓9.72%[0m) [0.10% of initial]
[Iter 19250/20000] Loss: 0.0001566 (Best: 0.0001290 @iter18688) ([91m↑4.67%[0m) [0.06% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 17500
Pruning 4 points (0.0%) from gaussian1 at iteration 17500
[Iter 19260/20000] Loss: 0.0001534 (Best: 0.0001290 @iter18688) ([92m↓2.04%[0m) [0.06% of initial]
[Iter 17510/20000] Loss: 0.0005680 (Best: 0.0002128 @iter15940) ([91m↑115.19%[0m) [0.23% of initial]
[Iter 19270/20000] Loss: 0.0001620 (Best: 0.0001290 @iter18688) ([91m↑5.60%[0m) [0.06% of initial]
[Iter 17520/20000] Loss: 0.0003855 (Best: 0.0002128 @iter15940) ([92m↓32.13%[0m) [0.15% of initial]
[Iter 19280/20000] Loss: 0.0001551 (Best: 0.0001290 @iter18688) ([92m↓4.28%[0m) [0.06% of initial]
[Iter 17530/20000] Loss: 0.0002953 (Best: 0.0002128 @iter15940) ([92m↓23.38%[0m) [0.12% of initial]
[Iter 19290/20000] Loss: 0.0001511 (Best: 0.0001290 @iter18688) ([92m↓2.60%[0m) [0.06% of initial]
[Iter 17540/20000] Loss: 0.0002706 (Best: 0.0002128 @iter15940) ([92m↓8.38%[0m) [0.11% of initial]
Iter:19299, L1 loss=0.0001763, Total loss=0.0001475, Time:129
[Iter 19300/20000] Loss: 0.0001502 (Best: 0.0001290 @iter18688) ([92m↓0.58%[0m) [0.06% of initial]
[Iter 17550/20000] Loss: 0.0002601 (Best: 0.0002128 @iter15940) ([92m↓3.87%[0m) [0.10% of initial]
[Iter 19310/20000] Loss: 0.0001657 (Best: 0.0001290 @iter18688) ([91m↑10.36%[0m) [0.07% of initial]
[Iter 17560/20000] Loss: 0.0002529 (Best: 0.0002128 @iter15940) ([92m↓2.76%[0m) [0.10% of initial]
[Iter 17570/20000] Loss: 0.0002657 (Best: 0.0002128 @iter15940) ([91m↑5.04%[0m) [0.11% of initial]
[Iter 19320/20000] Loss: 0.0001601 (Best: 0.0001290 @iter18688) ([92m↓3.43%[0m) [0.06% of initial]
[Iter 17580/20000] Loss: 0.0002584 (Best: 0.0002128 @iter15940) ([92m↓2.73%[0m) [0.10% of initial]
[Iter 19330/20000] Loss: 0.0001721 (Best: 0.0001290 @iter18688) ([91m↑7.51%[0m) [0.07% of initial]
[Iter 17590/20000] Loss: 0.0002594 (Best: 0.0002128 @iter15940) ([91m↑0.36%[0m) [0.10% of initial]
[Iter 19340/20000] Loss: 0.0002212 (Best: 0.0001290 @iter18688) ([91m↑28.53%[0m) [0.09% of initial]
Iter:17599, L1 loss=0.0002891, Total loss=0.0002551, Time:120
[Iter 17600/20000] Loss: 0.0002770 (Best: 0.0002128 @iter15940) ([91m↑6.81%[0m) [0.11% of initial]
[Iter 19350/20000] Loss: 0.0002727 (Best: 0.0001290 @iter18688) ([91m↑23.31%[0m) [0.11% of initial]
[Iter 17610/20000] Loss: 0.0002744 (Best: 0.0002128 @iter15940) ([92m↓0.94%[0m) [0.11% of initial]
[Iter 19360/20000] Loss: 0.0002482 (Best: 0.0001290 @iter18688) ([92m↓8.98%[0m) [0.10% of initial]
[Iter 17620/20000] Loss: 0.0002794 (Best: 0.0002128 @iter15940) ([91m↑1.82%[0m) [0.11% of initial]
[Iter 19370/20000] Loss: 0.0002193 (Best: 0.0001290 @iter18688) ([92m↓11.65%[0m) [0.09% of initial]
[Iter 17630/20000] Loss: 0.0002728 (Best: 0.0002128 @iter15940) ([92m↓2.37%[0m) [0.11% of initial]
[Iter 19380/20000] Loss: 0.0002317 (Best: 0.0001290 @iter18688) ([91m↑5.65%[0m) [0.09% of initial]
[Iter 17640/20000] Loss: 0.0002849 (Best: 0.0002128 @iter15940) ([91m↑4.44%[0m) [0.11% of initial]
[Iter 19390/20000] Loss: 0.0001741 (Best: 0.0001290 @iter18688) ([92m↓24.87%[0m) [0.07% of initial]
[Iter 17650/20000] Loss: 0.0002860 (Best: 0.0002128 @iter15940) ([91m↑0.38%[0m) [0.11% of initial]
Iter:19399, L1 loss=0.0001832, Total loss=0.0001535, Time:129
[Iter 17660/20000] Loss: 0.0002608 (Best: 0.0002128 @iter15940) ([92m↓8.82%[0m) [0.10% of initial]
[Iter 19400/20000] Loss: 0.0001649 (Best: 0.0001290 @iter18688) ([92m↓5.28%[0m) [0.07% of initial]
[Iter 17670/20000] Loss: 0.0002737 (Best: 0.0002128 @iter15940) ([91m↑4.94%[0m) [0.11% of initial]
[Iter 19410/20000] Loss: 0.0001470 (Best: 0.0001290 @iter18688) ([92m↓10.83%[0m) [0.06% of initial]
[Iter 17680/20000] Loss: 0.0002656 (Best: 0.0002128 @iter15940) ([92m↓2.97%[0m) [0.11% of initial]
[Iter 19420/20000] Loss: 0.0001437 (Best: 0.0001260 @iter19417) ([92m↓2.26%[0m) [0.06% of initial]
[Iter 17690/20000] Loss: 0.0002717 (Best: 0.0002128 @iter15940) ([91m↑2.32%[0m) [0.11% of initial]
[Iter 19430/20000] Loss: 0.0001412 (Best: 0.0001260 @iter19417) ([92m↓1.73%[0m) [0.06% of initial]
Iter:17699, L1 loss=0.0002907, Total loss=0.0002421, Time:110
[Iter 17700/20000] Loss: 0.0002608 (Best: 0.0002128 @iter15940) ([92m↓4.01%[0m) [0.10% of initial]
[Iter 19440/20000] Loss: 0.0001546 (Best: 0.0001260 @iter19417) ([91m↑9.44%[0m) [0.06% of initial]
[Iter 17710/20000] Loss: 0.0002655 (Best: 0.0002128 @iter15940) ([91m↑1.80%[0m) [0.11% of initial]
[Iter 19450/20000] Loss: 0.0001518 (Best: 0.0001260 @iter19417) ([92m↓1.80%[0m) [0.06% of initial]
[Iter 17720/20000] Loss: 0.0003444 (Best: 0.0002128 @iter15940) ([91m↑29.69%[0m) [0.14% of initial]
[Iter 19460/20000] Loss: 0.0002189 (Best: 0.0001260 @iter19417) ([91m↑44.20%[0m) [0.09% of initial]
[Iter 17730/20000] Loss: 0.0003221 (Best: 0.0002128 @iter15940) ([92m↓6.47%[0m) [0.13% of initial]
[Iter 19470/20000] Loss: 0.0002959 (Best: 0.0001260 @iter19417) ([91m↑35.20%[0m) [0.12% of initial]
[Iter 17740/20000] Loss: 0.0002938 (Best: 0.0002128 @iter15940) ([92m↓8.79%[0m) [0.12% of initial]
[Iter 17750/20000] Loss: 0.0002717 (Best: 0.0002128 @iter15940) ([92m↓7.53%[0m) [0.11% of initial]
[Iter 19480/20000] Loss: 0.0002885 (Best: 0.0001260 @iter19417) ([92m↓2.53%[0m) [0.11% of initial]
[Iter 17760/20000] Loss: 0.0002568 (Best: 0.0002128 @iter15940) ([92m↓5.46%[0m) [0.10% of initial]
[Iter 19490/20000] Loss: 0.0002557 (Best: 0.0001260 @iter19417) ([92m↓11.37%[0m) [0.10% of initial]
[Iter 17770/20000] Loss: 0.0002471 (Best: 0.0002128 @iter15940) ([92m↓3.76%[0m) [0.10% of initial]
Iter:19499, L1 loss=0.0002039, Total loss=0.0001868, Time:127
[Iter 19500/20000] Loss: 0.0002252 (Best: 0.0001260 @iter19417) ([92m↓11.90%[0m) [0.09% of initial]
[Iter 17780/20000] Loss: 0.0002526 (Best: 0.0002128 @iter15940) ([91m↑2.19%[0m) [0.10% of initial]
[Iter 19510/20000] Loss: 0.0001728 (Best: 0.0001260 @iter19417) ([92m↓23.28%[0m) [0.07% of initial]
[Iter 17790/20000] Loss: 0.0002862 (Best: 0.0002128 @iter15940) ([91m↑13.31%[0m) [0.11% of initial]
[Iter 19520/20000] Loss: 0.0001592 (Best: 0.0001260 @iter19417) ([92m↓7.91%[0m) [0.06% of initial]
Iter:17799, L1 loss=0.0004248, Total loss=0.0003626, Time:116
[Iter 17800/20000] Loss: 0.0003306 (Best: 0.0002128 @iter15940) ([91m↑15.52%[0m) [0.13% of initial]
[Iter 19530/20000] Loss: 0.0001737 (Best: 0.0001260 @iter19417) ([91m↑9.12%[0m) [0.07% of initial]
[Iter 17810/20000] Loss: 0.0003101 (Best: 0.0002128 @iter15940) ([92m↓6.19%[0m) [0.12% of initial]
[Iter 19540/20000] Loss: 0.0001498 (Best: 0.0001260 @iter19417) ([92m↓13.75%[0m) [0.06% of initial]
[Iter 17820/20000] Loss: 0.0002977 (Best: 0.0002128 @iter15940) ([92m↓4.00%[0m) [0.12% of initial]
[Iter 19550/20000] Loss: 0.0001670 (Best: 0.0001260 @iter19417) ([91m↑11.49%[0m) [0.07% of initial]
[Iter 17830/20000] Loss: 0.0002640 (Best: 0.0002128 @iter15940) ([92m↓11.32%[0m) [0.10% of initial]
[Iter 19560/20000] Loss: 0.0001671 (Best: 0.0001260 @iter19417) ([91m↑0.04%[0m) [0.07% of initial]
[Iter 17840/20000] Loss: 0.0002536 (Best: 0.0002128 @iter15940) ([92m↓3.96%[0m) [0.10% of initial]
[Iter 17850/20000] Loss: 0.0002541 (Best: 0.0002128 @iter15940) ([91m↑0.21%[0m) [0.10% of initial]
[Iter 19570/20000] Loss: 0.0001526 (Best: 0.0001260 @iter19417) ([92m↓8.64%[0m) [0.06% of initial]
[Iter 17860/20000] Loss: 0.0002513 (Best: 0.0002128 @iter15940) ([92m↓1.10%[0m) [0.10% of initial]
[Iter 19580/20000] Loss: 0.0001879 (Best: 0.0001260 @iter19417) ([91m↑23.08%[0m) [0.07% of initial]
[Iter 17870/20000] Loss: 0.0002689 (Best: 0.0002128 @iter15940) ([91m↑7.00%[0m) [0.11% of initial]
[Iter 19590/20000] Loss: 0.0001578 (Best: 0.0001260 @iter19417) ([92m↓15.98%[0m) [0.06% of initial]
[Iter 17880/20000] Loss: 0.0002755 (Best: 0.0002128 @iter15940) ([91m↑2.46%[0m) [0.11% of initial]
Iter:19599, L1 loss=0.0002018, Total loss=0.0001611, Time:139
[Iter 19600/20000] Loss: 0.0001518 (Best: 0.0001260 @iter19417) ([92m↓3.81%[0m) [0.06% of initial]
[Iter 17890/20000] Loss: 0.0002484 (Best: 0.0002128 @iter15940) ([92m↓9.85%[0m) [0.10% of initial]
[Iter 19610/20000] Loss: 0.0001489 (Best: 0.0001260 @iter19417) ([92m↓1.95%[0m) [0.06% of initial]
Iter:17899, L1 loss=0.0002899, Total loss=0.0002415, Time:111
[Iter 17900/20000] Loss: 0.0002528 (Best: 0.0002128 @iter15940) ([91m↑1.79%[0m) [0.10% of initial]
[Iter 19620/20000] Loss: 0.0001701 (Best: 0.0001260 @iter19417) ([91m↑14.30%[0m) [0.07% of initial]
[Iter 17910/20000] Loss: 0.0002570 (Best: 0.0002128 @iter15940) ([91m↑1.67%[0m) [0.10% of initial]
[Iter 19630/20000] Loss: 0.0001770 (Best: 0.0001260 @iter19417) ([91m↑4.03%[0m) [0.07% of initial]
[Iter 17920/20000] Loss: 0.0002794 (Best: 0.0002128 @iter15940) ([91m↑8.70%[0m) [0.11% of initial]
[Iter 19640/20000] Loss: 0.0001671 (Best: 0.0001260 @iter19417) ([92m↓5.62%[0m) [0.07% of initial]
[Iter 17930/20000] Loss: 0.0002567 (Best: 0.0002128 @iter15940) ([92m↓8.12%[0m) [0.10% of initial]
[Iter 17940/20000] Loss: 0.0002552 (Best: 0.0002128 @iter15940) ([92m↓0.59%[0m) [0.10% of initial]
[Iter 19650/20000] Loss: 0.0001841 (Best: 0.0001260 @iter19417) ([91m↑10.21%[0m) [0.07% of initial]
[Iter 17950/20000] Loss: 0.0002561 (Best: 0.0002128 @iter15940) ([91m↑0.35%[0m) [0.10% of initial]
[Iter 19660/20000] Loss: 0.0001523 (Best: 0.0001260 @iter19417) ([92m↓17.29%[0m) [0.06% of initial]
[Iter 17960/20000] Loss: 0.0002643 (Best: 0.0002128 @iter15940) ([91m↑3.20%[0m) [0.10% of initial]
[Iter 19670/20000] Loss: 0.0001432 (Best: 0.0001260 @iter19417) ([92m↓5.95%[0m) [0.06% of initial]
[Iter 17970/20000] Loss: 0.0002591 (Best: 0.0002128 @iter15940) ([92m↓1.95%[0m) [0.10% of initial]
[Iter 19680/20000] Loss: 0.0001524 (Best: 0.0001260 @iter19417) ([91m↑6.37%[0m) [0.06% of initial]
[Iter 17980/20000] Loss: 0.0002784 (Best: 0.0002128 @iter15940) ([91m↑7.45%[0m) [0.11% of initial]
[Iter 19690/20000] Loss: 0.0001528 (Best: 0.0001260 @iter19417) ([91m↑0.31%[0m) [0.06% of initial]
[Iter 17990/20000] Loss: 0.0002541 (Best: 0.0002128 @iter15940) ([92m↓8.73%[0m) [0.10% of initial]
Iter:19699, L1 loss=0.0001902, Total loss=0.0001709, Time:140
[Iter 19700/20000] Loss: 0.0002157 (Best: 0.0001260 @iter19417) ([91m↑41.13%[0m) [0.09% of initial]
Iter:17999, L1 loss=0.0003159, Total loss=0.00025, Time:124
[Iter 18000/20000] Loss: 0.0002453 (Best: 0.0002128 @iter15940) ([92m↓3.48%[0m) [0.10% of initial]
[Iter 19710/20000] Loss: 0.0001874 (Best: 0.0001260 @iter19417) ([92m↓13.11%[0m) [0.07% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 18000
Pruning 3 points (0.0%) from gaussian1 at iteration 18000
[Iter 19720/20000] Loss: 0.0001668 (Best: 0.0001260 @iter19417) ([92m↓11.02%[0m) [0.07% of initial]
[Iter 18010/20000] Loss: 0.0007080 (Best: 0.0002128 @iter15940) ([91m↑188.68%[0m) [0.28% of initial]
[Iter 19730/20000] Loss: 0.0001550 (Best: 0.0001260 @iter19417) ([92m↓7.06%[0m) [0.06% of initial]
[Iter 18020/20000] Loss: 0.0004336 (Best: 0.0002128 @iter15940) ([92m↓38.76%[0m) [0.17% of initial]
[Iter 19740/20000] Loss: 0.0001452 (Best: 0.0001260 @iter19417) ([92m↓6.32%[0m) [0.06% of initial]
[Iter 18030/20000] Loss: 0.0003593 (Best: 0.0002128 @iter15940) ([92m↓17.14%[0m) [0.14% of initial]
[Iter 19750/20000] Loss: 0.0001568 (Best: 0.0001260 @iter19417) ([91m↑7.97%[0m) [0.06% of initial]
[Iter 18040/20000] Loss: 0.0002887 (Best: 0.0002128 @iter15940) ([92m↓19.65%[0m) [0.11% of initial]
[Iter 18050/20000] Loss: 0.0002673 (Best: 0.0002128 @iter15940) ([92m↓7.40%[0m) [0.11% of initial]
[Iter 19760/20000] Loss: 0.0001498 (Best: 0.0001260 @iter19417) ([92m↓4.45%[0m) [0.06% of initial]
[Iter 18060/20000] Loss: 0.0002637 (Best: 0.0002128 @iter15940) ([92m↓1.33%[0m) [0.10% of initial]
[Iter 19770/20000] Loss: 0.0001474 (Best: 0.0001260 @iter19417) ([92m↓1.58%[0m) [0.06% of initial]
[Iter 18070/20000] Loss: 0.0002549 (Best: 0.0002128 @iter15940) ([92m↓3.37%[0m) [0.10% of initial]
[Iter 19780/20000] Loss: 0.0001548 (Best: 0.0001260 @iter19417) ([91m↑5.03%[0m) [0.06% of initial]
[Iter 18080/20000] Loss: 0.0002550 (Best: 0.0002128 @iter15940) ([91m↑0.07%[0m) [0.10% of initial]
[Iter 19790/20000] Loss: 0.0001459 (Best: 0.0001260 @iter19417) ([92m↓5.80%[0m) [0.06% of initial]
[Iter 18090/20000] Loss: 0.0002657 (Best: 0.0002128 @iter15940) ([91m↑4.18%[0m) [0.11% of initial]
Iter:19799, L1 loss=0.0001933, Total loss=0.0001558, Time:122
[Iter 19800/20000] Loss: 0.0001501 (Best: 0.0001260 @iter19417) ([91m↑2.92%[0m) [0.06% of initial]
Iter:18099, L1 loss=0.0003442, Total loss=0.0002976, Time:121
[Iter 18100/20000] Loss: 0.0002716 (Best: 0.0002128 @iter15940) ([91m↑2.23%[0m) [0.11% of initial]
[Iter 19810/20000] Loss: 0.0001574 (Best: 0.0001260 @iter19417) ([91m↑4.87%[0m) [0.06% of initial]
[Iter 18110/20000] Loss: 0.0002633 (Best: 0.0002128 @iter15940) ([92m↓3.05%[0m) [0.10% of initial]
[Iter 19820/20000] Loss: 0.0001504 (Best: 0.0001260 @iter19417) ([92m↓4.44%[0m) [0.06% of initial]
[Iter 18120/20000] Loss: 0.0002684 (Best: 0.0002128 @iter15940) ([91m↑1.92%[0m) [0.11% of initial]
[Iter 19830/20000] Loss: 0.0002024 (Best: 0.0001260 @iter19417) ([91m↑34.57%[0m) [0.08% of initial]
[Iter 18130/20000] Loss: 0.0002533 (Best: 0.0002128 @iter15940) ([92m↓5.62%[0m) [0.10% of initial]
[Iter 18140/20000] Loss: 0.0002617 (Best: 0.0002128 @iter15940) ([91m↑3.30%[0m) [0.10% of initial]
[Iter 19840/20000] Loss: 0.0002010 (Best: 0.0001260 @iter19417) ([92m↓0.73%[0m) [0.08% of initial]
[Iter 18150/20000] Loss: 0.0002679 (Best: 0.0002128 @iter15940) ([91m↑2.36%[0m) [0.11% of initial]
[Iter 19850/20000] Loss: 0.0001735 (Best: 0.0001260 @iter19417) ([92m↓13.67%[0m) [0.07% of initial]
[Iter 18160/20000] Loss: 0.0002511 (Best: 0.0002128 @iter15940) ([92m↓6.25%[0m) [0.10% of initial]
[Iter 19860/20000] Loss: 0.0002208 (Best: 0.0001260 @iter19417) ([91m↑27.28%[0m) [0.09% of initial]
[Iter 18170/20000] Loss: 0.0002573 (Best: 0.0002128 @iter15940) ([91m↑2.45%[0m) [0.10% of initial]
[Iter 19870/20000] Loss: 0.0002068 (Best: 0.0001260 @iter19417) ([92m↓6.35%[0m) [0.08% of initial]
[Iter 18180/20000] Loss: 0.0003009 (Best: 0.0002128 @iter15940) ([91m↑16.95%[0m) [0.12% of initial]
[Iter 19880/20000] Loss: 0.0001971 (Best: 0.0001260 @iter19417) ([92m↓4.68%[0m) [0.08% of initial]
[Iter 18190/20000] Loss: 0.0003176 (Best: 0.0002128 @iter15940) ([91m↑5.54%[0m) [0.13% of initial]
[Iter 19890/20000] Loss: 0.0002185 (Best: 0.0001260 @iter19417) ([91m↑10.86%[0m) [0.09% of initial]
Iter:18199, L1 loss=0.000341, Total loss=0.0002973, Time:116
[Iter 18200/20000] Loss: 0.0003427 (Best: 0.0002128 @iter15940) ([91m↑7.91%[0m) [0.14% of initial]
Iter:19899, L1 loss=0.000208, Total loss=0.0001713, Time:127
[Iter 19900/20000] Loss: 0.0001696 (Best: 0.0001260 @iter19417) ([92m↓22.40%[0m) [0.07% of initial]
[Iter 18210/20000] Loss: 0.0002983 (Best: 0.0002128 @iter15940) ([92m↓12.96%[0m) [0.12% of initial]
[Iter 19910/20000] Loss: 0.0001823 (Best: 0.0001260 @iter19417) ([91m↑7.47%[0m) [0.07% of initial]
[Iter 18220/20000] Loss: 0.0004039 (Best: 0.0002128 @iter15940) ([91m↑35.41%[0m) [0.16% of initial]
[Iter 19920/20000] Loss: 0.0001910 (Best: 0.0001260 @iter19417) ([91m↑4.82%[0m) [0.08% of initial]
[Iter 18230/20000] Loss: 0.0003294 (Best: 0.0002128 @iter15940) ([92m↓18.44%[0m) [0.13% of initial]
[Iter 18240/20000] Loss: 0.0002900 (Best: 0.0002128 @iter15940) ([92m↓11.96%[0m) [0.12% of initial]
[Iter 19930/20000] Loss: 0.0001774 (Best: 0.0001260 @iter19417) ([92m↓7.15%[0m) [0.07% of initial]
[Iter 18250/20000] Loss: 0.0002848 (Best: 0.0002128 @iter15940) ([92m↓1.77%[0m) [0.11% of initial]
[Iter 19940/20000] Loss: 0.0002010 (Best: 0.0001260 @iter19417) ([91m↑13.32%[0m) [0.08% of initial]
[Iter 18260/20000] Loss: 0.0002824 (Best: 0.0002128 @iter15940) ([92m↓0.86%[0m) [0.11% of initial]
[Iter 19950/20000] Loss: 0.0002181 (Best: 0.0001260 @iter19417) ([91m↑8.52%[0m) [0.09% of initial]
[Iter 18270/20000] Loss: 0.0002737 (Best: 0.0002128 @iter15940) ([92m↓3.08%[0m) [0.11% of initial]
[Iter 19960/20000] Loss: 0.0001697 (Best: 0.0001260 @iter19417) ([92m↓22.20%[0m) [0.07% of initial]
[Iter 18280/20000] Loss: 0.0002743 (Best: 0.0002128 @iter15940) ([91m↑0.23%[0m) [0.11% of initial]
[Iter 19970/20000] Loss: 0.0001662 (Best: 0.0001260 @iter19417) ([92m↓2.07%[0m) [0.07% of initial]
[Iter 18290/20000] Loss: 0.0003160 (Best: 0.0002128 @iter15940) ([91m↑15.18%[0m) [0.13% of initial]
[Iter 19980/20000] Loss: 0.0001641 (Best: 0.0001260 @iter19417) ([92m↓1.27%[0m) [0.07% of initial]
Iter:18299, L1 loss=0.0003418, Total loss=0.000336, Time:115
[Iter 18300/20000] Loss: 0.0003146 (Best: 0.0002128 @iter15940) ([92m↓0.44%[0m) [0.12% of initial]
[Iter 19990/20000] Loss: 0.0001411 (Best: 0.0001260 @iter19417) ([92m↓14.02%[0m) [0.06% of initial]
[Iter 18310/20000] Loss: 0.0003062 (Best: 0.0002128 @iter15940) ([92m↓2.65%[0m) [0.12% of initial]
Iter:19999, L1 loss=0.000165, Total loss=0.00014, Time:125
[Iter 20000/20000] Loss: 0.0001390 (Best: 0.0001260 @iter19417) ([92m↓1.43%[0m) [0.06% of initial]
[Iter 18320/20000] Loss: 0.0003048 (Best: 0.0002128 @iter15940) ([92m↓0.45%[0m) [0.12% of initial]
Testing Speed: 39.0440068721408 fps
Testing Time: 1.2806062698364258 s

[ITER 20000] Evaluating test: SSIM = 0.8432503938674927, PSNR = 17.84492208480835
[Iter 18330/20000] Loss: 0.0003620 (Best: 0.0002128 @iter15940) ([91m↑18.75%[0m) [0.14% of initial]
Testing Speed: 39.30980705788264 fps
Testing Time: 0.07631683349609375 s

[ITER 20000] Evaluating train: SSIM = 0.9999997019767761, PSNR = 69.666259765625
Iter:20000, total_points:198627

[ITER 20000] Saving Gaussians
[Iter 18340/20000] Loss: 0.0003552 (Best: 0.0002128 @iter15940) ([92m↓1.87%[0m) [0.14% of initial]
[Iter 18350/20000] Loss: 0.0003391 (Best: 0.0002128 @iter15940) ([92m↓4.54%[0m) [0.13% of initial]
[Iter 18360/20000] Loss: 0.0003828 (Best: 0.0002128 @iter15940) ([91m↑12.88%[0m) [0.15% of initial]
[Iter 18370/20000] Loss: 0.0003001 (Best: 0.0002128 @iter15940) ([92m↓21.61%[0m) [0.12% of initial]
[Iter 18380/20000] Loss: 0.0002602 (Best: 0.0002128 @iter15940) ([92m↓13.29%[0m) [0.10% of initial]

Training completed!
==================================================
Body part: chest
Testing Speed: 39 fps
Total time: 62.88 minutes
Test SSIM: 0.8433
Test PSNR: 17.845
Gaussian0 final points count: 198627
Gaussian1 final points count: 200848
Final loss: 0.0001390 (0.06% of initial)
Save path: 2024_11_26_17_16_02
Initial loss: 0.2517052
Best loss: 0.0001260 @iteration 19417 (0.05% of initial)
Train SSIM: 1.0000
Train PSNR: 69.666
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
[Iter 18390/20000] Loss: 0.0002684 (Best: 0.0002128 @iter15940) ([91m↑3.17%[0m) [0.11% of initial]
Iter:18399, L1 loss=0.0002819, Total loss=0.0002446, Time:90
[Iter 18400/20000] Loss: 0.0002415 (Best: 0.0002128 @iter15940) ([92m↓10.03%[0m) [0.10% of initial]
[Iter 18410/20000] Loss: 0.0002527 (Best: 0.0002128 @iter15940) ([91m↑4.63%[0m) [0.10% of initial]
[Iter 18420/20000] Loss: 0.0002383 (Best: 0.0002128 @iter15940) ([92m↓5.69%[0m) [0.09% of initial]
[Iter 18430/20000] Loss: 0.0002349 (Best: 0.0002128 @iter15940) ([92m↓1.44%[0m) [0.09% of initial]
[Iter 18440/20000] Loss: 0.0002668 (Best: 0.0002128 @iter15940) ([91m↑13.58%[0m) [0.11% of initial]
[Iter 18450/20000] Loss: 0.0002382 (Best: 0.0002128 @iter15940) ([92m↓10.72%[0m) [0.09% of initial]
[Iter 18460/20000] Loss: 0.0002425 (Best: 0.0002128 @iter15940) ([91m↑1.84%[0m) [0.10% of initial]
[Iter 18470/20000] Loss: 0.0002428 (Best: 0.0002128 @iter15940) ([91m↑0.10%[0m) [0.10% of initial]
[Iter 18480/20000] Loss: 0.0002376 (Best: 0.0002128 @iter15940) ([92m↓2.13%[0m) [0.09% of initial]
[Iter 18490/20000] Loss: 0.0002481 (Best: 0.0002128 @iter15940) ([91m↑4.44%[0m) [0.10% of initial]
Iter:18499, L1 loss=0.0003084, Total loss=0.0002575, Time:93
[Iter 18500/20000] Loss: 0.0002454 (Best: 0.0002128 @iter15940) ([92m↓1.10%[0m) [0.10% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 18500
Pruning 2 points (0.0%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0004767 (Best: 0.0002128 @iter15940) ([91m↑94.25%[0m) [0.19% of initial]
[Iter 18520/20000] Loss: 0.0003506 (Best: 0.0002128 @iter15940) ([92m↓26.45%[0m) [0.14% of initial]
[Iter 18530/20000] Loss: 0.0004307 (Best: 0.0002128 @iter15940) ([91m↑22.84%[0m) [0.17% of initial]
[Iter 18540/20000] Loss: 0.0002976 (Best: 0.0002128 @iter15940) ([92m↓30.91%[0m) [0.12% of initial]
[Iter 18550/20000] Loss: 0.0002728 (Best: 0.0002128 @iter15940) ([92m↓8.32%[0m) [0.11% of initial]
[Iter 18560/20000] Loss: 0.0002721 (Best: 0.0002128 @iter15940) ([92m↓0.26%[0m) [0.11% of initial]
[Iter 18570/20000] Loss: 0.0002785 (Best: 0.0002128 @iter15940) ([91m↑2.33%[0m) [0.11% of initial]
[Iter 18580/20000] Loss: 0.0002564 (Best: 0.0002128 @iter15940) ([92m↓7.91%[0m) [0.10% of initial]
[Iter 18590/20000] Loss: 0.0002528 (Best: 0.0002128 @iter15940) ([92m↓1.43%[0m) [0.10% of initial]
Iter:18599, L1 loss=0.000342, Total loss=0.0002685, Time:91
[Iter 18600/20000] Loss: 0.0002746 (Best: 0.0002128 @iter15940) ([91m↑8.65%[0m) [0.11% of initial]
[Iter 18610/20000] Loss: 0.0002575 (Best: 0.0002128 @iter15940) ([92m↓6.25%[0m) [0.10% of initial]
[Iter 18620/20000] Loss: 0.0002456 (Best: 0.0002128 @iter15940) ([92m↓4.62%[0m) [0.10% of initial]
[Iter 18630/20000] Loss: 0.0003009 (Best: 0.0002128 @iter15940) ([91m↑22.54%[0m) [0.12% of initial]
[Iter 18640/20000] Loss: 0.0002783 (Best: 0.0002128 @iter15940) ([92m↓7.50%[0m) [0.11% of initial]
[Iter 18650/20000] Loss: 0.0002562 (Best: 0.0002128 @iter15940) ([92m↓7.96%[0m) [0.10% of initial]
[Iter 18660/20000] Loss: 0.0002510 (Best: 0.0002128 @iter15940) ([92m↓2.03%[0m) [0.10% of initial]
[Iter 18670/20000] Loss: 0.0002406 (Best: 0.0002128 @iter15940) ([92m↓4.12%[0m) [0.10% of initial]
[Iter 18680/20000] Loss: 0.0002434 (Best: 0.0002128 @iter15940) ([91m↑1.15%[0m) [0.10% of initial]
[Iter 18690/20000] Loss: 0.0002446 (Best: 0.0002128 @iter15940) ([91m↑0.50%[0m) [0.10% of initial]
Iter:18699, L1 loss=0.0002792, Total loss=0.0002401, Time:82
[Iter 18700/20000] Loss: 0.0002344 (Best: 0.0002128 @iter15940) ([92m↓4.15%[0m) [0.09% of initial]
[Iter 18710/20000] Loss: 0.0002412 (Best: 0.0002128 @iter15940) ([91m↑2.86%[0m) [0.10% of initial]
[Iter 18720/20000] Loss: 0.0002352 (Best: 0.0002128 @iter15940) ([92m↓2.46%[0m) [0.09% of initial]
[Iter 18730/20000] Loss: 0.0002411 (Best: 0.0002128 @iter15940) ([91m↑2.50%[0m) [0.10% of initial]
[Iter 18740/20000] Loss: 0.0002493 (Best: 0.0002128 @iter15940) ([91m↑3.39%[0m) [0.10% of initial]
[Iter 18750/20000] Loss: 0.0002388 (Best: 0.0002128 @iter15940) ([92m↓4.21%[0m) [0.09% of initial]
[Iter 18760/20000] Loss: 0.0002423 (Best: 0.0002128 @iter15940) ([91m↑1.47%[0m) [0.10% of initial]
[Iter 18770/20000] Loss: 0.0002565 (Best: 0.0002128 @iter15940) ([91m↑5.88%[0m) [0.10% of initial]
[Iter 18780/20000] Loss: 0.0002567 (Best: 0.0002128 @iter15940) ([91m↑0.06%[0m) [0.10% of initial]
[Iter 18790/20000] Loss: 0.0002589 (Best: 0.0002128 @iter15940) ([91m↑0.85%[0m) [0.10% of initial]
Iter:18799, L1 loss=0.0002731, Total loss=0.000248, Time:79
[Iter 18800/20000] Loss: 0.0002555 (Best: 0.0002128 @iter15940) ([92m↓1.31%[0m) [0.10% of initial]
[Iter 18810/20000] Loss: 0.0002676 (Best: 0.0002128 @iter15940) ([91m↑4.76%[0m) [0.11% of initial]
[Iter 18820/20000] Loss: 0.0002751 (Best: 0.0002128 @iter15940) ([91m↑2.80%[0m) [0.11% of initial]
[Iter 18830/20000] Loss: 0.0002801 (Best: 0.0002128 @iter15940) ([91m↑1.82%[0m) [0.11% of initial]
[Iter 18840/20000] Loss: 0.0002630 (Best: 0.0002128 @iter15940) ([92m↓6.13%[0m) [0.10% of initial]
[Iter 18850/20000] Loss: 0.0002588 (Best: 0.0002128 @iter15940) ([92m↓1.58%[0m) [0.10% of initial]
[Iter 18860/20000] Loss: 0.0003101 (Best: 0.0002128 @iter15940) ([91m↑19.84%[0m) [0.12% of initial]
[Iter 18870/20000] Loss: 0.0002668 (Best: 0.0002128 @iter15940) ([92m↓13.96%[0m) [0.11% of initial]
[Iter 18880/20000] Loss: 0.0002671 (Best: 0.0002128 @iter15940) ([91m↑0.08%[0m) [0.11% of initial]
[Iter 18890/20000] Loss: 0.0002620 (Best: 0.0002128 @iter15940) ([92m↓1.90%[0m) [0.10% of initial]
Iter:18899, L1 loss=0.0002885, Total loss=0.0002602, Time:80
[Iter 18900/20000] Loss: 0.0002722 (Best: 0.0002128 @iter15940) ([91m↑3.91%[0m) [0.11% of initial]
[Iter 18910/20000] Loss: 0.0002916 (Best: 0.0002128 @iter15940) ([91m↑7.12%[0m) [0.12% of initial]
[Iter 18920/20000] Loss: 0.0002518 (Best: 0.0002128 @iter15940) ([92m↓13.65%[0m) [0.10% of initial]
[Iter 18930/20000] Loss: 0.0003285 (Best: 0.0002128 @iter15940) ([91m↑30.46%[0m) [0.13% of initial]
[Iter 18940/20000] Loss: 0.0002729 (Best: 0.0002128 @iter15940) ([92m↓16.93%[0m) [0.11% of initial]
[Iter 18950/20000] Loss: 0.0002710 (Best: 0.0002128 @iter15940) ([92m↓0.71%[0m) [0.11% of initial]
[Iter 18960/20000] Loss: 0.0002740 (Best: 0.0002128 @iter15940) ([91m↑1.11%[0m) [0.11% of initial]
[Iter 18970/20000] Loss: 0.0002766 (Best: 0.0002128 @iter15940) ([91m↑0.98%[0m) [0.11% of initial]
[Iter 18980/20000] Loss: 0.0002445 (Best: 0.0002128 @iter15940) ([92m↓11.64%[0m) [0.10% of initial]
[Iter 18990/20000] Loss: 0.0002446 (Best: 0.0002128 @iter15940) ([91m↑0.05%[0m) [0.10% of initial]
Iter:18999, L1 loss=0.0002721, Total loss=0.0002404, Time:82
[Iter 19000/20000] Loss: 0.0002355 (Best: 0.0002128 @iter15940) ([92m↓3.73%[0m) [0.09% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 19000
Pruning 5 points (0.0%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0006088 (Best: 0.0002128 @iter15940) ([91m↑158.52%[0m) [0.24% of initial]
[Iter 19020/20000] Loss: 0.0004287 (Best: 0.0002128 @iter15940) ([92m↓29.58%[0m) [0.17% of initial]
[Iter 19030/20000] Loss: 0.0003240 (Best: 0.0002128 @iter15940) ([92m↓24.41%[0m) [0.13% of initial]
[Iter 19040/20000] Loss: 0.0002801 (Best: 0.0002128 @iter15940) ([92m↓13.56%[0m) [0.11% of initial]
[Iter 19050/20000] Loss: 0.0002577 (Best: 0.0002128 @iter15940) ([92m↓7.99%[0m) [0.10% of initial]
[Iter 19060/20000] Loss: 0.0002470 (Best: 0.0002128 @iter15940) ([92m↓4.16%[0m) [0.10% of initial]
[Iter 19070/20000] Loss: 0.0002703 (Best: 0.0002128 @iter15940) ([91m↑9.44%[0m) [0.11% of initial]
[Iter 19080/20000] Loss: 0.0002421 (Best: 0.0002128 @iter15940) ([92m↓10.43%[0m) [0.10% of initial]
[Iter 19090/20000] Loss: 0.0002443 (Best: 0.0002128 @iter15940) ([91m↑0.91%[0m) [0.10% of initial]
Iter:19099, L1 loss=0.0002725, Total loss=0.0002432, Time:90
[Iter 19100/20000] Loss: 0.0002860 (Best: 0.0002128 @iter15940) ([91m↑17.03%[0m) [0.11% of initial]
[Iter 19110/20000] Loss: 0.0002634 (Best: 0.0002128 @iter15940) ([92m↓7.89%[0m) [0.10% of initial]
[Iter 19120/20000] Loss: 0.0002326 (Best: 0.0002128 @iter15940) ([92m↓11.69%[0m) [0.09% of initial]
[Iter 19130/20000] Loss: 0.0002286 (Best: 0.0002128 @iter15940) ([92m↓1.71%[0m) [0.09% of initial]
[Iter 19140/20000] Loss: 0.0002579 (Best: 0.0002128 @iter15940) ([91m↑12.80%[0m) [0.10% of initial]
[Iter 19150/20000] Loss: 0.0002441 (Best: 0.0002128 @iter15940) ([92m↓5.36%[0m) [0.10% of initial]
[Iter 19160/20000] Loss: 0.0002582 (Best: 0.0002128 @iter15940) ([91m↑5.78%[0m) [0.10% of initial]
[Iter 19170/20000] Loss: 0.0002441 (Best: 0.0002128 @iter15940) ([92m↓5.47%[0m) [0.10% of initial]
[Iter 19180/20000] Loss: 0.0002364 (Best: 0.0002128 @iter15940) ([92m↓3.14%[0m) [0.09% of initial]
[Iter 19190/20000] Loss: 0.0002543 (Best: 0.0002128 @iter15940) ([91m↑7.55%[0m) [0.10% of initial]
Iter:19199, L1 loss=0.0003285, Total loss=0.0002806, Time:90
[Iter 19200/20000] Loss: 0.0002657 (Best: 0.0002128 @iter15940) ([91m↑4.49%[0m) [0.11% of initial]
[Iter 19210/20000] Loss: 0.0002497 (Best: 0.0002128 @iter15940) ([92m↓6.01%[0m) [0.10% of initial]
[Iter 19220/20000] Loss: 0.0005176 (Best: 0.0002128 @iter15940) ([91m↑107.24%[0m) [0.21% of initial]
[Iter 19230/20000] Loss: 0.0002508 (Best: 0.0002128 @iter15940) ([92m↓51.54%[0m) [0.10% of initial]
[Iter 19240/20000] Loss: 0.0002355 (Best: 0.0002128 @iter15940) ([92m↓6.11%[0m) [0.09% of initial]
[Iter 19250/20000] Loss: 0.0002496 (Best: 0.0002128 @iter15940) ([91m↑5.97%[0m) [0.10% of initial]
[Iter 19260/20000] Loss: 0.0002429 (Best: 0.0002128 @iter15940) ([92m↓2.67%[0m) [0.10% of initial]
[Iter 19270/20000] Loss: 0.0002546 (Best: 0.0002128 @iter15940) ([91m↑4.81%[0m) [0.10% of initial]
[Iter 19280/20000] Loss: 0.0002700 (Best: 0.0002128 @iter15940) ([91m↑6.06%[0m) [0.11% of initial]
[Iter 19290/20000] Loss: 0.0002578 (Best: 0.0002128 @iter15940) ([92m↓4.52%[0m) [0.10% of initial]
Iter:19299, L1 loss=0.0002824, Total loss=0.0002515, Time:76
[Iter 19300/20000] Loss: 0.0002555 (Best: 0.0002128 @iter15940) ([92m↓0.87%[0m) [0.10% of initial]
[Iter 19310/20000] Loss: 0.0002826 (Best: 0.0002128 @iter15940) ([91m↑10.58%[0m) [0.11% of initial]
[Iter 19320/20000] Loss: 0.0002570 (Best: 0.0002128 @iter15940) ([92m↓9.04%[0m) [0.10% of initial]
[Iter 19330/20000] Loss: 0.0002571 (Best: 0.0002128 @iter15940) ([91m↑0.02%[0m) [0.10% of initial]
[Iter 19340/20000] Loss: 0.0003011 (Best: 0.0002128 @iter15940) ([91m↑17.12%[0m) [0.12% of initial]
[Iter 19350/20000] Loss: 0.0003063 (Best: 0.0002128 @iter15940) ([91m↑1.72%[0m) [0.12% of initial]
[Iter 19360/20000] Loss: 0.0002966 (Best: 0.0002128 @iter15940) ([92m↓3.16%[0m) [0.12% of initial]
[Iter 19370/20000] Loss: 0.0002989 (Best: 0.0002128 @iter15940) ([91m↑0.77%[0m) [0.12% of initial]
[Iter 19380/20000] Loss: 0.0003077 (Best: 0.0002128 @iter15940) ([91m↑2.95%[0m) [0.12% of initial]
[Iter 19390/20000] Loss: 0.0002539 (Best: 0.0002128 @iter15940) ([92m↓17.49%[0m) [0.10% of initial]
Iter:19399, L1 loss=0.0002758, Total loss=0.0002359, Time:76
[Iter 19400/20000] Loss: 0.0002469 (Best: 0.0002128 @iter15940) ([92m↓2.78%[0m) [0.10% of initial]
[Iter 19410/20000] Loss: 0.0002261 (Best: 0.0002128 @iter15940) ([92m↓8.40%[0m) [0.09% of initial]
[Iter 19420/20000] Loss: 0.0002259 (Best: 0.0002073 @iter19417) ([92m↓0.08%[0m) [0.09% of initial]
[Iter 19430/20000] Loss: 0.0002207 (Best: 0.0002073 @iter19417) ([92m↓2.29%[0m) [0.09% of initial]
[Iter 19440/20000] Loss: 0.0002350 (Best: 0.0002073 @iter19417) ([91m↑6.45%[0m) [0.09% of initial]
[Iter 19450/20000] Loss: 0.0002361 (Best: 0.0002073 @iter19417) ([91m↑0.46%[0m) [0.09% of initial]
[Iter 19460/20000] Loss: 0.0002857 (Best: 0.0002073 @iter19417) ([91m↑21.01%[0m) [0.11% of initial]
[Iter 19470/20000] Loss: 0.0003671 (Best: 0.0002073 @iter19417) ([91m↑28.51%[0m) [0.15% of initial]
[Iter 19480/20000] Loss: 0.0003834 (Best: 0.0002073 @iter19417) ([91m↑4.43%[0m) [0.15% of initial]
[Iter 19490/20000] Loss: 0.0003386 (Best: 0.0002073 @iter19417) ([92m↓11.67%[0m) [0.13% of initial]
Iter:19499, L1 loss=0.0003327, Total loss=0.0002686, Time:86
[Iter 19500/20000] Loss: 0.0002993 (Best: 0.0002073 @iter19417) ([92m↓11.60%[0m) [0.12% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 19500
Pruning 1 points (0.0%) from gaussian1 at iteration 19500
[Iter 19510/20000] Loss: 0.0005414 (Best: 0.0002073 @iter19417) ([91m↑80.88%[0m) [0.22% of initial]
[Iter 19520/20000] Loss: 0.0003431 (Best: 0.0002073 @iter19417) ([92m↓36.64%[0m) [0.14% of initial]
[Iter 19530/20000] Loss: 0.0002823 (Best: 0.0002073 @iter19417) ([92m↓17.71%[0m) [0.11% of initial]
[Iter 19540/20000] Loss: 0.0002428 (Best: 0.0002073 @iter19417) ([92m↓14.00%[0m) [0.10% of initial]
[Iter 19550/20000] Loss: 0.0002384 (Best: 0.0002073 @iter19417) ([92m↓1.81%[0m) [0.09% of initial]
[Iter 19560/20000] Loss: 0.0002330 (Best: 0.0002073 @iter19417) ([92m↓2.25%[0m) [0.09% of initial]
[Iter 19570/20000] Loss: 0.0002228 (Best: 0.0002073 @iter19417) ([92m↓4.40%[0m) [0.09% of initial]
[Iter 19580/20000] Loss: 0.0002626 (Best: 0.0002073 @iter19417) ([91m↑17.89%[0m) [0.10% of initial]
[Iter 19590/20000] Loss: 0.0002321 (Best: 0.0002073 @iter19417) ([92m↓11.62%[0m) [0.09% of initial]
Iter:19599, L1 loss=0.0002864, Total loss=0.0002363, Time:88
[Iter 19600/20000] Loss: 0.0002329 (Best: 0.0002073 @iter19417) ([91m↑0.36%[0m) [0.09% of initial]
[Iter 19610/20000] Loss: 0.0002375 (Best: 0.0002073 @iter19417) ([91m↑1.97%[0m) [0.09% of initial]
[Iter 19620/20000] Loss: 0.0002475 (Best: 0.0002073 @iter19417) ([91m↑4.19%[0m) [0.10% of initial]
[Iter 19630/20000] Loss: 0.0002620 (Best: 0.0002073 @iter19417) ([91m↑5.89%[0m) [0.10% of initial]
[Iter 19640/20000] Loss: 0.0002454 (Best: 0.0002073 @iter19417) ([92m↓6.35%[0m) [0.10% of initial]
[Iter 19650/20000] Loss: 0.0002625 (Best: 0.0002073 @iter19417) ([91m↑6.98%[0m) [0.10% of initial]
[Iter 19660/20000] Loss: 0.0002291 (Best: 0.0002073 @iter19417) ([92m↓12.74%[0m) [0.09% of initial]
[Iter 19670/20000] Loss: 0.0002274 (Best: 0.0002073 @iter19417) ([92m↓0.71%[0m) [0.09% of initial]
[Iter 19680/20000] Loss: 0.0002287 (Best: 0.0002073 @iter19417) ([91m↑0.54%[0m) [0.09% of initial]
[Iter 19690/20000] Loss: 0.0002234 (Best: 0.0002073 @iter19417) ([92m↓2.30%[0m) [0.09% of initial]
Iter:19699, L1 loss=0.000281, Total loss=0.0002483, Time:89
[Iter 19700/20000] Loss: 0.0003146 (Best: 0.0002073 @iter19417) ([91m↑40.81%[0m) [0.12% of initial]
[Iter 19710/20000] Loss: 0.0002713 (Best: 0.0002073 @iter19417) ([92m↓13.77%[0m) [0.11% of initial]
[Iter 19720/20000] Loss: 0.0002507 (Best: 0.0002073 @iter19417) ([92m↓7.59%[0m) [0.10% of initial]
[Iter 19730/20000] Loss: 0.0002423 (Best: 0.0002073 @iter19417) ([92m↓3.33%[0m) [0.10% of initial]
[Iter 19740/20000] Loss: 0.0002319 (Best: 0.0002073 @iter19417) ([92m↓4.30%[0m) [0.09% of initial]
[Iter 19750/20000] Loss: 0.0002535 (Best: 0.0002073 @iter19417) ([91m↑9.32%[0m) [0.10% of initial]
[Iter 19760/20000] Loss: 0.0002418 (Best: 0.0002073 @iter19417) ([92m↓4.62%[0m) [0.10% of initial]
[Iter 19770/20000] Loss: 0.0002361 (Best: 0.0002073 @iter19417) ([92m↓2.36%[0m) [0.09% of initial]
[Iter 19780/20000] Loss: 0.0002513 (Best: 0.0002073 @iter19417) ([91m↑6.43%[0m) [0.10% of initial]
[Iter 19790/20000] Loss: 0.0002362 (Best: 0.0002073 @iter19417) ([92m↓5.99%[0m) [0.09% of initial]
Iter:19799, L1 loss=0.0002918, Total loss=0.0002413, Time:78
[Iter 19800/20000] Loss: 0.0002348 (Best: 0.0002073 @iter19417) ([92m↓0.58%[0m) [0.09% of initial]
[Iter 19810/20000] Loss: 0.0002379 (Best: 0.0002073 @iter19417) ([91m↑1.29%[0m) [0.09% of initial]
[Iter 19820/20000] Loss: 0.0002351 (Best: 0.0002073 @iter19417) ([92m↓1.15%[0m) [0.09% of initial]
[Iter 19830/20000] Loss: 0.0002815 (Best: 0.0002073 @iter19417) ([91m↑19.72%[0m) [0.11% of initial]
[Iter 19840/20000] Loss: 0.0002815 (Best: 0.0002073 @iter19417) ([92m↓0.00%[0m) [0.11% of initial]
[Iter 19850/20000] Loss: 0.0002584 (Best: 0.0002073 @iter19417) ([92m↓8.18%[0m) [0.10% of initial]
[Iter 19860/20000] Loss: 0.0003098 (Best: 0.0002073 @iter19417) ([91m↑19.88%[0m) [0.12% of initial]
[Iter 19870/20000] Loss: 0.0002941 (Best: 0.0002073 @iter19417) ([92m↓5.07%[0m) [0.12% of initial]
[Iter 19880/20000] Loss: 0.0002846 (Best: 0.0002073 @iter19417) ([92m↓3.22%[0m) [0.11% of initial]
[Iter 19890/20000] Loss: 0.0003170 (Best: 0.0002073 @iter19417) ([91m↑11.37%[0m) [0.13% of initial]
Iter:19899, L1 loss=0.0003438, Total loss=0.0002631, Time:79
[Iter 19900/20000] Loss: 0.0002586 (Best: 0.0002073 @iter19417) ([92m↓18.44%[0m) [0.10% of initial]
[Iter 19910/20000] Loss: 0.0003064 (Best: 0.0002073 @iter19417) ([91m↑18.49%[0m) [0.12% of initial]
[Iter 19920/20000] Loss: 0.0003128 (Best: 0.0002073 @iter19417) ([91m↑2.11%[0m) [0.12% of initial]
[Iter 19930/20000] Loss: 0.0002952 (Best: 0.0002073 @iter19417) ([92m↓5.63%[0m) [0.12% of initial]
[Iter 19940/20000] Loss: 0.0003241 (Best: 0.0002073 @iter19417) ([91m↑9.80%[0m) [0.13% of initial]
[Iter 19950/20000] Loss: 0.0003235 (Best: 0.0002073 @iter19417) ([92m↓0.19%[0m) [0.13% of initial]
[Iter 19960/20000] Loss: 0.0002701 (Best: 0.0002073 @iter19417) ([92m↓16.50%[0m) [0.11% of initial]
[Iter 19970/20000] Loss: 0.0002604 (Best: 0.0002073 @iter19417) ([92m↓3.59%[0m) [0.10% of initial]
[Iter 19980/20000] Loss: 0.0002650 (Best: 0.0002073 @iter19417) ([91m↑1.74%[0m) [0.11% of initial]
[Iter 19990/20000] Loss: 0.0002281 (Best: 0.0002073 @iter19417) ([92m↓13.91%[0m) [0.09% of initial]
Iter:19999, L1 loss=0.0002556, Total loss=0.0002211, Time:77
[Iter 20000/20000] Loss: 0.0002256 (Best: 0.0002073 @iter19417) ([92m↓1.08%[0m) [0.09% of initial]
Testing Speed: 51.94422530815653 fps
Testing Time: 0.9625709056854248 s

[ITER 20000] Evaluating test: SSIM = 0.8862910890579224, PSNR = 19.014227561950683
Testing Speed: 61.200933852140075 fps
Testing Time: 0.04901885986328125 s

[ITER 20000] Evaluating train: SSIM = 0.9999991456667582, PSNR = 65.96644592285156
Iter:20000, total_points:186152

[ITER 20000] Saving Gaussians
Pruning 3 points (0.0%) from gaussian0 at iteration 20000
Pruning 1 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 51 fps
Total time: 62.51 minutes
Test SSIM: 0.8863
Test PSNR: 19.014
Gaussian0 final points count: 186149
Gaussian1 final points count: 182914
Final loss: 0.0002256 (0.09% of initial)
Save path: 2024_11_26_17_19_05
Initial loss: 0.2517052
Best loss: 0.0002073 @iteration 19417 (0.08% of initial)
Train SSIM: 1.0000
Train PSNR: 65.966
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126907 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746700 (Best: 0.1693029 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374907 (Best: 0.1327880 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123922 (Best: 0.1098370 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993459 (Best: 0.0965433 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936760 (Best: 0.0908517 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884581 (Best: 0.0869489 @iter70) ([92m↓5.57%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851913 (Best: 0.0831065 @iter80) ([92m↓3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824157 (Best: 0.0801591 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:42
[Iter 100/20000] Loss: 0.0786707 (Best: 0.0766291 @iter97) ([92m↓4.54%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753232 (Best: 0.0731430 @iter106) ([92m↓4.26%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714382 (Best: 0.0685603 @iter118) ([92m↓5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0667013 (Best: 0.0642063 @iter130) ([92m↓6.63%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635350 (Best: 0.0612904 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612661 (Best: 0.0583726 @iter148) ([92m↓3.57%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590614 (Best: 0.0559591 @iter157) ([92m↓3.60%[0m) [23.46% of initial]
[Iter 170/20000] Loss: 0.0563461 (Best: 0.0534980 @iter167) ([92m↓4.60%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523159 (Best: 0.0499886 @iter179) ([92m↓7.15%[0m) [20.78% of initial]
[Iter 190/20000] Loss: 0.0495292 (Best: 0.0477885 @iter188) ([92m↓5.33%[0m) [19.68% of initial]
Iter:199, L1 loss=0.03449, Total loss=0.04969, Time:36
[Iter 200/20000] Loss: 0.0477788 (Best: 0.0455963 @iter198) ([92m↓3.53%[0m) [18.98% of initial]
[Iter 210/20000] Loss: 0.0450845 (Best: 0.0428596 @iter209) ([92m↓5.64%[0m) [17.91% of initial]
[Iter 220/20000] Loss: 0.0441013 (Best: 0.0412251 @iter219) ([92m↓2.18%[0m) [17.52% of initial]
[Iter 230/20000] Loss: 0.0423832 (Best: 0.0399719 @iter227) ([92m↓3.90%[0m) [16.84% of initial]
[Iter 240/20000] Loss: 0.0402964 (Best: 0.0378256 @iter238) ([92m↓4.92%[0m) [16.01% of initial]
[Iter 250/20000] Loss: 0.0379623 (Best: 0.0362218 @iter248) ([92m↓5.79%[0m) [15.08% of initial]
[Iter 260/20000] Loss: 0.0358859 (Best: 0.0343062 @iter260) ([92m↓5.47%[0m) [14.26% of initial]
[Iter 270/20000] Loss: 0.0349702 (Best: 0.0328496 @iter269) ([92m↓2.55%[0m) [13.89% of initial]
[Iter 280/20000] Loss: 0.0346829 (Best: 0.0319019 @iter277) ([92m↓0.82%[0m) [13.78% of initial]
[Iter 290/20000] Loss: 0.0328418 (Best: 0.0302700 @iter287) ([92m↓5.31%[0m) [13.05% of initial]
Iter:299, L1 loss=0.02231, Total loss=0.0333, Time:36
[Iter 300/20000] Loss: 0.0307735 (Best: 0.0289764 @iter300) ([92m↓6.30%[0m) [12.23% of initial]
[Iter 310/20000] Loss: 0.0293826 (Best: 0.0274709 @iter310) ([92m↓4.52%[0m) [11.67% of initial]
[Iter 320/20000] Loss: 0.0279915 (Best: 0.0265886 @iter320) ([92m↓4.73%[0m) [11.12% of initial]
[Iter 330/20000] Loss: 0.0276192 (Best: 0.0258409 @iter330) ([92m↓1.33%[0m) [10.97% of initial]
[Iter 340/20000] Loss: 0.0255265 (Best: 0.0244293 @iter340) ([92m↓7.58%[0m) [10.14% of initial]
[Iter 350/20000] Loss: 0.0261592 (Best: 0.0234998 @iter349) ([91m↑2.48%[0m) [10.39% of initial]
[Iter 360/20000] Loss: 0.0246389 (Best: 0.0226214 @iter358) ([92m↓5.81%[0m) [9.79% of initial]
[Iter 370/20000] Loss: 0.0244010 (Best: 0.0222160 @iter368) ([92m↓0.97%[0m) [9.69% of initial]
[Iter 380/20000] Loss: 0.0222712 (Best: 0.0211089 @iter379) ([92m↓8.73%[0m) [8.85% of initial]
[Iter 390/20000] Loss: 0.0217852 (Best: 0.0202387 @iter390) ([92m↓2.18%[0m) [8.66% of initial]
Iter:399, L1 loss=0.0136, Total loss=0.02145, Time:36
[Iter 400/20000] Loss: 0.0205853 (Best: 0.0190422 @iter400) ([92m↓5.51%[0m) [8.18% of initial]
[Iter 410/20000] Loss: 0.0197102 (Best: 0.0185723 @iter410) ([92m↓4.25%[0m) [7.83% of initial]
[Iter 420/20000] Loss: 0.0202180 (Best: 0.0180728 @iter418) ([91m↑2.58%[0m) [8.03% of initial]
[Iter 430/20000] Loss: 0.0183081 (Best: 0.0174261 @iter430) ([92m↓9.45%[0m) [7.27% of initial]
[Iter 440/20000] Loss: 0.0188624 (Best: 0.0169937 @iter438) ([91m↑3.03%[0m) [7.49% of initial]
[Iter 450/20000] Loss: 0.0180283 (Best: 0.0160748 @iter449) ([92m↓4.42%[0m) [7.16% of initial]
[Iter 460/20000] Loss: 0.0173559 (Best: 0.0153750 @iter458) ([92m↓3.73%[0m) [6.90% of initial]
[Iter 470/20000] Loss: 0.0159543 (Best: 0.0149620 @iter470) ([92m↓8.08%[0m) [6.34% of initial]
[Iter 480/20000] Loss: 0.0158376 (Best: 0.0144701 @iter479) ([92m↓0.73%[0m) [6.29% of initial]
[Iter 490/20000] Loss: 0.0148683 (Best: 0.0136454 @iter490) ([92m↓6.12%[0m) [5.91% of initial]
Iter:499, L1 loss=0.008592, Total loss=0.01567, Time:36
[Iter 500/20000] Loss: 0.0148166 (Best: 0.0134485 @iter493) ([92m↓0.35%[0m) [5.89% of initial]
[Iter 510/20000] Loss: 0.0142603 (Best: 0.0130924 @iter508) ([92m↓3.75%[0m) [5.67% of initial]
[Iter 520/20000] Loss: 0.0133171 (Best: 0.0123394 @iter519) ([92m↓6.61%[0m) [5.29% of initial]
[Iter 530/20000] Loss: 0.0125661 (Best: 0.0113590 @iter529) ([92m↓5.64%[0m) [4.99% of initial]
[Iter 540/20000] Loss: 0.0131660 (Best: 0.0113590 @iter529) ([91m↑4.77%[0m) [5.23% of initial]
[Iter 550/20000] Loss: 0.0125381 (Best: 0.0112232 @iter548) ([92m↓4.77%[0m) [4.98% of initial]
[Iter 560/20000] Loss: 0.0125037 (Best: 0.0109258 @iter556) ([92m↓0.27%[0m) [4.97% of initial]
[Iter 570/20000] Loss: 0.0118459 (Best: 0.0105862 @iter569) ([92m↓5.26%[0m) [4.71% of initial]
[Iter 580/20000] Loss: 0.0114191 (Best: 0.0104257 @iter578) ([92m↓3.60%[0m) [4.54% of initial]
[Iter 590/20000] Loss: 0.0115391 (Best: 0.0104170 @iter583) ([91m↑1.05%[0m) [4.58% of initial]
Iter:599, L1 loss=0.006833, Total loss=0.01207, Time:37
[Iter 600/20000] Loss: 0.0112405 (Best: 0.0100180 @iter598) ([92m↓2.59%[0m) [4.47% of initial]
[Iter 610/20000] Loss: 0.0225141 (Best: 0.0100180 @iter598) ([91m↑100.30%[0m) [8.94% of initial]
[Iter 620/20000] Loss: 0.0143803 (Best: 0.0100180 @iter598) ([92m↓36.13%[0m) [5.71% of initial]
[Iter 630/20000] Loss: 0.0122922 (Best: 0.0100180 @iter598) ([92m↓14.52%[0m) [4.88% of initial]
[Iter 640/20000] Loss: 0.0103656 (Best: 0.0095626 @iter640) ([92m↓15.67%[0m) [4.12% of initial]
[Iter 650/20000] Loss: 0.0104669 (Best: 0.0091887 @iter646) ([91m↑0.98%[0m) [4.16% of initial]
[Iter 660/20000] Loss: 0.0100819 (Best: 0.0088939 @iter655) ([92m↓3.68%[0m) [4.01% of initial]
[Iter 670/20000] Loss: 0.0094570 (Best: 0.0085402 @iter667) ([92m↓6.20%[0m) [3.76% of initial]
[Iter 680/20000] Loss: 0.0088735 (Best: 0.0082855 @iter680) ([92m↓6.17%[0m) [3.53% of initial]
[Iter 690/20000] Loss: 0.0090853 (Best: 0.0079382 @iter682) ([91m↑2.39%[0m) [3.61% of initial]
Iter:699, L1 loss=0.005538, Total loss=0.009572, Time:25
[Iter 700/20000] Loss: 0.0088272 (Best: 0.0079219 @iter695) ([92m↓2.84%[0m) [3.51% of initial]
[Iter 710/20000] Loss: 0.0083920 (Best: 0.0077878 @iter703) ([92m↓4.93%[0m) [3.33% of initial]
[Iter 720/20000] Loss: 0.0083278 (Best: 0.0076351 @iter715) ([92m↓0.77%[0m) [3.31% of initial]
[Iter 730/20000] Loss: 0.0082977 (Best: 0.0070962 @iter727) ([92m↓0.36%[0m) [3.30% of initial]
[Iter 740/20000] Loss: 0.0083088 (Best: 0.0070962 @iter727) ([91m↑0.13%[0m) [3.30% of initial]
[Iter 750/20000] Loss: 0.0079249 (Best: 0.0067933 @iter748) ([92m↓4.62%[0m) [3.15% of initial]
[Iter 760/20000] Loss: 0.0073363 (Best: 0.0067933 @iter748) ([92m↓7.43%[0m) [2.91% of initial]
[Iter 770/20000] Loss: 0.0074323 (Best: 0.0067933 @iter748) ([91m↑1.31%[0m) [2.95% of initial]
[Iter 780/20000] Loss: 0.0076575 (Best: 0.0065820 @iter775) ([91m↑3.03%[0m) [3.04% of initial]
[Iter 790/20000] Loss: 0.0074364 (Best: 0.0064685 @iter787) ([92m↓2.89%[0m) [2.95% of initial]
Iter:799, L1 loss=0.004868, Total loss=0.008076, Time:25
[Iter 800/20000] Loss: 0.0072710 (Best: 0.0064685 @iter787) ([92m↓2.22%[0m) [2.89% of initial]
[Iter 810/20000] Loss: 0.0157431 (Best: 0.0064685 @iter787) ([91m↑116.52%[0m) [6.25% of initial]
[Iter 820/20000] Loss: 0.0104173 (Best: 0.0064685 @iter787) ([92m↓33.83%[0m) [4.14% of initial]
[Iter 830/20000] Loss: 0.0085758 (Best: 0.0064685 @iter787) ([92m↓17.68%[0m) [3.41% of initial]
[Iter 840/20000] Loss: 0.0079110 (Best: 0.0064685 @iter787) ([92m↓7.75%[0m) [3.14% of initial]
[Iter 850/20000] Loss: 0.0073993 (Best: 0.0064685 @iter787) ([92m↓6.47%[0m) [2.94% of initial]
[Iter 860/20000] Loss: 0.0069849 (Best: 0.0062559 @iter859) ([92m↓5.60%[0m) [2.78% of initial]
[Iter 870/20000] Loss: 0.0066165 (Best: 0.0060454 @iter862) ([92m↓5.27%[0m) [2.63% of initial]
[Iter 880/20000] Loss: 0.0065749 (Best: 0.0058777 @iter875) ([92m↓0.63%[0m) [2.61% of initial]
[Iter 890/20000] Loss: 0.0062034 (Best: 0.0056501 @iter884) ([92m↓5.65%[0m) [2.46% of initial]
Iter:899, L1 loss=0.003585, Total loss=0.005532, Time:32
[Iter 900/20000] Loss: 0.0063808 (Best: 0.0055321 @iter899) ([91m↑2.86%[0m) [2.54% of initial]
[Iter 910/20000] Loss: 0.0064705 (Best: 0.0054490 @iter907) ([91m↑1.41%[0m) [2.57% of initial]
[Iter 920/20000] Loss: 0.0059085 (Best: 0.0052405 @iter919) ([92m↓8.69%[0m) [2.35% of initial]
[Iter 930/20000] Loss: 0.0061337 (Best: 0.0052321 @iter928) ([91m↑3.81%[0m) [2.44% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 940/20000] Loss: 0.0061548 (Best: 0.0052066 @iter938) ([91m↑0.34%[0m) [2.45% of initial]
[Iter 950/20000] Loss: 0.0057773 (Best: 0.0051259 @iter946) ([92m↓6.13%[0m) [2.30% of initial]
[Iter 960/20000] Loss: 0.0058813 (Best: 0.0051259 @iter946) ([91m↑1.80%[0m) [2.34% of initial]
[Iter 970/20000] Loss: 0.0059058 (Best: 0.0051259 @iter946) ([91m↑0.42%[0m) [2.35% of initial]
[Iter 980/20000] Loss: 0.0060445 (Best: 0.0051259 @iter946) ([91m↑2.35%[0m) [2.40% of initial]
[Iter 990/20000] Loss: 0.0061017 (Best: 0.0051259 @iter946) ([91m↑0.95%[0m) [2.42% of initial]
Iter:999, L1 loss=0.004346, Total loss=0.006812, Time:37
[Iter 1000/20000] Loss: 0.0063517 (Best: 0.0051259 @iter946) ([91m↑4.10%[0m) [2.52% of initial]
Pruning 1010 points (7.3%) from gaussian0 at iteration 1000
Pruning 1028 points (7.4%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0146333 (Best: 0.0051259 @iter946) ([91m↑130.39%[0m) [5.81% of initial]
[Iter 1020/20000] Loss: 0.0101809 (Best: 0.0051259 @iter946) ([92m↓30.43%[0m) [4.04% of initial]
[Iter 1030/20000] Loss: 0.0082081 (Best: 0.0051259 @iter946) ([92m↓19.38%[0m) [3.26% of initial]
[Iter 1040/20000] Loss: 0.0073989 (Best: 0.0051259 @iter946) ([92m↓9.86%[0m) [2.94% of initial]
[Iter 1050/20000] Loss: 0.0070249 (Best: 0.0051259 @iter946) ([92m↓5.06%[0m) [2.79% of initial]
[Iter 1060/20000] Loss: 0.0065922 (Best: 0.0051259 @iter946) ([92m↓6.16%[0m) [2.62% of initial]
[Iter 1070/20000] Loss: 0.0065267 (Best: 0.0051259 @iter946) ([92m↓0.99%[0m) [2.59% of initial]
[Iter 1080/20000] Loss: 0.0061096 (Best: 0.0051259 @iter946) ([92m↓6.39%[0m) [2.43% of initial]
[Iter 1090/20000] Loss: 0.0060898 (Best: 0.0051259 @iter946) ([92m↓0.32%[0m) [2.42% of initial]
Iter:1099, L1 loss=0.003962, Total loss=0.006144, Time:33
[Iter 1100/20000] Loss: 0.0059245 (Best: 0.0051259 @iter946) ([92m↓2.71%[0m) [2.35% of initial]
[Iter 1110/20000] Loss: 0.0058474 (Best: 0.0051259 @iter946) ([92m↓1.30%[0m) [2.32% of initial]
[Iter 1120/20000] Loss: 0.0057980 (Best: 0.0050241 @iter1117) ([92m↓0.84%[0m) [2.30% of initial]
[Iter 1130/20000] Loss: 0.0058676 (Best: 0.0050241 @iter1117) ([91m↑1.20%[0m) [2.33% of initial]
[Iter 1140/20000] Loss: 0.0054587 (Best: 0.0048995 @iter1135) ([92m↓6.97%[0m) [2.17% of initial]
[Iter 1150/20000] Loss: 0.0051672 (Best: 0.0047995 @iter1145) ([92m↓5.34%[0m) [2.05% of initial]
[Iter 1160/20000] Loss: 0.0056682 (Best: 0.0047995 @iter1145) ([91m↑9.70%[0m) [2.25% of initial]
[Iter 1170/20000] Loss: 0.0053753 (Best: 0.0047995 @iter1145) ([92m↓5.17%[0m) [2.14% of initial]
[Iter 1180/20000] Loss: 0.0050425 (Best: 0.0047210 @iter1180) ([92m↓6.19%[0m) [2.00% of initial]
[Iter 1190/20000] Loss: 0.0053101 (Best: 0.0046112 @iter1186) ([91m↑5.31%[0m) [2.11% of initial]
Iter:1199, L1 loss=0.003694, Total loss=0.005546, Time:32
[Iter 1200/20000] Loss: 0.0052645 (Best: 0.0045622 @iter1195) ([92m↓0.86%[0m) [2.09% of initial]
[Iter 1210/20000] Loss: 0.0120844 (Best: 0.0045622 @iter1195) ([91m↑129.55%[0m) [4.80% of initial]
[Iter 1220/20000] Loss: 0.0078772 (Best: 0.0045622 @iter1195) ([92m↓34.81%[0m) [3.13% of initial]
[Iter 1230/20000] Loss: 0.0065985 (Best: 0.0045622 @iter1195) ([92m↓16.23%[0m) [2.62% of initial]
[Iter 1240/20000] Loss: 0.0061404 (Best: 0.0045622 @iter1195) ([92m↓6.94%[0m) [2.44% of initial]
[Iter 1250/20000] Loss: 0.0054051 (Best: 0.0045622 @iter1195) ([92m↓11.98%[0m) [2.15% of initial]
[Iter 1260/20000] Loss: 0.0051896 (Best: 0.0044248 @iter1258) ([92m↓3.99%[0m) [2.06% of initial]
[Iter 1270/20000] Loss: 0.0047889 (Best: 0.0044154 @iter1269) ([92m↓7.72%[0m) [1.90% of initial]
[Iter 1280/20000] Loss: 0.0049932 (Best: 0.0041398 @iter1273) ([91m↑4.27%[0m) [1.98% of initial]
[Iter 1290/20000] Loss: 0.0048838 (Best: 0.0039792 @iter1288) ([92m↓2.19%[0m) [1.94% of initial]
Iter:1299, L1 loss=0.002998, Total loss=0.004236, Time:36
[Iter 1300/20000] Loss: 0.0045429 (Best: 0.0039792 @iter1288) ([92m↓6.98%[0m) [1.80% of initial]
[Iter 1310/20000] Loss: 0.0046316 (Best: 0.0039762 @iter1301) ([91m↑1.95%[0m) [1.84% of initial]
[Iter 1320/20000] Loss: 0.0044608 (Best: 0.0037293 @iter1319) ([92m↓3.69%[0m) [1.77% of initial]
[Iter 1330/20000] Loss: 0.0044455 (Best: 0.0036444 @iter1321) ([92m↓0.34%[0m) [1.77% of initial]
[Iter 1340/20000] Loss: 0.0042247 (Best: 0.0036444 @iter1321) ([92m↓4.97%[0m) [1.68% of initial]
[Iter 1350/20000] Loss: 0.0043031 (Best: 0.0036444 @iter1321) ([91m↑1.85%[0m) [1.71% of initial]
[Iter 1360/20000] Loss: 0.0043057 (Best: 0.0036444 @iter1321) ([91m↑0.06%[0m) [1.71% of initial]
[Iter 1370/20000] Loss: 0.0041722 (Best: 0.0036444 @iter1321) ([92m↓3.10%[0m) [1.66% of initial]
[Iter 1380/20000] Loss: 0.0043207 (Best: 0.0036161 @iter1375) ([91m↑3.56%[0m) [1.72% of initial]
[Iter 1390/20000] Loss: 0.0041506 (Best: 0.0036161 @iter1375) ([92m↓3.94%[0m) [1.65% of initial]
Iter:1399, L1 loss=0.002503, Total loss=0.003411, Time:34
[Iter 1400/20000] Loss: 0.0039089 (Best: 0.0034114 @iter1399) ([92m↓5.82%[0m) [1.55% of initial]
[Iter 1410/20000] Loss: 0.0097815 (Best: 0.0034114 @iter1399) ([91m↑150.23%[0m) [3.89% of initial]
[Iter 1420/20000] Loss: 0.0067733 (Best: 0.0034114 @iter1399) ([92m↓30.75%[0m) [2.69% of initial]
[Iter 1430/20000] Loss: 0.0055525 (Best: 0.0034114 @iter1399) ([92m↓18.02%[0m) [2.21% of initial]
[Iter 1440/20000] Loss: 0.0049161 (Best: 0.0034114 @iter1399) ([92m↓11.46%[0m) [1.95% of initial]
[Iter 1450/20000] Loss: 0.0040682 (Best: 0.0034114 @iter1399) ([92m↓17.25%[0m) [1.62% of initial]
[Iter 1460/20000] Loss: 0.0041023 (Best: 0.0034114 @iter1399) ([91m↑0.84%[0m) [1.63% of initial]
[Iter 1470/20000] Loss: 0.0039174 (Best: 0.0034114 @iter1399) ([92m↓4.51%[0m) [1.56% of initial]
[Iter 1480/20000] Loss: 0.0036880 (Best: 0.0032260 @iter1480) ([92m↓5.86%[0m) [1.47% of initial]
[Iter 1490/20000] Loss: 0.0036553 (Best: 0.0032260 @iter1480) ([92m↓0.89%[0m) [1.45% of initial]
Iter:1499, L1 loss=0.002745, Total loss=0.003846, Time:34
[Iter 1500/20000] Loss: 0.0036097 (Best: 0.0032260 @iter1480) ([92m↓1.25%[0m) [1.43% of initial]
Pruning 604 points (2.4%) from gaussian0 at iteration 1500
Pruning 720 points (2.9%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0048582 (Best: 0.0032260 @iter1480) ([91m↑34.59%[0m) [1.93% of initial]
[Iter 1520/20000] Loss: 0.0041836 (Best: 0.0032260 @iter1480) ([92m↓13.89%[0m) [1.66% of initial]
[Iter 1530/20000] Loss: 0.0039639 (Best: 0.0032260 @iter1480) ([92m↓5.25%[0m) [1.57% of initial]
[Iter 1540/20000] Loss: 0.0037386 (Best: 0.0032260 @iter1480) ([92m↓5.68%[0m) [1.49% of initial]
[Iter 1550/20000] Loss: 0.0034510 (Best: 0.0031626 @iter1543) ([92m↓7.69%[0m) [1.37% of initial]
[Iter 1560/20000] Loss: 0.0036226 (Best: 0.0030113 @iter1558) ([91m↑4.97%[0m) [1.44% of initial]
[Iter 1570/20000] Loss: 0.0032347 (Best: 0.0029286 @iter1569) ([92m↓10.71%[0m) [1.29% of initial]
[Iter 1580/20000] Loss: 0.0032604 (Best: 0.0027759 @iter1573) ([91m↑0.79%[0m) [1.30% of initial]
[Iter 1590/20000] Loss: 0.0031891 (Best: 0.0027759 @iter1573) ([92m↓2.19%[0m) [1.27% of initial]
Iter:1599, L1 loss=0.00289, Total loss=0.003754, Time:35
[Iter 1600/20000] Loss: 0.0034631 (Best: 0.0027759 @iter1573) ([91m↑8.59%[0m) [1.38% of initial]
[Iter 1610/20000] Loss: 0.0095259 (Best: 0.0027759 @iter1573) ([91m↑175.07%[0m) [3.78% of initial]
[Iter 1620/20000] Loss: 0.0064225 (Best: 0.0027759 @iter1573) ([92m↓32.58%[0m) [2.55% of initial]
[Iter 1630/20000] Loss: 0.0048507 (Best: 0.0027759 @iter1573) ([92m↓24.47%[0m) [1.93% of initial]
[Iter 1640/20000] Loss: 0.0042981 (Best: 0.0027759 @iter1573) ([92m↓11.39%[0m) [1.71% of initial]
[Iter 1650/20000] Loss: 0.0039175 (Best: 0.0027759 @iter1573) ([92m↓8.86%[0m) [1.56% of initial]
[Iter 1660/20000] Loss: 0.0034265 (Best: 0.0027759 @iter1573) ([92m↓12.53%[0m) [1.36% of initial]
[Iter 1670/20000] Loss: 0.0033045 (Best: 0.0027759 @iter1573) ([92m↓3.56%[0m) [1.31% of initial]
[Iter 1680/20000] Loss: 0.0033663 (Best: 0.0027759 @iter1573) ([91m↑1.87%[0m) [1.34% of initial]
[Iter 1690/20000] Loss: 0.0034254 (Best: 0.0027759 @iter1573) ([91m↑1.75%[0m) [1.36% of initial]
Iter:1699, L1 loss=0.002564, Total loss=0.003385, Time:32
[Iter 1700/20000] Loss: 0.0031361 (Best: 0.0027759 @iter1573) ([92m↓8.44%[0m) [1.25% of initial]
[Iter 1710/20000] Loss: 0.0033086 (Best: 0.0027759 @iter1573) ([91m↑5.50%[0m) [1.31% of initial]
[Iter 1720/20000] Loss: 0.0028434 (Best: 0.0026620 @iter1720) ([92m↓14.06%[0m) [1.13% of initial]
[Iter 1730/20000] Loss: 0.0029370 (Best: 0.0026577 @iter1726) ([91m↑3.29%[0m) [1.17% of initial]
[Iter 1740/20000] Loss: 0.0029047 (Best: 0.0026080 @iter1738) ([92m↓1.10%[0m) [1.15% of initial]
[Iter 1750/20000] Loss: 0.0026589 (Best: 0.0024230 @iter1750) ([92m↓8.46%[0m) [1.06% of initial]
[Iter 1760/20000] Loss: 0.0028797 (Best: 0.0024230 @iter1750) ([91m↑8.31%[0m) [1.14% of initial]
[Iter 1770/20000] Loss: 0.0027657 (Best: 0.0024095 @iter1762) ([92m↓3.96%[0m) [1.10% of initial]
[Iter 1780/20000] Loss: 0.0027736 (Best: 0.0024095 @iter1762) ([91m↑0.29%[0m) [1.10% of initial]
[Iter 1790/20000] Loss: 0.0025155 (Best: 0.0022025 @iter1789) ([92m↓9.31%[0m) [1.00% of initial]
Iter:1799, L1 loss=0.001881, Total loss=0.002382, Time:36
[Iter 1800/20000] Loss: 0.0025844 (Best: 0.0022025 @iter1789) ([91m↑2.74%[0m) [1.03% of initial]
[Iter 1810/20000] Loss: 0.0086980 (Best: 0.0022025 @iter1789) ([91m↑236.56%[0m) [3.46% of initial]
[Iter 1820/20000] Loss: 0.0051362 (Best: 0.0022025 @iter1789) ([92m↓40.95%[0m) [2.04% of initial]
[Iter 1830/20000] Loss: 0.0042763 (Best: 0.0022025 @iter1789) ([92m↓16.74%[0m) [1.70% of initial]
[Iter 1840/20000] Loss: 0.0031550 (Best: 0.0022025 @iter1789) ([92m↓26.22%[0m) [1.25% of initial]
[Iter 1850/20000] Loss: 0.0029689 (Best: 0.0022025 @iter1789) ([92m↓5.90%[0m) [1.18% of initial]
[Iter 1860/20000] Loss: 0.0027380 (Best: 0.0022025 @iter1789) ([92m↓7.78%[0m) [1.09% of initial]
[Iter 1870/20000] Loss: 0.0025546 (Best: 0.0021947 @iter1867) ([92m↓6.70%[0m) [1.01% of initial]
[Iter 1880/20000] Loss: 0.0024465 (Best: 0.0021947 @iter1867) ([92m↓4.23%[0m) [0.97% of initial]
[Iter 1890/20000] Loss: 0.0022406 (Best: 0.0020979 @iter1890) ([92m↓8.42%[0m) [0.89% of initial]
Iter:1899, L1 loss=0.001902, Total loss=0.002319, Time:37
[Iter 1900/20000] Loss: 0.0023442 (Best: 0.0019694 @iter1891) ([91m↑4.62%[0m) [0.93% of initial]
[Iter 1910/20000] Loss: 0.0023727 (Best: 0.0019670 @iter1903) ([91m↑1.22%[0m) [0.94% of initial]
[Iter 1920/20000] Loss: 0.0024347 (Best: 0.0019670 @iter1903) ([91m↑2.61%[0m) [0.97% of initial]
[Iter 1930/20000] Loss: 0.0020787 (Best: 0.0019060 @iter1930) ([92m↓14.62%[0m) [0.83% of initial]
[Iter 1940/20000] Loss: 0.0021874 (Best: 0.0018365 @iter1939) ([91m↑5.23%[0m) [0.87% of initial]
[Iter 1950/20000] Loss: 0.0022995 (Best: 0.0018365 @iter1939) ([91m↑5.12%[0m) [0.91% of initial]
[Iter 1960/20000] Loss: 0.0021271 (Best: 0.0018365 @iter1939) ([92m↓7.50%[0m) [0.85% of initial]
[Iter 1970/20000] Loss: 0.0020115 (Best: 0.0017892 @iter1963) ([92m↓5.44%[0m) [0.80% of initial]
[Iter 1980/20000] Loss: 0.0023017 (Best: 0.0017892 @iter1963) ([91m↑14.43%[0m) [0.91% of initial]
[Iter 1990/20000] Loss: 0.0020440 (Best: 0.0017892 @iter1963) ([92m↓11.20%[0m) [0.81% of initial]
Iter:1999, L1 loss=0.001666, Total loss=0.001881, Time:43
[Iter 2000/20000] Loss: 0.0021344 (Best: 0.0016857 @iter1996) ([91m↑4.42%[0m) [0.85% of initial]
Testing Speed: 99.9206695962535 fps
Testing Time: 0.5003969669342041 s

[ITER 2000] Evaluating test: SSIM = 0.8582041430473328, PSNR = 17.65983522415161
Testing Speed: 93.55533580674661 fps
Testing Time: 0.03206658363342285 s

[ITER 2000] Evaluating train: SSIM = 0.9999534090360005, PSNR = 48.871744791666664
Iter:2000, total_points:42973
Pruning 641 points (1.2%) from gaussian0 at iteration 2000
Pruning 636 points (1.2%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.0079006 (Best: 0.0016857 @iter1996) ([91m↑270.16%[0m) [3.14% of initial]
[Iter 2020/20000] Loss: 0.0051636 (Best: 0.0016857 @iter1996) ([92m↓34.64%[0m) [2.05% of initial]
[Iter 2030/20000] Loss: 0.0037526 (Best: 0.0016857 @iter1996) ([92m↓27.33%[0m) [1.49% of initial]
[Iter 2040/20000] Loss: 0.0032083 (Best: 0.0016857 @iter1996) ([92m↓14.50%[0m) [1.27% of initial]
[Iter 2050/20000] Loss: 0.0028016 (Best: 0.0016857 @iter1996) ([92m↓12.68%[0m) [1.11% of initial]
[Iter 2060/20000] Loss: 0.0024211 (Best: 0.0016857 @iter1996) ([92m↓13.58%[0m) [0.96% of initial]
[Iter 2070/20000] Loss: 0.0025614 (Best: 0.0016857 @iter1996) ([91m↑5.80%[0m) [1.02% of initial]
[Iter 2080/20000] Loss: 0.0024374 (Best: 0.0016857 @iter1996) ([92m↓4.84%[0m) [0.97% of initial]
[Iter 2090/20000] Loss: 0.0023848 (Best: 0.0016857 @iter1996) ([92m↓2.16%[0m) [0.95% of initial]
Iter:2099, L1 loss=0.001958, Total loss=0.002288, Time:31
[Iter 2100/20000] Loss: 0.0022359 (Best: 0.0016857 @iter1996) ([92m↓6.25%[0m) [0.89% of initial]
[Iter 2110/20000] Loss: 0.0021936 (Best: 0.0016857 @iter1996) ([92m↓1.89%[0m) [0.87% of initial]
[Iter 2120/20000] Loss: 0.0019518 (Best: 0.0016857 @iter1996) ([92m↓11.02%[0m) [0.78% of initial]
[Iter 2130/20000] Loss: 0.0020943 (Best: 0.0016857 @iter1996) ([91m↑7.30%[0m) [0.83% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 2140/20000] Loss: 0.0022125 (Best: 0.0016857 @iter1996) ([91m↑5.64%[0m) [0.88% of initial]
[Iter 2150/20000] Loss: 0.0022169 (Best: 0.0016857 @iter1996) ([91m↑0.20%[0m) [0.88% of initial]
[Iter 2160/20000] Loss: 0.0020213 (Best: 0.0016857 @iter1996) ([92m↓8.82%[0m) [0.80% of initial]
[Iter 1] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2170/20000] Loss: 0.0020578 (Best: 0.0016857 @iter1996) ([91m↑1.81%[0m) [0.82% of initial]
[Iter 3] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 3] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 4] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 4] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 5] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 5] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 6] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 6] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 8] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 8] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 9] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 9] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 10] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 10] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 2180/20000] Loss: 0.0017955 (Best: 0.0016740 @iter2180) ([92m↓12.75%[0m) [0.71% of initial]
[Iter 11] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 11] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 12] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 12] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 13] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 13] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 14] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 14] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 15] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 15] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 16] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 16] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 17] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 17] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 18] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 18] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2190/20000] Loss: 0.0020421 (Best: 0.0016740 @iter2180) ([91m↑13.73%[0m) [0.81% of initial]
[Iter 19] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 19] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 20] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 20] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 21] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 21] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 22] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 22] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 23] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 23] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 24] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 24] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 25] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 25] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2199, L1 loss=0.001724, Total loss=0.001948, Time:51
[Iter 26] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 26] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2200/20000] Loss: 0.0020159 (Best: 0.0016685 @iter2191) ([92m↓1.28%[0m) [0.80% of initial]
[Iter 27] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 27] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 28] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 28] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 29] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 29] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 30] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 30] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 30/20000] Loss: 0.1374905 (Best: 0.1327883 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 31] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 31] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 32] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 32] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 33] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 33] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 34] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 34] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 35] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 35] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 36] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 36] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 37] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 37] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 38] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2210/20000] Loss: 0.0091341 (Best: 0.0016685 @iter2191) ([91m↑353.09%[0m) [3.63% of initial]
[Iter 38] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 39] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 39] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 40] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 40] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 40/20000] Loss: 0.1123920 (Best: 0.1098367 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 41] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 41] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 42] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 42] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 43] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 43] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 44] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 44] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 45] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 45] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 46] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 46] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2220/20000] Loss: 0.0052692 (Best: 0.0016685 @iter2191) ([92m↓42.31%[0m) [2.09% of initial]
[Iter 47] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 47] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 48] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 48] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 49] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 49] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 50] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 50] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 50/20000] Loss: 0.0993464 (Best: 0.0965471 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 51] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 51] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 52] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 52] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 53] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 53] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 54] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2230/20000] Loss: 0.0033481 (Best: 0.0016685 @iter2191) ([92m↓36.46%[0m) [1.33% of initial]
[Iter 54] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 55] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 55] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 56] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 56] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 57] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 57] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 58] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 58] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 59] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 59] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 60] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 60] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 60/20000] Loss: 0.0936772 (Best: 0.0908538 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 61] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 61] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 62] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 62] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2240/20000] Loss: 0.0027508 (Best: 0.0016685 @iter2191) ([92m↓17.84%[0m) [1.09% of initial]
[Iter 63] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 63] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 64] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 64] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 65] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 65] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 66] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 66] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 67] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 67] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 68] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 68] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 69] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 69] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 70] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 70] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 70/20000] Loss: 0.0884494 (Best: 0.0869375 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 2250/20000] Loss: 0.0025504 (Best: 0.0016685 @iter2191) ([92m↓7.28%[0m) [1.01% of initial]
[Iter 71] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 71] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 72] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 72] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 73] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 73] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 74] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 74] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 75] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 75] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 76] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 76] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 77] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 77] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 78] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 78] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2260/20000] Loss: 0.0021372 (Best: 0.0016685 @iter2191) ([92m↓16.20%[0m) [0.85% of initial]
[Iter 79] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 79] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 80] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 80] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 80/20000] Loss: 0.0851925 (Best: 0.0831073 @iter80) ([92m↓3.68%[0m) [33.85% of initial]
[Iter 81] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 81] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 82] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 82] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 83] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 83] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 84] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 84] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 85] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 85] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 86] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 86] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2270/20000] Loss: 0.0021941 (Best: 0.0016685 @iter2191) ([91m↑2.66%[0m) [0.87% of initial]
[Iter 87] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 87] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 88] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 88] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 89] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 89] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 90] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 90] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 90/20000] Loss: 0.0824137 (Best: 0.0801581 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
[Iter 91] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 91] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 92] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 92] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 93] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 93] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 94] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 94] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2280/20000] Loss: 0.0018408 (Best: 0.0016685 @iter2191) ([92m↓16.10%[0m) [0.73% of initial]
[Iter 95] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 95] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 96] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 96] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 97] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 97] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 98] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 98] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 99] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 99] Co-reg loss between gs1 and gs0: 0.0000000
Iter:99, L1 loss=0.05724, Total loss=0.07876, Time:65
[Iter 100] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 100] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 100/20000] Loss: 0.0786614 (Best: 0.0766153 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 101] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 101] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 102] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 102] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2290/20000] Loss: 0.0018004 (Best: 0.0015678 @iter2285) ([92m↓2.19%[0m) [0.72% of initial]
[Iter 103] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 103] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 104] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 104] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 105] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 105] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 106] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 106] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 107] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 107] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 108] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 108] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 109] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 109] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 110] Co-reg loss between gs0 and gs1: 0.0000000
Iter:2299, L1 loss=0.001556, Total loss=0.001765, Time:46
[Iter 110] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 110/20000] Loss: 0.0753325 (Best: 0.0731350 @iter106) ([92m↓4.23%[0m) [29.93% of initial]
[Iter 2300/20000] Loss: 0.0020476 (Best: 0.0015678 @iter2285) ([91m↑13.73%[0m) [0.81% of initial]
[Iter 111] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 111] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 112] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 112] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 113] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 113] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 114] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 114] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 115] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 115] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 116] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 116] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 117] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 117] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 118] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 118] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 119] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 119] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2310/20000] Loss: 0.0019116 (Best: 0.0015678 @iter2285) ([92m↓6.64%[0m) [0.76% of initial]
[Iter 120] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 120] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 120/20000] Loss: 0.0714376 (Best: 0.0685677 @iter118) ([92m↓5.17%[0m) [28.38% of initial]
[Iter 121] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 121] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 122] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 122] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 123] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 123] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 124] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 124] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 125] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 125] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 126] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 126] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 127] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 127] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2320/20000] Loss: 0.0016879 (Best: 0.0015663 @iter2320) ([92m↓11.70%[0m) [0.67% of initial]
[Iter 128] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 128] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 129] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 129] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 130] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 130] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 130/20000] Loss: 0.0666996 (Best: 0.0641974 @iter130) ([92m↓6.63%[0m) [26.50% of initial]
[Iter 131] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 131] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 132] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 132] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 133] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 133] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 134] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 134] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 135] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 135] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2330/20000] Loss: 0.0016624 (Best: 0.0014956 @iter2326) ([92m↓1.51%[0m) [0.66% of initial]
[Iter 136] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 136] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 137] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 137] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 138] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 138] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 139] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 139] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 140] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 140] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 140/20000] Loss: 0.0635290 (Best: 0.0612791 @iter140) ([92m↓4.75%[0m) [25.24% of initial]
[Iter 141] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 141] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 142] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 142] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 143] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 143] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2340/20000] Loss: 0.0017298 (Best: 0.0014680 @iter2338) ([91m↑4.06%[0m) [0.69% of initial]
[Iter 144] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 144] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 145] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 145] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 146] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 146] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 147] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 147] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 148] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 148] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 149] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 149] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 150] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 150] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 150/20000] Loss: 0.0612526 (Best: 0.0583600 @iter148) ([92m↓3.58%[0m) [24.34% of initial]
[Iter 151] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 151] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 152] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 152] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2350/20000] Loss: 0.0018512 (Best: 0.0014680 @iter2338) ([91m↑7.02%[0m) [0.74% of initial]
[Iter 153] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 153] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 154] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 154] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 155] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 155] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 156] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 156] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 157] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 157] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 158] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 158] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 159] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 159] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 160] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 160] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 160/20000] Loss: 0.0590196 (Best: 0.0559246 @iter157) ([92m↓3.65%[0m) [23.45% of initial]
[Iter 2360/20000] Loss: 0.0016543 (Best: 0.0014259 @iter2359) ([92m↓10.64%[0m) [0.66% of initial]
[Iter 161] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 161] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 162] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 162] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 163] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 163] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 164] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 164] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 165] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 165] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 166] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 166] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 167] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 167] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 168] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 168] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2370/20000] Loss: 0.0017602 (Best: 0.0014259 @iter2359) ([91m↑6.40%[0m) [0.70% of initial]
[Iter 169] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 169] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 170] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 170] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 170/20000] Loss: 0.0563429 (Best: 0.0534903 @iter167) ([92m↓4.54%[0m) [22.38% of initial]
[Iter 171] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 171] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 172] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 172] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 173] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 173] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 174] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 174] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 175] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 175] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 176] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 176] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 177] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 177] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2380/20000] Loss: 0.0017999 (Best: 0.0014259 @iter2359) ([91m↑2.26%[0m) [0.72% of initial]
[Iter 178] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 178] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 179] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 179] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 180] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 180] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 180/20000] Loss: 0.0523043 (Best: 0.0499750 @iter179) ([92m↓7.17%[0m) [20.78% of initial]
[Iter 181] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 181] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 182] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 182] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 183] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 183] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 184] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 184] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 185] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 185] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2390/20000] Loss: 0.0019501 (Best: 0.0014259 @iter2359) ([91m↑8.35%[0m) [0.77% of initial]
[Iter 186] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 186] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 187] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 187] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 188] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 188] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 189] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 189] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 190] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 190] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 190/20000] Loss: 0.0495141 (Best: 0.0477833 @iter188) ([92m↓5.33%[0m) [19.67% of initial]
[Iter 191] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 191] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 192] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 192] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 193] Co-reg loss between gs0 and gs1: 0.0000000
Iter:2399, L1 loss=0.001496, Total loss=0.001581, Time:52
[Iter 193] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2400/20000] Loss: 0.0016862 (Best: 0.0014259 @iter2359) ([92m↓13.53%[0m) [0.67% of initial]
[Iter 194] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 194] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 195] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 195] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 196] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 196] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 197] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 197] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 198] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 198] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 199] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 199] Co-reg loss between gs1 and gs0: 0.0000000
Iter:199, L1 loss=0.03442, Total loss=0.04968, Time:48
[Iter 200] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 200] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 200/20000] Loss: 0.0477601 (Best: 0.0456115 @iter198) ([92m↓3.54%[0m) [18.97% of initial]
[Iter 201] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 201] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 202] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 202] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 203] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 203] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 204] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 204] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 205] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 205] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 206] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 206] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2410/20000] Loss: 0.0070390 (Best: 0.0014259 @iter2359) ([91m↑317.45%[0m) [2.80% of initial]
[Iter 207] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 207] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 208] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 208] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 209] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 209] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 210] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 210] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 210/20000] Loss: 0.0450665 (Best: 0.0427731 @iter209) ([92m↓5.64%[0m) [17.90% of initial]
[Iter 211] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 211] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 212] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 212] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 213] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 213] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 214] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 214] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2420/20000] Loss: 0.0040767 (Best: 0.0014259 @iter2359) ([92m↓42.08%[0m) [1.62% of initial]
[Iter 215] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 215] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 216] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 216] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 217] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 217] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 218] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 218] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 219] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 219] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 220] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 220] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 220/20000] Loss: 0.0441127 (Best: 0.0412389 @iter219) ([92m↓2.12%[0m) [17.53% of initial]
[Iter 221] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 221] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 222] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 222] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 223] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 223] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2430/20000] Loss: 0.0028914 (Best: 0.0014259 @iter2359) ([92m↓29.08%[0m) [1.15% of initial]
[Iter 224] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 224] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 225] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 225] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 226] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 226] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 227] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 227] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 228] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 228] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 229] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 229] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 230] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 230] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 230/20000] Loss: 0.0424138 (Best: 0.0399610 @iter227) ([92m↓3.85%[0m) [16.85% of initial]
[Iter 231] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 231] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2440/20000] Loss: 0.0024069 (Best: 0.0014259 @iter2359) ([92m↓16.76%[0m) [0.96% of initial]
[Iter 232] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 232] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 233] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 233] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 234] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 234] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 235] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 235] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 236] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 236] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 237] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 237] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 238] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 238] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 239] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 239] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 240] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2450/20000] Loss: 0.0022848 (Best: 0.0014259 @iter2359) ([92m↓5.07%[0m) [0.91% of initial]
[Iter 240] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 240/20000] Loss: 0.0403140 (Best: 0.0377876 @iter238) ([92m↓4.95%[0m) [16.02% of initial]
[Iter 241] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 241] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 242] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 242] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 243] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 243] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 244] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 244] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 245] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 245] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 246] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 246] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 247] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 247] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 248] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 248] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2460/20000] Loss: 0.0020250 (Best: 0.0014259 @iter2359) ([92m↓11.37%[0m) [0.80% of initial]
[Iter 249] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 249] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 250] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 250] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 250/20000] Loss: 0.0380499 (Best: 0.0363496 @iter248) ([92m↓5.62%[0m) [15.12% of initial]
[Iter 251] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 251] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 252] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 252] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 253] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 253] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 254] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 254] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 255] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 255] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 256] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 256] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 257] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 257] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2470/20000] Loss: 0.0019440 (Best: 0.0014259 @iter2359) ([92m↓4.00%[0m) [0.77% of initial]
[Iter 258] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 258] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 259] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 259] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 260] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 260] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 260/20000] Loss: 0.0359828 (Best: 0.0344057 @iter260) ([92m↓5.43%[0m) [14.30% of initial]
[Iter 261] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 261] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 262] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 262] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 263] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 263] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 264] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 264] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 265] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 265] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2480/20000] Loss: 0.0019679 (Best: 0.0014259 @iter2359) ([91m↑1.23%[0m) [0.78% of initial]
[Iter 266] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 266] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 267] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 267] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 268] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 268] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 269] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 269] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 270] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 270] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 270/20000] Loss: 0.0351316 (Best: 0.0329903 @iter269) ([92m↓2.37%[0m) [13.96% of initial]
[Iter 271] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 271] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 272] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 272] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 273] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 273] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 274] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 274] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2490/20000] Loss: 0.0017769 (Best: 0.0014259 @iter2359) ([92m↓9.70%[0m) [0.71% of initial]
[Iter 275] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 275] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 276] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 276] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 277] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 277] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 278] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 278] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 279] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 279] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 280] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 280] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 280/20000] Loss: 0.0347324 (Best: 0.0319043 @iter277) ([92m↓1.14%[0m) [13.80% of initial]
[Iter 281] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 281] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 282] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 282] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2499, L1 loss=0.001392, Total loss=0.001573, Time:39
[Iter 2500/20000] Loss: 0.0015947 (Best: 0.0014259 @iter2359) ([92m↓10.25%[0m) [0.63% of initial]
[Iter 283] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 283] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 284] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 284] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 285] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 285] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 286] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 286] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 287] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 287] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 288] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 288] Co-reg loss between gs1 and gs0: 0.0000000
Pruning 472 points (0.6%) from gaussian0 at iteration 2500
[Iter 289] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 289] Co-reg loss between gs1 and gs0: 0.0000000
Pruning 478 points (0.6%) from gaussian1 at iteration 2500
[Iter 290] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 290] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 290/20000] Loss: 0.0328383 (Best: 0.0302037 @iter287) ([92m↓5.45%[0m) [13.05% of initial]
[Iter 291] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 291] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 292] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 292] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 293] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 293] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 294] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 294] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 295] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 295] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 296] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 296] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 297] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 297] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 298] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 298] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2510/20000] Loss: 0.0033430 (Best: 0.0014259 @iter2359) ([91m↑109.63%[0m) [1.33% of initial]
[Iter 299] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 299] Co-reg loss between gs1 and gs0: 0.0000000
Iter:299, L1 loss=0.02223, Total loss=0.0333, Time:57
[Iter 300] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 300] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 300/20000] Loss: 0.0307436 (Best: 0.0289348 @iter300) ([92m↓6.38%[0m) [12.21% of initial]
[Iter 301] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 301] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 302] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 302] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 303] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 303] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 304] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 304] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 305] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 305] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 306] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 306] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 307] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 307] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2520/20000] Loss: 0.0022532 (Best: 0.0014259 @iter2359) ([92m↓32.60%[0m) [0.90% of initial]
[Iter 308] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 308] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 309] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 309] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 310] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 310] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 310/20000] Loss: 0.0294082 (Best: 0.0274027 @iter310) ([92m↓4.34%[0m) [11.68% of initial]
[Iter 311] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 311] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 312] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 312] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 313] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 313] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 314] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 314] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 315] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 315] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 316] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2530/20000] Loss: 0.0017058 (Best: 0.0014259 @iter2359) ([92m↓24.30%[0m) [0.68% of initial]
[Iter 316] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 317] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 317] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 318] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 318] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 319] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 319] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 320] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 320] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 320/20000] Loss: 0.0280442 (Best: 0.0266023 @iter320) ([92m↓4.64%[0m) [11.14% of initial]
[Iter 321] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 321] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 322] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 322] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 323] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 323] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 324] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 324] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2540/20000] Loss: 0.0015847 (Best: 0.0014220 @iter2533) ([92m↓7.10%[0m) [0.63% of initial]
[Iter 325] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 325] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 326] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 326] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 327] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 327] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 328] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 328] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 329] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 329] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 330] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 330] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 330/20000] Loss: 0.0275844 (Best: 0.0257278 @iter330) ([92m↓1.64%[0m) [10.96% of initial]
[Iter 331] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 331] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 332] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 332] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 333] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 333] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2550/20000] Loss: 0.0016697 (Best: 0.0012864 @iter2548) ([91m↑5.37%[0m) [0.66% of initial]
[Iter 334] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 334] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 335] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 335] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 336] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 336] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 337] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 337] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 338] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 338] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 339] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 339] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 340] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 340] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 340/20000] Loss: 0.0254726 (Best: 0.0244473 @iter340) ([92m↓7.66%[0m) [10.12% of initial]
[Iter 341] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 341] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2560/20000] Loss: 0.0014265 (Best: 0.0012345 @iter2557) ([92m↓14.57%[0m) [0.57% of initial]
[Iter 342] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 342] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 343] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 343] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 344] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 344] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 345] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 345] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 346] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 346] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 347] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 347] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 348] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 348] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 349] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 349] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 350] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2570/20000] Loss: 0.0016603 (Best: 0.0012345 @iter2557) ([91m↑16.39%[0m) [0.66% of initial]
[Iter 350] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 350/20000] Loss: 0.0263606 (Best: 0.0237824 @iter349) ([91m↑3.49%[0m) [10.47% of initial]
[Iter 351] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 351] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 352] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 352] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 353] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 353] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 354] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 354] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 355] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 355] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 356] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 356] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 357] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 357] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 358] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2580/20000] Loss: 0.0015154 (Best: 0.0012013 @iter2578) ([92m↓8.72%[0m) [0.60% of initial]
[Iter 358] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 359] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 359] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 360] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 360] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 360/20000] Loss: 0.0247253 (Best: 0.0225357 @iter358) ([92m↓6.20%[0m) [9.82% of initial]
[Iter 361] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 361] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 362] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 362] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 363] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 363] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 364] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 364] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 365] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 365] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 366] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 366] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2590/20000] Loss: 0.0015690 (Best: 0.0011996 @iter2584) ([91m↑3.53%[0m) [0.62% of initial]
[Iter 367] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 367] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 368] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 368] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 369] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 369] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 370] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 370] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 370/20000] Loss: 0.0243959 (Best: 0.0220380 @iter368) ([92m↓1.33%[0m) [9.69% of initial]
[Iter 371] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 371] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 372] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 372] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 373] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 373] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 374] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 374] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2599, L1 loss=0.0012, Total loss=0.001236, Time:40
[Iter 375] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2600/20000] Loss: 0.0014560 (Best: 0.0011987 @iter2594) ([92m↓7.20%[0m) [0.58% of initial]
[Iter 375] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 376] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 376] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 377] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 377] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 378] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 378] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 379] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 379] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 380] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 380] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 380/20000] Loss: 0.0221491 (Best: 0.0209649 @iter379) ([92m↓9.21%[0m) [8.80% of initial]
[Iter 381] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 381] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 382] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 382] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 383] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 383] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 384] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 384] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 385] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 385] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 386] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 386] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 387] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2610/20000] Loss: 0.0069934 (Best: 0.0011987 @iter2594) ([91m↑380.32%[0m) [2.78% of initial]
[Iter 387] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 388] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 388] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 389] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 389] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 390] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 390] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 390/20000] Loss: 0.0217574 (Best: 0.0202753 @iter385) ([92m↓1.77%[0m) [8.64% of initial]
[Iter 391] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 391] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 392] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 392] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 393] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 393] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 394] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 394] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 395] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 395] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2620/20000] Loss: 0.0039034 (Best: 0.0011987 @iter2594) ([92m↓44.18%[0m) [1.55% of initial]
[Iter 396] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 396] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 397] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 397] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 398] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 398] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 399] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 399] Co-reg loss between gs1 and gs0: 0.0000000
Iter:399, L1 loss=0.01329, Total loss=0.02123, Time:50
[Iter 400] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 400] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 400/20000] Loss: 0.0205574 (Best: 0.0191277 @iter400) ([92m↓5.52%[0m) [8.17% of initial]
[Iter 401] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 401] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 402] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 402] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 403] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 403] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 404] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 404] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2630/20000] Loss: 0.0025609 (Best: 0.0011987 @iter2594) ([92m↓34.39%[0m) [1.02% of initial]
[Iter 405] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 405] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 406] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 406] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 407] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 407] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 408] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 408] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 409] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 409] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 410] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 410] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 410/20000] Loss: 0.0192991 (Best: 0.0183501 @iter410) ([92m↓6.12%[0m) [7.67% of initial]
[Iter 411] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 411] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 412] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 412] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2640/20000] Loss: 0.0020429 (Best: 0.0011987 @iter2594) ([92m↓20.23%[0m) [0.81% of initial]
[Iter 413] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 413] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 414] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 414] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 415] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 415] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 416] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 416] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 417] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 417] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 418] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 418] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 419] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 419] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 420] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 420] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 420/20000] Loss: 0.0197032 (Best: 0.0175441 @iter418) ([91m↑2.09%[0m) [7.83% of initial]
[Iter 421] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 421] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2650/20000] Loss: 0.0016968 (Best: 0.0011987 @iter2594) ([92m↓16.94%[0m) [0.67% of initial]
[Iter 422] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 422] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 423] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 423] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 424] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 424] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 425] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 425] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 426] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 426] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 427] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 427] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 428] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 428] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 429] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 429] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2660/20000] Loss: 0.0018785 (Best: 0.0011987 @iter2594) ([91m↑10.71%[0m) [0.75% of initial]
[Iter 430] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 430] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 430/20000] Loss: 0.0178200 (Best: 0.0169583 @iter430) ([92m↓9.56%[0m) [7.08% of initial]
[Iter 431] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 431] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 432] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 432] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 433] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 433] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 434] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 434] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 435] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 435] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 436] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 436] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 437] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 437] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 438] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 438] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2670/20000] Loss: 0.0018182 (Best: 0.0011987 @iter2594) ([92m↓3.21%[0m) [0.72% of initial]
[Iter 439] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 439] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 440] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 440] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 440/20000] Loss: 0.0180898 (Best: 0.0165387 @iter434) ([91m↑1.51%[0m) [7.19% of initial]
[Iter 441] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 441] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 442] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 442] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 443] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 443] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 444] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 444] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 445] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 445] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 446] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 446] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 447] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 447] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2680/20000] Loss: 0.0014467 (Best: 0.0011987 @iter2594) ([92m↓20.43%[0m) [0.57% of initial]
[Iter 448] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 448] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 449] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 449] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 450] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 450] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 450/20000] Loss: 0.0168903 (Best: 0.0150461 @iter449) ([92m↓6.63%[0m) [6.71% of initial]
[Iter 451] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 451] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 452] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 452] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 453] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 453] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 454] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 454] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 455] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 455] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2690/20000] Loss: 0.0013958 (Best: 0.0011987 @iter2594) ([92m↓3.51%[0m) [0.55% of initial]
[Iter 456] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 456] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 457] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 457] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 458] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 458] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 459] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 459] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 460] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 460] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 460/20000] Loss: 0.0159132 (Best: 0.0140497 @iter458) ([92m↓5.79%[0m) [6.32% of initial]
[Iter 461] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 461] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 462] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 462] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 463] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 463] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2699, L1 loss=0.001335, Total loss=0.001351, Time:52
[Iter 464] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 464] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2700/20000] Loss: 0.0016644 (Best: 0.0011987 @iter2594) ([91m↑19.24%[0m) [0.66% of initial]
[Iter 465] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 465] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 466] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 466] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 467] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 467] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 468] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 468] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 469] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 469] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 470] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 470] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 470/20000] Loss: 0.0143222 (Best: 0.0136143 @iter463) ([92m↓10.00%[0m) [5.69% of initial]
[Iter 471] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 471] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 472] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 472] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 473] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 473] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2710/20000] Loss: 0.0014194 (Best: 0.0011987 @iter2594) ([92m↓14.72%[0m) [0.56% of initial]
[Iter 474] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 474] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 475] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 475] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 476] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 476] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 477] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 477] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 478] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 478] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 479] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 479] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 480] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 480] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 480/20000] Loss: 0.0140323 (Best: 0.0129485 @iter479) ([92m↓2.02%[0m) [5.57% of initial]
[Iter 481] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 481] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 482] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 482] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2720/20000] Loss: 0.0012932 (Best: 0.0011397 @iter2718) ([92m↓8.89%[0m) [0.51% of initial]
[Iter 483] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 483] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 484] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 484] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 485] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 485] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 486] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 486] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 487] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 487] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 488] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 488] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 489] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 489] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 490] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 490] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 490/20000] Loss: 0.0137820 (Best: 0.0124093 @iter484) ([92m↓1.78%[0m) [5.48% of initial]
[Iter 2730/20000] Loss: 0.0011888 (Best: 0.0010245 @iter2727) ([92m↓8.07%[0m) [0.47% of initial]
[Iter 491] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 491] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 492] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 492] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 493] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 493] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 494] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 494] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 495] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 495] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 496] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 496] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 497] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 497] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 498] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 498] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2740/20000] Loss: 0.0010475 (Best: 0.0009424 @iter2740) ([92m↓11.89%[0m) [0.42% of initial]
[Iter 499] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 499] Co-reg loss between gs1 and gs0: 0.0000000
Iter:499, L1 loss=0.008169, Total loss=0.01435, Time:67
[Iter 500] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 500] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 500/20000] Loss: 0.0135641 (Best: 0.0124093 @iter484) ([92m↓1.58%[0m) [5.39% of initial]
[Iter 501] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 501] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 502] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 502] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 503] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 503] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 504] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 504] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 505] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 505] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 506] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 506] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 507] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 507] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2750/20000] Loss: 0.0013545 (Best: 0.0009424 @iter2740) ([91m↑29.30%[0m) [0.54% of initial]
[Iter 508] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 508] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 509] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 509] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 510] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 510] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 510/20000] Loss: 0.0134277 (Best: 0.0121786 @iter508) ([92m↓1.01%[0m) [5.33% of initial]
[Iter 511] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 511] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 512] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 512] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 513] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 513] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 514] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 514] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 515] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 515] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 516] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 516] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2760/20000] Loss: 0.0014939 (Best: 0.0009424 @iter2740) ([91m↑10.29%[0m) [0.59% of initial]
[Iter 517] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 517] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 518] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 518] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 519] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 519] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 520] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 520] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 520/20000] Loss: 0.0126566 (Best: 0.0117479 @iter514) ([92m↓5.74%[0m) [5.03% of initial]
[Iter 521] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 521] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 522] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 522] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 523] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 523] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 524] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 524] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2770/20000] Loss: 0.0016490 (Best: 0.0009424 @iter2740) ([91m↑10.38%[0m) [0.66% of initial]
[Iter 525] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 525] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 526] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 526] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 527] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 527] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 528] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 528] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 529] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 529] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 530] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 530] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 530/20000] Loss: 0.0124089 (Best: 0.0111708 @iter529) ([92m↓1.96%[0m) [4.93% of initial]
[Iter 531] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 531] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 532] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 532] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 533] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 533] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2780/20000] Loss: 0.0013234 (Best: 0.0009424 @iter2740) ([92m↓19.74%[0m) [0.53% of initial]
[Iter 534] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 534] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 535] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 535] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 536] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 536] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 537] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 537] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 538] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 538] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 539] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 539] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 540] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 540] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 540/20000] Loss: 0.0123809 (Best: 0.0110078 @iter538) ([92m↓0.23%[0m) [4.92% of initial]
[Iter 541] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 541] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2790/20000] Loss: 0.0013787 (Best: 0.0009424 @iter2740) ([91m↑4.18%[0m) [0.55% of initial]
[Iter 542] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 542] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 543] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 543] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 544] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 544] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 545] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 545] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 546] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 546] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 547] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 547] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 548] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 548] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 549] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 549] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2799, L1 loss=0.001412, Total loss=0.001489, Time:47
[Iter 550] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 550] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 550/20000] Loss: 0.0119922 (Best: 0.0110078 @iter538) ([92m↓3.14%[0m) [4.76% of initial]
[Iter 2800/20000] Loss: 0.0013720 (Best: 0.0009424 @iter2740) ([92m↓0.49%[0m) [0.55% of initial]
[Iter 551] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 551] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 552] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 552] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 553] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 553] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 554] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 554] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 555] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 555] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 556] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 556] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 557] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 557] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 558] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 558] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 559] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 559] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 560] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 560] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 560/20000] Loss: 0.0121969 (Best: 0.0107561 @iter556) ([91m↑1.71%[0m) [4.85% of initial]
[Iter 561] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 561] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 562] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 562] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 563] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 563] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 564] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2810/20000] Loss: 0.0059240 (Best: 0.0009424 @iter2740) ([91m↑331.78%[0m) [2.35% of initial]
[Iter 564] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 565] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 565] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 566] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 566] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 567] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 567] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 568] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 568] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 569] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 569] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 570] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 570] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 570/20000] Loss: 0.0118028 (Best: 0.0106272 @iter567) ([92m↓3.23%[0m) [4.69% of initial]
[Iter 571] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 571] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 572] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 572] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 573] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 573] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2820/20000] Loss: 0.0031378 (Best: 0.0009424 @iter2740) ([92m↓47.03%[0m) [1.25% of initial]
[Iter 574] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 574] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 575] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 575] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 576] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 576] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 577] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 577] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 578] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 578] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 579] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 579] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 580] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 580] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 580/20000] Loss: 0.0113484 (Best: 0.0103685 @iter574) ([92m↓3.85%[0m) [4.51% of initial]
[Iter 581] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 581] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 582] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 582] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2830/20000] Loss: 0.0020304 (Best: 0.0009424 @iter2740) ([92m↓35.29%[0m) [0.81% of initial]
[Iter 583] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 583] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 584] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 584] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 585] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 585] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 586] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 586] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 587] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 587] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 588] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 588] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 589] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 589] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 590] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 590] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 590/20000] Loss: 0.0113837 (Best: 0.0101942 @iter583) ([91m↑0.31%[0m) [4.52% of initial]
[Iter 591] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 591] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2840/20000] Loss: 0.0017167 (Best: 0.0009424 @iter2740) ([92m↓15.45%[0m) [0.68% of initial]
[Iter 592] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 592] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 593] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 593] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 594] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 594] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 595] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 595] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 596] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 596] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 597] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 597] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 598] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 598] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 599] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 599] Co-reg loss between gs1 and gs0: 0.0000000
Iter:599, L1 loss=0.007039, Total loss=0.01182, Time:53
[Iter 600] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 600] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 600/20000] Loss: 0.0109799 (Best: 0.0099245 @iter598) ([92m↓3.55%[0m) [4.36% of initial]
[Iter 2850/20000] Loss: 0.0015148 (Best: 0.0009424 @iter2740) ([92m↓11.76%[0m) [0.60% of initial]
[Iter 601] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 601] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 602] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 602] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 603] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 603] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 604] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 604] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 605] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 605] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 606] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 606] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2860/20000] Loss: 0.0016327 (Best: 0.0009424 @iter2740) ([91m↑7.78%[0m) [0.65% of initial]
[Iter 607] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 607] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 608] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 608] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 609] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 609] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 610] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 610] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 610/20000] Loss: 0.0232589 (Best: 0.0099245 @iter598) ([91m↑111.83%[0m) [9.24% of initial]
[Iter 611] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 611] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 612] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 612] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 613] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 613] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 614] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 614] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 615] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 615] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2870/20000] Loss: 0.0014330 (Best: 0.0009424 @iter2740) ([92m↓12.23%[0m) [0.57% of initial]
[Iter 616] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 616] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 617] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 617] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 618] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 618] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 619] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 619] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 620] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 620] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 620/20000] Loss: 0.0142208 (Best: 0.0099245 @iter598) ([92m↓38.86%[0m) [5.65% of initial]
[Iter 621] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 621] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 622] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 622] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 623] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 623] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 624] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 624] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 625] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2880/20000] Loss: 0.0013726 (Best: 0.0009424 @iter2740) ([92m↓4.22%[0m) [0.55% of initial]
[Iter 625] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 626] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 626] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 627] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 627] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 628] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 628] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 629] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 629] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 630] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 630] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 630/20000] Loss: 0.0118439 (Best: 0.0099245 @iter598) ([92m↓16.71%[0m) [4.71% of initial]
[Iter 631] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 631] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 632] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 632] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 633] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 633] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 634] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 634] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2890/20000] Loss: 0.0012738 (Best: 0.0009424 @iter2740) ([92m↓7.20%[0m) [0.51% of initial]
[Iter 635] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 635] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 636] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 636] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 637] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 637] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 638] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 638] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 639] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 639] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 640] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 640] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 640/20000] Loss: 0.0101062 (Best: 0.0092777 @iter640) ([92m↓14.67%[0m) [4.02% of initial]
[Iter 641] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 641] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 642] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 642] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2899, L1 loss=0.001002, Total loss=0.001026, Time:42
[Iter 643] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 643] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2900/20000] Loss: 0.0012213 (Best: 0.0009424 @iter2740) ([92m↓4.12%[0m) [0.49% of initial]
[Iter 644] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 644] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 645] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 645] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 646] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 646] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 647] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 647] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 648] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 648] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 649] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 649] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 650] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 650] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 650/20000] Loss: 0.0103133 (Best: 0.0090732 @iter646) ([91m↑2.05%[0m) [4.10% of initial]
[Iter 651] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 651] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 652] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 652] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2910/20000] Loss: 0.0013384 (Best: 0.0009424 @iter2740) ([91m↑9.58%[0m) [0.53% of initial]
[Iter 653] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 653] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 654] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 654] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 655] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 655] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 656] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 656] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 657] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 657] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 658] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 658] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 659] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 659] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 660] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 660] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 660/20000] Loss: 0.0101373 (Best: 0.0087525 @iter655) ([92m↓1.71%[0m) [4.03% of initial]
[Iter 661] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 661] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 662] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 662] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2920/20000] Loss: 0.0014578 (Best: 0.0009424 @iter2740) ([91m↑8.93%[0m) [0.58% of initial]
[Iter 663] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 663] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 664] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 664] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 665] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 665] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 666] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 666] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 667] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 667] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 668] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 668] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 669] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 669] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 670] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 670] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 670/20000] Loss: 0.0095786 (Best: 0.0087525 @iter655) ([92m↓5.51%[0m) [3.81% of initial]
[Iter 671] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 671] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2930/20000] Loss: 0.0013463 (Best: 0.0009424 @iter2740) ([92m↓7.65%[0m) [0.53% of initial]
[Iter 672] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 672] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 673] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 673] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 674] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 674] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 675] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 675] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 676] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 676] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 677] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 677] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 678] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 678] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 679] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 679] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 680] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 680] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 680/20000] Loss: 0.0088573 (Best: 0.0082981 @iter680) ([92m↓7.53%[0m) [3.52% of initial]
[Iter 2940/20000] Loss: 0.0011592 (Best: 0.0009424 @iter2740) ([92m↓13.90%[0m) [0.46% of initial]
[Iter 681] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 681] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 682] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 682] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 683] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 683] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 684] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 684] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 685] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 685] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 686] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 686] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 687] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 687] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 688] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 688] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 689] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 689] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2950/20000] Loss: 0.0010654 (Best: 0.0008958 @iter2950) ([92m↓8.09%[0m) [0.42% of initial]
[Iter 690] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 690] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 690/20000] Loss: 0.0092064 (Best: 0.0078083 @iter685) ([91m↑3.94%[0m) [3.66% of initial]
[Iter 691] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 691] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 692] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 692] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 693] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 693] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 694] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 694] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 695] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 695] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 696] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 696] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 697] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 697] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 698] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 698] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 699] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 699] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2960/20000] Loss: 0.0011825 (Best: 0.0008958 @iter2950) ([91m↑10.99%[0m) [0.47% of initial]
Iter:699, L1 loss=0.005651, Total loss=0.009357, Time:53
[Iter 700] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 700] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 700/20000] Loss: 0.0088647 (Best: 0.0078083 @iter685) ([92m↓3.71%[0m) [3.52% of initial]
[Iter 701] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 701] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 702] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 702] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 703] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 703] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 704] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 704] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 705] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 705] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 706] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 706] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 707] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 707] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 708] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 708] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2970/20000] Loss: 0.0010529 (Best: 0.0008581 @iter2969) ([92m↓10.96%[0m) [0.42% of initial]
[Iter 709] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 709] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 710] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 710] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 710/20000] Loss: 0.0083028 (Best: 0.0076604 @iter703) ([92m↓6.34%[0m) [3.30% of initial]
[Iter 711] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 711] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 712] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 712] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 713] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 713] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 714] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 714] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 715] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 715] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 716] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 716] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 717] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 717] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2980/20000] Loss: 0.0009792 (Best: 0.0008581 @iter2969) ([92m↓7.00%[0m) [0.39% of initial]
[Iter 718] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 718] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 719] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 719] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 720] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 720] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 720/20000] Loss: 0.0082886 (Best: 0.0076236 @iter715) ([92m↓0.17%[0m) [3.29% of initial]
[Iter 721] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 721] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 722] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 722] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 723] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 723] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 724] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 724] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 725] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 725] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 726] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 726] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2990/20000] Loss: 0.0010081 (Best: 0.0007929 @iter2983) ([91m↑2.95%[0m) [0.40% of initial]
[Iter 727] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 727] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 728] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 728] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 729] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 729] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 730] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 730] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 730/20000] Loss: 0.0084229 (Best: 0.0074175 @iter727) ([91m↑1.62%[0m) [3.35% of initial]
[Iter 731] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 731] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 732] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 732] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 733] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 733] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 734] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 734] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 735] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 735] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2999, L1 loss=0.0008145, Total loss=0.0007788, Time:47
[Iter 736] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 736] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3000/20000] Loss: 0.0009853 (Best: 0.0007788 @iter2999) ([92m↓2.26%[0m) [0.39% of initial]
[Iter 737] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 737] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 738] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 738] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 739] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 739] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 740] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 740] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 740/20000] Loss: 0.0084426 (Best: 0.0074092 @iter733) ([91m↑0.23%[0m) [3.35% of initial]
[Iter 741] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 741] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 742] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 742] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 743] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 743] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 744] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 744] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 745] Co-reg loss between gs0 and gs1: 0.0007755
[Iter 745] Co-reg loss between gs1 and gs0: 0.0007755
Pruning 422 points (0.4%) from gaussian0 at iteration 3000
[Iter 746] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 746] Co-reg loss between gs1 and gs0: 0.0000000
Pruning 416 points (0.3%) from gaussian1 at iteration 3000
[Iter 747] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 747] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 748] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 748] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 749] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 749] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 750] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 750] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 750/20000] Loss: 0.0080097 (Best: 0.0069750 @iter748) ([92m↓5.13%[0m) [3.18% of initial]
[Iter 751] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 751] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 752] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 752] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 753] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 753] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 754] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 754] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 755] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 755] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 756] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 756] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3010/20000] Loss: 0.0057267 (Best: 0.0007788 @iter2999) ([91m↑481.21%[0m) [2.28% of initial]
[Iter 757] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 757] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 758] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 758] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 759] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 759] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 760] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 760] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 760/20000] Loss: 0.0074666 (Best: 0.0069750 @iter748) ([92m↓6.78%[0m) [2.97% of initial]
[Iter 761] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 761] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 762] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 762] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 763] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 763] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 764] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 764] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 765] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 765] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 766] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 766] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3020/20000] Loss: 0.0034823 (Best: 0.0007788 @iter2999) ([92m↓39.19%[0m) [1.38% of initial]
[Iter 767] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 767] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 768] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 768] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 769] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 769] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 770] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 770] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 770/20000] Loss: 0.0075900 (Best: 0.0069750 @iter748) ([91m↑1.65%[0m) [3.02% of initial]
[Iter 771] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 771] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 772] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 772] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 773] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 773] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 774] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 774] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 775] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 775] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 776] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 776] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3030/20000] Loss: 0.0024767 (Best: 0.0007788 @iter2999) ([92m↓28.88%[0m) [0.98% of initial]
[Iter 777] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 777] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 778] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 778] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 779] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 779] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 780] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 780] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 780/20000] Loss: 0.0077309 (Best: 0.0068787 @iter775) ([91m↑1.86%[0m) [3.07% of initial]
[Iter 781] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 781] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 782] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 782] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 783] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 783] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 784] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 784] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 785] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 785] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3040/20000] Loss: 0.0019309 (Best: 0.0007788 @iter2999) ([92m↓22.04%[0m) [0.77% of initial]
[Iter 786] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 786] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 787] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 787] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 788] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 788] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 789] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 789] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 790] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 790] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 790/20000] Loss: 0.0075006 (Best: 0.0066282 @iter787) ([92m↓2.98%[0m) [2.98% of initial]
[Iter 791] Co-reg loss between gs0 and gs1: 0.0008414
[Iter 791] Co-reg loss between gs1 and gs0: 0.0008414
[Iter 792] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 792] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 793] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 793] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 794] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 794] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 795] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 795] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3050/20000] Loss: 0.0017333 (Best: 0.0007788 @iter2999) ([92m↓10.23%[0m) [0.69% of initial]
[Iter 796] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 796] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 797] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 797] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 798] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 798] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 799] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 799] Co-reg loss between gs1 and gs0: 0.0000000
Iter:799, L1 loss=0.005, Total loss=0.008025, Time:68
[Iter 800] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 800] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 800/20000] Loss: 0.0074187 (Best: 0.0066282 @iter787) ([92m↓1.09%[0m) [2.95% of initial]
[Iter 801] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 801] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3060/20000] Loss: 0.0016556 (Best: 0.0007788 @iter2999) ([92m↓4.48%[0m) [0.66% of initial]
[Iter 802] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 802] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 803] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 803] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 804] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 804] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 805] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 805] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 806] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 806] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 807] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 807] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 808] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 808] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 809] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 809] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 810] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 810] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 810/20000] Loss: 0.0157826 (Best: 0.0066282 @iter787) ([91m↑112.74%[0m) [6.27% of initial]
[Iter 3070/20000] Loss: 0.0014372 (Best: 0.0007788 @iter2999) ([92m↓13.20%[0m) [0.57% of initial]
[Iter 811] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 811] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 812] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 812] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 813] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 813] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 814] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 814] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 815] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 815] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 816] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 816] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 817] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 817] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 818] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 818] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 819] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 819] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 820] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 3080/20000] Loss: 0.0014339 (Best: 0.0007788 @iter2999) ([92m↓0.23%[0m) [0.57% of initial]
[Iter 820] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 820/20000] Loss: 0.0106263 (Best: 0.0066282 @iter787) ([92m↓32.67%[0m) [4.22% of initial]
[Iter 821] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 821] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 822] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 822] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 823] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 823] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 824] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 824] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 825] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 825] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 826] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 826] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 827] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 827] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 828] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 828] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 829] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 829] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3090/20000] Loss: 0.0013946 (Best: 0.0007788 @iter2999) ([92m↓2.74%[0m) [0.55% of initial]
[Iter 830] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 830] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 830/20000] Loss: 0.0087662 (Best: 0.0066282 @iter787) ([92m↓17.51%[0m) [3.48% of initial]
[Iter 831] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 831] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 832] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 832] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 833] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 833] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 834] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 834] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 835] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 835] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 836] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 836] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 837] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 837] Co-reg loss between gs1 and gs0: 0.0000000
Iter:3099, L1 loss=0.001126, Total loss=0.001199, Time:59
[Iter 838] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 838] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3100/20000] Loss: 0.0013015 (Best: 0.0007788 @iter2999) ([92m↓6.68%[0m) [0.52% of initial]
[Iter 839] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 839] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 840] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 840] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 840/20000] Loss: 0.0079387 (Best: 0.0066282 @iter787) ([92m↓9.44%[0m) [3.15% of initial]
[Iter 841] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 841] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 842] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 842] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 843] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 843] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 844] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 844] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 845] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 845] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 846] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 846] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 847] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 847] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 848] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 848] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3110/20000] Loss: 0.0014073 (Best: 0.0007788 @iter2999) ([91m↑8.13%[0m) [0.56% of initial]
[Iter 849] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 849] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 850] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 850] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 850/20000] Loss: 0.0073100 (Best: 0.0066282 @iter787) ([92m↓7.92%[0m) [2.90% of initial]
[Iter 851] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 851] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 852] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 852] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 853] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 853] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 854] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 854] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 855] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 855] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 856] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 856] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 857] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 857] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3120/20000] Loss: 0.0013503 (Best: 0.0007788 @iter2999) ([92m↓4.05%[0m) [0.54% of initial]
[Iter 858] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 858] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 859] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 859] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 860] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 860] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 860/20000] Loss: 0.0068371 (Best: 0.0062594 @iter853) ([92m↓6.47%[0m) [2.72% of initial]
[Iter 861] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 861] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 862] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 862] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 863] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 863] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 864] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 864] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 865] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 865] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 866] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 866] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 867] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 867] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3130/20000] Loss: 0.0011513 (Best: 0.0007788 @iter2999) ([92m↓14.74%[0m) [0.46% of initial]
[Iter 868] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 868] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 869] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 869] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 870] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 870] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 870/20000] Loss: 0.0065413 (Best: 0.0061388 @iter862) ([92m↓4.33%[0m) [2.60% of initial]
[Iter 871] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 871] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 872] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 872] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 873] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 873] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 874] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 874] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 875] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 875] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 876] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 876] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3140/20000] Loss: 0.0011149 (Best: 0.0007788 @iter2999) ([92m↓3.16%[0m) [0.44% of initial]
[Iter 877] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 877] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 878] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 878] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 879] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 879] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 880] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 880] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 880/20000] Loss: 0.0064733 (Best: 0.0058643 @iter875) ([92m↓1.04%[0m) [2.57% of initial]
[Iter 881] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 881] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 882] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 882] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 883] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 883] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 884] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 884] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 885] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 885] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3150/20000] Loss: 0.0011610 (Best: 0.0007788 @iter2999) ([91m↑4.13%[0m) [0.46% of initial]
[Iter 886] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 886] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 887] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 887] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 888] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 888] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 889] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 889] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 890] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 890] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 890/20000] Loss: 0.0060930 (Best: 0.0055751 @iter887) ([92m↓5.88%[0m) [2.42% of initial]
[Iter 891] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 891] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 892] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 892] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 893] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 893] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 894] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 894] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 895] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 895] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3160/20000] Loss: 0.0010652 (Best: 0.0007788 @iter2999) ([92m↓8.25%[0m) [0.42% of initial]
[Iter 896] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 896] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 897] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 897] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 898] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 898] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 899] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 899] Co-reg loss between gs1 and gs0: 0.0000000
Iter:899, L1 loss=0.003793, Total loss=0.005492, Time:66
[Iter 900] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 900] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 900/20000] Loss: 0.0062724 (Best: 0.0054923 @iter899) ([91m↑2.94%[0m) [2.49% of initial]
[Iter 901] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 901] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 902] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 902] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 903] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 903] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 904] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 904] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3170/20000] Loss: 0.0010834 (Best: 0.0007788 @iter2999) ([91m↑1.71%[0m) [0.43% of initial]
[Iter 905] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 905] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 906] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 906] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 907] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 907] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 908] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 908] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 909] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 909] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 910] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 910] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 910/20000] Loss: 0.0064572 (Best: 0.0054200 @iter907) ([91m↑2.95%[0m) [2.57% of initial]
[Iter 911] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 911] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 912] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 912] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 913] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 913] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 914] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 914] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3180/20000] Loss: 0.0011474 (Best: 0.0007788 @iter2999) ([91m↑5.91%[0m) [0.46% of initial]
[Iter 915] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 915] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 916] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 916] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 917] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 917] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 918] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 918] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 919] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 919] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 920] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 920] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 920/20000] Loss: 0.0059470 (Best: 0.0054200 @iter907) ([92m↓7.90%[0m) [2.36% of initial]
[Iter 921] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 921] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 922] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 922] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 923] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 923] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3190/20000] Loss: 0.0011331 (Best: 0.0007788 @iter2999) ([92m↓1.25%[0m) [0.45% of initial]
[Iter 924] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 924] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 925] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 925] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 926] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 926] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 927] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 927] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 928] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 928] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 929] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 929] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 930] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 930] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 930/20000] Loss: 0.0061256 (Best: 0.0052402 @iter925) ([91m↑3.00%[0m) [2.43% of initial]
[Iter 931] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 931] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 932] Co-reg loss between gs0 and gs1: 0.0000000
Iter:3199, L1 loss=0.00103, Total loss=0.001003, Time:61
[Iter 932] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3200/20000] Loss: 0.0010756 (Best: 0.0007788 @iter2999) ([92m↓5.07%[0m) [0.43% of initial]
[Iter 933] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 933] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 934] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 934] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 935] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 935] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 936] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 936] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 937] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 937] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 938] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 938] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 939] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 939] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 940] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 940] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 940/20000] Loss: 0.0061820 (Best: 0.0051256 @iter938) ([91m↑0.92%[0m) [2.46% of initial]
[Iter 941] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 941] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 942] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 942] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 943] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 943] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 944] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 944] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 945] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 945] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 946] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 946] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3210/20000] Loss: 0.0054826 (Best: 0.0007788 @iter2999) ([91m↑409.71%[0m) [2.18% of initial]
[Iter 947] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 947] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 948] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 948] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 949] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 949] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 950] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 950] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 950/20000] Loss: 0.0057310 (Best: 0.0051025 @iter946) ([92m↓7.30%[0m) [2.28% of initial]
[Iter 951] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 951] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 952] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 952] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 953] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 953] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 954] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 954] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 955] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 955] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3220/20000] Loss: 0.0031675 (Best: 0.0007788 @iter2999) ([92m↓42.23%[0m) [1.26% of initial]
[Iter 956] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 956] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 957] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 957] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 958] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 958] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 959] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 959] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 960] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 960] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 960/20000] Loss: 0.0058685 (Best: 0.0051025 @iter946) ([91m↑2.40%[0m) [2.33% of initial]
[Iter 961] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 961] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 962] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 962] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 963] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 963] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 964] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 964] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 965] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 965] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3230/20000] Loss: 0.0020220 (Best: 0.0007788 @iter2999) ([92m↓36.16%[0m) [0.80% of initial]
[Iter 966] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 966] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 967] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 967] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 968] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 968] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 969] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 969] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 970] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 970] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 970/20000] Loss: 0.0058455 (Best: 0.0050653 @iter964) ([92m↓0.39%[0m) [2.32% of initial]
[Iter 971] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 971] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 972] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 972] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 973] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 973] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 974] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 974] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3240/20000] Loss: 0.0018028 (Best: 0.0007788 @iter2999) ([92m↓10.84%[0m) [0.72% of initial]
[Iter 975] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 975] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 976] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 976] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 977] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 977] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 978] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 978] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 979] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 979] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 980] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 980] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 980/20000] Loss: 0.0059373 (Best: 0.0050245 @iter979) ([91m↑1.57%[0m) [2.36% of initial]
[Iter 981] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 981] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 982] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 982] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 983] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 983] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 984] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 984] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3250/20000] Loss: 0.0013527 (Best: 0.0007788 @iter2999) ([92m↓24.97%[0m) [0.54% of initial]
[Iter 985] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 985] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 986] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 986] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 987] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 987] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 988] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 988] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 989] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 989] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 990] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 990] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 990/20000] Loss: 0.0060180 (Best: 0.0050245 @iter979) ([91m↑1.36%[0m) [2.39% of initial]
[Iter 991] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 991] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 992] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 992] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 993] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 993] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3260/20000] Loss: 0.0012325 (Best: 0.0007788 @iter2999) ([92m↓8.89%[0m) [0.49% of initial]
[Iter 994] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 994] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 995] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 995] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 996] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 996] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 997] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 997] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 998] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 998] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 999] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 999] Co-reg loss between gs1 and gs0: 0.0000000
Iter:999, L1 loss=0.004469, Total loss=0.006664, Time:61
[Iter 1000] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1000] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1000/20000] Loss: 0.0062184 (Best: 0.0050245 @iter979) ([91m↑3.33%[0m) [2.47% of initial]
[Iter 3270/20000] Loss: 0.0012677 (Best: 0.0007788 @iter2999) ([91m↑2.86%[0m) [0.50% of initial]
[Iter 1001] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1001] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1002] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1002] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1003] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1003] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1004] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1004] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1005] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1005] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1006] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1006] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1007] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1007] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1008] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1008] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3280/20000] Loss: 0.0013232 (Best: 0.0007788 @iter2999) ([91m↑4.38%[0m) [0.53% of initial]
[Iter 1009] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1009] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1010] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1010] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1010/20000] Loss: 0.0115647 (Best: 0.0050245 @iter979) ([91m↑85.98%[0m) [4.59% of initial]
[Iter 1011] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1011] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1012] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1012] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1013] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1013] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1014] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1014] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1015] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1015] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1016] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1016] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1017] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1017] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3290/20000] Loss: 0.0009985 (Best: 0.0007788 @iter2999) ([92m↓24.54%[0m) [0.40% of initial]
[Iter 1018] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1018] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1019] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1019] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1020] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1020] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1020/20000] Loss: 0.0081270 (Best: 0.0050245 @iter979) ([92m↓29.73%[0m) [3.23% of initial]
[Iter 1021] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1021] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1022] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1022] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1023] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1023] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1024] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1024] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1025] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1025] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1026] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1026] Co-reg loss between gs1 and gs0: 0.0000000
Iter:3299, L1 loss=0.001496, Total loss=0.001575, Time:66
[Iter 1027] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1027] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3300/20000] Loss: 0.0013356 (Best: 0.0007788 @iter2999) ([91m↑33.75%[0m) [0.53% of initial]
[Iter 1028] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1028] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1029] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1029] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1030] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1030] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1030/20000] Loss: 0.0066467 (Best: 0.0050245 @iter979) ([92m↓18.22%[0m) [2.64% of initial]
[Iter 1031] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1031] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1032] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1032] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1033] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1033] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1034] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1034] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1035] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1035] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1036] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1036] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3310/20000] Loss: 0.0010041 (Best: 0.0007788 @iter2999) ([92m↓24.82%[0m) [0.40% of initial]
[Iter 1037] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1037] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1038] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1038] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1039] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1039] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1040] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1040] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1040/20000] Loss: 0.0058592 (Best: 0.0050245 @iter979) ([92m↓11.85%[0m) [2.33% of initial]
[Iter 1041] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1041] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1042] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1042] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1043] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1043] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1044] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1044] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1045] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1045] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3320/20000] Loss: 0.0011561 (Best: 0.0007788 @iter2999) ([91m↑15.13%[0m) [0.46% of initial]
[Iter 1046] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1046] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1047] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1047] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1048] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1048] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1049] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1049] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1050] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1050] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1050/20000] Loss: 0.0057350 (Best: 0.0049173 @iter1046) ([92m↓2.12%[0m) [2.28% of initial]
[Iter 1051] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1051] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1052] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1052] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1053] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1053] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1054] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1054] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3330/20000] Loss: 0.0012390 (Best: 0.0007788 @iter2999) ([91m↑7.17%[0m) [0.49% of initial]
[Iter 1055] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1055] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1056] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1056] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1057] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1057] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1058] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1058] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1059] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1059] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1060] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1060] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1060/20000] Loss: 0.0055923 (Best: 0.0047560 @iter1051) ([92m↓2.49%[0m) [2.22% of initial]
[Iter 1061] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1061] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 1062] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1062] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3340/20000] Loss: 0.0013525 (Best: 0.0007788 @iter2999) ([91m↑9.16%[0m) [0.54% of initial]
[Iter 3350/20000] Loss: 0.0011045 (Best: 0.0007788 @iter2999) ([92m↓18.34%[0m) [0.44% of initial]
[Iter 3360/20000] Loss: 0.0013664 (Best: 0.0007788 @iter2999) ([91m↑23.72%[0m) [0.54% of initial]
[Iter 3370/20000] Loss: 0.0009988 (Best: 0.0007788 @iter2999) ([92m↓26.91%[0m) [0.40% of initial]
[Iter 3380/20000] Loss: 0.0009550 (Best: 0.0007788 @iter2999) ([92m↓4.38%[0m) [0.38% of initial]
[Iter 3390/20000] Loss: 0.0012574 (Best: 0.0007788 @iter2999) ([91m↑31.67%[0m) [0.50% of initial]
Iter:3399, L1 loss=0.001463, Total loss=0.001547, Time:45
[Iter 3400/20000] Loss: 0.0012900 (Best: 0.0007788 @iter2999) ([91m↑2.60%[0m) [0.51% of initial]
[Iter 3410/20000] Loss: 0.0046896 (Best: 0.0007788 @iter2999) ([91m↑263.54%[0m) [1.86% of initial]
[Iter 3420/20000] Loss: 0.0025333 (Best: 0.0007788 @iter2999) ([92m↓45.98%[0m) [1.01% of initial]
[Iter 3430/20000] Loss: 0.0016439 (Best: 0.0007788 @iter2999) ([92m↓35.11%[0m) [0.65% of initial]
[Iter 3440/20000] Loss: 0.0014908 (Best: 0.0007788 @iter2999) ([92m↓9.31%[0m) [0.59% of initial]
[Iter 3450/20000] Loss: 0.0013834 (Best: 0.0007788 @iter2999) ([92m↓7.20%[0m) [0.55% of initial]
[Iter 3460/20000] Loss: 0.0012651 (Best: 0.0007788 @iter2999) ([92m↓8.56%[0m) [0.50% of initial]
[Iter 3470/20000] Loss: 0.0011974 (Best: 0.0007788 @iter2999) ([92m↓5.35%[0m) [0.48% of initial]
[Iter 3480/20000] Loss: 0.0010956 (Best: 0.0007788 @iter2999) ([92m↓8.50%[0m) [0.44% of initial]
[Iter 3490/20000] Loss: 0.0010300 (Best: 0.0007788 @iter2999) ([92m↓5.99%[0m) [0.41% of initial]
Iter:3499, L1 loss=0.0007821, Total loss=0.0007428, Time:59
[Iter 3500/20000] Loss: 0.0008136 (Best: 0.0007428 @iter3499) ([92m↓21.01%[0m) [0.32% of initial]
Pruning 311 points (0.2%) from gaussian0 at iteration 3500
Pruning 324 points (0.2%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0024646 (Best: 0.0007428 @iter3499) ([91m↑202.94%[0m) [0.98% of initial]
[Iter 3520/20000] Loss: 0.0015930 (Best: 0.0007428 @iter3499) ([92m↓35.37%[0m) [0.63% of initial]
[Iter 3530/20000] Loss: 0.0012404 (Best: 0.0007428 @iter3499) ([92m↓22.13%[0m) [0.49% of initial]
[Iter 3540/20000] Loss: 0.0014005 (Best: 0.0007428 @iter3499) ([91m↑12.90%[0m) [0.56% of initial]
[Iter 3550/20000] Loss: 0.0012778 (Best: 0.0007428 @iter3499) ([92m↓8.76%[0m) [0.51% of initial]
[Iter 3560/20000] Loss: 0.0010815 (Best: 0.0007428 @iter3499) ([92m↓15.36%[0m) [0.43% of initial]
[Iter 3570/20000] Loss: 0.0011491 (Best: 0.0007428 @iter3499) ([91m↑6.25%[0m) [0.46% of initial]
[Iter 3580/20000] Loss: 0.0008766 (Best: 0.0007428 @iter3499) ([92m↓23.72%[0m) [0.35% of initial]
[Iter 3590/20000] Loss: 0.0008654 (Best: 0.0007428 @iter3499) ([92m↓1.28%[0m) [0.34% of initial]
Iter:3599, L1 loss=0.0007964, Total loss=0.0007341, Time:63
[Iter 3600/20000] Loss: 0.0008410 (Best: 0.0007041 @iter3598) ([92m↓2.81%[0m) [0.33% of initial]
[Iter 3610/20000] Loss: 0.0043326 (Best: 0.0007041 @iter3598) ([91m↑415.15%[0m) [1.72% of initial]
[Iter 3620/20000] Loss: 0.0027361 (Best: 0.0007041 @iter3598) ([92m↓36.85%[0m) [1.09% of initial]
[Iter 3630/20000] Loss: 0.0016891 (Best: 0.0007041 @iter3598) ([92m↓38.27%[0m) [0.67% of initial]
[Iter 3640/20000] Loss: 0.0012844 (Best: 0.0007041 @iter3598) ([92m↓23.96%[0m) [0.51% of initial]
[Iter 3650/20000] Loss: 0.0012811 (Best: 0.0007041 @iter3598) ([92m↓0.26%[0m) [0.51% of initial]
[Iter 3660/20000] Loss: 0.0010541 (Best: 0.0007041 @iter3598) ([92m↓17.72%[0m) [0.42% of initial]
[Iter 3670/20000] Loss: 0.0009342 (Best: 0.0007041 @iter3598) ([92m↓11.37%[0m) [0.37% of initial]
[Iter 3680/20000] Loss: 0.0011494 (Best: 0.0007041 @iter3598) ([91m↑23.03%[0m) [0.46% of initial]
[Iter 3690/20000] Loss: 0.0013982 (Best: 0.0007041 @iter3598) ([91m↑21.65%[0m) [0.56% of initial]
Iter:3699, L1 loss=0.001196, Total loss=0.001219, Time:72
[Iter 3700/20000] Loss: 0.0012233 (Best: 0.0007041 @iter3598) ([92m↓12.51%[0m) [0.49% of initial]
[Iter 3710/20000] Loss: 0.0009466 (Best: 0.0007041 @iter3598) ([92m↓22.62%[0m) [0.38% of initial]
[Iter 3720/20000] Loss: 0.0010456 (Best: 0.0007041 @iter3598) ([91m↑10.46%[0m) [0.42% of initial]
[Iter 3730/20000] Loss: 0.0008950 (Best: 0.0007041 @iter3598) ([92m↓14.40%[0m) [0.36% of initial]
[Iter 3740/20000] Loss: 0.0009062 (Best: 0.0007041 @iter3598) ([91m↑1.25%[0m) [0.36% of initial]
[Iter 3750/20000] Loss: 0.0009712 (Best: 0.0007041 @iter3598) ([91m↑7.18%[0m) [0.39% of initial]
[Iter 3760/20000] Loss: 0.0009325 (Best: 0.0007041 @iter3598) ([92m↓3.99%[0m) [0.37% of initial]
[Iter 3770/20000] Loss: 0.0009026 (Best: 0.0007041 @iter3598) ([92m↓3.21%[0m) [0.36% of initial]
[Iter 3780/20000] Loss: 0.0008312 (Best: 0.0006505 @iter3775) ([92m↓7.91%[0m) [0.33% of initial]
[Iter 3790/20000] Loss: 0.0006796 (Best: 0.0006018 @iter3790) ([92m↓18.24%[0m) [0.27% of initial]
Iter:3799, L1 loss=0.0009145, Total loss=0.0008757, Time:57
[Iter 3800/20000] Loss: 0.0008575 (Best: 0.0006018 @iter3790) ([91m↑26.18%[0m) [0.34% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 3810/20000] Loss: 0.0040542 (Best: 0.0006018 @iter3790) ([91m↑372.78%[0m) [1.61% of initial]
[Iter 3820/20000] Loss: 0.0023137 (Best: 0.0006018 @iter3790) ([92m↓42.93%[0m) [0.92% of initial]
[Iter 3830/20000] Loss: 0.0013887 (Best: 0.0006018 @iter3790) ([92m↓39.98%[0m) [0.55% of initial]
[Iter 3840/20000] Loss: 0.0015101 (Best: 0.0006018 @iter3790) ([91m↑8.75%[0m) [0.60% of initial]
[Iter 3850/20000] Loss: 0.0011536 (Best: 0.0006018 @iter3790) ([92m↓23.61%[0m) [0.46% of initial]
[Iter 3860/20000] Loss: 0.0010976 (Best: 0.0006018 @iter3790) ([92m↓4.86%[0m) [0.44% of initial]
[Iter 3870/20000] Loss: 0.0008830 (Best: 0.0006018 @iter3790) ([92m↓19.55%[0m) [0.35% of initial]
[Iter 3880/20000] Loss: 0.0009169 (Best: 0.0006018 @iter3790) ([91m↑3.83%[0m) [0.36% of initial]
[Iter 3890/20000] Loss: 0.0007497 (Best: 0.0006018 @iter3790) ([92m↓18.24%[0m) [0.30% of initial]
Iter:3899, L1 loss=0.0008597, Total loss=0.0008208, Time:64
[Iter 3900/20000] Loss: 0.0007699 (Best: 0.0005913 @iter3898) ([91m↑2.70%[0m) [0.31% of initial]
[Iter 3910/20000] Loss: 0.0009699 (Best: 0.0005913 @iter3898) ([91m↑25.97%[0m) [0.39% of initial]
[Iter 3920/20000] Loss: 0.0009785 (Best: 0.0005913 @iter3898) ([91m↑0.89%[0m) [0.39% of initial]
[Iter 3930/20000] Loss: 0.0009616 (Best: 0.0005913 @iter3898) ([92m↓1.72%[0m) [0.38% of initial]
[Iter 3940/20000] Loss: 0.0007852 (Best: 0.0005913 @iter3898) ([92m↓18.35%[0m) [0.31% of initial]
[Iter 3950/20000] Loss: 0.0008578 (Best: 0.0005913 @iter3898) ([91m↑9.25%[0m) [0.34% of initial]
[Iter 3960/20000] Loss: 0.0008730 (Best: 0.0005913 @iter3898) ([91m↑1.77%[0m) [0.35% of initial]
[Iter 3970/20000] Loss: 0.0007818 (Best: 0.0005913 @iter3898) ([92m↓10.44%[0m) [0.31% of initial]
[Iter 3980/20000] Loss: 0.0011107 (Best: 0.0005913 @iter3898) ([91m↑42.07%[0m) [0.44% of initial]
[Iter 3990/20000] Loss: 0.0008380 (Best: 0.0005913 @iter3898) ([92m↓24.55%[0m) [0.33% of initial]
Iter:3999, L1 loss=0.0009824, Total loss=0.0009031, Time:57
[Iter 4000/20000] Loss: 0.0008199 (Best: 0.0005913 @iter3898) ([92m↓2.17%[0m) [0.33% of initial]
Pruning 215 points (0.1%) from gaussian0 at iteration 4000
Pruning 284 points (0.2%) from gaussian1 at iteration 4000
[Iter 4010/20000] Loss: 0.1514783 (Best: 0.0005913 @iter3898) ([91m↑18375.56%[0m) [60.18% of initial]
[Iter 4020/20000] Loss: 0.1032760 (Best: 0.0005913 @iter3898) ([92m↓31.82%[0m) [41.03% of initial]
[Iter 4030/20000] Loss: 0.0654379 (Best: 0.0005913 @iter3898) ([92m↓36.64%[0m) [26.00% of initial]
[Iter 4040/20000] Loss: 0.0355678 (Best: 0.0005913 @iter3898) ([92m↓45.65%[0m) [14.13% of initial]
[Iter 4050/20000] Loss: 0.0155379 (Best: 0.0005913 @iter3898) ([92m↓56.31%[0m) [6.17% of initial]
[Iter 4060/20000] Loss: 0.0073256 (Best: 0.0005913 @iter3898) ([92m↓52.85%[0m) [2.91% of initial]
[Iter 4070/20000] Loss: 0.0048458 (Best: 0.0005913 @iter3898) ([92m↓33.85%[0m) [1.93% of initial]
[Iter 4080/20000] Loss: 0.0037015 (Best: 0.0005913 @iter3898) ([92m↓23.61%[0m) [1.47% of initial]
[Iter 4090/20000] Loss: 0.0028127 (Best: 0.0005913 @iter3898) ([92m↓24.01%[0m) [1.12% of initial]
Iter:4099, L1 loss=0.002265, Total loss=0.002368, Time:70
[Iter 4100/20000] Loss: 0.0023822 (Best: 0.0005913 @iter3898) ([92m↓15.31%[0m) [0.95% of initial]
[Iter 4110/20000] Loss: 0.0021178 (Best: 0.0005913 @iter3898) ([92m↓11.10%[0m) [0.84% of initial]
[Iter 4120/20000] Loss: 0.0018442 (Best: 0.0005913 @iter3898) ([92m↓12.92%[0m) [0.73% of initial]
[Iter 4130/20000] Loss: 0.0018472 (Best: 0.0005913 @iter3898) ([91m↑0.16%[0m) [0.73% of initial]
[Iter 4140/20000] Loss: 0.0016719 (Best: 0.0005913 @iter3898) ([92m↓9.49%[0m) [0.66% of initial]
[Iter 4150/20000] Loss: 0.0015227 (Best: 0.0005913 @iter3898) ([92m↓8.93%[0m) [0.60% of initial]
[Iter 4160/20000] Loss: 0.0015892 (Best: 0.0005913 @iter3898) ([91m↑4.37%[0m) [0.63% of initial]
[Iter 4170/20000] Loss: 0.0014967 (Best: 0.0005913 @iter3898) ([92m↓5.82%[0m) [0.59% of initial]
[Iter 4180/20000] Loss: 0.0014857 (Best: 0.0005913 @iter3898) ([92m↓0.74%[0m) [0.59% of initial]
[Iter 4190/20000] Loss: 0.0012833 (Best: 0.0005913 @iter3898) ([92m↓13.62%[0m) [0.51% of initial]
Iter:4199, L1 loss=0.00123, Total loss=0.001267, Time:82
[Iter 4200/20000] Loss: 0.0013579 (Best: 0.0005913 @iter3898) ([91m↑5.81%[0m) [0.54% of initial]
[Iter 4210/20000] Loss: 0.0028737 (Best: 0.0005913 @iter3898) ([91m↑111.63%[0m) [1.14% of initial]
[Iter 4220/20000] Loss: 0.0020218 (Best: 0.0005913 @iter3898) ([92m↓29.65%[0m) [0.80% of initial]
[Iter 4230/20000] Loss: 0.0014807 (Best: 0.0005913 @iter3898) ([92m↓26.76%[0m) [0.59% of initial]
[Iter 4240/20000] Loss: 0.0013389 (Best: 0.0005913 @iter3898) ([92m↓9.58%[0m) [0.53% of initial]
[Iter 4250/20000] Loss: 0.0013142 (Best: 0.0005913 @iter3898) ([92m↓1.85%[0m) [0.52% of initial]
[Iter 4260/20000] Loss: 0.0013723 (Best: 0.0005913 @iter3898) ([91m↑4.43%[0m) [0.55% of initial]
[Iter 4270/20000] Loss: 0.0012841 (Best: 0.0005913 @iter3898) ([92m↓6.43%[0m) [0.51% of initial]
[Iter 4280/20000] Loss: 0.0010666 (Best: 0.0005913 @iter3898) ([92m↓16.94%[0m) [0.42% of initial]
[Iter 4290/20000] Loss: 0.0010785 (Best: 0.0005913 @iter3898) ([91m↑1.12%[0m) [0.43% of initial]
Iter:4299, L1 loss=0.001189, Total loss=0.001243, Time:71
[Iter 4300/20000] Loss: 0.0010425 (Best: 0.0005913 @iter3898) ([92m↓3.34%[0m) [0.41% of initial]
[Iter 4310/20000] Loss: 0.0009981 (Best: 0.0005913 @iter3898) ([92m↓4.26%[0m) [0.40% of initial]
[Iter 4320/20000] Loss: 0.0011474 (Best: 0.0005913 @iter3898) ([91m↑14.96%[0m) [0.46% of initial]
[Iter 4330/20000] Loss: 0.0009964 (Best: 0.0005913 @iter3898) ([92m↓13.16%[0m) [0.40% of initial]
[Iter 4340/20000] Loss: 0.0009881 (Best: 0.0005913 @iter3898) ([92m↓0.83%[0m) [0.39% of initial]
[Iter 4350/20000] Loss: 0.0009787 (Best: 0.0005913 @iter3898) ([92m↓0.96%[0m) [0.39% of initial]
[Iter 4360/20000] Loss: 0.0009501 (Best: 0.0005913 @iter3898) ([92m↓2.92%[0m) [0.38% of initial]
[Iter 4370/20000] Loss: 0.0009799 (Best: 0.0005913 @iter3898) ([91m↑3.14%[0m) [0.39% of initial]
[Iter 4380/20000] Loss: 0.0010062 (Best: 0.0005913 @iter3898) ([91m↑2.68%[0m) [0.40% of initial]
[Iter 4390/20000] Loss: 0.0009465 (Best: 0.0005913 @iter3898) ([92m↓5.94%[0m) [0.38% of initial]
Iter:4399, L1 loss=0.0008496, Total loss=0.0008223, Time:101
[Iter 4400/20000] Loss: 0.0009219 (Best: 0.0005913 @iter3898) ([92m↓2.59%[0m) [0.37% of initial]
[Iter 4410/20000] Loss: 0.0021912 (Best: 0.0005913 @iter3898) ([91m↑137.67%[0m) [0.87% of initial]
[Iter 4420/20000] Loss: 0.0014277 (Best: 0.0005913 @iter3898) ([92m↓34.84%[0m) [0.57% of initial]
[Iter 4430/20000] Loss: 0.0012081 (Best: 0.0005913 @iter3898) ([92m↓15.38%[0m) [0.48% of initial]
[Iter 4440/20000] Loss: 0.0010637 (Best: 0.0005913 @iter3898) ([92m↓11.95%[0m) [0.42% of initial]
[Iter 4450/20000] Loss: 0.0009684 (Best: 0.0005913 @iter3898) ([92m↓8.96%[0m) [0.38% of initial]
[Iter 4460/20000] Loss: 0.0009580 (Best: 0.0005913 @iter3898) ([92m↓1.08%[0m) [0.38% of initial]
[Iter 4470/20000] Loss: 0.0010608 (Best: 0.0005913 @iter3898) ([91m↑10.74%[0m) [0.42% of initial]
[Iter 4480/20000] Loss: 0.0009990 (Best: 0.0005913 @iter3898) ([92m↓5.82%[0m) [0.40% of initial]
[Iter 4490/20000] Loss: 0.0010056 (Best: 0.0005913 @iter3898) ([91m↑0.65%[0m) [0.40% of initial]
Iter:4499, L1 loss=0.00104, Total loss=0.00107, Time:72
[Iter 4500/20000] Loss: 0.0011159 (Best: 0.0005913 @iter3898) ([91m↑10.97%[0m) [0.44% of initial]
Pruning 326 points (0.2%) from gaussian0 at iteration 4500
Pruning 359 points (0.2%) from gaussian1 at iteration 4500
[Iter 4510/20000] Loss: 0.0018580 (Best: 0.0005913 @iter3898) ([91m↑66.50%[0m) [0.74% of initial]
[Iter 4520/20000] Loss: 0.0014906 (Best: 0.0005913 @iter3898) ([92m↓19.77%[0m) [0.59% of initial]
[Iter 4530/20000] Loss: 0.0014014 (Best: 0.0005913 @iter3898) ([92m↓5.99%[0m) [0.56% of initial]
[Iter 4540/20000] Loss: 0.0011531 (Best: 0.0005913 @iter3898) ([92m↓17.72%[0m) [0.46% of initial]
[Iter 4550/20000] Loss: 0.0010213 (Best: 0.0005913 @iter3898) ([92m↓11.43%[0m) [0.41% of initial]
[Iter 4560/20000] Loss: 0.0010154 (Best: 0.0005913 @iter3898) ([92m↓0.58%[0m) [0.40% of initial]
[Iter 4570/20000] Loss: 0.0009063 (Best: 0.0005913 @iter3898) ([92m↓10.75%[0m) [0.36% of initial]
[Iter 4580/20000] Loss: 0.0008733 (Best: 0.0005913 @iter3898) ([92m↓3.64%[0m) [0.35% of initial]
[Iter 4590/20000] Loss: 0.0009765 (Best: 0.0005913 @iter3898) ([91m↑11.82%[0m) [0.39% of initial]
Iter:4599, L1 loss=0.0009772, Total loss=0.0009289, Time:72
[Iter 4600/20000] Loss: 0.0009127 (Best: 0.0005913 @iter3898) ([92m↓6.53%[0m) [0.36% of initial]
[Iter 4610/20000] Loss: 0.0023432 (Best: 0.0005913 @iter3898) ([91m↑156.73%[0m) [0.93% of initial]
[Iter 4620/20000] Loss: 0.0016018 (Best: 0.0005913 @iter3898) ([92m↓31.64%[0m) [0.64% of initial]
[Iter 4630/20000] Loss: 0.0012303 (Best: 0.0005913 @iter3898) ([92m↓23.19%[0m) [0.49% of initial]
[Iter 4640/20000] Loss: 0.0010662 (Best: 0.0005913 @iter3898) ([92m↓13.34%[0m) [0.42% of initial]
[Iter 4650/20000] Loss: 0.0009503 (Best: 0.0005913 @iter3898) ([92m↓10.87%[0m) [0.38% of initial]
[Iter 4660/20000] Loss: 0.0008541 (Best: 0.0005913 @iter3898) ([92m↓10.12%[0m) [0.34% of initial]
[Iter 4670/20000] Loss: 0.0008349 (Best: 0.0005913 @iter3898) ([92m↓2.25%[0m) [0.33% of initial]
[Iter 4680/20000] Loss: 0.0008253 (Best: 0.0005913 @iter3898) ([92m↓1.15%[0m) [0.33% of initial]
[Iter 4690/20000] Loss: 0.0007858 (Best: 0.0005913 @iter3898) ([92m↓4.78%[0m) [0.31% of initial]
Iter:4699, L1 loss=0.000854, Total loss=0.0008089, Time:66
[Iter 4700/20000] Loss: 0.0008402 (Best: 0.0005913 @iter3898) ([91m↑6.92%[0m) [0.33% of initial]
[Iter 4710/20000] Loss: 0.0007708 (Best: 0.0005913 @iter3898) ([92m↓8.25%[0m) [0.31% of initial]
[Iter 4720/20000] Loss: 0.0008432 (Best: 0.0005913 @iter3898) ([91m↑9.38%[0m) [0.33% of initial]
[Iter 4730/20000] Loss: 0.0008375 (Best: 0.0005913 @iter3898) ([92m↓0.67%[0m) [0.33% of initial]
[Iter 4740/20000] Loss: 0.0009264 (Best: 0.0005913 @iter3898) ([91m↑10.61%[0m) [0.37% of initial]
[Iter 4750/20000] Loss: 0.0009080 (Best: 0.0005913 @iter3898) ([92m↓1.98%[0m) [0.36% of initial]
[Iter 4760/20000] Loss: 0.0008215 (Best: 0.0005913 @iter3898) ([92m↓9.52%[0m) [0.33% of initial]
[Iter 4770/20000] Loss: 0.0008792 (Best: 0.0005913 @iter3898) ([91m↑7.03%[0m) [0.35% of initial]
[Iter 4780/20000] Loss: 0.0009380 (Best: 0.0005913 @iter3898) ([91m↑6.68%[0m) [0.37% of initial]
[Iter 4790/20000] Loss: 0.0008344 (Best: 0.0005913 @iter3898) ([92m↓11.04%[0m) [0.33% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Iter:4799, L1 loss=0.0008569, Total loss=0.0008225, Time:81
[Iter 4800/20000] Loss: 0.0009493 (Best: 0.0005913 @iter3898) ([91m↑13.78%[0m) [0.38% of initial]
[Iter 4810/20000] Loss: 0.0019158 (Best: 0.0005913 @iter3898) ([91m↑101.80%[0m) [0.76% of initial]
[Iter 4820/20000] Loss: 0.0013706 (Best: 0.0005913 @iter3898) ([92m↓28.46%[0m) [0.54% of initial]
[Iter 4830/20000] Loss: 0.0011767 (Best: 0.0005913 @iter3898) ([92m↓14.15%[0m) [0.47% of initial]
[Iter 4840/20000] Loss: 0.0009232 (Best: 0.0005913 @iter3898) ([92m↓21.54%[0m) [0.37% of initial]
[Iter 4850/20000] Loss: 0.0007976 (Best: 0.0005913 @iter3898) ([92m↓13.60%[0m) [0.32% of initial]
[Iter 4860/20000] Loss: 0.0008360 (Best: 0.0005913 @iter3898) ([91m↑4.80%[0m) [0.33% of initial]
[Iter 4870/20000] Loss: 0.0007630 (Best: 0.0005913 @iter3898) ([92m↓8.73%[0m) [0.30% of initial]
[Iter 4880/20000] Loss: 0.0008294 (Best: 0.0005913 @iter3898) ([91m↑8.70%[0m) [0.33% of initial]
[Iter 4890/20000] Loss: 0.0007670 (Best: 0.0005913 @iter3898) ([92m↓7.52%[0m) [0.30% of initial]
Iter:4899, L1 loss=0.0008821, Total loss=0.0008645, Time:77
[Iter 4900/20000] Loss: 0.0007657 (Best: 0.0005913 @iter3898) ([92m↓0.18%[0m) [0.30% of initial]
[Iter 4910/20000] Loss: 0.0009483 (Best: 0.0005913 @iter3898) ([91m↑23.86%[0m) [0.38% of initial]
[Iter 4920/20000] Loss: 0.0008298 (Best: 0.0005913 @iter3898) ([92m↓12.50%[0m) [0.33% of initial]
[Iter 4930/20000] Loss: 0.0007533 (Best: 0.0005913 @iter3898) ([92m↓9.21%[0m) [0.30% of initial]
[Iter 4940/20000] Loss: 0.0007820 (Best: 0.0005913 @iter3898) ([91m↑3.80%[0m) [0.31% of initial]
[Iter 4950/20000] Loss: 0.0006927 (Best: 0.0005913 @iter3898) ([92m↓11.42%[0m) [0.28% of initial]
[Iter 4960/20000] Loss: 0.0007247 (Best: 0.0005913 @iter3898) ([91m↑4.63%[0m) [0.29% of initial]
[Iter 4970/20000] Loss: 0.0007502 (Best: 0.0005913 @iter3898) ([91m↑3.51%[0m) [0.30% of initial]
[Iter 4980/20000] Loss: 0.0007632 (Best: 0.0005913 @iter3898) ([91m↑1.73%[0m) [0.30% of initial]
[Iter 4990/20000] Loss: 0.0007033 (Best: 0.0005913 @iter3898) ([92m↓7.84%[0m) [0.28% of initial]
Iter:4999, L1 loss=0.0007112, Total loss=0.0006652, Time:79
[Iter 5000/20000] Loss: 0.0006624 (Best: 0.0005913 @iter3898) ([92m↓5.81%[0m) [0.26% of initial]
Pruning 165 points (0.1%) from gaussian0 at iteration 5000
Pruning 166 points (0.1%) from gaussian1 at iteration 5000
[Iter 5010/20000] Loss: 0.0020716 (Best: 0.0005913 @iter3898) ([91m↑212.74%[0m) [0.82% of initial]
[Iter 5020/20000] Loss: 0.0014640 (Best: 0.0005913 @iter3898) ([92m↓29.33%[0m) [0.58% of initial]
[Iter 5030/20000] Loss: 0.0010522 (Best: 0.0005913 @iter3898) ([92m↓28.12%[0m) [0.42% of initial]
[Iter 5040/20000] Loss: 0.0010482 (Best: 0.0005913 @iter3898) ([92m↓0.39%[0m) [0.42% of initial]
[Iter 5050/20000] Loss: 0.0009206 (Best: 0.0005913 @iter3898) ([92m↓12.17%[0m) [0.37% of initial]
[Iter 5060/20000] Loss: 0.0007517 (Best: 0.0005913 @iter3898) ([92m↓18.35%[0m) [0.30% of initial]
[Iter 5070/20000] Loss: 0.0008321 (Best: 0.0005913 @iter3898) ([91m↑10.69%[0m) [0.33% of initial]
[Iter 5080/20000] Loss: 0.0007241 (Best: 0.0005913 @iter3898) ([92m↓12.98%[0m) [0.29% of initial]
[Iter 5090/20000] Loss: 0.0007646 (Best: 0.0005913 @iter3898) ([91m↑5.60%[0m) [0.30% of initial]
Iter:5099, L1 loss=0.0008173, Total loss=0.0007439, Time:81
[Iter 5100/20000] Loss: 0.0007891 (Best: 0.0005913 @iter3898) ([91m↑3.20%[0m) [0.31% of initial]
[Iter 5110/20000] Loss: 0.0007766 (Best: 0.0005913 @iter3898) ([92m↓1.59%[0m) [0.31% of initial]
[Iter 5120/20000] Loss: 0.0007719 (Best: 0.0005913 @iter3898) ([92m↓0.60%[0m) [0.31% of initial]
[Iter 5130/20000] Loss: 0.0007899 (Best: 0.0005913 @iter3898) ([91m↑2.33%[0m) [0.31% of initial]
[Iter 5140/20000] Loss: 0.0006908 (Best: 0.0005913 @iter3898) ([92m↓12.54%[0m) [0.27% of initial]
[Iter 5150/20000] Loss: 0.0007053 (Best: 0.0005913 @iter3898) ([91m↑2.10%[0m) [0.28% of initial]
[Iter 5160/20000] Loss: 0.0007075 (Best: 0.0005912 @iter5158) ([91m↑0.32%[0m) [0.28% of initial]
[Iter 5170/20000] Loss: 0.0007580 (Best: 0.0005912 @iter5158) ([91m↑7.13%[0m) [0.30% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 5180/20000] Loss: 0.0007059 (Best: 0.0005912 @iter5158) ([92m↓6.88%[0m) [0.28% of initial]
[Iter 5190/20000] Loss: 0.0007247 (Best: 0.0005912 @iter5158) ([91m↑2.67%[0m) [0.29% of initial]
Iter:5199, L1 loss=0.0008008, Total loss=0.0007642, Time:85
[Iter 5200/20000] Loss: 0.0007038 (Best: 0.0005912 @iter5158) ([92m↓2.88%[0m) [0.28% of initial]
[Iter 5210/20000] Loss: 0.0018308 (Best: 0.0005912 @iter5158) ([91m↑160.11%[0m) [0.73% of initial]
[Iter 5220/20000] Loss: 0.0013440 (Best: 0.0005912 @iter5158) ([92m↓26.59%[0m) [0.53% of initial]
[Iter 5230/20000] Loss: 0.0010462 (Best: 0.0005912 @iter5158) ([92m↓22.16%[0m) [0.42% of initial]
[Iter 5240/20000] Loss: 0.0008172 (Best: 0.0005912 @iter5158) ([92m↓21.89%[0m) [0.32% of initial]
[Iter 5250/20000] Loss: 0.0010557 (Best: 0.0005912 @iter5158) ([91m↑29.18%[0m) [0.42% of initial]
[Iter 5260/20000] Loss: 0.0008531 (Best: 0.0005912 @iter5158) ([92m↓19.19%[0m) [0.34% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 5270/20000] Loss: 0.0007930 (Best: 0.0005912 @iter5158) ([92m↓7.04%[0m) [0.32% of initial]
[Iter 5280/20000] Loss: 0.0008480 (Best: 0.0005912 @iter5158) ([91m↑6.94%[0m) [0.34% of initial]
[Iter 5290/20000] Loss: 0.0008060 (Best: 0.0005912 @iter5158) ([92m↓4.95%[0m) [0.32% of initial]
Iter:5299, L1 loss=0.0008575, Total loss=0.0008225, Time:92
[Iter 5300/20000] Loss: 0.0008839 (Best: 0.0005912 @iter5158) ([91m↑9.66%[0m) [0.35% of initial]
[Iter 5310/20000] Loss: 0.0008699 (Best: 0.0005912 @iter5158) ([92m↓1.59%[0m) [0.35% of initial]
[Iter 5320/20000] Loss: 0.0007713 (Best: 0.0005912 @iter5158) ([92m↓11.33%[0m) [0.31% of initial]
[Iter 5330/20000] Loss: 0.0006673 (Best: 0.0005912 @iter5158) ([92m↓13.48%[0m) [0.27% of initial]
[Iter 5340/20000] Loss: 0.0006923 (Best: 0.0005912 @iter5158) ([91m↑3.74%[0m) [0.28% of initial]
[Iter 5350/20000] Loss: 0.0007249 (Best: 0.0005622 @iter5344) ([91m↑4.71%[0m) [0.29% of initial]
[Iter 5360/20000] Loss: 0.0007159 (Best: 0.0005622 @iter5344) ([92m↓1.25%[0m) [0.28% of initial]
[Iter 5370/20000] Loss: 0.0007437 (Best: 0.0005622 @iter5344) ([91m↑3.88%[0m) [0.30% of initial]
[Iter 5380/20000] Loss: 0.0007360 (Best: 0.0005622 @iter5344) ([92m↓1.03%[0m) [0.29% of initial]
[Iter 5390/20000] Loss: 0.0007347 (Best: 0.0005622 @iter5344) ([92m↓0.18%[0m) [0.29% of initial]
Iter:5399, L1 loss=0.0006915, Total loss=0.0006434, Time:103
[Iter 5400/20000] Loss: 0.0007338 (Best: 0.0005622 @iter5344) ([92m↓0.11%[0m) [0.29% of initial]
[Iter 5410/20000] Loss: 0.0016384 (Best: 0.0005622 @iter5344) ([91m↑123.26%[0m) [0.65% of initial]
[Iter 5420/20000] Loss: 0.0012191 (Best: 0.0005622 @iter5344) ([92m↓25.59%[0m) [0.48% of initial]
[Iter 5430/20000] Loss: 0.0009068 (Best: 0.0005622 @iter5344) ([92m↓25.61%[0m) [0.36% of initial]
[Iter 5440/20000] Loss: 0.0008187 (Best: 0.0005622 @iter5344) ([92m↓9.72%[0m) [0.33% of initial]
[Iter 5450/20000] Loss: 0.0007135 (Best: 0.0005622 @iter5344) ([92m↓12.85%[0m) [0.28% of initial]
[Iter 5460/20000] Loss: 0.0007901 (Best: 0.0005622 @iter5344) ([91m↑10.74%[0m) [0.31% of initial]
[Iter 5470/20000] Loss: 0.0006758 (Best: 0.0005622 @iter5344) ([92m↓14.46%[0m) [0.27% of initial]
[Iter 5480/20000] Loss: 0.0006482 (Best: 0.0005596 @iter5476) ([92m↓4.10%[0m) [0.26% of initial]
[Iter 5490/20000] Loss: 0.0006717 (Best: 0.0005596 @iter5476) ([91m↑3.64%[0m) [0.27% of initial]
Iter:5499, L1 loss=0.0007175, Total loss=0.000671, Time:104
[Iter 5500/20000] Loss: 0.0006205 (Best: 0.0005596 @iter5476) ([92m↓7.63%[0m) [0.25% of initial]
Pruning 102 points (0.1%) from gaussian0 at iteration 5500
Pruning 104 points (0.1%) from gaussian1 at iteration 5500
[Iter 5510/20000] Loss: 0.0011514 (Best: 0.0005596 @iter5476) ([91m↑85.56%[0m) [0.46% of initial]
[Iter 5520/20000] Loss: 0.0008645 (Best: 0.0005596 @iter5476) ([92m↓24.92%[0m) [0.34% of initial]
[Iter 5530/20000] Loss: 0.0007990 (Best: 0.0005596 @iter5476) ([92m↓7.58%[0m) [0.32% of initial]
[Iter 5540/20000] Loss: 0.0007401 (Best: 0.0005596 @iter5476) ([92m↓7.37%[0m) [0.29% of initial]
[Iter 5550/20000] Loss: 0.0007094 (Best: 0.0005596 @iter5476) ([92m↓4.14%[0m) [0.28% of initial]
[Iter 5560/20000] Loss: 0.0006567 (Best: 0.0005596 @iter5476) ([92m↓7.43%[0m) [0.26% of initial]
[Iter 5570/20000] Loss: 0.0006572 (Best: 0.0005596 @iter5476) ([91m↑0.07%[0m) [0.26% of initial]
[Iter 5580/20000] Loss: 0.0007568 (Best: 0.0005596 @iter5476) ([91m↑15.15%[0m) [0.30% of initial]
[Iter 5590/20000] Loss: 0.0008124 (Best: 0.0005596 @iter5476) ([91m↑7.35%[0m) [0.32% of initial]
Iter:5599, L1 loss=0.0006718, Total loss=0.0006083, Time:81
[Iter 5600/20000] Loss: 0.0006379 (Best: 0.0005596 @iter5476) ([92m↓21.48%[0m) [0.25% of initial]
[Iter 5610/20000] Loss: 0.0017132 (Best: 0.0005596 @iter5476) ([91m↑168.57%[0m) [0.68% of initial]
[Iter 5620/20000] Loss: 0.0010962 (Best: 0.0005596 @iter5476) ([92m↓36.01%[0m) [0.44% of initial]
[Iter 5630/20000] Loss: 0.0009183 (Best: 0.0005596 @iter5476) ([92m↓16.23%[0m) [0.36% of initial]
[Iter 5640/20000] Loss: 0.0008148 (Best: 0.0005596 @iter5476) ([92m↓11.28%[0m) [0.32% of initial]
[Iter 5650/20000] Loss: 0.0006953 (Best: 0.0005596 @iter5476) ([92m↓14.67%[0m) [0.28% of initial]
[Iter 5660/20000] Loss: 0.0006787 (Best: 0.0005596 @iter5476) ([92m↓2.37%[0m) [0.27% of initial]
[Iter 5670/20000] Loss: 0.0006843 (Best: 0.0005596 @iter5476) ([91m↑0.81%[0m) [0.27% of initial]
[Iter 5680/20000] Loss: 0.0006375 (Best: 0.0005596 @iter5476) ([92m↓6.84%[0m) [0.25% of initial]
[Iter 5690/20000] Loss: 0.0006718 (Best: 0.0005596 @iter5476) ([91m↑5.38%[0m) [0.27% of initial]
Iter:5699, L1 loss=0.0006497, Total loss=0.0005957, Time:80
[Iter 5700/20000] Loss: 0.0005825 (Best: 0.0005559 @iter5698) ([92m↓13.29%[0m) [0.23% of initial]
[Iter 5710/20000] Loss: 0.0007256 (Best: 0.0005162 @iter5701) ([91m↑24.57%[0m) [0.29% of initial]
[Iter 5720/20000] Loss: 0.0006512 (Best: 0.0005162 @iter5701) ([92m↓10.25%[0m) [0.26% of initial]
[Iter 5730/20000] Loss: 0.0006854 (Best: 0.0005162 @iter5701) ([91m↑5.24%[0m) [0.27% of initial]
[Iter 5740/20000] Loss: 0.0005836 (Best: 0.0005162 @iter5701) ([92m↓14.85%[0m) [0.23% of initial]
[Iter 5750/20000] Loss: 0.0006011 (Best: 0.0005162 @iter5701) ([91m↑3.01%[0m) [0.24% of initial]
[Iter 5760/20000] Loss: 0.0006015 (Best: 0.0005162 @iter5701) ([91m↑0.06%[0m) [0.24% of initial]
[Iter 5770/20000] Loss: 0.0005395 (Best: 0.0004901 @iter5770) ([92m↓10.31%[0m) [0.21% of initial]
[Iter 5780/20000] Loss: 0.0005513 (Best: 0.0004901 @iter5770) ([91m↑2.19%[0m) [0.22% of initial]
[Iter 5790/20000] Loss: 0.0005967 (Best: 0.0004901 @iter5770) ([91m↑8.23%[0m) [0.24% of initial]
Iter:5799, L1 loss=0.0006173, Total loss=0.0005864, Time:100
[Iter 5800/20000] Loss: 0.0005786 (Best: 0.0004733 @iter5797) ([92m↓3.04%[0m) [0.23% of initial]
[Iter 5810/20000] Loss: 0.0013433 (Best: 0.0004733 @iter5797) ([91m↑132.17%[0m) [0.53% of initial]
[Iter 5820/20000] Loss: 0.0010214 (Best: 0.0004733 @iter5797) ([92m↓23.96%[0m) [0.41% of initial]
[Iter 5830/20000] Loss: 0.0008001 (Best: 0.0004733 @iter5797) ([92m↓21.66%[0m) [0.32% of initial]
[Iter 5840/20000] Loss: 0.0007058 (Best: 0.0004733 @iter5797) ([92m↓11.79%[0m) [0.28% of initial]
[Iter 5850/20000] Loss: 0.0007038 (Best: 0.0004733 @iter5797) ([92m↓0.29%[0m) [0.28% of initial]
[Iter 5860/20000] Loss: 0.0005889 (Best: 0.0004733 @iter5797) ([92m↓16.32%[0m) [0.23% of initial]
[Iter 5870/20000] Loss: 0.0006871 (Best: 0.0004733 @iter5797) ([91m↑16.68%[0m) [0.27% of initial]
[Iter 5880/20000] Loss: 0.0006357 (Best: 0.0004733 @iter5797) ([92m↓7.49%[0m) [0.25% of initial]
[Iter 5890/20000] Loss: 0.0005919 (Best: 0.0004733 @iter5797) ([92m↓6.89%[0m) [0.24% of initial]
Iter:5899, L1 loss=0.0006225, Total loss=0.0005673, Time:111
[Iter 5900/20000] Loss: 0.0005822 (Best: 0.0004733 @iter5797) ([92m↓1.65%[0m) [0.23% of initial]
[Iter 5910/20000] Loss: 0.0006177 (Best: 0.0004733 @iter5797) ([91m↑6.10%[0m) [0.25% of initial]
[Iter 5920/20000] Loss: 0.0005927 (Best: 0.0004733 @iter5797) ([92m↓4.04%[0m) [0.24% of initial]
[Iter 5930/20000] Loss: 0.0005046 (Best: 0.0004733 @iter5797) ([92m↓14.86%[0m) [0.20% of initial]
[Iter 5940/20000] Loss: 0.0006544 (Best: 0.0004733 @iter5797) ([91m↑29.69%[0m) [0.26% of initial]
[Iter 5950/20000] Loss: 0.0005339 (Best: 0.0004733 @iter5797) ([92m↓18.42%[0m) [0.21% of initial]
[Iter 5960/20000] Loss: 0.0005815 (Best: 0.0004733 @iter5797) ([91m↑8.91%[0m) [0.23% of initial]
[Iter 5970/20000] Loss: 0.0006762 (Best: 0.0004733 @iter5797) ([91m↑16.28%[0m) [0.27% of initial]
[Iter 5980/20000] Loss: 0.0006095 (Best: 0.0004733 @iter5797) ([92m↓9.86%[0m) [0.24% of initial]
[Iter 5990/20000] Loss: 0.0006185 (Best: 0.0004733 @iter5797) ([91m↑1.48%[0m) [0.25% of initial]
Iter:5999, L1 loss=0.0006834, Total loss=0.0006212, Time:102
[Iter 6000/20000] Loss: 0.0006225 (Best: 0.0004733 @iter5797) ([91m↑0.64%[0m) [0.25% of initial]
Pruning 86 points (0.0%) from gaussian0 at iteration 6000
Pruning 91 points (0.0%) from gaussian1 at iteration 6000
[Iter 6010/20000] Loss: 0.0019477 (Best: 0.0004733 @iter5797) ([91m↑212.88%[0m) [0.77% of initial]
[Iter 6020/20000] Loss: 0.0012966 (Best: 0.0004733 @iter5797) ([92m↓33.43%[0m) [0.52% of initial]
[Iter 6030/20000] Loss: 0.0008824 (Best: 0.0004733 @iter5797) ([92m↓31.95%[0m) [0.35% of initial]
[Iter 6040/20000] Loss: 0.0006900 (Best: 0.0004733 @iter5797) ([92m↓21.81%[0m) [0.27% of initial]
[Iter 6050/20000] Loss: 0.0006237 (Best: 0.0004733 @iter5797) ([92m↓9.60%[0m) [0.25% of initial]
[Iter 6060/20000] Loss: 0.0006587 (Best: 0.0004733 @iter5797) ([91m↑5.61%[0m) [0.26% of initial]
[Iter 6070/20000] Loss: 0.0006423 (Best: 0.0004733 @iter5797) ([92m↓2.50%[0m) [0.26% of initial]
[Iter 6080/20000] Loss: 0.0006421 (Best: 0.0004733 @iter5797) ([92m↓0.03%[0m) [0.26% of initial]
[Iter 6090/20000] Loss: 0.0005803 (Best: 0.0004733 @iter5797) ([92m↓9.62%[0m) [0.23% of initial]
Iter:6099, L1 loss=0.0006062, Total loss=0.0005467, Time:84
[Iter 6100/20000] Loss: 0.0005766 (Best: 0.0004733 @iter5797) ([92m↓0.65%[0m) [0.23% of initial]
[Iter 6110/20000] Loss: 0.0005621 (Best: 0.0004733 @iter5797) ([92m↓2.51%[0m) [0.22% of initial]
[Iter 6120/20000] Loss: 0.0006367 (Best: 0.0004733 @iter5797) ([91m↑13.26%[0m) [0.25% of initial]
[Iter 6130/20000] Loss: 0.0006053 (Best: 0.0004733 @iter5797) ([92m↓4.93%[0m) [0.24% of initial]
[Iter 6140/20000] Loss: 0.0005295 (Best: 0.0004733 @iter5797) ([92m↓12.51%[0m) [0.21% of initial]
[Iter 6150/20000] Loss: 0.0005536 (Best: 0.0004733 @iter5797) ([91m↑4.55%[0m) [0.22% of initial]
[Iter 6160/20000] Loss: 0.0005349 (Best: 0.0004693 @iter6152) ([92m↓3.37%[0m) [0.21% of initial]
[Iter 6170/20000] Loss: 0.0005536 (Best: 0.0004693 @iter6152) ([91m↑3.49%[0m) [0.22% of initial]
[Iter 6180/20000] Loss: 0.0006215 (Best: 0.0004693 @iter6152) ([91m↑12.27%[0m) [0.25% of initial]
[Iter 6190/20000] Loss: 0.0005243 (Best: 0.0004693 @iter6152) ([92m↓15.64%[0m) [0.21% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Iter:6199, L1 loss=0.000526, Total loss=0.0004804, Time:113
[Iter 6200/20000] Loss: 0.0005334 (Best: 0.0004693 @iter6152) ([91m↑1.73%[0m) [0.21% of initial]
[Iter 6210/20000] Loss: 0.0014091 (Best: 0.0004693 @iter6152) ([91m↑164.17%[0m) [0.56% of initial]
[Iter 6220/20000] Loss: 0.0009848 (Best: 0.0004693 @iter6152) ([92m↓30.11%[0m) [0.39% of initial]
[Iter 6230/20000] Loss: 0.0008724 (Best: 0.0004693 @iter6152) ([92m↓11.42%[0m) [0.35% of initial]
[Iter 6240/20000] Loss: 0.0006935 (Best: 0.0004693 @iter6152) ([92m↓20.51%[0m) [0.28% of initial]
[Iter 6250/20000] Loss: 0.0006183 (Best: 0.0004693 @iter6152) ([92m↓10.84%[0m) [0.25% of initial]
[Iter 6260/20000] Loss: 0.0006765 (Best: 0.0004693 @iter6152) ([91m↑9.41%[0m) [0.27% of initial]
[Iter 6270/20000] Loss: 0.0006075 (Best: 0.0004693 @iter6152) ([92m↓10.20%[0m) [0.24% of initial]
[Iter 6280/20000] Loss: 0.0006375 (Best: 0.0004693 @iter6152) ([91m↑4.94%[0m) [0.25% of initial]
[Iter 6290/20000] Loss: 0.0005725 (Best: 0.0004693 @iter6152) ([92m↓10.19%[0m) [0.23% of initial]
Iter:6299, L1 loss=0.0007275, Total loss=0.000657, Time:94
[Iter 6300/20000] Loss: 0.0007575 (Best: 0.0004693 @iter6152) ([91m↑32.33%[0m) [0.30% of initial]
[Iter 6310/20000] Loss: 0.0006624 (Best: 0.0004693 @iter6152) ([92m↓12.56%[0m) [0.26% of initial]
[Iter 6320/20000] Loss: 0.0006569 (Best: 0.0004693 @iter6152) ([92m↓0.83%[0m) [0.26% of initial]
[Iter 6330/20000] Loss: 0.0006266 (Best: 0.0004693 @iter6152) ([92m↓4.62%[0m) [0.25% of initial]
[Iter 6340/20000] Loss: 0.0005124 (Best: 0.0004604 @iter6340) ([92m↓18.23%[0m) [0.20% of initial]
[Iter 6350/20000] Loss: 0.0005151 (Best: 0.0004604 @iter6340) ([91m↑0.53%[0m) [0.20% of initial]
[Iter 6360/20000] Loss: 0.0005859 (Best: 0.0004604 @iter6340) ([91m↑13.74%[0m) [0.23% of initial]
[Iter 6370/20000] Loss: 0.0005686 (Best: 0.0004604 @iter6340) ([92m↓2.94%[0m) [0.23% of initial]
[Iter 6380/20000] Loss: 0.0005281 (Best: 0.0004604 @iter6340) ([92m↓7.14%[0m) [0.21% of initial]
[Iter 6390/20000] Loss: 0.0005531 (Best: 0.0004604 @iter6340) ([91m↑4.75%[0m) [0.22% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Iter:6399, L1 loss=0.0005768, Total loss=0.0005216, Time:97
[Iter 6400/20000] Loss: 0.0005753 (Best: 0.0004604 @iter6340) ([91m↑4.01%[0m) [0.23% of initial]
[Iter 6410/20000] Loss: 0.0013116 (Best: 0.0004604 @iter6340) ([91m↑128.00%[0m) [0.52% of initial]
[Iter 6420/20000] Loss: 0.0010982 (Best: 0.0004604 @iter6340) ([92m↓16.27%[0m) [0.44% of initial]
[Iter 6430/20000] Loss: 0.0009027 (Best: 0.0004604 @iter6340) ([92m↓17.80%[0m) [0.36% of initial]
[Iter 6440/20000] Loss: 0.0007524 (Best: 0.0004604 @iter6340) ([92m↓16.65%[0m) [0.30% of initial]
[Iter 6450/20000] Loss: 0.0006685 (Best: 0.0004604 @iter6340) ([92m↓11.16%[0m) [0.27% of initial]
[Iter 6460/20000] Loss: 0.0005861 (Best: 0.0004604 @iter6340) ([92m↓12.31%[0m) [0.23% of initial]
[Iter 6470/20000] Loss: 0.0005650 (Best: 0.0004604 @iter6340) ([92m↓3.62%[0m) [0.22% of initial]
[Iter 6480/20000] Loss: 0.0005636 (Best: 0.0004604 @iter6340) ([92m↓0.24%[0m) [0.22% of initial]
[Iter 6490/20000] Loss: 0.0005222 (Best: 0.0004604 @iter6340) ([92m↓7.34%[0m) [0.21% of initial]
Iter:6499, L1 loss=0.0006694, Total loss=0.0006259, Time:95
[Iter 6500/20000] Loss: 0.0006163 (Best: 0.0004604 @iter6340) ([91m↑18.01%[0m) [0.24% of initial]
Pruning 79 points (0.0%) from gaussian0 at iteration 6500
Pruning 79 points (0.0%) from gaussian1 at iteration 6500
[Iter 6510/20000] Loss: 0.0012996 (Best: 0.0004604 @iter6340) ([91m↑110.87%[0m) [0.52% of initial]
[Iter 6520/20000] Loss: 0.0008348 (Best: 0.0004604 @iter6340) ([92m↓35.76%[0m) [0.33% of initial]
[Iter 6530/20000] Loss: 0.0007666 (Best: 0.0004604 @iter6340) ([92m↓8.17%[0m) [0.30% of initial]
[Iter 6540/20000] Loss: 0.0006142 (Best: 0.0004604 @iter6340) ([92m↓19.89%[0m) [0.24% of initial]
[Iter 6550/20000] Loss: 0.0005581 (Best: 0.0004604 @iter6340) ([92m↓9.13%[0m) [0.22% of initial]
[Iter 6560/20000] Loss: 0.0004787 (Best: 0.0004477 @iter6559) ([92m↓14.22%[0m) [0.19% of initial]
[Iter 6570/20000] Loss: 0.0005663 (Best: 0.0004368 @iter6568) ([91m↑18.28%[0m) [0.22% of initial]
[Iter 6580/20000] Loss: 0.0005676 (Best: 0.0004368 @iter6568) ([91m↑0.24%[0m) [0.23% of initial]
[Iter 6590/20000] Loss: 0.0004848 (Best: 0.0004368 @iter6568) ([92m↓14.59%[0m) [0.19% of initial]
Iter:6599, L1 loss=0.0005573, Total loss=0.0004976, Time:105
[Iter 6600/20000] Loss: 0.0005112 (Best: 0.0004337 @iter6592) ([91m↑5.45%[0m) [0.20% of initial]
[Iter 6610/20000] Loss: 0.0013936 (Best: 0.0004337 @iter6592) ([91m↑172.61%[0m) [0.55% of initial]
[Iter 6620/20000] Loss: 0.0009479 (Best: 0.0004337 @iter6592) ([92m↓31.98%[0m) [0.38% of initial]
[Iter 6630/20000] Loss: 0.0006879 (Best: 0.0004337 @iter6592) ([92m↓27.43%[0m) [0.27% of initial]
[Iter 6640/20000] Loss: 0.0005611 (Best: 0.0004337 @iter6592) ([92m↓18.44%[0m) [0.22% of initial]
[Iter 6650/20000] Loss: 0.0005358 (Best: 0.0004337 @iter6592) ([92m↓4.51%[0m) [0.21% of initial]
[Iter 6660/20000] Loss: 0.0005939 (Best: 0.0004337 @iter6592) ([91m↑10.85%[0m) [0.24% of initial]
[Iter 6670/20000] Loss: 0.0005685 (Best: 0.0004337 @iter6592) ([92m↓4.28%[0m) [0.23% of initial]
[Iter 6680/20000] Loss: 0.0006010 (Best: 0.0004337 @iter6592) ([91m↑5.72%[0m) [0.24% of initial]
[Iter 6690/20000] Loss: 0.0005448 (Best: 0.0004337 @iter6592) ([92m↓9.35%[0m) [0.22% of initial]
Iter:6699, L1 loss=0.000625, Total loss=0.0005384, Time:92
[Iter 6700/20000] Loss: 0.0005129 (Best: 0.0004337 @iter6592) ([92m↓5.85%[0m) [0.20% of initial]
[Iter 6710/20000] Loss: 0.0005621 (Best: 0.0004337 @iter6592) ([91m↑9.58%[0m) [0.22% of initial]
[Iter 6720/20000] Loss: 0.0005078 (Best: 0.0004337 @iter6592) ([92m↓9.65%[0m) [0.20% of initial]
[Iter 6730/20000] Loss: 0.0004542 (Best: 0.0004152 @iter6724) ([92m↓10.56%[0m) [0.18% of initial]
[Iter 6740/20000] Loss: 0.0004938 (Best: 0.0004152 @iter6724) ([91m↑8.73%[0m) [0.20% of initial]
[Iter 6750/20000] Loss: 0.0005187 (Best: 0.0004152 @iter6724) ([91m↑5.05%[0m) [0.21% of initial]
[Iter 6760/20000] Loss: 0.0004911 (Best: 0.0004152 @iter6724) ([92m↓5.33%[0m) [0.20% of initial]
[Iter 6770/20000] Loss: 0.0004823 (Best: 0.0004152 @iter6724) ([92m↓1.79%[0m) [0.19% of initial]
[Iter 6780/20000] Loss: 0.0004486 (Best: 0.0004152 @iter6724) ([92m↓6.98%[0m) [0.18% of initial]
[Iter 6790/20000] Loss: 0.0005107 (Best: 0.0003936 @iter6781) ([91m↑13.83%[0m) [0.20% of initial]
Iter:6799, L1 loss=0.0004682, Total loss=0.0004236, Time:94
[Iter 6800/20000] Loss: 0.0004423 (Best: 0.0003936 @iter6781) ([92m↓13.39%[0m) [0.18% of initial]
[Iter 6810/20000] Loss: 0.0010974 (Best: 0.0003936 @iter6781) ([91m↑148.14%[0m) [0.44% of initial]
[Iter 6820/20000] Loss: 0.0008794 (Best: 0.0003936 @iter6781) ([92m↓19.87%[0m) [0.35% of initial]
[Iter 6830/20000] Loss: 0.0006638 (Best: 0.0003936 @iter6781) ([92m↓24.52%[0m) [0.26% of initial]
[Iter 6840/20000] Loss: 0.0005849 (Best: 0.0003936 @iter6781) ([92m↓11.88%[0m) [0.23% of initial]
[Iter 6850/20000] Loss: 0.0005520 (Best: 0.0003936 @iter6781) ([92m↓5.63%[0m) [0.22% of initial]
[Iter 6860/20000] Loss: 0.0005064 (Best: 0.0003936 @iter6781) ([92m↓8.26%[0m) [0.20% of initial]
[Iter 6870/20000] Loss: 0.0005091 (Best: 0.0003936 @iter6781) ([91m↑0.53%[0m) [0.20% of initial]
[Iter 6880/20000] Loss: 0.0004784 (Best: 0.0003936 @iter6781) ([92m↓6.03%[0m) [0.19% of initial]
[Iter 6890/20000] Loss: 0.0005594 (Best: 0.0003936 @iter6781) ([91m↑16.93%[0m) [0.22% of initial]
Iter:6899, L1 loss=0.0006073, Total loss=0.0005784, Time:103
[Iter 6900/20000] Loss: 0.0005674 (Best: 0.0003936 @iter6781) ([91m↑1.43%[0m) [0.23% of initial]
[Iter 6910/20000] Loss: 0.0005751 (Best: 0.0003936 @iter6781) ([91m↑1.36%[0m) [0.23% of initial]
[Iter 6920/20000] Loss: 0.0005108 (Best: 0.0003936 @iter6781) ([92m↓11.17%[0m) [0.20% of initial]
[Iter 6930/20000] Loss: 0.0005103 (Best: 0.0003936 @iter6781) ([92m↓0.10%[0m) [0.20% of initial]
[Iter 6940/20000] Loss: 0.0004560 (Best: 0.0003936 @iter6781) ([92m↓10.65%[0m) [0.18% of initial]
[Iter 6950/20000] Loss: 0.0004520 (Best: 0.0003936 @iter6781) ([92m↓0.87%[0m) [0.18% of initial]
[Iter 6960/20000] Loss: 0.0004331 (Best: 0.0003901 @iter6959) ([92m↓4.17%[0m) [0.17% of initial]
[Iter 6970/20000] Loss: 0.0005111 (Best: 0.0003783 @iter6961) ([91m↑18.00%[0m) [0.20% of initial]
[Iter 6980/20000] Loss: 0.0005301 (Best: 0.0003783 @iter6961) ([91m↑3.72%[0m) [0.21% of initial]
[Iter 6990/20000] Loss: 0.0004818 (Best: 0.0003783 @iter6961) ([92m↓9.11%[0m) [0.19% of initial]
Iter:6999, L1 loss=0.0006088, Total loss=0.0005712, Time:71
[Iter 7000/20000] Loss: 0.0004814 (Best: 0.0003783 @iter6961) ([92m↓0.09%[0m) [0.19% of initial]
Pruning 93 points (0.1%) from gaussian0 at iteration 7000
Pruning 58 points (0.0%) from gaussian1 at iteration 7000
[Iter 7010/20000] Loss: 0.0014508 (Best: 0.0003783 @iter6961) ([91m↑201.38%[0m) [0.58% of initial]
[Iter 7020/20000] Loss: 0.0009645 (Best: 0.0003783 @iter6961) ([92m↓33.52%[0m) [0.38% of initial]
[Iter 7030/20000] Loss: 0.0006940 (Best: 0.0003783 @iter6961) ([92m↓28.05%[0m) [0.28% of initial]
[Iter 7040/20000] Loss: 0.0005756 (Best: 0.0003783 @iter6961) ([92m↓17.07%[0m) [0.23% of initial]
[Iter 7050/20000] Loss: 0.0005417 (Best: 0.0003783 @iter6961) ([92m↓5.88%[0m) [0.22% of initial]
[Iter 7060/20000] Loss: 0.0005716 (Best: 0.0003783 @iter6961) ([91m↑5.52%[0m) [0.23% of initial]
[Iter 7070/20000] Loss: 0.0005105 (Best: 0.0003783 @iter6961) ([92m↓10.70%[0m) [0.20% of initial]
[Iter 7080/20000] Loss: 0.0005198 (Best: 0.0003783 @iter6961) ([91m↑1.84%[0m) [0.21% of initial]
[Iter 7090/20000] Loss: 0.0005364 (Best: 0.0003783 @iter6961) ([91m↑3.19%[0m) [0.21% of initial]
Iter:7099, L1 loss=0.0005326, Total loss=0.000472, Time:91
[Iter 7100/20000] Loss: 0.0005021 (Best: 0.0003783 @iter6961) ([92m↓6.41%[0m) [0.20% of initial]
[Iter 7110/20000] Loss: 0.0005133 (Best: 0.0003783 @iter6961) ([91m↑2.24%[0m) [0.20% of initial]
[Iter 7120/20000] Loss: 0.0004755 (Best: 0.0003783 @iter6961) ([92m↓7.36%[0m) [0.19% of initial]
[Iter 7130/20000] Loss: 0.0004614 (Best: 0.0003783 @iter6961) ([92m↓2.98%[0m) [0.18% of initial]
[Iter 7140/20000] Loss: 0.0005437 (Best: 0.0003783 @iter6961) ([91m↑17.84%[0m) [0.22% of initial]
[Iter 7150/20000] Loss: 0.0004944 (Best: 0.0003783 @iter6961) ([92m↓9.06%[0m) [0.20% of initial]
[Iter 7160/20000] Loss: 0.0004914 (Best: 0.0003783 @iter6961) ([92m↓0.61%[0m) [0.20% of initial]
[Iter 7170/20000] Loss: 0.0004998 (Best: 0.0003783 @iter6961) ([91m↑1.70%[0m) [0.20% of initial]
[Iter 7180/20000] Loss: 0.0005121 (Best: 0.0003783 @iter6961) ([91m↑2.46%[0m) [0.20% of initial]
[Iter 7190/20000] Loss: 0.0004422 (Best: 0.0003783 @iter6961) ([92m↓13.64%[0m) [0.18% of initial]
Iter:7199, L1 loss=0.000506, Total loss=0.0004681, Time:81
[Iter 7200/20000] Loss: 0.0004731 (Best: 0.0003783 @iter6961) ([91m↑6.99%[0m) [0.19% of initial]
[Iter 7210/20000] Loss: 0.0011732 (Best: 0.0003783 @iter6961) ([91m↑147.95%[0m) [0.47% of initial]
[Iter 7220/20000] Loss: 0.0009795 (Best: 0.0003783 @iter6961) ([92m↓16.51%[0m) [0.39% of initial]
[Iter 7230/20000] Loss: 0.0007380 (Best: 0.0003783 @iter6961) ([92m↓24.65%[0m) [0.29% of initial]
[Iter 7240/20000] Loss: 0.0006054 (Best: 0.0003783 @iter6961) ([92m↓17.97%[0m) [0.24% of initial]
[Iter 7250/20000] Loss: 0.0005095 (Best: 0.0003783 @iter6961) ([92m↓15.84%[0m) [0.20% of initial]
[Iter 7260/20000] Loss: 0.0004873 (Best: 0.0003783 @iter6961) ([92m↓4.36%[0m) [0.19% of initial]
[Iter 7270/20000] Loss: 0.0004508 (Best: 0.0003783 @iter6961) ([92m↓7.49%[0m) [0.18% of initial]
[Iter 7280/20000] Loss: 0.0004395 (Best: 0.0003783 @iter6961) ([92m↓2.51%[0m) [0.17% of initial]
[Iter 7290/20000] Loss: 0.0004575 (Best: 0.0003783 @iter6961) ([91m↑4.10%[0m) [0.18% of initial]
Iter:7299, L1 loss=0.0005688, Total loss=0.0005242, Time:99
[Iter 7300/20000] Loss: 0.0004755 (Best: 0.0003783 @iter6961) ([91m↑3.92%[0m) [0.19% of initial]
[Iter 7310/20000] Loss: 0.0004684 (Best: 0.0003783 @iter6961) ([92m↓1.48%[0m) [0.19% of initial]
[Iter 7320/20000] Loss: 0.0005378 (Best: 0.0003783 @iter6961) ([91m↑14.82%[0m) [0.21% of initial]
[Iter 7330/20000] Loss: 0.0005081 (Best: 0.0003783 @iter6961) ([92m↓5.52%[0m) [0.20% of initial]
[Iter 7340/20000] Loss: 0.0004719 (Best: 0.0003783 @iter6961) ([92m↓7.13%[0m) [0.19% of initial]
[Iter 7350/20000] Loss: 0.0005250 (Best: 0.0003783 @iter6961) ([91m↑11.26%[0m) [0.21% of initial]
[Iter 7360/20000] Loss: 0.0005313 (Best: 0.0003783 @iter6961) ([91m↑1.19%[0m) [0.21% of initial]
[Iter 7370/20000] Loss: 0.0004590 (Best: 0.0003783 @iter6961) ([92m↓13.61%[0m) [0.18% of initial]
[Iter 7380/20000] Loss: 0.0005900 (Best: 0.0003783 @iter6961) ([91m↑28.56%[0m) [0.23% of initial]
[Iter 7390/20000] Loss: 0.0005962 (Best: 0.0003783 @iter6961) ([91m↑1.04%[0m) [0.24% of initial]
Iter:7399, L1 loss=0.0006489, Total loss=0.0005343, Time:96
[Iter 7400/20000] Loss: 0.0005901 (Best: 0.0003783 @iter6961) ([92m↓1.02%[0m) [0.23% of initial]
[Iter 7410/20000] Loss: 0.0011791 (Best: 0.0003783 @iter6961) ([91m↑99.82%[0m) [0.47% of initial]
[Iter 7420/20000] Loss: 0.0008477 (Best: 0.0003783 @iter6961) ([92m↓28.11%[0m) [0.34% of initial]
[Iter 7430/20000] Loss: 0.0006935 (Best: 0.0003783 @iter6961) ([92m↓18.19%[0m) [0.28% of initial]
[Iter 7440/20000] Loss: 0.0006343 (Best: 0.0003783 @iter6961) ([92m↓8.53%[0m) [0.25% of initial]
[Iter 7450/20000] Loss: 0.0005605 (Best: 0.0003783 @iter6961) ([92m↓11.64%[0m) [0.22% of initial]
[Iter 7460/20000] Loss: 0.0005347 (Best: 0.0003783 @iter6961) ([92m↓4.60%[0m) [0.21% of initial]
[Iter 7470/20000] Loss: 0.0005030 (Best: 0.0003783 @iter6961) ([92m↓5.92%[0m) [0.20% of initial]
[Iter 7480/20000] Loss: 0.0004996 (Best: 0.0003783 @iter6961) ([92m↓0.69%[0m) [0.20% of initial]
[Iter 7490/20000] Loss: 0.0004204 (Best: 0.0003783 @iter6961) ([92m↓15.85%[0m) [0.17% of initial]
Iter:7499, L1 loss=0.0005078, Total loss=0.0004542, Time:89
[Iter 7500/20000] Loss: 0.0004643 (Best: 0.0003783 @iter6961) ([91m↑10.45%[0m) [0.18% of initial]
Pruning 66 points (0.0%) from gaussian0 at iteration 7500
Pruning 74 points (0.0%) from gaussian1 at iteration 7500
[Iter 7510/20000] Loss: 0.0011868 (Best: 0.0003783 @iter6961) ([91m↑155.60%[0m) [0.47% of initial]
[Iter 7520/20000] Loss: 0.0007697 (Best: 0.0003783 @iter6961) ([92m↓35.15%[0m) [0.31% of initial]
[Iter 7530/20000] Loss: 0.0005858 (Best: 0.0003783 @iter6961) ([92m↓23.89%[0m) [0.23% of initial]
[Iter 7540/20000] Loss: 0.0004347 (Best: 0.0003783 @iter6961) ([92m↓25.79%[0m) [0.17% of initial]
[Iter 7550/20000] Loss: 0.0004306 (Best: 0.0003783 @iter6961) ([92m↓0.94%[0m) [0.17% of initial]
[Iter 7560/20000] Loss: 0.0004157 (Best: 0.0003646 @iter7555) ([92m↓3.47%[0m) [0.17% of initial]
[Iter 7570/20000] Loss: 0.0004362 (Best: 0.0003646 @iter7555) ([91m↑4.93%[0m) [0.17% of initial]
[Iter 7580/20000] Loss: 0.0004590 (Best: 0.0003646 @iter7555) ([91m↑5.23%[0m) [0.18% of initial]
[Iter 7590/20000] Loss: 0.0004722 (Best: 0.0003646 @iter7555) ([91m↑2.89%[0m) [0.19% of initial]
Iter:7599, L1 loss=0.0004668, Total loss=0.0004125, Time:100
[Iter 7600/20000] Loss: 0.0004188 (Best: 0.0003646 @iter7555) ([92m↓11.30%[0m) [0.17% of initial]
[Iter 7610/20000] Loss: 0.0011043 (Best: 0.0003646 @iter7555) ([91m↑163.67%[0m) [0.44% of initial]
[Iter 7620/20000] Loss: 0.0007760 (Best: 0.0003646 @iter7555) ([92m↓29.73%[0m) [0.31% of initial]
[Iter 7630/20000] Loss: 0.0006590 (Best: 0.0003646 @iter7555) ([92m↓15.08%[0m) [0.26% of initial]
[Iter 7640/20000] Loss: 0.0005524 (Best: 0.0003646 @iter7555) ([92m↓16.17%[0m) [0.22% of initial]
[Iter 7650/20000] Loss: 0.0004963 (Best: 0.0003646 @iter7555) ([92m↓10.16%[0m) [0.20% of initial]
[Iter 7660/20000] Loss: 0.0004125 (Best: 0.0003646 @iter7555) ([92m↓16.89%[0m) [0.16% of initial]
[Iter 7670/20000] Loss: 0.0003844 (Best: 0.0003646 @iter7555) ([92m↓6.81%[0m) [0.15% of initial]
[Iter 7680/20000] Loss: 0.0004197 (Best: 0.0003644 @iter7675) ([91m↑9.19%[0m) [0.17% of initial]
[Iter 7690/20000] Loss: 0.0004013 (Best: 0.0003628 @iter7690) ([92m↓4.39%[0m) [0.16% of initial]
Iter:7699, L1 loss=0.0004224, Total loss=0.0003881, Time:95
[Iter 7700/20000] Loss: 0.0003978 (Best: 0.0003628 @iter7690) ([92m↓0.87%[0m) [0.16% of initial]
[Iter 7710/20000] Loss: 0.0003831 (Best: 0.0003628 @iter7690) ([92m↓3.69%[0m) [0.15% of initial]
[Iter 7720/20000] Loss: 0.0003728 (Best: 0.0003297 @iter7714) ([92m↓2.69%[0m) [0.15% of initial]
[Iter 7730/20000] Loss: 0.0003719 (Best: 0.0003297 @iter7714) ([92m↓0.23%[0m) [0.15% of initial]
[Iter 7740/20000] Loss: 0.0003755 (Best: 0.0003278 @iter7738) ([91m↑0.95%[0m) [0.15% of initial]
[Iter 7750/20000] Loss: 0.0004179 (Best: 0.0003278 @iter7738) ([91m↑11.31%[0m) [0.17% of initial]
[Iter 7760/20000] Loss: 0.0004661 (Best: 0.0003278 @iter7738) ([91m↑11.53%[0m) [0.19% of initial]
[Iter 7770/20000] Loss: 0.0004476 (Best: 0.0003278 @iter7738) ([92m↓3.97%[0m) [0.18% of initial]
[Iter 7780/20000] Loss: 0.0004404 (Best: 0.0003278 @iter7738) ([92m↓1.62%[0m) [0.17% of initial]
[Iter 7790/20000] Loss: 0.0004580 (Best: 0.0003278 @iter7738) ([91m↑4.00%[0m) [0.18% of initial]
Iter:7799, L1 loss=0.0004498, Total loss=0.0003997, Time:72
[Iter 7800/20000] Loss: 0.0004541 (Best: 0.0003278 @iter7738) ([92m↓0.85%[0m) [0.18% of initial]
[Iter 7810/20000] Loss: 0.0009385 (Best: 0.0003278 @iter7738) ([91m↑106.68%[0m) [0.37% of initial]
[Iter 7820/20000] Loss: 0.0007138 (Best: 0.0003278 @iter7738) ([92m↓23.95%[0m) [0.28% of initial]
[Iter 7830/20000] Loss: 0.0006233 (Best: 0.0003278 @iter7738) ([92m↓12.68%[0m) [0.25% of initial]
[Iter 7840/20000] Loss: 0.0005440 (Best: 0.0003278 @iter7738) ([92m↓12.72%[0m) [0.22% of initial]
[Iter 7850/20000] Loss: 0.0005271 (Best: 0.0003278 @iter7738) ([92m↓3.11%[0m) [0.21% of initial]
[Iter 7860/20000] Loss: 0.0005402 (Best: 0.0003278 @iter7738) ([91m↑2.50%[0m) [0.21% of initial]
[Iter 7870/20000] Loss: 0.0004961 (Best: 0.0003278 @iter7738) ([92m↓8.17%[0m) [0.20% of initial]
[Iter 7880/20000] Loss: 0.0004432 (Best: 0.0003278 @iter7738) ([92m↓10.66%[0m) [0.18% of initial]
[Iter 7890/20000] Loss: 0.0005279 (Best: 0.0003278 @iter7738) ([91m↑19.11%[0m) [0.21% of initial]
Iter:7899, L1 loss=0.0005075, Total loss=0.0004559, Time:97
[Iter 7900/20000] Loss: 0.0004627 (Best: 0.0003278 @iter7738) ([92m↓12.36%[0m) [0.18% of initial]
[Iter 7910/20000] Loss: 0.0004548 (Best: 0.0003278 @iter7738) ([92m↓1.70%[0m) [0.18% of initial]
[Iter 7920/20000] Loss: 0.0005448 (Best: 0.0003278 @iter7738) ([91m↑19.78%[0m) [0.22% of initial]
[Iter 7930/20000] Loss: 0.0004646 (Best: 0.0003278 @iter7738) ([92m↓14.72%[0m) [0.18% of initial]
[Iter 7940/20000] Loss: 0.0004184 (Best: 0.0003278 @iter7738) ([92m↓9.93%[0m) [0.17% of initial]
[Iter 7950/20000] Loss: 0.0004049 (Best: 0.0003278 @iter7738) ([92m↓3.23%[0m) [0.16% of initial]
[Iter 7960/20000] Loss: 0.0004797 (Best: 0.0003278 @iter7738) ([91m↑18.47%[0m) [0.19% of initial]
[Iter 7970/20000] Loss: 0.0004756 (Best: 0.0003278 @iter7738) ([92m↓0.86%[0m) [0.19% of initial]
[Iter 7980/20000] Loss: 0.0004847 (Best: 0.0003278 @iter7738) ([91m↑1.92%[0m) [0.19% of initial]
[Iter 7990/20000] Loss: 0.0004234 (Best: 0.0003278 @iter7738) ([92m↓12.66%[0m) [0.17% of initial]
Iter:7999, L1 loss=0.0004616, Total loss=0.0004137, Time:69
[Iter 8000/20000] Loss: 0.0004136 (Best: 0.0003278 @iter7738) ([92m↓2.30%[0m) [0.16% of initial]
Pruning 40 points (0.0%) from gaussian0 at iteration 8000
Pruning 52 points (0.0%) from gaussian1 at iteration 8000
[Iter 8010/20000] Loss: 0.0407030 (Best: 0.0003278 @iter7738) ([91m↑9740.51%[0m) [16.17% of initial]
[Iter 8020/20000] Loss: 0.0163417 (Best: 0.0003278 @iter7738) ([92m↓59.85%[0m) [6.49% of initial]
[Iter 8030/20000] Loss: 0.0053590 (Best: 0.0003278 @iter7738) ([92m↓67.21%[0m) [2.13% of initial]
[Iter 8040/20000] Loss: 0.0038490 (Best: 0.0003278 @iter7738) ([92m↓28.18%[0m) [1.53% of initial]
[Iter 8050/20000] Loss: 0.0022359 (Best: 0.0003278 @iter7738) ([92m↓41.91%[0m) [0.89% of initial]
[Iter 8060/20000] Loss: 0.0015245 (Best: 0.0003278 @iter7738) ([92m↓31.82%[0m) [0.61% of initial]
[Iter 8070/20000] Loss: 0.0012147 (Best: 0.0003278 @iter7738) ([92m↓20.32%[0m) [0.48% of initial]
[Iter 8080/20000] Loss: 0.0009619 (Best: 0.0003278 @iter7738) ([92m↓20.81%[0m) [0.38% of initial]
[Iter 8090/20000] Loss: 0.0008010 (Best: 0.0003278 @iter7738) ([92m↓16.73%[0m) [0.32% of initial]
Iter:8099, L1 loss=0.0007306, Total loss=0.0006902, Time:84
[Iter 8100/20000] Loss: 0.0007752 (Best: 0.0003278 @iter7738) ([92m↓3.23%[0m) [0.31% of initial]
[Iter 8110/20000] Loss: 0.0006736 (Best: 0.0003278 @iter7738) ([92m↓13.10%[0m) [0.27% of initial]
[Iter 8120/20000] Loss: 0.0006082 (Best: 0.0003278 @iter7738) ([92m↓9.70%[0m) [0.24% of initial]
[Iter 8130/20000] Loss: 0.0006355 (Best: 0.0003278 @iter7738) ([91m↑4.49%[0m) [0.25% of initial]
[Iter 8140/20000] Loss: 0.0006118 (Best: 0.0003278 @iter7738) ([92m↓3.73%[0m) [0.24% of initial]
[Iter 8150/20000] Loss: 0.0005841 (Best: 0.0003278 @iter7738) ([92m↓4.53%[0m) [0.23% of initial]
[Iter 8160/20000] Loss: 0.0005841 (Best: 0.0003278 @iter7738) ([92m↓0.01%[0m) [0.23% of initial]
[Iter 8170/20000] Loss: 0.0005715 (Best: 0.0003278 @iter7738) ([92m↓2.16%[0m) [0.23% of initial]
[Iter 8180/20000] Loss: 0.0005756 (Best: 0.0003278 @iter7738) ([91m↑0.72%[0m) [0.23% of initial]
[Iter 8190/20000] Loss: 0.0005550 (Best: 0.0003278 @iter7738) ([92m↓3.57%[0m) [0.22% of initial]
Iter:8199, L1 loss=0.0006057, Total loss=0.0005648, Time:86
[Iter 8200/20000] Loss: 0.0005384 (Best: 0.0003278 @iter7738) ([92m↓3.00%[0m) [0.21% of initial]
[Iter 8210/20000] Loss: 0.0005124 (Best: 0.0003278 @iter7738) ([92m↓4.82%[0m) [0.20% of initial]
[Iter 8220/20000] Loss: 0.0005216 (Best: 0.0003278 @iter7738) ([91m↑1.79%[0m) [0.21% of initial]
[Iter 8230/20000] Loss: 0.0005306 (Best: 0.0003278 @iter7738) ([91m↑1.73%[0m) [0.21% of initial]
[Iter 8240/20000] Loss: 0.0005218 (Best: 0.0003278 @iter7738) ([92m↓1.67%[0m) [0.21% of initial]
[Iter 8250/20000] Loss: 0.0005623 (Best: 0.0003278 @iter7738) ([91m↑7.77%[0m) [0.22% of initial]
[Iter 8260/20000] Loss: 0.0005394 (Best: 0.0003278 @iter7738) ([92m↓4.07%[0m) [0.21% of initial]
[Iter 8270/20000] Loss: 0.0005455 (Best: 0.0003278 @iter7738) ([91m↑1.12%[0m) [0.22% of initial]
[Iter 8280/20000] Loss: 0.0005303 (Best: 0.0003278 @iter7738) ([92m↓2.79%[0m) [0.21% of initial]
[Iter 8290/20000] Loss: 0.0005469 (Best: 0.0003278 @iter7738) ([91m↑3.15%[0m) [0.22% of initial]
Iter:8299, L1 loss=0.0005153, Total loss=0.0004701, Time:112
[Iter 8300/20000] Loss: 0.0005039 (Best: 0.0003278 @iter7738) ([92m↓7.87%[0m) [0.20% of initial]
[Iter 8310/20000] Loss: 0.0005011 (Best: 0.0003278 @iter7738) ([92m↓0.55%[0m) [0.20% of initial]
[Iter 8320/20000] Loss: 0.0004780 (Best: 0.0003278 @iter7738) ([92m↓4.62%[0m) [0.19% of initial]
[Iter 8330/20000] Loss: 0.0004879 (Best: 0.0003278 @iter7738) ([91m↑2.07%[0m) [0.19% of initial]
[Iter 8340/20000] Loss: 0.0005023 (Best: 0.0003278 @iter7738) ([91m↑2.97%[0m) [0.20% of initial]
[Iter 8350/20000] Loss: 0.0004565 (Best: 0.0003278 @iter7738) ([92m↓9.13%[0m) [0.18% of initial]
[Iter 8360/20000] Loss: 0.0004665 (Best: 0.0003278 @iter7738) ([91m↑2.20%[0m) [0.19% of initial]
[Iter 8370/20000] Loss: 0.0004600 (Best: 0.0003278 @iter7738) ([92m↓1.41%[0m) [0.18% of initial]
[Iter 8380/20000] Loss: 0.0004735 (Best: 0.0003278 @iter7738) ([91m↑2.95%[0m) [0.19% of initial]
[Iter 8390/20000] Loss: 0.0004407 (Best: 0.0003278 @iter7738) ([92m↓6.92%[0m) [0.18% of initial]
Iter:8399, L1 loss=0.0004952, Total loss=0.000456, Time:112
[Iter 8400/20000] Loss: 0.0004833 (Best: 0.0003278 @iter7738) ([91m↑9.65%[0m) [0.19% of initial]
[Iter 8410/20000] Loss: 0.0004590 (Best: 0.0003278 @iter7738) ([92m↓5.02%[0m) [0.18% of initial]
[Iter 8420/20000] Loss: 0.0004573 (Best: 0.0003278 @iter7738) ([92m↓0.37%[0m) [0.18% of initial]
[Iter 8430/20000] Loss: 0.0004811 (Best: 0.0003278 @iter7738) ([91m↑5.22%[0m) [0.19% of initial]
[Iter 8440/20000] Loss: 0.0004588 (Best: 0.0003278 @iter7738) ([92m↓4.64%[0m) [0.18% of initial]
[Iter 8450/20000] Loss: 0.0004909 (Best: 0.0003278 @iter7738) ([91m↑7.00%[0m) [0.20% of initial]
[Iter 8460/20000] Loss: 0.0004730 (Best: 0.0003278 @iter7738) ([92m↓3.65%[0m) [0.19% of initial]
[Iter 8470/20000] Loss: 0.0004893 (Best: 0.0003278 @iter7738) ([91m↑3.45%[0m) [0.19% of initial]
[Iter 8480/20000] Loss: 0.0004677 (Best: 0.0003278 @iter7738) ([92m↓4.41%[0m) [0.19% of initial]
[Iter 8490/20000] Loss: 0.0004842 (Best: 0.0003278 @iter7738) ([91m↑3.52%[0m) [0.19% of initial]
Iter:8499, L1 loss=0.0005602, Total loss=0.0005132, Time:113
[Iter 8500/20000] Loss: 0.0005060 (Best: 0.0003278 @iter7738) ([91m↑4.51%[0m) [0.20% of initial]
Pruning 113 points (0.1%) from gaussian0 at iteration 8500
Pruning 96 points (0.1%) from gaussian1 at iteration 8500
[Iter 8510/20000] Loss: 0.0011310 (Best: 0.0003278 @iter7738) ([91m↑123.52%[0m) [0.45% of initial]
[Iter 8520/20000] Loss: 0.0007978 (Best: 0.0003278 @iter7738) ([92m↓29.47%[0m) [0.32% of initial]
[Iter 8530/20000] Loss: 0.0006146 (Best: 0.0003278 @iter7738) ([92m↓22.96%[0m) [0.24% of initial]
[Iter 8540/20000] Loss: 0.0005507 (Best: 0.0003278 @iter7738) ([92m↓10.39%[0m) [0.22% of initial]
[Iter 8550/20000] Loss: 0.0005210 (Best: 0.0003278 @iter7738) ([92m↓5.40%[0m) [0.21% of initial]
[Iter 8560/20000] Loss: 0.0005074 (Best: 0.0003278 @iter7738) ([92m↓2.60%[0m) [0.20% of initial]
[Iter 8570/20000] Loss: 0.0004936 (Best: 0.0003278 @iter7738) ([92m↓2.72%[0m) [0.20% of initial]
[Iter 8580/20000] Loss: 0.0004908 (Best: 0.0003278 @iter7738) ([92m↓0.58%[0m) [0.19% of initial]
[Iter 8590/20000] Loss: 0.0004675 (Best: 0.0003278 @iter7738) ([92m↓4.74%[0m) [0.19% of initial]
Iter:8599, L1 loss=0.0004694, Total loss=0.0004279, Time:94
[Iter 8600/20000] Loss: 0.0004612 (Best: 0.0003278 @iter7738) ([92m↓1.36%[0m) [0.18% of initial]
[Iter 8610/20000] Loss: 0.0004786 (Best: 0.0003278 @iter7738) ([91m↑3.77%[0m) [0.19% of initial]
[Iter 8620/20000] Loss: 0.0004672 (Best: 0.0003278 @iter7738) ([92m↓2.38%[0m) [0.19% of initial]
[Iter 8630/20000] Loss: 0.0004649 (Best: 0.0003278 @iter7738) ([92m↓0.49%[0m) [0.18% of initial]
[Iter 8640/20000] Loss: 0.0004467 (Best: 0.0003278 @iter7738) ([92m↓3.91%[0m) [0.18% of initial]
[Iter 8650/20000] Loss: 0.0004661 (Best: 0.0003278 @iter7738) ([91m↑4.33%[0m) [0.19% of initial]
[Iter 8660/20000] Loss: 0.0005108 (Best: 0.0003278 @iter7738) ([91m↑9.59%[0m) [0.20% of initial]
[Iter 8670/20000] Loss: 0.0005123 (Best: 0.0003278 @iter7738) ([91m↑0.31%[0m) [0.20% of initial]
[Iter 8680/20000] Loss: 0.0004860 (Best: 0.0003278 @iter7738) ([92m↓5.14%[0m) [0.19% of initial]
[Iter 8690/20000] Loss: 0.0005624 (Best: 0.0003278 @iter7738) ([91m↑15.72%[0m) [0.22% of initial]
Iter:8699, L1 loss=0.0005305, Total loss=0.0004891, Time:112
[Iter 8700/20000] Loss: 0.0005123 (Best: 0.0003278 @iter7738) ([92m↓8.91%[0m) [0.20% of initial]
[Iter 8710/20000] Loss: 0.0004939 (Best: 0.0003278 @iter7738) ([92m↓3.58%[0m) [0.20% of initial]
[Iter 8720/20000] Loss: 0.0004779 (Best: 0.0003278 @iter7738) ([92m↓3.25%[0m) [0.19% of initial]
[Iter 8730/20000] Loss: 0.0005167 (Best: 0.0003278 @iter7738) ([91m↑8.13%[0m) [0.21% of initial]
[Iter 8740/20000] Loss: 0.0004774 (Best: 0.0003278 @iter7738) ([92m↓7.61%[0m) [0.19% of initial]
[Iter 8750/20000] Loss: 0.0005524 (Best: 0.0003278 @iter7738) ([91m↑15.71%[0m) [0.22% of initial]
[Iter 8760/20000] Loss: 0.0005151 (Best: 0.0003278 @iter7738) ([92m↓6.75%[0m) [0.20% of initial]
[Iter 8770/20000] Loss: 0.0005278 (Best: 0.0003278 @iter7738) ([91m↑2.46%[0m) [0.21% of initial]
[Iter 8780/20000] Loss: 0.0005172 (Best: 0.0003278 @iter7738) ([92m↓2.00%[0m) [0.21% of initial]
[Iter 8790/20000] Loss: 0.0005125 (Best: 0.0003278 @iter7738) ([92m↓0.92%[0m) [0.20% of initial]
Iter:8799, L1 loss=0.0005952, Total loss=0.0005537, Time:81
[Iter 8800/20000] Loss: 0.0004943 (Best: 0.0003278 @iter7738) ([92m↓3.56%[0m) [0.20% of initial]
[Iter 8810/20000] Loss: 0.0004461 (Best: 0.0003278 @iter7738) ([92m↓9.74%[0m) [0.18% of initial]
[Iter 8820/20000] Loss: 0.0005020 (Best: 0.0003278 @iter7738) ([91m↑12.52%[0m) [0.20% of initial]
[Iter 8830/20000] Loss: 0.0005899 (Best: 0.0003278 @iter7738) ([91m↑17.52%[0m) [0.23% of initial]
[Iter 8840/20000] Loss: 0.0005386 (Best: 0.0003278 @iter7738) ([92m↓8.70%[0m) [0.21% of initial]
[Iter 8850/20000] Loss: 0.0005820 (Best: 0.0003278 @iter7738) ([91m↑8.06%[0m) [0.23% of initial]
[Iter 8860/20000] Loss: 0.0004892 (Best: 0.0003278 @iter7738) ([92m↓15.95%[0m) [0.19% of initial]
[Iter 8870/20000] Loss: 0.0004605 (Best: 0.0003278 @iter7738) ([92m↓5.87%[0m) [0.18% of initial]
[Iter 8880/20000] Loss: 0.0004585 (Best: 0.0003278 @iter7738) ([92m↓0.43%[0m) [0.18% of initial]
[Iter 8890/20000] Loss: 0.0004397 (Best: 0.0003278 @iter7738) ([92m↓4.10%[0m) [0.17% of initial]
Iter:8899, L1 loss=0.0004775, Total loss=0.000441, Time:84
[Iter 8900/20000] Loss: 0.0004783 (Best: 0.0003278 @iter7738) ([91m↑8.79%[0m) [0.19% of initial]
[Iter 8910/20000] Loss: 0.0004878 (Best: 0.0003278 @iter7738) ([91m↑1.98%[0m) [0.19% of initial]
[Iter 8920/20000] Loss: 0.0004684 (Best: 0.0003278 @iter7738) ([92m↓3.97%[0m) [0.19% of initial]
[Iter 8930/20000] Loss: 0.0004715 (Best: 0.0003278 @iter7738) ([91m↑0.66%[0m) [0.19% of initial]
[Iter 8940/20000] Loss: 0.0004728 (Best: 0.0003278 @iter7738) ([91m↑0.27%[0m) [0.19% of initial]
[Iter 8950/20000] Loss: 0.0004881 (Best: 0.0003278 @iter7738) ([91m↑3.25%[0m) [0.19% of initial]
[Iter 8960/20000] Loss: 0.0004886 (Best: 0.0003278 @iter7738) ([91m↑0.10%[0m) [0.19% of initial]
[Iter 8970/20000] Loss: 0.0005571 (Best: 0.0003278 @iter7738) ([91m↑14.01%[0m) [0.22% of initial]
[Iter 8980/20000] Loss: 0.0005215 (Best: 0.0003278 @iter7738) ([92m↓6.38%[0m) [0.21% of initial]
[Iter 8990/20000] Loss: 0.0004909 (Best: 0.0003278 @iter7738) ([92m↓5.86%[0m) [0.20% of initial]
Iter:8999, L1 loss=0.0004718, Total loss=0.0004261, Time:108
[Iter 9000/20000] Loss: 0.0004586 (Best: 0.0003278 @iter7738) ([92m↓6.60%[0m) [0.18% of initial]
Pruning 36 points (0.0%) from gaussian0 at iteration 9000
Pruning 39 points (0.0%) from gaussian1 at iteration 9000
[Iter 9010/20000] Loss: 0.0008599 (Best: 0.0003278 @iter7738) ([91m↑87.52%[0m) [0.34% of initial]
[Iter 9020/20000] Loss: 0.0006525 (Best: 0.0003278 @iter7738) ([92m↓24.11%[0m) [0.26% of initial]
[Iter 9030/20000] Loss: 0.0005370 (Best: 0.0003278 @iter7738) ([92m↓17.70%[0m) [0.21% of initial]
[Iter 9040/20000] Loss: 0.0004876 (Best: 0.0003278 @iter7738) ([92m↓9.20%[0m) [0.19% of initial]
[Iter 9050/20000] Loss: 0.0004544 (Best: 0.0003278 @iter7738) ([92m↓6.82%[0m) [0.18% of initial]
[Iter 9060/20000] Loss: 0.0004744 (Best: 0.0003278 @iter7738) ([91m↑4.39%[0m) [0.19% of initial]
[Iter 9070/20000] Loss: 0.0004816 (Best: 0.0003278 @iter7738) ([91m↑1.53%[0m) [0.19% of initial]
[Iter 9080/20000] Loss: 0.0005056 (Best: 0.0003278 @iter7738) ([91m↑4.99%[0m) [0.20% of initial]
[Iter 9090/20000] Loss: 0.0004777 (Best: 0.0003278 @iter7738) ([92m↓5.52%[0m) [0.19% of initial]
Iter:9099, L1 loss=0.0005871, Total loss=0.0005198, Time:86
[Iter 9100/20000] Loss: 0.0004777 (Best: 0.0003278 @iter7738) ([92m↓0.02%[0m) [0.19% of initial]
[Iter 9110/20000] Loss: 0.0005224 (Best: 0.0003278 @iter7738) ([91m↑9.36%[0m) [0.21% of initial]
[Iter 9120/20000] Loss: 0.0004691 (Best: 0.0003278 @iter7738) ([92m↓10.20%[0m) [0.19% of initial]
[Iter 9130/20000] Loss: 0.0004709 (Best: 0.0003278 @iter7738) ([91m↑0.40%[0m) [0.19% of initial]
[Iter 9140/20000] Loss: 0.0004656 (Best: 0.0003278 @iter7738) ([92m↓1.13%[0m) [0.18% of initial]
[Iter 9150/20000] Loss: 0.0004367 (Best: 0.0003278 @iter7738) ([92m↓6.22%[0m) [0.17% of initial]
[Iter 9160/20000] Loss: 0.0004532 (Best: 0.0003278 @iter7738) ([91m↑3.78%[0m) [0.18% of initial]
[Iter 9170/20000] Loss: 0.0004281 (Best: 0.0003278 @iter7738) ([92m↓5.54%[0m) [0.17% of initial]
[Iter 9180/20000] Loss: 0.0004409 (Best: 0.0003278 @iter7738) ([91m↑2.99%[0m) [0.18% of initial]
[Iter 9190/20000] Loss: 0.0003983 (Best: 0.0003278 @iter7738) ([92m↓9.66%[0m) [0.16% of initial]
Iter:9199, L1 loss=0.000459, Total loss=0.0004213, Time:74
[Iter 9200/20000] Loss: 0.0004236 (Best: 0.0003278 @iter7738) ([91m↑6.37%[0m) [0.17% of initial]
[Iter 9210/20000] Loss: 0.0004365 (Best: 0.0003278 @iter7738) ([91m↑3.04%[0m) [0.17% of initial]
[Iter 9220/20000] Loss: 0.0004416 (Best: 0.0003278 @iter7738) ([91m↑1.16%[0m) [0.18% of initial]
[Iter 9230/20000] Loss: 0.0004377 (Best: 0.0003278 @iter7738) ([92m↓0.88%[0m) [0.17% of initial]
[Iter 9240/20000] Loss: 0.0004554 (Best: 0.0003278 @iter7738) ([91m↑4.04%[0m) [0.18% of initial]
[Iter 9250/20000] Loss: 0.0004446 (Best: 0.0003278 @iter7738) ([92m↓2.37%[0m) [0.18% of initial]
[Iter 9260/20000] Loss: 0.0004453 (Best: 0.0003278 @iter7738) ([91m↑0.15%[0m) [0.18% of initial]
[Iter 9270/20000] Loss: 0.0004324 (Best: 0.0003278 @iter7738) ([92m↓2.88%[0m) [0.17% of initial]
[Iter 9280/20000] Loss: 0.0003974 (Best: 0.0003278 @iter7738) ([92m↓8.10%[0m) [0.16% of initial]
[Iter 9290/20000] Loss: 0.0003953 (Best: 0.0003278 @iter7738) ([92m↓0.53%[0m) [0.16% of initial]
Iter:9299, L1 loss=0.0004341, Total loss=0.000386, Time:107
[Iter 9300/20000] Loss: 0.0004261 (Best: 0.0003278 @iter7738) ([91m↑7.80%[0m) [0.17% of initial]
[Iter 9310/20000] Loss: 0.0004405 (Best: 0.0003278 @iter7738) ([91m↑3.38%[0m) [0.18% of initial]
[Iter 9320/20000] Loss: 0.0004623 (Best: 0.0003278 @iter7738) ([91m↑4.94%[0m) [0.18% of initial]
[Iter 9330/20000] Loss: 0.0005011 (Best: 0.0003278 @iter7738) ([91m↑8.40%[0m) [0.20% of initial]
[Iter 9340/20000] Loss: 0.0004991 (Best: 0.0003278 @iter7738) ([92m↓0.42%[0m) [0.20% of initial]
[Iter 9350/20000] Loss: 0.0004482 (Best: 0.0003278 @iter7738) ([92m↓10.20%[0m) [0.18% of initial]
[Iter 9360/20000] Loss: 0.0004799 (Best: 0.0003278 @iter7738) ([91m↑7.07%[0m) [0.19% of initial]
[Iter 9370/20000] Loss: 0.0004278 (Best: 0.0003278 @iter7738) ([92m↓10.85%[0m) [0.17% of initial]
[Iter 9380/20000] Loss: 0.0004481 (Best: 0.0003278 @iter7738) ([91m↑4.73%[0m) [0.18% of initial]
[Iter 9390/20000] Loss: 0.0004481 (Best: 0.0003278 @iter7738) ([91m↑0.01%[0m) [0.18% of initial]
Iter:9399, L1 loss=0.0005643, Total loss=0.00052, Time:86
[Iter 9400/20000] Loss: 0.0004289 (Best: 0.0003278 @iter7738) ([92m↓4.30%[0m) [0.17% of initial]
[Iter 9410/20000] Loss: 0.0004335 (Best: 0.0003278 @iter7738) ([91m↑1.08%[0m) [0.17% of initial]
[Iter 9420/20000] Loss: 0.0004501 (Best: 0.0003278 @iter7738) ([91m↑3.83%[0m) [0.18% of initial]
[Iter 9430/20000] Loss: 0.0004062 (Best: 0.0003278 @iter7738) ([92m↓9.75%[0m) [0.16% of initial]
[Iter 9440/20000] Loss: 0.0004549 (Best: 0.0003278 @iter7738) ([91m↑11.99%[0m) [0.18% of initial]
[Iter 9450/20000] Loss: 0.0004359 (Best: 0.0003278 @iter7738) ([92m↓4.18%[0m) [0.17% of initial]
[Iter 9460/20000] Loss: 0.0003837 (Best: 0.0003278 @iter7738) ([92m↓11.97%[0m) [0.15% of initial]
[Iter 9470/20000] Loss: 0.0003832 (Best: 0.0003278 @iter7738) ([92m↓0.13%[0m) [0.15% of initial]
[Iter 9480/20000] Loss: 0.0004598 (Best: 0.0003278 @iter7738) ([91m↑20.00%[0m) [0.18% of initial]
[Iter 9490/20000] Loss: 0.0004234 (Best: 0.0003278 @iter7738) ([92m↓7.92%[0m) [0.17% of initial]
Iter:9499, L1 loss=0.0004739, Total loss=0.0004224, Time:105
[Iter 9500/20000] Loss: 0.0004298 (Best: 0.0003278 @iter7738) ([91m↑1.51%[0m) [0.17% of initial]
Pruning 42 points (0.0%) from gaussian0 at iteration 9500
Pruning 23 points (0.0%) from gaussian1 at iteration 9500
[Iter 9510/20000] Loss: 0.0007520 (Best: 0.0003278 @iter7738) ([91m↑74.98%[0m) [0.30% of initial]
[Iter 9520/20000] Loss: 0.0005840 (Best: 0.0003278 @iter7738) ([92m↓22.35%[0m) [0.23% of initial]
[Iter 9530/20000] Loss: 0.0005957 (Best: 0.0003278 @iter7738) ([91m↑2.00%[0m) [0.24% of initial]
[Iter 9540/20000] Loss: 0.0004652 (Best: 0.0003278 @iter7738) ([92m↓21.90%[0m) [0.18% of initial]
[Iter 9550/20000] Loss: 0.0004042 (Best: 0.0003278 @iter7738) ([92m↓13.11%[0m) [0.16% of initial]
[Iter 9560/20000] Loss: 0.0003883 (Best: 0.0003278 @iter7738) ([92m↓3.95%[0m) [0.15% of initial]
[Iter 9570/20000] Loss: 0.0003799 (Best: 0.0003278 @iter7738) ([92m↓2.16%[0m) [0.15% of initial]
[Iter 9580/20000] Loss: 0.0003655 (Best: 0.0003278 @iter7738) ([92m↓3.79%[0m) [0.15% of initial]
[Iter 9590/20000] Loss: 0.0003694 (Best: 0.0003278 @iter7738) ([91m↑1.06%[0m) [0.15% of initial]
Iter:9599, L1 loss=0.0005124, Total loss=0.0004392, Time:102
[Iter 9600/20000] Loss: 0.0003971 (Best: 0.0003278 @iter7738) ([91m↑7.49%[0m) [0.16% of initial]
[Iter 9610/20000] Loss: 0.0003812 (Best: 0.0003278 @iter7738) ([92m↓3.99%[0m) [0.15% of initial]
[Iter 9620/20000] Loss: 0.0003920 (Best: 0.0003278 @iter7738) ([91m↑2.84%[0m) [0.16% of initial]
[Iter 9630/20000] Loss: 0.0003752 (Best: 0.0003261 @iter9628) ([92m↓4.28%[0m) [0.15% of initial]
[Iter 9640/20000] Loss: 0.0003650 (Best: 0.0003261 @iter9628) ([92m↓2.73%[0m) [0.15% of initial]
[Iter 9650/20000] Loss: 0.0004146 (Best: 0.0003261 @iter9628) ([91m↑13.59%[0m) [0.16% of initial]
[Iter 9660/20000] Loss: 0.0003916 (Best: 0.0003261 @iter9628) ([92m↓5.54%[0m) [0.16% of initial]
[Iter 9670/20000] Loss: 0.0004383 (Best: 0.0003261 @iter9628) ([91m↑11.90%[0m) [0.17% of initial]
[Iter 9680/20000] Loss: 0.0004426 (Best: 0.0003261 @iter9628) ([91m↑0.99%[0m) [0.18% of initial]
[Iter 9690/20000] Loss: 0.0005097 (Best: 0.0003261 @iter9628) ([91m↑15.17%[0m) [0.20% of initial]
Iter:9699, L1 loss=0.0006105, Total loss=0.0005961, Time:108
[Iter 9700/20000] Loss: 0.0004838 (Best: 0.0003261 @iter9628) ([92m↓5.08%[0m) [0.19% of initial]
[Iter 9710/20000] Loss: 0.0004672 (Best: 0.0003261 @iter9628) ([92m↓3.45%[0m) [0.19% of initial]
[Iter 9720/20000] Loss: 0.0004369 (Best: 0.0003261 @iter9628) ([92m↓6.48%[0m) [0.17% of initial]
[Iter 9730/20000] Loss: 0.0004075 (Best: 0.0003261 @iter9628) ([92m↓6.72%[0m) [0.16% of initial]
[Iter 9740/20000] Loss: 0.0004330 (Best: 0.0003261 @iter9628) ([91m↑6.25%[0m) [0.17% of initial]
[Iter 9750/20000] Loss: 0.0004293 (Best: 0.0003261 @iter9628) ([92m↓0.85%[0m) [0.17% of initial]
[Iter 9760/20000] Loss: 0.0003988 (Best: 0.0003261 @iter9628) ([92m↓7.11%[0m) [0.16% of initial]
[Iter 9770/20000] Loss: 0.0004008 (Best: 0.0003261 @iter9628) ([91m↑0.52%[0m) [0.16% of initial]
[Iter 9780/20000] Loss: 0.0003859 (Best: 0.0003261 @iter9628) ([92m↓3.73%[0m) [0.15% of initial]
[Iter 9790/20000] Loss: 0.0003790 (Best: 0.0003261 @iter9628) ([92m↓1.78%[0m) [0.15% of initial]
Iter:9799, L1 loss=0.0004299, Total loss=0.0003838, Time:92
[Iter 9800/20000] Loss: 0.0004087 (Best: 0.0003261 @iter9628) ([91m↑7.84%[0m) [0.16% of initial]
[Iter 9810/20000] Loss: 0.0003860 (Best: 0.0003261 @iter9628) ([92m↓5.56%[0m) [0.15% of initial]
[Iter 9820/20000] Loss: 0.0003609 (Best: 0.0003261 @iter9628) ([92m↓6.51%[0m) [0.14% of initial]
[Iter 9830/20000] Loss: 0.0003965 (Best: 0.0003261 @iter9628) ([91m↑9.88%[0m) [0.16% of initial]
[Iter 9840/20000] Loss: 0.0004052 (Best: 0.0003261 @iter9628) ([91m↑2.19%[0m) [0.16% of initial]
[Iter 9850/20000] Loss: 0.0003741 (Best: 0.0003261 @iter9628) ([92m↓7.68%[0m) [0.15% of initial]
[Iter 9860/20000] Loss: 0.0003743 (Best: 0.0003261 @iter9628) ([91m↑0.06%[0m) [0.15% of initial]
[Iter 9870/20000] Loss: 0.0004019 (Best: 0.0003261 @iter9628) ([91m↑7.37%[0m) [0.16% of initial]
[Iter 9880/20000] Loss: 0.0004038 (Best: 0.0003261 @iter9628) ([91m↑0.47%[0m) [0.16% of initial]
[Iter 9890/20000] Loss: 0.0004978 (Best: 0.0003261 @iter9628) ([91m↑23.28%[0m) [0.20% of initial]
Iter:9899, L1 loss=0.0005669, Total loss=0.0004789, Time:91
[Iter 9900/20000] Loss: 0.0004486 (Best: 0.0003261 @iter9628) ([92m↓9.88%[0m) [0.18% of initial]
[Iter 9910/20000] Loss: 0.0003715 (Best: 0.0003261 @iter9628) ([92m↓17.20%[0m) [0.15% of initial]
[Iter 9920/20000] Loss: 0.0003728 (Best: 0.0003261 @iter9628) ([91m↑0.36%[0m) [0.15% of initial]
[Iter 9930/20000] Loss: 0.0003961 (Best: 0.0003261 @iter9628) ([91m↑6.25%[0m) [0.16% of initial]
[Iter 9940/20000] Loss: 0.0003953 (Best: 0.0003261 @iter9628) ([92m↓0.21%[0m) [0.16% of initial]
[Iter 9950/20000] Loss: 0.0004309 (Best: 0.0003261 @iter9628) ([91m↑9.02%[0m) [0.17% of initial]
[Iter 9960/20000] Loss: 0.0004369 (Best: 0.0003261 @iter9628) ([91m↑1.39%[0m) [0.17% of initial]
[Iter 9970/20000] Loss: 0.0004100 (Best: 0.0003261 @iter9628) ([92m↓6.16%[0m) [0.16% of initial]
[Iter 9980/20000] Loss: 0.0003951 (Best: 0.0003261 @iter9628) ([92m↓3.65%[0m) [0.16% of initial]
[Iter 9990/20000] Loss: 0.0004233 (Best: 0.0003261 @iter9628) ([91m↑7.16%[0m) [0.17% of initial]
Iter:9999, L1 loss=0.0006045, Total loss=0.0005771, Time:97
[Iter 10000/20000] Loss: 0.0005064 (Best: 0.0003261 @iter9628) ([91m↑19.61%[0m) [0.20% of initial]
Pruning 18 points (0.0%) from gaussian0 at iteration 10000
Pruning 23 points (0.0%) from gaussian1 at iteration 10000
[Iter 10010/20000] Loss: 0.0007201 (Best: 0.0003261 @iter9628) ([91m↑42.22%[0m) [0.29% of initial]
[Iter 10020/20000] Loss: 0.0005891 (Best: 0.0003261 @iter9628) ([92m↓18.20%[0m) [0.23% of initial]
[Iter 10030/20000] Loss: 0.0004419 (Best: 0.0003261 @iter9628) ([92m↓24.98%[0m) [0.18% of initial]
[Iter 10040/20000] Loss: 0.0003978 (Best: 0.0003261 @iter9628) ([92m↓9.98%[0m) [0.16% of initial]
[Iter 10050/20000] Loss: 0.0003724 (Best: 0.0003261 @iter9628) ([92m↓6.40%[0m) [0.15% of initial]
[Iter 10060/20000] Loss: 0.0003394 (Best: 0.0003215 @iter10057) ([92m↓8.85%[0m) [0.13% of initial]
[Iter 10070/20000] Loss: 0.0003393 (Best: 0.0003215 @iter10057) ([92m↓0.03%[0m) [0.13% of initial]
[Iter 10080/20000] Loss: 0.0003523 (Best: 0.0003153 @iter10072) ([91m↑3.83%[0m) [0.14% of initial]
[Iter 10090/20000] Loss: 0.0003444 (Best: 0.0003092 @iter10084) ([92m↓2.23%[0m) [0.14% of initial]
Iter:10099, L1 loss=0.0003855, Total loss=0.000343, Time:101
[Iter 10100/20000] Loss: 0.0003610 (Best: 0.0003092 @iter10084) ([91m↑4.82%[0m) [0.14% of initial]
[Iter 10110/20000] Loss: 0.0003629 (Best: 0.0003092 @iter10084) ([91m↑0.51%[0m) [0.14% of initial]
[Iter 10120/20000] Loss: 0.0003593 (Best: 0.0003092 @iter10084) ([92m↓0.99%[0m) [0.14% of initial]
[Iter 10130/20000] Loss: 0.0003583 (Best: 0.0003092 @iter10084) ([92m↓0.27%[0m) [0.14% of initial]
[Iter 10140/20000] Loss: 0.0004055 (Best: 0.0003092 @iter10084) ([91m↑13.16%[0m) [0.16% of initial]
[Iter 10150/20000] Loss: 0.0004023 (Best: 0.0003092 @iter10084) ([92m↓0.77%[0m) [0.16% of initial]
[Iter 10160/20000] Loss: 0.0004095 (Best: 0.0003092 @iter10084) ([91m↑1.77%[0m) [0.16% of initial]
[Iter 10170/20000] Loss: 0.0003924 (Best: 0.0003092 @iter10084) ([92m↓4.16%[0m) [0.16% of initial]
[Iter 10180/20000] Loss: 0.0003505 (Best: 0.0003092 @iter10084) ([92m↓10.68%[0m) [0.14% of initial]
[Iter 10190/20000] Loss: 0.0003256 (Best: 0.0003082 @iter10183) ([92m↓7.10%[0m) [0.13% of initial]
Iter:10199, L1 loss=0.0004366, Total loss=0.0003848, Time:79
[Iter 10200/20000] Loss: 0.0003614 (Best: 0.0003082 @iter10183) ([91m↑10.98%[0m) [0.14% of initial]
[Iter 10210/20000] Loss: 0.0003456 (Best: 0.0003082 @iter10183) ([92m↓4.36%[0m) [0.14% of initial]
[Iter 10220/20000] Loss: 0.0003545 (Best: 0.0003082 @iter10183) ([91m↑2.57%[0m) [0.14% of initial]
[Iter 10230/20000] Loss: 0.0003531 (Best: 0.0003082 @iter10183) ([92m↓0.38%[0m) [0.14% of initial]
[Iter 10240/20000] Loss: 0.0003449 (Best: 0.0003036 @iter10237) ([92m↓2.32%[0m) [0.14% of initial]
[Iter 10250/20000] Loss: 0.0003460 (Best: 0.0003036 @iter10237) ([91m↑0.31%[0m) [0.14% of initial]
[Iter 10260/20000] Loss: 0.0003744 (Best: 0.0003036 @iter10237) ([91m↑8.19%[0m) [0.15% of initial]
[Iter 10270/20000] Loss: 0.0003511 (Best: 0.0003036 @iter10237) ([92m↓6.22%[0m) [0.14% of initial]
[Iter 10280/20000] Loss: 0.0003570 (Best: 0.0003036 @iter10237) ([91m↑1.70%[0m) [0.14% of initial]
[Iter 10290/20000] Loss: 0.0003938 (Best: 0.0003036 @iter10237) ([91m↑10.30%[0m) [0.16% of initial]
Iter:10299, L1 loss=0.000407, Total loss=0.0003572, Time:96
[Iter 10300/20000] Loss: 0.0003626 (Best: 0.0003036 @iter10237) ([92m↓7.92%[0m) [0.14% of initial]
[Iter 10310/20000] Loss: 0.0003785 (Best: 0.0003036 @iter10237) ([91m↑4.37%[0m) [0.15% of initial]
[Iter 10320/20000] Loss: 0.0003876 (Best: 0.0003036 @iter10237) ([91m↑2.40%[0m) [0.15% of initial]
[Iter 10330/20000] Loss: 0.0003618 (Best: 0.0003036 @iter10237) ([92m↓6.64%[0m) [0.14% of initial]
[Iter 10340/20000] Loss: 0.0003801 (Best: 0.0003036 @iter10237) ([91m↑5.07%[0m) [0.15% of initial]
[Iter 10350/20000] Loss: 0.0003739 (Best: 0.0003036 @iter10237) ([92m↓1.65%[0m) [0.15% of initial]
[Iter 10360/20000] Loss: 0.0004140 (Best: 0.0003036 @iter10237) ([91m↑10.73%[0m) [0.16% of initial]
[Iter 10370/20000] Loss: 0.0004292 (Best: 0.0003036 @iter10237) ([91m↑3.67%[0m) [0.17% of initial]
[Iter 10380/20000] Loss: 0.0003939 (Best: 0.0003036 @iter10237) ([92m↓8.22%[0m) [0.16% of initial]
[Iter 10390/20000] Loss: 0.0004129 (Best: 0.0003036 @iter10237) ([91m↑4.83%[0m) [0.16% of initial]
Iter:10399, L1 loss=0.000412, Total loss=0.0003661, Time:73
[Iter 10400/20000] Loss: 0.0003902 (Best: 0.0003036 @iter10237) ([92m↓5.48%[0m) [0.16% of initial]
[Iter 10410/20000] Loss: 0.0003584 (Best: 0.0003036 @iter10237) ([92m↓8.16%[0m) [0.14% of initial]
[Iter 10420/20000] Loss: 0.0003659 (Best: 0.0003036 @iter10237) ([91m↑2.10%[0m) [0.15% of initial]
[Iter 10430/20000] Loss: 0.0004170 (Best: 0.0003036 @iter10237) ([91m↑13.95%[0m) [0.17% of initial]
[Iter 10440/20000] Loss: 0.0003904 (Best: 0.0003036 @iter10237) ([92m↓6.39%[0m) [0.16% of initial]
[Iter 10450/20000] Loss: 0.0004022 (Best: 0.0003036 @iter10237) ([91m↑3.02%[0m) [0.16% of initial]
[Iter 10460/20000] Loss: 0.0003445 (Best: 0.0003036 @iter10237) ([92m↓14.33%[0m) [0.14% of initial]
[Iter 10470/20000] Loss: 0.0004108 (Best: 0.0003036 @iter10237) ([91m↑19.22%[0m) [0.16% of initial]
[Iter 10480/20000] Loss: 0.0003666 (Best: 0.0003036 @iter10237) ([92m↓10.75%[0m) [0.15% of initial]
[Iter 10490/20000] Loss: 0.0003445 (Best: 0.0003036 @iter10237) ([92m↓6.02%[0m) [0.14% of initial]
Iter:10499, L1 loss=0.0003889, Total loss=0.0003377, Time:69
[Iter 10500/20000] Loss: 0.0003494 (Best: 0.0003036 @iter10237) ([91m↑1.40%[0m) [0.14% of initial]
Pruning 21 points (0.0%) from gaussian0 at iteration 10500
Pruning 28 points (0.0%) from gaussian1 at iteration 10500
[Iter 10510/20000] Loss: 0.0006110 (Best: 0.0003036 @iter10237) ([91m↑74.89%[0m) [0.24% of initial]
[Iter 10520/20000] Loss: 0.0004803 (Best: 0.0003036 @iter10237) ([92m↓21.40%[0m) [0.19% of initial]
[Iter 10530/20000] Loss: 0.0004338 (Best: 0.0003036 @iter10237) ([92m↓9.67%[0m) [0.17% of initial]
[Iter 10540/20000] Loss: 0.0003935 (Best: 0.0003036 @iter10237) ([92m↓9.29%[0m) [0.16% of initial]
[Iter 10550/20000] Loss: 0.0003537 (Best: 0.0003036 @iter10237) ([92m↓10.11%[0m) [0.14% of initial]
[Iter 10560/20000] Loss: 0.0003403 (Best: 0.0003036 @iter10237) ([92m↓3.81%[0m) [0.14% of initial]
[Iter 10570/20000] Loss: 0.0003387 (Best: 0.0003036 @iter10237) ([92m↓0.45%[0m) [0.13% of initial]
[Iter 10580/20000] Loss: 0.0003435 (Best: 0.0003036 @iter10237) ([91m↑1.41%[0m) [0.14% of initial]
[Iter 10590/20000] Loss: 0.0003442 (Best: 0.0003036 @iter10237) ([91m↑0.21%[0m) [0.14% of initial]
Iter:10599, L1 loss=0.0003644, Total loss=0.0003313, Time:99
[Iter 10600/20000] Loss: 0.0003381 (Best: 0.0003036 @iter10237) ([92m↓1.77%[0m) [0.13% of initial]
[Iter 10610/20000] Loss: 0.0003366 (Best: 0.0002983 @iter10607) ([92m↓0.46%[0m) [0.13% of initial]
[Iter 10620/20000] Loss: 0.0003310 (Best: 0.0002983 @iter10607) ([92m↓1.66%[0m) [0.13% of initial]
[Iter 10630/20000] Loss: 0.0003419 (Best: 0.0002978 @iter10627) ([91m↑3.30%[0m) [0.14% of initial]
[Iter 10640/20000] Loss: 0.0003792 (Best: 0.0002978 @iter10627) ([91m↑10.92%[0m) [0.15% of initial]
[Iter 10650/20000] Loss: 0.0003682 (Best: 0.0002978 @iter10627) ([92m↓2.91%[0m) [0.15% of initial]
[Iter 10660/20000] Loss: 0.0003497 (Best: 0.0002978 @iter10627) ([92m↓5.02%[0m) [0.14% of initial]
[Iter 10670/20000] Loss: 0.0003438 (Best: 0.0002978 @iter10627) ([92m↓1.69%[0m) [0.14% of initial]
[Iter 10680/20000] Loss: 0.0003259 (Best: 0.0002978 @iter10627) ([92m↓5.20%[0m) [0.13% of initial]
[Iter 10690/20000] Loss: 0.0003398 (Best: 0.0002978 @iter10627) ([91m↑4.28%[0m) [0.14% of initial]
Iter:10699, L1 loss=0.0004014, Total loss=0.0003649, Time:102
[Iter 10700/20000] Loss: 0.0003848 (Best: 0.0002978 @iter10627) ([91m↑13.23%[0m) [0.15% of initial]
[Iter 10710/20000] Loss: 0.0003896 (Best: 0.0002978 @iter10627) ([91m↑1.24%[0m) [0.15% of initial]
[Iter 10720/20000] Loss: 0.0004250 (Best: 0.0002978 @iter10627) ([91m↑9.09%[0m) [0.17% of initial]
[Iter 10730/20000] Loss: 0.0004203 (Best: 0.0002978 @iter10627) ([92m↓1.11%[0m) [0.17% of initial]
[Iter 10740/20000] Loss: 0.0003677 (Best: 0.0002978 @iter10627) ([92m↓12.51%[0m) [0.15% of initial]
[Iter 10750/20000] Loss: 0.0003721 (Best: 0.0002978 @iter10627) ([91m↑1.19%[0m) [0.15% of initial]
[Iter 10760/20000] Loss: 0.0003328 (Best: 0.0002978 @iter10627) ([92m↓10.55%[0m) [0.13% of initial]
[Iter 10770/20000] Loss: 0.0003229 (Best: 0.0002978 @iter10627) ([92m↓2.98%[0m) [0.13% of initial]
[Iter 10780/20000] Loss: 0.0003236 (Best: 0.0002935 @iter10774) ([91m↑0.22%[0m) [0.13% of initial]
[Iter 10790/20000] Loss: 0.0003326 (Best: 0.0002922 @iter10784) ([91m↑2.80%[0m) [0.13% of initial]
Iter:10799, L1 loss=0.0003725, Total loss=0.0003284, Time:102
[Iter 10800/20000] Loss: 0.0003581 (Best: 0.0002922 @iter10784) ([91m↑7.67%[0m) [0.14% of initial]
[Iter 10810/20000] Loss: 0.0003958 (Best: 0.0002922 @iter10784) ([91m↑10.53%[0m) [0.16% of initial]
[Iter 10820/20000] Loss: 0.0003671 (Best: 0.0002922 @iter10784) ([92m↓7.26%[0m) [0.15% of initial]
[Iter 10830/20000] Loss: 0.0003773 (Best: 0.0002922 @iter10784) ([91m↑2.77%[0m) [0.15% of initial]
[Iter 10840/20000] Loss: 0.0003368 (Best: 0.0002922 @iter10784) ([92m↓10.73%[0m) [0.13% of initial]
[Iter 10850/20000] Loss: 0.0003597 (Best: 0.0002922 @iter10784) ([91m↑6.81%[0m) [0.14% of initial]
[Iter 10860/20000] Loss: 0.0003445 (Best: 0.0002922 @iter10784) ([92m↓4.24%[0m) [0.14% of initial]
[Iter 10870/20000] Loss: 0.0003436 (Best: 0.0002922 @iter10784) ([92m↓0.25%[0m) [0.14% of initial]
[Iter 10880/20000] Loss: 0.0003407 (Best: 0.0002922 @iter10784) ([92m↓0.86%[0m) [0.14% of initial]
[Iter 10890/20000] Loss: 0.0003673 (Best: 0.0002922 @iter10784) ([91m↑7.82%[0m) [0.15% of initial]
Iter:10899, L1 loss=0.0004433, Total loss=0.0004682, Time:100
[Iter 10900/20000] Loss: 0.0004033 (Best: 0.0002922 @iter10784) ([91m↑9.81%[0m) [0.16% of initial]
[Iter 10910/20000] Loss: 0.0003869 (Best: 0.0002922 @iter10784) ([92m↓4.08%[0m) [0.15% of initial]
[Iter 10920/20000] Loss: 0.0003678 (Best: 0.0002922 @iter10784) ([92m↓4.92%[0m) [0.15% of initial]
[Iter 10930/20000] Loss: 0.0003491 (Best: 0.0002922 @iter10784) ([92m↓5.09%[0m) [0.14% of initial]
[Iter 10940/20000] Loss: 0.0003621 (Best: 0.0002922 @iter10784) ([91m↑3.72%[0m) [0.14% of initial]
[Iter 10950/20000] Loss: 0.0003282 (Best: 0.0002922 @iter10784) ([92m↓9.36%[0m) [0.13% of initial]
[Iter 10960/20000] Loss: 0.0003272 (Best: 0.0002922 @iter10784) ([92m↓0.31%[0m) [0.13% of initial]
[Iter 10970/20000] Loss: 0.0003138 (Best: 0.0002922 @iter10784) ([92m↓4.12%[0m) [0.12% of initial]
[Iter 10980/20000] Loss: 0.0003030 (Best: 0.0002858 @iter10976) ([92m↓3.41%[0m) [0.12% of initial]
[Iter 10990/20000] Loss: 0.0003143 (Best: 0.0002836 @iter10981) ([91m↑3.72%[0m) [0.12% of initial]
Iter:10999, L1 loss=0.0003928, Total loss=0.0003217, Time:95
[Iter 11000/20000] Loss: 0.0003033 (Best: 0.0002836 @iter10981) ([92m↓3.51%[0m) [0.12% of initial]
Pruning 24 points (0.0%) from gaussian0 at iteration 11000
Pruning 20 points (0.0%) from gaussian1 at iteration 11000
[Iter 11010/20000] Loss: 0.0007080 (Best: 0.0002836 @iter10981) ([91m↑133.43%[0m) [0.28% of initial]
[Iter 11020/20000] Loss: 0.0005263 (Best: 0.0002836 @iter10981) ([92m↓25.66%[0m) [0.21% of initial]
[Iter 11030/20000] Loss: 0.0003918 (Best: 0.0002836 @iter10981) ([92m↓25.55%[0m) [0.16% of initial]
[Iter 11040/20000] Loss: 0.0003406 (Best: 0.0002836 @iter10981) ([92m↓13.09%[0m) [0.14% of initial]
[Iter 11050/20000] Loss: 0.0003341 (Best: 0.0002836 @iter10981) ([92m↓1.89%[0m) [0.13% of initial]
[Iter 11060/20000] Loss: 0.0003071 (Best: 0.0002822 @iter11056) ([92m↓8.08%[0m) [0.12% of initial]
[Iter 11070/20000] Loss: 0.0003294 (Best: 0.0002822 @iter11056) ([91m↑7.25%[0m) [0.13% of initial]
[Iter 11080/20000] Loss: 0.0003124 (Best: 0.0002822 @iter11056) ([92m↓5.17%[0m) [0.12% of initial]
[Iter 11090/20000] Loss: 0.0003342 (Best: 0.0002822 @iter11056) ([91m↑6.99%[0m) [0.13% of initial]
Iter:11099, L1 loss=0.0003404, Total loss=0.0003073, Time:112
[Iter 11100/20000] Loss: 0.0003373 (Best: 0.0002822 @iter11056) ([91m↑0.94%[0m) [0.13% of initial]
[Iter 11110/20000] Loss: 0.0003647 (Best: 0.0002822 @iter11056) ([91m↑8.11%[0m) [0.14% of initial]
[Iter 11120/20000] Loss: 0.0003217 (Best: 0.0002822 @iter11056) ([92m↓11.78%[0m) [0.13% of initial]
[Iter 11130/20000] Loss: 0.0003718 (Best: 0.0002822 @iter11056) ([91m↑15.56%[0m) [0.15% of initial]
[Iter 11140/20000] Loss: 0.0003324 (Best: 0.0002822 @iter11056) ([92m↓10.59%[0m) [0.13% of initial]
[Iter 11150/20000] Loss: 0.0003305 (Best: 0.0002822 @iter11056) ([92m↓0.56%[0m) [0.13% of initial]
[Iter 11160/20000] Loss: 0.0003471 (Best: 0.0002822 @iter11056) ([91m↑5.01%[0m) [0.14% of initial]
[Iter 11170/20000] Loss: 0.0003709 (Best: 0.0002822 @iter11056) ([91m↑6.85%[0m) [0.15% of initial]
[Iter 11180/20000] Loss: 0.0003521 (Best: 0.0002822 @iter11056) ([92m↓5.07%[0m) [0.14% of initial]
[Iter 11190/20000] Loss: 0.0003699 (Best: 0.0002822 @iter11056) ([91m↑5.05%[0m) [0.15% of initial]
Iter:11199, L1 loss=0.0003815, Total loss=0.000328, Time:85
[Iter 11200/20000] Loss: 0.0003275 (Best: 0.0002822 @iter11056) ([92m↓11.46%[0m) [0.13% of initial]
[Iter 11210/20000] Loss: 0.0003092 (Best: 0.0002822 @iter11056) ([92m↓5.57%[0m) [0.12% of initial]
[Iter 11220/20000] Loss: 0.0003245 (Best: 0.0002822 @iter11056) ([91m↑4.93%[0m) [0.13% of initial]
[Iter 11230/20000] Loss: 0.0003193 (Best: 0.0002822 @iter11056) ([92m↓1.61%[0m) [0.13% of initial]
[Iter 11240/20000] Loss: 0.0003210 (Best: 0.0002822 @iter11056) ([91m↑0.54%[0m) [0.13% of initial]
[Iter 11250/20000] Loss: 0.0003193 (Best: 0.0002822 @iter11056) ([92m↓0.54%[0m) [0.13% of initial]
[Iter 11260/20000] Loss: 0.0003001 (Best: 0.0002822 @iter11056) ([92m↓6.00%[0m) [0.12% of initial]
[Iter 11270/20000] Loss: 0.0002921 (Best: 0.0002731 @iter11270) ([92m↓2.67%[0m) [0.12% of initial]
[Iter 11280/20000] Loss: 0.0003080 (Best: 0.0002731 @iter11270) ([91m↑5.44%[0m) [0.12% of initial]
[Iter 11290/20000] Loss: 0.0003034 (Best: 0.0002731 @iter11270) ([92m↓1.48%[0m) [0.12% of initial]
Iter:11299, L1 loss=0.000329, Total loss=0.0002839, Time:96
[Iter 11300/20000] Loss: 0.0003059 (Best: 0.0002731 @iter11270) ([91m↑0.82%[0m) [0.12% of initial]
[Iter 11310/20000] Loss: 0.0002775 (Best: 0.0002720 @iter11310) ([92m↓9.29%[0m) [0.11% of initial]
[Iter 11320/20000] Loss: 0.0002967 (Best: 0.0002656 @iter11315) ([91m↑6.92%[0m) [0.12% of initial]
[Iter 11330/20000] Loss: 0.0003018 (Best: 0.0002656 @iter11315) ([91m↑1.72%[0m) [0.12% of initial]
[Iter 11340/20000] Loss: 0.0003287 (Best: 0.0002656 @iter11315) ([91m↑8.90%[0m) [0.13% of initial]
[Iter 11350/20000] Loss: 0.0003865 (Best: 0.0002656 @iter11315) ([91m↑17.59%[0m) [0.15% of initial]
[Iter 11360/20000] Loss: 0.0003101 (Best: 0.0002656 @iter11315) ([92m↓19.78%[0m) [0.12% of initial]
[Iter 11370/20000] Loss: 0.0003409 (Best: 0.0002656 @iter11315) ([91m↑9.96%[0m) [0.14% of initial]
[Iter 11380/20000] Loss: 0.0003427 (Best: 0.0002656 @iter11315) ([91m↑0.51%[0m) [0.14% of initial]
[Iter 11390/20000] Loss: 0.0003476 (Best: 0.0002656 @iter11315) ([91m↑1.44%[0m) [0.14% of initial]
Iter:11399, L1 loss=0.0003882, Total loss=0.0003526, Time:88
[Iter 11400/20000] Loss: 0.0003519 (Best: 0.0002656 @iter11315) ([91m↑1.24%[0m) [0.14% of initial]
[Iter 11410/20000] Loss: 0.0003264 (Best: 0.0002656 @iter11315) ([92m↓7.25%[0m) [0.13% of initial]
[Iter 11420/20000] Loss: 0.0003108 (Best: 0.0002656 @iter11315) ([92m↓4.79%[0m) [0.12% of initial]
[Iter 11430/20000] Loss: 0.0003503 (Best: 0.0002656 @iter11315) ([91m↑12.71%[0m) [0.14% of initial]
[Iter 11440/20000] Loss: 0.0003502 (Best: 0.0002656 @iter11315) ([92m↓0.03%[0m) [0.14% of initial]
[Iter 11450/20000] Loss: 0.0003624 (Best: 0.0002656 @iter11315) ([91m↑3.49%[0m) [0.14% of initial]
[Iter 11460/20000] Loss: 0.0003244 (Best: 0.0002656 @iter11315) ([92m↓10.49%[0m) [0.13% of initial]
[Iter 11470/20000] Loss: 0.0003180 (Best: 0.0002656 @iter11315) ([92m↓1.96%[0m) [0.13% of initial]
[Iter 11480/20000] Loss: 0.0003128 (Best: 0.0002656 @iter11315) ([92m↓1.64%[0m) [0.12% of initial]
[Iter 11490/20000] Loss: 0.0003145 (Best: 0.0002656 @iter11315) ([91m↑0.55%[0m) [0.12% of initial]
Iter:11499, L1 loss=0.0004382, Total loss=0.0003706, Time:108
[Iter 11500/20000] Loss: 0.0003321 (Best: 0.0002656 @iter11315) ([91m↑5.59%[0m) [0.13% of initial]
Pruning 10 points (0.0%) from gaussian0 at iteration 11500
Pruning 9 points (0.0%) from gaussian1 at iteration 11500
[Iter 11510/20000] Loss: 0.0006078 (Best: 0.0002656 @iter11315) ([91m↑83.01%[0m) [0.24% of initial]
[Iter 11520/20000] Loss: 0.0004401 (Best: 0.0002656 @iter11315) ([92m↓27.59%[0m) [0.17% of initial]
[Iter 11530/20000] Loss: 0.0003643 (Best: 0.0002656 @iter11315) ([92m↓17.22%[0m) [0.14% of initial]
[Iter 11540/20000] Loss: 0.0003327 (Best: 0.0002656 @iter11315) ([92m↓8.68%[0m) [0.13% of initial]
[Iter 11550/20000] Loss: 0.0003250 (Best: 0.0002656 @iter11315) ([92m↓2.30%[0m) [0.13% of initial]
[Iter 11560/20000] Loss: 0.0003321 (Best: 0.0002656 @iter11315) ([91m↑2.17%[0m) [0.13% of initial]
[Iter 11570/20000] Loss: 0.0003177 (Best: 0.0002656 @iter11315) ([92m↓4.33%[0m) [0.13% of initial]
[Iter 11580/20000] Loss: 0.0003320 (Best: 0.0002656 @iter11315) ([91m↑4.50%[0m) [0.13% of initial]
[Iter 11590/20000] Loss: 0.0003161 (Best: 0.0002656 @iter11315) ([92m↓4.79%[0m) [0.13% of initial]
Iter:11599, L1 loss=0.000329, Total loss=0.000289, Time:96
[Iter 11600/20000] Loss: 0.0003017 (Best: 0.0002656 @iter11315) ([92m↓4.56%[0m) [0.12% of initial]
[Iter 11610/20000] Loss: 0.0002956 (Best: 0.0002656 @iter11315) ([92m↓2.02%[0m) [0.12% of initial]
[Iter 11620/20000] Loss: 0.0002909 (Best: 0.0002656 @iter11315) ([92m↓1.59%[0m) [0.12% of initial]
[Iter 11630/20000] Loss: 0.0002639 (Best: 0.0002534 @iter11629) ([92m↓9.28%[0m) [0.10% of initial]
[Iter 11640/20000] Loss: 0.0003026 (Best: 0.0002534 @iter11629) ([91m↑14.65%[0m) [0.12% of initial]
[Iter 11650/20000] Loss: 0.0003251 (Best: 0.0002534 @iter11629) ([91m↑7.43%[0m) [0.13% of initial]
[Iter 11660/20000] Loss: 0.0003206 (Best: 0.0002534 @iter11629) ([92m↓1.38%[0m) [0.13% of initial]
[Iter 11670/20000] Loss: 0.0003073 (Best: 0.0002534 @iter11629) ([92m↓4.16%[0m) [0.12% of initial]
[Iter 11680/20000] Loss: 0.0003179 (Best: 0.0002534 @iter11629) ([91m↑3.47%[0m) [0.13% of initial]
[Iter 11690/20000] Loss: 0.0003087 (Best: 0.0002534 @iter11629) ([92m↓2.89%[0m) [0.12% of initial]
Iter:11699, L1 loss=0.0003259, Total loss=0.000283, Time:90
[Iter 11700/20000] Loss: 0.0002909 (Best: 0.0002534 @iter11629) ([92m↓5.78%[0m) [0.12% of initial]
[Iter 11710/20000] Loss: 0.0002872 (Best: 0.0002534 @iter11629) ([92m↓1.27%[0m) [0.11% of initial]
[Iter 11720/20000] Loss: 0.0002827 (Best: 0.0002534 @iter11629) ([92m↓1.55%[0m) [0.11% of initial]
[Iter 11730/20000] Loss: 0.0002981 (Best: 0.0002534 @iter11629) ([91m↑5.43%[0m) [0.12% of initial]
[Iter 11740/20000] Loss: 0.0003216 (Best: 0.0002534 @iter11629) ([91m↑7.88%[0m) [0.13% of initial]
[Iter 11750/20000] Loss: 0.0003280 (Best: 0.0002534 @iter11629) ([91m↑1.98%[0m) [0.13% of initial]
[Iter 11760/20000] Loss: 0.0003578 (Best: 0.0002534 @iter11629) ([91m↑9.09%[0m) [0.14% of initial]
[Iter 11770/20000] Loss: 0.0003142 (Best: 0.0002534 @iter11629) ([92m↓12.19%[0m) [0.12% of initial]
[Iter 11780/20000] Loss: 0.0003104 (Best: 0.0002534 @iter11629) ([92m↓1.19%[0m) [0.12% of initial]
[Iter 11790/20000] Loss: 0.0002901 (Best: 0.0002534 @iter11629) ([92m↓6.56%[0m) [0.12% of initial]
Iter:11799, L1 loss=0.0003596, Total loss=0.0002982, Time:74
[Iter 11800/20000] Loss: 0.0002807 (Best: 0.0002534 @iter11629) ([92m↓3.22%[0m) [0.11% of initial]
[Iter 11810/20000] Loss: 0.0002683 (Best: 0.0002534 @iter11629) ([92m↓4.42%[0m) [0.11% of initial]
[Iter 11820/20000] Loss: 0.0002897 (Best: 0.0002534 @iter11629) ([91m↑7.97%[0m) [0.12% of initial]
[Iter 11830/20000] Loss: 0.0003186 (Best: 0.0002534 @iter11629) ([91m↑9.97%[0m) [0.13% of initial]
[Iter 11840/20000] Loss: 0.0003167 (Best: 0.0002534 @iter11629) ([92m↓0.60%[0m) [0.13% of initial]
[Iter 11850/20000] Loss: 0.0003079 (Best: 0.0002534 @iter11629) ([92m↓2.75%[0m) [0.12% of initial]
[Iter 11860/20000] Loss: 0.0003004 (Best: 0.0002534 @iter11629) ([92m↓2.46%[0m) [0.12% of initial]
[Iter 11870/20000] Loss: 0.0002998 (Best: 0.0002534 @iter11629) ([92m↓0.20%[0m) [0.12% of initial]
[Iter 11880/20000] Loss: 0.0003059 (Best: 0.0002534 @iter11629) ([91m↑2.03%[0m) [0.12% of initial]
[Iter 11890/20000] Loss: 0.0003845 (Best: 0.0002534 @iter11629) ([91m↑25.72%[0m) [0.15% of initial]
Iter:11899, L1 loss=0.0003913, Total loss=0.0003354, Time:80
[Iter 11900/20000] Loss: 0.0003433 (Best: 0.0002534 @iter11629) ([92m↓10.74%[0m) [0.14% of initial]
[Iter 11910/20000] Loss: 0.0003390 (Best: 0.0002534 @iter11629) ([92m↓1.25%[0m) [0.13% of initial]
[Iter 11920/20000] Loss: 0.0003665 (Best: 0.0002534 @iter11629) ([91m↑8.14%[0m) [0.15% of initial]
[Iter 11930/20000] Loss: 0.0003297 (Best: 0.0002534 @iter11629) ([92m↓10.06%[0m) [0.13% of initial]
[Iter 11940/20000] Loss: 0.0003158 (Best: 0.0002534 @iter11629) ([92m↓4.19%[0m) [0.13% of initial]
[Iter 11950/20000] Loss: 0.0003113 (Best: 0.0002534 @iter11629) ([92m↓1.45%[0m) [0.12% of initial]
[Iter 11960/20000] Loss: 0.0002683 (Best: 0.0002534 @iter11629) ([92m↓13.81%[0m) [0.11% of initial]
[Iter 11970/20000] Loss: 0.0002888 (Best: 0.0002534 @iter11629) ([91m↑7.66%[0m) [0.11% of initial]
[Iter 11980/20000] Loss: 0.0002786 (Best: 0.0002534 @iter11629) ([92m↓3.54%[0m) [0.11% of initial]
[Iter 11990/20000] Loss: 0.0002860 (Best: 0.0002534 @iter11629) ([91m↑2.66%[0m) [0.11% of initial]
Iter:11999, L1 loss=0.0003264, Total loss=0.000273, Time:77
[Iter 12000/20000] Loss: 0.0003013 (Best: 0.0002534 @iter11629) ([91m↑5.34%[0m) [0.12% of initial]
Pruning 12 points (0.0%) from gaussian0 at iteration 12000
Pruning 13 points (0.0%) from gaussian1 at iteration 12000
[Iter 12010/20000] Loss: 0.0207722 (Best: 0.0002534 @iter11629) ([91m↑6793.52%[0m) [8.25% of initial]
[Iter 12020/20000] Loss: 0.0059293 (Best: 0.0002534 @iter11629) ([92m↓71.46%[0m) [2.36% of initial]
[Iter 12030/20000] Loss: 0.0038689 (Best: 0.0002534 @iter11629) ([92m↓34.75%[0m) [1.54% of initial]
[Iter 12040/20000] Loss: 0.0021228 (Best: 0.0002534 @iter11629) ([92m↓45.13%[0m) [0.84% of initial]
[Iter 12050/20000] Loss: 0.0014072 (Best: 0.0002534 @iter11629) ([92m↓33.71%[0m) [0.56% of initial]
[Iter 12060/20000] Loss: 0.0010214 (Best: 0.0002534 @iter11629) ([92m↓27.41%[0m) [0.41% of initial]
[Iter 12070/20000] Loss: 0.0007796 (Best: 0.0002534 @iter11629) ([92m↓23.67%[0m) [0.31% of initial]
[Iter 12080/20000] Loss: 0.0006594 (Best: 0.0002534 @iter11629) ([92m↓15.41%[0m) [0.26% of initial]
[Iter 12090/20000] Loss: 0.0005764 (Best: 0.0002534 @iter11629) ([92m↓12.59%[0m) [0.23% of initial]
Iter:12099, L1 loss=0.0006315, Total loss=0.0005815, Time:98
[Iter 12100/20000] Loss: 0.0005410 (Best: 0.0002534 @iter11629) ([92m↓6.14%[0m) [0.21% of initial]
[Iter 12110/20000] Loss: 0.0004986 (Best: 0.0002534 @iter11629) ([92m↓7.84%[0m) [0.20% of initial]
[Iter 12120/20000] Loss: 0.0004689 (Best: 0.0002534 @iter11629) ([92m↓5.95%[0m) [0.19% of initial]
[Iter 12130/20000] Loss: 0.0004353 (Best: 0.0002534 @iter11629) ([92m↓7.17%[0m) [0.17% of initial]
[Iter 12140/20000] Loss: 0.0004187 (Best: 0.0002534 @iter11629) ([92m↓3.81%[0m) [0.17% of initial]
[Iter 12150/20000] Loss: 0.0004240 (Best: 0.0002534 @iter11629) ([91m↑1.27%[0m) [0.17% of initial]
[Iter 12160/20000] Loss: 0.0003994 (Best: 0.0002534 @iter11629) ([92m↓5.80%[0m) [0.16% of initial]
[Iter 12170/20000] Loss: 0.0003800 (Best: 0.0002534 @iter11629) ([92m↓4.86%[0m) [0.15% of initial]
[Iter 12180/20000] Loss: 0.0003705 (Best: 0.0002534 @iter11629) ([92m↓2.51%[0m) [0.15% of initial]
[Iter 12190/20000] Loss: 0.0003672 (Best: 0.0002534 @iter11629) ([92m↓0.89%[0m) [0.15% of initial]
Iter:12199, L1 loss=0.0004162, Total loss=0.0003627, Time:104
[Iter 12200/20000] Loss: 0.0003509 (Best: 0.0002534 @iter11629) ([92m↓4.42%[0m) [0.14% of initial]
[Iter 12210/20000] Loss: 0.0003663 (Best: 0.0002534 @iter11629) ([91m↑4.38%[0m) [0.15% of initial]
[Iter 12220/20000] Loss: 0.0003545 (Best: 0.0002534 @iter11629) ([92m↓3.22%[0m) [0.14% of initial]
[Iter 12230/20000] Loss: 0.0003529 (Best: 0.0002534 @iter11629) ([92m↓0.44%[0m) [0.14% of initial]
[Iter 12240/20000] Loss: 0.0003671 (Best: 0.0002534 @iter11629) ([91m↑4.01%[0m) [0.15% of initial]
[Iter 12250/20000] Loss: 0.0003520 (Best: 0.0002534 @iter11629) ([92m↓4.12%[0m) [0.14% of initial]
[Iter 12260/20000] Loss: 0.0003481 (Best: 0.0002534 @iter11629) ([92m↓1.12%[0m) [0.14% of initial]
[Iter 12270/20000] Loss: 0.0003486 (Best: 0.0002534 @iter11629) ([91m↑0.14%[0m) [0.14% of initial]
[Iter 12280/20000] Loss: 0.0003581 (Best: 0.0002534 @iter11629) ([91m↑2.73%[0m) [0.14% of initial]
[Iter 12290/20000] Loss: 0.0004050 (Best: 0.0002534 @iter11629) ([91m↑13.10%[0m) [0.16% of initial]
Iter:12299, L1 loss=0.0004126, Total loss=0.0003706, Time:86
[Iter 12300/20000] Loss: 0.0003666 (Best: 0.0002534 @iter11629) ([92m↓9.49%[0m) [0.15% of initial]
[Iter 12310/20000] Loss: 0.0003473 (Best: 0.0002534 @iter11629) ([92m↓5.25%[0m) [0.14% of initial]
[Iter 12320/20000] Loss: 0.0003377 (Best: 0.0002534 @iter11629) ([92m↓2.76%[0m) [0.13% of initial]
[Iter 12330/20000] Loss: 0.0003543 (Best: 0.0002534 @iter11629) ([91m↑4.92%[0m) [0.14% of initial]
[Iter 12340/20000] Loss: 0.0003508 (Best: 0.0002534 @iter11629) ([92m↓0.99%[0m) [0.14% of initial]
[Iter 12350/20000] Loss: 0.0003427 (Best: 0.0002534 @iter11629) ([92m↓2.32%[0m) [0.14% of initial]
[Iter 12360/20000] Loss: 0.0003365 (Best: 0.0002534 @iter11629) ([92m↓1.82%[0m) [0.13% of initial]
[Iter 12370/20000] Loss: 0.0003284 (Best: 0.0002534 @iter11629) ([92m↓2.39%[0m) [0.13% of initial]
[Iter 12380/20000] Loss: 0.0003320 (Best: 0.0002534 @iter11629) ([91m↑1.08%[0m) [0.13% of initial]
[Iter 12390/20000] Loss: 0.0003346 (Best: 0.0002534 @iter11629) ([91m↑0.80%[0m) [0.13% of initial]
Iter:12399, L1 loss=0.0003629, Total loss=0.0003247, Time:108
[Iter 12400/20000] Loss: 0.0003345 (Best: 0.0002534 @iter11629) ([92m↓0.03%[0m) [0.13% of initial]
[Iter 12410/20000] Loss: 0.0003506 (Best: 0.0002534 @iter11629) ([91m↑4.82%[0m) [0.14% of initial]
[Iter 12420/20000] Loss: 0.0003425 (Best: 0.0002534 @iter11629) ([92m↓2.32%[0m) [0.14% of initial]
[Iter 12430/20000] Loss: 0.0003376 (Best: 0.0002534 @iter11629) ([92m↓1.43%[0m) [0.13% of initial]
[Iter 12440/20000] Loss: 0.0003470 (Best: 0.0002534 @iter11629) ([91m↑2.79%[0m) [0.14% of initial]
[Iter 12450/20000] Loss: 0.0003483 (Best: 0.0002534 @iter11629) ([91m↑0.36%[0m) [0.14% of initial]
[Iter 12460/20000] Loss: 0.0003362 (Best: 0.0002534 @iter11629) ([92m↓3.45%[0m) [0.13% of initial]
[Iter 12470/20000] Loss: 0.0003408 (Best: 0.0002534 @iter11629) ([91m↑1.36%[0m) [0.14% of initial]
[Iter 12480/20000] Loss: 0.0003436 (Best: 0.0002534 @iter11629) ([91m↑0.81%[0m) [0.14% of initial]
[Iter 12490/20000] Loss: 0.0003365 (Best: 0.0002534 @iter11629) ([92m↓2.06%[0m) [0.13% of initial]
Iter:12499, L1 loss=0.0003866, Total loss=0.0003462, Time:75
[Iter 12500/20000] Loss: 0.0003443 (Best: 0.0002534 @iter11629) ([91m↑2.33%[0m) [0.14% of initial]
Pruning 31 points (0.0%) from gaussian0 at iteration 12500
Pruning 19 points (0.0%) from gaussian1 at iteration 12500
[Iter 12510/20000] Loss: 0.0006706 (Best: 0.0002534 @iter11629) ([91m↑94.76%[0m) [0.27% of initial]
[Iter 12520/20000] Loss: 0.0004916 (Best: 0.0002534 @iter11629) ([92m↓26.69%[0m) [0.20% of initial]
[Iter 12530/20000] Loss: 0.0004011 (Best: 0.0002534 @iter11629) ([92m↓18.42%[0m) [0.16% of initial]
[Iter 12540/20000] Loss: 0.0003666 (Best: 0.0002534 @iter11629) ([92m↓8.59%[0m) [0.15% of initial]
[Iter 12550/20000] Loss: 0.0003290 (Best: 0.0002534 @iter11629) ([92m↓10.25%[0m) [0.13% of initial]
[Iter 12560/20000] Loss: 0.0003286 (Best: 0.0002534 @iter11629) ([92m↓0.12%[0m) [0.13% of initial]
[Iter 12570/20000] Loss: 0.0003423 (Best: 0.0002534 @iter11629) ([91m↑4.16%[0m) [0.14% of initial]
[Iter 12580/20000] Loss: 0.0003488 (Best: 0.0002534 @iter11629) ([91m↑1.91%[0m) [0.14% of initial]
[Iter 12590/20000] Loss: 0.0003445 (Best: 0.0002534 @iter11629) ([92m↓1.26%[0m) [0.14% of initial]
Iter:12599, L1 loss=0.0004673, Total loss=0.0004001, Time:108
[Iter 12600/20000] Loss: 0.0003710 (Best: 0.0002534 @iter11629) ([91m↑7.70%[0m) [0.15% of initial]
[Iter 12610/20000] Loss: 0.0003601 (Best: 0.0002534 @iter11629) ([92m↓2.92%[0m) [0.14% of initial]
[Iter 12620/20000] Loss: 0.0003434 (Best: 0.0002534 @iter11629) ([92m↓4.64%[0m) [0.14% of initial]
[Iter 12630/20000] Loss: 0.0003614 (Best: 0.0002534 @iter11629) ([91m↑5.24%[0m) [0.14% of initial]
[Iter 12640/20000] Loss: 0.0003567 (Best: 0.0002534 @iter11629) ([92m↓1.31%[0m) [0.14% of initial]
[Iter 12650/20000] Loss: 0.0003660 (Best: 0.0002534 @iter11629) ([91m↑2.61%[0m) [0.15% of initial]
[Iter 12660/20000] Loss: 0.0003605 (Best: 0.0002534 @iter11629) ([92m↓1.51%[0m) [0.14% of initial]
[Iter 12670/20000] Loss: 0.0003660 (Best: 0.0002534 @iter11629) ([91m↑1.54%[0m) [0.15% of initial]
[Iter 12680/20000] Loss: 0.0003910 (Best: 0.0002534 @iter11629) ([91m↑6.83%[0m) [0.16% of initial]
[Iter 12690/20000] Loss: 0.0003609 (Best: 0.0002534 @iter11629) ([92m↓7.69%[0m) [0.14% of initial]
Iter:12699, L1 loss=0.0004527, Total loss=0.000385, Time:103
[Iter 12700/20000] Loss: 0.0003735 (Best: 0.0002534 @iter11629) ([91m↑3.48%[0m) [0.15% of initial]
[Iter 12710/20000] Loss: 0.0003672 (Best: 0.0002534 @iter11629) ([92m↓1.68%[0m) [0.15% of initial]
[Iter 12720/20000] Loss: 0.0003685 (Best: 0.0002534 @iter11629) ([91m↑0.35%[0m) [0.15% of initial]
[Iter 12730/20000] Loss: 0.0003792 (Best: 0.0002534 @iter11629) ([91m↑2.92%[0m) [0.15% of initial]
[Iter 12740/20000] Loss: 0.0003561 (Best: 0.0002534 @iter11629) ([92m↓6.10%[0m) [0.14% of initial]
[Iter 12750/20000] Loss: 0.0003331 (Best: 0.0002534 @iter11629) ([92m↓6.47%[0m) [0.13% of initial]
[Iter 12760/20000] Loss: 0.0003328 (Best: 0.0002534 @iter11629) ([92m↓0.07%[0m) [0.13% of initial]
[Iter 12770/20000] Loss: 0.0003398 (Best: 0.0002534 @iter11629) ([91m↑2.09%[0m) [0.13% of initial]
[Iter 12780/20000] Loss: 0.0003633 (Best: 0.0002534 @iter11629) ([91m↑6.92%[0m) [0.14% of initial]
[Iter 12790/20000] Loss: 0.0003536 (Best: 0.0002534 @iter11629) ([92m↓2.69%[0m) [0.14% of initial]
Iter:12799, L1 loss=0.0003998, Total loss=0.000356, Time:87
[Iter 12800/20000] Loss: 0.0003599 (Best: 0.0002534 @iter11629) ([91m↑1.80%[0m) [0.14% of initial]
[Iter 12810/20000] Loss: 0.0003727 (Best: 0.0002534 @iter11629) ([91m↑3.54%[0m) [0.15% of initial]
[Iter 12820/20000] Loss: 0.0003520 (Best: 0.0002534 @iter11629) ([92m↓5.55%[0m) [0.14% of initial]
[Iter 12830/20000] Loss: 0.0003421 (Best: 0.0002534 @iter11629) ([92m↓2.81%[0m) [0.14% of initial]
[Iter 12840/20000] Loss: 0.0003555 (Best: 0.0002534 @iter11629) ([91m↑3.92%[0m) [0.14% of initial]
[Iter 12850/20000] Loss: 0.0003289 (Best: 0.0002534 @iter11629) ([92m↓7.48%[0m) [0.13% of initial]
[Iter 12860/20000] Loss: 0.0003296 (Best: 0.0002534 @iter11629) ([91m↑0.20%[0m) [0.13% of initial]
[Iter 12870/20000] Loss: 0.0003187 (Best: 0.0002534 @iter11629) ([92m↓3.31%[0m) [0.13% of initial]
[Iter 12880/20000] Loss: 0.0003127 (Best: 0.0002534 @iter11629) ([92m↓1.87%[0m) [0.12% of initial]
[Iter 12890/20000] Loss: 0.0003160 (Best: 0.0002534 @iter11629) ([91m↑1.05%[0m) [0.13% of initial]
Iter:12899, L1 loss=0.0003527, Total loss=0.0003213, Time:81
[Iter 12900/20000] Loss: 0.0003153 (Best: 0.0002534 @iter11629) ([92m↓0.21%[0m) [0.13% of initial]
[Iter 12910/20000] Loss: 0.0003172 (Best: 0.0002534 @iter11629) ([91m↑0.58%[0m) [0.13% of initial]
[Iter 12920/20000] Loss: 0.0003410 (Best: 0.0002534 @iter11629) ([91m↑7.52%[0m) [0.14% of initial]
[Iter 12930/20000] Loss: 0.0003463 (Best: 0.0002534 @iter11629) ([91m↑1.56%[0m) [0.14% of initial]
[Iter 12940/20000] Loss: 0.0003606 (Best: 0.0002534 @iter11629) ([91m↑4.11%[0m) [0.14% of initial]
[Iter 12950/20000] Loss: 0.0003738 (Best: 0.0002534 @iter11629) ([91m↑3.68%[0m) [0.15% of initial]
[Iter 12960/20000] Loss: 0.0004153 (Best: 0.0002534 @iter11629) ([91m↑11.09%[0m) [0.16% of initial]
[Iter 12970/20000] Loss: 0.0003520 (Best: 0.0002534 @iter11629) ([92m↓15.24%[0m) [0.14% of initial]
[Iter 12980/20000] Loss: 0.0003696 (Best: 0.0002534 @iter11629) ([91m↑5.01%[0m) [0.15% of initial]
[Iter 12990/20000] Loss: 0.0003678 (Best: 0.0002534 @iter11629) ([92m↓0.50%[0m) [0.15% of initial]
Iter:12999, L1 loss=0.0003599, Total loss=0.0003301, Time:67
[Iter 13000/20000] Loss: 0.0003349 (Best: 0.0002534 @iter11629) ([92m↓8.95%[0m) [0.13% of initial]
Pruning 13 points (0.0%) from gaussian0 at iteration 13000
Pruning 20 points (0.0%) from gaussian1 at iteration 13000
[Iter 13010/20000] Loss: 0.0008158 (Best: 0.0002534 @iter11629) ([91m↑143.61%[0m) [0.32% of initial]
[Iter 13020/20000] Loss: 0.0005225 (Best: 0.0002534 @iter11629) ([92m↓35.95%[0m) [0.21% of initial]
[Iter 13030/20000] Loss: 0.0004353 (Best: 0.0002534 @iter11629) ([92m↓16.69%[0m) [0.17% of initial]
[Iter 13040/20000] Loss: 0.0003922 (Best: 0.0002534 @iter11629) ([92m↓9.89%[0m) [0.16% of initial]
[Iter 13050/20000] Loss: 0.0003412 (Best: 0.0002534 @iter11629) ([92m↓13.02%[0m) [0.14% of initial]
[Iter 13060/20000] Loss: 0.0003259 (Best: 0.0002534 @iter11629) ([92m↓4.49%[0m) [0.13% of initial]
[Iter 13070/20000] Loss: 0.0003276 (Best: 0.0002534 @iter11629) ([91m↑0.53%[0m) [0.13% of initial]
[Iter 13080/20000] Loss: 0.0003211 (Best: 0.0002534 @iter11629) ([92m↓1.98%[0m) [0.13% of initial]
[Iter 13090/20000] Loss: 0.0003347 (Best: 0.0002534 @iter11629) ([91m↑4.23%[0m) [0.13% of initial]
Iter:13099, L1 loss=0.0003764, Total loss=0.0003194, Time:88
[Iter 13100/20000] Loss: 0.0003363 (Best: 0.0002534 @iter11629) ([91m↑0.48%[0m) [0.13% of initial]
[Iter 13110/20000] Loss: 0.0003440 (Best: 0.0002534 @iter11629) ([91m↑2.30%[0m) [0.14% of initial]
[Iter 13120/20000] Loss: 0.0003332 (Best: 0.0002534 @iter11629) ([92m↓3.13%[0m) [0.13% of initial]
[Iter 13130/20000] Loss: 0.0003422 (Best: 0.0002534 @iter11629) ([91m↑2.70%[0m) [0.14% of initial]
[Iter 13140/20000] Loss: 0.0003289 (Best: 0.0002534 @iter11629) ([92m↓3.88%[0m) [0.13% of initial]
[Iter 13150/20000] Loss: 0.0003099 (Best: 0.0002534 @iter11629) ([92m↓5.79%[0m) [0.12% of initial]
[Iter 13160/20000] Loss: 0.0003296 (Best: 0.0002534 @iter11629) ([91m↑6.37%[0m) [0.13% of initial]
[Iter 13170/20000] Loss: 0.0003286 (Best: 0.0002534 @iter11629) ([92m↓0.33%[0m) [0.13% of initial]
[Iter 13180/20000] Loss: 0.0003542 (Best: 0.0002534 @iter11629) ([91m↑7.80%[0m) [0.14% of initial]
[Iter 13190/20000] Loss: 0.0003448 (Best: 0.0002534 @iter11629) ([92m↓2.64%[0m) [0.14% of initial]
Iter:13199, L1 loss=0.0003775, Total loss=0.0003486, Time:96
[Iter 13200/20000] Loss: 0.0003515 (Best: 0.0002534 @iter11629) ([91m↑1.94%[0m) [0.14% of initial]
[Iter 13210/20000] Loss: 0.0003601 (Best: 0.0002534 @iter11629) ([91m↑2.45%[0m) [0.14% of initial]
[Iter 13220/20000] Loss: 0.0003191 (Best: 0.0002534 @iter11629) ([92m↓11.39%[0m) [0.13% of initial]
[Iter 13230/20000] Loss: 0.0003708 (Best: 0.0002534 @iter11629) ([91m↑16.20%[0m) [0.15% of initial]
[Iter 13240/20000] Loss: 0.0003456 (Best: 0.0002534 @iter11629) ([92m↓6.80%[0m) [0.14% of initial]
[Iter 13250/20000] Loss: 0.0003366 (Best: 0.0002534 @iter11629) ([92m↓2.59%[0m) [0.13% of initial]
[Iter 13260/20000] Loss: 0.0003229 (Best: 0.0002534 @iter11629) ([92m↓4.08%[0m) [0.13% of initial]
[Iter 13270/20000] Loss: 0.0003301 (Best: 0.0002534 @iter11629) ([91m↑2.23%[0m) [0.13% of initial]
[Iter 13280/20000] Loss: 0.0003334 (Best: 0.0002534 @iter11629) ([91m↑1.00%[0m) [0.13% of initial]
[Iter 13290/20000] Loss: 0.0003091 (Best: 0.0002534 @iter11629) ([92m↓7.27%[0m) [0.12% of initial]
Iter:13299, L1 loss=0.0003347, Total loss=0.0002977, Time:106
[Iter 13300/20000] Loss: 0.0003017 (Best: 0.0002534 @iter11629) ([92m↓2.39%[0m) [0.12% of initial]
[Iter 13310/20000] Loss: 0.0003013 (Best: 0.0002534 @iter11629) ([92m↓0.13%[0m) [0.12% of initial]
[Iter 13320/20000] Loss: 0.0003042 (Best: 0.0002534 @iter11629) ([91m↑0.94%[0m) [0.12% of initial]
[Iter 13330/20000] Loss: 0.0003059 (Best: 0.0002534 @iter11629) ([91m↑0.56%[0m) [0.12% of initial]
[Iter 13340/20000] Loss: 0.0003129 (Best: 0.0002534 @iter11629) ([91m↑2.28%[0m) [0.12% of initial]
[Iter 13350/20000] Loss: 0.0003016 (Best: 0.0002534 @iter11629) ([92m↓3.61%[0m) [0.12% of initial]
[Iter 13360/20000] Loss: 0.0003064 (Best: 0.0002534 @iter11629) ([91m↑1.60%[0m) [0.12% of initial]
[Iter 13370/20000] Loss: 0.0002903 (Best: 0.0002534 @iter11629) ([92m↓5.27%[0m) [0.12% of initial]
[Iter 13380/20000] Loss: 0.0003181 (Best: 0.0002534 @iter11629) ([91m↑9.58%[0m) [0.13% of initial]
[Iter 13390/20000] Loss: 0.0003121 (Best: 0.0002534 @iter11629) ([92m↓1.87%[0m) [0.12% of initial]
Iter:13399, L1 loss=0.0003468, Total loss=0.0002947, Time:90
[Iter 13400/20000] Loss: 0.0003096 (Best: 0.0002534 @iter11629) ([92m↓0.80%[0m) [0.12% of initial]
[Iter 13410/20000] Loss: 0.0003074 (Best: 0.0002534 @iter11629) ([92m↓0.72%[0m) [0.12% of initial]
[Iter 13420/20000] Loss: 0.0003076 (Best: 0.0002534 @iter11629) ([91m↑0.07%[0m) [0.12% of initial]
[Iter 13430/20000] Loss: 0.0002945 (Best: 0.0002534 @iter11629) ([92m↓4.27%[0m) [0.12% of initial]
[Iter 13440/20000] Loss: 0.0003073 (Best: 0.0002534 @iter11629) ([91m↑4.36%[0m) [0.12% of initial]
[Iter 13450/20000] Loss: 0.0002936 (Best: 0.0002534 @iter11629) ([92m↓4.47%[0m) [0.12% of initial]
[Iter 13460/20000] Loss: 0.0002949 (Best: 0.0002534 @iter11629) ([91m↑0.45%[0m) [0.12% of initial]
[Iter 13470/20000] Loss: 0.0003115 (Best: 0.0002534 @iter11629) ([91m↑5.62%[0m) [0.12% of initial]
[Iter 13480/20000] Loss: 0.0003048 (Best: 0.0002534 @iter11629) ([92m↓2.13%[0m) [0.12% of initial]
[Iter 13490/20000] Loss: 0.0003604 (Best: 0.0002534 @iter11629) ([91m↑18.24%[0m) [0.14% of initial]
Iter:13499, L1 loss=0.000384, Total loss=0.0003259, Time:70
[Iter 13500/20000] Loss: 0.0003388 (Best: 0.0002534 @iter11629) ([92m↓6.01%[0m) [0.13% of initial]
Pruning 14 points (0.0%) from gaussian0 at iteration 13500
Pruning 11 points (0.0%) from gaussian1 at iteration 13500
[Iter 13510/20000] Loss: 0.0006974 (Best: 0.0002534 @iter11629) ([91m↑105.85%[0m) [0.28% of initial]
[Iter 13520/20000] Loss: 0.0004768 (Best: 0.0002534 @iter11629) ([92m↓31.63%[0m) [0.19% of initial]
[Iter 13530/20000] Loss: 0.0004204 (Best: 0.0002534 @iter11629) ([92m↓11.82%[0m) [0.17% of initial]
[Iter 13540/20000] Loss: 0.0003524 (Best: 0.0002534 @iter11629) ([92m↓16.18%[0m) [0.14% of initial]
[Iter 13550/20000] Loss: 0.0003185 (Best: 0.0002534 @iter11629) ([92m↓9.64%[0m) [0.13% of initial]
[Iter 13560/20000] Loss: 0.0003027 (Best: 0.0002534 @iter11629) ([92m↓4.96%[0m) [0.12% of initial]
[Iter 13570/20000] Loss: 0.0002832 (Best: 0.0002534 @iter11629) ([92m↓6.43%[0m) [0.11% of initial]
[Iter 13580/20000] Loss: 0.0002987 (Best: 0.0002534 @iter11629) ([91m↑5.48%[0m) [0.12% of initial]
[Iter 13590/20000] Loss: 0.0003087 (Best: 0.0002534 @iter11629) ([91m↑3.35%[0m) [0.12% of initial]
Iter:13599, L1 loss=0.0003535, Total loss=0.0002823, Time:100
[Iter 13600/20000] Loss: 0.0002798 (Best: 0.0002534 @iter11629) ([92m↓9.36%[0m) [0.11% of initial]
[Iter 13610/20000] Loss: 0.0002904 (Best: 0.0002534 @iter11629) ([91m↑3.80%[0m) [0.12% of initial]
[Iter 13620/20000] Loss: 0.0002828 (Best: 0.0002534 @iter11629) ([92m↓2.64%[0m) [0.11% of initial]
[Iter 13630/20000] Loss: 0.0002767 (Best: 0.0002534 @iter11629) ([92m↓2.14%[0m) [0.11% of initial]
[Iter 13640/20000] Loss: 0.0003149 (Best: 0.0002534 @iter11629) ([91m↑13.79%[0m) [0.13% of initial]
[Iter 13650/20000] Loss: 0.0003137 (Best: 0.0002534 @iter11629) ([92m↓0.38%[0m) [0.12% of initial]
[Iter 13660/20000] Loss: 0.0003042 (Best: 0.0002534 @iter11629) ([92m↓3.01%[0m) [0.12% of initial]
[Iter 13670/20000] Loss: 0.0003196 (Best: 0.0002534 @iter11629) ([91m↑5.05%[0m) [0.13% of initial]
[Iter 13680/20000] Loss: 0.0003221 (Best: 0.0002534 @iter11629) ([91m↑0.77%[0m) [0.13% of initial]
[Iter 13690/20000] Loss: 0.0003320 (Best: 0.0002534 @iter11629) ([91m↑3.08%[0m) [0.13% of initial]
Iter:13699, L1 loss=0.0004448, Total loss=0.0003308, Time:81
[Iter 13700/20000] Loss: 0.0003129 (Best: 0.0002534 @iter11629) ([92m↓5.76%[0m) [0.12% of initial]
[Iter 13710/20000] Loss: 0.0002983 (Best: 0.0002534 @iter11629) ([92m↓4.64%[0m) [0.12% of initial]
[Iter 13720/20000] Loss: 0.0003162 (Best: 0.0002534 @iter11629) ([91m↑5.98%[0m) [0.13% of initial]
[Iter 13730/20000] Loss: 0.0003251 (Best: 0.0002534 @iter11629) ([91m↑2.83%[0m) [0.13% of initial]
[Iter 13740/20000] Loss: 0.0003347 (Best: 0.0002534 @iter11629) ([91m↑2.94%[0m) [0.13% of initial]
[Iter 13750/20000] Loss: 0.0003074 (Best: 0.0002534 @iter11629) ([92m↓8.17%[0m) [0.12% of initial]
[Iter 13760/20000] Loss: 0.0003233 (Best: 0.0002534 @iter11629) ([91m↑5.18%[0m) [0.13% of initial]
[Iter 13770/20000] Loss: 0.0003279 (Best: 0.0002534 @iter11629) ([91m↑1.42%[0m) [0.13% of initial]
[Iter 13780/20000] Loss: 0.0003272 (Best: 0.0002534 @iter11629) ([92m↓0.20%[0m) [0.13% of initial]
[Iter 13790/20000] Loss: 0.0003816 (Best: 0.0002534 @iter11629) ([91m↑16.60%[0m) [0.15% of initial]
Iter:13799, L1 loss=0.000405, Total loss=0.000328, Time:83
[Iter 13800/20000] Loss: 0.0003183 (Best: 0.0002534 @iter11629) ([92m↓16.59%[0m) [0.13% of initial]
[Iter 13810/20000] Loss: 0.0003228 (Best: 0.0002534 @iter11629) ([91m↑1.44%[0m) [0.13% of initial]
[Iter 13820/20000] Loss: 0.0003144 (Best: 0.0002534 @iter11629) ([92m↓2.63%[0m) [0.12% of initial]
[Iter 13830/20000] Loss: 0.0003252 (Best: 0.0002534 @iter11629) ([91m↑3.46%[0m) [0.13% of initial]
[Iter 13840/20000] Loss: 0.0003112 (Best: 0.0002534 @iter11629) ([92m↓4.30%[0m) [0.12% of initial]
[Iter 13850/20000] Loss: 0.0002966 (Best: 0.0002534 @iter11629) ([92m↓4.69%[0m) [0.12% of initial]
[Iter 13860/20000] Loss: 0.0002981 (Best: 0.0002534 @iter11629) ([91m↑0.49%[0m) [0.12% of initial]
[Iter 13870/20000] Loss: 0.0002872 (Best: 0.0002534 @iter11629) ([92m↓3.64%[0m) [0.11% of initial]
[Iter 13880/20000] Loss: 0.0002947 (Best: 0.0002534 @iter11629) ([91m↑2.61%[0m) [0.12% of initial]
[Iter 13890/20000] Loss: 0.0003009 (Best: 0.0002534 @iter11629) ([91m↑2.11%[0m) [0.12% of initial]
Iter:13899, L1 loss=0.0003723, Total loss=0.0003361, Time:78
[Iter 13900/20000] Loss: 0.0003169 (Best: 0.0002534 @iter11629) ([91m↑5.32%[0m) [0.13% of initial]
[Iter 13910/20000] Loss: 0.0003015 (Best: 0.0002534 @iter11629) ([92m↓4.86%[0m) [0.12% of initial]
[Iter 13920/20000] Loss: 0.0003159 (Best: 0.0002534 @iter11629) ([91m↑4.75%[0m) [0.13% of initial]
[Iter 13930/20000] Loss: 0.0002904 (Best: 0.0002534 @iter11629) ([92m↓8.07%[0m) [0.12% of initial]
[Iter 13940/20000] Loss: 0.0002971 (Best: 0.0002534 @iter11629) ([91m↑2.31%[0m) [0.12% of initial]
[Iter 13950/20000] Loss: 0.0003091 (Best: 0.0002534 @iter11629) ([91m↑4.06%[0m) [0.12% of initial]
[Iter 13960/20000] Loss: 0.0002878 (Best: 0.0002534 @iter11629) ([92m↓6.88%[0m) [0.11% of initial]
[Iter 13970/20000] Loss: 0.0002996 (Best: 0.0002534 @iter11629) ([91m↑4.09%[0m) [0.12% of initial]
[Iter 13980/20000] Loss: 0.0003098 (Best: 0.0002534 @iter11629) ([91m↑3.39%[0m) [0.12% of initial]
[Iter 13990/20000] Loss: 0.0003534 (Best: 0.0002534 @iter11629) ([91m↑14.06%[0m) [0.14% of initial]
Iter:13999, L1 loss=0.0003208, Total loss=0.0002883, Time:94
[Iter 14000/20000] Loss: 0.0003144 (Best: 0.0002534 @iter11629) ([92m↓11.03%[0m) [0.12% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 14000
Pruning 6 points (0.0%) from gaussian1 at iteration 14000
[Iter 14010/20000] Loss: 0.0006112 (Best: 0.0002534 @iter11629) ([91m↑94.41%[0m) [0.24% of initial]
[Iter 14020/20000] Loss: 0.0004202 (Best: 0.0002534 @iter11629) ([92m↓31.25%[0m) [0.17% of initial]
[Iter 14030/20000] Loss: 0.0003558 (Best: 0.0002534 @iter11629) ([92m↓15.32%[0m) [0.14% of initial]
[Iter 14040/20000] Loss: 0.0003148 (Best: 0.0002534 @iter11629) ([92m↓11.54%[0m) [0.13% of initial]
[Iter 14050/20000] Loss: 0.0003182 (Best: 0.0002534 @iter11629) ([91m↑1.10%[0m) [0.13% of initial]
[Iter 14060/20000] Loss: 0.0003158 (Best: 0.0002534 @iter11629) ([92m↓0.78%[0m) [0.13% of initial]
[Iter 14070/20000] Loss: 0.0003087 (Best: 0.0002534 @iter11629) ([92m↓2.24%[0m) [0.12% of initial]
[Iter 14080/20000] Loss: 0.0002917 (Best: 0.0002534 @iter11629) ([92m↓5.49%[0m) [0.12% of initial]
[Iter 14090/20000] Loss: 0.0002921 (Best: 0.0002534 @iter11629) ([91m↑0.11%[0m) [0.12% of initial]
Iter:14099, L1 loss=0.0003276, Total loss=0.0002853, Time:93
[Iter 14100/20000] Loss: 0.0002865 (Best: 0.0002534 @iter11629) ([92m↓1.89%[0m) [0.11% of initial]
[Iter 14110/20000] Loss: 0.0003146 (Best: 0.0002534 @iter11629) ([91m↑9.80%[0m) [0.12% of initial]
[Iter 14120/20000] Loss: 0.0002961 (Best: 0.0002534 @iter11629) ([92m↓5.89%[0m) [0.12% of initial]
[Iter 14130/20000] Loss: 0.0003243 (Best: 0.0002534 @iter11629) ([91m↑9.51%[0m) [0.13% of initial]
[Iter 14140/20000] Loss: 0.0003099 (Best: 0.0002534 @iter11629) ([92m↓4.42%[0m) [0.12% of initial]
[Iter 14150/20000] Loss: 0.0003032 (Best: 0.0002534 @iter11629) ([92m↓2.16%[0m) [0.12% of initial]
[Iter 14160/20000] Loss: 0.0002782 (Best: 0.0002534 @iter11629) ([92m↓8.25%[0m) [0.11% of initial]
[Iter 14170/20000] Loss: 0.0003030 (Best: 0.0002534 @iter11629) ([91m↑8.89%[0m) [0.12% of initial]
[Iter 14180/20000] Loss: 0.0002897 (Best: 0.0002534 @iter11629) ([92m↓4.37%[0m) [0.12% of initial]
[Iter 14190/20000] Loss: 0.0002878 (Best: 0.0002534 @iter11629) ([92m↓0.66%[0m) [0.11% of initial]
Iter:14199, L1 loss=0.0003133, Total loss=0.000269, Time:82
[Iter 14200/20000] Loss: 0.0002769 (Best: 0.0002534 @iter11629) ([92m↓3.79%[0m) [0.11% of initial]
[Iter 14210/20000] Loss: 0.0002657 (Best: 0.0002451 @iter14206) ([92m↓4.07%[0m) [0.11% of initial]
[Iter 14220/20000] Loss: 0.0002676 (Best: 0.0002451 @iter14206) ([91m↑0.73%[0m) [0.11% of initial]
[Iter 14230/20000] Loss: 0.0003253 (Best: 0.0002451 @iter14206) ([91m↑21.55%[0m) [0.13% of initial]
[Iter 14240/20000] Loss: 0.0002840 (Best: 0.0002451 @iter14206) ([92m↓12.69%[0m) [0.11% of initial]
[Iter 14250/20000] Loss: 0.0003007 (Best: 0.0002451 @iter14206) ([91m↑5.90%[0m) [0.12% of initial]
[Iter 14260/20000] Loss: 0.0002918 (Best: 0.0002451 @iter14206) ([92m↓2.97%[0m) [0.12% of initial]
[Iter 14270/20000] Loss: 0.0003069 (Best: 0.0002451 @iter14206) ([91m↑5.16%[0m) [0.12% of initial]
[Iter 14280/20000] Loss: 0.0003008 (Best: 0.0002451 @iter14206) ([92m↓1.96%[0m) [0.12% of initial]
[Iter 14290/20000] Loss: 0.0002798 (Best: 0.0002451 @iter14206) ([92m↓6.98%[0m) [0.11% of initial]
Iter:14299, L1 loss=0.0003303, Total loss=0.0002921, Time:84
[Iter 14300/20000] Loss: 0.0002887 (Best: 0.0002451 @iter14206) ([91m↑3.16%[0m) [0.11% of initial]
[Iter 14310/20000] Loss: 0.0003068 (Best: 0.0002451 @iter14206) ([91m↑6.27%[0m) [0.12% of initial]
[Iter 14320/20000] Loss: 0.0002952 (Best: 0.0002451 @iter14206) ([92m↓3.78%[0m) [0.12% of initial]
[Iter 14330/20000] Loss: 0.0003017 (Best: 0.0002451 @iter14206) ([91m↑2.20%[0m) [0.12% of initial]
[Iter 14340/20000] Loss: 0.0003530 (Best: 0.0002451 @iter14206) ([91m↑17.02%[0m) [0.14% of initial]
[Iter 14350/20000] Loss: 0.0003279 (Best: 0.0002451 @iter14206) ([92m↓7.12%[0m) [0.13% of initial]
[Iter 14360/20000] Loss: 0.0003141 (Best: 0.0002451 @iter14206) ([92m↓4.20%[0m) [0.12% of initial]
[Iter 14370/20000] Loss: 0.0002974 (Best: 0.0002451 @iter14206) ([92m↓5.31%[0m) [0.12% of initial]
[Iter 14380/20000] Loss: 0.0003002 (Best: 0.0002451 @iter14206) ([91m↑0.92%[0m) [0.12% of initial]
[Iter 14390/20000] Loss: 0.0003115 (Best: 0.0002451 @iter14206) ([91m↑3.78%[0m) [0.12% of initial]
Iter:14399, L1 loss=0.0003005, Total loss=0.0002666, Time:105
[Iter 14400/20000] Loss: 0.0002904 (Best: 0.0002451 @iter14206) ([92m↓6.78%[0m) [0.12% of initial]
[Iter 14410/20000] Loss: 0.0002957 (Best: 0.0002451 @iter14206) ([91m↑1.81%[0m) [0.12% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 14420/20000] Loss: 0.0003820 (Best: 0.0002451 @iter14206) ([91m↑29.19%[0m) [0.15% of initial]
[Iter 14430/20000] Loss: 0.0003576 (Best: 0.0002451 @iter14206) ([92m↓6.37%[0m) [0.14% of initial]
[Iter 14440/20000] Loss: 0.0003359 (Best: 0.0002451 @iter14206) ([92m↓6.07%[0m) [0.13% of initial]
[Iter 14450/20000] Loss: 0.0003314 (Best: 0.0002451 @iter14206) ([92m↓1.35%[0m) [0.13% of initial]
[Iter 14460/20000] Loss: 0.0003332 (Best: 0.0002451 @iter14206) ([91m↑0.54%[0m) [0.13% of initial]
[Iter 14470/20000] Loss: 0.0003141 (Best: 0.0002451 @iter14206) ([92m↓5.74%[0m) [0.12% of initial]
[Iter 14480/20000] Loss: 0.0003050 (Best: 0.0002451 @iter14206) ([92m↓2.90%[0m) [0.12% of initial]
[Iter 14490/20000] Loss: 0.0003072 (Best: 0.0002451 @iter14206) ([91m↑0.73%[0m) [0.12% of initial]
Iter:14499, L1 loss=0.0003663, Total loss=0.000322, Time:89
[Iter 14500/20000] Loss: 0.0003029 (Best: 0.0002451 @iter14206) ([92m↓1.38%[0m) [0.12% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 14500
Pruning 6 points (0.0%) from gaussian1 at iteration 14500
[Iter 14510/20000] Loss: 0.0006496 (Best: 0.0002451 @iter14206) ([91m↑114.46%[0m) [0.26% of initial]
[Iter 14520/20000] Loss: 0.0005516 (Best: 0.0002451 @iter14206) ([92m↓15.09%[0m) [0.22% of initial]
[Iter 14530/20000] Loss: 0.0004287 (Best: 0.0002451 @iter14206) ([92m↓22.28%[0m) [0.17% of initial]
[Iter 14540/20000] Loss: 0.0003531 (Best: 0.0002451 @iter14206) ([92m↓17.65%[0m) [0.14% of initial]
[Iter 14550/20000] Loss: 0.0003255 (Best: 0.0002451 @iter14206) ([92m↓7.82%[0m) [0.13% of initial]
[Iter 14560/20000] Loss: 0.0002857 (Best: 0.0002451 @iter14206) ([92m↓12.22%[0m) [0.11% of initial]
[Iter 14570/20000] Loss: 0.0002761 (Best: 0.0002451 @iter14206) ([92m↓3.34%[0m) [0.11% of initial]
[Iter 14580/20000] Loss: 0.0002651 (Best: 0.0002451 @iter14206) ([92m↓4.01%[0m) [0.11% of initial]
[Iter 14590/20000] Loss: 0.0002722 (Best: 0.0002451 @iter14206) ([91m↑2.68%[0m) [0.11% of initial]
Iter:14599, L1 loss=0.0003227, Total loss=0.0002904, Time:94
[Iter 14600/20000] Loss: 0.0002894 (Best: 0.0002451 @iter14206) ([91m↑6.34%[0m) [0.11% of initial]
[Iter 14610/20000] Loss: 0.0003273 (Best: 0.0002451 @iter14206) ([91m↑13.10%[0m) [0.13% of initial]
[Iter 14620/20000] Loss: 0.0002962 (Best: 0.0002451 @iter14206) ([92m↓9.51%[0m) [0.12% of initial]
[Iter 14630/20000] Loss: 0.0002643 (Best: 0.0002451 @iter14206) ([92m↓10.79%[0m) [0.10% of initial]
[Iter 14640/20000] Loss: 0.0002820 (Best: 0.0002444 @iter14632) ([91m↑6.70%[0m) [0.11% of initial]
[Iter 14650/20000] Loss: 0.0002862 (Best: 0.0002444 @iter14632) ([91m↑1.52%[0m) [0.11% of initial]
[Iter 14660/20000] Loss: 0.0002797 (Best: 0.0002444 @iter14632) ([92m↓2.29%[0m) [0.11% of initial]
[Iter 14670/20000] Loss: 0.0002760 (Best: 0.0002444 @iter14632) ([92m↓1.31%[0m) [0.11% of initial]
[Iter 14680/20000] Loss: 0.0002726 (Best: 0.0002444 @iter14632) ([92m↓1.26%[0m) [0.11% of initial]
[Iter 14690/20000] Loss: 0.0002567 (Best: 0.0002444 @iter14632) ([92m↓5.83%[0m) [0.10% of initial]
Iter:14699, L1 loss=0.0003162, Total loss=0.0002736, Time:100
[Iter 14700/20000] Loss: 0.0002740 (Best: 0.0002444 @iter14632) ([91m↑6.76%[0m) [0.11% of initial]
[Iter 14710/20000] Loss: 0.0002647 (Best: 0.0002444 @iter14632) ([92m↓3.39%[0m) [0.11% of initial]
[Iter 14720/20000] Loss: 0.0002766 (Best: 0.0002444 @iter14632) ([91m↑4.50%[0m) [0.11% of initial]
[Iter 14730/20000] Loss: 0.0002801 (Best: 0.0002444 @iter14632) ([91m↑1.27%[0m) [0.11% of initial]
[Iter 14740/20000] Loss: 0.0002598 (Best: 0.0002444 @iter14632) ([92m↓7.28%[0m) [0.10% of initial]
[Iter 14750/20000] Loss: 0.0002609 (Best: 0.0002444 @iter14632) ([91m↑0.42%[0m) [0.10% of initial]
[Iter 14760/20000] Loss: 0.0002889 (Best: 0.0002431 @iter14752) ([91m↑10.74%[0m) [0.11% of initial]
[Iter 14770/20000] Loss: 0.0003676 (Best: 0.0002431 @iter14752) ([91m↑27.25%[0m) [0.15% of initial]
[Iter 14780/20000] Loss: 0.0003663 (Best: 0.0002431 @iter14752) ([92m↓0.34%[0m) [0.15% of initial]
[Iter 14790/20000] Loss: 0.0003676 (Best: 0.0002431 @iter14752) ([91m↑0.33%[0m) [0.15% of initial]
Iter:14799, L1 loss=0.0004493, Total loss=0.0003876, Time:103
[Iter 14800/20000] Loss: 0.0003430 (Best: 0.0002431 @iter14752) ([92m↓6.68%[0m) [0.14% of initial]
[Iter 14810/20000] Loss: 0.0003091 (Best: 0.0002431 @iter14752) ([92m↓9.89%[0m) [0.12% of initial]
[Iter 14820/20000] Loss: 0.0002868 (Best: 0.0002431 @iter14752) ([92m↓7.20%[0m) [0.11% of initial]
[Iter 14830/20000] Loss: 0.0002741 (Best: 0.0002431 @iter14752) ([92m↓4.42%[0m) [0.11% of initial]
[Iter 14840/20000] Loss: 0.0002739 (Best: 0.0002431 @iter14752) ([92m↓0.08%[0m) [0.11% of initial]
[Iter 14850/20000] Loss: 0.0002841 (Best: 0.0002431 @iter14752) ([91m↑3.71%[0m) [0.11% of initial]
[Iter 14860/20000] Loss: 0.0002879 (Best: 0.0002431 @iter14752) ([91m↑1.35%[0m) [0.11% of initial]
[Iter 14870/20000] Loss: 0.0002736 (Best: 0.0002431 @iter14752) ([92m↓4.99%[0m) [0.11% of initial]
[Iter 14880/20000] Loss: 0.0002650 (Best: 0.0002431 @iter14752) ([92m↓3.13%[0m) [0.11% of initial]
[Iter 14890/20000] Loss: 0.0002590 (Best: 0.0002359 @iter14884) ([92m↓2.25%[0m) [0.10% of initial]
Iter:14899, L1 loss=0.0003078, Total loss=0.0002494, Time:100
[Iter 14900/20000] Loss: 0.0002511 (Best: 0.0002359 @iter14884) ([92m↓3.06%[0m) [0.10% of initial]
[Iter 14910/20000] Loss: 0.0002608 (Best: 0.0002344 @iter14905) ([91m↑3.87%[0m) [0.10% of initial]
[Iter 14920/20000] Loss: 0.0002693 (Best: 0.0002344 @iter14905) ([91m↑3.26%[0m) [0.11% of initial]
[Iter 14930/20000] Loss: 0.0002632 (Best: 0.0002344 @iter14905) ([92m↓2.28%[0m) [0.10% of initial]
[Iter 14940/20000] Loss: 0.0002532 (Best: 0.0002344 @iter14905) ([92m↓3.78%[0m) [0.10% of initial]
[Iter 14950/20000] Loss: 0.0002677 (Best: 0.0002344 @iter14905) ([91m↑5.74%[0m) [0.11% of initial]
[Iter 14960/20000] Loss: 0.0002593 (Best: 0.0002344 @iter14905) ([92m↓3.13%[0m) [0.10% of initial]
[Iter 14970/20000] Loss: 0.0003319 (Best: 0.0002344 @iter14905) ([91m↑27.98%[0m) [0.13% of initial]
[Iter 14980/20000] Loss: 0.0003143 (Best: 0.0002344 @iter14905) ([92m↓5.30%[0m) [0.12% of initial]
[Iter 14990/20000] Loss: 0.0003915 (Best: 0.0002344 @iter14905) ([91m↑24.57%[0m) [0.16% of initial]
Iter:14999, L1 loss=0.0003794, Total loss=0.0003893, Time:100
[Iter 15000/20000] Loss: 0.0004511 (Best: 0.0002344 @iter14905) ([91m↑15.22%[0m) [0.18% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 15000
Pruning 6 points (0.0%) from gaussian1 at iteration 15000
[Iter 15010/20000] Loss: 0.0004900 (Best: 0.0002344 @iter14905) ([91m↑8.60%[0m) [0.19% of initial]
[Iter 15020/20000] Loss: 0.0004113 (Best: 0.0002344 @iter14905) ([92m↓16.05%[0m) [0.16% of initial]
[Iter 15030/20000] Loss: 0.0003217 (Best: 0.0002344 @iter14905) ([92m↓21.78%[0m) [0.13% of initial]
[Iter 15040/20000] Loss: 0.0002891 (Best: 0.0002344 @iter14905) ([92m↓10.13%[0m) [0.11% of initial]
[Iter 15050/20000] Loss: 0.0002677 (Best: 0.0002344 @iter14905) ([92m↓7.40%[0m) [0.11% of initial]
[Iter 15060/20000] Loss: 0.0002871 (Best: 0.0002344 @iter14905) ([91m↑7.22%[0m) [0.11% of initial]
[Iter 15070/20000] Loss: 0.0002642 (Best: 0.0002344 @iter14905) ([92m↓7.96%[0m) [0.10% of initial]
[Iter 15080/20000] Loss: 0.0002556 (Best: 0.0002344 @iter14905) ([92m↓3.28%[0m) [0.10% of initial]
[Iter 15090/20000] Loss: 0.0002542 (Best: 0.0002344 @iter14905) ([92m↓0.52%[0m) [0.10% of initial]
Iter:15099, L1 loss=0.0002893, Total loss=0.0002425, Time:94
[Iter 15100/20000] Loss: 0.0002414 (Best: 0.0002344 @iter14905) ([92m↓5.04%[0m) [0.10% of initial]
[Iter 15110/20000] Loss: 0.0002647 (Best: 0.0002315 @iter15101) ([91m↑9.64%[0m) [0.11% of initial]
[Iter 15120/20000] Loss: 0.0002760 (Best: 0.0002315 @iter15101) ([91m↑4.28%[0m) [0.11% of initial]
[Iter 15130/20000] Loss: 0.0002885 (Best: 0.0002315 @iter15101) ([91m↑4.55%[0m) [0.11% of initial]
[Iter 15140/20000] Loss: 0.0002658 (Best: 0.0002315 @iter15101) ([92m↓7.90%[0m) [0.11% of initial]
[Iter 15150/20000] Loss: 0.0003023 (Best: 0.0002315 @iter15101) ([91m↑13.76%[0m) [0.12% of initial]
[Iter 15160/20000] Loss: 0.0002750 (Best: 0.0002315 @iter15101) ([92m↓9.05%[0m) [0.11% of initial]
[Iter 15170/20000] Loss: 0.0002708 (Best: 0.0002315 @iter15101) ([92m↓1.52%[0m) [0.11% of initial]
[Iter 15180/20000] Loss: 0.0002911 (Best: 0.0002315 @iter15101) ([91m↑7.49%[0m) [0.12% of initial]
[Iter 15190/20000] Loss: 0.0002685 (Best: 0.0002315 @iter15101) ([92m↓7.78%[0m) [0.11% of initial]
Iter:15199, L1 loss=0.0003125, Total loss=0.0002868, Time:85
[Iter 15200/20000] Loss: 0.0002762 (Best: 0.0002315 @iter15101) ([91m↑2.88%[0m) [0.11% of initial]
[Iter 15210/20000] Loss: 0.0003441 (Best: 0.0002315 @iter15101) ([91m↑24.61%[0m) [0.14% of initial]
[Iter 15220/20000] Loss: 0.0003377 (Best: 0.0002315 @iter15101) ([92m↓1.86%[0m) [0.13% of initial]
[Iter 15230/20000] Loss: 0.0002849 (Best: 0.0002315 @iter15101) ([92m↓15.64%[0m) [0.11% of initial]
[Iter 15240/20000] Loss: 0.0002764 (Best: 0.0002315 @iter15101) ([92m↓2.99%[0m) [0.11% of initial]
[Iter 15250/20000] Loss: 0.0002569 (Best: 0.0002315 @iter15101) ([92m↓7.05%[0m) [0.10% of initial]
[Iter 15260/20000] Loss: 0.0002725 (Best: 0.0002315 @iter15101) ([91m↑6.08%[0m) [0.11% of initial]
[Iter 15270/20000] Loss: 0.0002673 (Best: 0.0002315 @iter15101) ([92m↓1.91%[0m) [0.11% of initial]
[Iter 15280/20000] Loss: 0.0002611 (Best: 0.0002315 @iter15101) ([92m↓2.34%[0m) [0.10% of initial]
[Iter 15290/20000] Loss: 0.0002748 (Best: 0.0002315 @iter15101) ([91m↑5.27%[0m) [0.11% of initial]
Iter:15299, L1 loss=0.0003383, Total loss=0.0002886, Time:90
[Iter 15300/20000] Loss: 0.0002898 (Best: 0.0002315 @iter15101) ([91m↑5.45%[0m) [0.12% of initial]
[Iter 15310/20000] Loss: 0.0003010 (Best: 0.0002315 @iter15101) ([91m↑3.84%[0m) [0.12% of initial]
[Iter 15320/20000] Loss: 0.0002940 (Best: 0.0002315 @iter15101) ([92m↓2.32%[0m) [0.12% of initial]
[Iter 15330/20000] Loss: 0.0002949 (Best: 0.0002315 @iter15101) ([91m↑0.32%[0m) [0.12% of initial]
[Iter 15340/20000] Loss: 0.0002819 (Best: 0.0002315 @iter15101) ([92m↓4.43%[0m) [0.11% of initial]
[Iter 15350/20000] Loss: 0.0002787 (Best: 0.0002315 @iter15101) ([92m↓1.11%[0m) [0.11% of initial]
[Iter 15360/20000] Loss: 0.0003138 (Best: 0.0002315 @iter15101) ([91m↑12.60%[0m) [0.12% of initial]
[Iter 15370/20000] Loss: 0.0002982 (Best: 0.0002315 @iter15101) ([92m↓4.97%[0m) [0.12% of initial]
[Iter 15380/20000] Loss: 0.0002928 (Best: 0.0002315 @iter15101) ([92m↓1.82%[0m) [0.12% of initial]
[Iter 15390/20000] Loss: 0.0002735 (Best: 0.0002315 @iter15101) ([92m↓6.57%[0m) [0.11% of initial]
Iter:15399, L1 loss=0.0002847, Total loss=0.0002407, Time:102
[Iter 15400/20000] Loss: 0.0002457 (Best: 0.0002315 @iter15101) ([92m↓10.18%[0m) [0.10% of initial]
[Iter 15410/20000] Loss: 0.0002447 (Best: 0.0002306 @iter15409) ([92m↓0.40%[0m) [0.10% of initial]
[Iter 15420/20000] Loss: 0.0002464 (Best: 0.0002239 @iter15415) ([91m↑0.68%[0m) [0.10% of initial]
[Iter 15430/20000] Loss: 0.0002420 (Best: 0.0002239 @iter15415) ([92m↓1.78%[0m) [0.10% of initial]
[Iter 15440/20000] Loss: 0.0002519 (Best: 0.0002239 @iter15415) ([91m↑4.10%[0m) [0.10% of initial]
[Iter 15450/20000] Loss: 0.0002727 (Best: 0.0002239 @iter15415) ([91m↑8.26%[0m) [0.11% of initial]
[Iter 15460/20000] Loss: 0.0003046 (Best: 0.0002239 @iter15415) ([91m↑11.70%[0m) [0.12% of initial]
[Iter 15470/20000] Loss: 0.0003322 (Best: 0.0002239 @iter15415) ([91m↑9.06%[0m) [0.13% of initial]
[Iter 15480/20000] Loss: 0.0003082 (Best: 0.0002239 @iter15415) ([92m↓7.22%[0m) [0.12% of initial]
[Iter 15490/20000] Loss: 0.0002642 (Best: 0.0002239 @iter15415) ([92m↓14.28%[0m) [0.10% of initial]
Iter:15499, L1 loss=0.0003034, Total loss=0.0002625, Time:100
[Iter 15500/20000] Loss: 0.0002702 (Best: 0.0002239 @iter15415) ([91m↑2.26%[0m) [0.11% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 15500
Pruning 4 points (0.0%) from gaussian1 at iteration 15500
[Iter 15510/20000] Loss: 0.0006185 (Best: 0.0002239 @iter15415) ([91m↑128.95%[0m) [0.25% of initial]
[Iter 15520/20000] Loss: 0.0004289 (Best: 0.0002239 @iter15415) ([92m↓30.67%[0m) [0.17% of initial]
[Iter 15530/20000] Loss: 0.0003563 (Best: 0.0002239 @iter15415) ([92m↓16.92%[0m) [0.14% of initial]
[Iter 15540/20000] Loss: 0.0002863 (Best: 0.0002239 @iter15415) ([92m↓19.66%[0m) [0.11% of initial]
[Iter 15550/20000] Loss: 0.0002668 (Best: 0.0002239 @iter15415) ([92m↓6.80%[0m) [0.11% of initial]
[Iter 15560/20000] Loss: 0.0002737 (Best: 0.0002239 @iter15415) ([91m↑2.58%[0m) [0.11% of initial]
[Iter 15570/20000] Loss: 0.0003032 (Best: 0.0002239 @iter15415) ([91m↑10.78%[0m) [0.12% of initial]
[Iter 15580/20000] Loss: 0.0002693 (Best: 0.0002239 @iter15415) ([92m↓11.20%[0m) [0.11% of initial]
[Iter 15590/20000] Loss: 0.0002521 (Best: 0.0002239 @iter15415) ([92m↓6.36%[0m) [0.10% of initial]
Iter:15599, L1 loss=0.000285, Total loss=0.0002413, Time:99
[Iter 15600/20000] Loss: 0.0002501 (Best: 0.0002239 @iter15415) ([92m↓0.80%[0m) [0.10% of initial]
[Iter 15610/20000] Loss: 0.0002512 (Best: 0.0002239 @iter15415) ([91m↑0.45%[0m) [0.10% of initial]
[Iter 15620/20000] Loss: 0.0002379 (Best: 0.0002239 @iter15415) ([92m↓5.29%[0m) [0.09% of initial]
[Iter 15630/20000] Loss: 0.0002659 (Best: 0.0002239 @iter15415) ([91m↑11.76%[0m) [0.11% of initial]
[Iter 15640/20000] Loss: 0.0002589 (Best: 0.0002239 @iter15415) ([92m↓2.66%[0m) [0.10% of initial]
[Iter 15650/20000] Loss: 0.0002975 (Best: 0.0002239 @iter15415) ([91m↑14.94%[0m) [0.12% of initial]
[Iter 15660/20000] Loss: 0.0002675 (Best: 0.0002239 @iter15415) ([92m↓10.09%[0m) [0.11% of initial]
[Iter 15670/20000] Loss: 0.0002761 (Best: 0.0002239 @iter15415) ([91m↑3.22%[0m) [0.11% of initial]
[Iter 15680/20000] Loss: 0.0003506 (Best: 0.0002239 @iter15415) ([91m↑26.97%[0m) [0.14% of initial]
[Iter 15690/20000] Loss: 0.0003084 (Best: 0.0002239 @iter15415) ([92m↓12.04%[0m) [0.12% of initial]
Iter:15699, L1 loss=0.000325, Total loss=0.000263, Time:95
[Iter 15700/20000] Loss: 0.0002662 (Best: 0.0002239 @iter15415) ([92m↓13.68%[0m) [0.11% of initial]
[Iter 15710/20000] Loss: 0.0002399 (Best: 0.0002239 @iter15415) ([92m↓9.88%[0m) [0.10% of initial]
[Iter 15720/20000] Loss: 0.0002573 (Best: 0.0002239 @iter15415) ([91m↑7.26%[0m) [0.10% of initial]
[Iter 15730/20000] Loss: 0.0002705 (Best: 0.0002239 @iter15415) ([91m↑5.13%[0m) [0.11% of initial]
[Iter 15740/20000] Loss: 0.0002573 (Best: 0.0002239 @iter15415) ([92m↓4.89%[0m) [0.10% of initial]
[Iter 15750/20000] Loss: 0.0002710 (Best: 0.0002239 @iter15415) ([91m↑5.35%[0m) [0.11% of initial]
[Iter 15760/20000] Loss: 0.0002941 (Best: 0.0002239 @iter15415) ([91m↑8.51%[0m) [0.12% of initial]
[Iter 15770/20000] Loss: 0.0003210 (Best: 0.0002239 @iter15415) ([91m↑9.16%[0m) [0.13% of initial]
[Iter 15780/20000] Loss: 0.0002765 (Best: 0.0002239 @iter15415) ([92m↓13.88%[0m) [0.11% of initial]
[Iter 15790/20000] Loss: 0.0002599 (Best: 0.0002239 @iter15415) ([92m↓5.99%[0m) [0.10% of initial]
Iter:15799, L1 loss=0.0002718, Total loss=0.0002354, Time:95
[Iter 15800/20000] Loss: 0.0002515 (Best: 0.0002239 @iter15415) ([92m↓3.25%[0m) [0.10% of initial]
[Iter 15810/20000] Loss: 0.0002868 (Best: 0.0002239 @iter15415) ([91m↑14.04%[0m) [0.11% of initial]
[Iter 15820/20000] Loss: 0.0002925 (Best: 0.0002239 @iter15415) ([91m↑1.98%[0m) [0.12% of initial]
[Iter 15830/20000] Loss: 0.0003060 (Best: 0.0002239 @iter15415) ([91m↑4.63%[0m) [0.12% of initial]
[Iter 15840/20000] Loss: 0.0002826 (Best: 0.0002239 @iter15415) ([92m↓7.66%[0m) [0.11% of initial]
[Iter 15850/20000] Loss: 0.0002718 (Best: 0.0002239 @iter15415) ([92m↓3.81%[0m) [0.11% of initial]
[Iter 15860/20000] Loss: 0.0002726 (Best: 0.0002239 @iter15415) ([91m↑0.30%[0m) [0.11% of initial]
[Iter 15870/20000] Loss: 0.0002762 (Best: 0.0002239 @iter15415) ([91m↑1.31%[0m) [0.11% of initial]
[Iter 15880/20000] Loss: 0.0002665 (Best: 0.0002239 @iter15415) ([92m↓3.51%[0m) [0.11% of initial]
[Iter 15890/20000] Loss: 0.0002543 (Best: 0.0002239 @iter15415) ([92m↓4.58%[0m) [0.10% of initial]
Iter:15899, L1 loss=0.0002748, Total loss=0.0002253, Time:86
[Iter 15900/20000] Loss: 0.0002343 (Best: 0.0002239 @iter15415) ([92m↓7.84%[0m) [0.09% of initial]
[Iter 15910/20000] Loss: 0.0002357 (Best: 0.0002164 @iter15902) ([91m↑0.58%[0m) [0.09% of initial]
[Iter 15920/20000] Loss: 0.0002432 (Best: 0.0002164 @iter15902) ([91m↑3.16%[0m) [0.10% of initial]
[Iter 15930/20000] Loss: 0.0002376 (Best: 0.0002164 @iter15902) ([92m↓2.28%[0m) [0.09% of initial]
[Iter 15940/20000] Loss: 0.0002272 (Best: 0.0002155 @iter15940) ([92m↓4.38%[0m) [0.09% of initial]
[Iter 15950/20000] Loss: 0.0002806 (Best: 0.0002155 @iter15940) ([91m↑23.51%[0m) [0.11% of initial]
[Iter 15960/20000] Loss: 0.0002478 (Best: 0.0002155 @iter15940) ([92m↓11.70%[0m) [0.10% of initial]
[Iter 15970/20000] Loss: 0.0002432 (Best: 0.0002155 @iter15940) ([92m↓1.86%[0m) [0.10% of initial]
[Iter 15980/20000] Loss: 0.0002404 (Best: 0.0002155 @iter15940) ([92m↓1.16%[0m) [0.10% of initial]
[Iter 15990/20000] Loss: 0.0002584 (Best: 0.0002155 @iter15940) ([91m↑7.51%[0m) [0.10% of initial]
Iter:15999, L1 loss=0.0002879, Total loss=0.0002607, Time:77
[Iter 16000/20000] Loss: 0.0002755 (Best: 0.0002155 @iter15940) ([91m↑6.60%[0m) [0.11% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 16000
Pruning 4 points (0.0%) from gaussian1 at iteration 16000
[Iter 16010/20000] Loss: 0.0129956 (Best: 0.0002155 @iter15940) ([91m↑4617.43%[0m) [5.16% of initial]
[Iter 16020/20000] Loss: 0.0051516 (Best: 0.0002155 @iter15940) ([92m↓60.36%[0m) [2.05% of initial]
[Iter 16030/20000] Loss: 0.0026676 (Best: 0.0002155 @iter15940) ([92m↓48.22%[0m) [1.06% of initial]
[Iter 16040/20000] Loss: 0.0017120 (Best: 0.0002155 @iter15940) ([92m↓35.82%[0m) [0.68% of initial]
[Iter 16050/20000] Loss: 0.0011212 (Best: 0.0002155 @iter15940) ([92m↓34.51%[0m) [0.45% of initial]
[Iter 16060/20000] Loss: 0.0008612 (Best: 0.0002155 @iter15940) ([92m↓23.19%[0m) [0.34% of initial]
[Iter 16070/20000] Loss: 0.0006909 (Best: 0.0002155 @iter15940) ([92m↓19.78%[0m) [0.27% of initial]
[Iter 16080/20000] Loss: 0.0006111 (Best: 0.0002155 @iter15940) ([92m↓11.56%[0m) [0.24% of initial]
[Iter 16090/20000] Loss: 0.0005262 (Best: 0.0002155 @iter15940) ([92m↓13.89%[0m) [0.21% of initial]
Iter:16099, L1 loss=0.0004753, Total loss=0.0004401, Time:102
[Iter 16100/20000] Loss: 0.0004665 (Best: 0.0002155 @iter15940) ([92m↓11.34%[0m) [0.19% of initial]
[Iter 16110/20000] Loss: 0.0004452 (Best: 0.0002155 @iter15940) ([92m↓4.58%[0m) [0.18% of initial]
[Iter 16120/20000] Loss: 0.0004135 (Best: 0.0002155 @iter15940) ([92m↓7.11%[0m) [0.16% of initial]
[Iter 16130/20000] Loss: 0.0003931 (Best: 0.0002155 @iter15940) ([92m↓4.94%[0m) [0.16% of initial]
[Iter 16140/20000] Loss: 0.0003695 (Best: 0.0002155 @iter15940) ([92m↓6.00%[0m) [0.15% of initial]
[Iter 16150/20000] Loss: 0.0003529 (Best: 0.0002155 @iter15940) ([92m↓4.48%[0m) [0.14% of initial]
[Iter 16160/20000] Loss: 0.0003548 (Best: 0.0002155 @iter15940) ([91m↑0.53%[0m) [0.14% of initial]
[Iter 16170/20000] Loss: 0.0003458 (Best: 0.0002155 @iter15940) ([92m↓2.55%[0m) [0.14% of initial]
[Iter 16180/20000] Loss: 0.0003375 (Best: 0.0002155 @iter15940) ([92m↓2.40%[0m) [0.13% of initial]
[Iter 16190/20000] Loss: 0.0003294 (Best: 0.0002155 @iter15940) ([92m↓2.38%[0m) [0.13% of initial]
Iter:16199, L1 loss=0.0003581, Total loss=0.0003305, Time:97
[Iter 16200/20000] Loss: 0.0003355 (Best: 0.0002155 @iter15940) ([91m↑1.86%[0m) [0.13% of initial]
[Iter 16210/20000] Loss: 0.0003405 (Best: 0.0002155 @iter15940) ([91m↑1.47%[0m) [0.14% of initial]
[Iter 16220/20000] Loss: 0.0003308 (Best: 0.0002155 @iter15940) ([92m↓2.85%[0m) [0.13% of initial]
[Iter 16230/20000] Loss: 0.0003307 (Best: 0.0002155 @iter15940) ([92m↓0.01%[0m) [0.13% of initial]
[Iter 16240/20000] Loss: 0.0003575 (Best: 0.0002155 @iter15940) ([91m↑8.10%[0m) [0.14% of initial]
[Iter 16250/20000] Loss: 0.0003221 (Best: 0.0002155 @iter15940) ([92m↓9.92%[0m) [0.13% of initial]
[Iter 16260/20000] Loss: 0.0003075 (Best: 0.0002155 @iter15940) ([92m↓4.51%[0m) [0.12% of initial]
[Iter 16270/20000] Loss: 0.0002964 (Best: 0.0002155 @iter15940) ([92m↓3.62%[0m) [0.12% of initial]
[Iter 16280/20000] Loss: 0.0002907 (Best: 0.0002155 @iter15940) ([92m↓1.91%[0m) [0.12% of initial]
[Iter 16290/20000] Loss: 0.0002990 (Best: 0.0002155 @iter15940) ([91m↑2.84%[0m) [0.12% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
Iter:16299, L1 loss=0.0003662, Total loss=0.0003405, Time:83
[Iter 16300/20000] Loss: 0.0002998 (Best: 0.0002155 @iter15940) ([91m↑0.26%[0m) [0.12% of initial]
[Iter 16310/20000] Loss: 0.0003507 (Best: 0.0002155 @iter15940) ([91m↑16.97%[0m) [0.14% of initial]
[Iter 16320/20000] Loss: 0.0003385 (Best: 0.0002155 @iter15940) ([92m↓3.46%[0m) [0.13% of initial]
[Iter 16330/20000] Loss: 0.0003319 (Best: 0.0002155 @iter15940) ([92m↓1.98%[0m) [0.13% of initial]
[Iter 16340/20000] Loss: 0.0002977 (Best: 0.0002155 @iter15940) ([92m↓10.30%[0m) [0.12% of initial]
[Iter 16350/20000] Loss: 0.0003072 (Best: 0.0002155 @iter15940) ([91m↑3.20%[0m) [0.12% of initial]
[Iter 16360/20000] Loss: 0.0003044 (Best: 0.0002155 @iter15940) ([92m↓0.90%[0m) [0.12% of initial]
[Iter 16370/20000] Loss: 0.0003352 (Best: 0.0002155 @iter15940) ([91m↑10.11%[0m) [0.13% of initial]
[Iter 16380/20000] Loss: 0.0003354 (Best: 0.0002155 @iter15940) ([91m↑0.05%[0m) [0.13% of initial]
[Iter 16390/20000] Loss: 0.0003313 (Best: 0.0002155 @iter15940) ([92m↓1.23%[0m) [0.13% of initial]
Iter:16399, L1 loss=0.0003252, Total loss=0.0002938, Time:122
[Iter 16400/20000] Loss: 0.0003166 (Best: 0.0002155 @iter15940) ([92m↓4.41%[0m) [0.13% of initial]
[Iter 16410/20000] Loss: 0.0003094 (Best: 0.0002155 @iter15940) ([92m↓2.29%[0m) [0.12% of initial]
[Iter 16420/20000] Loss: 0.0002901 (Best: 0.0002155 @iter15940) ([92m↓6.23%[0m) [0.12% of initial]
[Iter 16430/20000] Loss: 0.0002884 (Best: 0.0002155 @iter15940) ([92m↓0.58%[0m) [0.11% of initial]
[Iter 16440/20000] Loss: 0.0002910 (Best: 0.0002155 @iter15940) ([91m↑0.88%[0m) [0.12% of initial]
[Iter 16450/20000] Loss: 0.0002949 (Best: 0.0002155 @iter15940) ([91m↑1.36%[0m) [0.12% of initial]
[Iter 16460/20000] Loss: 0.0002874 (Best: 0.0002155 @iter15940) ([92m↓2.57%[0m) [0.11% of initial]
[Iter 16470/20000] Loss: 0.0003027 (Best: 0.0002155 @iter15940) ([91m↑5.34%[0m) [0.12% of initial]
[Iter 16480/20000] Loss: 0.0002900 (Best: 0.0002155 @iter15940) ([92m↓4.21%[0m) [0.12% of initial]
[Iter 16490/20000] Loss: 0.0002877 (Best: 0.0002155 @iter15940) ([92m↓0.77%[0m) [0.11% of initial]
Iter:16499, L1 loss=0.0003689, Total loss=0.0003029, Time:82
[Iter 16500/20000] Loss: 0.0003256 (Best: 0.0002155 @iter15940) ([91m↑13.18%[0m) [0.13% of initial]
Pruning 14 points (0.0%) from gaussian0 at iteration 16500
Pruning 7 points (0.0%) from gaussian1 at iteration 16500
[Iter 16510/20000] Loss: 0.0005363 (Best: 0.0002155 @iter15940) ([91m↑64.69%[0m) [0.21% of initial]
[Iter 16520/20000] Loss: 0.0004227 (Best: 0.0002155 @iter15940) ([92m↓21.18%[0m) [0.17% of initial]
[Iter 16530/20000] Loss: 0.0003585 (Best: 0.0002155 @iter15940) ([92m↓15.19%[0m) [0.14% of initial]
[Iter 16540/20000] Loss: 0.0003271 (Best: 0.0002155 @iter15940) ([92m↓8.75%[0m) [0.13% of initial]
[Iter 16550/20000] Loss: 0.0003003 (Best: 0.0002155 @iter15940) ([92m↓8.19%[0m) [0.12% of initial]
[Iter 16560/20000] Loss: 0.0002986 (Best: 0.0002155 @iter15940) ([92m↓0.58%[0m) [0.12% of initial]
[Iter 16570/20000] Loss: 0.0002861 (Best: 0.0002155 @iter15940) ([92m↓4.19%[0m) [0.11% of initial]
[Iter 16580/20000] Loss: 0.0002832 (Best: 0.0002155 @iter15940) ([92m↓1.02%[0m) [0.11% of initial]
[Iter 16590/20000] Loss: 0.0002928 (Best: 0.0002155 @iter15940) ([91m↑3.38%[0m) [0.12% of initial]
Iter:16599, L1 loss=0.0003315, Total loss=0.0002984, Time:74
[Iter 16600/20000] Loss: 0.0002859 (Best: 0.0002155 @iter15940) ([92m↓2.35%[0m) [0.11% of initial]
[Iter 16610/20000] Loss: 0.0002845 (Best: 0.0002155 @iter15940) ([92m↓0.48%[0m) [0.11% of initial]
[Iter 16620/20000] Loss: 0.0002896 (Best: 0.0002155 @iter15940) ([91m↑1.81%[0m) [0.12% of initial]
[Iter 16630/20000] Loss: 0.0003063 (Best: 0.0002155 @iter15940) ([91m↑5.74%[0m) [0.12% of initial]
[Iter 16640/20000] Loss: 0.0003303 (Best: 0.0002155 @iter15940) ([91m↑7.84%[0m) [0.13% of initial]
[Iter 16650/20000] Loss: 0.0003743 (Best: 0.0002155 @iter15940) ([91m↑13.31%[0m) [0.15% of initial]
[Iter 16660/20000] Loss: 0.0003892 (Best: 0.0002155 @iter15940) ([91m↑3.98%[0m) [0.15% of initial]
[Iter 16670/20000] Loss: 0.0003584 (Best: 0.0002155 @iter15940) ([92m↓7.90%[0m) [0.14% of initial]
[Iter 16680/20000] Loss: 0.0003176 (Best: 0.0002155 @iter15940) ([92m↓11.37%[0m) [0.13% of initial]
[Iter 16690/20000] Loss: 0.0002912 (Best: 0.0002155 @iter15940) ([92m↓8.32%[0m) [0.12% of initial]
Iter:16699, L1 loss=0.0003502, Total loss=0.0003084, Time:74
[Iter 16700/20000] Loss: 0.0002984 (Best: 0.0002155 @iter15940) ([91m↑2.46%[0m) [0.12% of initial]
[Iter 16710/20000] Loss: 0.0002973 (Best: 0.0002155 @iter15940) ([92m↓0.35%[0m) [0.12% of initial]
[Iter 16720/20000] Loss: 0.0003165 (Best: 0.0002155 @iter15940) ([91m↑6.44%[0m) [0.13% of initial]
[Iter 16730/20000] Loss: 0.0002982 (Best: 0.0002155 @iter15940) ([92m↓5.78%[0m) [0.12% of initial]
[Iter 16740/20000] Loss: 0.0003108 (Best: 0.0002155 @iter15940) ([91m↑4.25%[0m) [0.12% of initial]
[Iter 16750/20000] Loss: 0.0003010 (Best: 0.0002155 @iter15940) ([92m↓3.18%[0m) [0.12% of initial]
[Iter 16760/20000] Loss: 0.0002888 (Best: 0.0002155 @iter15940) ([92m↓4.03%[0m) [0.11% of initial]
[Iter 16770/20000] Loss: 0.0002899 (Best: 0.0002155 @iter15940) ([91m↑0.37%[0m) [0.12% of initial]
[Iter 16780/20000] Loss: 0.0002880 (Best: 0.0002155 @iter15940) ([92m↓0.66%[0m) [0.11% of initial]
[Iter 16790/20000] Loss: 0.0003056 (Best: 0.0002155 @iter15940) ([91m↑6.12%[0m) [0.12% of initial]
Iter:16799, L1 loss=0.0003619, Total loss=0.0003176, Time:96
[Iter 16800/20000] Loss: 0.0003129 (Best: 0.0002155 @iter15940) ([91m↑2.40%[0m) [0.12% of initial]
[Iter 16810/20000] Loss: 0.0003615 (Best: 0.0002155 @iter15940) ([91m↑15.53%[0m) [0.14% of initial]
[Iter 16820/20000] Loss: 0.0003435 (Best: 0.0002155 @iter15940) ([92m↓4.98%[0m) [0.14% of initial]
[Iter 16830/20000] Loss: 0.0003480 (Best: 0.0002155 @iter15940) ([91m↑1.30%[0m) [0.14% of initial]
[Iter 16840/20000] Loss: 0.0004365 (Best: 0.0002155 @iter15940) ([91m↑25.43%[0m) [0.17% of initial]
[Iter 16850/20000] Loss: 0.0003566 (Best: 0.0002155 @iter15940) ([92m↓18.32%[0m) [0.14% of initial]
[Iter 16860/20000] Loss: 0.0003291 (Best: 0.0002155 @iter15940) ([92m↓7.71%[0m) [0.13% of initial]
[Iter 16870/20000] Loss: 0.0003011 (Best: 0.0002155 @iter15940) ([92m↓8.51%[0m) [0.12% of initial]
[Iter 16880/20000] Loss: 0.0002868 (Best: 0.0002155 @iter15940) ([92m↓4.74%[0m) [0.11% of initial]
[Iter 16890/20000] Loss: 0.0003179 (Best: 0.0002155 @iter15940) ([91m↑10.86%[0m) [0.13% of initial]
Iter:16899, L1 loss=0.0003739, Total loss=0.0003331, Time:78
[Iter 16900/20000] Loss: 0.0003017 (Best: 0.0002155 @iter15940) ([92m↓5.10%[0m) [0.12% of initial]
[Iter 16910/20000] Loss: 0.0002844 (Best: 0.0002155 @iter15940) ([92m↓5.72%[0m) [0.11% of initial]
[Iter 16920/20000] Loss: 0.0003385 (Best: 0.0002155 @iter15940) ([91m↑19.01%[0m) [0.13% of initial]
[Iter 16930/20000] Loss: 0.0003141 (Best: 0.0002155 @iter15940) ([92m↓7.23%[0m) [0.12% of initial]
[Iter 16940/20000] Loss: 0.0003551 (Best: 0.0002155 @iter15940) ([91m↑13.07%[0m) [0.14% of initial]
[Iter 16950/20000] Loss: 0.0003426 (Best: 0.0002155 @iter15940) ([92m↓3.51%[0m) [0.14% of initial]
[Iter 16960/20000] Loss: 0.0003551 (Best: 0.0002155 @iter15940) ([91m↑3.63%[0m) [0.14% of initial]
[Iter 16970/20000] Loss: 0.0003324 (Best: 0.0002155 @iter15940) ([92m↓6.39%[0m) [0.13% of initial]
[Iter 16980/20000] Loss: 0.0003059 (Best: 0.0002155 @iter15940) ([92m↓7.98%[0m) [0.12% of initial]
[Iter 16990/20000] Loss: 0.0003115 (Best: 0.0002155 @iter15940) ([91m↑1.83%[0m) [0.12% of initial]
Iter:16999, L1 loss=0.0003367, Total loss=0.0003016, Time:92
[Iter 17000/20000] Loss: 0.0003009 (Best: 0.0002155 @iter15940) ([92m↓3.41%[0m) [0.12% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 17000
Pruning 10 points (0.0%) from gaussian1 at iteration 17000
[Iter 17010/20000] Loss: 0.0005605 (Best: 0.0002155 @iter15940) ([91m↑86.29%[0m) [0.22% of initial]
[Iter 17020/20000] Loss: 0.0003956 (Best: 0.0002155 @iter15940) ([92m↓29.42%[0m) [0.16% of initial]
[Iter 17030/20000] Loss: 0.0003334 (Best: 0.0002155 @iter15940) ([92m↓15.73%[0m) [0.13% of initial]
[Iter 17040/20000] Loss: 0.0002988 (Best: 0.0002155 @iter15940) ([92m↓10.37%[0m) [0.12% of initial]
[Iter 17050/20000] Loss: 0.0002882 (Best: 0.0002155 @iter15940) ([92m↓3.55%[0m) [0.11% of initial]
[Iter 17060/20000] Loss: 0.0003038 (Best: 0.0002155 @iter15940) ([91m↑5.42%[0m) [0.12% of initial]
[Iter 17070/20000] Loss: 0.0003051 (Best: 0.0002155 @iter15940) ([91m↑0.43%[0m) [0.12% of initial]
[Iter 17080/20000] Loss: 0.0002791 (Best: 0.0002155 @iter15940) ([92m↓8.52%[0m) [0.11% of initial]
[Iter 17090/20000] Loss: 0.0002674 (Best: 0.0002155 @iter15940) ([92m↓4.22%[0m) [0.11% of initial]
Iter:17099, L1 loss=0.0002961, Total loss=0.0002521, Time:83
[Iter 17100/20000] Loss: 0.0002656 (Best: 0.0002155 @iter15940) ([92m↓0.67%[0m) [0.11% of initial]
[Iter 17110/20000] Loss: 0.0002808 (Best: 0.0002155 @iter15940) ([91m↑5.73%[0m) [0.11% of initial]
[Iter 17120/20000] Loss: 0.0002737 (Best: 0.0002155 @iter15940) ([92m↓2.53%[0m) [0.11% of initial]
[Iter 17130/20000] Loss: 0.0002758 (Best: 0.0002155 @iter15940) ([91m↑0.75%[0m) [0.11% of initial]
[Iter 17140/20000] Loss: 0.0002897 (Best: 0.0002155 @iter15940) ([91m↑5.05%[0m) [0.12% of initial]
[Iter 17150/20000] Loss: 0.0002868 (Best: 0.0002155 @iter15940) ([92m↓0.99%[0m) [0.11% of initial]
[Iter 17160/20000] Loss: 0.0003066 (Best: 0.0002155 @iter15940) ([91m↑6.89%[0m) [0.12% of initial]
[Iter 17170/20000] Loss: 0.0003435 (Best: 0.0002155 @iter15940) ([91m↑12.06%[0m) [0.14% of initial]
[Iter 17180/20000] Loss: 0.0002978 (Best: 0.0002155 @iter15940) ([92m↓13.32%[0m) [0.12% of initial]
[Iter 17190/20000] Loss: 0.0002975 (Best: 0.0002155 @iter15940) ([92m↓0.09%[0m) [0.12% of initial]
Iter:17199, L1 loss=0.0003057, Total loss=0.0002759, Time:80
[Iter 17200/20000] Loss: 0.0002827 (Best: 0.0002155 @iter15940) ([92m↓4.99%[0m) [0.11% of initial]
[Iter 17210/20000] Loss: 0.0002803 (Best: 0.0002155 @iter15940) ([92m↓0.84%[0m) [0.11% of initial]
[Iter 17220/20000] Loss: 0.0002709 (Best: 0.0002155 @iter15940) ([92m↓3.34%[0m) [0.11% of initial]
[Iter 17230/20000] Loss: 0.0002687 (Best: 0.0002155 @iter15940) ([92m↓0.84%[0m) [0.11% of initial]
[Iter 17240/20000] Loss: 0.0003039 (Best: 0.0002155 @iter15940) ([91m↑13.11%[0m) [0.12% of initial]
[Iter 17250/20000] Loss: 0.0003219 (Best: 0.0002155 @iter15940) ([91m↑5.94%[0m) [0.13% of initial]
[Iter 17260/20000] Loss: 0.0002913 (Best: 0.0002155 @iter15940) ([92m↓9.50%[0m) [0.12% of initial]
[Iter 17270/20000] Loss: 0.0002987 (Best: 0.0002155 @iter15940) ([91m↑2.55%[0m) [0.12% of initial]
[Iter 17280/20000] Loss: 0.0002993 (Best: 0.0002155 @iter15940) ([91m↑0.18%[0m) [0.12% of initial]
[Iter 17290/20000] Loss: 0.0004102 (Best: 0.0002155 @iter15940) ([91m↑37.07%[0m) [0.16% of initial]
Iter:17299, L1 loss=0.0003423, Total loss=0.0003014, Time:72
[Iter 17300/20000] Loss: 0.0003180 (Best: 0.0002155 @iter15940) ([92m↓22.49%[0m) [0.13% of initial]
[Iter 17310/20000] Loss: 0.0002999 (Best: 0.0002155 @iter15940) ([92m↓5.70%[0m) [0.12% of initial]
[Iter 17320/20000] Loss: 0.0003146 (Best: 0.0002155 @iter15940) ([91m↑4.93%[0m) [0.12% of initial]
[Iter 17330/20000] Loss: 0.0002849 (Best: 0.0002155 @iter15940) ([92m↓9.44%[0m) [0.11% of initial]
[Iter 17340/20000] Loss: 0.0002688 (Best: 0.0002155 @iter15940) ([92m↓5.64%[0m) [0.11% of initial]
[Iter 17350/20000] Loss: 0.0003019 (Best: 0.0002155 @iter15940) ([91m↑12.30%[0m) [0.12% of initial]
[Iter 17360/20000] Loss: 0.0003148 (Best: 0.0002155 @iter15940) ([91m↑4.26%[0m) [0.13% of initial]
[Iter 17370/20000] Loss: 0.0002917 (Best: 0.0002155 @iter15940) ([92m↓7.33%[0m) [0.12% of initial]
[Iter 17380/20000] Loss: 0.0002894 (Best: 0.0002155 @iter15940) ([92m↓0.80%[0m) [0.11% of initial]
[Iter 17390/20000] Loss: 0.0002852 (Best: 0.0002155 @iter15940) ([92m↓1.45%[0m) [0.11% of initial]
Iter:17399, L1 loss=0.0003505, Total loss=0.0002697, Time:89
[Iter 17400/20000] Loss: 0.0002854 (Best: 0.0002155 @iter15940) ([91m↑0.06%[0m) [0.11% of initial]
[Iter 17410/20000] Loss: 0.0002920 (Best: 0.0002155 @iter15940) ([91m↑2.32%[0m) [0.12% of initial]
[Iter 17420/20000] Loss: 0.0003028 (Best: 0.0002155 @iter15940) ([91m↑3.70%[0m) [0.12% of initial]
[Iter 17430/20000] Loss: 0.0003076 (Best: 0.0002155 @iter15940) ([91m↑1.60%[0m) [0.12% of initial]
[Iter 17440/20000] Loss: 0.0002842 (Best: 0.0002155 @iter15940) ([92m↓7.62%[0m) [0.11% of initial]
[Iter 17450/20000] Loss: 0.0002936 (Best: 0.0002155 @iter15940) ([91m↑3.31%[0m) [0.12% of initial]
[Iter 17460/20000] Loss: 0.0003230 (Best: 0.0002155 @iter15940) ([91m↑10.02%[0m) [0.13% of initial]
[Iter 17470/20000] Loss: 0.0002971 (Best: 0.0002155 @iter15940) ([92m↓8.03%[0m) [0.12% of initial]
[Iter 17480/20000] Loss: 0.0002859 (Best: 0.0002155 @iter15940) ([92m↓3.75%[0m) [0.11% of initial]
[Iter 17490/20000] Loss: 0.0003133 (Best: 0.0002155 @iter15940) ([91m↑9.59%[0m) [0.12% of initial]
Iter:17499, L1 loss=0.0003393, Total loss=0.00029, Time:87
[Iter 17500/20000] Loss: 0.0002807 (Best: 0.0002155 @iter15940) ([92m↓10.42%[0m) [0.11% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 17500
Pruning 5 points (0.0%) from gaussian1 at iteration 17500
[Iter 17510/20000] Loss: 0.0005794 (Best: 0.0002155 @iter15940) ([91m↑106.44%[0m) [0.23% of initial]
[Iter 17520/20000] Loss: 0.0003967 (Best: 0.0002155 @iter15940) ([92m↓31.52%[0m) [0.16% of initial]
[Iter 17530/20000] Loss: 0.0003042 (Best: 0.0002155 @iter15940) ([92m↓23.32%[0m) [0.12% of initial]
[Iter 17540/20000] Loss: 0.0002795 (Best: 0.0002155 @iter15940) ([92m↓8.12%[0m) [0.11% of initial]
[Iter 17550/20000] Loss: 0.0002626 (Best: 0.0002155 @iter15940) ([92m↓6.06%[0m) [0.10% of initial]
[Iter 17560/20000] Loss: 0.0002537 (Best: 0.0002155 @iter15940) ([92m↓3.39%[0m) [0.10% of initial]
[Iter 17570/20000] Loss: 0.0002655 (Best: 0.0002155 @iter15940) ([91m↑4.65%[0m) [0.11% of initial]
[Iter 17580/20000] Loss: 0.0002619 (Best: 0.0002155 @iter15940) ([92m↓1.33%[0m) [0.10% of initial]
[Iter 17590/20000] Loss: 0.0002597 (Best: 0.0002155 @iter15940) ([92m↓0.88%[0m) [0.10% of initial]
Iter:17599, L1 loss=0.0002892, Total loss=0.0002484, Time:74
[Iter 17600/20000] Loss: 0.0002765 (Best: 0.0002155 @iter15940) ([91m↑6.48%[0m) [0.11% of initial]
[Iter 17610/20000] Loss: 0.0002748 (Best: 0.0002155 @iter15940) ([92m↓0.62%[0m) [0.11% of initial]
[Iter 17620/20000] Loss: 0.0002816 (Best: 0.0002155 @iter15940) ([91m↑2.50%[0m) [0.11% of initial]
[Iter 17630/20000] Loss: 0.0002761 (Best: 0.0002155 @iter15940) ([92m↓1.96%[0m) [0.11% of initial]
[Iter 17640/20000] Loss: 0.0002794 (Best: 0.0002155 @iter15940) ([91m↑1.20%[0m) [0.11% of initial]
[Iter 17650/20000] Loss: 0.0002835 (Best: 0.0002155 @iter15940) ([91m↑1.46%[0m) [0.11% of initial]
[Iter 17660/20000] Loss: 0.0002805 (Best: 0.0002155 @iter15940) ([92m↓1.05%[0m) [0.11% of initial]
[Iter 17670/20000] Loss: 0.0002836 (Best: 0.0002155 @iter15940) ([91m↑1.08%[0m) [0.11% of initial]
[Iter 17680/20000] Loss: 0.0002857 (Best: 0.0002155 @iter15940) ([91m↑0.75%[0m) [0.11% of initial]
[Iter 17690/20000] Loss: 0.0002898 (Best: 0.0002155 @iter15940) ([91m↑1.43%[0m) [0.12% of initial]
Iter:17699, L1 loss=0.0002938, Total loss=0.0002516, Time:105
[Iter 17700/20000] Loss: 0.0002725 (Best: 0.0002155 @iter15940) ([92m↓5.97%[0m) [0.11% of initial]
[Iter 17710/20000] Loss: 0.0002677 (Best: 0.0002155 @iter15940) ([92m↓1.75%[0m) [0.11% of initial]
[Iter 17720/20000] Loss: 0.0003216 (Best: 0.0002155 @iter15940) ([91m↑20.13%[0m) [0.13% of initial]
[Iter 17730/20000] Loss: 0.0003077 (Best: 0.0002155 @iter15940) ([92m↓4.31%[0m) [0.12% of initial]
[Iter 17740/20000] Loss: 0.0002843 (Best: 0.0002155 @iter15940) ([92m↓7.63%[0m) [0.11% of initial]
[Iter 17750/20000] Loss: 0.0002826 (Best: 0.0002155 @iter15940) ([92m↓0.57%[0m) [0.11% of initial]
[Iter 17760/20000] Loss: 0.0002610 (Best: 0.0002155 @iter15940) ([92m↓7.68%[0m) [0.10% of initial]
[Iter 17770/20000] Loss: 0.0002532 (Best: 0.0002155 @iter15940) ([92m↓2.97%[0m) [0.10% of initial]
[Iter 17780/20000] Loss: 0.0002583 (Best: 0.0002155 @iter15940) ([91m↑2.01%[0m) [0.10% of initial]
[Iter 17790/20000] Loss: 0.0002999 (Best: 0.0002155 @iter15940) ([91m↑16.12%[0m) [0.12% of initial]
Iter:17799, L1 loss=0.000412, Total loss=0.000371, Time:92
[Iter 17800/20000] Loss: 0.0003223 (Best: 0.0002155 @iter15940) ([91m↑7.45%[0m) [0.13% of initial]
[Iter 17810/20000] Loss: 0.0003125 (Best: 0.0002155 @iter15940) ([92m↓3.04%[0m) [0.12% of initial]
[Iter 17820/20000] Loss: 0.0003061 (Best: 0.0002155 @iter15940) ([92m↓2.05%[0m) [0.12% of initial]
[Iter 17830/20000] Loss: 0.0002799 (Best: 0.0002155 @iter15940) ([92m↓8.53%[0m) [0.11% of initial]
[Iter 17840/20000] Loss: 0.0002679 (Best: 0.0002155 @iter15940) ([92m↓4.29%[0m) [0.11% of initial]
[Iter 17850/20000] Loss: 0.0002631 (Best: 0.0002155 @iter15940) ([92m↓1.79%[0m) [0.10% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
[Iter 17860/20000] Loss: 0.0002659 (Best: 0.0002155 @iter15940) ([91m↑1.04%[0m) [0.11% of initial]
[Iter 17870/20000] Loss: 0.0002871 (Best: 0.0002155 @iter15940) ([91m↑7.98%[0m) [0.11% of initial]
[Iter 17880/20000] Loss: 0.0003393 (Best: 0.0002155 @iter15940) ([91m↑18.19%[0m) [0.13% of initial]
[Iter 17890/20000] Loss: 0.0002708 (Best: 0.0002155 @iter15940) ([92m↓20.18%[0m) [0.11% of initial]
Iter:17899, L1 loss=0.0003091, Total loss=0.0002639, Time:74
[Iter 17900/20000] Loss: 0.0002729 (Best: 0.0002155 @iter15940) ([91m↑0.78%[0m) [0.11% of initial]
[Iter 17910/20000] Loss: 0.0002769 (Best: 0.0002155 @iter15940) ([91m↑1.45%[0m) [0.11% of initial]
[Iter 17920/20000] Loss: 0.0002895 (Best: 0.0002155 @iter15940) ([91m↑4.56%[0m) [0.12% of initial]
[Iter 17930/20000] Loss: 0.0002613 (Best: 0.0002155 @iter15940) ([92m↓9.76%[0m) [0.10% of initial]
[Iter 17940/20000] Loss: 0.0002556 (Best: 0.0002155 @iter15940) ([92m↓2.16%[0m) [0.10% of initial]
[Iter 17950/20000] Loss: 0.0002549 (Best: 0.0002155 @iter15940) ([92m↓0.29%[0m) [0.10% of initial]
[Iter 17960/20000] Loss: 0.0002634 (Best: 0.0002155 @iter15940) ([91m↑3.36%[0m) [0.10% of initial]
[Iter 17970/20000] Loss: 0.0002565 (Best: 0.0002155 @iter15940) ([92m↓2.63%[0m) [0.10% of initial]
[Iter 17980/20000] Loss: 0.0002652 (Best: 0.0002155 @iter15940) ([91m↑3.39%[0m) [0.11% of initial]
[Iter 17990/20000] Loss: 0.0002489 (Best: 0.0002155 @iter15940) ([92m↓6.14%[0m) [0.10% of initial]
Iter:17999, L1 loss=0.0003168, Total loss=0.0002492, Time:72
[Iter 18000/20000] Loss: 0.0002451 (Best: 0.0002155 @iter15940) ([92m↓1.55%[0m) [0.10% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 18000
Pruning 5 points (0.0%) from gaussian1 at iteration 18000
[Iter 18010/20000] Loss: 0.0007248 (Best: 0.0002155 @iter15940) ([91m↑195.76%[0m) [0.29% of initial]
[Iter 18020/20000] Loss: 0.0004266 (Best: 0.0002155 @iter15940) ([92m↓41.14%[0m) [0.17% of initial]
[Iter 18030/20000] Loss: 0.0003573 (Best: 0.0002155 @iter15940) ([92m↓16.25%[0m) [0.14% of initial]
[Iter 18040/20000] Loss: 0.0002871 (Best: 0.0002155 @iter15940) ([92m↓19.63%[0m) [0.11% of initial]
[Iter 18050/20000] Loss: 0.0002725 (Best: 0.0002155 @iter15940) ([92m↓5.10%[0m) [0.11% of initial]
[Iter 18060/20000] Loss: 0.0002690 (Best: 0.0002155 @iter15940) ([92m↓1.27%[0m) [0.11% of initial]
[Iter 18070/20000] Loss: 0.0002596 (Best: 0.0002155 @iter15940) ([92m↓3.52%[0m) [0.10% of initial]
[Iter 18080/20000] Loss: 0.0002614 (Best: 0.0002155 @iter15940) ([91m↑0.72%[0m) [0.10% of initial]
[Iter 18090/20000] Loss: 0.0002795 (Best: 0.0002155 @iter15940) ([91m↑6.92%[0m) [0.11% of initial]
Iter:18099, L1 loss=0.0003547, Total loss=0.0003132, Time:94
[Iter 18100/20000] Loss: 0.0002757 (Best: 0.0002155 @iter15940) ([92m↓1.36%[0m) [0.11% of initial]
[Iter 18110/20000] Loss: 0.0002685 (Best: 0.0002155 @iter15940) ([92m↓2.62%[0m) [0.11% of initial]
[Iter 18120/20000] Loss: 0.0002618 (Best: 0.0002155 @iter15940) ([92m↓2.48%[0m) [0.10% of initial]
[Iter 18130/20000] Loss: 0.0002522 (Best: 0.0002155 @iter15940) ([92m↓3.69%[0m) [0.10% of initial]
[Iter 18140/20000] Loss: 0.0002604 (Best: 0.0002155 @iter15940) ([91m↑3.27%[0m) [0.10% of initial]
[Iter 18150/20000] Loss: 0.0002570 (Best: 0.0002155 @iter15940) ([92m↓1.31%[0m) [0.10% of initial]
[Iter 18160/20000] Loss: 0.0002575 (Best: 0.0002155 @iter15940) ([91m↑0.19%[0m) [0.10% of initial]
[Iter 18170/20000] Loss: 0.0002913 (Best: 0.0002155 @iter15940) ([91m↑13.13%[0m) [0.12% of initial]
[Iter 18180/20000] Loss: 0.0004377 (Best: 0.0002155 @iter15940) ([91m↑50.24%[0m) [0.17% of initial]
[Iter 18190/20000] Loss: 0.0004148 (Best: 0.0002155 @iter15940) ([92m↓5.23%[0m) [0.16% of initial]
Iter:18199, L1 loss=0.0003143, Total loss=0.000304, Time:96
[Iter 18200/20000] Loss: 0.0003443 (Best: 0.0002155 @iter15940) ([92m↓16.99%[0m) [0.14% of initial]
[Iter 18210/20000] Loss: 0.0003010 (Best: 0.0002155 @iter15940) ([92m↓12.57%[0m) [0.12% of initial]
[Iter 18220/20000] Loss: 0.0002645 (Best: 0.0002155 @iter15940) ([92m↓12.13%[0m) [0.11% of initial]
[Iter 18230/20000] Loss: 0.0002967 (Best: 0.0002155 @iter15940) ([91m↑12.17%[0m) [0.12% of initial]
[Iter 18240/20000] Loss: 0.0002732 (Best: 0.0002155 @iter15940) ([92m↓7.92%[0m) [0.11% of initial]
[Iter 18250/20000] Loss: 0.0002719 (Best: 0.0002155 @iter15940) ([92m↓0.48%[0m) [0.11% of initial]
[Iter 18260/20000] Loss: 0.0002635 (Best: 0.0002155 @iter15940) ([92m↓3.09%[0m) [0.10% of initial]
[Iter 18270/20000] Loss: 0.0002604 (Best: 0.0002155 @iter15940) ([92m↓1.18%[0m) [0.10% of initial]
[Iter 18280/20000] Loss: 0.0002515 (Best: 0.0002155 @iter15940) ([92m↓3.39%[0m) [0.10% of initial]
[Iter 18290/20000] Loss: 0.0002737 (Best: 0.0002155 @iter15940) ([91m↑8.80%[0m) [0.11% of initial]
Iter:18299, L1 loss=0.0003563, Total loss=0.0003215, Time:79
[Iter 18300/20000] Loss: 0.0002933 (Best: 0.0002155 @iter15940) ([91m↑7.18%[0m) [0.12% of initial]
[Iter 18310/20000] Loss: 0.0003095 (Best: 0.0002155 @iter15940) ([91m↑5.51%[0m) [0.12% of initial]
[Iter 18320/20000] Loss: 0.0003038 (Best: 0.0002155 @iter15940) ([92m↓1.85%[0m) [0.12% of initial]
[Iter 18330/20000] Loss: 0.0003592 (Best: 0.0002155 @iter15940) ([91m↑18.25%[0m) [0.14% of initial]
[Iter 18340/20000] Loss: 0.0003576 (Best: 0.0002155 @iter15940) ([92m↓0.45%[0m) [0.14% of initial]
[Iter 18350/20000] Loss: 0.0003411 (Best: 0.0002155 @iter15940) ([92m↓4.61%[0m) [0.14% of initial]
[Iter 18360/20000] Loss: 0.0003945 (Best: 0.0002155 @iter15940) ([91m↑15.65%[0m) [0.16% of initial]
[Iter 18370/20000] Loss: 0.0003033 (Best: 0.0002155 @iter15940) ([92m↓23.12%[0m) [0.12% of initial]
[Iter 18380/20000] Loss: 0.0002641 (Best: 0.0002155 @iter15940) ([92m↓12.91%[0m) [0.10% of initial]
[Iter 18390/20000] Loss: 0.0002688 (Best: 0.0002155 @iter15940) ([91m↑1.78%[0m) [0.11% of initial]
Iter:18399, L1 loss=0.000282, Total loss=0.0002456, Time:98
[Iter 18400/20000] Loss: 0.0002419 (Best: 0.0002155 @iter15940) ([92m↓10.00%[0m) [0.10% of initial]
[Iter 18410/20000] Loss: 0.0002536 (Best: 0.0002155 @iter15940) ([91m↑4.82%[0m) [0.10% of initial]
[Iter 18420/20000] Loss: 0.0002382 (Best: 0.0002155 @iter15940) ([92m↓6.08%[0m) [0.09% of initial]
[Iter 18430/20000] Loss: 0.0002383 (Best: 0.0002155 @iter15940) ([91m↑0.08%[0m) [0.09% of initial]
[Iter 18440/20000] Loss: 0.0002396 (Best: 0.0002155 @iter15940) ([91m↑0.51%[0m) [0.10% of initial]
[Iter 18450/20000] Loss: 0.0002436 (Best: 0.0002155 @iter15940) ([91m↑1.69%[0m) [0.10% of initial]
[Iter 18460/20000] Loss: 0.0002454 (Best: 0.0002155 @iter15940) ([91m↑0.75%[0m) [0.10% of initial]
[Iter 18470/20000] Loss: 0.0002455 (Best: 0.0002155 @iter15940) ([91m↑0.04%[0m) [0.10% of initial]
[Iter 18480/20000] Loss: 0.0002398 (Best: 0.0002155 @iter15940) ([92m↓2.32%[0m) [0.10% of initial]
[Iter 18490/20000] Loss: 0.0002554 (Best: 0.0002155 @iter15940) ([91m↑6.47%[0m) [0.10% of initial]
Iter:18499, L1 loss=0.0003016, Total loss=0.0002542, Time:95
[Iter 18500/20000] Loss: 0.0002513 (Best: 0.0002155 @iter15940) ([92m↓1.58%[0m) [0.10% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 18500
Pruning 1 points (0.0%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0004963 (Best: 0.0002155 @iter15940) ([91m↑97.48%[0m) [0.20% of initial]
[Iter 18520/20000] Loss: 0.0003451 (Best: 0.0002155 @iter15940) ([92m↓30.46%[0m) [0.14% of initial]
[Iter 18530/20000] Loss: 0.0002859 (Best: 0.0002155 @iter15940) ([92m↓17.15%[0m) [0.11% of initial]
[Iter 18540/20000] Loss: 0.0003083 (Best: 0.0002155 @iter15940) ([91m↑7.81%[0m) [0.12% of initial]
[Iter 18550/20000] Loss: 0.0002841 (Best: 0.0002155 @iter15940) ([92m↓7.86%[0m) [0.11% of initial]
[Iter 18560/20000] Loss: 0.0002903 (Best: 0.0002155 @iter15940) ([91m↑2.18%[0m) [0.12% of initial]
[Iter 18570/20000] Loss: 0.0003077 (Best: 0.0002155 @iter15940) ([91m↑6.02%[0m) [0.12% of initial]
[Iter 18580/20000] Loss: 0.0002619 (Best: 0.0002155 @iter15940) ([92m↓14.89%[0m) [0.10% of initial]
[Iter 18590/20000] Loss: 0.0002567 (Best: 0.0002155 @iter15940) ([92m↓2.01%[0m) [0.10% of initial]
Iter:18599, L1 loss=0.0003211, Total loss=0.0002634, Time:94
[Iter 18600/20000] Loss: 0.0002786 (Best: 0.0002155 @iter15940) ([91m↑8.55%[0m) [0.11% of initial]
[Iter 18610/20000] Loss: 0.0002594 (Best: 0.0002155 @iter15940) ([92m↓6.89%[0m) [0.10% of initial]
[Iter 18620/20000] Loss: 0.0002409 (Best: 0.0002155 @iter15940) ([92m↓7.15%[0m) [0.10% of initial]
[Iter 18630/20000] Loss: 0.0002839 (Best: 0.0002155 @iter15940) ([91m↑17.88%[0m) [0.11% of initial]
[Iter 18640/20000] Loss: 0.0002650 (Best: 0.0002155 @iter15940) ([92m↓6.65%[0m) [0.11% of initial]
[Iter 18650/20000] Loss: 0.0002478 (Best: 0.0002155 @iter15940) ([92m↓6.51%[0m) [0.10% of initial]
[Iter 18660/20000] Loss: 0.0002589 (Best: 0.0002155 @iter15940) ([91m↑4.48%[0m) [0.10% of initial]
[Iter 18670/20000] Loss: 0.0002477 (Best: 0.0002155 @iter15940) ([92m↓4.30%[0m) [0.10% of initial]
[Iter 18680/20000] Loss: 0.0002466 (Best: 0.0002155 @iter15940) ([92m↓0.44%[0m) [0.10% of initial]
[Iter 18690/20000] Loss: 0.0002493 (Best: 0.0002155 @iter15940) ([91m↑1.07%[0m) [0.10% of initial]
Iter:18699, L1 loss=0.0002739, Total loss=0.0002424, Time:82
[Iter 18700/20000] Loss: 0.0002332 (Best: 0.0002155 @iter15940) ([92m↓6.46%[0m) [0.09% of initial]
[Iter 18710/20000] Loss: 0.0002396 (Best: 0.0002155 @iter15940) ([91m↑2.75%[0m) [0.10% of initial]
[Iter 18720/20000] Loss: 0.0002357 (Best: 0.0002155 @iter15940) ([92m↓1.62%[0m) [0.09% of initial]
[Iter 18730/20000] Loss: 0.0002430 (Best: 0.0002155 @iter15940) ([91m↑3.09%[0m) [0.10% of initial]
[Iter 18740/20000] Loss: 0.0002510 (Best: 0.0002155 @iter15940) ([91m↑3.31%[0m) [0.10% of initial]
[Iter 18750/20000] Loss: 0.0002434 (Best: 0.0002155 @iter15940) ([92m↓3.05%[0m) [0.10% of initial]
[Iter 18760/20000] Loss: 0.0002500 (Best: 0.0002155 @iter15940) ([91m↑2.71%[0m) [0.10% of initial]
[Iter 18770/20000] Loss: 0.0002557 (Best: 0.0002155 @iter15940) ([91m↑2.31%[0m) [0.10% of initial]
[Iter 18780/20000] Loss: 0.0002582 (Best: 0.0002155 @iter15940) ([91m↑0.97%[0m) [0.10% of initial]
[Iter 18790/20000] Loss: 0.0002708 (Best: 0.0002155 @iter15940) ([91m↑4.88%[0m) [0.11% of initial]
Iter:18799, L1 loss=0.0002896, Total loss=0.0002507, Time:109
[Iter 18800/20000] Loss: 0.0002593 (Best: 0.0002155 @iter15940) ([92m↓4.26%[0m) [0.10% of initial]
[Iter 18810/20000] Loss: 0.0002676 (Best: 0.0002155 @iter15940) ([91m↑3.20%[0m) [0.11% of initial]
[Iter 18820/20000] Loss: 0.0002588 (Best: 0.0002155 @iter15940) ([92m↓3.30%[0m) [0.10% of initial]
[Iter 18830/20000] Loss: 0.0002700 (Best: 0.0002155 @iter15940) ([91m↑4.34%[0m) [0.11% of initial]
[Iter 18840/20000] Loss: 0.0002614 (Best: 0.0002155 @iter15940) ([92m↓3.17%[0m) [0.10% of initial]
[Iter 18850/20000] Loss: 0.0002578 (Best: 0.0002155 @iter15940) ([92m↓1.40%[0m) [0.10% of initial]
[Iter 18860/20000] Loss: 0.0002975 (Best: 0.0002155 @iter15940) ([91m↑15.41%[0m) [0.12% of initial]
[Iter 18870/20000] Loss: 0.0002571 (Best: 0.0002155 @iter15940) ([92m↓13.59%[0m) [0.10% of initial]
[Iter 18880/20000] Loss: 0.0002470 (Best: 0.0002155 @iter15940) ([92m↓3.91%[0m) [0.10% of initial]
[Iter 18890/20000] Loss: 0.0002566 (Best: 0.0002155 @iter15940) ([91m↑3.87%[0m) [0.10% of initial]
Iter:18899, L1 loss=0.0002944, Total loss=0.0002536, Time:93
[Iter 18900/20000] Loss: 0.0002557 (Best: 0.0002155 @iter15940) ([92m↓0.32%[0m) [0.10% of initial]
[Iter 18910/20000] Loss: 0.0002684 (Best: 0.0002155 @iter15940) ([91m↑4.94%[0m) [0.11% of initial]
[Iter 18920/20000] Loss: 0.0002432 (Best: 0.0002155 @iter15940) ([92m↓9.36%[0m) [0.10% of initial]
[Iter 18930/20000] Loss: 0.0003062 (Best: 0.0002155 @iter15940) ([91m↑25.87%[0m) [0.12% of initial]
[Iter 18940/20000] Loss: 0.0002635 (Best: 0.0002155 @iter15940) ([92m↓13.93%[0m) [0.10% of initial]
[Iter 18950/20000] Loss: 0.0002613 (Best: 0.0002155 @iter15940) ([92m↓0.84%[0m) [0.10% of initial]
[Iter 18960/20000] Loss: 0.0002684 (Best: 0.0002155 @iter15940) ([91m↑2.71%[0m) [0.11% of initial]
[Iter 18970/20000] Loss: 0.0002817 (Best: 0.0002155 @iter15940) ([91m↑4.96%[0m) [0.11% of initial]
[Iter 18980/20000] Loss: 0.0002496 (Best: 0.0002155 @iter15940) ([92m↓11.38%[0m) [0.10% of initial]
[Iter 18990/20000] Loss: 0.0002497 (Best: 0.0002155 @iter15940) ([91m↑0.01%[0m) [0.10% of initial]
Iter:18999, L1 loss=0.0002749, Total loss=0.0002392, Time:107
[Iter 19000/20000] Loss: 0.0002352 (Best: 0.0002155 @iter15940) ([92m↓5.79%[0m) [0.09% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 19000
Pruning 2 points (0.0%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0005944 (Best: 0.0002155 @iter15940) ([91m↑152.72%[0m) [0.24% of initial]
[Iter 19020/20000] Loss: 0.0004336 (Best: 0.0002155 @iter15940) ([92m↓27.06%[0m) [0.17% of initial]
[Iter 19030/20000] Loss: 0.0003337 (Best: 0.0002155 @iter15940) ([92m↓23.04%[0m) [0.13% of initial]
[Iter 19040/20000] Loss: 0.0002753 (Best: 0.0002155 @iter15940) ([92m↓17.49%[0m) [0.11% of initial]
[Iter 19050/20000] Loss: 0.0002561 (Best: 0.0002155 @iter15940) ([92m↓6.96%[0m) [0.10% of initial]
[Iter 19060/20000] Loss: 0.0002450 (Best: 0.0002155 @iter15940) ([92m↓4.36%[0m) [0.10% of initial]
[Iter 19070/20000] Loss: 0.0002754 (Best: 0.0002155 @iter15940) ([91m↑12.44%[0m) [0.11% of initial]
[Iter 19080/20000] Loss: 0.0002432 (Best: 0.0002155 @iter15940) ([92m↓11.69%[0m) [0.10% of initial]
[Iter 19090/20000] Loss: 0.0002385 (Best: 0.0002155 @iter15940) ([92m↓1.96%[0m) [0.09% of initial]
Iter:19099, L1 loss=0.0002721, Total loss=0.0002331, Time:97
[Iter 19100/20000] Loss: 0.0002601 (Best: 0.0002155 @iter15940) ([91m↑9.08%[0m) [0.10% of initial]
[Iter 19110/20000] Loss: 0.0002753 (Best: 0.0002155 @iter15940) ([91m↑5.83%[0m) [0.11% of initial]
[Iter 19120/20000] Loss: 0.0002394 (Best: 0.0002155 @iter15940) ([92m↓13.03%[0m) [0.10% of initial]
[Iter 19130/20000] Loss: 0.0002337 (Best: 0.0002155 @iter15940) ([92m↓2.40%[0m) [0.09% of initial]
[Iter 19140/20000] Loss: 0.0002492 (Best: 0.0002155 @iter15940) ([91m↑6.65%[0m) [0.10% of initial]
[Iter 19150/20000] Loss: 0.0002466 (Best: 0.0002155 @iter15940) ([92m↓1.08%[0m) [0.10% of initial]
[Iter 19160/20000] Loss: 0.0002590 (Best: 0.0002155 @iter15940) ([91m↑5.05%[0m) [0.10% of initial]
[Iter 19170/20000] Loss: 0.0002428 (Best: 0.0002155 @iter15940) ([92m↓6.24%[0m) [0.10% of initial]
[Iter 19180/20000] Loss: 0.0002383 (Best: 0.0002155 @iter15940) ([92m↓1.88%[0m) [0.09% of initial]
[Iter 19190/20000] Loss: 0.0002510 (Best: 0.0002155 @iter15940) ([91m↑5.34%[0m) [0.10% of initial]
Iter:19199, L1 loss=0.0003486, Total loss=0.0002945, Time:74
[Iter 19200/20000] Loss: 0.0002670 (Best: 0.0002155 @iter15940) ([91m↑6.39%[0m) [0.11% of initial]
[Iter 19210/20000] Loss: 0.0002534 (Best: 0.0002155 @iter15940) ([92m↓5.10%[0m) [0.10% of initial]
[Iter 19220/20000] Loss: 0.0002719 (Best: 0.0002155 @iter15940) ([91m↑7.30%[0m) [0.11% of initial]
[Iter 19230/20000] Loss: 0.0002401 (Best: 0.0002155 @iter15940) ([92m↓11.71%[0m) [0.10% of initial]
[Iter 19240/20000] Loss: 0.0002314 (Best: 0.0002155 @iter15940) ([92m↓3.61%[0m) [0.09% of initial]
[Iter 19250/20000] Loss: 0.0002464 (Best: 0.0002155 @iter15940) ([91m↑6.46%[0m) [0.10% of initial]
[Iter 19260/20000] Loss: 0.0002430 (Best: 0.0002155 @iter15940) ([92m↓1.38%[0m) [0.10% of initial]
[Iter 19270/20000] Loss: 0.0002628 (Best: 0.0002155 @iter15940) ([91m↑8.15%[0m) [0.10% of initial]
[Iter 19280/20000] Loss: 0.0002649 (Best: 0.0002155 @iter15940) ([91m↑0.79%[0m) [0.11% of initial]
[Iter 19290/20000] Loss: 0.0002584 (Best: 0.0002155 @iter15940) ([92m↓2.45%[0m) [0.10% of initial]
Iter:19299, L1 loss=0.0002727, Total loss=0.0002461, Time:96
[Iter 19300/20000] Loss: 0.0002474 (Best: 0.0002155 @iter15940) ([92m↓4.24%[0m) [0.10% of initial]
[Iter 19310/20000] Loss: 0.0002700 (Best: 0.0002155 @iter15940) ([91m↑9.12%[0m) [0.11% of initial]
[Iter 19320/20000] Loss: 0.0002597 (Best: 0.0002155 @iter15940) ([92m↓3.82%[0m) [0.10% of initial]
[Iter 19330/20000] Loss: 0.0002642 (Best: 0.0002155 @iter15940) ([91m↑1.72%[0m) [0.10% of initial]
[Iter 19340/20000] Loss: 0.0002998 (Best: 0.0002155 @iter15940) ([91m↑13.48%[0m) [0.12% of initial]
[Iter 19350/20000] Loss: 0.0003166 (Best: 0.0002155 @iter15940) ([91m↑5.61%[0m) [0.13% of initial]
[Iter 19360/20000] Loss: 0.0003078 (Best: 0.0002155 @iter15940) ([92m↓2.77%[0m) [0.12% of initial]
[Iter 19370/20000] Loss: 0.0003316 (Best: 0.0002155 @iter15940) ([91m↑7.72%[0m) [0.13% of initial]
[Iter 19380/20000] Loss: 0.0003847 (Best: 0.0002155 @iter15940) ([91m↑16.01%[0m) [0.15% of initial]
[Iter 19390/20000] Loss: 0.0002943 (Best: 0.0002155 @iter15940) ([92m↓23.51%[0m) [0.12% of initial]
Iter:19399, L1 loss=0.0002719, Total loss=0.0002444, Time:94
[Iter 19400/20000] Loss: 0.0002654 (Best: 0.0002155 @iter15940) ([92m↓9.82%[0m) [0.11% of initial]
[Iter 19410/20000] Loss: 0.0002381 (Best: 0.0002155 @iter15940) ([92m↓10.26%[0m) [0.09% of initial]
[Iter 19420/20000] Loss: 0.0002311 (Best: 0.0002132 @iter19415) ([92m↓2.95%[0m) [0.09% of initial]
[Iter 19430/20000] Loss: 0.0002250 (Best: 0.0002129 @iter19421) ([92m↓2.62%[0m) [0.09% of initial]
[Iter 19440/20000] Loss: 0.0002382 (Best: 0.0002129 @iter19421) ([91m↑5.84%[0m) [0.09% of initial]
[Iter 19450/20000] Loss: 0.0002425 (Best: 0.0002129 @iter19421) ([91m↑1.81%[0m) [0.10% of initial]
[Iter 19460/20000] Loss: 0.0002799 (Best: 0.0002129 @iter19421) ([91m↑15.42%[0m) [0.11% of initial]
[Iter 19470/20000] Loss: 0.0003497 (Best: 0.0002129 @iter19421) ([91m↑24.94%[0m) [0.14% of initial]
[Iter 19480/20000] Loss: 0.0003657 (Best: 0.0002129 @iter19421) ([91m↑4.57%[0m) [0.15% of initial]
[Iter 19490/20000] Loss: 0.0003374 (Best: 0.0002129 @iter19421) ([92m↓7.73%[0m) [0.13% of initial]
Iter:19499, L1 loss=0.000306, Total loss=0.0002692, Time:80
[Iter 19500/20000] Loss: 0.0002955 (Best: 0.0002129 @iter19421) ([92m↓12.42%[0m) [0.12% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 19500
Pruning 1 points (0.0%) from gaussian1 at iteration 19500
[Iter 19510/20000] Loss: 0.0005778 (Best: 0.0002129 @iter19421) ([91m↑95.53%[0m) [0.23% of initial]
[Iter 19520/20000] Loss: 0.0003513 (Best: 0.0002129 @iter19421) ([92m↓39.19%[0m) [0.14% of initial]
[Iter 19530/20000] Loss: 0.0002917 (Best: 0.0002129 @iter19421) ([92m↓16.97%[0m) [0.12% of initial]
[Iter 19540/20000] Loss: 0.0002463 (Best: 0.0002129 @iter19421) ([92m↓15.58%[0m) [0.10% of initial]
[Iter 19550/20000] Loss: 0.0002465 (Best: 0.0002129 @iter19421) ([91m↑0.09%[0m) [0.10% of initial]
[Iter 19560/20000] Loss: 0.0002386 (Best: 0.0002129 @iter19421) ([92m↓3.22%[0m) [0.09% of initial]
[Iter 19570/20000] Loss: 0.0002252 (Best: 0.0002129 @iter19421) ([92m↓5.62%[0m) [0.09% of initial]
[Iter 19580/20000] Loss: 0.0002705 (Best: 0.0002129 @iter19421) ([91m↑20.14%[0m) [0.11% of initial]
[Iter 19590/20000] Loss: 0.0002378 (Best: 0.0002129 @iter19421) ([92m↓12.08%[0m) [0.09% of initial]
Iter:19599, L1 loss=0.0002737, Total loss=0.0002408, Time:105
[Iter 19600/20000] Loss: 0.0002305 (Best: 0.0002129 @iter19421) ([92m↓3.07%[0m) [0.09% of initial]
[Iter 19610/20000] Loss: 0.0002290 (Best: 0.0002124 @iter19609) ([92m↓0.67%[0m) [0.09% of initial]
[Iter 19620/20000] Loss: 0.0002457 (Best: 0.0002113 @iter19612) ([91m↑7.30%[0m) [0.10% of initial]
[Iter 19630/20000] Loss: 0.0002524 (Best: 0.0002113 @iter19612) ([91m↑2.73%[0m) [0.10% of initial]
[Iter 19640/20000] Loss: 0.0002397 (Best: 0.0002113 @iter19612) ([92m↓5.03%[0m) [0.10% of initial]
[Iter 19650/20000] Loss: 0.0002569 (Best: 0.0002113 @iter19612) ([91m↑7.18%[0m) [0.10% of initial]
[Iter 19660/20000] Loss: 0.0002268 (Best: 0.0002113 @iter19612) ([92m↓11.72%[0m) [0.09% of initial]
[Iter 19670/20000] Loss: 0.0002248 (Best: 0.0002113 @iter19612) ([92m↓0.90%[0m) [0.09% of initial]
[Iter 19680/20000] Loss: 0.0002293 (Best: 0.0002113 @iter19612) ([91m↑2.00%[0m) [0.09% of initial]
[Iter 19690/20000] Loss: 0.0002272 (Best: 0.0002113 @iter19612) ([92m↓0.89%[0m) [0.09% of initial]
Iter:19699, L1 loss=0.0002809, Total loss=0.0002439, Time:71
[Iter 19700/20000] Loss: 0.0002464 (Best: 0.0002113 @iter19612) ([91m↑8.43%[0m) [0.10% of initial]
[Iter 19710/20000] Loss: 0.0002648 (Best: 0.0002113 @iter19612) ([91m↑7.50%[0m) [0.11% of initial]
[Iter 19720/20000] Loss: 0.0002580 (Best: 0.0002113 @iter19612) ([92m↓2.59%[0m) [0.10% of initial]
[Iter 19730/20000] Loss: 0.0002542 (Best: 0.0002113 @iter19612) ([92m↓1.45%[0m) [0.10% of initial]
[Iter 19740/20000] Loss: 0.0002395 (Best: 0.0002113 @iter19612) ([92m↓5.80%[0m) [0.10% of initial]
[Iter 19750/20000] Loss: 0.0002426 (Best: 0.0002113 @iter19612) ([91m↑1.29%[0m) [0.10% of initial]
[Iter 19760/20000] Loss: 0.0002577 (Best: 0.0002113 @iter19612) ([91m↑6.23%[0m) [0.10% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 19770/20000] Loss: 0.0002441 (Best: 0.0002113 @iter19612) ([92m↓5.27%[0m) [0.10% of initial]
[Iter 19780/20000] Loss: 0.0002544 (Best: 0.0002113 @iter19612) ([91m↑4.22%[0m) [0.10% of initial]
[Iter 19790/20000] Loss: 0.0002504 (Best: 0.0002113 @iter19612) ([92m↓1.56%[0m) [0.10% of initial]
Iter:19799, L1 loss=0.0002823, Total loss=0.0002477, Time:95
[Iter 19800/20000] Loss: 0.0002476 (Best: 0.0002113 @iter19612) ([92m↓1.12%[0m) [0.10% of initial]
[Iter 19810/20000] Loss: 0.0002500 (Best: 0.0002113 @iter19612) ([91m↑0.98%[0m) [0.10% of initial]
[Iter 19820/20000] Loss: 0.0002422 (Best: 0.0002113 @iter19612) ([92m↓3.14%[0m) [0.10% of initial]
[Iter 19830/20000] Loss: 0.0003060 (Best: 0.0002113 @iter19612) ([91m↑26.37%[0m) [0.12% of initial]
[Iter 19840/20000] Loss: 0.0002986 (Best: 0.0002113 @iter19612) ([92m↓2.43%[0m) [0.12% of initial]
[Iter 19850/20000] Loss: 0.0002758 (Best: 0.0002113 @iter19612) ([92m↓7.63%[0m) [0.11% of initial]
[Iter 19860/20000] Loss: 0.0003380 (Best: 0.0002113 @iter19612) ([91m↑22.53%[0m) [0.13% of initial]
[Iter 19870/20000] Loss: 0.0003144 (Best: 0.0002113 @iter19612) ([92m↓6.96%[0m) [0.12% of initial]
[Iter 19880/20000] Loss: 0.0002947 (Best: 0.0002113 @iter19612) ([92m↓6.26%[0m) [0.12% of initial]
[Iter 19890/20000] Loss: 0.0003237 (Best: 0.0002113 @iter19612) ([91m↑9.82%[0m) [0.13% of initial]
Iter:19899, L1 loss=0.0003234, Total loss=0.0002544, Time:68
[Iter 19900/20000] Loss: 0.0002578 (Best: 0.0002113 @iter19612) ([92m↓20.36%[0m) [0.10% of initial]
[Iter 19910/20000] Loss: 0.0002957 (Best: 0.0002113 @iter19612) ([91m↑14.70%[0m) [0.12% of initial]
[Iter 19920/20000] Loss: 0.0002816 (Best: 0.0002113 @iter19612) ([92m↓4.77%[0m) [0.11% of initial]
[Iter 19930/20000] Loss: 0.0002636 (Best: 0.0002113 @iter19612) ([92m↓6.39%[0m) [0.10% of initial]
[Iter 19940/20000] Loss: 0.0002954 (Best: 0.0002113 @iter19612) ([91m↑12.05%[0m) [0.12% of initial]
[Iter 19950/20000] Loss: 0.0002847 (Best: 0.0002113 @iter19612) ([92m↓3.60%[0m) [0.11% of initial]
[Iter 19960/20000] Loss: 0.0002443 (Best: 0.0002113 @iter19612) ([92m↓14.19%[0m) [0.10% of initial]
[Iter 19970/20000] Loss: 0.0002417 (Best: 0.0002113 @iter19612) ([92m↓1.09%[0m) [0.10% of initial]
[Iter 19980/20000] Loss: 0.0002417 (Best: 0.0002100 @iter19975) ([91m↑0.02%[0m) [0.10% of initial]
[Iter 19990/20000] Loss: 0.0002210 (Best: 0.0002100 @iter19975) ([92m↓8.57%[0m) [0.09% of initial]
Iter:19999, L1 loss=0.000268, Total loss=0.0002267, Time:94
[Iter 20000/20000] Loss: 0.0002227 (Best: 0.0002100 @iter19975) ([91m↑0.78%[0m) [0.09% of initial]
Testing Speed: 42.439368413597016 fps
Testing Time: 1.1781513690948486 s

[ITER 20000] Evaluating test: SSIM = 0.9248011720180511, PSNR = 21.29801551818848
Testing Speed: 57.60457067516344 fps
Testing Time: 0.052079200744628906 s

[ITER 20000] Evaluating train: SSIM = 0.9999992251396179, PSNR = 66.15402475992838
Iter:20000, total_points:185255

[ITER 20000] Saving Gaussians
Pruning 0 points (0.0%) from gaussian0 at iteration 20000
Pruning 2 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 42 fps
Total time: 41.72 minutes
Test SSIM: 0.9248
Test PSNR: 21.298
Gaussian0 final points count: 185255
Gaussian1 final points count: 186198
Final loss: 0.0002227 (0.09% of initial)
Save path: 2024_11_26_19_22_45
Initial loss: 0.2517052
Best loss: 0.0002100 @iteration 19975 (0.08% of initial)
Train SSIM: 1.0000
Train PSNR: 66.154
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 1] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 1] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 3] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 3] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 4] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 4] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 5] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 5] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 6] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 6] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 8] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 8] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 9] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 9] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 10] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 10] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 11] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 11] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 12] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 12] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 13] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 13] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 14] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 14] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 15] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 15] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 16] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 16] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 17] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 17] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 18] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 18] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 19] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 19] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 20] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 20] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693030 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 21] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 21] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 22] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 22] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 23] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 23] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 24] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 24] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 25] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 25] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 26] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 26] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 27] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 27] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 28] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 28] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 29] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 29] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 30] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 30] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 30/20000] Loss: 0.1374909 (Best: 0.1327883 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 31] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 31] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 32] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 32] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 33] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 33] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 34] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 34] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 35] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 35] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 36] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 36] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 37] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 37] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 38] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 38] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 39] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 39] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 40] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 40] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 40/20000] Loss: 0.1123928 (Best: 0.1098375 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 41] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 41] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 42] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 42] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 43] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 43] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 44] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 44] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 45] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 45] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 46] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 46] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 47] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 47] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 48] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 48] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 49] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 49] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 50] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 50] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 50/20000] Loss: 0.0993458 (Best: 0.0965473 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 51] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 51] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 52] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 52] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 53] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 53] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 54] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 54] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 55] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 55] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 56] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 56] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 57] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 57] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 58] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 58] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 59] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 59] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 60] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 60] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 60/20000] Loss: 0.0936788 (Best: 0.0908542 @iter59) ([92m↓5.70%[0m) [37.22% of initial]
[Iter 61] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 61] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 62] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 62] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 63] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 63] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 64] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 64] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 65] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 65] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 66] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 66] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 67] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 67] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 68] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 68] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 69] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 69] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 70] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 70] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 70/20000] Loss: 0.0884519 (Best: 0.0869414 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 71] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 71] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 72] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 72] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 73] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 73] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 74] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 74] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 75] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 75] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 76] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 76] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 77] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 77] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 78] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 78] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 79] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 79] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 80] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 80] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 80/20000] Loss: 0.0851905 (Best: 0.0831072 @iter80) ([92m↓3.69%[0m) [33.85% of initial]
[Iter 81] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 81] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 82] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 82] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 83] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 83] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 84] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 84] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 85] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 85] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 86] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 86] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 87] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 87] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 88] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 88] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 89] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 89] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 90] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 90] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 90/20000] Loss: 0.0824179 (Best: 0.0801575 @iter88) ([92m↓3.25%[0m) [32.74% of initial]
[Iter 91] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 91] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 92] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 92] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 93] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 93] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 94] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 94] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 95] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 95] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 96] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 96] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 97] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 97] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 98] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 98] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 99] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 99] Co-reg loss between gs1 and gs0: 0.0000000
Iter:99, L1 loss=0.05723, Total loss=0.07877, Time:149
[Iter 100] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 100] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 100/20000] Loss: 0.0786722 (Best: 0.0766238 @iter97) ([92m↓4.54%[0m) [31.26% of initial]
[Iter 101] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 101] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 102] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 102] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 103] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 103] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 104] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 104] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 105] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 105] Co-reg loss between gs1 and gs0: 0.0000000
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374907 (Best: 0.1327884 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123916 (Best: 0.1098363 @iter40) ([92m↓18.26%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993441 (Best: 0.0965435 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936757 (Best: 0.0908537 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884530 (Best: 0.0869407 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851916 (Best: 0.0831042 @iter80) ([92m↓3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824149 (Best: 0.0801608 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07877, Time:72
[Iter 100/20000] Loss: 0.0786736 (Best: 0.0766291 @iter97) ([92m↓4.54%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753316 (Best: 0.0731384 @iter106) ([92m↓4.25%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714468 (Best: 0.0685868 @iter118) ([92m↓5.16%[0m) [28.39% of initial]
[Iter 130/20000] Loss: 0.0667170 (Best: 0.0642193 @iter130) ([92m↓6.62%[0m) [26.51% of initial]
[Iter 140/20000] Loss: 0.0635702 (Best: 0.0613280 @iter140) ([92m↓4.72%[0m) [25.26% of initial]
[Iter 150/20000] Loss: 0.0613064 (Best: 0.0584209 @iter148) ([92m↓3.56%[0m) [24.36% of initial]
[Iter 160/20000] Loss: 0.0591068 (Best: 0.0559818 @iter157) ([92m↓3.59%[0m) [23.48% of initial]
[Iter 170/20000] Loss: 0.0563722 (Best: 0.0535458 @iter167) ([92m↓4.63%[0m) [22.40% of initial]
[Iter 180/20000] Loss: 0.0523649 (Best: 0.0500187 @iter179) ([92m↓7.11%[0m) [20.80% of initial]
[Iter 190/20000] Loss: 0.0495705 (Best: 0.0478115 @iter188) ([92m↓5.34%[0m) [19.69% of initial]
Iter:199, L1 loss=0.03444, Total loss=0.04975, Time:63
[Iter 200/20000] Loss: 0.0478086 (Best: 0.0456901 @iter198) ([92m↓3.55%[0m) [18.99% of initial]
[Iter 210/20000] Loss: 0.0450115 (Best: 0.0427589 @iter209) ([92m↓5.85%[0m) [17.88% of initial]
[Iter 220/20000] Loss: 0.0440124 (Best: 0.0411532 @iter219) ([92m↓2.22%[0m) [17.49% of initial]
[Iter 230/20000] Loss: 0.0422616 (Best: 0.0398767 @iter227) ([92m↓3.98%[0m) [16.79% of initial]
[Iter 240/20000] Loss: 0.0402576 (Best: 0.0378096 @iter238) ([92m↓4.74%[0m) [15.99% of initial]
[Iter 250/20000] Loss: 0.0380381 (Best: 0.0362397 @iter248) ([92m↓5.51%[0m) [15.11% of initial]
[Iter 260/20000] Loss: 0.0358770 (Best: 0.0342451 @iter260) ([92m↓5.68%[0m) [14.25% of initial]
[Iter 270/20000] Loss: 0.0350682 (Best: 0.0329881 @iter269) ([92m↓2.25%[0m) [13.93% of initial]
[Iter 280/20000] Loss: 0.0346806 (Best: 0.0317708 @iter277) ([92m↓1.11%[0m) [13.78% of initial]
[Iter 290/20000] Loss: 0.0330887 (Best: 0.0304059 @iter287) ([92m↓4.59%[0m) [13.15% of initial]
Iter:299, L1 loss=0.02236, Total loss=0.03343, Time:71
[Iter 300/20000] Loss: 0.0309032 (Best: 0.0289789 @iter300) ([92m↓6.61%[0m) [12.28% of initial]
[Iter 310/20000] Loss: 0.0293219 (Best: 0.0273496 @iter310) ([92m↓5.12%[0m) [11.65% of initial]
[Iter 320/20000] Loss: 0.0278298 (Best: 0.0264009 @iter320) ([92m↓5.09%[0m) [11.06% of initial]
[Iter 330/20000] Loss: 0.0274025 (Best: 0.0255541 @iter330) ([92m↓1.54%[0m) [10.89% of initial]
[Iter 340/20000] Loss: 0.0254053 (Best: 0.0242757 @iter340) ([92m↓7.29%[0m) [10.09% of initial]
[Iter 350/20000] Loss: 0.0262670 (Best: 0.0236870 @iter349) ([91m↑3.39%[0m) [10.44% of initial]
[Iter 360/20000] Loss: 0.0247360 (Best: 0.0224886 @iter358) ([92m↓5.83%[0m) [9.83% of initial]
[Iter 370/20000] Loss: 0.0241889 (Best: 0.0218088 @iter368) ([92m↓2.21%[0m) [9.61% of initial]
[Iter 380/20000] Loss: 0.0217819 (Best: 0.0206430 @iter379) ([92m↓9.95%[0m) [8.65% of initial]
[Iter 390/20000] Loss: 0.0215605 (Best: 0.0200917 @iter385) ([92m↓1.02%[0m) [8.57% of initial]
Iter:399, L1 loss=0.01392, Total loss=0.02105, Time:69
[Iter 400/20000] Loss: 0.0203418 (Best: 0.0188190 @iter400) ([92m↓5.65%[0m) [8.08% of initial]
[Iter 410/20000] Loss: 0.0191123 (Best: 0.0180156 @iter410) ([92m↓6.04%[0m) [7.59% of initial]
[Iter 420/20000] Loss: 0.0193147 (Best: 0.0173053 @iter418) ([91m↑1.06%[0m) [7.67% of initial]
[Iter 430/20000] Loss: 0.0172065 (Best: 0.0163483 @iter430) ([92m↓10.92%[0m) [6.84% of initial]
[Iter 440/20000] Loss: 0.0179407 (Best: 0.0158804 @iter434) ([91m↑4.27%[0m) [7.13% of initial]
[Iter 450/20000] Loss: 0.0170947 (Best: 0.0150264 @iter445) ([92m↓4.72%[0m) [6.79% of initial]
[Iter 460/20000] Loss: 0.0164848 (Best: 0.0145296 @iter458) ([92m↓3.57%[0m) [6.55% of initial]
[Iter 470/20000] Loss: 0.0145782 (Best: 0.0135348 @iter470) ([92m↓11.57%[0m) [5.79% of initial]
[Iter 480/20000] Loss: 0.0143441 (Best: 0.0129366 @iter479) ([92m↓1.61%[0m) [5.70% of initial]
[Iter 490/20000] Loss: 0.0135873 (Best: 0.0124032 @iter487) ([92m↓5.28%[0m) [5.40% of initial]
Iter:499, L1 loss=0.008601, Total loss=0.01467, Time:67
[Iter 500/20000] Loss: 0.0136697 (Best: 0.0124032 @iter487) ([91m↑0.61%[0m) [5.43% of initial]
[Iter 510/20000] Loss: 0.0136592 (Best: 0.0121301 @iter508) ([92m↓0.08%[0m) [5.43% of initial]
[Iter 520/20000] Loss: 0.0129796 (Best: 0.0120122 @iter511) ([92m↓4.97%[0m) [5.16% of initial]
[Iter 530/20000] Loss: 0.0126925 (Best: 0.0114398 @iter529) ([92m↓2.21%[0m) [5.04% of initial]
[Iter 540/20000] Loss: 0.0126578 (Best: 0.0110683 @iter538) ([92m↓0.27%[0m) [5.03% of initial]
[Iter 550/20000] Loss: 0.0122276 (Best: 0.0110683 @iter538) ([92m↓3.40%[0m) [4.86% of initial]
[Iter 560/20000] Loss: 0.0121977 (Best: 0.0106931 @iter556) ([92m↓0.24%[0m) [4.85% of initial]
[Iter 570/20000] Loss: 0.0118820 (Best: 0.0105075 @iter569) ([92m↓2.59%[0m) [4.72% of initial]
[Iter 580/20000] Loss: 0.0113367 (Best: 0.0102386 @iter574) ([92m↓4.59%[0m) [4.50% of initial]
[Iter 590/20000] Loss: 0.0114605 (Best: 0.0101285 @iter583) ([91m↑1.09%[0m) [4.55% of initial]
Iter:599, L1 loss=0.007037, Total loss=0.01187, Time:67
[Iter 600/20000] Loss: 0.0111215 (Best: 0.0100634 @iter594) ([92m↓2.96%[0m) [4.42% of initial]
[Iter 610/20000] Loss: 0.0254387 (Best: 0.0100634 @iter594) ([91m↑128.73%[0m) [10.11% of initial]
[Iter 620/20000] Loss: 0.0148657 (Best: 0.0100634 @iter594) ([92m↓41.56%[0m) [5.91% of initial]
[Iter 630/20000] Loss: 0.0124018 (Best: 0.0100634 @iter594) ([92m↓16.57%[0m) [4.93% of initial]
[Iter 640/20000] Loss: 0.0104789 (Best: 0.0095136 @iter640) ([92m↓15.51%[0m) [4.16% of initial]
[Iter 650/20000] Loss: 0.0106395 (Best: 0.0092970 @iter646) ([91m↑1.53%[0m) [4.23% of initial]
[Iter 660/20000] Loss: 0.0101213 (Best: 0.0088983 @iter655) ([92m↓4.87%[0m) [4.02% of initial]
[Iter 670/20000] Loss: 0.0098512 (Best: 0.0088541 @iter667) ([92m↓2.67%[0m) [3.91% of initial]
[Iter 680/20000] Loss: 0.0090625 (Best: 0.0083872 @iter680) ([92m↓8.01%[0m) [3.60% of initial]
[Iter 690/20000] Loss: 0.0091881 (Best: 0.0079931 @iter685) ([91m↑1.39%[0m) [3.65% of initial]
Iter:699, L1 loss=0.005749, Total loss=0.009774, Time:66
[Iter 700/20000] Loss: 0.0089370 (Best: 0.0079860 @iter695) ([92m↓2.73%[0m) [3.55% of initial]
[Iter 710/20000] Loss: 0.0083510 (Best: 0.0077150 @iter703) ([92m↓6.56%[0m) [3.32% of initial]
[Iter 720/20000] Loss: 0.0084274 (Best: 0.0076321 @iter715) ([91m↑0.91%[0m) [3.35% of initial]
[Iter 730/20000] Loss: 0.0085449 (Best: 0.0073606 @iter727) ([91m↑1.40%[0m) [3.39% of initial]
[Iter 740/20000] Loss: 0.0085830 (Best: 0.0073606 @iter727) ([91m↑0.45%[0m) [3.41% of initial]
[Iter 750/20000] Loss: 0.0080679 (Best: 0.0070611 @iter748) ([92m↓6.00%[0m) [3.21% of initial]
[Iter 760/20000] Loss: 0.0074209 (Best: 0.0069486 @iter754) ([92m↓8.02%[0m) [2.95% of initial]
[Iter 770/20000] Loss: 0.0076392 (Best: 0.0069486 @iter754) ([91m↑2.94%[0m) [3.03% of initial]
[Iter 780/20000] Loss: 0.0078898 (Best: 0.0067389 @iter775) ([91m↑3.28%[0m) [3.13% of initial]
[Iter 790/20000] Loss: 0.0075463 (Best: 0.0065679 @iter787) ([92m↓4.35%[0m) [3.00% of initial]
Iter:799, L1 loss=0.005022, Total loss=0.008195, Time:69
[Iter 800/20000] Loss: 0.0073414 (Best: 0.0065679 @iter787) ([92m↓2.72%[0m) [2.92% of initial]
[Iter 810/20000] Loss: 0.0163833 (Best: 0.0065679 @iter787) ([91m↑123.16%[0m) [6.51% of initial]
[Iter 820/20000] Loss: 0.0103581 (Best: 0.0065679 @iter787) ([92m↓36.78%[0m) [4.12% of initial]
[Iter 830/20000] Loss: 0.0088629 (Best: 0.0065679 @iter787) ([92m↓14.44%[0m) [3.52% of initial]
[Iter 840/20000] Loss: 0.0079485 (Best: 0.0065679 @iter787) ([92m↓10.32%[0m) [3.16% of initial]
[Iter 850/20000] Loss: 0.0073515 (Best: 0.0065531 @iter847) ([92m↓7.51%[0m) [2.92% of initial]
[Iter 860/20000] Loss: 0.0070007 (Best: 0.0063086 @iter853) ([92m↓4.77%[0m) [2.78% of initial]
[Iter 870/20000] Loss: 0.0066343 (Best: 0.0061350 @iter862) ([92m↓5.23%[0m) [2.64% of initial]
[Iter 880/20000] Loss: 0.0066366 (Best: 0.0059001 @iter875) ([91m↑0.03%[0m) [2.64% of initial]
[Iter 890/20000] Loss: 0.0062373 (Best: 0.0057106 @iter884) ([92m↓6.02%[0m) [2.48% of initial]
Iter:899, L1 loss=0.00365, Total loss=0.005644, Time:65
[Iter 900/20000] Loss: 0.0063795 (Best: 0.0056441 @iter899) ([91m↑2.28%[0m) [2.53% of initial]
[Iter 910/20000] Loss: 0.0064831 (Best: 0.0054517 @iter907) ([91m↑1.62%[0m) [2.58% of initial]
[Iter 920/20000] Loss: 0.0058697 (Best: 0.0053209 @iter919) ([92m↓9.46%[0m) [2.33% of initial]
[Iter 930/20000] Loss: 0.0061457 (Best: 0.0052296 @iter928) ([91m↑4.70%[0m) [2.44% of initial]
[Iter 940/20000] Loss: 0.0062491 (Best: 0.0051374 @iter938) ([91m↑1.68%[0m) [2.48% of initial]
[Iter 950/20000] Loss: 0.0058313 (Best: 0.0051374 @iter938) ([92m↓6.69%[0m) [2.32% of initial]
[Iter 960/20000] Loss: 0.0059704 (Best: 0.0051374 @iter938) ([91m↑2.38%[0m) [2.37% of initial]
[Iter 970/20000] Loss: 0.0059310 (Best: 0.0050990 @iter964) ([92m↓0.66%[0m) [2.36% of initial]
[Iter 980/20000] Loss: 0.0059929 (Best: 0.0050808 @iter979) ([91m↑1.04%[0m) [2.38% of initial]
[Iter 990/20000] Loss: 0.0060661 (Best: 0.0050808 @iter979) ([91m↑1.22%[0m) [2.41% of initial]
Iter:999, L1 loss=0.004419, Total loss=0.006571, Time:61
[Iter 1000/20000] Loss: 0.0061943 (Best: 0.0050808 @iter979) ([91m↑2.11%[0m) [2.46% of initial]
[Iter 1010/20000] Loss: 0.0116960 (Best: 0.0050808 @iter979) ([91m↑88.82%[0m) [4.65% of initial]
[Iter 1020/20000] Loss: 0.0082812 (Best: 0.0050808 @iter979) ([92m↓29.20%[0m) [3.29% of initial]
[Iter 1030/20000] Loss: 0.0067331 (Best: 0.0050808 @iter979) ([92m↓18.69%[0m) [2.68% of initial]
[Iter 1040/20000] Loss: 0.0059971 (Best: 0.0050808 @iter979) ([92m↓10.93%[0m) [2.38% of initial]
[Iter 1050/20000] Loss: 0.0058216 (Best: 0.0050281 @iter1049) ([92m↓2.93%[0m) [2.31% of initial]
[Iter 1060/20000] Loss: 0.0057654 (Best: 0.0048398 @iter1051) ([92m↓0.97%[0m) [2.29% of initial]
[Iter 1070/20000] Loss: 0.0053461 (Best: 0.0044569 @iter1069) ([92m↓7.27%[0m) [2.12% of initial]
[Iter 1080/20000] Loss: 0.0053189 (Best: 0.0044569 @iter1069) ([92m↓0.51%[0m) [2.11% of initial]
[Iter 1090/20000] Loss: 0.0050496 (Best: 0.0044569 @iter1069) ([92m↓5.06%[0m) [2.01% of initial]
Iter:1099, L1 loss=0.003379, Total loss=0.005024, Time:83
[Iter 1100/20000] Loss: 0.0049402 (Best: 0.0042348 @iter1093) ([92m↓2.17%[0m) [1.96% of initial]
[Iter 1110/20000] Loss: 0.0050714 (Best: 0.0042348 @iter1093) ([91m↑2.66%[0m) [2.01% of initial]
[Iter 1120/20000] Loss: 0.0049964 (Best: 0.0041392 @iter1117) ([92m↓1.48%[0m) [1.99% of initial]
[Iter 1130/20000] Loss: 0.0053560 (Best: 0.0041392 @iter1117) ([91m↑7.20%[0m) [2.13% of initial]
[Iter 1140/20000] Loss: 0.0048508 (Best: 0.0041392 @iter1117) ([92m↓9.43%[0m) [1.93% of initial]
[Iter 1150/20000] Loss: 0.0045545 (Best: 0.0040664 @iter1145) ([92m↓6.11%[0m) [1.81% of initial]
[Iter 1160/20000] Loss: 0.0050459 (Best: 0.0040664 @iter1145) ([91m↑10.79%[0m) [2.00% of initial]
[Iter 1170/20000] Loss: 0.0046922 (Best: 0.0040664 @iter1145) ([92m↓7.01%[0m) [1.86% of initial]
[Iter 1180/20000] Loss: 0.0042926 (Best: 0.0038951 @iter1180) ([92m↓8.52%[0m) [1.71% of initial]
[Iter 1190/20000] Loss: 0.0046079 (Best: 0.0038951 @iter1180) ([91m↑7.34%[0m) [1.83% of initial]
Iter:1199, L1 loss=0.003507, Total loss=0.004833, Time:70
[Iter 1200/20000] Loss: 0.0046445 (Best: 0.0038488 @iter1198) ([91m↑0.79%[0m) [1.85% of initial]
[Iter 1210/20000] Loss: 0.0106166 (Best: 0.0038488 @iter1198) ([91m↑128.59%[0m) [4.22% of initial]
[Iter 1220/20000] Loss: 0.0070228 (Best: 0.0038488 @iter1198) ([92m↓33.85%[0m) [2.79% of initial]
[Iter 1230/20000] Loss: 0.0060028 (Best: 0.0038488 @iter1198) ([92m↓14.52%[0m) [2.38% of initial]
[Iter 1240/20000] Loss: 0.0053570 (Best: 0.0038488 @iter1198) ([92m↓10.76%[0m) [2.13% of initial]
[Iter 1250/20000] Loss: 0.0047909 (Best: 0.0038488 @iter1198) ([92m↓10.57%[0m) [1.90% of initial]
[Iter 1260/20000] Loss: 0.0045496 (Best: 0.0036870 @iter1258) ([92m↓5.04%[0m) [1.81% of initial]
[Iter 1270/20000] Loss: 0.0041070 (Best: 0.0036870 @iter1258) ([92m↓9.73%[0m) [1.63% of initial]
[Iter 1280/20000] Loss: 0.0043083 (Best: 0.0034129 @iter1273) ([91m↑4.90%[0m) [1.71% of initial]
[Iter 1290/20000] Loss: 0.0041977 (Best: 0.0033459 @iter1285) ([92m↓2.57%[0m) [1.67% of initial]
Iter:1299, L1 loss=0.00278, Total loss=0.003556, Time:65
[Iter 1300/20000] Loss: 0.0039203 (Best: 0.0033249 @iter1294) ([92m↓6.61%[0m) [1.56% of initial]
[Iter 1310/20000] Loss: 0.0039470 (Best: 0.0032625 @iter1301) ([91m↑0.68%[0m) [1.57% of initial]
[Iter 1320/20000] Loss: 0.0038369 (Best: 0.0030705 @iter1319) ([92m↓2.79%[0m) [1.52% of initial]
[Iter 1330/20000] Loss: 0.0038755 (Best: 0.0030589 @iter1321) ([91m↑1.01%[0m) [1.54% of initial]
[Iter 1340/20000] Loss: 0.0036119 (Best: 0.0030589 @iter1321) ([92m↓6.80%[0m) [1.43% of initial]
[Iter 1350/20000] Loss: 0.0036784 (Best: 0.0030589 @iter1321) ([91m↑1.84%[0m) [1.46% of initial]
[Iter 1360/20000] Loss: 0.0037901 (Best: 0.0030589 @iter1321) ([91m↑3.04%[0m) [1.51% of initial]
[Iter 1370/20000] Loss: 0.0036190 (Best: 0.0030589 @iter1321) ([92m↓4.51%[0m) [1.44% of initial]
[Iter 1380/20000] Loss: 0.0039123 (Best: 0.0030589 @iter1321) ([91m↑8.10%[0m) [1.55% of initial]
[Iter 1390/20000] Loss: 0.0037819 (Best: 0.0030589 @iter1321) ([92m↓3.33%[0m) [1.50% of initial]
Iter:1399, L1 loss=0.002272, Total loss=0.002996, Time:68
[Iter 1400/20000] Loss: 0.0034877 (Best: 0.0029964 @iter1399) ([92m↓7.78%[0m) [1.39% of initial]
[Iter 1410/20000] Loss: 0.0085563 (Best: 0.0029964 @iter1399) ([91m↑145.33%[0m) [3.40% of initial]
[Iter 1420/20000] Loss: 0.0057914 (Best: 0.0029964 @iter1399) ([92m↓32.31%[0m) [2.30% of initial]
[Iter 1430/20000] Loss: 0.0048010 (Best: 0.0029964 @iter1399) ([92m↓17.10%[0m) [1.91% of initial]
[Iter 1440/20000] Loss: 0.0043870 (Best: 0.0029964 @iter1399) ([92m↓8.62%[0m) [1.74% of initial]
[Iter 1450/20000] Loss: 0.0035253 (Best: 0.0029964 @iter1399) ([92m↓19.64%[0m) [1.40% of initial]
[Iter 1460/20000] Loss: 0.0034687 (Best: 0.0029314 @iter1459) ([92m↓1.60%[0m) [1.38% of initial]
[Iter 1470/20000] Loss: 0.0033496 (Best: 0.0029314 @iter1459) ([92m↓3.44%[0m) [1.33% of initial]
[Iter 1480/20000] Loss: 0.0032184 (Best: 0.0027537 @iter1480) ([92m↓3.92%[0m) [1.28% of initial]
[Iter 1490/20000] Loss: 0.0031578 (Best: 0.0027537 @iter1480) ([92m↓1.88%[0m) [1.25% of initial]
Iter:1499, L1 loss=0.002537, Total loss=0.003319, Time:49
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126909 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693034 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374908 (Best: 0.1327880 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123916 (Best: 0.1098376 @iter40) ([92m↓18.26%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993461 (Best: 0.0965456 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936753 (Best: 0.0908539 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884487 (Best: 0.0869378 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851855 (Best: 0.0831028 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824092 (Best: 0.0801499 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07875, Time:48
[Iter 100/20000] Loss: 0.0786587 (Best: 0.0766218 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753201 (Best: 0.0731058 @iter106) ([92m↓4.24%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714359 (Best: 0.0685453 @iter118) ([92m↓5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0666982 (Best: 0.0642000 @iter130) ([92m↓6.63%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635226 (Best: 0.0612628 @iter140) ([92m↓4.76%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612688 (Best: 0.0583593 @iter148) ([92m↓3.55%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590275 (Best: 0.0559326 @iter157) ([92m↓3.66%[0m) [23.45% of initial]
[Iter 170/20000] Loss: 0.0563536 (Best: 0.0534801 @iter167) ([92m↓4.53%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523119 (Best: 0.0499735 @iter179) ([92m↓7.17%[0m) [20.78% of initial]
[Iter 190/20000] Loss: 0.0495139 (Best: 0.0477682 @iter188) ([92m↓5.35%[0m) [19.67% of initial]
Iter:199, L1 loss=0.0344, Total loss=0.04973, Time:53
[Iter 200/20000] Loss: 0.0477948 (Best: 0.0456063 @iter198) ([92m↓3.47%[0m) [18.99% of initial]
[Iter 210/20000] Loss: 0.0451795 (Best: 0.0429631 @iter209) ([92m↓5.47%[0m) [17.95% of initial]
[Iter 220/20000] Loss: 0.0441005 (Best: 0.0412497 @iter219) ([92m↓2.39%[0m) [17.52% of initial]
[Iter 230/20000] Loss: 0.0423699 (Best: 0.0399231 @iter227) ([92m↓3.92%[0m) [16.83% of initial]
[Iter 240/20000] Loss: 0.0402537 (Best: 0.0377806 @iter238) ([92m↓4.99%[0m) [15.99% of initial]
[Iter 250/20000] Loss: 0.0379242 (Best: 0.0361626 @iter248) ([92m↓5.79%[0m) [15.07% of initial]
[Iter 260/20000] Loss: 0.0358840 (Best: 0.0344035 @iter260) ([92m↓5.38%[0m) [14.26% of initial]
[Iter 270/20000] Loss: 0.0350094 (Best: 0.0328000 @iter269) ([92m↓2.44%[0m) [13.91% of initial]
[Iter 280/20000] Loss: 0.0347171 (Best: 0.0319505 @iter277) ([92m↓0.83%[0m) [13.79% of initial]
[Iter 290/20000] Loss: 0.0330574 (Best: 0.0304588 @iter287) ([92m↓4.78%[0m) [13.13% of initial]
Iter:299, L1 loss=0.02216, Total loss=0.03339, Time:56
[Iter 300/20000] Loss: 0.0308507 (Best: 0.0289971 @iter300) ([92m↓6.68%[0m) [12.26% of initial]
[Iter 310/20000] Loss: 0.0293937 (Best: 0.0274206 @iter310) ([92m↓4.72%[0m) [11.68% of initial]
[Iter 320/20000] Loss: 0.0280751 (Best: 0.0266170 @iter320) ([92m↓4.49%[0m) [11.15% of initial]
[Iter 330/20000] Loss: 0.0275219 (Best: 0.0256557 @iter330) ([92m↓1.97%[0m) [10.93% of initial]
[Iter 340/20000] Loss: 0.0255485 (Best: 0.0245730 @iter340) ([92m↓7.17%[0m) [10.15% of initial]
[Iter 350/20000] Loss: 0.0261559 (Best: 0.0235567 @iter349) ([91m↑2.38%[0m) [10.39% of initial]
[Iter 360/20000] Loss: 0.0248687 (Best: 0.0227117 @iter358) ([92m↓4.92%[0m) [9.88% of initial]
[Iter 370/20000] Loss: 0.0247214 (Best: 0.0222210 @iter368) ([92m↓0.59%[0m) [9.82% of initial]
[Iter 380/20000] Loss: 0.0222974 (Best: 0.0210791 @iter379) ([92m↓9.81%[0m) [8.86% of initial]
[Iter 390/20000] Loss: 0.0218689 (Best: 0.0203072 @iter390) ([92m↓1.92%[0m) [8.69% of initial]
Iter:399, L1 loss=0.01349, Total loss=0.02105, Time:41
[Iter 400/20000] Loss: 0.0204634 (Best: 0.0189341 @iter400) ([92m↓6.43%[0m) [8.13% of initial]
[Iter 410/20000] Loss: 0.0196727 (Best: 0.0186161 @iter410) ([92m↓3.86%[0m) [7.82% of initial]
[Iter 420/20000] Loss: 0.0200051 (Best: 0.0179246 @iter418) ([91m↑1.69%[0m) [7.95% of initial]
[Iter 430/20000] Loss: 0.0177421 (Best: 0.0169050 @iter430) ([92m↓11.31%[0m) [7.05% of initial]
[Iter 440/20000] Loss: 0.0181684 (Best: 0.0166116 @iter434) ([91m↑2.40%[0m) [7.22% of initial]
[Iter 450/20000] Loss: 0.0172636 (Best: 0.0154094 @iter445) ([92m↓4.98%[0m) [6.86% of initial]
[Iter 460/20000] Loss: 0.0164645 (Best: 0.0146269 @iter458) ([92m↓4.63%[0m) [6.54% of initial]
[Iter 470/20000] Loss: 0.0149725 (Best: 0.0141710 @iter470) ([92m↓9.06%[0m) [5.95% of initial]
[Iter 480/20000] Loss: 0.0146552 (Best: 0.0132193 @iter479) ([92m↓2.12%[0m) [5.82% of initial]
[Iter 490/20000] Loss: 0.0136957 (Best: 0.0127359 @iter490) ([92m↓6.55%[0m) [5.44% of initial]
Iter:499, L1 loss=0.008178, Total loss=0.01449, Time:37
[Iter 500/20000] Loss: 0.0135423 (Best: 0.0122868 @iter498) ([92m↓1.12%[0m) [5.38% of initial]
[Iter 510/20000] Loss: 0.0137898 (Best: 0.0121416 @iter503) ([91m↑1.83%[0m) [5.48% of initial]
[Iter 520/20000] Loss: 0.0126293 (Best: 0.0117256 @iter519) ([92m↓8.42%[0m) [5.02% of initial]
[Iter 530/20000] Loss: 0.0124703 (Best: 0.0113078 @iter529) ([92m↓1.26%[0m) [4.95% of initial]
[Iter 540/20000] Loss: 0.0123889 (Best: 0.0111394 @iter538) ([92m↓0.65%[0m) [4.92% of initial]
[Iter 550/20000] Loss: 0.0119414 (Best: 0.0107962 @iter548) ([92m↓3.61%[0m) [4.74% of initial]
[Iter 560/20000] Loss: 0.0119962 (Best: 0.0104496 @iter556) ([91m↑0.46%[0m) [4.77% of initial]
[Iter 570/20000] Loss: 0.0115524 (Best: 0.0103309 @iter569) ([92m↓3.70%[0m) [4.59% of initial]
[Iter 580/20000] Loss: 0.0111640 (Best: 0.0100471 @iter578) ([92m↓3.36%[0m) [4.44% of initial]
[Iter 590/20000] Loss: 0.0112221 (Best: 0.0099127 @iter583) ([91m↑0.52%[0m) [4.46% of initial]
Iter:599, L1 loss=0.006836, Total loss=0.01188, Time:42
[Iter 600/20000] Loss: 0.0109357 (Best: 0.0099127 @iter583) ([92m↓2.55%[0m) [4.34% of initial]
[Iter 610/20000] Loss: 0.0200125 (Best: 0.0099127 @iter583) ([91m↑83.00%[0m) [7.95% of initial]
[Iter 620/20000] Loss: 0.0140704 (Best: 0.0099127 @iter583) ([92m↓29.69%[0m) [5.59% of initial]
[Iter 630/20000] Loss: 0.0119376 (Best: 0.0099127 @iter583) ([92m↓15.16%[0m) [4.74% of initial]
[Iter 640/20000] Loss: 0.0102024 (Best: 0.0092101 @iter640) ([92m↓14.54%[0m) [4.05% of initial]
[Iter 650/20000] Loss: 0.0105017 (Best: 0.0089995 @iter646) ([91m↑2.93%[0m) [4.17% of initial]
[Iter 660/20000] Loss: 0.0098642 (Best: 0.0085692 @iter659) ([92m↓6.07%[0m) [3.92% of initial]
[Iter 670/20000] Loss: 0.0095439 (Best: 0.0082892 @iter667) ([92m↓3.25%[0m) [3.79% of initial]
[Iter 680/20000] Loss: 0.0087921 (Best: 0.0080804 @iter674) ([92m↓7.88%[0m) [3.49% of initial]
[Iter 690/20000] Loss: 0.0090558 (Best: 0.0077937 @iter685) ([91m↑3.00%[0m) [3.60% of initial]
Iter:699, L1 loss=0.005721, Total loss=0.01015, Time:53
[Iter 700/20000] Loss: 0.0091834 (Best: 0.0077790 @iter695) ([91m↑1.41%[0m) [3.65% of initial]
[Iter 710/20000] Loss: 0.0084408 (Best: 0.0077790 @iter695) ([92m↓8.09%[0m) [3.35% of initial]
[Iter 720/20000] Loss: 0.0084748 (Best: 0.0075915 @iter715) ([91m↑0.40%[0m) [3.37% of initial]
[Iter 730/20000] Loss: 0.0086432 (Best: 0.0074606 @iter727) ([91m↑1.99%[0m) [3.43% of initial]
[Iter 740/20000] Loss: 0.0087533 (Best: 0.0074301 @iter736) ([91m↑1.27%[0m) [3.48% of initial]
[Iter 750/20000] Loss: 0.0081717 (Best: 0.0069642 @iter748) ([92m↓6.64%[0m) [3.25% of initial]
[Iter 760/20000] Loss: 0.0075733 (Best: 0.0069103 @iter751) ([92m↓7.32%[0m) [3.01% of initial]
[Iter 770/20000] Loss: 0.0076200 (Best: 0.0069076 @iter769) ([91m↑0.62%[0m) [3.03% of initial]
[Iter 780/20000] Loss: 0.0077366 (Best: 0.0065732 @iter775) ([91m↑1.53%[0m) [3.07% of initial]
[Iter 790/20000] Loss: 0.0075658 (Best: 0.0064276 @iter787) ([92m↓2.21%[0m) [3.01% of initial]
Iter:799, L1 loss=0.004994, Total loss=0.007934, Time:47
[Iter 800/20000] Loss: 0.0071905 (Best: 0.0063415 @iter796) ([92m↓4.96%[0m) [2.86% of initial]
[Iter 810/20000] Loss: 0.0160313 (Best: 0.0063415 @iter796) ([91m↑122.95%[0m) [6.37% of initial]
[Iter 820/20000] Loss: 0.0104157 (Best: 0.0063415 @iter796) ([92m↓35.03%[0m) [4.14% of initial]
[Iter 830/20000] Loss: 0.0087270 (Best: 0.0063415 @iter796) ([92m↓16.21%[0m) [3.47% of initial]
[Iter 840/20000] Loss: 0.0079040 (Best: 0.0063415 @iter796) ([92m↓9.43%[0m) [3.14% of initial]
[Iter 850/20000] Loss: 0.0073748 (Best: 0.0063415 @iter796) ([92m↓6.70%[0m) [2.93% of initial]
[Iter 860/20000] Loss: 0.0069431 (Best: 0.0062110 @iter856) ([92m↓5.85%[0m) [2.76% of initial]
[Iter 870/20000] Loss: 0.0065997 (Best: 0.0060265 @iter862) ([92m↓4.95%[0m) [2.62% of initial]
[Iter 880/20000] Loss: 0.0065695 (Best: 0.0058278 @iter875) ([92m↓0.46%[0m) [2.61% of initial]
[Iter 890/20000] Loss: 0.0062378 (Best: 0.0056131 @iter884) ([92m↓5.05%[0m) [2.48% of initial]
Iter:899, L1 loss=0.003658, Total loss=0.005466, Time:43
[Iter 900/20000] Loss: 0.0063707 (Best: 0.0054659 @iter899) ([91m↑2.13%[0m) [2.53% of initial]
[Iter 910/20000] Loss: 0.0064485 (Best: 0.0053661 @iter907) ([91m↑1.22%[0m) [2.56% of initial]
[Iter 920/20000] Loss: 0.0058822 (Best: 0.0052031 @iter916) ([92m↓8.78%[0m) [2.34% of initial]
[Iter 930/20000] Loss: 0.0061497 (Best: 0.0051763 @iter928) ([91m↑4.55%[0m) [2.44% of initial]
[Iter 940/20000] Loss: 0.0061859 (Best: 0.0050489 @iter938) ([91m↑0.59%[0m) [2.46% of initial]
[Iter 950/20000] Loss: 0.0057083 (Best: 0.0050489 @iter938) ([92m↓7.72%[0m) [2.27% of initial]
[Iter 960/20000] Loss: 0.0058745 (Best: 0.0050489 @iter938) ([91m↑2.91%[0m) [2.33% of initial]
[Iter 970/20000] Loss: 0.0058631 (Best: 0.0049641 @iter964) ([92m↓0.19%[0m) [2.33% of initial]
[Iter 980/20000] Loss: 0.0059828 (Best: 0.0049506 @iter974) ([91m↑2.04%[0m) [2.38% of initial]
[Iter 990/20000] Loss: 0.0059351 (Best: 0.0049506 @iter974) ([92m↓0.80%[0m) [2.36% of initial]
Iter:999, L1 loss=0.004379, Total loss=0.006564, Time:54
[Iter 1000/20000] Loss: 0.0061621 (Best: 0.0049506 @iter974) ([91m↑3.82%[0m) [2.45% of initial]
Pruning 1005 points (7.3%) from gaussian0 at iteration 1000
Pruning 1040 points (7.6%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0134022 (Best: 0.0049506 @iter974) ([91m↑117.49%[0m) [5.32% of initial]
[Iter 1020/20000] Loss: 0.0095400 (Best: 0.0049506 @iter974) ([92m↓28.82%[0m) [3.79% of initial]
[Iter 1030/20000] Loss: 0.0077734 (Best: 0.0049506 @iter974) ([92m↓18.52%[0m) [3.09% of initial]
[Iter 1040/20000] Loss: 0.0071316 (Best: 0.0049506 @iter974) ([92m↓8.26%[0m) [2.83% of initial]
[Iter 1050/20000] Loss: 0.0067807 (Best: 0.0049506 @iter974) ([92m↓4.92%[0m) [2.69% of initial]
[Iter 1060/20000] Loss: 0.0064491 (Best: 0.0049506 @iter974) ([92m↓4.89%[0m) [2.56% of initial]
[Iter 1070/20000] Loss: 0.0062501 (Best: 0.0049506 @iter974) ([92m↓3.09%[0m) [2.48% of initial]
[Iter 1080/20000] Loss: 0.0059636 (Best: 0.0049506 @iter974) ([92m↓4.58%[0m) [2.37% of initial]
[Iter 1090/20000] Loss: 0.0059379 (Best: 0.0049506 @iter974) ([92m↓0.43%[0m) [2.36% of initial]
Iter:1099, L1 loss=0.003951, Total loss=0.005979, Time:55
[Iter 1100/20000] Loss: 0.0059034 (Best: 0.0049506 @iter974) ([92m↓0.58%[0m) [2.35% of initial]
[Iter 1110/20000] Loss: 0.0057265 (Best: 0.0049506 @iter974) ([92m↓3.00%[0m) [2.28% of initial]
[Iter 1120/20000] Loss: 0.0057714 (Best: 0.0048882 @iter1117) ([91m↑0.78%[0m) [2.29% of initial]
[Iter 1130/20000] Loss: 0.0058840 (Best: 0.0048882 @iter1117) ([91m↑1.95%[0m) [2.34% of initial]
[Iter 1140/20000] Loss: 0.0055070 (Best: 0.0047277 @iter1135) ([92m↓6.41%[0m) [2.19% of initial]
[Iter 1150/20000] Loss: 0.0051092 (Best: 0.0047037 @iter1145) ([92m↓7.22%[0m) [2.03% of initial]
[Iter 1160/20000] Loss: 0.0056508 (Best: 0.0046249 @iter1156) ([91m↑10.60%[0m) [2.25% of initial]
[Iter 1170/20000] Loss: 0.0052524 (Best: 0.0046249 @iter1156) ([92m↓7.05%[0m) [2.09% of initial]
[Iter 1180/20000] Loss: 0.0049025 (Best: 0.0045414 @iter1180) ([92m↓6.66%[0m) [1.95% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
[Iter 1190/20000] Loss: 0.0052623 (Best: 0.0044911 @iter1183) ([91m↑7.34%[0m) [2.09% of initial]
Iter:1199, L1 loss=0.003816, Total loss=0.005546, Time:37
[Iter 1200/20000] Loss: 0.0051889 (Best: 0.0044264 @iter1198) ([92m↓1.40%[0m) [2.06% of initial]
[Iter 1210/20000] Loss: 0.0122192 (Best: 0.0044264 @iter1198) ([91m↑135.49%[0m) [4.85% of initial]
[Iter 1220/20000] Loss: 0.0078875 (Best: 0.0044264 @iter1198) ([92m↓35.45%[0m) [3.13% of initial]
[Iter 1230/20000] Loss: 0.0065709 (Best: 0.0044264 @iter1198) ([92m↓16.69%[0m) [2.61% of initial]
[Iter 1240/20000] Loss: 0.0059777 (Best: 0.0044264 @iter1198) ([92m↓9.03%[0m) [2.37% of initial]
[Iter 1250/20000] Loss: 0.0052890 (Best: 0.0044264 @iter1198) ([92m↓11.52%[0m) [2.10% of initial]
[Iter 1260/20000] Loss: 0.0051323 (Best: 0.0042927 @iter1258) ([92m↓2.96%[0m) [2.04% of initial]
[Iter 1270/20000] Loss: 0.0048803 (Best: 0.0042927 @iter1258) ([92m↓4.91%[0m) [1.94% of initial]
[Iter 1280/20000] Loss: 0.0052094 (Best: 0.0042927 @iter1258) ([91m↑6.74%[0m) [2.07% of initial]
[Iter 1290/20000] Loss: 0.0050211 (Best: 0.0041731 @iter1288) ([92m↓3.61%[0m) [1.99% of initial]
Iter:1299, L1 loss=0.003211, Total loss=0.00451, Time:38
[Iter 1300/20000] Loss: 0.0046908 (Best: 0.0041731 @iter1288) ([92m↓6.58%[0m) [1.86% of initial]
[Iter 1310/20000] Loss: 0.0047184 (Best: 0.0040783 @iter1301) ([91m↑0.59%[0m) [1.87% of initial]
[Iter 1320/20000] Loss: 0.0045527 (Best: 0.0038752 @iter1319) ([92m↓3.51%[0m) [1.81% of initial]
[Iter 1330/20000] Loss: 0.0044925 (Best: 0.0037264 @iter1321) ([92m↓1.32%[0m) [1.78% of initial]
[Iter 1340/20000] Loss: 0.0042142 (Best: 0.0037264 @iter1321) ([92m↓6.19%[0m) [1.67% of initial]
[Iter 1350/20000] Loss: 0.0042399 (Best: 0.0037062 @iter1346) ([91m↑0.61%[0m) [1.68% of initial]
[Iter 1360/20000] Loss: 0.0043250 (Best: 0.0036866 @iter1351) ([91m↑2.01%[0m) [1.72% of initial]
[Iter 1370/20000] Loss: 0.0041919 (Best: 0.0036866 @iter1351) ([92m↓3.08%[0m) [1.67% of initial]
[Iter 1380/20000] Loss: 0.0043453 (Best: 0.0035705 @iter1375) ([91m↑3.66%[0m) [1.73% of initial]
[Iter 1390/20000] Loss: 0.0041340 (Best: 0.0035705 @iter1375) ([92m↓4.86%[0m) [1.64% of initial]
Iter:1399, L1 loss=0.002483, Total loss=0.003347, Time:61
[Iter 1400/20000] Loss: 0.0038561 (Best: 0.0033468 @iter1399) ([92m↓6.72%[0m) [1.53% of initial]
[Iter 1410/20000] Loss: 0.0097220 (Best: 0.0033468 @iter1399) ([91m↑152.12%[0m) [3.86% of initial]
[Iter 1420/20000] Loss: 0.0067470 (Best: 0.0033468 @iter1399) ([92m↓30.60%[0m) [2.68% of initial]
[Iter 1430/20000] Loss: 0.0056550 (Best: 0.0033468 @iter1399) ([92m↓16.18%[0m) [2.25% of initial]
[Iter 1440/20000] Loss: 0.0049958 (Best: 0.0033468 @iter1399) ([92m↓11.66%[0m) [1.98% of initial]
[Iter 1450/20000] Loss: 0.0039776 (Best: 0.0033468 @iter1399) ([92m↓20.38%[0m) [1.58% of initial]
[Iter 1460/20000] Loss: 0.0039268 (Best: 0.0033468 @iter1399) ([92m↓1.28%[0m) [1.56% of initial]
[Iter 1470/20000] Loss: 0.0038646 (Best: 0.0033468 @iter1399) ([92m↓1.58%[0m) [1.54% of initial]
[Iter 1480/20000] Loss: 0.0036313 (Best: 0.0031429 @iter1480) ([92m↓6.04%[0m) [1.44% of initial]
[Iter 1490/20000] Loss: 0.0036671 (Best: 0.0031429 @iter1480) ([91m↑0.99%[0m) [1.46% of initial]
Iter:1499, L1 loss=0.002713, Total loss=0.003856, Time:62
[Iter 1500/20000] Loss: 0.0036290 (Best: 0.0031429 @iter1480) ([92m↓1.04%[0m) [1.44% of initial]
Pruning 736 points (2.9%) from gaussian0 at iteration 1500
Pruning 740 points (3.0%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0048939 (Best: 0.0031429 @iter1480) ([91m↑34.86%[0m) [1.94% of initial]
[Iter 1520/20000] Loss: 0.0040842 (Best: 0.0031429 @iter1480) ([92m↓16.55%[0m) [1.62% of initial]
[Iter 1530/20000] Loss: 0.0039135 (Best: 0.0031429 @iter1480) ([92m↓4.18%[0m) [1.55% of initial]
[Iter 1540/20000] Loss: 0.0037196 (Best: 0.0031429 @iter1480) ([92m↓4.95%[0m) [1.48% of initial]
[Iter 1550/20000] Loss: 0.0034671 (Best: 0.0030856 @iter1543) ([92m↓6.79%[0m) [1.38% of initial]
[Iter 1560/20000] Loss: 0.0036752 (Best: 0.0030243 @iter1558) ([91m↑6.00%[0m) [1.46% of initial]
[Iter 1570/20000] Loss: 0.0033468 (Best: 0.0030243 @iter1558) ([92m↓8.94%[0m) [1.33% of initial]
[Iter 1580/20000] Loss: 0.0032481 (Best: 0.0027825 @iter1579) ([92m↓2.95%[0m) [1.29% of initial]
[Iter 1590/20000] Loss: 0.0031526 (Best: 0.0027825 @iter1579) ([92m↓2.94%[0m) [1.25% of initial]
Iter:1599, L1 loss=0.00289, Total loss=0.003748, Time:38
[Iter 1600/20000] Loss: 0.0034425 (Best: 0.0027557 @iter1591) ([91m↑9.19%[0m) [1.37% of initial]
[Iter 1610/20000] Loss: 0.0094753 (Best: 0.0027557 @iter1591) ([91m↑175.24%[0m) [3.76% of initial]
[Iter 1620/20000] Loss: 0.0063114 (Best: 0.0027557 @iter1591) ([92m↓33.39%[0m) [2.51% of initial]
[Iter 1630/20000] Loss: 0.0047083 (Best: 0.0027557 @iter1591) ([92m↓25.40%[0m) [1.87% of initial]
[Iter 1640/20000] Loss: 0.0042892 (Best: 0.0027557 @iter1591) ([92m↓8.90%[0m) [1.70% of initial]
[Iter 1650/20000] Loss: 0.0037994 (Best: 0.0027557 @iter1591) ([92m↓11.42%[0m) [1.51% of initial]
[Iter 1660/20000] Loss: 0.0033741 (Best: 0.0027557 @iter1591) ([92m↓11.19%[0m) [1.34% of initial]
[Iter 1670/20000] Loss: 0.0031993 (Best: 0.0027557 @iter1591) ([92m↓5.18%[0m) [1.27% of initial]
[Iter 1680/20000] Loss: 0.0032409 (Best: 0.0027557 @iter1591) ([91m↑1.30%[0m) [1.29% of initial]
[Iter 1690/20000] Loss: 0.0033516 (Best: 0.0027557 @iter1591) ([91m↑3.41%[0m) [1.33% of initial]
Iter:1699, L1 loss=0.002646, Total loss=0.003378, Time:51
[Iter 1700/20000] Loss: 0.0031302 (Best: 0.0027557 @iter1591) ([92m↓6.61%[0m) [1.24% of initial]
[Iter 1710/20000] Loss: 0.0033169 (Best: 0.0027542 @iter1705) ([91m↑5.96%[0m) [1.32% of initial]
[Iter 1720/20000] Loss: 0.0028893 (Best: 0.0026997 @iter1720) ([92m↓12.89%[0m) [1.15% of initial]
[Iter 1730/20000] Loss: 0.0031301 (Best: 0.0026997 @iter1720) ([91m↑8.34%[0m) [1.24% of initial]
[Iter 1740/20000] Loss: 0.0031776 (Best: 0.0026997 @iter1720) ([91m↑1.52%[0m) [1.26% of initial]
[Iter 1750/20000] Loss: 0.0027943 (Best: 0.0025692 @iter1750) ([92m↓12.06%[0m) [1.11% of initial]
[Iter 1760/20000] Loss: 0.0029512 (Best: 0.0025692 @iter1750) ([91m↑5.62%[0m) [1.17% of initial]
[Iter 1770/20000] Loss: 0.0028737 (Best: 0.0024208 @iter1762) ([92m↓2.63%[0m) [1.14% of initial]
[Iter 1780/20000] Loss: 0.0028723 (Best: 0.0024208 @iter1762) ([92m↓0.05%[0m) [1.14% of initial]
[Iter 1790/20000] Loss: 0.0025457 (Best: 0.0021777 @iter1789) ([92m↓11.37%[0m) [1.01% of initial]
Iter:1799, L1 loss=0.00191, Total loss=0.002324, Time:45
[Iter 1800/20000] Loss: 0.0025618 (Best: 0.0021777 @iter1789) ([91m↑0.63%[0m) [1.02% of initial]
[Iter 1810/20000] Loss: 0.0085945 (Best: 0.0021777 @iter1789) ([91m↑235.49%[0m) [3.41% of initial]
[Iter 1820/20000] Loss: 0.0052177 (Best: 0.0021777 @iter1789) ([92m↓39.29%[0m) [2.07% of initial]
[Iter 1830/20000] Loss: 0.0044280 (Best: 0.0021777 @iter1789) ([92m↓15.13%[0m) [1.76% of initial]
[Iter 1840/20000] Loss: 0.0032927 (Best: 0.0021777 @iter1789) ([92m↓25.64%[0m) [1.31% of initial]
[Iter 1850/20000] Loss: 0.0030386 (Best: 0.0021777 @iter1789) ([92m↓7.72%[0m) [1.21% of initial]
[Iter 1860/20000] Loss: 0.0031098 (Best: 0.0021777 @iter1789) ([91m↑2.34%[0m) [1.24% of initial]
[Iter 1870/20000] Loss: 0.0027626 (Best: 0.0021777 @iter1789) ([92m↓11.16%[0m) [1.10% of initial]
[Iter 1880/20000] Loss: 0.0026573 (Best: 0.0021777 @iter1789) ([92m↓3.81%[0m) [1.06% of initial]
[Iter 1890/20000] Loss: 0.0022767 (Best: 0.0021198 @iter1890) ([92m↓14.33%[0m) [0.90% of initial]
Iter:1899, L1 loss=0.001943, Total loss=0.002348, Time:48
[Iter 1900/20000] Loss: 0.0023709 (Best: 0.0020048 @iter1891) ([91m↑4.14%[0m) [0.94% of initial]
[Iter 1910/20000] Loss: 0.0023551 (Best: 0.0019924 @iter1903) ([92m↓0.67%[0m) [0.94% of initial]
[Iter 1920/20000] Loss: 0.0024000 (Best: 0.0019924 @iter1903) ([91m↑1.91%[0m) [0.95% of initial]
[Iter 1930/20000] Loss: 0.0020572 (Best: 0.0018916 @iter1930) ([92m↓14.28%[0m) [0.82% of initial]
[Iter 1940/20000] Loss: 0.0021520 (Best: 0.0018348 @iter1939) ([91m↑4.61%[0m) [0.85% of initial]
[Iter 1950/20000] Loss: 0.0022877 (Best: 0.0018348 @iter1939) ([91m↑6.30%[0m) [0.91% of initial]
[Iter 1960/20000] Loss: 0.0021126 (Best: 0.0018348 @iter1939) ([92m↓7.66%[0m) [0.84% of initial]
[Iter 1970/20000] Loss: 0.0019652 (Best: 0.0017802 @iter1963) ([92m↓6.97%[0m) [0.78% of initial]
[Iter 1980/20000] Loss: 0.0023215 (Best: 0.0017802 @iter1963) ([91m↑18.13%[0m) [0.92% of initial]
[Iter 1990/20000] Loss: 0.0020722 (Best: 0.0017802 @iter1963) ([92m↓10.74%[0m) [0.82% of initial]
Iter:1999, L1 loss=0.001739, Total loss=0.001899, Time:40
[Iter 2000/20000] Loss: 0.0021476 (Best: 0.0017189 @iter1996) ([91m↑3.64%[0m) [0.85% of initial]
Testing Speed: 92.60662347692575 fps
Testing Time: 0.5399181842803955 s

[ITER 2000] Evaluating test: SSIM = 0.8664894211292267, PSNR = 17.72182538986206
Testing Speed: 93.02071412730095 fps
Testing Time: 0.03225088119506836 s

[ITER 2000] Evaluating train: SSIM = 0.999950607617696, PSNR = 48.604139963785805
Iter:2000, total_points:43200
Pruning 644 points (1.2%) from gaussian0 at iteration 2000
Pruning 614 points (1.1%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.0081362 (Best: 0.0017189 @iter1996) ([91m↑278.86%[0m) [3.23% of initial]
[Iter 2020/20000] Loss: 0.0051225 (Best: 0.0017189 @iter1996) ([92m↓37.04%[0m) [2.04% of initial]
[Iter 2030/20000] Loss: 0.0039549 (Best: 0.0017189 @iter1996) ([92m↓22.79%[0m) [1.57% of initial]
[Iter 2040/20000] Loss: 0.0032845 (Best: 0.0017189 @iter1996) ([92m↓16.95%[0m) [1.30% of initial]
[Iter 2050/20000] Loss: 0.0028784 (Best: 0.0017189 @iter1996) ([92m↓12.36%[0m) [1.14% of initial]
[Iter 2060/20000] Loss: 0.0025248 (Best: 0.0017189 @iter1996) ([92m↓12.29%[0m) [1.00% of initial]
[Iter 2070/20000] Loss: 0.0026417 (Best: 0.0017189 @iter1996) ([91m↑4.63%[0m) [1.05% of initial]
[Iter 2080/20000] Loss: 0.0024691 (Best: 0.0017189 @iter1996) ([92m↓6.53%[0m) [0.98% of initial]
[Iter 2090/20000] Loss: 0.0024338 (Best: 0.0017189 @iter1996) ([92m↓1.43%[0m) [0.97% of initial]
Iter:2099, L1 loss=0.001947, Total loss=0.002348, Time:55
[Iter 2100/20000] Loss: 0.0023179 (Best: 0.0017189 @iter1996) ([92m↓4.76%[0m) [0.92% of initial]
[Iter 2110/20000] Loss: 0.0021787 (Best: 0.0017189 @iter1996) ([92m↓6.01%[0m) [0.87% of initial]
[Iter 2120/20000] Loss: 0.0020017 (Best: 0.0017189 @iter1996) ([92m↓8.12%[0m) [0.80% of initial]
[Iter 2130/20000] Loss: 0.0021414 (Best: 0.0017189 @iter1996) ([91m↑6.98%[0m) [0.85% of initial]
[Iter 2140/20000] Loss: 0.0021922 (Best: 0.0017189 @iter1996) ([91m↑2.37%[0m) [0.87% of initial]
[Iter 2150/20000] Loss: 0.0021887 (Best: 0.0017189 @iter1996) ([92m↓0.16%[0m) [0.87% of initial]
[Iter 2160/20000] Loss: 0.0020097 (Best: 0.0017189 @iter1996) ([92m↓8.18%[0m) [0.80% of initial]
[Iter 2170/20000] Loss: 0.0020577 (Best: 0.0017059 @iter2167) ([91m↑2.39%[0m) [0.82% of initial]
[Iter 2180/20000] Loss: 0.0017804 (Best: 0.0016424 @iter2180) ([92m↓13.47%[0m) [0.71% of initial]
[Iter 2190/20000] Loss: 0.0020511 (Best: 0.0016424 @iter2180) ([91m↑15.21%[0m) [0.81% of initial]
Iter:2199, L1 loss=0.001693, Total loss=0.001947, Time:57
[Iter 2200/20000] Loss: 0.0020416 (Best: 0.0016424 @iter2180) ([92m↓0.47%[0m) [0.81% of initial]
[Iter 2210/20000] Loss: 0.0085169 (Best: 0.0016424 @iter2180) ([91m↑317.17%[0m) [3.38% of initial]
[Iter 2220/20000] Loss: 0.0049434 (Best: 0.0016424 @iter2180) ([92m↓41.96%[0m) [1.96% of initial]
[Iter 2230/20000] Loss: 0.0031779 (Best: 0.0016424 @iter2180) ([92m↓35.71%[0m) [1.26% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 2240/20000] Loss: 0.0026633 (Best: 0.0016424 @iter2180) ([92m↓16.19%[0m) [1.06% of initial]
[Iter 2250/20000] Loss: 0.0025023 (Best: 0.0016424 @iter2180) ([92m↓6.04%[0m) [0.99% of initial]
[Iter 2260/20000] Loss: 0.0020978 (Best: 0.0016424 @iter2180) ([92m↓16.17%[0m) [0.83% of initial]
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 2270/20000] Loss: 0.0021425 (Best: 0.0016424 @iter2180) ([91m↑2.13%[0m) [0.85% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 2280/20000] Loss: 0.0017927 (Best: 0.0016424 @iter2180) ([92m↓16.33%[0m) [0.71% of initial]
[Iter 30/20000] Loss: 0.1374910 (Best: 0.1327888 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 2290/20000] Loss: 0.0017490 (Best: 0.0015032 @iter2287) ([92m↓2.44%[0m) [0.69% of initial]
[Iter 40/20000] Loss: 0.1123923 (Best: 0.1098373 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
Iter:2299, L1 loss=0.001515, Total loss=0.001718, Time:56
[Iter 2300/20000] Loss: 0.0020150 (Best: 0.0015032 @iter2287) ([91m↑15.21%[0m) [0.80% of initial]
[Iter 50/20000] Loss: 0.0993457 (Best: 0.0965482 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 2310/20000] Loss: 0.0019101 (Best: 0.0015032 @iter2287) ([92m↓5.21%[0m) [0.76% of initial]
[Iter 60/20000] Loss: 0.0936775 (Best: 0.0908547 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 2320/20000] Loss: 0.0016570 (Best: 0.0014946 @iter2320) ([92m↓13.25%[0m) [0.66% of initial]
[Iter 70/20000] Loss: 0.0884519 (Best: 0.0869392 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 2330/20000] Loss: 0.0016334 (Best: 0.0014515 @iter2329) ([92m↓1.42%[0m) [0.65% of initial]
[Iter 80/20000] Loss: 0.0851842 (Best: 0.0830954 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 2340/20000] Loss: 0.0016665 (Best: 0.0014302 @iter2338) ([91m↑2.02%[0m) [0.66% of initial]
[Iter 90/20000] Loss: 0.0824116 (Best: 0.0801662 @iter88) ([92m↓3.25%[0m) [32.74% of initial]
[Iter 2350/20000] Loss: 0.0017642 (Best: 0.0014302 @iter2338) ([91m↑5.87%[0m) [0.70% of initial]
Iter:99, L1 loss=0.05724, Total loss=0.07877, Time:42
[Iter 100/20000] Loss: 0.0786681 (Best: 0.0766230 @iter97) ([92m↓4.54%[0m) [31.25% of initial]
[Iter 2360/20000] Loss: 0.0015792 (Best: 0.0013573 @iter2359) ([92m↓10.48%[0m) [0.63% of initial]
[Iter 110/20000] Loss: 0.0753137 (Best: 0.0731465 @iter106) ([92m↓4.26%[0m) [29.92% of initial]
[Iter 2370/20000] Loss: 0.0017109 (Best: 0.0013573 @iter2359) ([91m↑8.34%[0m) [0.68% of initial]
[Iter 120/20000] Loss: 0.0714321 (Best: 0.0685692 @iter118) ([92m↓5.15%[0m) [28.38% of initial]
[Iter 2380/20000] Loss: 0.0017622 (Best: 0.0013573 @iter2359) ([91m↑3.00%[0m) [0.70% of initial]
[Iter 130/20000] Loss: 0.0666941 (Best: 0.0641910 @iter130) ([92m↓6.63%[0m) [26.50% of initial]
[Iter 2390/20000] Loss: 0.0019079 (Best: 0.0013573 @iter2359) ([91m↑8.27%[0m) [0.76% of initial]
[Iter 140/20000] Loss: 0.0635335 (Best: 0.0612760 @iter140) ([92m↓4.74%[0m) [25.24% of initial]
Iter:2399, L1 loss=0.001416, Total loss=0.001565, Time:50
[Iter 2400/20000] Loss: 0.0016350 (Best: 0.0013573 @iter2359) ([92m↓14.30%[0m) [0.65% of initial]
[Iter 150/20000] Loss: 0.0612772 (Best: 0.0584001 @iter148) ([92m↓3.55%[0m) [24.34% of initial]
[Iter 2410/20000] Loss: 0.0068331 (Best: 0.0013573 @iter2359) ([91m↑317.92%[0m) [2.71% of initial]
[Iter 160/20000] Loss: 0.0590620 (Best: 0.0559467 @iter157) ([92m↓3.62%[0m) [23.46% of initial]
[Iter 2420/20000] Loss: 0.0040206 (Best: 0.0013573 @iter2359) ([92m↓41.16%[0m) [1.60% of initial]
[Iter 170/20000] Loss: 0.0563644 (Best: 0.0534845 @iter167) ([92m↓4.57%[0m) [22.39% of initial]
[Iter 2430/20000] Loss: 0.0028711 (Best: 0.0013573 @iter2359) ([92m↓28.59%[0m) [1.14% of initial]
[Iter 180/20000] Loss: 0.0523306 (Best: 0.0499811 @iter179) ([92m↓7.16%[0m) [20.79% of initial]
[Iter 2440/20000] Loss: 0.0023553 (Best: 0.0013573 @iter2359) ([92m↓17.96%[0m) [0.94% of initial]
[Iter 190/20000] Loss: 0.0495268 (Best: 0.0478395 @iter188) ([92m↓5.36%[0m) [19.68% of initial]
[Iter 2450/20000] Loss: 0.0022854 (Best: 0.0013573 @iter2359) ([92m↓2.97%[0m) [0.91% of initial]
Iter:199, L1 loss=0.03443, Total loss=0.04971, Time:50
[Iter 200/20000] Loss: 0.0477579 (Best: 0.0456682 @iter198) ([92m↓3.57%[0m) [18.97% of initial]
[Iter 2460/20000] Loss: 0.0019206 (Best: 0.0013573 @iter2359) ([92m↓15.96%[0m) [0.76% of initial]
[Iter 210/20000] Loss: 0.0450537 (Best: 0.0428520 @iter209) ([92m↓5.66%[0m) [17.90% of initial]
[Iter 2470/20000] Loss: 0.0018831 (Best: 0.0013573 @iter2359) ([92m↓1.95%[0m) [0.75% of initial]
[Iter 220/20000] Loss: 0.0440570 (Best: 0.0411947 @iter219) ([92m↓2.21%[0m) [17.50% of initial]
[Iter 2480/20000] Loss: 0.0019279 (Best: 0.0013573 @iter2359) ([91m↑2.38%[0m) [0.77% of initial]
[Iter 230/20000] Loss: 0.0422559 (Best: 0.0397744 @iter227) ([92m↓4.09%[0m) [16.79% of initial]
[Iter 2490/20000] Loss: 0.0017001 (Best: 0.0013573 @iter2359) ([92m↓11.81%[0m) [0.68% of initial]
[Iter 240/20000] Loss: 0.0402101 (Best: 0.0377897 @iter238) ([92m↓4.84%[0m) [15.98% of initial]
Iter:2499, L1 loss=0.001449, Total loss=0.001479, Time:51
[Iter 2500/20000] Loss: 0.0015217 (Best: 0.0013573 @iter2359) ([92m↓10.50%[0m) [0.60% of initial]
[Iter 250/20000] Loss: 0.0380050 (Best: 0.0363086 @iter248) ([92m↓5.48%[0m) [15.10% of initial]
Pruning 494 points (0.6%) from gaussian0 at iteration 2500
Pruning 420 points (0.5%) from gaussian1 at iteration 2500
[Iter 260/20000] Loss: 0.0358454 (Best: 0.0342529 @iter260) ([92m↓5.68%[0m) [14.24% of initial]
[Iter 2510/20000] Loss: 0.0033782 (Best: 0.0013573 @iter2359) ([91m↑122.01%[0m) [1.34% of initial]
[Iter 270/20000] Loss: 0.0349091 (Best: 0.0328840 @iter269) ([92m↓2.61%[0m) [13.87% of initial]
[Iter 2520/20000] Loss: 0.0022411 (Best: 0.0013573 @iter2359) ([92m↓33.66%[0m) [0.89% of initial]
[Iter 280/20000] Loss: 0.0346918 (Best: 0.0319735 @iter277) ([92m↓0.62%[0m) [13.78% of initial]
[Iter 2530/20000] Loss: 0.0016829 (Best: 0.0013573 @iter2359) ([92m↓24.90%[0m) [0.67% of initial]
[Iter 290/20000] Loss: 0.0330827 (Best: 0.0305019 @iter287) ([92m↓4.64%[0m) [13.14% of initial]
[Iter 2540/20000] Loss: 0.0015237 (Best: 0.0013573 @iter2359) ([92m↓9.46%[0m) [0.61% of initial]
Iter:299, L1 loss=0.02219, Total loss=0.03338, Time:46
[Iter 300/20000] Loss: 0.0308006 (Best: 0.0288991 @iter300) ([92m↓6.90%[0m) [12.24% of initial]
[Iter 2550/20000] Loss: 0.0016223 (Best: 0.0012416 @iter2548) ([91m↑6.47%[0m) [0.64% of initial]
[Iter 310/20000] Loss: 0.0292404 (Best: 0.0272727 @iter310) ([92m↓5.07%[0m) [11.62% of initial]
[Iter 2560/20000] Loss: 0.0013870 (Best: 0.0011984 @iter2557) ([92m↓14.50%[0m) [0.55% of initial]
[Iter 320/20000] Loss: 0.0277723 (Best: 0.0263552 @iter320) ([92m↓5.02%[0m) [11.03% of initial]
[Iter 2570/20000] Loss: 0.0016381 (Best: 0.0011984 @iter2557) ([91m↑18.10%[0m) [0.65% of initial]
[Iter 330/20000] Loss: 0.0274095 (Best: 0.0254844 @iter330) ([92m↓1.31%[0m) [10.89% of initial]
[Iter 2580/20000] Loss: 0.0014740 (Best: 0.0011509 @iter2578) ([92m↓10.01%[0m) [0.59% of initial]
[Iter 340/20000] Loss: 0.0251313 (Best: 0.0240126 @iter340) ([92m↓8.31%[0m) [9.98% of initial]
[Iter 2590/20000] Loss: 0.0015247 (Best: 0.0011381 @iter2584) ([91m↑3.44%[0m) [0.61% of initial]
[Iter 350/20000] Loss: 0.0257236 (Best: 0.0232365 @iter349) ([91m↑2.36%[0m) [10.22% of initial]
Iter:2599, L1 loss=0.001211, Total loss=0.00118, Time:51
[Iter 2600/20000] Loss: 0.0014015 (Best: 0.0011232 @iter2594) ([92m↓8.08%[0m) [0.56% of initial]
[Iter 360/20000] Loss: 0.0242865 (Best: 0.0223664 @iter358) ([92m↓5.59%[0m) [9.65% of initial]
[Iter 370/20000] Loss: 0.0239637 (Best: 0.0216428 @iter368) ([92m↓1.33%[0m) [9.52% of initial]
[Iter 2610/20000] Loss: 0.0066332 (Best: 0.0011232 @iter2594) ([91m↑373.31%[0m) [2.64% of initial]
[Iter 380/20000] Loss: 0.0217983 (Best: 0.0207155 @iter379) ([92m↓9.04%[0m) [8.66% of initial]
[Iter 2620/20000] Loss: 0.0037444 (Best: 0.0011232 @iter2594) ([92m↓43.55%[0m) [1.49% of initial]
[Iter 390/20000] Loss: 0.0213413 (Best: 0.0199036 @iter385) ([92m↓2.10%[0m) [8.48% of initial]
[Iter 2630/20000] Loss: 0.0024700 (Best: 0.0011232 @iter2594) ([92m↓34.04%[0m) [0.98% of initial]
Iter:399, L1 loss=0.01383, Total loss=0.02113, Time:37
[Iter 400/20000] Loss: 0.0203040 (Best: 0.0188106 @iter400) ([92m↓4.86%[0m) [8.07% of initial]
[Iter 2640/20000] Loss: 0.0019611 (Best: 0.0011232 @iter2594) ([92m↓20.60%[0m) [0.78% of initial]
[Iter 410/20000] Loss: 0.0195342 (Best: 0.0184903 @iter410) ([92m↓3.79%[0m) [7.76% of initial]
[Iter 2650/20000] Loss: 0.0016263 (Best: 0.0011232 @iter2594) ([92m↓17.08%[0m) [0.65% of initial]
[Iter 420/20000] Loss: 0.0199761 (Best: 0.0178645 @iter418) ([91m↑2.26%[0m) [7.94% of initial]
[Iter 2660/20000] Loss: 0.0018731 (Best: 0.0011232 @iter2594) ([91m↑15.18%[0m) [0.74% of initial]
[Iter 430/20000] Loss: 0.0179320 (Best: 0.0170198 @iter430) ([92m↓10.23%[0m) [7.12% of initial]
[Iter 2670/20000] Loss: 0.0017785 (Best: 0.0011232 @iter2594) ([92m↓5.05%[0m) [0.71% of initial]
[Iter 440/20000] Loss: 0.0184393 (Best: 0.0164734 @iter438) ([91m↑2.83%[0m) [7.33% of initial]
[Iter 2680/20000] Loss: 0.0014413 (Best: 0.0011232 @iter2594) ([92m↓18.96%[0m) [0.57% of initial]
[Iter 450/20000] Loss: 0.0173312 (Best: 0.0153257 @iter449) ([92m↓6.01%[0m) [6.89% of initial]
[Iter 2690/20000] Loss: 0.0013890 (Best: 0.0011232 @iter2594) ([92m↓3.63%[0m) [0.55% of initial]
[Iter 460/20000] Loss: 0.0167264 (Best: 0.0148107 @iter458) ([92m↓3.49%[0m) [6.65% of initial]
Iter:2699, L1 loss=0.001307, Total loss=0.001382, Time:49
[Iter 470/20000] Loss: 0.0154995 (Best: 0.0143866 @iter461) ([92m↓7.34%[0m) [6.16% of initial]
[Iter 2700/20000] Loss: 0.0016601 (Best: 0.0011232 @iter2594) ([91m↑19.52%[0m) [0.66% of initial]
[Iter 480/20000] Loss: 0.0152929 (Best: 0.0140127 @iter479) ([92m↓1.33%[0m) [6.08% of initial]
[Iter 2710/20000] Loss: 0.0014121 (Best: 0.0011232 @iter2594) ([92m↓14.94%[0m) [0.56% of initial]
[Iter 490/20000] Loss: 0.0139164 (Best: 0.0126770 @iter490) ([92m↓9.00%[0m) [5.53% of initial]
[Iter 2720/20000] Loss: 0.0012907 (Best: 0.0011232 @iter2594) ([92m↓8.60%[0m) [0.51% of initial]
Iter:499, L1 loss=0.008522, Total loss=0.01476, Time:51
[Iter 500/20000] Loss: 0.0139358 (Best: 0.0125702 @iter493) ([91m↑0.14%[0m) [5.54% of initial]
[Iter 2730/20000] Loss: 0.0011698 (Best: 0.0010300 @iter2727) ([92m↓9.37%[0m) [0.46% of initial]
[Iter 510/20000] Loss: 0.0137635 (Best: 0.0123963 @iter503) ([92m↓1.24%[0m) [5.47% of initial]
[Iter 2740/20000] Loss: 0.0011154 (Best: 0.0009828 @iter2732) ([92m↓4.65%[0m) [0.44% of initial]
[Iter 520/20000] Loss: 0.0129142 (Best: 0.0117151 @iter514) ([92m↓6.17%[0m) [5.13% of initial]
[Iter 2750/20000] Loss: 0.0013396 (Best: 0.0009828 @iter2732) ([91m↑20.10%[0m) [0.53% of initial]
[Iter 530/20000] Loss: 0.0125111 (Best: 0.0113965 @iter529) ([92m↓3.12%[0m) [4.97% of initial]
[Iter 2760/20000] Loss: 0.0014337 (Best: 0.0009828 @iter2732) ([91m↑7.03%[0m) [0.57% of initial]
[Iter 540/20000] Loss: 0.0123896 (Best: 0.0111195 @iter538) ([92m↓0.97%[0m) [4.92% of initial]
[Iter 2770/20000] Loss: 0.0015496 (Best: 0.0009828 @iter2732) ([91m↑8.08%[0m) [0.62% of initial]
[Iter 550/20000] Loss: 0.0118557 (Best: 0.0108114 @iter548) ([92m↓4.31%[0m) [4.71% of initial]
[Iter 2780/20000] Loss: 0.0012767 (Best: 0.0009828 @iter2732) ([92m↓17.61%[0m) [0.51% of initial]
[Iter 560/20000] Loss: 0.0124968 (Best: 0.0106685 @iter554) ([91m↑5.41%[0m) [4.96% of initial]
[Iter 2790/20000] Loss: 0.0013257 (Best: 0.0009796 @iter2785) ([91m↑3.84%[0m) [0.53% of initial]
[Iter 570/20000] Loss: 0.0119030 (Best: 0.0106103 @iter563) ([92m↓4.75%[0m) [4.73% of initial]
Iter:2799, L1 loss=0.00136, Total loss=0.001492, Time:68
[Iter 2800/20000] Loss: 0.0013426 (Best: 0.0009796 @iter2785) ([91m↑1.27%[0m) [0.53% of initial]
[Iter 580/20000] Loss: 0.0112091 (Best: 0.0102154 @iter578) ([92m↓5.83%[0m) [4.45% of initial]
[Iter 590/20000] Loss: 0.0113504 (Best: 0.0100657 @iter583) ([91m↑1.26%[0m) [4.51% of initial]
[Iter 2810/20000] Loss: 0.0057358 (Best: 0.0009796 @iter2785) ([91m↑327.22%[0m) [2.28% of initial]
Iter:599, L1 loss=0.007027, Total loss=0.01218, Time:41
[Iter 600/20000] Loss: 0.0112697 (Best: 0.0100082 @iter594) ([92m↓0.71%[0m) [4.48% of initial]
[Iter 2820/20000] Loss: 0.0030930 (Best: 0.0009796 @iter2785) ([92m↓46.07%[0m) [1.23% of initial]
[Iter 610/20000] Loss: 0.0205322 (Best: 0.0100082 @iter594) ([91m↑82.19%[0m) [8.16% of initial]
[Iter 2830/20000] Loss: 0.0019995 (Best: 0.0009796 @iter2785) ([92m↓35.36%[0m) [0.79% of initial]
[Iter 620/20000] Loss: 0.0138431 (Best: 0.0100082 @iter594) ([92m↓32.58%[0m) [5.50% of initial]
[Iter 2840/20000] Loss: 0.0016961 (Best: 0.0009796 @iter2785) ([92m↓15.17%[0m) [0.67% of initial]
[Iter 630/20000] Loss: 0.0116414 (Best: 0.0100082 @iter594) ([92m↓15.90%[0m) [4.63% of initial]
[Iter 2850/20000] Loss: 0.0014879 (Best: 0.0009796 @iter2785) ([92m↓12.27%[0m) [0.59% of initial]
[Iter 640/20000] Loss: 0.0099615 (Best: 0.0090248 @iter640) ([92m↓14.43%[0m) [3.96% of initial]
[Iter 2860/20000] Loss: 0.0015984 (Best: 0.0009796 @iter2785) ([91m↑7.43%[0m) [0.64% of initial]
[Iter 650/20000] Loss: 0.0102870 (Best: 0.0089563 @iter646) ([91m↑3.27%[0m) [4.09% of initial]
[Iter 2870/20000] Loss: 0.0013653 (Best: 0.0009796 @iter2785) ([92m↓14.58%[0m) [0.54% of initial]
[Iter 660/20000] Loss: 0.0097390 (Best: 0.0085513 @iter655) ([92m↓5.33%[0m) [3.87% of initial]
[Iter 2880/20000] Loss: 0.0013397 (Best: 0.0009796 @iter2785) ([92m↓1.88%[0m) [0.53% of initial]
[Iter 670/20000] Loss: 0.0092582 (Best: 0.0081794 @iter667) ([92m↓4.94%[0m) [3.68% of initial]
[Iter 680/20000] Loss: 0.0086453 (Best: 0.0080584 @iter680) ([92m↓6.62%[0m) [3.43% of initial]
[Iter 2890/20000] Loss: 0.0012572 (Best: 0.0009796 @iter2785) ([92m↓6.16%[0m) [0.50% of initial]
[Iter 690/20000] Loss: 0.0088544 (Best: 0.0075888 @iter685) ([91m↑2.42%[0m) [3.52% of initial]
Iter:2899, L1 loss=0.001006, Total loss=0.000997, Time:74
[Iter 2900/20000] Loss: 0.0011841 (Best: 0.0009796 @iter2785) ([92m↓5.82%[0m) [0.47% of initial]
Iter:699, L1 loss=0.006045, Total loss=0.009217, Time:59
[Iter 700/20000] Loss: 0.0086229 (Best: 0.0075888 @iter685) ([92m↓2.61%[0m) [3.43% of initial]
[Iter 2910/20000] Loss: 0.0013204 (Best: 0.0009796 @iter2785) ([91m↑11.51%[0m) [0.52% of initial]
[Iter 710/20000] Loss: 0.0080410 (Best: 0.0073116 @iter703) ([92m↓6.75%[0m) [3.19% of initial]
[Iter 2920/20000] Loss: 0.0014955 (Best: 0.0009796 @iter2785) ([91m↑13.27%[0m) [0.59% of initial]
[Iter 720/20000] Loss: 0.0080327 (Best: 0.0072337 @iter715) ([92m↓0.10%[0m) [3.19% of initial]
[Iter 2930/20000] Loss: 0.0013648 (Best: 0.0009796 @iter2785) ([92m↓8.74%[0m) [0.54% of initial]
[Iter 730/20000] Loss: 0.0081785 (Best: 0.0071119 @iter727) ([91m↑1.82%[0m) [3.25% of initial]
[Iter 2940/20000] Loss: 0.0011437 (Best: 0.0009796 @iter2785) ([92m↓16.21%[0m) [0.45% of initial]
[Iter 740/20000] Loss: 0.0082079 (Best: 0.0070349 @iter736) ([91m↑0.36%[0m) [3.26% of initial]
[Iter 2950/20000] Loss: 0.0010608 (Best: 0.0008859 @iter2950) ([92m↓7.24%[0m) [0.42% of initial]
[Iter 750/20000] Loss: 0.0077826 (Best: 0.0067059 @iter748) ([92m↓5.18%[0m) [3.09% of initial]
[Iter 2960/20000] Loss: 0.0011651 (Best: 0.0008859 @iter2950) ([91m↑9.83%[0m) [0.46% of initial]
[Iter 760/20000] Loss: 0.0071728 (Best: 0.0066817 @iter754) ([92m↓7.84%[0m) [2.85% of initial]
[Iter 2970/20000] Loss: 0.0010285 (Best: 0.0008217 @iter2969) ([92m↓11.73%[0m) [0.41% of initial]
[Iter 770/20000] Loss: 0.0073491 (Best: 0.0066817 @iter754) ([91m↑2.46%[0m) [2.92% of initial]
[Iter 780/20000] Loss: 0.0075111 (Best: 0.0064942 @iter778) ([91m↑2.20%[0m) [2.98% of initial]
[Iter 2980/20000] Loss: 0.0009642 (Best: 0.0008217 @iter2969) ([92m↓6.25%[0m) [0.38% of initial]
[Iter 790/20000] Loss: 0.0072162 (Best: 0.0062767 @iter787) ([92m↓3.93%[0m) [2.87% of initial]
[Iter 2990/20000] Loss: 0.0010041 (Best: 0.0007719 @iter2983) ([91m↑4.14%[0m) [0.40% of initial]
Iter:799, L1 loss=0.005035, Total loss=0.00773, Time:48
[Iter 800/20000] Loss: 0.0069920 (Best: 0.0062767 @iter787) ([92m↓3.11%[0m) [2.78% of initial]
Iter:2999, L1 loss=0.0008115, Total loss=0.0007854, Time:58
[Iter 3000/20000] Loss: 0.0009916 (Best: 0.0007719 @iter2983) ([92m↓1.24%[0m) [0.39% of initial]
Pruning 423 points (0.4%) from gaussian0 at iteration 3000
Pruning 388 points (0.3%) from gaussian1 at iteration 3000
[Iter 810/20000] Loss: 0.0164929 (Best: 0.0062767 @iter787) ([91m↑135.88%[0m) [6.55% of initial]
[Iter 820/20000] Loss: 0.0104415 (Best: 0.0062767 @iter787) ([92m↓36.69%[0m) [4.15% of initial]
[Iter 3010/20000] Loss: 0.0058159 (Best: 0.0007719 @iter2983) ([91m↑486.49%[0m) [2.31% of initial]
[Iter 830/20000] Loss: 0.0085793 (Best: 0.0062767 @iter787) ([92m↓17.83%[0m) [3.41% of initial]
[Iter 3020/20000] Loss: 0.0034233 (Best: 0.0007719 @iter2983) ([92m↓41.14%[0m) [1.36% of initial]
[Iter 840/20000] Loss: 0.0078543 (Best: 0.0062767 @iter787) ([92m↓8.45%[0m) [3.12% of initial]
[Iter 3030/20000] Loss: 0.0024258 (Best: 0.0007719 @iter2983) ([92m↓29.14%[0m) [0.96% of initial]
[Iter 850/20000] Loss: 0.0072338 (Best: 0.0062767 @iter787) ([92m↓7.90%[0m) [2.87% of initial]
[Iter 3040/20000] Loss: 0.0018726 (Best: 0.0007719 @iter2983) ([92m↓22.80%[0m) [0.74% of initial]
[Iter 860/20000] Loss: 0.0068465 (Best: 0.0062060 @iter856) ([92m↓5.35%[0m) [2.72% of initial]
[Iter 3050/20000] Loss: 0.0017197 (Best: 0.0007719 @iter2983) ([92m↓8.16%[0m) [0.68% of initial]
[Iter 870/20000] Loss: 0.0066384 (Best: 0.0060320 @iter862) ([92m↓3.04%[0m) [2.64% of initial]
[Iter 3060/20000] Loss: 0.0015911 (Best: 0.0007719 @iter2983) ([92m↓7.48%[0m) [0.63% of initial]
[Iter 880/20000] Loss: 0.0064829 (Best: 0.0058543 @iter875) ([92m↓2.34%[0m) [2.58% of initial]
[Iter 3070/20000] Loss: 0.0014190 (Best: 0.0007719 @iter2983) ([92m↓10.81%[0m) [0.56% of initial]
[Iter 890/20000] Loss: 0.0061056 (Best: 0.0055047 @iter884) ([92m↓5.82%[0m) [2.43% of initial]
Iter:899, L1 loss=0.003786, Total loss=0.005483, Time:45
[Iter 900/20000] Loss: 0.0062801 (Best: 0.0054832 @iter899) ([91m↑2.86%[0m) [2.50% of initial]
[Iter 3080/20000] Loss: 0.0014152 (Best: 0.0007719 @iter2983) ([92m↓0.27%[0m) [0.56% of initial]
[Iter 910/20000] Loss: 0.0064621 (Best: 0.0052776 @iter907) ([91m↑2.90%[0m) [2.57% of initial]
[Iter 3090/20000] Loss: 0.0013246 (Best: 0.0007719 @iter2983) ([92m↓6.40%[0m) [0.53% of initial]
[Iter 920/20000] Loss: 0.0057638 (Best: 0.0052234 @iter916) ([92m↓10.81%[0m) [2.29% of initial]
Iter:3099, L1 loss=0.001103, Total loss=0.001119, Time:56
[Iter 3100/20000] Loss: 0.0012736 (Best: 0.0007719 @iter2983) ([92m↓3.85%[0m) [0.51% of initial]
[Iter 930/20000] Loss: 0.0061204 (Best: 0.0051445 @iter928) ([91m↑6.19%[0m) [2.43% of initial]
[Iter 3110/20000] Loss: 0.0014159 (Best: 0.0007719 @iter2983) ([91m↑11.17%[0m) [0.56% of initial]
[Iter 940/20000] Loss: 0.0062068 (Best: 0.0050752 @iter938) ([91m↑1.41%[0m) [2.47% of initial]
[Iter 3120/20000] Loss: 0.0013603 (Best: 0.0007719 @iter2983) ([92m↓3.93%[0m) [0.54% of initial]
[Iter 950/20000] Loss: 0.0056600 (Best: 0.0050532 @iter946) ([92m↓8.81%[0m) [2.25% of initial]
[Iter 3130/20000] Loss: 0.0011524 (Best: 0.0007719 @iter2983) ([92m↓15.28%[0m) [0.46% of initial]
[Iter 960/20000] Loss: 0.0057604 (Best: 0.0050532 @iter946) ([91m↑1.77%[0m) [2.29% of initial]
[Iter 3140/20000] Loss: 0.0010971 (Best: 0.0007719 @iter2983) ([92m↓4.81%[0m) [0.44% of initial]
[Iter 970/20000] Loss: 0.0057090 (Best: 0.0049181 @iter964) ([92m↓0.89%[0m) [2.27% of initial]
[Iter 980/20000] Loss: 0.0058885 (Best: 0.0049181 @iter964) ([91m↑3.15%[0m) [2.34% of initial]
[Iter 3150/20000] Loss: 0.0011398 (Best: 0.0007719 @iter2983) ([91m↑3.89%[0m) [0.45% of initial]
[Iter 990/20000] Loss: 0.0059234 (Best: 0.0049181 @iter964) ([91m↑0.59%[0m) [2.35% of initial]
[Iter 3160/20000] Loss: 0.0010461 (Best: 0.0007719 @iter2983) ([92m↓8.22%[0m) [0.42% of initial]
Iter:999, L1 loss=0.00446, Total loss=0.006758, Time:46
[Iter 1000/20000] Loss: 0.0062658 (Best: 0.0049181 @iter964) ([91m↑5.78%[0m) [2.49% of initial]
[Iter 3170/20000] Loss: 0.0010694 (Best: 0.0007719 @iter2983) ([91m↑2.23%[0m) [0.42% of initial]
Pruning 936 points (6.7%) from gaussian0 at iteration 1000
Pruning 935 points (6.7%) from gaussian1 at iteration 1000
[Iter 3180/20000] Loss: 0.0011484 (Best: 0.0007719 @iter2983) ([91m↑7.38%[0m) [0.46% of initial]
[Iter 1010/20000] Loss: 0.0143043 (Best: 0.0049181 @iter964) ([91m↑128.29%[0m) [5.68% of initial]
[Iter 3190/20000] Loss: 0.0011072 (Best: 0.0007719 @iter2983) ([92m↓3.58%[0m) [0.44% of initial]
[Iter 1020/20000] Loss: 0.0099555 (Best: 0.0049181 @iter964) ([92m↓30.40%[0m) [3.96% of initial]
Iter:3199, L1 loss=0.0009735, Total loss=0.0009876, Time:64
[Iter 1030/20000] Loss: 0.0083529 (Best: 0.0049181 @iter964) ([92m↓16.10%[0m) [3.32% of initial]
[Iter 3200/20000] Loss: 0.0010662 (Best: 0.0007719 @iter2983) ([92m↓3.70%[0m) [0.42% of initial]
[Iter 1040/20000] Loss: 0.0073221 (Best: 0.0049181 @iter964) ([92m↓12.34%[0m) [2.91% of initial]
[Iter 3210/20000] Loss: 0.0055454 (Best: 0.0007719 @iter2983) ([91m↑420.09%[0m) [2.20% of initial]
[Iter 1050/20000] Loss: 0.0069713 (Best: 0.0049181 @iter964) ([92m↓4.79%[0m) [2.77% of initial]
[Iter 3220/20000] Loss: 0.0031775 (Best: 0.0007719 @iter2983) ([92m↓42.70%[0m) [1.26% of initial]
[Iter 1060/20000] Loss: 0.0068242 (Best: 0.0049181 @iter964) ([92m↓2.11%[0m) [2.71% of initial]
[Iter 3230/20000] Loss: 0.0020105 (Best: 0.0007719 @iter2983) ([92m↓36.73%[0m) [0.80% of initial]
[Iter 1070/20000] Loss: 0.0063982 (Best: 0.0049181 @iter964) ([92m↓6.24%[0m) [2.54% of initial]
[Iter 1080/20000] Loss: 0.0060336 (Best: 0.0049181 @iter964) ([92m↓5.70%[0m) [2.40% of initial]
[Iter 3240/20000] Loss: 0.0017934 (Best: 0.0007719 @iter2983) ([92m↓10.80%[0m) [0.71% of initial]
[Iter 1090/20000] Loss: 0.0059025 (Best: 0.0049181 @iter964) ([92m↓2.17%[0m) [2.34% of initial]
[Iter 3250/20000] Loss: 0.0013627 (Best: 0.0007719 @iter2983) ([92m↓24.01%[0m) [0.54% of initial]
Iter:1099, L1 loss=0.00385, Total loss=0.005871, Time:52
[Iter 1100/20000] Loss: 0.0056896 (Best: 0.0049181 @iter964) ([92m↓3.61%[0m) [2.26% of initial]
[Iter 3260/20000] Loss: 0.0012154 (Best: 0.0007719 @iter2983) ([92m↓10.81%[0m) [0.48% of initial]
[Iter 1110/20000] Loss: 0.0056192 (Best: 0.0049181 @iter964) ([92m↓1.24%[0m) [2.23% of initial]
[Iter 3270/20000] Loss: 0.0012347 (Best: 0.0007719 @iter2983) ([91m↑1.59%[0m) [0.49% of initial]
[Iter 1120/20000] Loss: 0.0056869 (Best: 0.0048084 @iter1117) ([91m↑1.20%[0m) [2.26% of initial]
[Iter 3280/20000] Loss: 0.0012927 (Best: 0.0007719 @iter2983) ([91m↑4.69%[0m) [0.51% of initial]
[Iter 1130/20000] Loss: 0.0057849 (Best: 0.0048084 @iter1117) ([91m↑1.72%[0m) [2.30% of initial]
[Iter 3290/20000] Loss: 0.0009851 (Best: 0.0007719 @iter2983) ([92m↓23.79%[0m) [0.39% of initial]
[Iter 1140/20000] Loss: 0.0054757 (Best: 0.0047438 @iter1135) ([92m↓5.34%[0m) [2.18% of initial]
Iter:3299, L1 loss=0.00146, Total loss=0.001542, Time:67
[Iter 3300/20000] Loss: 0.0013041 (Best: 0.0007719 @iter2983) ([91m↑32.38%[0m) [0.52% of initial]
[Iter 1150/20000] Loss: 0.0050964 (Best: 0.0047102 @iter1145) ([92m↓6.93%[0m) [2.02% of initial]
[Iter 1160/20000] Loss: 0.0056188 (Best: 0.0047102 @iter1145) ([91m↑10.25%[0m) [2.23% of initial]
[Iter 3310/20000] Loss: 0.0009919 (Best: 0.0007719 @iter2983) ([92m↓23.94%[0m) [0.39% of initial]
[Iter 1170/20000] Loss: 0.0054416 (Best: 0.0047040 @iter1166) ([92m↓3.15%[0m) [2.16% of initial]
[Iter 3320/20000] Loss: 0.0011327 (Best: 0.0007719 @iter2983) ([91m↑14.19%[0m) [0.45% of initial]
[Iter 1180/20000] Loss: 0.0050768 (Best: 0.0046804 @iter1180) ([92m↓6.70%[0m) [2.02% of initial]
[Iter 3330/20000] Loss: 0.0012342 (Best: 0.0007719 @iter2983) ([91m↑8.96%[0m) [0.49% of initial]
[Iter 1190/20000] Loss: 0.0053638 (Best: 0.0045637 @iter1186) ([91m↑5.65%[0m) [2.13% of initial]
[Iter 3340/20000] Loss: 0.0013273 (Best: 0.0007719 @iter2983) ([91m↑7.54%[0m) [0.53% of initial]
Iter:1199, L1 loss=0.00386, Total loss=0.005662, Time:42
[Iter 1200/20000] Loss: 0.0052622 (Best: 0.0043967 @iter1195) ([92m↓1.90%[0m) [2.09% of initial]
[Iter 3350/20000] Loss: 0.0010659 (Best: 0.0007719 @iter2983) ([92m↓19.69%[0m) [0.42% of initial]
[Iter 1210/20000] Loss: 0.0124128 (Best: 0.0043967 @iter1195) ([91m↑135.89%[0m) [4.93% of initial]
[Iter 3360/20000] Loss: 0.0013080 (Best: 0.0007719 @iter2983) ([91m↑22.71%[0m) [0.52% of initial]
[Iter 1220/20000] Loss: 0.0078038 (Best: 0.0043967 @iter1195) ([92m↓37.13%[0m) [3.10% of initial]
[Iter 3370/20000] Loss: 0.0009700 (Best: 0.0007719 @iter2983) ([92m↓25.84%[0m) [0.39% of initial]
[Iter 1230/20000] Loss: 0.0066061 (Best: 0.0043967 @iter1195) ([92m↓15.35%[0m) [2.62% of initial]
[Iter 3380/20000] Loss: 0.0009401 (Best: 0.0007719 @iter2983) ([92m↓3.09%[0m) [0.37% of initial]
[Iter 1240/20000] Loss: 0.0060759 (Best: 0.0043967 @iter1195) ([92m↓8.03%[0m) [2.41% of initial]
[Iter 3390/20000] Loss: 0.0012508 (Best: 0.0007719 @iter2983) ([91m↑33.06%[0m) [0.50% of initial]
[Iter 1250/20000] Loss: 0.0053387 (Best: 0.0043967 @iter1195) ([92m↓12.13%[0m) [2.12% of initial]
Iter:3399, L1 loss=0.001493, Total loss=0.001562, Time:74
[Iter 3400/20000] Loss: 0.0012976 (Best: 0.0007719 @iter2983) ([91m↑3.74%[0m) [0.52% of initial]
[Iter 1260/20000] Loss: 0.0051575 (Best: 0.0042705 @iter1258) ([92m↓3.39%[0m) [2.05% of initial]
[Iter 1270/20000] Loss: 0.0046937 (Best: 0.0042705 @iter1258) ([92m↓8.99%[0m) [1.86% of initial]
[Iter 3410/20000] Loss: 0.0046883 (Best: 0.0007719 @iter2983) ([91m↑261.30%[0m) [1.86% of initial]
[Iter 1280/20000] Loss: 0.0049373 (Best: 0.0039741 @iter1273) ([91m↑5.19%[0m) [1.96% of initial]
[Iter 3420/20000] Loss: 0.0025082 (Best: 0.0007719 @iter2983) ([92m↓46.50%[0m) [1.00% of initial]
[Iter 1290/20000] Loss: 0.0048394 (Best: 0.0039403 @iter1288) ([92m↓1.98%[0m) [1.92% of initial]
Iter:1299, L1 loss=0.002946, Total loss=0.004142, Time:63
[Iter 3430/20000] Loss: 0.0015867 (Best: 0.0007719 @iter2983) ([92m↓36.74%[0m) [0.63% of initial]
[Iter 1300/20000] Loss: 0.0045162 (Best: 0.0039403 @iter1288) ([92m↓6.68%[0m) [1.79% of initial]
[Iter 1310/20000] Loss: 0.0045736 (Best: 0.0039162 @iter1301) ([91m↑1.27%[0m) [1.82% of initial]
[Iter 3440/20000] Loss: 0.0014471 (Best: 0.0007719 @iter2983) ([92m↓8.80%[0m) [0.57% of initial]
[Iter 1320/20000] Loss: 0.0044166 (Best: 0.0036719 @iter1319) ([92m↓3.43%[0m) [1.75% of initial]
[Iter 3450/20000] Loss: 0.0013929 (Best: 0.0007719 @iter2983) ([92m↓3.75%[0m) [0.55% of initial]
[Iter 1330/20000] Loss: 0.0044243 (Best: 0.0035738 @iter1321) ([91m↑0.17%[0m) [1.76% of initial]
[Iter 3460/20000] Loss: 0.0012755 (Best: 0.0007719 @iter2983) ([92m↓8.42%[0m) [0.51% of initial]
[Iter 1340/20000] Loss: 0.0041498 (Best: 0.0035738 @iter1321) ([92m↓6.20%[0m) [1.65% of initial]
[Iter 3470/20000] Loss: 0.0011949 (Best: 0.0007719 @iter2983) ([92m↓6.32%[0m) [0.47% of initial]
[Iter 1350/20000] Loss: 0.0041590 (Best: 0.0035738 @iter1321) ([91m↑0.22%[0m) [1.65% of initial]
[Iter 3480/20000] Loss: 0.0011038 (Best: 0.0007719 @iter2983) ([92m↓7.62%[0m) [0.44% of initial]
[Iter 1360/20000] Loss: 0.0042012 (Best: 0.0035738 @iter1321) ([91m↑1.01%[0m) [1.67% of initial]
[Iter 1370/20000] Loss: 0.0040074 (Best: 0.0035738 @iter1321) ([92m↓4.61%[0m) [1.59% of initial]
[Iter 3490/20000] Loss: 0.0010224 (Best: 0.0007719 @iter2983) ([92m↓7.38%[0m) [0.41% of initial]
[Iter 1380/20000] Loss: 0.0042483 (Best: 0.0034641 @iter1375) ([91m↑6.01%[0m) [1.69% of initial]
Iter:3499, L1 loss=0.0007796, Total loss=0.000738, Time:82
[Iter 3500/20000] Loss: 0.0008127 (Best: 0.0007380 @iter3499) ([92m↓20.51%[0m) [0.32% of initial]
[Iter 1390/20000] Loss: 0.0041064 (Best: 0.0034641 @iter1375) ([92m↓3.34%[0m) [1.63% of initial]
Pruning 282 points (0.2%) from gaussian0 at iteration 3500
Pruning 282 points (0.2%) from gaussian1 at iteration 3500
Iter:1399, L1 loss=0.002417, Total loss=0.003333, Time:63
[Iter 1400/20000] Loss: 0.0038202 (Best: 0.0033328 @iter1399) ([92m↓6.97%[0m) [1.52% of initial]
[Iter 3510/20000] Loss: 0.0024511 (Best: 0.0007380 @iter3499) ([91m↑201.61%[0m) [0.97% of initial]
[Iter 1410/20000] Loss: 0.0095205 (Best: 0.0033328 @iter1399) ([91m↑149.21%[0m) [3.78% of initial]
[Iter 3520/20000] Loss: 0.0015825 (Best: 0.0007380 @iter3499) ([92m↓35.44%[0m) [0.63% of initial]
[Iter 1420/20000] Loss: 0.0066055 (Best: 0.0033328 @iter1399) ([92m↓30.62%[0m) [2.62% of initial]
[Iter 3530/20000] Loss: 0.0012029 (Best: 0.0007380 @iter3499) ([92m↓23.98%[0m) [0.48% of initial]
[Iter 1430/20000] Loss: 0.0052019 (Best: 0.0033328 @iter1399) ([92m↓21.25%[0m) [2.07% of initial]
[Iter 3540/20000] Loss: 0.0013677 (Best: 0.0007380 @iter3499) ([91m↑13.70%[0m) [0.54% of initial]
[Iter 1440/20000] Loss: 0.0047724 (Best: 0.0033328 @iter1399) ([92m↓8.26%[0m) [1.90% of initial]
[Iter 3550/20000] Loss: 0.0012191 (Best: 0.0007380 @iter3499) ([92m↓10.87%[0m) [0.48% of initial]
[Iter 1450/20000] Loss: 0.0038998 (Best: 0.0033328 @iter1399) ([92m↓18.28%[0m) [1.55% of initial]
[Iter 3560/20000] Loss: 0.0010677 (Best: 0.0007380 @iter3499) ([92m↓12.42%[0m) [0.42% of initial]
[Iter 1460/20000] Loss: 0.0038460 (Best: 0.0032633 @iter1459) ([92m↓1.38%[0m) [1.53% of initial]
[Iter 3570/20000] Loss: 0.0011669 (Best: 0.0007380 @iter3499) ([91m↑9.30%[0m) [0.46% of initial]
[Iter 1470/20000] Loss: 0.0037453 (Best: 0.0032633 @iter1459) ([92m↓2.62%[0m) [1.49% of initial]
[Iter 1480/20000] Loss: 0.0035683 (Best: 0.0030624 @iter1480) ([92m↓4.72%[0m) [1.42% of initial]
[Iter 3580/20000] Loss: 0.0008769 (Best: 0.0007380 @iter3499) ([92m↓24.85%[0m) [0.35% of initial]
[Iter 1490/20000] Loss: 0.0035387 (Best: 0.0030624 @iter1480) ([92m↓0.83%[0m) [1.41% of initial]
[Iter 3590/20000] Loss: 0.0008726 (Best: 0.0007380 @iter3499) ([92m↓0.49%[0m) [0.35% of initial]
Iter:1499, L1 loss=0.002763, Total loss=0.003657, Time:63
[Iter 1500/20000] Loss: 0.0035176 (Best: 0.0030624 @iter1480) ([92m↓0.60%[0m) [1.40% of initial]
Pruning 788 points (3.1%) from gaussian0 at iteration 1500
Iter:3599, L1 loss=0.000767, Total loss=0.0007408, Time:80
Pruning 711 points (2.8%) from gaussian1 at iteration 1500
[Iter 3600/20000] Loss: 0.0008445 (Best: 0.0006957 @iter3598) ([92m↓3.23%[0m) [0.34% of initial]
[Iter 1510/20000] Loss: 0.0049889 (Best: 0.0030624 @iter1480) ([91m↑41.83%[0m) [1.98% of initial]
[Iter 3610/20000] Loss: 0.0044474 (Best: 0.0006957 @iter3598) ([91m↑426.66%[0m) [1.77% of initial]
[Iter 1520/20000] Loss: 0.0040955 (Best: 0.0030624 @iter1480) ([92m↓17.91%[0m) [1.63% of initial]
[Iter 3620/20000] Loss: 0.0027570 (Best: 0.0006957 @iter3598) ([92m↓38.01%[0m) [1.10% of initial]
[Iter 1530/20000] Loss: 0.0038581 (Best: 0.0030624 @iter1480) ([92m↓5.80%[0m) [1.53% of initial]
[Iter 1540/20000] Loss: 0.0036604 (Best: 0.0030624 @iter1480) ([92m↓5.12%[0m) [1.45% of initial]
[Iter 3630/20000] Loss: 0.0017030 (Best: 0.0006957 @iter3598) ([92m↓38.23%[0m) [0.68% of initial]
[Iter 1550/20000] Loss: 0.0033296 (Best: 0.0030624 @iter1480) ([92m↓9.04%[0m) [1.32% of initial]
[Iter 3640/20000] Loss: 0.0013000 (Best: 0.0006957 @iter3598) ([92m↓23.66%[0m) [0.52% of initial]
[Iter 1560/20000] Loss: 0.0035522 (Best: 0.0028924 @iter1558) ([91m↑6.68%[0m) [1.41% of initial]
[Iter 3650/20000] Loss: 0.0012680 (Best: 0.0006957 @iter3598) ([92m↓2.46%[0m) [0.50% of initial]
[Iter 1570/20000] Loss: 0.0032072 (Best: 0.0028924 @iter1558) ([92m↓9.71%[0m) [1.27% of initial]
[Iter 3660/20000] Loss: 0.0010497 (Best: 0.0006957 @iter3598) ([92m↓17.22%[0m) [0.42% of initial]
[Iter 1580/20000] Loss: 0.0031856 (Best: 0.0027374 @iter1579) ([92m↓0.68%[0m) [1.27% of initial]
[Iter 3670/20000] Loss: 0.0009318 (Best: 0.0006957 @iter3598) ([92m↓11.23%[0m) [0.37% of initial]
[Iter 1590/20000] Loss: 0.0031361 (Best: 0.0027374 @iter1579) ([92m↓1.55%[0m) [1.25% of initial]
Iter:1599, L1 loss=0.002911, Total loss=0.003705, Time:65
[Iter 3680/20000] Loss: 0.0011598 (Best: 0.0006957 @iter3598) ([91m↑24.47%[0m) [0.46% of initial]
[Iter 1600/20000] Loss: 0.0034097 (Best: 0.0027374 @iter1579) ([91m↑8.72%[0m) [1.35% of initial]
[Iter 3690/20000] Loss: 0.0014758 (Best: 0.0006957 @iter3598) ([91m↑27.24%[0m) [0.59% of initial]
[Iter 1610/20000] Loss: 0.0096996 (Best: 0.0027374 @iter1579) ([91m↑184.47%[0m) [3.85% of initial]
Iter:3699, L1 loss=0.001166, Total loss=0.001227, Time:77
[Iter 3700/20000] Loss: 0.0012436 (Best: 0.0006957 @iter3598) ([92m↓15.73%[0m) [0.49% of initial]
[Iter 1620/20000] Loss: 0.0063065 (Best: 0.0027374 @iter1579) ([92m↓34.98%[0m) [2.51% of initial]
[Iter 1630/20000] Loss: 0.0046255 (Best: 0.0027374 @iter1579) ([92m↓26.66%[0m) [1.84% of initial]
[Iter 3710/20000] Loss: 0.0009709 (Best: 0.0006957 @iter3598) ([92m↓21.93%[0m) [0.39% of initial]
[Iter 1640/20000] Loss: 0.0041546 (Best: 0.0027374 @iter1579) ([92m↓10.18%[0m) [1.65% of initial]
[Iter 3720/20000] Loss: 0.0010537 (Best: 0.0006957 @iter3598) ([91m↑8.53%[0m) [0.42% of initial]
[Iter 1650/20000] Loss: 0.0036834 (Best: 0.0027374 @iter1579) ([92m↓11.34%[0m) [1.46% of initial]
[Iter 3730/20000] Loss: 0.0008901 (Best: 0.0006957 @iter3598) ([92m↓15.52%[0m) [0.35% of initial]
[Iter 1660/20000] Loss: 0.0032707 (Best: 0.0027374 @iter1579) ([92m↓11.20%[0m) [1.30% of initial]
[Iter 3740/20000] Loss: 0.0009052 (Best: 0.0006957 @iter3598) ([91m↑1.69%[0m) [0.36% of initial]
[Iter 1670/20000] Loss: 0.0031209 (Best: 0.0027080 @iter1669) ([92m↓4.58%[0m) [1.24% of initial]
[Iter 3750/20000] Loss: 0.0009521 (Best: 0.0006957 @iter3598) ([91m↑5.19%[0m) [0.38% of initial]
[Iter 1680/20000] Loss: 0.0031557 (Best: 0.0027080 @iter1669) ([91m↑1.11%[0m) [1.25% of initial]
[Iter 3760/20000] Loss: 0.0009298 (Best: 0.0006957 @iter3598) ([92m↓2.35%[0m) [0.37% of initial]
[Iter 1690/20000] Loss: 0.0032549 (Best: 0.0026674 @iter1684) ([91m↑3.15%[0m) [1.29% of initial]
Iter:1699, L1 loss=0.002655, Total loss=0.003337, Time:43
[Iter 3770/20000] Loss: 0.0009074 (Best: 0.0006957 @iter3598) ([92m↓2.41%[0m) [0.36% of initial]
[Iter 1700/20000] Loss: 0.0029955 (Best: 0.0026674 @iter1684) ([92m↓7.97%[0m) [1.19% of initial]
[Iter 1710/20000] Loss: 0.0031660 (Best: 0.0026503 @iter1705) ([91m↑5.69%[0m) [1.26% of initial]
[Iter 3780/20000] Loss: 0.0008324 (Best: 0.0006564 @iter3775) ([92m↓8.26%[0m) [0.33% of initial]
[Iter 1720/20000] Loss: 0.0027642 (Best: 0.0025755 @iter1720) ([92m↓12.69%[0m) [1.10% of initial]
[Iter 3790/20000] Loss: 0.0006955 (Best: 0.0006199 @iter3790) ([92m↓16.45%[0m) [0.28% of initial]
[Iter 1730/20000] Loss: 0.0028645 (Best: 0.0025285 @iter1726) ([91m↑3.63%[0m) [1.14% of initial]
Iter:3799, L1 loss=0.0009195, Total loss=0.0008855, Time:90
[Iter 3800/20000] Loss: 0.0008668 (Best: 0.0006199 @iter3790) ([91m↑24.64%[0m) [0.34% of initial]
[Iter 1740/20000] Loss: 0.0028405 (Best: 0.0025184 @iter1732) ([92m↓0.84%[0m) [1.13% of initial]
[Iter 3810/20000] Loss: 0.0040930 (Best: 0.0006199 @iter3790) ([91m↑372.19%[0m) [1.63% of initial]
[Iter 1750/20000] Loss: 0.0026169 (Best: 0.0023855 @iter1750) ([92m↓7.87%[0m) [1.04% of initial]
[Iter 1760/20000] Loss: 0.0028508 (Best: 0.0023855 @iter1750) ([91m↑8.94%[0m) [1.13% of initial]
[Iter 3820/20000] Loss: 0.0023301 (Best: 0.0006199 @iter3790) ([92m↓43.07%[0m) [0.93% of initial]
[Iter 1770/20000] Loss: 0.0026977 (Best: 0.0023669 @iter1762) ([92m↓5.37%[0m) [1.07% of initial]
[Iter 3830/20000] Loss: 0.0014143 (Best: 0.0006199 @iter3790) ([92m↓39.30%[0m) [0.56% of initial]
[Iter 1780/20000] Loss: 0.0027260 (Best: 0.0023669 @iter1762) ([91m↑1.05%[0m) [1.08% of initial]
[Iter 3840/20000] Loss: 0.0016050 (Best: 0.0006199 @iter3790) ([91m↑13.49%[0m) [0.64% of initial]
[Iter 1790/20000] Loss: 0.0024765 (Best: 0.0021050 @iter1789) ([92m↓9.15%[0m) [0.98% of initial]
[Iter 3850/20000] Loss: 0.0012100 (Best: 0.0006199 @iter3790) ([92m↓24.61%[0m) [0.48% of initial]
Iter:1799, L1 loss=0.001851, Total loss=0.002282, Time:44
[Iter 1800/20000] Loss: 0.0025097 (Best: 0.0021050 @iter1789) ([91m↑1.34%[0m) [1.00% of initial]
[Iter 3860/20000] Loss: 0.0011344 (Best: 0.0006199 @iter3790) ([92m↓6.24%[0m) [0.45% of initial]
[Iter 1810/20000] Loss: 0.0084460 (Best: 0.0021050 @iter1789) ([91m↑236.53%[0m) [3.36% of initial]
[Iter 3870/20000] Loss: 0.0009072 (Best: 0.0006199 @iter3790) ([92m↓20.03%[0m) [0.36% of initial]
[Iter 1820/20000] Loss: 0.0050863 (Best: 0.0021050 @iter1789) ([92m↓39.78%[0m) [2.02% of initial]
[Iter 3880/20000] Loss: 0.0009202 (Best: 0.0006199 @iter3790) ([91m↑1.43%[0m) [0.37% of initial]
[Iter 1830/20000] Loss: 0.0043223 (Best: 0.0021050 @iter1789) ([92m↓15.02%[0m) [1.72% of initial]
[Iter 3890/20000] Loss: 0.0007570 (Best: 0.0006199 @iter3790) ([92m↓17.73%[0m) [0.30% of initial]
[Iter 1840/20000] Loss: 0.0030707 (Best: 0.0021050 @iter1789) ([92m↓28.96%[0m) [1.22% of initial]
Iter:3899, L1 loss=0.0008616, Total loss=0.0008361, Time:72
[Iter 1850/20000] Loss: 0.0029173 (Best: 0.0021050 @iter1789) ([92m↓4.99%[0m) [1.16% of initial]
[Iter 3900/20000] Loss: 0.0007790 (Best: 0.0005826 @iter3898) ([91m↑2.91%[0m) [0.31% of initial]
[Iter 1860/20000] Loss: 0.0026749 (Best: 0.0021050 @iter1789) ([92m↓8.31%[0m) [1.06% of initial]
[Iter 3910/20000] Loss: 0.0009619 (Best: 0.0005826 @iter3898) ([91m↑23.48%[0m) [0.38% of initial]
[Iter 1870/20000] Loss: 0.0025034 (Best: 0.0021050 @iter1789) ([92m↓6.41%[0m) [0.99% of initial]
[Iter 3920/20000] Loss: 0.0009754 (Best: 0.0005826 @iter3898) ([91m↑1.41%[0m) [0.39% of initial]
[Iter 1880/20000] Loss: 0.0025111 (Best: 0.0021050 @iter1789) ([91m↑0.31%[0m) [1.00% of initial]
[Iter 3930/20000] Loss: 0.0009607 (Best: 0.0005826 @iter3898) ([92m↓1.51%[0m) [0.38% of initial]
[Iter 1890/20000] Loss: 0.0022955 (Best: 0.0021050 @iter1789) ([92m↓8.58%[0m) [0.91% of initial]
[Iter 3940/20000] Loss: 0.0007860 (Best: 0.0005826 @iter3898) ([92m↓18.18%[0m) [0.31% of initial]
Iter:1899, L1 loss=0.001879, Total loss=0.002232, Time:71
[Iter 1900/20000] Loss: 0.0023034 (Best: 0.0019971 @iter1891) ([91m↑0.34%[0m) [0.92% of initial]
[Iter 3950/20000] Loss: 0.0008532 (Best: 0.0005826 @iter3898) ([91m↑8.54%[0m) [0.34% of initial]
[Iter 1910/20000] Loss: 0.0023684 (Best: 0.0019285 @iter1903) ([91m↑2.82%[0m) [0.94% of initial]
[Iter 3960/20000] Loss: 0.0008521 (Best: 0.0005826 @iter3898) ([92m↓0.13%[0m) [0.34% of initial]
[Iter 1920/20000] Loss: 0.0024159 (Best: 0.0019285 @iter1903) ([91m↑2.00%[0m) [0.96% of initial]
[Iter 1930/20000] Loss: 0.0020458 (Best: 0.0019160 @iter1930) ([92m↓15.32%[0m) [0.81% of initial]
[Iter 3970/20000] Loss: 0.0007734 (Best: 0.0005826 @iter3898) ([92m↓9.24%[0m) [0.31% of initial]
[Iter 1940/20000] Loss: 0.0022570 (Best: 0.0018996 @iter1939) ([91m↑10.32%[0m) [0.90% of initial]
[Iter 3980/20000] Loss: 0.0011077 (Best: 0.0005826 @iter3898) ([91m↑43.22%[0m) [0.44% of initial]
[Iter 1950/20000] Loss: 0.0023615 (Best: 0.0018996 @iter1939) ([91m↑4.63%[0m) [0.94% of initial]
[Iter 3990/20000] Loss: 0.0008447 (Best: 0.0005826 @iter3898) ([92m↓23.74%[0m) [0.34% of initial]
[Iter 1960/20000] Loss: 0.0021425 (Best: 0.0018996 @iter1939) ([92m↓9.27%[0m) [0.85% of initial]
Iter:3999, L1 loss=0.0009405, Total loss=0.000926, Time:73
[Iter 4000/20000] Loss: 0.0008456 (Best: 0.0005826 @iter3898) ([91m↑0.11%[0m) [0.34% of initial]
[Iter 1970/20000] Loss: 0.0020477 (Best: 0.0018856 @iter1963) ([92m↓4.43%[0m) [0.81% of initial]
Pruning 208 points (0.1%) from gaussian0 at iteration 4000
Pruning 226 points (0.1%) from gaussian1 at iteration 4000
[Iter 1980/20000] Loss: 0.0023428 (Best: 0.0018856 @iter1963) ([91m↑14.41%[0m) [0.93% of initial]
[Iter 1990/20000] Loss: 0.0020864 (Best: 0.0018856 @iter1963) ([92m↓10.94%[0m) [0.83% of initial]
[Iter 4010/20000] Loss: 0.1539870 (Best: 0.0005826 @iter3898) ([91m↑18111.01%[0m) [61.18% of initial]
Iter:1999, L1 loss=0.001644, Total loss=0.001903, Time:48
[Iter 2000/20000] Loss: 0.0021567 (Best: 0.0017471 @iter1996) ([91m↑3.37%[0m) [0.86% of initial]
[Iter 4020/20000] Loss: 0.1066509 (Best: 0.0005826 @iter3898) ([92m↓30.74%[0m) [42.37% of initial]
Testing Speed: 85.06049321775896 fps
Testing Time: 0.5878169536590576 s

[ITER 2000] Evaluating test: SSIM = 0.865769305229187, PSNR = 17.907934684753418
Testing Speed: 73.75681125439625 fps
Testing Time: 0.04067420959472656 s

[ITER 2000] Evaluating train: SSIM = 0.9999489188194275, PSNR = 47.9374148050944
Iter:2000, total_points:43474
Pruning 692 points (1.2%) from gaussian0 at iteration 2000
Pruning 608 points (1.1%) from gaussian1 at iteration 2000
[Iter 4030/20000] Loss: 0.0693783 (Best: 0.0005826 @iter3898) ([92m↓34.95%[0m) [27.56% of initial]
[Iter 2010/20000] Loss: 0.2043303 (Best: 0.0017471 @iter1996) ([91m↑9374.09%[0m) [81.18% of initial]
[Iter 4040/20000] Loss: 0.0394597 (Best: 0.0005826 @iter3898) ([92m↓43.12%[0m) [15.68% of initial]
[Iter 2020/20000] Loss: 0.1558236 (Best: 0.0017471 @iter1996) ([92m↓23.74%[0m) [61.91% of initial]
[Iter 4050/20000] Loss: 0.0188693 (Best: 0.0005826 @iter3898) ([92m↓52.18%[0m) [7.50% of initial]
[Iter 2030/20000] Loss: 0.1067978 (Best: 0.0017471 @iter1996) ([92m↓31.46%[0m) [42.43% of initial]
[Iter 4060/20000] Loss: 0.0093931 (Best: 0.0005826 @iter3898) ([92m↓50.22%[0m) [3.73% of initial]
[Iter 2040/20000] Loss: 0.0694004 (Best: 0.0017471 @iter1996) ([92m↓35.02%[0m) [27.57% of initial]
[Iter 4070/20000] Loss: 0.0058481 (Best: 0.0005826 @iter3898) ([92m↓37.74%[0m) [2.32% of initial]
[Iter 2050/20000] Loss: 0.0401422 (Best: 0.0017471 @iter1996) ([92m↓42.16%[0m) [15.95% of initial]
[Iter 4080/20000] Loss: 0.0040859 (Best: 0.0005826 @iter3898) ([92m↓30.13%[0m) [1.62% of initial]
[Iter 2060/20000] Loss: 0.0191745 (Best: 0.0017471 @iter1996) ([92m↓52.23%[0m) [7.62% of initial]
[Iter 2070/20000] Loss: 0.0115597 (Best: 0.0017471 @iter1996) ([92m↓39.71%[0m) [4.59% of initial]
[Iter 4090/20000] Loss: 0.0029307 (Best: 0.0005826 @iter3898) ([92m↓28.27%[0m) [1.16% of initial]
[Iter 2080/20000] Loss: 0.0073092 (Best: 0.0017471 @iter1996) ([92m↓36.77%[0m) [2.90% of initial]
Iter:4099, L1 loss=0.002121, Total loss=0.002332, Time:81
[Iter 4100/20000] Loss: 0.0024023 (Best: 0.0005826 @iter3898) ([92m↓18.03%[0m) [0.95% of initial]
[Iter 2090/20000] Loss: 0.0058697 (Best: 0.0017471 @iter1996) ([92m↓19.69%[0m) [2.33% of initial]
[Iter 4110/20000] Loss: 0.0020967 (Best: 0.0005826 @iter3898) ([92m↓12.72%[0m) [0.83% of initial]
Iter:2099, L1 loss=0.003609, Total loss=0.004544, Time:81
[Iter 2100/20000] Loss: 0.0047932 (Best: 0.0017471 @iter1996) ([92m↓18.34%[0m) [1.90% of initial]
[Iter 4120/20000] Loss: 0.0018309 (Best: 0.0005826 @iter3898) ([92m↓12.68%[0m) [0.73% of initial]
[Iter 2110/20000] Loss: 0.0041563 (Best: 0.0017471 @iter1996) ([92m↓13.29%[0m) [1.65% of initial]
[Iter 4130/20000] Loss: 0.0018143 (Best: 0.0005826 @iter3898) ([92m↓0.91%[0m) [0.72% of initial]
[Iter 2120/20000] Loss: 0.0036214 (Best: 0.0017471 @iter1996) ([92m↓12.87%[0m) [1.44% of initial]
[Iter 4140/20000] Loss: 0.0016375 (Best: 0.0005826 @iter3898) ([92m↓9.74%[0m) [0.65% of initial]
[Iter 2130/20000] Loss: 0.0035713 (Best: 0.0017471 @iter1996) ([92m↓1.38%[0m) [1.42% of initial]
[Iter 4150/20000] Loss: 0.0014984 (Best: 0.0005826 @iter3898) ([92m↓8.49%[0m) [0.60% of initial]
[Iter 2140/20000] Loss: 0.0034292 (Best: 0.0017471 @iter1996) ([92m↓3.98%[0m) [1.36% of initial]
[Iter 2150/20000] Loss: 0.0031458 (Best: 0.0017471 @iter1996) ([92m↓8.26%[0m) [1.25% of initial]
[Iter 4160/20000] Loss: 0.0015454 (Best: 0.0005826 @iter3898) ([91m↑3.14%[0m) [0.61% of initial]
[Iter 2160/20000] Loss: 0.0029903 (Best: 0.0017471 @iter1996) ([92m↓4.94%[0m) [1.19% of initial]
[Iter 4170/20000] Loss: 0.0014623 (Best: 0.0005826 @iter3898) ([92m↓5.38%[0m) [0.58% of initial]
[Iter 2170/20000] Loss: 0.0030299 (Best: 0.0017471 @iter1996) ([91m↑1.32%[0m) [1.20% of initial]
[Iter 4180/20000] Loss: 0.0014489 (Best: 0.0005826 @iter3898) ([92m↓0.91%[0m) [0.58% of initial]
[Iter 2180/20000] Loss: 0.0026089 (Best: 0.0017471 @iter1996) ([92m↓13.90%[0m) [1.04% of initial]
[Iter 4190/20000] Loss: 0.0012559 (Best: 0.0005826 @iter3898) ([92m↓13.32%[0m) [0.50% of initial]
[Iter 2190/20000] Loss: 0.0027615 (Best: 0.0017471 @iter1996) ([91m↑5.85%[0m) [1.10% of initial]
Iter:4199, L1 loss=0.001223, Total loss=0.001241, Time:89
[Iter 4200/20000] Loss: 0.0013340 (Best: 0.0005826 @iter3898) ([91m↑6.21%[0m) [0.53% of initial]
Iter:2199, L1 loss=0.002139, Total loss=0.002564, Time:70
[Iter 2200/20000] Loss: 0.0027130 (Best: 0.0017471 @iter1996) ([92m↓1.76%[0m) [1.08% of initial]
[Iter 4210/20000] Loss: 0.0032079 (Best: 0.0005826 @iter3898) ([91m↑140.47%[0m) [1.27% of initial]
[Iter 2210/20000] Loss: 0.0081655 (Best: 0.0017471 @iter1996) ([91m↑200.98%[0m) [3.24% of initial]
[Iter 4220/20000] Loss: 0.0021140 (Best: 0.0005826 @iter3898) ([92m↓34.10%[0m) [0.84% of initial]
[Iter 2220/20000] Loss: 0.0049049 (Best: 0.0017471 @iter1996) ([92m↓39.93%[0m) [1.95% of initial]
[Iter 4230/20000] Loss: 0.0014748 (Best: 0.0005826 @iter3898) ([92m↓30.23%[0m) [0.59% of initial]
[Iter 2230/20000] Loss: 0.0034635 (Best: 0.0017471 @iter1996) ([92m↓29.39%[0m) [1.38% of initial]
[Iter 2240/20000] Loss: 0.0030585 (Best: 0.0017471 @iter1996) ([92m↓11.69%[0m) [1.22% of initial]
[Iter 4240/20000] Loss: 0.0013561 (Best: 0.0005826 @iter3898) ([92m↓8.05%[0m) [0.54% of initial]
[Iter 2250/20000] Loss: 0.0027721 (Best: 0.0017471 @iter1996) ([92m↓9.36%[0m) [1.10% of initial]
[Iter 4250/20000] Loss: 0.0013249 (Best: 0.0005826 @iter3898) ([92m↓2.31%[0m) [0.53% of initial]
[Iter 2260/20000] Loss: 0.0024179 (Best: 0.0017471 @iter1996) ([92m↓12.78%[0m) [0.96% of initial]
[Iter 4260/20000] Loss: 0.0013681 (Best: 0.0005826 @iter3898) ([91m↑3.26%[0m) [0.54% of initial]
[Iter 2270/20000] Loss: 0.0025451 (Best: 0.0017471 @iter1996) ([91m↑5.26%[0m) [1.01% of initial]
[Iter 4270/20000] Loss: 0.0012880 (Best: 0.0005826 @iter3898) ([92m↓5.86%[0m) [0.51% of initial]
[Iter 2280/20000] Loss: 0.0021944 (Best: 0.0017471 @iter1996) ([92m↓13.78%[0m) [0.87% of initial]
[Iter 4280/20000] Loss: 0.0010537 (Best: 0.0005826 @iter3898) ([92m↓18.19%[0m) [0.42% of initial]
[Iter 2290/20000] Loss: 0.0021519 (Best: 0.0017471 @iter1996) ([92m↓1.94%[0m) [0.85% of initial]
[Iter 4290/20000] Loss: 0.0010669 (Best: 0.0005826 @iter3898) ([91m↑1.26%[0m) [0.42% of initial]
Iter:2299, L1 loss=0.00175, Total loss=0.002068, Time:83
[Iter 2300/20000] Loss: 0.0023316 (Best: 0.0017471 @iter1996) ([91m↑8.35%[0m) [0.93% of initial]
Iter:4299, L1 loss=0.001215, Total loss=0.001254, Time:87
[Iter 4300/20000] Loss: 0.0010311 (Best: 0.0005826 @iter3898) ([92m↓3.36%[0m) [0.41% of initial]
[Iter 2310/20000] Loss: 0.0021830 (Best: 0.0017471 @iter1996) ([92m↓6.37%[0m) [0.87% of initial]
[Iter 4310/20000] Loss: 0.0010000 (Best: 0.0005826 @iter3898) ([92m↓3.02%[0m) [0.40% of initial]
[Iter 2320/20000] Loss: 0.0019168 (Best: 0.0017471 @iter1996) ([92m↓12.19%[0m) [0.76% of initial]
[Iter 4320/20000] Loss: 0.0011512 (Best: 0.0005826 @iter3898) ([91m↑15.12%[0m) [0.46% of initial]
[Iter 2330/20000] Loss: 0.0019165 (Best: 0.0016837 @iter2329) ([92m↓0.02%[0m) [0.76% of initial]
[Iter 2340/20000] Loss: 0.0020101 (Best: 0.0016837 @iter2329) ([91m↑4.88%[0m) [0.80% of initial]
[Iter 4330/20000] Loss: 0.0009984 (Best: 0.0005826 @iter3898) ([92m↓13.27%[0m) [0.40% of initial]
[Iter 2350/20000] Loss: 0.0019458 (Best: 0.0016837 @iter2329) ([92m↓3.20%[0m) [0.77% of initial]
[Iter 4340/20000] Loss: 0.0009971 (Best: 0.0005826 @iter3898) ([92m↓0.13%[0m) [0.40% of initial]
[Iter 2360/20000] Loss: 0.0018229 (Best: 0.0016837 @iter2329) ([92m↓6.32%[0m) [0.72% of initial]
[Iter 4350/20000] Loss: 0.0009793 (Best: 0.0005826 @iter3898) ([92m↓1.78%[0m) [0.39% of initial]
[Iter 2370/20000] Loss: 0.0018967 (Best: 0.0016837 @iter2329) ([91m↑4.05%[0m) [0.75% of initial]
[Iter 4360/20000] Loss: 0.0009479 (Best: 0.0005826 @iter3898) ([92m↓3.20%[0m) [0.38% of initial]
[Iter 2380/20000] Loss: 0.0019901 (Best: 0.0016837 @iter2329) ([91m↑4.92%[0m) [0.79% of initial]
[Iter 4370/20000] Loss: 0.0009777 (Best: 0.0005826 @iter3898) ([91m↑3.14%[0m) [0.39% of initial]
[Iter 2390/20000] Loss: 0.0019875 (Best: 0.0016837 @iter2329) ([92m↓0.13%[0m) [0.79% of initial]
[Iter 4380/20000] Loss: 0.0009916 (Best: 0.0005826 @iter3898) ([91m↑1.42%[0m) [0.39% of initial]
Iter:2399, L1 loss=0.001541, Total loss=0.00176, Time:62
[Iter 2400/20000] Loss: 0.0018049 (Best: 0.0016837 @iter2329) ([92m↓9.18%[0m) [0.72% of initial]
[Iter 4390/20000] Loss: 0.0009463 (Best: 0.0005826 @iter3898) ([92m↓4.57%[0m) [0.38% of initial]
[Iter 2410/20000] Loss: 0.0053949 (Best: 0.0016837 @iter2329) ([91m↑198.90%[0m) [2.14% of initial]
Iter:4399, L1 loss=0.0008637, Total loss=0.0008181, Time:84
[Iter 4400/20000] Loss: 0.0009327 (Best: 0.0005826 @iter3898) ([92m↓1.44%[0m) [0.37% of initial]
[Iter 2420/20000] Loss: 0.0035136 (Best: 0.0016837 @iter2329) ([92m↓34.87%[0m) [1.40% of initial]
[Iter 2430/20000] Loss: 0.0027159 (Best: 0.0016837 @iter2329) ([92m↓22.70%[0m) [1.08% of initial]
[Iter 4410/20000] Loss: 0.0021692 (Best: 0.0005826 @iter3898) ([91m↑132.57%[0m) [0.86% of initial]
[Iter 2440/20000] Loss: 0.0023101 (Best: 0.0016837 @iter2329) ([92m↓14.94%[0m) [0.92% of initial]
[Iter 4420/20000] Loss: 0.0013565 (Best: 0.0005826 @iter3898) ([92m↓37.46%[0m) [0.54% of initial]
[Iter 2450/20000] Loss: 0.0022107 (Best: 0.0016837 @iter2329) ([92m↓4.30%[0m) [0.88% of initial]
[Iter 4430/20000] Loss: 0.0012039 (Best: 0.0005826 @iter3898) ([92m↓11.25%[0m) [0.48% of initial]
[Iter 2460/20000] Loss: 0.0020433 (Best: 0.0016837 @iter2329) ([92m↓7.57%[0m) [0.81% of initial]
[Iter 4440/20000] Loss: 0.0010602 (Best: 0.0005826 @iter3898) ([92m↓11.94%[0m) [0.42% of initial]
[Iter 2470/20000] Loss: 0.0020184 (Best: 0.0016386 @iter2464) ([92m↓1.22%[0m) [0.80% of initial]
[Iter 4450/20000] Loss: 0.0009767 (Best: 0.0005826 @iter3898) ([92m↓7.88%[0m) [0.39% of initial]
[Iter 2480/20000] Loss: 0.0019709 (Best: 0.0016386 @iter2464) ([92m↓2.35%[0m) [0.78% of initial]
[Iter 4460/20000] Loss: 0.0009489 (Best: 0.0005826 @iter3898) ([92m↓2.84%[0m) [0.38% of initial]
[Iter 2490/20000] Loss: 0.0018106 (Best: 0.0016289 @iter2489) ([92m↓8.13%[0m) [0.72% of initial]
[Iter 4470/20000] Loss: 0.0010486 (Best: 0.0005826 @iter3898) ([91m↑10.50%[0m) [0.42% of initial]
Iter:2499, L1 loss=0.001561, Total loss=0.001645, Time:71
[Iter 2500/20000] Loss: 0.0017083 (Best: 0.0016037 @iter2491) ([92m↓5.65%[0m) [0.68% of initial]
Pruning 441 points (0.7%) from gaussian0 at iteration 2500
Pruning 493 points (0.7%) from gaussian1 at iteration 2500
[Iter 4480/20000] Loss: 0.0009883 (Best: 0.0005826 @iter3898) ([92m↓5.75%[0m) [0.39% of initial]
[Iter 2510/20000] Loss: 0.0029231 (Best: 0.0016037 @iter2491) ([91m↑71.11%[0m) [1.16% of initial]
[Iter 4490/20000] Loss: 0.0009954 (Best: 0.0005826 @iter3898) ([91m↑0.72%[0m) [0.40% of initial]
[Iter 2520/20000] Loss: 0.0021940 (Best: 0.0016037 @iter2491) ([92m↓24.94%[0m) [0.87% of initial]
Iter:4499, L1 loss=0.001053, Total loss=0.00101, Time:92
[Iter 4500/20000] Loss: 0.0010973 (Best: 0.0005826 @iter3898) ([91m↑10.23%[0m) [0.44% of initial]
[Iter 2530/20000] Loss: 0.0018160 (Best: 0.0016037 @iter2491) ([92m↓17.23%[0m) [0.72% of initial]
Pruning 314 points (0.2%) from gaussian0 at iteration 4500
Pruning 358 points (0.2%) from gaussian1 at iteration 4500
[Iter 2540/20000] Loss: 0.0017564 (Best: 0.0015944 @iter2533) ([92m↓3.28%[0m) [0.70% of initial]
[Iter 4510/20000] Loss: 0.0018713 (Best: 0.0005826 @iter3898) ([91m↑70.54%[0m) [0.74% of initial]
[Iter 2550/20000] Loss: 0.0017776 (Best: 0.0014738 @iter2548) ([91m↑1.21%[0m) [0.71% of initial]
[Iter 4520/20000] Loss: 0.0014881 (Best: 0.0005826 @iter3898) ([92m↓20.48%[0m) [0.59% of initial]
[Iter 2560/20000] Loss: 0.0016318 (Best: 0.0014511 @iter2558) ([92m↓8.20%[0m) [0.65% of initial]
[Iter 4530/20000] Loss: 0.0014056 (Best: 0.0005826 @iter3898) ([92m↓5.54%[0m) [0.56% of initial]
[Iter 2570/20000] Loss: 0.0017983 (Best: 0.0014511 @iter2558) ([91m↑10.20%[0m) [0.71% of initial]
[Iter 4540/20000] Loss: 0.0011396 (Best: 0.0005826 @iter3898) ([92m↓18.92%[0m) [0.45% of initial]
[Iter 2580/20000] Loss: 0.0016667 (Best: 0.0013883 @iter2578) ([92m↓7.32%[0m) [0.66% of initial]
[Iter 4550/20000] Loss: 0.0009988 (Best: 0.0005826 @iter3898) ([92m↓12.36%[0m) [0.40% of initial]
[Iter 2590/20000] Loss: 0.0016652 (Best: 0.0013883 @iter2578) ([92m↓0.09%[0m) [0.66% of initial]
[Iter 4560/20000] Loss: 0.0010035 (Best: 0.0005826 @iter3898) ([91m↑0.48%[0m) [0.40% of initial]
Iter:2599, L1 loss=0.001356, Total loss=0.001437, Time:82
[Iter 2600/20000] Loss: 0.0015966 (Best: 0.0013786 @iter2596) ([92m↓4.12%[0m) [0.63% of initial]
[Iter 4570/20000] Loss: 0.0008896 (Best: 0.0005826 @iter3898) ([92m↓11.35%[0m) [0.35% of initial]
[Iter 2610/20000] Loss: 0.0051509 (Best: 0.0013786 @iter2596) ([91m↑222.61%[0m) [2.05% of initial]
[Iter 4580/20000] Loss: 0.0008710 (Best: 0.0005826 @iter3898) ([92m↓2.09%[0m) [0.35% of initial]
[Iter 2620/20000] Loss: 0.0033923 (Best: 0.0013786 @iter2596) ([92m↓34.14%[0m) [1.35% of initial]
[Iter 4590/20000] Loss: 0.0009627 (Best: 0.0005826 @iter3898) ([91m↑10.52%[0m) [0.38% of initial]
[Iter 2630/20000] Loss: 0.0023996 (Best: 0.0013786 @iter2596) ([92m↓29.26%[0m) [0.95% of initial]
Iter:4599, L1 loss=0.0009688, Total loss=0.0009312, Time:85
[Iter 4600/20000] Loss: 0.0008988 (Best: 0.0005826 @iter3898) ([92m↓6.63%[0m) [0.36% of initial]
[Iter 2640/20000] Loss: 0.0020055 (Best: 0.0013786 @iter2596) ([92m↓16.42%[0m) [0.80% of initial]
[Iter 2650/20000] Loss: 0.0017002 (Best: 0.0013786 @iter2596) ([92m↓15.23%[0m) [0.68% of initial]
[Iter 4610/20000] Loss: 0.0023188 (Best: 0.0005826 @iter3898) ([91m↑157.98%[0m) [0.92% of initial]
[Iter 2660/20000] Loss: 0.0018231 (Best: 0.0013786 @iter2596) ([91m↑7.23%[0m) [0.72% of initial]
[Iter 4620/20000] Loss: 0.0015943 (Best: 0.0005826 @iter3898) ([92m↓31.25%[0m) [0.63% of initial]
[Iter 2670/20000] Loss: 0.0017389 (Best: 0.0013786 @iter2596) ([92m↓4.61%[0m) [0.69% of initial]
[Iter 4630/20000] Loss: 0.0012060 (Best: 0.0005826 @iter3898) ([92m↓24.35%[0m) [0.48% of initial]
[Iter 2680/20000] Loss: 0.0014789 (Best: 0.0013370 @iter2680) ([92m↓14.95%[0m) [0.59% of initial]
[Iter 4640/20000] Loss: 0.0010408 (Best: 0.0005826 @iter3898) ([92m↓13.69%[0m) [0.41% of initial]
[Iter 2690/20000] Loss: 0.0014587 (Best: 0.0013363 @iter2686) ([92m↓1.37%[0m) [0.58% of initial]
[Iter 4650/20000] Loss: 0.0009446 (Best: 0.0005826 @iter3898) ([92m↓9.24%[0m) [0.38% of initial]
Iter:2699, L1 loss=0.001354, Total loss=0.001432, Time:82
[Iter 2700/20000] Loss: 0.0016364 (Best: 0.0013363 @iter2686) ([91m↑12.18%[0m) [0.65% of initial]
[Iter 4660/20000] Loss: 0.0008435 (Best: 0.0005826 @iter3898) ([92m↓10.71%[0m) [0.34% of initial]
[Iter 2710/20000] Loss: 0.0014451 (Best: 0.0013218 @iter2704) ([92m↓11.69%[0m) [0.57% of initial]
[Iter 4670/20000] Loss: 0.0008318 (Best: 0.0005826 @iter3898) ([92m↓1.39%[0m) [0.33% of initial]
[Iter 2720/20000] Loss: 0.0013806 (Best: 0.0012750 @iter2715) ([92m↓4.47%[0m) [0.55% of initial]
[Iter 4680/20000] Loss: 0.0008217 (Best: 0.0005826 @iter3898) ([92m↓1.20%[0m) [0.33% of initial]
[Iter 2730/20000] Loss: 0.0013122 (Best: 0.0011773 @iter2725) ([92m↓4.95%[0m) [0.52% of initial]
[Iter 4690/20000] Loss: 0.0007790 (Best: 0.0005826 @iter3898) ([92m↓5.20%[0m) [0.31% of initial]
[Iter 2740/20000] Loss: 0.0012002 (Best: 0.0011324 @iter2740) ([92m↓8.54%[0m) [0.48% of initial]
Iter:4699, L1 loss=0.0008632, Total loss=0.000817, Time:87
[Iter 4700/20000] Loss: 0.0008416 (Best: 0.0005826 @iter3898) ([91m↑8.03%[0m) [0.33% of initial]
[Iter 2750/20000] Loss: 0.0013874 (Best: 0.0011324 @iter2740) ([91m↑15.60%[0m) [0.55% of initial]
[Iter 4710/20000] Loss: 0.0007672 (Best: 0.0005826 @iter3898) ([92m↓8.85%[0m) [0.30% of initial]
[Iter 2760/20000] Loss: 0.0014893 (Best: 0.0011324 @iter2740) ([91m↑7.34%[0m) [0.59% of initial]
[Iter 4720/20000] Loss: 0.0008382 (Best: 0.0005826 @iter3898) ([91m↑9.26%[0m) [0.33% of initial]
[Iter 2770/20000] Loss: 0.0015158 (Best: 0.0011324 @iter2740) ([91m↑1.78%[0m) [0.60% of initial]
[Iter 4730/20000] Loss: 0.0008370 (Best: 0.0005826 @iter3898) ([92m↓0.15%[0m) [0.33% of initial]
[Iter 2780/20000] Loss: 0.0013764 (Best: 0.0011324 @iter2740) ([92m↓9.20%[0m) [0.55% of initial]
[Iter 4740/20000] Loss: 0.0009398 (Best: 0.0005826 @iter3898) ([91m↑12.29%[0m) [0.37% of initial]
[Iter 2790/20000] Loss: 0.0014610 (Best: 0.0011324 @iter2740) ([91m↑6.14%[0m) [0.58% of initial]
[Iter 4750/20000] Loss: 0.0009063 (Best: 0.0005826 @iter3898) ([92m↓3.56%[0m) [0.36% of initial]
Iter:2799, L1 loss=0.001392, Total loss=0.001479, Time:84
[Iter 2800/20000] Loss: 0.0014199 (Best: 0.0011324 @iter2740) ([92m↓2.82%[0m) [0.56% of initial]
[Iter 4760/20000] Loss: 0.0008254 (Best: 0.0005826 @iter3898) ([92m↓8.92%[0m) [0.33% of initial]
[Iter 2810/20000] Loss: 0.0043417 (Best: 0.0011324 @iter2740) ([91m↑205.78%[0m) [1.72% of initial]
[Iter 4770/20000] Loss: 0.0008804 (Best: 0.0005826 @iter3898) ([91m↑6.66%[0m) [0.35% of initial]
[Iter 2820/20000] Loss: 0.0028661 (Best: 0.0011324 @iter2740) ([92m↓33.99%[0m) [1.14% of initial]
[Iter 4780/20000] Loss: 0.0009413 (Best: 0.0005826 @iter3898) ([91m↑6.92%[0m) [0.37% of initial]
[Iter 2830/20000] Loss: 0.0020100 (Best: 0.0011324 @iter2740) ([92m↓29.87%[0m) [0.80% of initial]
[Iter 4790/20000] Loss: 0.0008479 (Best: 0.0005826 @iter3898) ([92m↓9.92%[0m) [0.34% of initial]
[Iter 2840/20000] Loss: 0.0016817 (Best: 0.0011324 @iter2740) ([92m↓16.34%[0m) [0.67% of initial]
Iter:4799, L1 loss=0.0008579, Total loss=0.0008204, Time:114
[Iter 4800/20000] Loss: 0.0009536 (Best: 0.0005826 @iter3898) ([91m↑12.46%[0m) [0.38% of initial]
[Iter 2850/20000] Loss: 0.0015301 (Best: 0.0011324 @iter2740) ([92m↓9.01%[0m) [0.61% of initial]
[Iter 2860/20000] Loss: 0.0015504 (Best: 0.0011324 @iter2740) ([91m↑1.33%[0m) [0.62% of initial]
[Iter 4810/20000] Loss: 0.0020567 (Best: 0.0005826 @iter3898) ([91m↑115.69%[0m) [0.82% of initial]
[Iter 2870/20000] Loss: 0.0014054 (Best: 0.0011324 @iter2740) ([92m↓9.35%[0m) [0.56% of initial]
[Iter 4820/20000] Loss: 0.0014657 (Best: 0.0005826 @iter3898) ([92m↓28.74%[0m) [0.58% of initial]
[Iter 2880/20000] Loss: 0.0014181 (Best: 0.0011324 @iter2740) ([91m↑0.90%[0m) [0.56% of initial]
[Iter 4830/20000] Loss: 0.0012294 (Best: 0.0005826 @iter3898) ([92m↓16.12%[0m) [0.49% of initial]
[Iter 2890/20000] Loss: 0.0012920 (Best: 0.0011324 @iter2740) ([92m↓8.89%[0m) [0.51% of initial]
[Iter 4840/20000] Loss: 0.0009459 (Best: 0.0005826 @iter3898) ([92m↓23.06%[0m) [0.38% of initial]
Iter:2899, L1 loss=0.001129, Total loss=0.001147, Time:83
[Iter 2900/20000] Loss: 0.0012529 (Best: 0.0011324 @iter2740) ([92m↓3.03%[0m) [0.50% of initial]
[Iter 4850/20000] Loss: 0.0008113 (Best: 0.0005826 @iter3898) ([92m↓14.23%[0m) [0.32% of initial]
[Iter 2910/20000] Loss: 0.0013545 (Best: 0.0011324 @iter2740) ([91m↑8.11%[0m) [0.54% of initial]
[Iter 4860/20000] Loss: 0.0008451 (Best: 0.0005826 @iter3898) ([91m↑4.16%[0m) [0.34% of initial]
[Iter 2920/20000] Loss: 0.0014340 (Best: 0.0011324 @iter2740) ([91m↑5.87%[0m) [0.57% of initial]
[Iter 4870/20000] Loss: 0.0007680 (Best: 0.0005826 @iter3898) ([92m↓9.13%[0m) [0.31% of initial]
[Iter 2930/20000] Loss: 0.0013226 (Best: 0.0011324 @iter2740) ([92m↓7.77%[0m) [0.53% of initial]
[Iter 4880/20000] Loss: 0.0008288 (Best: 0.0005826 @iter3898) ([91m↑7.93%[0m) [0.33% of initial]
[Iter 2940/20000] Loss: 0.0012146 (Best: 0.0010948 @iter2932) ([92m↓8.17%[0m) [0.48% of initial]
[Iter 4890/20000] Loss: 0.0007764 (Best: 0.0005826 @iter3898) ([92m↓6.33%[0m) [0.31% of initial]
[Iter 2950/20000] Loss: 0.0011370 (Best: 0.0010455 @iter2950) ([92m↓6.38%[0m) [0.45% of initial]
Iter:4899, L1 loss=0.0009013, Total loss=0.0008643, Time:82
[Iter 4900/20000] Loss: 0.0007644 (Best: 0.0005826 @iter3898) ([92m↓1.54%[0m) [0.30% of initial]
[Iter 2960/20000] Loss: 0.0012047 (Best: 0.0010455 @iter2950) ([91m↑5.95%[0m) [0.48% of initial]
[Iter 4910/20000] Loss: 0.0009501 (Best: 0.0005826 @iter3898) ([91m↑24.29%[0m) [0.38% of initial]
[Iter 2970/20000] Loss: 0.0011299 (Best: 0.0009936 @iter2969) ([92m↓6.22%[0m) [0.45% of initial]
[Iter 4920/20000] Loss: 0.0008259 (Best: 0.0005826 @iter3898) ([92m↓13.07%[0m) [0.33% of initial]
[Iter 2980/20000] Loss: 0.0010876 (Best: 0.0009936 @iter2969) ([92m↓3.74%[0m) [0.43% of initial]
[Iter 4930/20000] Loss: 0.0007441 (Best: 0.0005826 @iter3898) ([92m↓9.90%[0m) [0.30% of initial]
[Iter 2990/20000] Loss: 0.0010871 (Best: 0.0009622 @iter2983) ([92m↓0.04%[0m) [0.43% of initial]
Iter:2999, L1 loss=0.0009547, Total loss=0.0009362, Time:88
[Iter 3000/20000] Loss: 0.0010754 (Best: 0.0009362 @iter2999) ([92m↓1.08%[0m) [0.43% of initial]
[Iter 4940/20000] Loss: 0.0007662 (Best: 0.0005826 @iter3898) ([91m↑2.97%[0m) [0.30% of initial]
Pruning 303 points (0.4%) from gaussian0 at iteration 3000
Pruning 307 points (0.4%) from gaussian1 at iteration 3000
[Iter 4950/20000] Loss: 0.0006724 (Best: 0.0005826 @iter3898) ([92m↓12.24%[0m) [0.27% of initial]
[Iter 3010/20000] Loss: 0.0041691 (Best: 0.0009362 @iter2999) ([91m↑287.69%[0m) [1.66% of initial]
[Iter 4960/20000] Loss: 0.0007207 (Best: 0.0005826 @iter3898) ([91m↑7.18%[0m) [0.29% of initial]
[Iter 3020/20000] Loss: 0.0028852 (Best: 0.0009362 @iter2999) ([92m↓30.80%[0m) [1.15% of initial]
[Iter 4970/20000] Loss: 0.0007447 (Best: 0.0005826 @iter3898) ([91m↑3.33%[0m) [0.30% of initial]
[Iter 3030/20000] Loss: 0.0021081 (Best: 0.0009362 @iter2999) ([92m↓26.93%[0m) [0.84% of initial]
[Iter 4980/20000] Loss: 0.0007569 (Best: 0.0005826 @iter3898) ([91m↑1.64%[0m) [0.30% of initial]
[Iter 3040/20000] Loss: 0.0016466 (Best: 0.0009362 @iter2999) ([92m↓21.89%[0m) [0.65% of initial]
[Iter 4990/20000] Loss: 0.0007052 (Best: 0.0005826 @iter3898) ([92m↓6.83%[0m) [0.28% of initial]
[Iter 3050/20000] Loss: 0.0015350 (Best: 0.0009362 @iter2999) ([92m↓6.78%[0m) [0.61% of initial]
Iter:4999, L1 loss=0.0007119, Total loss=0.0006712, Time:94
[Iter 5000/20000] Loss: 0.0006692 (Best: 0.0005826 @iter3898) ([92m↓5.10%[0m) [0.27% of initial]
[Iter 3060/20000] Loss: 0.0014575 (Best: 0.0009362 @iter2999) ([92m↓5.05%[0m) [0.58% of initial]
Pruning 161 points (0.1%) from gaussian0 at iteration 5000
Pruning 175 points (0.1%) from gaussian1 at iteration 5000
[Iter 3070/20000] Loss: 0.0013009 (Best: 0.0009362 @iter2999) ([92m↓10.75%[0m) [0.52% of initial]
[Iter 5010/20000] Loss: 0.0021894 (Best: 0.0005826 @iter3898) ([91m↑227.15%[0m) [0.87% of initial]
[Iter 3080/20000] Loss: 0.0013130 (Best: 0.0009362 @iter2999) ([91m↑0.93%[0m) [0.52% of initial]
[Iter 5020/20000] Loss: 0.0015636 (Best: 0.0005826 @iter3898) ([92m↓28.58%[0m) [0.62% of initial]
[Iter 3090/20000] Loss: 0.0012918 (Best: 0.0009362 @iter2999) ([92m↓1.61%[0m) [0.51% of initial]
Iter:3099, L1 loss=0.001143, Total loss=0.001155, Time:80
[Iter 3100/20000] Loss: 0.0011990 (Best: 0.0009362 @iter2999) ([92m↓7.19%[0m) [0.48% of initial]
[Iter 5030/20000] Loss: 0.0010798 (Best: 0.0005826 @iter3898) ([92m↓30.94%[0m) [0.43% of initial]
[Iter 3110/20000] Loss: 0.0012969 (Best: 0.0009362 @iter2999) ([91m↑8.17%[0m) [0.52% of initial]
[Iter 5040/20000] Loss: 0.0010443 (Best: 0.0005826 @iter3898) ([92m↓3.29%[0m) [0.41% of initial]
[Iter 3120/20000] Loss: 0.0012463 (Best: 0.0009362 @iter2999) ([92m↓3.90%[0m) [0.50% of initial]
[Iter 5050/20000] Loss: 0.0009205 (Best: 0.0005826 @iter3898) ([92m↓11.86%[0m) [0.37% of initial]
[Iter 3130/20000] Loss: 0.0011388 (Best: 0.0009362 @iter2999) ([92m↓8.63%[0m) [0.45% of initial]
[Iter 5060/20000] Loss: 0.0007606 (Best: 0.0005826 @iter3898) ([92m↓17.37%[0m) [0.30% of initial]
[Iter 3140/20000] Loss: 0.0011332 (Best: 0.0009362 @iter2999) ([92m↓0.50%[0m) [0.45% of initial]
[Iter 5070/20000] Loss: 0.0008422 (Best: 0.0005826 @iter3898) ([91m↑10.73%[0m) [0.33% of initial]
[Iter 3150/20000] Loss: 0.0011406 (Best: 0.0009362 @iter2999) ([91m↑0.65%[0m) [0.45% of initial]
[Iter 5080/20000] Loss: 0.0007230 (Best: 0.0005826 @iter3898) ([92m↓14.15%[0m) [0.29% of initial]
[Iter 3160/20000] Loss: 0.0010923 (Best: 0.0009362 @iter2999) ([92m↓4.24%[0m) [0.43% of initial]
[Iter 5090/20000] Loss: 0.0007689 (Best: 0.0005826 @iter3898) ([91m↑6.34%[0m) [0.31% of initial]
[Iter 3170/20000] Loss: 0.0010947 (Best: 0.0009362 @iter2999) ([91m↑0.23%[0m) [0.43% of initial]
Iter:5099, L1 loss=0.0008043, Total loss=0.000752, Time:100
[Iter 5100/20000] Loss: 0.0008132 (Best: 0.0005826 @iter3898) ([91m↑5.76%[0m) [0.32% of initial]
[Iter 3180/20000] Loss: 0.0011759 (Best: 0.0009362 @iter2999) ([91m↑7.42%[0m) [0.47% of initial]
[Iter 5110/20000] Loss: 0.0007753 (Best: 0.0005826 @iter3898) ([92m↓4.66%[0m) [0.31% of initial]
[Iter 3190/20000] Loss: 0.0011120 (Best: 0.0009362 @iter2999) ([92m↓5.44%[0m) [0.44% of initial]
[Iter 5120/20000] Loss: 0.0007788 (Best: 0.0005826 @iter3898) ([91m↑0.44%[0m) [0.31% of initial]
Iter:3199, L1 loss=0.001064, Total loss=0.001026, Time:86
[Iter 3200/20000] Loss: 0.0010455 (Best: 0.0009362 @iter2999) ([92m↓5.98%[0m) [0.42% of initial]
[Iter 5130/20000] Loss: 0.0008007 (Best: 0.0005826 @iter3898) ([91m↑2.81%[0m) [0.32% of initial]
[Iter 3210/20000] Loss: 0.0039976 (Best: 0.0009362 @iter2999) ([91m↑282.37%[0m) [1.59% of initial]
[Iter 5140/20000] Loss: 0.0006979 (Best: 0.0005826 @iter3898) ([92m↓12.83%[0m) [0.28% of initial]
[Iter 3220/20000] Loss: 0.0026881 (Best: 0.0009362 @iter2999) ([92m↓32.76%[0m) [1.07% of initial]
[Iter 5150/20000] Loss: 0.0007089 (Best: 0.0005826 @iter3898) ([91m↑1.57%[0m) [0.28% of initial]
[Iter 3230/20000] Loss: 0.0018072 (Best: 0.0009362 @iter2999) ([92m↓32.77%[0m) [0.72% of initial]
[Iter 5160/20000] Loss: 0.0007035 (Best: 0.0005826 @iter3898) ([92m↓0.76%[0m) [0.28% of initial]
[Iter 3240/20000] Loss: 0.0016863 (Best: 0.0009362 @iter2999) ([92m↓6.69%[0m) [0.67% of initial]
[Iter 5170/20000] Loss: 0.0007557 (Best: 0.0005826 @iter3898) ([91m↑7.42%[0m) [0.30% of initial]
[Iter 3250/20000] Loss: 0.0013470 (Best: 0.0009362 @iter2999) ([92m↓20.12%[0m) [0.54% of initial]
[Iter 3260/20000] Loss: 0.0012435 (Best: 0.0009362 @iter2999) ([92m↓7.68%[0m) [0.49% of initial]
[Iter 5180/20000] Loss: 0.0007038 (Best: 0.0005826 @iter3898) ([92m↓6.87%[0m) [0.28% of initial]
[Iter 3270/20000] Loss: 0.0012199 (Best: 0.0009362 @iter2999) ([92m↓1.90%[0m) [0.48% of initial]
[Iter 5190/20000] Loss: 0.0007163 (Best: 0.0005826 @iter3898) ([91m↑1.77%[0m) [0.28% of initial]
[Iter 3280/20000] Loss: 0.0012670 (Best: 0.0009362 @iter2999) ([91m↑3.86%[0m) [0.50% of initial]
Iter:5199, L1 loss=0.0007796, Total loss=0.0007565, Time:86
[Iter 5200/20000] Loss: 0.0006980 (Best: 0.0005826 @iter3898) ([92m↓2.55%[0m) [0.28% of initial]
[Iter 3290/20000] Loss: 0.0010779 (Best: 0.0009362 @iter2999) ([92m↓14.92%[0m) [0.43% of initial]
[Iter 5210/20000] Loss: 0.0017581 (Best: 0.0005826 @iter3898) ([91m↑151.87%[0m) [0.70% of initial]
Iter:3299, L1 loss=0.001455, Total loss=0.001582, Time:92
[Iter 3300/20000] Loss: 0.0013295 (Best: 0.0009362 @iter2999) ([91m↑23.34%[0m) [0.53% of initial]
[Iter 5220/20000] Loss: 0.0013548 (Best: 0.0005826 @iter3898) ([92m↓22.94%[0m) [0.54% of initial]
[Iter 3310/20000] Loss: 0.0010681 (Best: 0.0009362 @iter2999) ([92m↓19.66%[0m) [0.42% of initial]
[Iter 5230/20000] Loss: 0.0010403 (Best: 0.0005826 @iter3898) ([92m↓23.22%[0m) [0.41% of initial]
[Iter 3320/20000] Loss: 0.0011380 (Best: 0.0009362 @iter2999) ([91m↑6.54%[0m) [0.45% of initial]
[Iter 3330/20000] Loss: 0.0011932 (Best: 0.0009362 @iter2999) ([91m↑4.84%[0m) [0.47% of initial]
[Iter 5240/20000] Loss: 0.0008129 (Best: 0.0005826 @iter3898) ([92m↓21.85%[0m) [0.32% of initial]
[Iter 3340/20000] Loss: 0.0012374 (Best: 0.0009362 @iter2999) ([91m↑3.71%[0m) [0.49% of initial]
[Iter 5250/20000] Loss: 0.0010630 (Best: 0.0005826 @iter3898) ([91m↑30.77%[0m) [0.42% of initial]
[Iter 3350/20000] Loss: 0.0011228 (Best: 0.0009362 @iter2999) ([92m↓9.26%[0m) [0.45% of initial]
[Iter 5260/20000] Loss: 0.0008469 (Best: 0.0005826 @iter3898) ([92m↓20.33%[0m) [0.34% of initial]
[Iter 3360/20000] Loss: 0.0013262 (Best: 0.0009362 @iter2999) ([91m↑18.12%[0m) [0.53% of initial]
[Iter 5270/20000] Loss: 0.0007888 (Best: 0.0005826 @iter3898) ([92m↓6.86%[0m) [0.31% of initial]
[Iter 3370/20000] Loss: 0.0010578 (Best: 0.0009362 @iter2999) ([92m↓20.24%[0m) [0.42% of initial]
[Iter 5280/20000] Loss: 0.0008567 (Best: 0.0005826 @iter3898) ([91m↑8.60%[0m) [0.34% of initial]
[Iter 3380/20000] Loss: 0.0009973 (Best: 0.0009286 @iter3379) ([92m↓5.72%[0m) [0.40% of initial]
[Iter 5290/20000] Loss: 0.0007981 (Best: 0.0005826 @iter3898) ([92m↓6.84%[0m) [0.32% of initial]
[Iter 3390/20000] Loss: 0.0012599 (Best: 0.0009286 @iter3379) ([91m↑26.33%[0m) [0.50% of initial]
Iter:5299, L1 loss=0.0008725, Total loss=0.0008205, Time:104
[Iter 5300/20000] Loss: 0.0008843 (Best: 0.0005826 @iter3898) ([91m↑10.81%[0m) [0.35% of initial]
Iter:3399, L1 loss=0.001312, Total loss=0.001377, Time:79
[Iter 3400/20000] Loss: 0.0012725 (Best: 0.0009286 @iter3379) ([91m↑1.00%[0m) [0.51% of initial]
[Iter 5310/20000] Loss: 0.0008751 (Best: 0.0005826 @iter3898) ([92m↓1.04%[0m) [0.35% of initial]
[Iter 3410/20000] Loss: 0.0034033 (Best: 0.0009286 @iter3379) ([91m↑167.46%[0m) [1.35% of initial]
[Iter 5320/20000] Loss: 0.0007760 (Best: 0.0005826 @iter3898) ([92m↓11.33%[0m) [0.31% of initial]
[Iter 3420/20000] Loss: 0.0021465 (Best: 0.0009286 @iter3379) ([92m↓36.93%[0m) [0.85% of initial]
[Iter 5330/20000] Loss: 0.0006667 (Best: 0.0005826 @iter3898) ([92m↓14.09%[0m) [0.26% of initial]
[Iter 3430/20000] Loss: 0.0014959 (Best: 0.0009286 @iter3379) ([92m↓30.31%[0m) [0.59% of initial]
[Iter 5340/20000] Loss: 0.0006924 (Best: 0.0005826 @iter3898) ([91m↑3.86%[0m) [0.28% of initial]
[Iter 3440/20000] Loss: 0.0014520 (Best: 0.0009286 @iter3379) ([92m↓2.93%[0m) [0.58% of initial]
[Iter 5350/20000] Loss: 0.0007079 (Best: 0.0005651 @iter5344) ([91m↑2.24%[0m) [0.28% of initial]
[Iter 3450/20000] Loss: 0.0013377 (Best: 0.0009286 @iter3379) ([92m↓7.87%[0m) [0.53% of initial]
[Iter 5360/20000] Loss: 0.0007039 (Best: 0.0005651 @iter5344) ([92m↓0.56%[0m) [0.28% of initial]
[Iter 3460/20000] Loss: 0.0012358 (Best: 0.0009286 @iter3379) ([92m↓7.62%[0m) [0.49% of initial]
[Iter 3470/20000] Loss: 0.0011843 (Best: 0.0009286 @iter3379) ([92m↓4.16%[0m) [0.47% of initial]
[Iter 5370/20000] Loss: 0.0007225 (Best: 0.0005651 @iter5344) ([91m↑2.64%[0m) [0.29% of initial]
[Iter 3480/20000] Loss: 0.0011321 (Best: 0.0009286 @iter3379) ([92m↓4.41%[0m) [0.45% of initial]
[Iter 5380/20000] Loss: 0.0007188 (Best: 0.0005651 @iter5344) ([92m↓0.51%[0m) [0.29% of initial]
[Iter 3490/20000] Loss: 0.0010425 (Best: 0.0008903 @iter3487) ([92m↓7.92%[0m) [0.41% of initial]
[Iter 5390/20000] Loss: 0.0007222 (Best: 0.0005651 @iter5344) ([91m↑0.48%[0m) [0.29% of initial]
Iter:3499, L1 loss=0.0008799, Total loss=0.0008372, Time:90
[Iter 3500/20000] Loss: 0.0008977 (Best: 0.0008372 @iter3499) ([92m↓13.89%[0m) [0.36% of initial]
Iter:5399, L1 loss=0.0006922, Total loss=0.0006394, Time:103
Pruning 241 points (0.3%) from gaussian0 at iteration 3500
[Iter 5400/20000] Loss: 0.0007228 (Best: 0.0005651 @iter5344) ([91m↑0.08%[0m) [0.29% of initial]
Pruning 223 points (0.2%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0020557 (Best: 0.0008372 @iter3499) ([91m↑128.99%[0m) [0.82% of initial]
[Iter 5410/20000] Loss: 0.0015538 (Best: 0.0005651 @iter5344) ([91m↑114.96%[0m) [0.62% of initial]
[Iter 3520/20000] Loss: 0.0014519 (Best: 0.0008372 @iter3499) ([92m↓29.37%[0m) [0.58% of initial]
[Iter 5420/20000] Loss: 0.0012221 (Best: 0.0005651 @iter5344) ([92m↓21.35%[0m) [0.49% of initial]
[Iter 3530/20000] Loss: 0.0011954 (Best: 0.0008372 @iter3499) ([92m↓17.66%[0m) [0.47% of initial]
[Iter 5430/20000] Loss: 0.0008781 (Best: 0.0005651 @iter5344) ([92m↓28.15%[0m) [0.35% of initial]
[Iter 3540/20000] Loss: 0.0012944 (Best: 0.0008372 @iter3499) ([91m↑8.28%[0m) [0.51% of initial]
[Iter 5440/20000] Loss: 0.0007964 (Best: 0.0005651 @iter5344) ([92m↓9.31%[0m) [0.32% of initial]
[Iter 3550/20000] Loss: 0.0011980 (Best: 0.0008372 @iter3499) ([92m↓7.45%[0m) [0.48% of initial]
[Iter 5450/20000] Loss: 0.0006970 (Best: 0.0005651 @iter5344) ([92m↓12.47%[0m) [0.28% of initial]
[Iter 3560/20000] Loss: 0.0011062 (Best: 0.0008372 @iter3499) ([92m↓7.66%[0m) [0.44% of initial]
[Iter 5460/20000] Loss: 0.0007643 (Best: 0.0005651 @iter5344) ([91m↑9.65%[0m) [0.30% of initial]
[Iter 3570/20000] Loss: 0.0011930 (Best: 0.0008372 @iter3499) ([91m↑7.85%[0m) [0.47% of initial]
[Iter 3580/20000] Loss: 0.0009532 (Best: 0.0008372 @iter3499) ([92m↓20.10%[0m) [0.38% of initial]
[Iter 5470/20000] Loss: 0.0006756 (Best: 0.0005651 @iter5344) ([92m↓11.60%[0m) [0.27% of initial]
[Iter 3590/20000] Loss: 0.0009359 (Best: 0.0008372 @iter3499) ([92m↓1.81%[0m) [0.37% of initial]
[Iter 5480/20000] Loss: 0.0006370 (Best: 0.0005454 @iter5476) ([92m↓5.72%[0m) [0.25% of initial]
Iter:3599, L1 loss=0.0009053, Total loss=0.0008562, Time:90
[Iter 3600/20000] Loss: 0.0009218 (Best: 0.0008226 @iter3598) ([92m↓1.51%[0m) [0.37% of initial]
[Iter 5490/20000] Loss: 0.0006633 (Best: 0.0005454 @iter5476) ([91m↑4.12%[0m) [0.26% of initial]
Iter:5499, L1 loss=0.0007172, Total loss=0.0006643, Time:99
[Iter 3610/20000] Loss: 0.0036160 (Best: 0.0008226 @iter3598) ([91m↑292.28%[0m) [1.44% of initial]
[Iter 5500/20000] Loss: 0.0006145 (Best: 0.0005454 @iter5476) ([92m↓7.36%[0m) [0.24% of initial]
Pruning 104 points (0.1%) from gaussian0 at iteration 5500
Pruning 97 points (0.1%) from gaussian1 at iteration 5500
[Iter 3620/20000] Loss: 0.0025787 (Best: 0.0008226 @iter3598) ([92m↓28.68%[0m) [1.02% of initial]
[Iter 5510/20000] Loss: 0.0011416 (Best: 0.0005454 @iter5476) ([91m↑85.78%[0m) [0.45% of initial]
[Iter 3630/20000] Loss: 0.0016161 (Best: 0.0008226 @iter3598) ([92m↓37.33%[0m) [0.64% of initial]
[Iter 5520/20000] Loss: 0.0008652 (Best: 0.0005454 @iter5476) ([92m↓24.22%[0m) [0.34% of initial]
[Iter 3640/20000] Loss: 0.0012820 (Best: 0.0008226 @iter3598) ([92m↓20.67%[0m) [0.51% of initial]
[Iter 3650/20000] Loss: 0.0012421 (Best: 0.0008226 @iter3598) ([92m↓3.11%[0m) [0.49% of initial]
[Iter 5530/20000] Loss: 0.0007997 (Best: 0.0005454 @iter5476) ([92m↓7.57%[0m) [0.32% of initial]
[Iter 3660/20000] Loss: 0.0010879 (Best: 0.0008226 @iter3598) ([92m↓12.42%[0m) [0.43% of initial]
[Iter 5540/20000] Loss: 0.0007479 (Best: 0.0005454 @iter5476) ([92m↓6.47%[0m) [0.30% of initial]
[Iter 3670/20000] Loss: 0.0010084 (Best: 0.0008226 @iter3598) ([92m↓7.31%[0m) [0.40% of initial]
[Iter 5550/20000] Loss: 0.0007111 (Best: 0.0005454 @iter5476) ([92m↓4.92%[0m) [0.28% of initial]
[Iter 3680/20000] Loss: 0.0010972 (Best: 0.0008226 @iter3598) ([91m↑8.82%[0m) [0.44% of initial]
[Iter 5560/20000] Loss: 0.0006600 (Best: 0.0005454 @iter5476) ([92m↓7.19%[0m) [0.26% of initial]
[Iter 3690/20000] Loss: 0.0013417 (Best: 0.0008226 @iter3598) ([91m↑22.28%[0m) [0.53% of initial]
[Iter 5570/20000] Loss: 0.0006588 (Best: 0.0005454 @iter5476) ([92m↓0.17%[0m) [0.26% of initial]
Iter:3699, L1 loss=0.001162, Total loss=0.00114, Time:82
[Iter 3700/20000] Loss: 0.0011725 (Best: 0.0008226 @iter3598) ([92m↓12.61%[0m) [0.47% of initial]
[Iter 5580/20000] Loss: 0.0007629 (Best: 0.0005454 @iter5476) ([91m↑15.80%[0m) [0.30% of initial]
[Iter 3710/20000] Loss: 0.0009755 (Best: 0.0008226 @iter3598) ([92m↓16.80%[0m) [0.39% of initial]
[Iter 5590/20000] Loss: 0.0008209 (Best: 0.0005454 @iter5476) ([91m↑7.60%[0m) [0.33% of initial]
[Iter 3720/20000] Loss: 0.0010859 (Best: 0.0008093 @iter3712) ([91m↑11.31%[0m) [0.43% of initial]
Iter:5599, L1 loss=0.0006638, Total loss=0.0006068, Time:108
[Iter 5600/20000] Loss: 0.0006343 (Best: 0.0005454 @iter5476) ([92m↓22.74%[0m) [0.25% of initial]
[Iter 3730/20000] Loss: 0.0009412 (Best: 0.0008093 @iter3712) ([92m↓13.32%[0m) [0.37% of initial]
[Iter 3740/20000] Loss: 0.0009496 (Best: 0.0008093 @iter3712) ([91m↑0.89%[0m) [0.38% of initial]
[Iter 5610/20000] Loss: 0.0017021 (Best: 0.0005454 @iter5476) ([91m↑168.35%[0m) [0.68% of initial]
[Iter 3750/20000] Loss: 0.0009995 (Best: 0.0008093 @iter3712) ([91m↑5.25%[0m) [0.40% of initial]
[Iter 5620/20000] Loss: 0.0011164 (Best: 0.0005454 @iter5476) ([92m↓34.41%[0m) [0.44% of initial]
[Iter 3760/20000] Loss: 0.0009403 (Best: 0.0008093 @iter3712) ([92m↓5.92%[0m) [0.37% of initial]
[Iter 5630/20000] Loss: 0.0009132 (Best: 0.0005454 @iter5476) ([92m↓18.20%[0m) [0.36% of initial]
[Iter 3770/20000] Loss: 0.0009488 (Best: 0.0007933 @iter3763) ([91m↑0.90%[0m) [0.38% of initial]
[Iter 5640/20000] Loss: 0.0008197 (Best: 0.0005454 @iter5476) ([92m↓10.23%[0m) [0.33% of initial]
[Iter 3780/20000] Loss: 0.0009172 (Best: 0.0007593 @iter3775) ([92m↓3.33%[0m) [0.36% of initial]
[Iter 5650/20000] Loss: 0.0007016 (Best: 0.0005454 @iter5476) ([92m↓14.41%[0m) [0.28% of initial]
[Iter 3790/20000] Loss: 0.0007977 (Best: 0.0007481 @iter3790) ([92m↓13.03%[0m) [0.32% of initial]
[Iter 5660/20000] Loss: 0.0006986 (Best: 0.0005454 @iter5476) ([92m↓0.43%[0m) [0.28% of initial]
Iter:3799, L1 loss=0.0009468, Total loss=0.0009384, Time:85
[Iter 3800/20000] Loss: 0.0009125 (Best: 0.0007481 @iter3790) ([91m↑14.40%[0m) [0.36% of initial]
[Iter 5670/20000] Loss: 0.0006969 (Best: 0.0005454 @iter5476) ([92m↓0.23%[0m) [0.28% of initial]
[Iter 3810/20000] Loss: 0.0031489 (Best: 0.0007481 @iter3790) ([91m↑245.07%[0m) [1.25% of initial]
[Iter 5680/20000] Loss: 0.0006331 (Best: 0.0005454 @iter5476) ([92m↓9.16%[0m) [0.25% of initial]
[Iter 3820/20000] Loss: 0.0020456 (Best: 0.0007481 @iter3790) ([92m↓35.04%[0m) [0.81% of initial]
[Iter 5690/20000] Loss: 0.0006722 (Best: 0.0005454 @iter5476) ([91m↑6.16%[0m) [0.27% of initial]
[Iter 3830/20000] Loss: 0.0013717 (Best: 0.0007481 @iter3790) ([92m↓32.94%[0m) [0.54% of initial]
Iter:5699, L1 loss=0.0006586, Total loss=0.0005932, Time:104
[Iter 5700/20000] Loss: 0.0005848 (Best: 0.0005454 @iter5476) ([92m↓13.00%[0m) [0.23% of initial]
[Iter 3840/20000] Loss: 0.0014319 (Best: 0.0007481 @iter3790) ([91m↑4.39%[0m) [0.57% of initial]
[Iter 3850/20000] Loss: 0.0011297 (Best: 0.0007481 @iter3790) ([92m↓21.11%[0m) [0.45% of initial]
[Iter 5710/20000] Loss: 0.0007323 (Best: 0.0005175 @iter5701) ([91m↑25.22%[0m) [0.29% of initial]
[Iter 3860/20000] Loss: 0.0010759 (Best: 0.0007481 @iter3790) ([92m↓4.76%[0m) [0.43% of initial]
[Iter 5720/20000] Loss: 0.0006569 (Best: 0.0005175 @iter5701) ([92m↓10.29%[0m) [0.26% of initial]
[Iter 3870/20000] Loss: 0.0009293 (Best: 0.0007481 @iter3790) ([92m↓13.62%[0m) [0.37% of initial]
[Iter 5730/20000] Loss: 0.0006818 (Best: 0.0005163 @iter5725) ([91m↑3.78%[0m) [0.27% of initial]
[Iter 3880/20000] Loss: 0.0009363 (Best: 0.0007481 @iter3790) ([91m↑0.75%[0m) [0.37% of initial]
[Iter 5740/20000] Loss: 0.0005843 (Best: 0.0005163 @iter5725) ([92m↓14.31%[0m) [0.23% of initial]
[Iter 3890/20000] Loss: 0.0008285 (Best: 0.0007403 @iter3883) ([92m↓11.51%[0m) [0.33% of initial]
[Iter 5750/20000] Loss: 0.0005889 (Best: 0.0005163 @iter5725) ([91m↑0.80%[0m) [0.23% of initial]
Iter:3899, L1 loss=0.0009281, Total loss=0.0009019, Time:85
[Iter 3900/20000] Loss: 0.0008212 (Best: 0.0006949 @iter3898) ([92m↓0.89%[0m) [0.33% of initial]
[Iter 5760/20000] Loss: 0.0005956 (Best: 0.0005163 @iter5725) ([91m↑1.14%[0m) [0.24% of initial]
[Iter 3910/20000] Loss: 0.0009351 (Best: 0.0006949 @iter3898) ([91m↑13.87%[0m) [0.37% of initial]
[Iter 5770/20000] Loss: 0.0005295 (Best: 0.0004732 @iter5770) ([92m↓11.10%[0m) [0.21% of initial]
[Iter 3920/20000] Loss: 0.0009599 (Best: 0.0006949 @iter3898) ([91m↑2.66%[0m) [0.38% of initial]
[Iter 5780/20000] Loss: 0.0005499 (Best: 0.0004732 @iter5770) ([91m↑3.85%[0m) [0.22% of initial]
[Iter 3930/20000] Loss: 0.0009315 (Best: 0.0006949 @iter3898) ([92m↓2.97%[0m) [0.37% of initial]
[Iter 5790/20000] Loss: 0.0005837 (Best: 0.0004732 @iter5770) ([91m↑6.15%[0m) [0.23% of initial]
[Iter 3940/20000] Loss: 0.0008536 (Best: 0.0006949 @iter3898) ([92m↓8.36%[0m) [0.34% of initial]
Iter:5799, L1 loss=0.0006193, Total loss=0.0005695, Time:94
[Iter 3950/20000] Loss: 0.0008898 (Best: 0.0006949 @iter3898) ([91m↑4.24%[0m) [0.35% of initial]
[Iter 5800/20000] Loss: 0.0005666 (Best: 0.0004593 @iter5797) ([92m↓2.93%[0m) [0.23% of initial]
[Iter 3960/20000] Loss: 0.0009222 (Best: 0.0006949 @iter3898) ([91m↑3.63%[0m) [0.37% of initial]
[Iter 5810/20000] Loss: 0.0013635 (Best: 0.0004593 @iter5797) ([91m↑140.64%[0m) [0.54% of initial]
[Iter 3970/20000] Loss: 0.0008664 (Best: 0.0006949 @iter3898) ([92m↓6.05%[0m) [0.34% of initial]
[Iter 5820/20000] Loss: 0.0011070 (Best: 0.0004593 @iter5797) ([92m↓18.81%[0m) [0.44% of initial]
[Iter 3980/20000] Loss: 0.0011146 (Best: 0.0006949 @iter3898) ([91m↑28.65%[0m) [0.44% of initial]
[Iter 5830/20000] Loss: 0.0008350 (Best: 0.0004593 @iter5797) ([92m↓24.57%[0m) [0.33% of initial]
[Iter 3990/20000] Loss: 0.0009111 (Best: 0.0006949 @iter3898) ([92m↓18.26%[0m) [0.36% of initial]
[Iter 5840/20000] Loss: 0.0007115 (Best: 0.0004593 @iter5797) ([92m↓14.79%[0m) [0.28% of initial]
Iter:3999, L1 loss=0.0009555, Total loss=0.0008931, Time:66
[Iter 4000/20000] Loss: 0.0008598 (Best: 0.0006949 @iter3898) ([92m↓5.63%[0m) [0.34% of initial]
Pruning 173 points (0.2%) from gaussian0 at iteration 4000
Pruning 184 points (0.2%) from gaussian1 at iteration 4000
[Iter 5850/20000] Loss: 0.0007083 (Best: 0.0004593 @iter5797) ([92m↓0.45%[0m) [0.28% of initial]
[Iter 4010/20000] Loss: 0.0034466 (Best: 0.0006949 @iter3898) ([91m↑300.85%[0m) [1.37% of initial]
[Iter 5860/20000] Loss: 0.0005963 (Best: 0.0004593 @iter5797) ([92m↓15.81%[0m) [0.24% of initial]
[Iter 4020/20000] Loss: 0.0022368 (Best: 0.0006949 @iter3898) ([92m↓35.10%[0m) [0.89% of initial]
[Iter 5870/20000] Loss: 0.0006748 (Best: 0.0004593 @iter5797) ([91m↑13.16%[0m) [0.27% of initial]
[Iter 4030/20000] Loss: 0.0014126 (Best: 0.0006949 @iter3898) ([92m↓36.85%[0m) [0.56% of initial]
[Iter 5880/20000] Loss: 0.0006286 (Best: 0.0004593 @iter5797) ([92m↓6.84%[0m) [0.25% of initial]
[Iter 4040/20000] Loss: 0.0011300 (Best: 0.0006949 @iter3898) ([92m↓20.01%[0m) [0.45% of initial]
[Iter 5890/20000] Loss: 0.0005917 (Best: 0.0004593 @iter5797) ([92m↓5.87%[0m) [0.24% of initial]
[Iter 4050/20000] Loss: 0.0010267 (Best: 0.0006949 @iter3898) ([92m↓9.14%[0m) [0.41% of initial]
Iter:5899, L1 loss=0.0006195, Total loss=0.0005694, Time:89
[Iter 5900/20000] Loss: 0.0005780 (Best: 0.0004593 @iter5797) ([92m↓2.31%[0m) [0.23% of initial]
[Iter 4060/20000] Loss: 0.0009571 (Best: 0.0006949 @iter3898) ([92m↓6.78%[0m) [0.38% of initial]
[Iter 5910/20000] Loss: 0.0006164 (Best: 0.0004593 @iter5797) ([91m↑6.64%[0m) [0.24% of initial]
[Iter 4070/20000] Loss: 0.0008555 (Best: 0.0006949 @iter3898) ([92m↓10.62%[0m) [0.34% of initial]
[Iter 5920/20000] Loss: 0.0005828 (Best: 0.0004593 @iter5797) ([92m↓5.45%[0m) [0.23% of initial]
[Iter 4080/20000] Loss: 0.0009222 (Best: 0.0006949 @iter3898) ([91m↑7.80%[0m) [0.37% of initial]
[Iter 5930/20000] Loss: 0.0004980 (Best: 0.0004593 @iter5797) ([92m↓14.56%[0m) [0.20% of initial]
[Iter 4090/20000] Loss: 0.0008043 (Best: 0.0006949 @iter3898) ([92m↓12.79%[0m) [0.32% of initial]
Iter:4099, L1 loss=0.0008445, Total loss=0.0008173, Time:95
[Iter 4100/20000] Loss: 0.0007945 (Best: 0.0006949 @iter3898) ([92m↓1.22%[0m) [0.32% of initial]
[Iter 5940/20000] Loss: 0.0006626 (Best: 0.0004593 @iter5797) ([91m↑33.07%[0m) [0.26% of initial]
[Iter 4110/20000] Loss: 0.0008982 (Best: 0.0006949 @iter3898) ([91m↑13.06%[0m) [0.36% of initial]
[Iter 5950/20000] Loss: 0.0005371 (Best: 0.0004593 @iter5797) ([92m↓18.94%[0m) [0.21% of initial]
[Iter 4120/20000] Loss: 0.0009108 (Best: 0.0006949 @iter3898) ([91m↑1.40%[0m) [0.36% of initial]
[Iter 5960/20000] Loss: 0.0005799 (Best: 0.0004593 @iter5797) ([91m↑7.96%[0m) [0.23% of initial]
[Iter 4130/20000] Loss: 0.0010192 (Best: 0.0006949 @iter3898) ([91m↑11.90%[0m) [0.40% of initial]
[Iter 5970/20000] Loss: 0.0006724 (Best: 0.0004593 @iter5797) ([91m↑15.94%[0m) [0.27% of initial]
[Iter 4140/20000] Loss: 0.0009807 (Best: 0.0006949 @iter3898) ([92m↓3.78%[0m) [0.39% of initial]
[Iter 5980/20000] Loss: 0.0006056 (Best: 0.0004593 @iter5797) ([92m↓9.92%[0m) [0.24% of initial]
[Iter 4150/20000] Loss: 0.0008359 (Best: 0.0006949 @iter3898) ([92m↓14.76%[0m) [0.33% of initial]
[Iter 5990/20000] Loss: 0.0006060 (Best: 0.0004593 @iter5797) ([91m↑0.06%[0m) [0.24% of initial]
[Iter 4160/20000] Loss: 0.0009980 (Best: 0.0006949 @iter3898) ([91m↑19.39%[0m) [0.40% of initial]
Iter:5999, L1 loss=0.0006792, Total loss=0.0006244, Time:102
[Iter 6000/20000] Loss: 0.0006173 (Best: 0.0004593 @iter5797) ([91m↑1.86%[0m) [0.25% of initial]
[Iter 4170/20000] Loss: 0.0008496 (Best: 0.0006949 @iter3898) ([92m↓14.87%[0m) [0.34% of initial]
Pruning 82 points (0.0%) from gaussian0 at iteration 6000
Pruning 102 points (0.1%) from gaussian1 at iteration 6000
[Iter 4180/20000] Loss: 0.0008675 (Best: 0.0006949 @iter3898) ([91m↑2.11%[0m) [0.34% of initial]
[Iter 4190/20000] Loss: 0.0008915 (Best: 0.0006949 @iter3898) ([91m↑2.76%[0m) [0.35% of initial]
[Iter 6010/20000] Loss: 0.0019485 (Best: 0.0004593 @iter5797) ([91m↑215.67%[0m) [0.77% of initial]
Iter:4199, L1 loss=0.0008864, Total loss=0.0008683, Time:88
[Iter 4200/20000] Loss: 0.0009405 (Best: 0.0006949 @iter3898) ([91m↑5.49%[0m) [0.37% of initial]
[Iter 6020/20000] Loss: 0.0013360 (Best: 0.0004593 @iter5797) ([92m↓31.43%[0m) [0.53% of initial]
[Iter 6030/20000] Loss: 0.0008994 (Best: 0.0004593 @iter5797) ([92m↓32.68%[0m) [0.36% of initial]
[Iter 4210/20000] Loss: 0.0029104 (Best: 0.0006949 @iter3898) ([91m↑209.46%[0m) [1.16% of initial]
[Iter 6040/20000] Loss: 0.0007048 (Best: 0.0004593 @iter5797) ([92m↓21.63%[0m) [0.28% of initial]
[Iter 4220/20000] Loss: 0.0018524 (Best: 0.0006949 @iter3898) ([92m↓36.35%[0m) [0.74% of initial]
[Iter 4230/20000] Loss: 0.0012242 (Best: 0.0006949 @iter3898) ([92m↓33.91%[0m) [0.49% of initial]
[Iter 6050/20000] Loss: 0.0006318 (Best: 0.0004593 @iter5797) ([92m↓10.36%[0m) [0.25% of initial]
[Iter 4240/20000] Loss: 0.0009994 (Best: 0.0006949 @iter3898) ([92m↓18.36%[0m) [0.40% of initial]
[Iter 6060/20000] Loss: 0.0006694 (Best: 0.0004593 @iter5797) ([91m↑5.94%[0m) [0.27% of initial]
[Iter 4250/20000] Loss: 0.0009818 (Best: 0.0006949 @iter3898) ([92m↓1.76%[0m) [0.39% of initial]
[Iter 6070/20000] Loss: 0.0006572 (Best: 0.0004593 @iter5797) ([92m↓1.81%[0m) [0.26% of initial]
[Iter 4260/20000] Loss: 0.0010834 (Best: 0.0006949 @iter3898) ([91m↑10.35%[0m) [0.43% of initial]
[Iter 6080/20000] Loss: 0.0006429 (Best: 0.0004593 @iter5797) ([92m↓2.18%[0m) [0.26% of initial]
[Iter 4270/20000] Loss: 0.0009668 (Best: 0.0006949 @iter3898) ([92m↓10.76%[0m) [0.38% of initial]
[Iter 6090/20000] Loss: 0.0005806 (Best: 0.0004593 @iter5797) ([92m↓9.69%[0m) [0.23% of initial]
[Iter 4280/20000] Loss: 0.0008375 (Best: 0.0006949 @iter3898) ([92m↓13.37%[0m) [0.33% of initial]
Iter:6099, L1 loss=0.0006044, Total loss=0.0005431, Time:124
[Iter 6100/20000] Loss: 0.0005806 (Best: 0.0004593 @iter5797) ([91m↑0.00%[0m) [0.23% of initial]
[Iter 4290/20000] Loss: 0.0007909 (Best: 0.0006949 @iter3898) ([92m↓5.57%[0m) [0.31% of initial]
[Iter 6110/20000] Loss: 0.0005698 (Best: 0.0004593 @iter5797) ([92m↓1.86%[0m) [0.23% of initial]
Iter:4299, L1 loss=0.0009037, Total loss=0.0008658, Time:92
[Iter 4300/20000] Loss: 0.0007964 (Best: 0.0006949 @iter3898) ([91m↑0.70%[0m) [0.32% of initial]
[Iter 6120/20000] Loss: 0.0006352 (Best: 0.0004593 @iter5797) ([91m↑11.47%[0m) [0.25% of initial]
[Iter 4310/20000] Loss: 0.0007816 (Best: 0.0006949 @iter3898) ([92m↓1.86%[0m) [0.31% of initial]
[Iter 6130/20000] Loss: 0.0006068 (Best: 0.0004593 @iter5797) ([92m↓4.46%[0m) [0.24% of initial]
[Iter 4320/20000] Loss: 0.0009564 (Best: 0.0006949 @iter3898) ([91m↑22.36%[0m) [0.38% of initial]
[Iter 4330/20000] Loss: 0.0008257 (Best: 0.0006949 @iter3898) ([92m↓13.66%[0m) [0.33% of initial]
[Iter 6140/20000] Loss: 0.0005206 (Best: 0.0004593 @iter5797) ([92m↓14.21%[0m) [0.21% of initial]
[Iter 4340/20000] Loss: 0.0007861 (Best: 0.0006638 @iter4336) ([92m↓4.80%[0m) [0.31% of initial]
[Iter 6150/20000] Loss: 0.0005434 (Best: 0.0004593 @iter5797) ([91m↑4.39%[0m) [0.22% of initial]
[Iter 4350/20000] Loss: 0.0007601 (Best: 0.0006638 @iter4336) ([92m↓3.30%[0m) [0.30% of initial]
[Iter 6160/20000] Loss: 0.0005223 (Best: 0.0004593 @iter5797) ([92m↓3.89%[0m) [0.21% of initial]
[Iter 4360/20000] Loss: 0.0007743 (Best: 0.0006638 @iter4336) ([91m↑1.87%[0m) [0.31% of initial]
[Iter 6170/20000] Loss: 0.0005505 (Best: 0.0004593 @iter5797) ([91m↑5.42%[0m) [0.22% of initial]
[Iter 4370/20000] Loss: 0.0007698 (Best: 0.0006638 @iter4336) ([92m↓0.59%[0m) [0.31% of initial]
[Iter 6180/20000] Loss: 0.0006207 (Best: 0.0004593 @iter5797) ([91m↑12.74%[0m) [0.25% of initial]
[Iter 4380/20000] Loss: 0.0008363 (Best: 0.0006638 @iter4336) ([91m↑8.64%[0m) [0.33% of initial]
[Iter 6190/20000] Loss: 0.0005214 (Best: 0.0004593 @iter5797) ([92m↓15.99%[0m) [0.21% of initial]
[Iter 4390/20000] Loss: 0.0007439 (Best: 0.0006638 @iter4336) ([92m↓11.04%[0m) [0.30% of initial]
Iter:6199, L1 loss=0.0005262, Total loss=0.0004799, Time:122
[Iter 6200/20000] Loss: 0.0005327 (Best: 0.0004593 @iter5797) ([91m↑2.16%[0m) [0.21% of initial]
Iter:4399, L1 loss=0.0007384, Total loss=0.0006984, Time:82
[Iter 4400/20000] Loss: 0.0007307 (Best: 0.0006476 @iter4396) ([92m↓1.78%[0m) [0.29% of initial]
[Iter 6210/20000] Loss: 0.0013780 (Best: 0.0004593 @iter5797) ([91m↑158.68%[0m) [0.55% of initial]
[Iter 4410/20000] Loss: 0.0026616 (Best: 0.0006476 @iter4396) ([91m↑264.25%[0m) [1.06% of initial]
[Iter 6220/20000] Loss: 0.0010307 (Best: 0.0004593 @iter5797) ([92m↓25.20%[0m) [0.41% of initial]
[Iter 4420/20000] Loss: 0.0015461 (Best: 0.0006476 @iter4396) ([92m↓41.91%[0m) [0.61% of initial]
[Iter 4430/20000] Loss: 0.0012137 (Best: 0.0006476 @iter4396) ([92m↓21.50%[0m) [0.48% of initial]
[Iter 6230/20000] Loss: 0.0008827 (Best: 0.0004593 @iter5797) ([92m↓14.36%[0m) [0.35% of initial]
[Iter 4440/20000] Loss: 0.0009579 (Best: 0.0006476 @iter4396) ([92m↓21.08%[0m) [0.38% of initial]
[Iter 6240/20000] Loss: 0.0006981 (Best: 0.0004593 @iter5797) ([92m↓20.92%[0m) [0.28% of initial]
[Iter 4450/20000] Loss: 0.0008322 (Best: 0.0006476 @iter4396) ([92m↓13.13%[0m) [0.33% of initial]
[Iter 6250/20000] Loss: 0.0006119 (Best: 0.0004593 @iter5797) ([92m↓12.35%[0m) [0.24% of initial]
[Iter 4460/20000] Loss: 0.0008517 (Best: 0.0006476 @iter4396) ([91m↑2.35%[0m) [0.34% of initial]
[Iter 6260/20000] Loss: 0.0006953 (Best: 0.0004593 @iter5797) ([91m↑13.63%[0m) [0.28% of initial]
[Iter 4470/20000] Loss: 0.0008907 (Best: 0.0006476 @iter4396) ([91m↑4.58%[0m) [0.35% of initial]
[Iter 6270/20000] Loss: 0.0006165 (Best: 0.0004593 @iter5797) ([92m↓11.32%[0m) [0.24% of initial]
[Iter 4480/20000] Loss: 0.0008645 (Best: 0.0006476 @iter4396) ([92m↓2.94%[0m) [0.34% of initial]
[Iter 6280/20000] Loss: 0.0006450 (Best: 0.0004593 @iter5797) ([91m↑4.62%[0m) [0.26% of initial]
[Iter 4490/20000] Loss: 0.0008315 (Best: 0.0006476 @iter4396) ([92m↓3.82%[0m) [0.33% of initial]
[Iter 6290/20000] Loss: 0.0005726 (Best: 0.0004593 @iter5797) ([92m↓11.23%[0m) [0.23% of initial]
Iter:4499, L1 loss=0.0009776, Total loss=0.0008999, Time:59
[Iter 4500/20000] Loss: 0.0009605 (Best: 0.0006476 @iter4396) ([91m↑15.51%[0m) [0.38% of initial]
Pruning 146 points (0.1%) from gaussian0 at iteration 4500
Pruning 131 points (0.1%) from gaussian1 at iteration 4500
Iter:6299, L1 loss=0.0006925, Total loss=0.0006342, Time:104
[Iter 6300/20000] Loss: 0.0007412 (Best: 0.0004593 @iter5797) ([91m↑29.45%[0m) [0.29% of initial]
[Iter 4510/20000] Loss: 0.0015256 (Best: 0.0006476 @iter4396) ([91m↑58.84%[0m) [0.61% of initial]
[Iter 6310/20000] Loss: 0.0006392 (Best: 0.0004593 @iter5797) ([92m↓13.76%[0m) [0.25% of initial]
[Iter 4520/20000] Loss: 0.0012109 (Best: 0.0006476 @iter4396) ([92m↓20.63%[0m) [0.48% of initial]
[Iter 6320/20000] Loss: 0.0006345 (Best: 0.0004593 @iter5797) ([92m↓0.74%[0m) [0.25% of initial]
[Iter 4530/20000] Loss: 0.0011164 (Best: 0.0006476 @iter4396) ([92m↓7.80%[0m) [0.44% of initial]
[Iter 6330/20000] Loss: 0.0006040 (Best: 0.0004593 @iter5797) ([92m↓4.81%[0m) [0.24% of initial]
[Iter 4540/20000] Loss: 0.0009234 (Best: 0.0006476 @iter4396) ([92m↓17.29%[0m) [0.37% of initial]
[Iter 6340/20000] Loss: 0.0004937 (Best: 0.0004413 @iter6340) ([92m↓18.25%[0m) [0.20% of initial]
[Iter 4550/20000] Loss: 0.0008208 (Best: 0.0006476 @iter4396) ([92m↓11.10%[0m) [0.33% of initial]
[Iter 6350/20000] Loss: 0.0005036 (Best: 0.0004413 @iter6340) ([91m↑2.00%[0m) [0.20% of initial]
[Iter 4560/20000] Loss: 0.0008467 (Best: 0.0006476 @iter4396) ([91m↑3.15%[0m) [0.34% of initial]
[Iter 4570/20000] Loss: 0.0007348 (Best: 0.0006476 @iter4396) ([92m↓13.22%[0m) [0.29% of initial]
[Iter 6360/20000] Loss: 0.0005814 (Best: 0.0004413 @iter6340) ([91m↑15.46%[0m) [0.23% of initial]
[Iter 4580/20000] Loss: 0.0007283 (Best: 0.0006476 @iter4396) ([92m↓0.88%[0m) [0.29% of initial]
[Iter 6370/20000] Loss: 0.0005580 (Best: 0.0004413 @iter6340) ([92m↓4.03%[0m) [0.22% of initial]
[Iter 4590/20000] Loss: 0.0007997 (Best: 0.0006476 @iter4396) ([91m↑9.81%[0m) [0.32% of initial]
[Iter 6380/20000] Loss: 0.0005176 (Best: 0.0004413 @iter6340) ([92m↓7.26%[0m) [0.21% of initial]
Iter:4599, L1 loss=0.000831, Total loss=0.0008002, Time:98
[Iter 4600/20000] Loss: 0.0007744 (Best: 0.0006476 @iter4396) ([92m↓3.16%[0m) [0.31% of initial]
[Iter 6390/20000] Loss: 0.0005450 (Best: 0.0004413 @iter6340) ([91m↑5.30%[0m) [0.22% of initial]
[Iter 4610/20000] Loss: 0.0030389 (Best: 0.0006476 @iter4396) ([91m↑292.42%[0m) [1.21% of initial]
Iter:6399, L1 loss=0.0005684, Total loss=0.0005171, Time:102
[Iter 6400/20000] Loss: 0.0005809 (Best: 0.0004413 @iter6340) ([91m↑6.59%[0m) [0.23% of initial]
[Iter 4620/20000] Loss: 0.0017919 (Best: 0.0006476 @iter4396) ([92m↓41.03%[0m) [0.71% of initial]
[Iter 6410/20000] Loss: 0.0013178 (Best: 0.0004413 @iter6340) ([91m↑126.86%[0m) [0.52% of initial]
[Iter 4630/20000] Loss: 0.0011645 (Best: 0.0006476 @iter4396) ([92m↓35.01%[0m) [0.46% of initial]
[Iter 6420/20000] Loss: 0.0011161 (Best: 0.0004413 @iter6340) ([92m↓15.30%[0m) [0.44% of initial]
[Iter 4640/20000] Loss: 0.0009592 (Best: 0.0006476 @iter4396) ([92m↓17.63%[0m) [0.38% of initial]
[Iter 6430/20000] Loss: 0.0009197 (Best: 0.0004413 @iter6340) ([92m↓17.60%[0m) [0.37% of initial]
[Iter 4650/20000] Loss: 0.0008523 (Best: 0.0006476 @iter4396) ([92m↓11.14%[0m) [0.34% of initial]
[Iter 6440/20000] Loss: 0.0007281 (Best: 0.0004413 @iter6340) ([92m↓20.83%[0m) [0.29% of initial]
[Iter 4660/20000] Loss: 0.0007471 (Best: 0.0006476 @iter4396) ([92m↓12.34%[0m) [0.30% of initial]
[Iter 4670/20000] Loss: 0.0007369 (Best: 0.0006476 @iter4396) ([92m↓1.36%[0m) [0.29% of initial]
[Iter 6450/20000] Loss: 0.0006488 (Best: 0.0004413 @iter6340) ([92m↓10.89%[0m) [0.26% of initial]
[Iter 4680/20000] Loss: 0.0007233 (Best: 0.0006266 @iter4672) ([92m↓1.85%[0m) [0.29% of initial]
[Iter 6460/20000] Loss: 0.0005677 (Best: 0.0004413 @iter6340) ([92m↓12.50%[0m) [0.23% of initial]
[Iter 4690/20000] Loss: 0.0006935 (Best: 0.0006198 @iter4681) ([92m↓4.12%[0m) [0.28% of initial]
[Iter 6470/20000] Loss: 0.0005524 (Best: 0.0004413 @iter6340) ([92m↓2.70%[0m) [0.22% of initial]
Iter:4699, L1 loss=0.0007812, Total loss=0.0007221, Time:89
[Iter 4700/20000] Loss: 0.0007582 (Best: 0.0006198 @iter4681) ([91m↑9.34%[0m) [0.30% of initial]
[Iter 6480/20000] Loss: 0.0005538 (Best: 0.0004413 @iter6340) ([91m↑0.26%[0m) [0.22% of initial]
[Iter 4710/20000] Loss: 0.0006760 (Best: 0.0006198 @iter4681) ([92m↓10.84%[0m) [0.27% of initial]
[Iter 6490/20000] Loss: 0.0005066 (Best: 0.0004413 @iter6340) ([92m↓8.53%[0m) [0.20% of initial]
[Iter 4720/20000] Loss: 0.0007373 (Best: 0.0005760 @iter4711) ([91m↑9.06%[0m) [0.29% of initial]
Iter:6499, L1 loss=0.0006783, Total loss=0.0006224, Time:86
[Iter 6500/20000] Loss: 0.0005962 (Best: 0.0004413 @iter6340) ([91m↑17.69%[0m) [0.24% of initial]
[Iter 4730/20000] Loss: 0.0007225 (Best: 0.0005760 @iter4711) ([92m↓2.01%[0m) [0.29% of initial]
Pruning 68 points (0.0%) from gaussian0 at iteration 6500
Pruning 69 points (0.0%) from gaussian1 at iteration 6500
[Iter 4740/20000] Loss: 0.0007947 (Best: 0.0005760 @iter4711) ([91m↑9.99%[0m) [0.32% of initial]
[Iter 6510/20000] Loss: 0.0012860 (Best: 0.0004413 @iter6340) ([91m↑115.69%[0m) [0.51% of initial]
[Iter 4750/20000] Loss: 0.0008082 (Best: 0.0005760 @iter4711) ([91m↑1.70%[0m) [0.32% of initial]
[Iter 6520/20000] Loss: 0.0008319 (Best: 0.0004413 @iter6340) ([92m↓35.31%[0m) [0.33% of initial]
[Iter 4760/20000] Loss: 0.0007279 (Best: 0.0005760 @iter4711) ([92m↓9.94%[0m) [0.29% of initial]
[Iter 6530/20000] Loss: 0.0007687 (Best: 0.0004413 @iter6340) ([92m↓7.60%[0m) [0.31% of initial]
[Iter 4770/20000] Loss: 0.0007593 (Best: 0.0005760 @iter4711) ([91m↑4.31%[0m) [0.30% of initial]
[Iter 6540/20000] Loss: 0.0006139 (Best: 0.0004413 @iter6340) ([92m↓20.14%[0m) [0.24% of initial]
[Iter 4780/20000] Loss: 0.0008375 (Best: 0.0005760 @iter4711) ([91m↑10.29%[0m) [0.33% of initial]
[Iter 6550/20000] Loss: 0.0005532 (Best: 0.0004413 @iter6340) ([92m↓9.89%[0m) [0.22% of initial]
[Iter 4790/20000] Loss: 0.0007196 (Best: 0.0005760 @iter4711) ([92m↓14.07%[0m) [0.29% of initial]
[Iter 6560/20000] Loss: 0.0004738 (Best: 0.0004413 @iter6340) ([92m↓14.35%[0m) [0.19% of initial]
Iter:4799, L1 loss=0.0007706, Total loss=0.0007027, Time:90
[Iter 4800/20000] Loss: 0.0008207 (Best: 0.0005760 @iter4711) ([91m↑14.05%[0m) [0.33% of initial]
[Iter 6570/20000] Loss: 0.0005539 (Best: 0.0004260 @iter6568) ([91m↑16.91%[0m) [0.22% of initial]
[Iter 4810/20000] Loss: 0.0025178 (Best: 0.0005760 @iter4711) ([91m↑206.80%[0m) [1.00% of initial]
[Iter 6580/20000] Loss: 0.0005545 (Best: 0.0004260 @iter6568) ([91m↑0.11%[0m) [0.22% of initial]
[Iter 4820/20000] Loss: 0.0014760 (Best: 0.0005760 @iter4711) ([92m↓41.38%[0m) [0.59% of initial]
[Iter 6590/20000] Loss: 0.0004736 (Best: 0.0004260 @iter6568) ([92m↓14.60%[0m) [0.19% of initial]
[Iter 4830/20000] Loss: 0.0011824 (Best: 0.0005760 @iter4711) ([92m↓19.89%[0m) [0.47% of initial]
Iter:6599, L1 loss=0.0005451, Total loss=0.0005006, Time:94
[Iter 6600/20000] Loss: 0.0005109 (Best: 0.0004260 @iter6568) ([91m↑7.88%[0m) [0.20% of initial]
[Iter 4840/20000] Loss: 0.0008927 (Best: 0.0005760 @iter4711) ([92m↓24.50%[0m) [0.35% of initial]
[Iter 4850/20000] Loss: 0.0007311 (Best: 0.0005760 @iter4711) ([92m↓18.11%[0m) [0.29% of initial]
[Iter 6610/20000] Loss: 0.0012798 (Best: 0.0004260 @iter6568) ([91m↑150.52%[0m) [0.51% of initial]
[Iter 4860/20000] Loss: 0.0007771 (Best: 0.0005760 @iter4711) ([91m↑6.29%[0m) [0.31% of initial]
[Iter 6620/20000] Loss: 0.0009130 (Best: 0.0004260 @iter6568) ([92m↓28.66%[0m) [0.36% of initial]
[Iter 4870/20000] Loss: 0.0007034 (Best: 0.0005760 @iter4711) ([92m↓9.48%[0m) [0.28% of initial]
[Iter 6630/20000] Loss: 0.0006731 (Best: 0.0004260 @iter6568) ([92m↓26.27%[0m) [0.27% of initial]
[Iter 4880/20000] Loss: 0.0007505 (Best: 0.0005760 @iter4711) ([91m↑6.69%[0m) [0.30% of initial]
[Iter 6640/20000] Loss: 0.0005656 (Best: 0.0004260 @iter6568) ([92m↓15.98%[0m) [0.22% of initial]
[Iter 4890/20000] Loss: 0.0006960 (Best: 0.0005760 @iter4711) ([92m↓7.27%[0m) [0.28% of initial]
[Iter 6650/20000] Loss: 0.0005323 (Best: 0.0004260 @iter6568) ([92m↓5.89%[0m) [0.21% of initial]
Iter:4899, L1 loss=0.0008082, Total loss=0.0008153, Time:96
[Iter 4900/20000] Loss: 0.0007124 (Best: 0.0005760 @iter4711) ([91m↑2.36%[0m) [0.28% of initial]
[Iter 6660/20000] Loss: 0.0005985 (Best: 0.0004260 @iter6568) ([91m↑12.45%[0m) [0.24% of initial]
[Iter 4910/20000] Loss: 0.0008667 (Best: 0.0005760 @iter4711) ([91m↑21.66%[0m) [0.34% of initial]
[Iter 4920/20000] Loss: 0.0007606 (Best: 0.0005760 @iter4711) ([92m↓12.25%[0m) [0.30% of initial]
[Iter 6670/20000] Loss: 0.0005789 (Best: 0.0004260 @iter6568) ([92m↓3.28%[0m) [0.23% of initial]
[Iter 4930/20000] Loss: 0.0006732 (Best: 0.0005760 @iter4711) ([92m↓11.48%[0m) [0.27% of initial]
[Iter 6680/20000] Loss: 0.0005940 (Best: 0.0004260 @iter6568) ([91m↑2.62%[0m) [0.24% of initial]
[Iter 4940/20000] Loss: 0.0007131 (Best: 0.0005760 @iter4711) ([91m↑5.92%[0m) [0.28% of initial]
[Iter 6690/20000] Loss: 0.0005420 (Best: 0.0004260 @iter6568) ([92m↓8.75%[0m) [0.22% of initial]
[Iter 4950/20000] Loss: 0.0006264 (Best: 0.0005528 @iter4949) ([92m↓12.16%[0m) [0.25% of initial]
Iter:6699, L1 loss=0.0006011, Total loss=0.0005417, Time:103
[Iter 6700/20000] Loss: 0.0005120 (Best: 0.0004260 @iter6568) ([92m↓5.54%[0m) [0.20% of initial]
[Iter 4960/20000] Loss: 0.0006467 (Best: 0.0005469 @iter4957) ([91m↑3.25%[0m) [0.26% of initial]
[Iter 6710/20000] Loss: 0.0005571 (Best: 0.0004260 @iter6568) ([91m↑8.81%[0m) [0.22% of initial]
[Iter 4970/20000] Loss: 0.0006758 (Best: 0.0005469 @iter4957) ([91m↑4.49%[0m) [0.27% of initial]
[Iter 6720/20000] Loss: 0.0005076 (Best: 0.0004260 @iter6568) ([92m↓8.89%[0m) [0.20% of initial]
[Iter 4980/20000] Loss: 0.0006992 (Best: 0.0005469 @iter4957) ([91m↑3.46%[0m) [0.28% of initial]
[Iter 6730/20000] Loss: 0.0004604 (Best: 0.0004192 @iter6724) ([92m↓9.30%[0m) [0.18% of initial]
[Iter 4990/20000] Loss: 0.0006513 (Best: 0.0005469 @iter4957) ([92m↓6.85%[0m) [0.26% of initial]
[Iter 6740/20000] Loss: 0.0004992 (Best: 0.0004192 @iter6724) ([91m↑8.42%[0m) [0.20% of initial]
Iter:4999, L1 loss=0.0006582, Total loss=0.0006301, Time:91
[Iter 5000/20000] Loss: 0.0006106 (Best: 0.0005469 @iter4957) ([92m↓6.25%[0m) [0.24% of initial]
[Iter 6750/20000] Loss: 0.0005202 (Best: 0.0004192 @iter6724) ([91m↑4.21%[0m) [0.21% of initial]
Pruning 130 points (0.1%) from gaussian0 at iteration 5000
Pruning 173 points (0.1%) from gaussian1 at iteration 5000
[Iter 6760/20000] Loss: 0.0004833 (Best: 0.0004192 @iter6724) ([92m↓7.09%[0m) [0.19% of initial]
[Iter 5010/20000] Loss: 0.0027509 (Best: 0.0005469 @iter4957) ([91m↑350.53%[0m) [1.09% of initial]
[Iter 5020/20000] Loss: 0.0016835 (Best: 0.0005469 @iter4957) ([92m↓38.80%[0m) [0.67% of initial]
[Iter 6770/20000] Loss: 0.0004729 (Best: 0.0004192 @iter6724) ([92m↓2.16%[0m) [0.19% of initial]
[Iter 5030/20000] Loss: 0.0011137 (Best: 0.0005469 @iter4957) ([92m↓33.84%[0m) [0.44% of initial]
[Iter 6780/20000] Loss: 0.0004389 (Best: 0.0004166 @iter6778) ([92m↓7.18%[0m) [0.17% of initial]
[Iter 5040/20000] Loss: 0.0010700 (Best: 0.0005469 @iter4957) ([92m↓3.93%[0m) [0.43% of initial]
[Iter 6790/20000] Loss: 0.0005048 (Best: 0.0003832 @iter6781) ([91m↑15.00%[0m) [0.20% of initial]
[Iter 5050/20000] Loss: 0.0009194 (Best: 0.0005469 @iter4957) ([92m↓14.08%[0m) [0.37% of initial]
Iter:6799, L1 loss=0.0004707, Total loss=0.0004209, Time:89
[Iter 6800/20000] Loss: 0.0004362 (Best: 0.0003832 @iter6781) ([92m↓13.58%[0m) [0.17% of initial]
[Iter 5060/20000] Loss: 0.0007603 (Best: 0.0005469 @iter4957) ([92m↓17.30%[0m) [0.30% of initial]
[Iter 6810/20000] Loss: 0.0011368 (Best: 0.0003832 @iter6781) ([91m↑160.60%[0m) [0.45% of initial]
[Iter 5070/20000] Loss: 0.0008064 (Best: 0.0005469 @iter4957) ([91m↑6.07%[0m) [0.32% of initial]
[Iter 6820/20000] Loss: 0.0009108 (Best: 0.0003832 @iter6781) ([92m↓19.88%[0m) [0.36% of initial]
[Iter 5080/20000] Loss: 0.0007049 (Best: 0.0005469 @iter4957) ([92m↓12.59%[0m) [0.28% of initial]
[Iter 5090/20000] Loss: 0.0007325 (Best: 0.0005469 @iter4957) ([91m↑3.91%[0m) [0.29% of initial]
[Iter 6830/20000] Loss: 0.0006481 (Best: 0.0003832 @iter6781) ([92m↓28.85%[0m) [0.26% of initial]
Iter:5099, L1 loss=0.0007793, Total loss=0.0007038, Time:96
[Iter 5100/20000] Loss: 0.0007719 (Best: 0.0005469 @iter4957) ([91m↑5.38%[0m) [0.31% of initial]
[Iter 6840/20000] Loss: 0.0005691 (Best: 0.0003832 @iter6781) ([92m↓12.19%[0m) [0.23% of initial]
[Iter 5110/20000] Loss: 0.0007469 (Best: 0.0005469 @iter4957) ([92m↓3.24%[0m) [0.30% of initial]
[Iter 6850/20000] Loss: 0.0005496 (Best: 0.0003832 @iter6781) ([92m↓3.41%[0m) [0.22% of initial]
[Iter 5120/20000] Loss: 0.0007604 (Best: 0.0005469 @iter4957) ([91m↑1.81%[0m) [0.30% of initial]
[Iter 6860/20000] Loss: 0.0005161 (Best: 0.0003832 @iter6781) ([92m↓6.11%[0m) [0.21% of initial]
[Iter 5130/20000] Loss: 0.0007761 (Best: 0.0005469 @iter4957) ([91m↑2.06%[0m) [0.31% of initial]
[Iter 6870/20000] Loss: 0.0004952 (Best: 0.0003832 @iter6781) ([92m↓4.05%[0m) [0.20% of initial]
[Iter 5140/20000] Loss: 0.0006704 (Best: 0.0005469 @iter4957) ([92m↓13.61%[0m) [0.27% of initial]
[Iter 6880/20000] Loss: 0.0004694 (Best: 0.0003832 @iter6781) ([92m↓5.21%[0m) [0.19% of initial]
[Iter 5150/20000] Loss: 0.0006814 (Best: 0.0005469 @iter4957) ([91m↑1.64%[0m) [0.27% of initial]
[Iter 6890/20000] Loss: 0.0005512 (Best: 0.0003832 @iter6781) ([91m↑17.43%[0m) [0.22% of initial]
[Iter 5160/20000] Loss: 0.0006804 (Best: 0.0005469 @iter4957) ([92m↓0.15%[0m) [0.27% of initial]
Iter:6899, L1 loss=0.0006012, Total loss=0.0005581, Time:89
[Iter 6900/20000] Loss: 0.0005551 (Best: 0.0003832 @iter6781) ([91m↑0.71%[0m) [0.22% of initial]
[Iter 5170/20000] Loss: 0.0007255 (Best: 0.0005469 @iter4957) ([91m↑6.63%[0m) [0.29% of initial]
[Iter 6910/20000] Loss: 0.0005639 (Best: 0.0003832 @iter6781) ([91m↑1.59%[0m) [0.22% of initial]
[Iter 5180/20000] Loss: 0.0006663 (Best: 0.0005469 @iter4957) ([92m↓8.17%[0m) [0.26% of initial]
[Iter 6920/20000] Loss: 0.0005080 (Best: 0.0003832 @iter6781) ([92m↓9.92%[0m) [0.20% of initial]
[Iter 5190/20000] Loss: 0.0006867 (Best: 0.0005469 @iter4957) ([91m↑3.06%[0m) [0.27% of initial]
Iter:5199, L1 loss=0.0007494, Total loss=0.0007029, Time:85
[Iter 5200/20000] Loss: 0.0006490 (Best: 0.0005469 @iter4957) ([92m↓5.49%[0m) [0.26% of initial]
[Iter 6930/20000] Loss: 0.0005088 (Best: 0.0003832 @iter6781) ([91m↑0.15%[0m) [0.20% of initial]
[Iter 6940/20000] Loss: 0.0004514 (Best: 0.0003832 @iter6781) ([92m↓11.28%[0m) [0.18% of initial]
[Iter 5210/20000] Loss: 0.0026999 (Best: 0.0005469 @iter4957) ([91m↑316.02%[0m) [1.07% of initial]
[Iter 6950/20000] Loss: 0.0004551 (Best: 0.0003832 @iter6781) ([91m↑0.82%[0m) [0.18% of initial]
[Iter 5220/20000] Loss: 0.0015817 (Best: 0.0005469 @iter4957) ([92m↓41.42%[0m) [0.63% of initial]
[Iter 6960/20000] Loss: 0.0004279 (Best: 0.0003832 @iter6781) ([92m↓5.96%[0m) [0.17% of initial]
[Iter 5230/20000] Loss: 0.0010636 (Best: 0.0005469 @iter4957) ([92m↓32.75%[0m) [0.42% of initial]
[Iter 5240/20000] Loss: 0.0008256 (Best: 0.0005469 @iter4957) ([92m↓22.38%[0m) [0.33% of initial]
[Iter 6970/20000] Loss: 0.0005110 (Best: 0.0003786 @iter6961) ([91m↑19.41%[0m) [0.20% of initial]
[Iter 5250/20000] Loss: 0.0009894 (Best: 0.0005469 @iter4957) ([91m↑19.85%[0m) [0.39% of initial]
[Iter 6980/20000] Loss: 0.0005258 (Best: 0.0003786 @iter6961) ([91m↑2.90%[0m) [0.21% of initial]
[Iter 5260/20000] Loss: 0.0008248 (Best: 0.0005469 @iter4957) ([92m↓16.64%[0m) [0.33% of initial]
[Iter 6990/20000] Loss: 0.0004747 (Best: 0.0003786 @iter6961) ([92m↓9.72%[0m) [0.19% of initial]
[Iter 5270/20000] Loss: 0.0007372 (Best: 0.0005469 @iter4957) ([92m↓10.62%[0m) [0.29% of initial]
Iter:6999, L1 loss=0.0006223, Total loss=0.0005687, Time:104
[Iter 7000/20000] Loss: 0.0004773 (Best: 0.0003786 @iter6961) ([91m↑0.55%[0m) [0.19% of initial]
[Iter 5280/20000] Loss: 0.0008232 (Best: 0.0005469 @iter4957) ([91m↑11.67%[0m) [0.33% of initial]
Pruning 44 points (0.0%) from gaussian0 at iteration 7000
Pruning 52 points (0.0%) from gaussian1 at iteration 7000
[Iter 5290/20000] Loss: 0.0007932 (Best: 0.0005469 @iter4957) ([92m↓3.65%[0m) [0.32% of initial]
[Iter 7010/20000] Loss: 0.0015118 (Best: 0.0003786 @iter6961) ([91m↑216.72%[0m) [0.60% of initial]
Iter:5299, L1 loss=0.0008892, Total loss=0.000861, Time:89
[Iter 5300/20000] Loss: 0.0008714 (Best: 0.0005469 @iter4957) ([91m↑9.86%[0m) [0.35% of initial]
[Iter 7020/20000] Loss: 0.0010036 (Best: 0.0003786 @iter6961) ([92m↓33.61%[0m) [0.40% of initial]
[Iter 5310/20000] Loss: 0.0008901 (Best: 0.0005469 @iter4957) ([91m↑2.15%[0m) [0.35% of initial]
[Iter 7030/20000] Loss: 0.0006999 (Best: 0.0003786 @iter6961) ([92m↓30.26%[0m) [0.28% of initial]
[Iter 5320/20000] Loss: 0.0007578 (Best: 0.0005469 @iter4957) ([92m↓14.86%[0m) [0.30% of initial]
[Iter 7040/20000] Loss: 0.0005719 (Best: 0.0003786 @iter6961) ([92m↓18.30%[0m) [0.23% of initial]
[Iter 5330/20000] Loss: 0.0006232 (Best: 0.0005469 @iter4957) ([92m↓17.77%[0m) [0.25% of initial]
[Iter 7050/20000] Loss: 0.0005484 (Best: 0.0003786 @iter6961) ([92m↓4.11%[0m) [0.22% of initial]
[Iter 5340/20000] Loss: 0.0006611 (Best: 0.0005469 @iter4957) ([91m↑6.09%[0m) [0.26% of initial]
[Iter 7060/20000] Loss: 0.0005935 (Best: 0.0003786 @iter6961) ([91m↑8.23%[0m) [0.24% of initial]
[Iter 5350/20000] Loss: 0.0006632 (Best: 0.0005323 @iter5344) ([91m↑0.31%[0m) [0.26% of initial]
[Iter 7070/20000] Loss: 0.0005286 (Best: 0.0003786 @iter6961) ([92m↓10.94%[0m) [0.21% of initial]
[Iter 5360/20000] Loss: 0.0006933 (Best: 0.0005323 @iter5344) ([91m↑4.54%[0m) [0.28% of initial]
[Iter 5370/20000] Loss: 0.0007068 (Best: 0.0005323 @iter5344) ([91m↑1.96%[0m) [0.28% of initial]
[Iter 7080/20000] Loss: 0.0005282 (Best: 0.0003786 @iter6961) ([92m↓0.07%[0m) [0.21% of initial]
[Iter 5380/20000] Loss: 0.0007029 (Best: 0.0005323 @iter5344) ([92m↓0.56%[0m) [0.28% of initial]
[Iter 7090/20000] Loss: 0.0005499 (Best: 0.0003786 @iter6961) ([91m↑4.11%[0m) [0.22% of initial]
[Iter 5390/20000] Loss: 0.0007120 (Best: 0.0005323 @iter5344) ([91m↑1.30%[0m) [0.28% of initial]
Iter:7099, L1 loss=0.0005184, Total loss=0.0004699, Time:127
[Iter 7100/20000] Loss: 0.0005001 (Best: 0.0003786 @iter6961) ([92m↓9.06%[0m) [0.20% of initial]
Iter:5399, L1 loss=0.0006682, Total loss=0.0006228, Time:92
[Iter 5400/20000] Loss: 0.0007031 (Best: 0.0005323 @iter5344) ([92m↓1.25%[0m) [0.28% of initial]
[Iter 7110/20000] Loss: 0.0005110 (Best: 0.0003786 @iter6961) ([91m↑2.19%[0m) [0.20% of initial]
[Iter 5410/20000] Loss: 0.0021847 (Best: 0.0005323 @iter5344) ([91m↑210.71%[0m) [0.87% of initial]
[Iter 7120/20000] Loss: 0.0004784 (Best: 0.0003786 @iter6961) ([92m↓6.38%[0m) [0.19% of initial]
[Iter 5420/20000] Loss: 0.0014575 (Best: 0.0005323 @iter5344) ([92m↓33.29%[0m) [0.58% of initial]
[Iter 7130/20000] Loss: 0.0004603 (Best: 0.0003786 @iter6961) ([92m↓3.78%[0m) [0.18% of initial]
[Iter 5430/20000] Loss: 0.0009278 (Best: 0.0005323 @iter5344) ([92m↓36.34%[0m) [0.37% of initial]
[Iter 7140/20000] Loss: 0.0005310 (Best: 0.0003786 @iter6961) ([91m↑15.36%[0m) [0.21% of initial]
[Iter 5440/20000] Loss: 0.0008285 (Best: 0.0005323 @iter5344) ([92m↓10.71%[0m) [0.33% of initial]
[Iter 7150/20000] Loss: 0.0004870 (Best: 0.0003786 @iter6961) ([92m↓8.30%[0m) [0.19% of initial]
[Iter 5450/20000] Loss: 0.0006941 (Best: 0.0005323 @iter5344) ([92m↓16.22%[0m) [0.28% of initial]
[Iter 7160/20000] Loss: 0.0004805 (Best: 0.0003786 @iter6961) ([92m↓1.33%[0m) [0.19% of initial]
[Iter 5460/20000] Loss: 0.0008081 (Best: 0.0005323 @iter5344) ([91m↑16.42%[0m) [0.32% of initial]
[Iter 7170/20000] Loss: 0.0005002 (Best: 0.0003786 @iter6961) ([91m↑4.10%[0m) [0.20% of initial]
[Iter 5470/20000] Loss: 0.0006923 (Best: 0.0005323 @iter5344) ([92m↓14.32%[0m) [0.28% of initial]
[Iter 7180/20000] Loss: 0.0005075 (Best: 0.0003786 @iter6961) ([91m↑1.47%[0m) [0.20% of initial]
[Iter 5480/20000] Loss: 0.0006417 (Best: 0.0005323 @iter5344) ([92m↓7.32%[0m) [0.25% of initial]
[Iter 7190/20000] Loss: 0.0004362 (Best: 0.0003786 @iter6961) ([92m↓14.07%[0m) [0.17% of initial]
[Iter 5490/20000] Loss: 0.0006746 (Best: 0.0005323 @iter5344) ([91m↑5.13%[0m) [0.27% of initial]
Iter:7199, L1 loss=0.0005035, Total loss=0.0004656, Time:88
[Iter 7200/20000] Loss: 0.0004634 (Best: 0.0003786 @iter6961) ([91m↑6.25%[0m) [0.18% of initial]
Iter:5499, L1 loss=0.0007132, Total loss=0.0006663, Time:88
[Iter 5500/20000] Loss: 0.0006289 (Best: 0.0005323 @iter5344) ([92m↓6.78%[0m) [0.25% of initial]
Pruning 140 points (0.1%) from gaussian0 at iteration 5500
Pruning 111 points (0.1%) from gaussian1 at iteration 5500
[Iter 7210/20000] Loss: 0.0012481 (Best: 0.0003786 @iter6961) ([91m↑169.34%[0m) [0.50% of initial]
[Iter 5510/20000] Loss: 0.0011652 (Best: 0.0005323 @iter5344) ([91m↑85.29%[0m) [0.46% of initial]
[Iter 7220/20000] Loss: 0.0010486 (Best: 0.0003786 @iter6961) ([92m↓15.99%[0m) [0.42% of initial]
[Iter 5520/20000] Loss: 0.0008820 (Best: 0.0005323 @iter5344) ([92m↓24.31%[0m) [0.35% of initial]
[Iter 7230/20000] Loss: 0.0007521 (Best: 0.0003786 @iter6961) ([92m↓28.27%[0m) [0.30% of initial]
[Iter 5530/20000] Loss: 0.0007917 (Best: 0.0005323 @iter5344) ([92m↓10.24%[0m) [0.31% of initial]
[Iter 7240/20000] Loss: 0.0006181 (Best: 0.0003786 @iter6961) ([92m↓17.81%[0m) [0.25% of initial]
[Iter 5540/20000] Loss: 0.0007188 (Best: 0.0005323 @iter5344) ([92m↓9.21%[0m) [0.29% of initial]
[Iter 7250/20000] Loss: 0.0005323 (Best: 0.0003786 @iter6961) ([92m↓13.88%[0m) [0.21% of initial]
[Iter 5550/20000] Loss: 0.0006907 (Best: 0.0005323 @iter5344) ([92m↓3.90%[0m) [0.27% of initial]
[Iter 7260/20000] Loss: 0.0004884 (Best: 0.0003786 @iter6961) ([92m↓8.26%[0m) [0.19% of initial]
[Iter 5560/20000] Loss: 0.0006349 (Best: 0.0005323 @iter5344) ([92m↓8.08%[0m) [0.25% of initial]
[Iter 7270/20000] Loss: 0.0004502 (Best: 0.0003786 @iter6961) ([92m↓7.82%[0m) [0.18% of initial]
[Iter 5570/20000] Loss: 0.0006345 (Best: 0.0005323 @iter5344) ([92m↓0.06%[0m) [0.25% of initial]
[Iter 5580/20000] Loss: 0.0007605 (Best: 0.0005323 @iter5344) ([91m↑19.85%[0m) [0.30% of initial]
[Iter 7280/20000] Loss: 0.0004329 (Best: 0.0003745 @iter7276) ([92m↓3.84%[0m) [0.17% of initial]
[Iter 5590/20000] Loss: 0.0007962 (Best: 0.0005323 @iter5344) ([91m↑4.69%[0m) [0.32% of initial]
[Iter 7290/20000] Loss: 0.0004577 (Best: 0.0003745 @iter7276) ([91m↑5.73%[0m) [0.18% of initial]
Iter:5599, L1 loss=0.0006509, Total loss=0.0006041, Time:88
[Iter 5600/20000] Loss: 0.0006162 (Best: 0.0005323 @iter5344) ([92m↓22.61%[0m) [0.24% of initial]
Iter:7299, L1 loss=0.0005779, Total loss=0.0005474, Time:113
[Iter 7300/20000] Loss: 0.0004755 (Best: 0.0003745 @iter7276) ([91m↑3.90%[0m) [0.19% of initial]
[Iter 7310/20000] Loss: 0.0004628 (Best: 0.0003745 @iter7276) ([92m↓2.68%[0m) [0.18% of initial]
[Iter 5610/20000] Loss: 0.0025346 (Best: 0.0005323 @iter5344) ([91m↑311.35%[0m) [1.01% of initial]
[Iter 7320/20000] Loss: 0.0005265 (Best: 0.0003745 @iter7276) ([91m↑13.77%[0m) [0.21% of initial]
[Iter 5620/20000] Loss: 0.0014392 (Best: 0.0005323 @iter5344) ([92m↓43.22%[0m) [0.57% of initial]
[Iter 5630/20000] Loss: 0.0010081 (Best: 0.0005323 @iter5344) ([92m↓29.95%[0m) [0.40% of initial]
[Iter 7330/20000] Loss: 0.0005026 (Best: 0.0003745 @iter7276) ([92m↓4.53%[0m) [0.20% of initial]
[Iter 5640/20000] Loss: 0.0008524 (Best: 0.0005323 @iter5344) ([92m↓15.44%[0m) [0.34% of initial]
[Iter 7340/20000] Loss: 0.0004566 (Best: 0.0003745 @iter7276) ([92m↓9.16%[0m) [0.18% of initial]
[Iter 5650/20000] Loss: 0.0006961 (Best: 0.0005323 @iter5344) ([92m↓18.33%[0m) [0.28% of initial]
[Iter 7350/20000] Loss: 0.0005003 (Best: 0.0003745 @iter7276) ([91m↑9.58%[0m) [0.20% of initial]
[Iter 5660/20000] Loss: 0.0006829 (Best: 0.0005323 @iter5344) ([92m↓1.90%[0m) [0.27% of initial]
[Iter 7360/20000] Loss: 0.0005102 (Best: 0.0003745 @iter7276) ([91m↑1.96%[0m) [0.20% of initial]
[Iter 5670/20000] Loss: 0.0006870 (Best: 0.0005323 @iter5344) ([91m↑0.59%[0m) [0.27% of initial]
[Iter 7370/20000] Loss: 0.0004474 (Best: 0.0003745 @iter7276) ([92m↓12.30%[0m) [0.18% of initial]
[Iter 5680/20000] Loss: 0.0006291 (Best: 0.0005308 @iter5677) ([92m↓8.43%[0m) [0.25% of initial]
[Iter 7380/20000] Loss: 0.0005924 (Best: 0.0003745 @iter7276) ([91m↑32.39%[0m) [0.24% of initial]
[Iter 5690/20000] Loss: 0.0006787 (Best: 0.0005308 @iter5677) ([91m↑7.88%[0m) [0.27% of initial]
[Iter 7390/20000] Loss: 0.0006177 (Best: 0.0003745 @iter7276) ([91m↑4.27%[0m) [0.25% of initial]
Iter:5699, L1 loss=0.0006272, Total loss=0.0005578, Time:91
[Iter 5700/20000] Loss: 0.0005764 (Best: 0.0005308 @iter5677) ([92m↓15.07%[0m) [0.23% of initial]
Iter:7399, L1 loss=0.0006184, Total loss=0.0005711, Time:109
[Iter 7400/20000] Loss: 0.0006127 (Best: 0.0003745 @iter7276) ([92m↓0.82%[0m) [0.24% of initial]
[Iter 5710/20000] Loss: 0.0007571 (Best: 0.0004933 @iter5701) ([91m↑31.36%[0m) [0.30% of initial]
[Iter 7410/20000] Loss: 0.0012169 (Best: 0.0003745 @iter7276) ([91m↑98.63%[0m) [0.48% of initial]
[Iter 5720/20000] Loss: 0.0006621 (Best: 0.0004933 @iter5701) ([92m↓12.56%[0m) [0.26% of initial]
[Iter 7420/20000] Loss: 0.0008695 (Best: 0.0003745 @iter7276) ([92m↓28.55%[0m) [0.35% of initial]
[Iter 5730/20000] Loss: 0.0006776 (Best: 0.0004933 @iter5701) ([91m↑2.34%[0m) [0.27% of initial]
[Iter 5740/20000] Loss: 0.0005857 (Best: 0.0004933 @iter5701) ([92m↓13.56%[0m) [0.23% of initial]
[Iter 7430/20000] Loss: 0.0006903 (Best: 0.0003745 @iter7276) ([92m↓20.61%[0m) [0.27% of initial]
[Iter 5750/20000] Loss: 0.0005847 (Best: 0.0004933 @iter5701) ([92m↓0.17%[0m) [0.23% of initial]
[Iter 7440/20000] Loss: 0.0006140 (Best: 0.0003745 @iter7276) ([92m↓11.05%[0m) [0.24% of initial]
[Iter 5760/20000] Loss: 0.0005829 (Best: 0.0004933 @iter5701) ([92m↓0.30%[0m) [0.23% of initial]
[Iter 7450/20000] Loss: 0.0005507 (Best: 0.0003745 @iter7276) ([92m↓10.31%[0m) [0.22% of initial]
[Iter 5770/20000] Loss: 0.0005228 (Best: 0.0004617 @iter5770) ([92m↓10.32%[0m) [0.21% of initial]
[Iter 7460/20000] Loss: 0.0005212 (Best: 0.0003745 @iter7276) ([92m↓5.36%[0m) [0.21% of initial]
[Iter 5780/20000] Loss: 0.0005444 (Best: 0.0004617 @iter5770) ([91m↑4.14%[0m) [0.22% of initial]
[Iter 7470/20000] Loss: 0.0004879 (Best: 0.0003745 @iter7276) ([92m↓6.39%[0m) [0.19% of initial]
[Iter 5790/20000] Loss: 0.0005893 (Best: 0.0004617 @iter5770) ([91m↑8.25%[0m) [0.23% of initial]
[Iter 7480/20000] Loss: 0.0004670 (Best: 0.0003745 @iter7276) ([92m↓4.30%[0m) [0.19% of initial]
Iter:5799, L1 loss=0.0006119, Total loss=0.0005687, Time:100
[Iter 5800/20000] Loss: 0.0005524 (Best: 0.0004476 @iter5797) ([92m↓6.25%[0m) [0.22% of initial]
[Iter 7490/20000] Loss: 0.0004147 (Best: 0.0003745 @iter7276) ([92m↓11.20%[0m) [0.16% of initial]
[Iter 5810/20000] Loss: 0.0020434 (Best: 0.0004476 @iter5797) ([91m↑269.88%[0m) [0.81% of initial]
Iter:7499, L1 loss=0.0005129, Total loss=0.000445, Time:120
[Iter 7500/20000] Loss: 0.0004603 (Best: 0.0003745 @iter7276) ([91m↑11.01%[0m) [0.18% of initial]
Pruning 52 points (0.0%) from gaussian0 at iteration 7500
Pruning 63 points (0.0%) from gaussian1 at iteration 7500
[Iter 5820/20000] Loss: 0.0013538 (Best: 0.0004476 @iter5797) ([92m↓33.75%[0m) [0.54% of initial]
[Iter 7510/20000] Loss: 0.0011905 (Best: 0.0003745 @iter7276) ([91m↑158.61%[0m) [0.47% of initial]
[Iter 5830/20000] Loss: 0.0009033 (Best: 0.0004476 @iter5797) ([92m↓33.27%[0m) [0.36% of initial]
[Iter 5840/20000] Loss: 0.0007517 (Best: 0.0004476 @iter5797) ([92m↓16.78%[0m) [0.30% of initial]
[Iter 7520/20000] Loss: 0.0007731 (Best: 0.0003745 @iter7276) ([92m↓35.06%[0m) [0.31% of initial]
[Iter 5850/20000] Loss: 0.0007373 (Best: 0.0004476 @iter5797) ([92m↓1.93%[0m) [0.29% of initial]
[Iter 7530/20000] Loss: 0.0005886 (Best: 0.0003745 @iter7276) ([92m↓23.86%[0m) [0.23% of initial]
[Iter 5860/20000] Loss: 0.0005984 (Best: 0.0004476 @iter5797) ([92m↓18.83%[0m) [0.24% of initial]
[Iter 7540/20000] Loss: 0.0004294 (Best: 0.0003745 @iter7276) ([92m↓27.06%[0m) [0.17% of initial]
[Iter 5870/20000] Loss: 0.0006877 (Best: 0.0004476 @iter5797) ([91m↑14.92%[0m) [0.27% of initial]
[Iter 7550/20000] Loss: 0.0004259 (Best: 0.0003745 @iter7276) ([92m↓0.80%[0m) [0.17% of initial]
[Iter 5880/20000] Loss: 0.0006352 (Best: 0.0004476 @iter5797) ([92m↓7.63%[0m) [0.25% of initial]
[Iter 7560/20000] Loss: 0.0004137 (Best: 0.0003595 @iter7555) ([92m↓2.88%[0m) [0.16% of initial]
[Iter 5890/20000] Loss: 0.0006060 (Best: 0.0004476 @iter5797) ([92m↓4.60%[0m) [0.24% of initial]
[Iter 7570/20000] Loss: 0.0004349 (Best: 0.0003595 @iter7555) ([91m↑5.13%[0m) [0.17% of initial]
Iter:5899, L1 loss=0.0006255, Total loss=0.0006049, Time:103
[Iter 5900/20000] Loss: 0.0005917 (Best: 0.0004476 @iter5797) ([92m↓2.36%[0m) [0.24% of initial]
[Iter 7580/20000] Loss: 0.0004678 (Best: 0.0003595 @iter7555) ([91m↑7.56%[0m) [0.19% of initial]
[Iter 5910/20000] Loss: 0.0006367 (Best: 0.0004476 @iter5797) ([91m↑7.61%[0m) [0.25% of initial]
[Iter 7590/20000] Loss: 0.0004692 (Best: 0.0003595 @iter7555) ([91m↑0.32%[0m) [0.19% of initial]
[Iter 5920/20000] Loss: 0.0006004 (Best: 0.0004476 @iter5797) ([92m↓5.70%[0m) [0.24% of initial]
Iter:7599, L1 loss=0.0004691, Total loss=0.0004064, Time:105
[Iter 7600/20000] Loss: 0.0004142 (Best: 0.0003595 @iter7555) ([92m↓11.73%[0m) [0.16% of initial]
[Iter 5930/20000] Loss: 0.0005000 (Best: 0.0004476 @iter5797) ([92m↓16.72%[0m) [0.20% of initial]
[Iter 7610/20000] Loss: 0.0012395 (Best: 0.0003595 @iter7555) ([91m↑199.27%[0m) [0.49% of initial]
[Iter 5940/20000] Loss: 0.0006962 (Best: 0.0004476 @iter5797) ([91m↑39.25%[0m) [0.28% of initial]
[Iter 7620/20000] Loss: 0.0008190 (Best: 0.0003595 @iter7555) ([92m↓33.93%[0m) [0.33% of initial]
[Iter 5950/20000] Loss: 0.0005486 (Best: 0.0004476 @iter5797) ([92m↓21.20%[0m) [0.22% of initial]
[Iter 5960/20000] Loss: 0.0005823 (Best: 0.0004476 @iter5797) ([91m↑6.13%[0m) [0.23% of initial]
[Iter 7630/20000] Loss: 0.0006833 (Best: 0.0003595 @iter7555) ([92m↓16.57%[0m) [0.27% of initial]
[Iter 5970/20000] Loss: 0.0007010 (Best: 0.0004476 @iter5797) ([91m↑20.40%[0m) [0.28% of initial]
[Iter 7640/20000] Loss: 0.0005525 (Best: 0.0003595 @iter7555) ([92m↓19.15%[0m) [0.22% of initial]
[Iter 5980/20000] Loss: 0.0005897 (Best: 0.0004476 @iter5797) ([92m↓15.88%[0m) [0.23% of initial]
[Iter 7650/20000] Loss: 0.0004888 (Best: 0.0003595 @iter7555) ([92m↓11.52%[0m) [0.19% of initial]
[Iter 5990/20000] Loss: 0.0006231 (Best: 0.0004476 @iter5797) ([91m↑5.66%[0m) [0.25% of initial]
[Iter 7660/20000] Loss: 0.0004075 (Best: 0.0003595 @iter7555) ([92m↓16.63%[0m) [0.16% of initial]
Iter:5999, L1 loss=0.0006597, Total loss=0.0006585, Time:112
[Iter 6000/20000] Loss: 0.0006185 (Best: 0.0004476 @iter5797) ([92m↓0.73%[0m) [0.25% of initial]
[Iter 7670/20000] Loss: 0.0003889 (Best: 0.0003595 @iter7555) ([92m↓4.57%[0m) [0.15% of initial]
Pruning 164 points (0.1%) from gaussian0 at iteration 6000
Pruning 100 points (0.1%) from gaussian1 at iteration 6000
[Iter 7680/20000] Loss: 0.0004174 (Best: 0.0003595 @iter7555) ([91m↑7.34%[0m) [0.17% of initial]
[Iter 6010/20000] Loss: 0.0592943 (Best: 0.0004476 @iter5797) ([91m↑9486.22%[0m) [23.56% of initial]
[Iter 7690/20000] Loss: 0.0003996 (Best: 0.0003571 @iter7690) ([92m↓4.27%[0m) [0.16% of initial]
[Iter 6020/20000] Loss: 0.0305040 (Best: 0.0004476 @iter5797) ([92m↓48.55%[0m) [12.12% of initial]
Iter:7699, L1 loss=0.0004234, Total loss=0.0003959, Time:105
[Iter 7700/20000] Loss: 0.0003988 (Best: 0.0003571 @iter7690) ([92m↓0.21%[0m) [0.16% of initial]
[Iter 6030/20000] Loss: 0.0109937 (Best: 0.0004476 @iter5797) ([92m↓63.96%[0m) [4.37% of initial]
[Iter 7710/20000] Loss: 0.0003801 (Best: 0.0003571 @iter7690) ([92m↓4.69%[0m) [0.15% of initial]
[Iter 6040/20000] Loss: 0.0054863 (Best: 0.0004476 @iter5797) ([92m↓50.10%[0m) [2.18% of initial]
[Iter 7720/20000] Loss: 0.0003805 (Best: 0.0003265 @iter7714) ([91m↑0.10%[0m) [0.15% of initial]
[Iter 6050/20000] Loss: 0.0034041 (Best: 0.0004476 @iter5797) ([92m↓37.95%[0m) [1.35% of initial]
[Iter 7730/20000] Loss: 0.0003775 (Best: 0.0003265 @iter7714) ([92m↓0.79%[0m) [0.15% of initial]
[Iter 6060/20000] Loss: 0.0024851 (Best: 0.0004476 @iter5797) ([92m↓27.00%[0m) [0.99% of initial]
[Iter 7740/20000] Loss: 0.0003761 (Best: 0.0003264 @iter7738) ([92m↓0.37%[0m) [0.15% of initial]
[Iter 6070/20000] Loss: 0.0018456 (Best: 0.0004476 @iter5797) ([92m↓25.73%[0m) [0.73% of initial]
[Iter 7750/20000] Loss: 0.0004154 (Best: 0.0003264 @iter7738) ([91m↑10.47%[0m) [0.17% of initial]
[Iter 6080/20000] Loss: 0.0015721 (Best: 0.0004476 @iter5797) ([92m↓14.82%[0m) [0.62% of initial]
[Iter 7760/20000] Loss: 0.0004659 (Best: 0.0003264 @iter7738) ([91m↑12.15%[0m) [0.19% of initial]
[Iter 6090/20000] Loss: 0.0013073 (Best: 0.0004476 @iter5797) ([92m↓16.84%[0m) [0.52% of initial]
[Iter 7770/20000] Loss: 0.0004545 (Best: 0.0003264 @iter7738) ([92m↓2.45%[0m) [0.18% of initial]
Iter:6099, L1 loss=0.001171, Total loss=0.00122, Time:107
[Iter 6100/20000] Loss: 0.0011708 (Best: 0.0004476 @iter5797) ([92m↓10.44%[0m) [0.47% of initial]
[Iter 7780/20000] Loss: 0.0004503 (Best: 0.0003264 @iter7738) ([92m↓0.92%[0m) [0.18% of initial]
[Iter 6110/20000] Loss: 0.0011391 (Best: 0.0004476 @iter5797) ([92m↓2.71%[0m) [0.45% of initial]
[Iter 7790/20000] Loss: 0.0004554 (Best: 0.0003264 @iter7738) ([91m↑1.12%[0m) [0.18% of initial]
[Iter 6120/20000] Loss: 0.0010611 (Best: 0.0004476 @iter5797) ([92m↓6.85%[0m) [0.42% of initial]
Iter:7799, L1 loss=0.0004446, Total loss=0.0003919, Time:114
[Iter 7800/20000] Loss: 0.0004504 (Best: 0.0003264 @iter7738) ([92m↓1.10%[0m) [0.18% of initial]
[Iter 6130/20000] Loss: 0.0009905 (Best: 0.0004476 @iter5797) ([92m↓6.65%[0m) [0.39% of initial]
[Iter 6140/20000] Loss: 0.0009208 (Best: 0.0004476 @iter5797) ([92m↓7.04%[0m) [0.37% of initial]
[Iter 7810/20000] Loss: 0.0010086 (Best: 0.0003264 @iter7738) ([91m↑123.93%[0m) [0.40% of initial]
[Iter 6150/20000] Loss: 0.0009057 (Best: 0.0004476 @iter5797) ([92m↓1.64%[0m) [0.36% of initial]
[Iter 7820/20000] Loss: 0.0007542 (Best: 0.0003264 @iter7738) ([92m↓25.22%[0m) [0.30% of initial]
[Iter 6160/20000] Loss: 0.0008313 (Best: 0.0004476 @iter5797) ([92m↓8.22%[0m) [0.33% of initial]
[Iter 7830/20000] Loss: 0.0006462 (Best: 0.0003264 @iter7738) ([92m↓14.31%[0m) [0.26% of initial]
[Iter 6170/20000] Loss: 0.0008897 (Best: 0.0004476 @iter5797) ([91m↑7.03%[0m) [0.35% of initial]
[Iter 7840/20000] Loss: 0.0005689 (Best: 0.0003264 @iter7738) ([92m↓11.97%[0m) [0.23% of initial]
[Iter 6180/20000] Loss: 0.0009182 (Best: 0.0004476 @iter5797) ([91m↑3.20%[0m) [0.36% of initial]
[Iter 7850/20000] Loss: 0.0005360 (Best: 0.0003264 @iter7738) ([92m↓5.78%[0m) [0.21% of initial]
[Iter 6190/20000] Loss: 0.0007910 (Best: 0.0004476 @iter5797) ([92m↓13.85%[0m) [0.31% of initial]
[Iter 7860/20000] Loss: 0.0005206 (Best: 0.0003264 @iter7738) ([92m↓2.87%[0m) [0.21% of initial]
Iter:6199, L1 loss=0.0007987, Total loss=0.0007767, Time:100
[Iter 6200/20000] Loss: 0.0007961 (Best: 0.0004476 @iter5797) ([91m↑0.64%[0m) [0.32% of initial]
[Iter 7870/20000] Loss: 0.0004825 (Best: 0.0003264 @iter7738) ([92m↓7.32%[0m) [0.19% of initial]
[Iter 6210/20000] Loss: 0.0021715 (Best: 0.0004476 @iter5797) ([91m↑172.78%[0m) [0.86% of initial]
[Iter 7880/20000] Loss: 0.0004348 (Best: 0.0003264 @iter7738) ([92m↓9.89%[0m) [0.17% of initial]
[Iter 6220/20000] Loss: 0.0014242 (Best: 0.0004476 @iter5797) ([92m↓34.42%[0m) [0.57% of initial]
[Iter 7890/20000] Loss: 0.0005251 (Best: 0.0003264 @iter7738) ([91m↑20.79%[0m) [0.21% of initial]
Iter:7899, L1 loss=0.0004889, Total loss=0.0004425, Time:82
[Iter 6230/20000] Loss: 0.0011536 (Best: 0.0004476 @iter5797) ([92m↓19.00%[0m) [0.46% of initial]
[Iter 7900/20000] Loss: 0.0004536 (Best: 0.0003264 @iter7738) ([92m↓13.63%[0m) [0.18% of initial]
[Iter 6240/20000] Loss: 0.0009586 (Best: 0.0004476 @iter5797) ([92m↓16.91%[0m) [0.38% of initial]
[Iter 7910/20000] Loss: 0.0004485 (Best: 0.0003264 @iter7738) ([92m↓1.11%[0m) [0.18% of initial]
[Iter 6250/20000] Loss: 0.0008681 (Best: 0.0004476 @iter5797) ([92m↓9.44%[0m) [0.34% of initial]
[Iter 7920/20000] Loss: 0.0005451 (Best: 0.0003264 @iter7738) ([91m↑21.52%[0m) [0.22% of initial]
[Iter 6260/20000] Loss: 0.0009574 (Best: 0.0004476 @iter5797) ([91m↑10.29%[0m) [0.38% of initial]
[Iter 7930/20000] Loss: 0.0004566 (Best: 0.0003264 @iter7738) ([92m↓16.23%[0m) [0.18% of initial]
[Iter 6270/20000] Loss: 0.0008361 (Best: 0.0004476 @iter5797) ([92m↓12.67%[0m) [0.33% of initial]
[Iter 7940/20000] Loss: 0.0004078 (Best: 0.0003264 @iter7738) ([92m↓10.70%[0m) [0.16% of initial]
[Iter 6280/20000] Loss: 0.0008632 (Best: 0.0004476 @iter5797) ([91m↑3.24%[0m) [0.34% of initial]
[Iter 7950/20000] Loss: 0.0003967 (Best: 0.0003264 @iter7738) ([92m↓2.71%[0m) [0.16% of initial]
[Iter 6290/20000] Loss: 0.0007788 (Best: 0.0004476 @iter5797) ([92m↓9.77%[0m) [0.31% of initial]
[Iter 7960/20000] Loss: 0.0004732 (Best: 0.0003264 @iter7738) ([91m↑19.27%[0m) [0.19% of initial]
Iter:6299, L1 loss=0.0008179, Total loss=0.0007929, Time:87
[Iter 6300/20000] Loss: 0.0008758 (Best: 0.0004476 @iter5797) ([91m↑12.45%[0m) [0.35% of initial]
[Iter 7970/20000] Loss: 0.0004670 (Best: 0.0003264 @iter7738) ([92m↓1.30%[0m) [0.19% of initial]
[Iter 6310/20000] Loss: 0.0007795 (Best: 0.0004476 @iter5797) ([92m↓10.99%[0m) [0.31% of initial]
[Iter 7980/20000] Loss: 0.0004719 (Best: 0.0003264 @iter7738) ([91m↑1.05%[0m) [0.19% of initial]
[Iter 6320/20000] Loss: 0.0008181 (Best: 0.0004476 @iter5797) ([91m↑4.95%[0m) [0.33% of initial]
[Iter 7990/20000] Loss: 0.0004119 (Best: 0.0003264 @iter7738) ([92m↓12.73%[0m) [0.16% of initial]
[Iter 6330/20000] Loss: 0.0008048 (Best: 0.0004476 @iter5797) ([92m↓1.62%[0m) [0.32% of initial]
Iter:7999, L1 loss=0.0004542, Total loss=0.0004061, Time:93
[Iter 8000/20000] Loss: 0.0004098 (Best: 0.0003264 @iter7738) ([92m↓0.51%[0m) [0.16% of initial]
Pruning 33 points (0.0%) from gaussian0 at iteration 8000
Pruning 57 points (0.0%) from gaussian1 at iteration 8000
[Iter 6340/20000] Loss: 0.0006965 (Best: 0.0004476 @iter5797) ([92m↓13.46%[0m) [0.28% of initial]
[Iter 8010/20000] Loss: 0.0008447 (Best: 0.0003264 @iter7738) ([91m↑106.13%[0m) [0.34% of initial]
[Iter 6350/20000] Loss: 0.0007275 (Best: 0.0004476 @iter5797) ([91m↑4.45%[0m) [0.29% of initial]
[Iter 8020/20000] Loss: 0.0005940 (Best: 0.0003264 @iter7738) ([92m↓29.68%[0m) [0.24% of initial]
[Iter 8030/20000] Loss: 0.0004933 (Best: 0.0003264 @iter7738) ([92m↓16.94%[0m) [0.20% of initial]
[Iter 6360/20000] Loss: 0.0007667 (Best: 0.0004476 @iter5797) ([91m↑5.40%[0m) [0.30% of initial]
[Iter 8040/20000] Loss: 0.0004967 (Best: 0.0003264 @iter7738) ([91m↑0.69%[0m) [0.20% of initial]
[Iter 8050/20000] Loss: 0.0004306 (Best: 0.0003264 @iter7738) ([92m↓13.31%[0m) [0.17% of initial]
[Iter 6370/20000] Loss: 0.0007397 (Best: 0.0004476 @iter5797) ([92m↓3.53%[0m) [0.29% of initial]
[Iter 8060/20000] Loss: 0.0003772 (Best: 0.0003264 @iter7738) ([92m↓12.40%[0m) [0.15% of initial]
[Iter 6380/20000] Loss: 0.0006952 (Best: 0.0004476 @iter5797) ([92m↓6.01%[0m) [0.28% of initial]
[Iter 8070/20000] Loss: 0.0003821 (Best: 0.0003264 @iter7738) ([91m↑1.32%[0m) [0.15% of initial]
[Iter 8080/20000] Loss: 0.0003818 (Best: 0.0003244 @iter8074) ([92m↓0.10%[0m) [0.15% of initial]
[Iter 6390/20000] Loss: 0.0007367 (Best: 0.0004476 @iter5797) ([91m↑5.97%[0m) [0.29% of initial]
[Iter 8090/20000] Loss: 0.0003609 (Best: 0.0003244 @iter8074) ([92m↓5.47%[0m) [0.14% of initial]
Iter:8099, L1 loss=0.0004152, Total loss=0.0003821, Time:88
Iter:6399, L1 loss=0.0007279, Total loss=0.0006814, Time:104
[Iter 8100/20000] Loss: 0.0003882 (Best: 0.0003225 @iter8092) ([91m↑7.58%[0m) [0.15% of initial]
[Iter 6400/20000] Loss: 0.0007679 (Best: 0.0004476 @iter5797) ([91m↑4.24%[0m) [0.31% of initial]
[Iter 8110/20000] Loss: 0.0003850 (Best: 0.0003225 @iter8092) ([92m↓0.84%[0m) [0.15% of initial]
[Iter 8120/20000] Loss: 0.0003778 (Best: 0.0003225 @iter8092) ([92m↓1.86%[0m) [0.15% of initial]
[Iter 6410/20000] Loss: 0.0012140 (Best: 0.0004476 @iter5797) ([91m↑58.10%[0m) [0.48% of initial]
[Iter 8130/20000] Loss: 0.0004507 (Best: 0.0003225 @iter8092) ([91m↑19.30%[0m) [0.18% of initial]
[Iter 6420/20000] Loss: 0.0012235 (Best: 0.0004476 @iter5797) ([91m↑0.78%[0m) [0.49% of initial]
[Iter 8140/20000] Loss: 0.0004207 (Best: 0.0003225 @iter8092) ([92m↓6.66%[0m) [0.17% of initial]
[Iter 8150/20000] Loss: 0.0004405 (Best: 0.0003225 @iter8092) ([91m↑4.71%[0m) [0.18% of initial]
[Iter 6430/20000] Loss: 0.0010610 (Best: 0.0004476 @iter5797) ([92m↓13.29%[0m) [0.42% of initial]
[Iter 8160/20000] Loss: 0.0004283 (Best: 0.0003225 @iter8092) ([92m↓2.76%[0m) [0.17% of initial]
[Iter 8170/20000] Loss: 0.0004235 (Best: 0.0003225 @iter8092) ([92m↓1.14%[0m) [0.17% of initial]
[Iter 6440/20000] Loss: 0.0008723 (Best: 0.0004476 @iter5797) ([92m↓17.78%[0m) [0.35% of initial]
[Iter 8180/20000] Loss: 0.0004331 (Best: 0.0003225 @iter8092) ([91m↑2.27%[0m) [0.17% of initial]
[Iter 8190/20000] Loss: 0.0004466 (Best: 0.0003225 @iter8092) ([91m↑3.13%[0m) [0.18% of initial]
[Iter 6450/20000] Loss: 0.0008263 (Best: 0.0004476 @iter5797) ([92m↓5.28%[0m) [0.33% of initial]
Iter:8199, L1 loss=0.0004998, Total loss=0.000446, Time:100
[Iter 8200/20000] Loss: 0.0004261 (Best: 0.0003225 @iter8092) ([92m↓4.61%[0m) [0.17% of initial]
[Iter 8210/20000] Loss: 0.0004356 (Best: 0.0003225 @iter8092) ([91m↑2.23%[0m) [0.17% of initial]
[Iter 6460/20000] Loss: 0.0007788 (Best: 0.0004476 @iter5797) ([92m↓5.74%[0m) [0.31% of initial]
[Iter 8220/20000] Loss: 0.0004355 (Best: 0.0003225 @iter8092) ([92m↓0.01%[0m) [0.17% of initial]
[Iter 6470/20000] Loss: 0.0007562 (Best: 0.0004476 @iter5797) ([92m↓2.90%[0m) [0.30% of initial]
[Iter 8230/20000] Loss: 0.0004190 (Best: 0.0003225 @iter8092) ([92m↓3.81%[0m) [0.17% of initial]
[Iter 8240/20000] Loss: 0.0004080 (Best: 0.0003225 @iter8092) ([92m↓2.61%[0m) [0.16% of initial]
[Iter 6480/20000] Loss: 0.0007575 (Best: 0.0004476 @iter5797) ([91m↑0.17%[0m) [0.30% of initial]
[Iter 8250/20000] Loss: 0.0004603 (Best: 0.0003225 @iter8092) ([91m↑12.81%[0m) [0.18% of initial]
[Iter 8260/20000] Loss: 0.0004393 (Best: 0.0003225 @iter8092) ([92m↓4.55%[0m) [0.17% of initial]
[Iter 6490/20000] Loss: 0.0007081 (Best: 0.0004476 @iter5797) ([92m↓6.53%[0m) [0.28% of initial]
[Iter 8270/20000] Loss: 0.0004721 (Best: 0.0003225 @iter8092) ([91m↑7.47%[0m) [0.19% of initial]
Iter:6499, L1 loss=0.0008132, Total loss=0.0008229, Time:105
[Iter 8280/20000] Loss: 0.0004479 (Best: 0.0003225 @iter8092) ([92m↓5.12%[0m) [0.18% of initial]
[Iter 6500/20000] Loss: 0.0007893 (Best: 0.0004476 @iter5797) ([91m↑11.48%[0m) [0.31% of initial]
Pruning 114 points (0.1%) from gaussian0 at iteration 6500
[Iter 8290/20000] Loss: 0.0004617 (Best: 0.0003225 @iter8092) ([91m↑3.08%[0m) [0.18% of initial]
Pruning 123 points (0.1%) from gaussian1 at iteration 6500
Iter:8299, L1 loss=0.0004144, Total loss=0.0003635, Time:94
[Iter 8300/20000] Loss: 0.0004118 (Best: 0.0003225 @iter8092) ([92m↓10.81%[0m) [0.16% of initial]
[Iter 6510/20000] Loss: 0.0016840 (Best: 0.0004476 @iter5797) ([91m↑113.35%[0m) [0.67% of initial]
[Iter 8310/20000] Loss: 0.0004085 (Best: 0.0003225 @iter8092) ([92m↓0.81%[0m) [0.16% of initial]
[Iter 8320/20000] Loss: 0.0003732 (Best: 0.0003225 @iter8092) ([92m↓8.64%[0m) [0.15% of initial]
[Iter 6520/20000] Loss: 0.0011336 (Best: 0.0004476 @iter5797) ([92m↓32.68%[0m) [0.45% of initial]
[Iter 8330/20000] Loss: 0.0003650 (Best: 0.0003225 @iter8092) ([92m↓2.19%[0m) [0.15% of initial]
[Iter 8340/20000] Loss: 0.0004035 (Best: 0.0003225 @iter8092) ([91m↑10.53%[0m) [0.16% of initial]
[Iter 6530/20000] Loss: 0.0010710 (Best: 0.0004476 @iter5797) ([92m↓5.52%[0m) [0.43% of initial]
[Iter 8350/20000] Loss: 0.0003513 (Best: 0.0003225 @iter8092) ([92m↓12.92%[0m) [0.14% of initial]
[Iter 6540/20000] Loss: 0.0008662 (Best: 0.0004476 @iter5797) ([92m↓19.13%[0m) [0.34% of initial]
[Iter 8360/20000] Loss: 0.0003446 (Best: 0.0003025 @iter8356) ([92m↓1.92%[0m) [0.14% of initial]
[Iter 8370/20000] Loss: 0.0003392 (Best: 0.0003025 @iter8356) ([92m↓1.57%[0m) [0.13% of initial]
[Iter 6550/20000] Loss: 0.0007699 (Best: 0.0004476 @iter5797) ([92m↓11.12%[0m) [0.31% of initial]
[Iter 8380/20000] Loss: 0.0003719 (Best: 0.0002997 @iter8371) ([91m↑9.65%[0m) [0.15% of initial]
[Iter 8390/20000] Loss: 0.0003244 (Best: 0.0002997 @iter8371) ([92m↓12.78%[0m) [0.13% of initial]
[Iter 6560/20000] Loss: 0.0006872 (Best: 0.0004476 @iter5797) ([92m↓10.73%[0m) [0.27% of initial]
Iter:8399, L1 loss=0.0003844, Total loss=0.0003353, Time:92
[Iter 8400/20000] Loss: 0.0003741 (Best: 0.0002997 @iter8371) ([91m↑15.32%[0m) [0.15% of initial]
[Iter 8410/20000] Loss: 0.0003485 (Best: 0.0002997 @iter8371) ([92m↓6.84%[0m) [0.14% of initial]
[Iter 6570/20000] Loss: 0.0007684 (Best: 0.0004476 @iter5797) ([91m↑11.81%[0m) [0.31% of initial]
[Iter 8420/20000] Loss: 0.0003454 (Best: 0.0002997 @iter8371) ([92m↓0.90%[0m) [0.14% of initial]
[Iter 6580/20000] Loss: 0.0007410 (Best: 0.0004476 @iter5797) ([92m↓3.57%[0m) [0.29% of initial]
[Iter 8430/20000] Loss: 0.0003786 (Best: 0.0002908 @iter8425) ([91m↑9.64%[0m) [0.15% of initial]
[Iter 8440/20000] Loss: 0.0003548 (Best: 0.0002908 @iter8425) ([92m↓6.30%[0m) [0.14% of initial]
[Iter 6590/20000] Loss: 0.0006766 (Best: 0.0004476 @iter5797) ([92m↓8.69%[0m) [0.27% of initial]
[Iter 8450/20000] Loss: 0.0003832 (Best: 0.0002908 @iter8425) ([91m↑7.99%[0m) [0.15% of initial]
[Iter 8460/20000] Loss: 0.0003707 (Best: 0.0002908 @iter8425) ([92m↓3.26%[0m) [0.15% of initial]
Iter:6599, L1 loss=0.0007294, Total loss=0.0007044, Time:121
[Iter 6600/20000] Loss: 0.0007037 (Best: 0.0004476 @iter5797) ([91m↑4.00%[0m) [0.28% of initial]
[Iter 8470/20000] Loss: 0.0003751 (Best: 0.0002908 @iter8425) ([91m↑1.19%[0m) [0.15% of initial]
[Iter 8480/20000] Loss: 0.0003566 (Best: 0.0002908 @iter8425) ([92m↓4.93%[0m) [0.14% of initial]
[Iter 6610/20000] Loss: 0.0012342 (Best: 0.0004476 @iter5797) ([91m↑75.38%[0m) [0.49% of initial]
[Iter 8490/20000] Loss: 0.0003860 (Best: 0.0002908 @iter8425) ([91m↑8.24%[0m) [0.15% of initial]
Iter:8499, L1 loss=0.0004929, Total loss=0.0004274, Time:89
[Iter 8500/20000] Loss: 0.0004429 (Best: 0.0002908 @iter8425) ([91m↑14.73%[0m) [0.18% of initial]
[Iter 6620/20000] Loss: 0.0009792 (Best: 0.0004476 @iter5797) ([92m↓20.66%[0m) [0.39% of initial]
Pruning 23 points (0.0%) from gaussian0 at iteration 8500
Pruning 28 points (0.0%) from gaussian1 at iteration 8500
[Iter 6630/20000] Loss: 0.0008149 (Best: 0.0004476 @iter5797) ([92m↓16.78%[0m) [0.32% of initial]
[Iter 8510/20000] Loss: 0.0008773 (Best: 0.0002908 @iter8425) ([91m↑98.08%[0m) [0.35% of initial]
[Iter 8520/20000] Loss: 0.0006057 (Best: 0.0002908 @iter8425) ([92m↓30.96%[0m) [0.24% of initial]
[Iter 6640/20000] Loss: 0.0007298 (Best: 0.0004476 @iter5797) ([92m↓10.45%[0m) [0.29% of initial]
[Iter 8530/20000] Loss: 0.0004499 (Best: 0.0002908 @iter8425) ([92m↓25.72%[0m) [0.18% of initial]
[Iter 8540/20000] Loss: 0.0003998 (Best: 0.0002908 @iter8425) ([92m↓11.13%[0m) [0.16% of initial]
[Iter 6650/20000] Loss: 0.0007117 (Best: 0.0004476 @iter5797) ([92m↓2.47%[0m) [0.28% of initial]
[Iter 8550/20000] Loss: 0.0003800 (Best: 0.0002908 @iter8425) ([92m↓4.96%[0m) [0.15% of initial]
[Iter 6660/20000] Loss: 0.0007644 (Best: 0.0004476 @iter5797) ([91m↑7.41%[0m) [0.30% of initial]
[Iter 8560/20000] Loss: 0.0003665 (Best: 0.0002908 @iter8425) ([92m↓3.54%[0m) [0.15% of initial]
[Iter 8570/20000] Loss: 0.0003642 (Best: 0.0002908 @iter8425) ([92m↓0.65%[0m) [0.14% of initial]
[Iter 6670/20000] Loss: 0.0007391 (Best: 0.0004476 @iter5797) ([92m↓3.32%[0m) [0.29% of initial]
[Iter 8580/20000] Loss: 0.0003627 (Best: 0.0002908 @iter8425) ([92m↓0.41%[0m) [0.14% of initial]
[Iter 8590/20000] Loss: 0.0003548 (Best: 0.0002908 @iter8425) ([92m↓2.17%[0m) [0.14% of initial]
[Iter 6680/20000] Loss: 0.0007543 (Best: 0.0004476 @iter5797) ([91m↑2.06%[0m) [0.30% of initial]
Iter:8599, L1 loss=0.0003586, Total loss=0.000303, Time:94
[Iter 8600/20000] Loss: 0.0003308 (Best: 0.0002908 @iter8425) ([92m↓6.75%[0m) [0.13% of initial]
[Iter 6690/20000] Loss: 0.0007163 (Best: 0.0004476 @iter5797) ([92m↓5.05%[0m) [0.28% of initial]
[Iter 8610/20000] Loss: 0.0003552 (Best: 0.0002908 @iter8425) ([91m↑7.37%[0m) [0.14% of initial]
[Iter 8620/20000] Loss: 0.0003502 (Best: 0.0002908 @iter8425) ([92m↓1.42%[0m) [0.14% of initial]
Iter:6699, L1 loss=0.000752, Total loss=0.0006972, Time:105
[Iter 6700/20000] Loss: 0.0006828 (Best: 0.0004476 @iter5797) ([92m↓4.67%[0m) [0.27% of initial]
[Iter 8630/20000] Loss: 0.0003476 (Best: 0.0002908 @iter8425) ([92m↓0.74%[0m) [0.14% of initial]
[Iter 8640/20000] Loss: 0.0003269 (Best: 0.0002908 @iter8425) ([92m↓5.97%[0m) [0.13% of initial]
[Iter 6710/20000] Loss: 0.0007355 (Best: 0.0004476 @iter5797) ([91m↑7.71%[0m) [0.29% of initial]
[Iter 8650/20000] Loss: 0.0003338 (Best: 0.0002859 @iter8644) ([91m↑2.11%[0m) [0.13% of initial]
[Iter 6720/20000] Loss: 0.0006885 (Best: 0.0004476 @iter5797) ([92m↓6.38%[0m) [0.27% of initial]
[Iter 8660/20000] Loss: 0.0003930 (Best: 0.0002859 @iter8644) ([91m↑17.75%[0m) [0.16% of initial]
[Iter 8670/20000] Loss: 0.0003927 (Best: 0.0002859 @iter8644) ([92m↓0.08%[0m) [0.16% of initial]
[Iter 6730/20000] Loss: 0.0006445 (Best: 0.0004476 @iter5797) ([92m↓6.39%[0m) [0.26% of initial]
[Iter 8680/20000] Loss: 0.0003552 (Best: 0.0002859 @iter8644) ([92m↓9.57%[0m) [0.14% of initial]
[Iter 8690/20000] Loss: 0.0004336 (Best: 0.0002859 @iter8644) ([91m↑22.09%[0m) [0.17% of initial]
[Iter 6740/20000] Loss: 0.0006894 (Best: 0.0004476 @iter5797) ([91m↑6.96%[0m) [0.27% of initial]
Iter:8699, L1 loss=0.0004137, Total loss=0.0003663, Time:98
[Iter 8700/20000] Loss: 0.0003771 (Best: 0.0002859 @iter8644) ([92m↓13.03%[0m) [0.15% of initial]
[Iter 6750/20000] Loss: 0.0006955 (Best: 0.0004476 @iter5797) ([91m↑0.90%[0m) [0.28% of initial]
[Iter 8710/20000] Loss: 0.0003627 (Best: 0.0002859 @iter8644) ([92m↓3.82%[0m) [0.14% of initial]
[Iter 8720/20000] Loss: 0.0003447 (Best: 0.0002859 @iter8644) ([92m↓4.96%[0m) [0.14% of initial]
[Iter 6760/20000] Loss: 0.0006598 (Best: 0.0004476 @iter5797) ([92m↓5.13%[0m) [0.26% of initial]
[Iter 8730/20000] Loss: 0.0003838 (Best: 0.0002859 @iter8644) ([91m↑11.33%[0m) [0.15% of initial]
[Iter 8740/20000] Loss: 0.0003584 (Best: 0.0002859 @iter8644) ([92m↓6.61%[0m) [0.14% of initial]
[Iter 6770/20000] Loss: 0.0006508 (Best: 0.0004476 @iter5797) ([92m↓1.37%[0m) [0.26% of initial]
[Iter 8750/20000] Loss: 0.0004386 (Best: 0.0002859 @iter8644) ([91m↑22.38%[0m) [0.17% of initial]
[Iter 8760/20000] Loss: 0.0003985 (Best: 0.0002859 @iter8644) ([92m↓9.15%[0m) [0.16% of initial]
[Iter 6780/20000] Loss: 0.0006129 (Best: 0.0004476 @iter5797) ([92m↓5.82%[0m) [0.24% of initial]
[Iter 8770/20000] Loss: 0.0004072 (Best: 0.0002859 @iter8644) ([91m↑2.19%[0m) [0.16% of initial]
[Iter 6790/20000] Loss: 0.0006711 (Best: 0.0004476 @iter5797) ([91m↑9.50%[0m) [0.27% of initial]
[Iter 8780/20000] Loss: 0.0003929 (Best: 0.0002859 @iter8644) ([92m↓3.49%[0m) [0.16% of initial]
[Iter 8790/20000] Loss: 0.0003917 (Best: 0.0002859 @iter8644) ([92m↓0.30%[0m) [0.16% of initial]
Iter:6799, L1 loss=0.000653, Total loss=0.0006178, Time:111
[Iter 6800/20000] Loss: 0.0006111 (Best: 0.0004476 @iter5797) ([92m↓8.94%[0m) [0.24% of initial]
Iter:8799, L1 loss=0.0004836, Total loss=0.0004244, Time:92
[Iter 8800/20000] Loss: 0.0003778 (Best: 0.0002859 @iter8644) ([92m↓3.55%[0m) [0.15% of initial]
[Iter 8810/20000] Loss: 0.0003279 (Best: 0.0002859 @iter8644) ([92m↓13.22%[0m) [0.13% of initial]
[Iter 6810/20000] Loss: 0.0010876 (Best: 0.0004476 @iter5797) ([91m↑77.96%[0m) [0.43% of initial]
[Iter 8820/20000] Loss: 0.0003958 (Best: 0.0002859 @iter8644) ([91m↑20.73%[0m) [0.16% of initial]
[Iter 8830/20000] Loss: 0.0004770 (Best: 0.0002859 @iter8644) ([91m↑20.51%[0m) [0.19% of initial]
[Iter 6820/20000] Loss: 0.0009828 (Best: 0.0004476 @iter5797) ([92m↓9.63%[0m) [0.39% of initial]
[Iter 8840/20000] Loss: 0.0004300 (Best: 0.0002859 @iter8644) ([92m↓9.86%[0m) [0.17% of initial]
[Iter 6830/20000] Loss: 0.0007834 (Best: 0.0004476 @iter5797) ([92m↓20.29%[0m) [0.31% of initial]
[Iter 8850/20000] Loss: 0.0004460 (Best: 0.0002859 @iter8644) ([91m↑3.73%[0m) [0.18% of initial]
[Iter 8860/20000] Loss: 0.0003719 (Best: 0.0002859 @iter8644) ([92m↓16.61%[0m) [0.15% of initial]
[Iter 6840/20000] Loss: 0.0007220 (Best: 0.0004476 @iter5797) ([92m↓7.84%[0m) [0.29% of initial]
[Iter 8870/20000] Loss: 0.0003451 (Best: 0.0002859 @iter8644) ([92m↓7.21%[0m) [0.14% of initial]
[Iter 8880/20000] Loss: 0.0003518 (Best: 0.0002859 @iter8644) ([91m↑1.94%[0m) [0.14% of initial]
[Iter 6850/20000] Loss: 0.0007143 (Best: 0.0004476 @iter5797) ([92m↓1.06%[0m) [0.28% of initial]
[Iter 8890/20000] Loss: 0.0003337 (Best: 0.0002859 @iter8644) ([92m↓5.14%[0m) [0.13% of initial]
Iter:8899, L1 loss=0.0003656, Total loss=0.0003297, Time:88
[Iter 8900/20000] Loss: 0.0003783 (Best: 0.0002859 @iter8644) ([91m↑13.38%[0m) [0.15% of initial]
[Iter 6860/20000] Loss: 0.0006744 (Best: 0.0004476 @iter5797) ([92m↓5.58%[0m) [0.27% of initial]
[Iter 8910/20000] Loss: 0.0003740 (Best: 0.0002859 @iter8644) ([92m↓1.14%[0m) [0.15% of initial]
[Iter 6870/20000] Loss: 0.0006693 (Best: 0.0004476 @iter5797) ([92m↓0.76%[0m) [0.27% of initial]
[Iter 8920/20000] Loss: 0.0003515 (Best: 0.0002859 @iter8644) ([92m↓6.03%[0m) [0.14% of initial]
[Iter 8930/20000] Loss: 0.0003498 (Best: 0.0002859 @iter8644) ([92m↓0.49%[0m) [0.14% of initial]
[Iter 6880/20000] Loss: 0.0006538 (Best: 0.0004476 @iter5797) ([92m↓2.32%[0m) [0.26% of initial]
[Iter 8940/20000] Loss: 0.0003528 (Best: 0.0002859 @iter8644) ([91m↑0.87%[0m) [0.14% of initial]
[Iter 8950/20000] Loss: 0.0003821 (Best: 0.0002859 @iter8644) ([91m↑8.31%[0m) [0.15% of initial]
[Iter 6890/20000] Loss: 0.0007264 (Best: 0.0004476 @iter5797) ([91m↑11.11%[0m) [0.29% of initial]
[Iter 8960/20000] Loss: 0.0003860 (Best: 0.0002859 @iter8644) ([91m↑1.00%[0m) [0.15% of initial]
Iter:6899, L1 loss=0.0007525, Total loss=0.0007501, Time:104
[Iter 6900/20000] Loss: 0.0007332 (Best: 0.0004476 @iter5797) ([91m↑0.93%[0m) [0.29% of initial]
[Iter 8970/20000] Loss: 0.0004479 (Best: 0.0002859 @iter8644) ([91m↑16.05%[0m) [0.18% of initial]
[Iter 8980/20000] Loss: 0.0004225 (Best: 0.0002859 @iter8644) ([92m↓5.68%[0m) [0.17% of initial]
[Iter 6910/20000] Loss: 0.0007439 (Best: 0.0004476 @iter5797) ([91m↑1.47%[0m) [0.30% of initial]
[Iter 8990/20000] Loss: 0.0003749 (Best: 0.0002859 @iter8644) ([92m↓11.26%[0m) [0.15% of initial]
Iter:8999, L1 loss=0.0003623, Total loss=0.0003172, Time:88
[Iter 9000/20000] Loss: 0.0003520 (Best: 0.0002859 @iter8644) ([92m↓6.10%[0m) [0.14% of initial]
[Iter 6920/20000] Loss: 0.0006876 (Best: 0.0004476 @iter5797) ([92m↓7.58%[0m) [0.27% of initial]
Pruning 29 points (0.0%) from gaussian0 at iteration 9000
Pruning 26 points (0.0%) from gaussian1 at iteration 9000
[Iter 6930/20000] Loss: 0.0006867 (Best: 0.0004476 @iter5797) ([92m↓0.13%[0m) [0.27% of initial]
[Iter 9010/20000] Loss: 0.0007432 (Best: 0.0002859 @iter8644) ([91m↑111.14%[0m) [0.30% of initial]
[Iter 9020/20000] Loss: 0.0005335 (Best: 0.0002859 @iter8644) ([92m↓28.22%[0m) [0.21% of initial]
[Iter 6940/20000] Loss: 0.0006234 (Best: 0.0004476 @iter5797) ([92m↓9.21%[0m) [0.25% of initial]
[Iter 9030/20000] Loss: 0.0004218 (Best: 0.0002859 @iter8644) ([92m↓20.94%[0m) [0.17% of initial]
[Iter 9040/20000] Loss: 0.0003778 (Best: 0.0002859 @iter8644) ([92m↓10.44%[0m) [0.15% of initial]
[Iter 6950/20000] Loss: 0.0006255 (Best: 0.0004476 @iter5797) ([91m↑0.34%[0m) [0.25% of initial]
[Iter 9050/20000] Loss: 0.0003491 (Best: 0.0002859 @iter8644) ([92m↓7.58%[0m) [0.14% of initial]
[Iter 9060/20000] Loss: 0.0003704 (Best: 0.0002859 @iter8644) ([91m↑6.09%[0m) [0.15% of initial]
[Iter 6960/20000] Loss: 0.0006013 (Best: 0.0004476 @iter5797) ([92m↓3.88%[0m) [0.24% of initial]
[Iter 9070/20000] Loss: 0.0003819 (Best: 0.0002859 @iter8644) ([91m↑3.10%[0m) [0.15% of initial]
[Iter 9080/20000] Loss: 0.0004007 (Best: 0.0002859 @iter8644) ([91m↑4.93%[0m) [0.16% of initial]
[Iter 6970/20000] Loss: 0.0006787 (Best: 0.0004476 @iter5797) ([91m↑12.89%[0m) [0.27% of initial]
[Iter 9090/20000] Loss: 0.0003803 (Best: 0.0002859 @iter8644) ([92m↓5.08%[0m) [0.15% of initial]
[Iter 6980/20000] Loss: 0.0006845 (Best: 0.0004476 @iter5797) ([91m↑0.85%[0m) [0.27% of initial]
Iter:9099, L1 loss=0.0004749, Total loss=0.0004311, Time:99
[Iter 9100/20000] Loss: 0.0003861 (Best: 0.0002859 @iter8644) ([91m↑1.51%[0m) [0.15% of initial]
[Iter 9110/20000] Loss: 0.0004613 (Best: 0.0002859 @iter8644) ([91m↑19.49%[0m) [0.18% of initial]
[Iter 6990/20000] Loss: 0.0006404 (Best: 0.0004476 @iter5797) ([92m↓6.45%[0m) [0.25% of initial]
[Iter 9120/20000] Loss: 0.0003833 (Best: 0.0002859 @iter8644) ([92m↓16.92%[0m) [0.15% of initial]
Iter:6999, L1 loss=0.0007905, Total loss=0.0007486, Time:123
[Iter 9130/20000] Loss: 0.0003736 (Best: 0.0002859 @iter8644) ([92m↓2.51%[0m) [0.15% of initial]
[Iter 7000/20000] Loss: 0.0006512 (Best: 0.0004476 @iter5797) ([91m↑1.69%[0m) [0.26% of initial]
[Iter 9140/20000] Loss: 0.0003750 (Best: 0.0002859 @iter8644) ([91m↑0.36%[0m) [0.15% of initial]
Pruning 110 points (0.1%) from gaussian0 at iteration 7000
Pruning 92 points (0.1%) from gaussian1 at iteration 7000
[Iter 9150/20000] Loss: 0.0003358 (Best: 0.0002859 @iter8644) ([92m↓10.45%[0m) [0.13% of initial]
[Iter 9160/20000] Loss: 0.0003574 (Best: 0.0002859 @iter8644) ([91m↑6.43%[0m) [0.14% of initial]
[Iter 7010/20000] Loss: 0.0015966 (Best: 0.0004476 @iter5797) ([91m↑145.18%[0m) [0.63% of initial]
[Iter 9170/20000] Loss: 0.0003304 (Best: 0.0002859 @iter8644) ([92m↓7.54%[0m) [0.13% of initial]
[Iter 7020/20000] Loss: 0.0011207 (Best: 0.0004476 @iter5797) ([92m↓29.81%[0m) [0.45% of initial]
[Iter 9180/20000] Loss: 0.0003520 (Best: 0.0002859 @iter8644) ([91m↑6.52%[0m) [0.14% of initial]
[Iter 9190/20000] Loss: 0.0003030 (Best: 0.0002834 @iter9187) ([92m↓13.90%[0m) [0.12% of initial]
[Iter 7030/20000] Loss: 0.0008398 (Best: 0.0004476 @iter5797) ([92m↓25.07%[0m) [0.33% of initial]
Iter:9199, L1 loss=0.0003562, Total loss=0.0003208, Time:103
[Iter 9200/20000] Loss: 0.0003296 (Best: 0.0002834 @iter9187) ([91m↑8.76%[0m) [0.13% of initial]
[Iter 9210/20000] Loss: 0.0003424 (Best: 0.0002834 @iter9187) ([91m↑3.88%[0m) [0.14% of initial]
[Iter 7040/20000] Loss: 0.0007275 (Best: 0.0004476 @iter5797) ([92m↓13.37%[0m) [0.29% of initial]
[Iter 9220/20000] Loss: 0.0003470 (Best: 0.0002834 @iter9187) ([91m↑1.35%[0m) [0.14% of initial]
[Iter 7050/20000] Loss: 0.0006972 (Best: 0.0004476 @iter5797) ([92m↓4.17%[0m) [0.28% of initial]
[Iter 9230/20000] Loss: 0.0003477 (Best: 0.0002834 @iter9187) ([91m↑0.21%[0m) [0.14% of initial]
[Iter 9240/20000] Loss: 0.0003641 (Best: 0.0002834 @iter9187) ([91m↑4.71%[0m) [0.14% of initial]
[Iter 7060/20000] Loss: 0.0007151 (Best: 0.0004476 @iter5797) ([91m↑2.56%[0m) [0.28% of initial]
[Iter 9250/20000] Loss: 0.0003530 (Best: 0.0002834 @iter9187) ([92m↓3.05%[0m) [0.14% of initial]
[Iter 9260/20000] Loss: 0.0003552 (Best: 0.0002834 @iter9187) ([91m↑0.63%[0m) [0.14% of initial]
[Iter 7070/20000] Loss: 0.0006574 (Best: 0.0004476 @iter5797) ([92m↓8.06%[0m) [0.26% of initial]
[Iter 9270/20000] Loss: 0.0003433 (Best: 0.0002834 @iter9187) ([92m↓3.36%[0m) [0.14% of initial]
[Iter 7080/20000] Loss: 0.0006578 (Best: 0.0004476 @iter5797) ([91m↑0.06%[0m) [0.26% of initial]
[Iter 9280/20000] Loss: 0.0003119 (Best: 0.0002834 @iter9187) ([92m↓9.13%[0m) [0.12% of initial]
[Iter 9290/20000] Loss: 0.0003096 (Best: 0.0002772 @iter9289) ([92m↓0.74%[0m) [0.12% of initial]
[Iter 7090/20000] Loss: 0.0006807 (Best: 0.0004476 @iter5797) ([91m↑3.48%[0m) [0.27% of initial]
Iter:9299, L1 loss=0.0003377, Total loss=0.0002898, Time:106
[Iter 9300/20000] Loss: 0.0003341 (Best: 0.0002772 @iter9289) ([91m↑7.91%[0m) [0.13% of initial]
Iter:7099, L1 loss=0.000665, Total loss=0.0006101, Time:101
[Iter 9310/20000] Loss: 0.0003417 (Best: 0.0002772 @iter9289) ([91m↑2.25%[0m) [0.14% of initial]
[Iter 7100/20000] Loss: 0.0006405 (Best: 0.0004476 @iter5797) ([92m↓5.92%[0m) [0.25% of initial]
[Iter 9320/20000] Loss: 0.0003431 (Best: 0.0002772 @iter9289) ([91m↑0.43%[0m) [0.14% of initial]
[Iter 7110/20000] Loss: 0.0006560 (Best: 0.0004476 @iter5797) ([91m↑2.43%[0m) [0.26% of initial]
[Iter 9330/20000] Loss: 0.0003979 (Best: 0.0002772 @iter9289) ([91m↑15.96%[0m) [0.16% of initial]
[Iter 9340/20000] Loss: 0.0004010 (Best: 0.0002772 @iter9289) ([91m↑0.78%[0m) [0.16% of initial]
[Iter 7120/20000] Loss: 0.0006212 (Best: 0.0004476 @iter5797) ([92m↓5.30%[0m) [0.25% of initial]
[Iter 9350/20000] Loss: 0.0003485 (Best: 0.0002772 @iter9289) ([92m↓13.10%[0m) [0.14% of initial]
[Iter 9360/20000] Loss: 0.0003813 (Best: 0.0002772 @iter9289) ([91m↑9.42%[0m) [0.15% of initial]
[Iter 7130/20000] Loss: 0.0006118 (Best: 0.0004476 @iter5797) ([92m↓1.52%[0m) [0.24% of initial]
[Iter 9370/20000] Loss: 0.0003224 (Best: 0.0002772 @iter9289) ([92m↓15.43%[0m) [0.13% of initial]
[Iter 7140/20000] Loss: 0.0006752 (Best: 0.0004476 @iter5797) ([91m↑10.37%[0m) [0.27% of initial]
[Iter 9380/20000] Loss: 0.0003445 (Best: 0.0002772 @iter9289) ([91m↑6.85%[0m) [0.14% of initial]
[Iter 9390/20000] Loss: 0.0003490 (Best: 0.0002772 @iter9289) ([91m↑1.30%[0m) [0.14% of initial]
[Iter 7150/20000] Loss: 0.0006476 (Best: 0.0004476 @iter5797) ([92m↓4.09%[0m) [0.26% of initial]
Iter:9399, L1 loss=0.0004507, Total loss=0.0004242, Time:96
[Iter 9400/20000] Loss: 0.0003443 (Best: 0.0002772 @iter9289) ([92m↓1.36%[0m) [0.14% of initial]
[Iter 9410/20000] Loss: 0.0003452 (Best: 0.0002772 @iter9289) ([91m↑0.27%[0m) [0.14% of initial]
[Iter 7160/20000] Loss: 0.0006334 (Best: 0.0004476 @iter5797) ([92m↓2.19%[0m) [0.25% of initial]
[Iter 9420/20000] Loss: 0.0003524 (Best: 0.0002772 @iter9289) ([91m↑2.08%[0m) [0.14% of initial]
[Iter 7170/20000] Loss: 0.0006397 (Best: 0.0004476 @iter5797) ([91m↑0.99%[0m) [0.25% of initial]
[Iter 9430/20000] Loss: 0.0003132 (Best: 0.0002772 @iter9289) ([92m↓11.12%[0m) [0.12% of initial]
[Iter 9440/20000] Loss: 0.0003607 (Best: 0.0002772 @iter9289) ([91m↑15.16%[0m) [0.14% of initial]
[Iter 7180/20000] Loss: 0.0006498 (Best: 0.0004476 @iter5797) ([91m↑1.57%[0m) [0.26% of initial]
[Iter 9450/20000] Loss: 0.0003375 (Best: 0.0002772 @iter9289) ([92m↓6.43%[0m) [0.13% of initial]
[Iter 9460/20000] Loss: 0.0002940 (Best: 0.0002772 @iter9289) ([92m↓12.89%[0m) [0.12% of initial]
[Iter 7190/20000] Loss: 0.0005809 (Best: 0.0004476 @iter5797) ([92m↓10.60%[0m) [0.23% of initial]
[Iter 9470/20000] Loss: 0.0002941 (Best: 0.0002724 @iter9466) ([91m↑0.04%[0m) [0.12% of initial]
Iter:7199, L1 loss=0.000645, Total loss=0.0006133, Time:125
[Iter 7200/20000] Loss: 0.0006103 (Best: 0.0004476 @iter5797) ([91m↑5.06%[0m) [0.24% of initial]
[Iter 9480/20000] Loss: 0.0003622 (Best: 0.0002724 @iter9466) ([91m↑23.17%[0m) [0.14% of initial]
[Iter 9490/20000] Loss: 0.0003295 (Best: 0.0002724 @iter9466) ([92m↓9.04%[0m) [0.13% of initial]
Iter:9499, L1 loss=0.0003482, Total loss=0.00032, Time:108
[Iter 9500/20000] Loss: 0.0003362 (Best: 0.0002724 @iter9466) ([91m↑2.04%[0m) [0.13% of initial]
[Iter 7210/20000] Loss: 0.0011517 (Best: 0.0004476 @iter5797) ([91m↑88.72%[0m) [0.46% of initial]
Pruning 24 points (0.0%) from gaussian0 at iteration 9500
Pruning 29 points (0.0%) from gaussian1 at iteration 9500
[Iter 7220/20000] Loss: 0.0010745 (Best: 0.0004476 @iter5797) ([92m↓6.70%[0m) [0.43% of initial]
[Iter 9510/20000] Loss: 0.0006345 (Best: 0.0002724 @iter9466) ([91m↑88.70%[0m) [0.25% of initial]
[Iter 9520/20000] Loss: 0.0004693 (Best: 0.0002724 @iter9466) ([92m↓26.03%[0m) [0.19% of initial]
[Iter 7230/20000] Loss: 0.0008583 (Best: 0.0004476 @iter5797) ([92m↓20.12%[0m) [0.34% of initial]
[Iter 9530/20000] Loss: 0.0004955 (Best: 0.0002724 @iter9466) ([91m↑5.58%[0m) [0.20% of initial]
[Iter 7240/20000] Loss: 0.0007248 (Best: 0.0004476 @iter5797) ([92m↓15.56%[0m) [0.29% of initial]
[Iter 9540/20000] Loss: 0.0003672 (Best: 0.0002724 @iter9466) ([92m↓25.89%[0m) [0.15% of initial]
[Iter 9550/20000] Loss: 0.0003153 (Best: 0.0002724 @iter9466) ([92m↓14.12%[0m) [0.13% of initial]
[Iter 7250/20000] Loss: 0.0006498 (Best: 0.0004476 @iter5797) ([92m↓10.34%[0m) [0.26% of initial]
[Iter 9560/20000] Loss: 0.0003051 (Best: 0.0002711 @iter9553) ([92m↓3.24%[0m) [0.12% of initial]
[Iter 9570/20000] Loss: 0.0003022 (Best: 0.0002711 @iter9553) ([92m↓0.97%[0m) [0.12% of initial]
[Iter 7260/20000] Loss: 0.0006311 (Best: 0.0004476 @iter5797) ([92m↓2.88%[0m) [0.25% of initial]
[Iter 9580/20000] Loss: 0.0002835 (Best: 0.0002572 @iter9574) ([92m↓6.19%[0m) [0.11% of initial]
[Iter 7270/20000] Loss: 0.0005854 (Best: 0.0004476 @iter5797) ([92m↓7.24%[0m) [0.23% of initial]
[Iter 9590/20000] Loss: 0.0002844 (Best: 0.0002572 @iter9574) ([91m↑0.32%[0m) [0.11% of initial]
Iter:9599, L1 loss=0.0004309, Total loss=0.0003852, Time:91
[Iter 9600/20000] Loss: 0.0003268 (Best: 0.0002572 @iter9574) ([91m↑14.90%[0m) [0.13% of initial]
[Iter 7280/20000] Loss: 0.0005720 (Best: 0.0004476 @iter5797) ([92m↓2.28%[0m) [0.23% of initial]
[Iter 9610/20000] Loss: 0.0003076 (Best: 0.0002572 @iter9574) ([92m↓5.86%[0m) [0.12% of initial]
[Iter 9620/20000] Loss: 0.0003224 (Best: 0.0002572 @iter9574) ([91m↑4.78%[0m) [0.13% of initial]
[Iter 7290/20000] Loss: 0.0005984 (Best: 0.0004476 @iter5797) ([91m↑4.61%[0m) [0.24% of initial]
[Iter 9630/20000] Loss: 0.0002920 (Best: 0.0002565 @iter9628) ([92m↓9.41%[0m) [0.12% of initial]
Iter:7299, L1 loss=0.0007194, Total loss=0.0006812, Time:116
[Iter 7300/20000] Loss: 0.0006097 (Best: 0.0004476 @iter5797) ([91m↑1.89%[0m) [0.24% of initial]
[Iter 9640/20000] Loss: 0.0002874 (Best: 0.0002510 @iter9638) ([92m↓1.57%[0m) [0.11% of initial]
[Iter 9650/20000] Loss: 0.0003401 (Best: 0.0002510 @iter9638) ([91m↑18.33%[0m) [0.14% of initial]
[Iter 7310/20000] Loss: 0.0006149 (Best: 0.0004476 @iter5797) ([91m↑0.86%[0m) [0.24% of initial]
[Iter 9660/20000] Loss: 0.0003142 (Best: 0.0002510 @iter9638) ([92m↓7.63%[0m) [0.12% of initial]
[Iter 9670/20000] Loss: 0.0003524 (Best: 0.0002510 @iter9638) ([91m↑12.15%[0m) [0.14% of initial]
[Iter 7320/20000] Loss: 0.0006807 (Best: 0.0004476 @iter5797) ([91m↑10.69%[0m) [0.27% of initial]
[Iter 9680/20000] Loss: 0.0003457 (Best: 0.0002510 @iter9638) ([92m↓1.88%[0m) [0.14% of initial]
[Iter 7330/20000] Loss: 0.0006597 (Best: 0.0004476 @iter5797) ([92m↓3.09%[0m) [0.26% of initial]
[Iter 9690/20000] Loss: 0.0004119 (Best: 0.0002510 @iter9638) ([91m↑19.14%[0m) [0.16% of initial]
Iter:9699, L1 loss=0.0005269, Total loss=0.0004545, Time:95
[Iter 9700/20000] Loss: 0.0003690 (Best: 0.0002510 @iter9638) ([92m↓10.43%[0m) [0.15% of initial]
[Iter 7340/20000] Loss: 0.0006107 (Best: 0.0004476 @iter5797) ([92m↓7.43%[0m) [0.24% of initial]
[Iter 9710/20000] Loss: 0.0003571 (Best: 0.0002510 @iter9638) ([92m↓3.23%[0m) [0.14% of initial]
[Iter 9720/20000] Loss: 0.0003316 (Best: 0.0002510 @iter9638) ([92m↓7.13%[0m) [0.13% of initial]
[Iter 7350/20000] Loss: 0.0006401 (Best: 0.0004476 @iter5797) ([91m↑4.81%[0m) [0.25% of initial]
[Iter 9730/20000] Loss: 0.0003140 (Best: 0.0002510 @iter9638) ([92m↓5.30%[0m) [0.12% of initial]
[Iter 7360/20000] Loss: 0.0006509 (Best: 0.0004476 @iter5797) ([91m↑1.69%[0m) [0.26% of initial]
[Iter 9740/20000] Loss: 0.0003356 (Best: 0.0002510 @iter9638) ([91m↑6.87%[0m) [0.13% of initial]
[Iter 9750/20000] Loss: 0.0003340 (Best: 0.0002510 @iter9638) ([92m↓0.47%[0m) [0.13% of initial]
[Iter 7370/20000] Loss: 0.0005919 (Best: 0.0004476 @iter5797) ([92m↓9.07%[0m) [0.24% of initial]
[Iter 9760/20000] Loss: 0.0003104 (Best: 0.0002510 @iter9638) ([92m↓7.07%[0m) [0.12% of initial]
[Iter 9770/20000] Loss: 0.0003162 (Best: 0.0002510 @iter9638) ([91m↑1.89%[0m) [0.13% of initial]
[Iter 7380/20000] Loss: 0.0006976 (Best: 0.0004476 @iter5797) ([91m↑17.87%[0m) [0.28% of initial]
[Iter 9780/20000] Loss: 0.0002962 (Best: 0.0002510 @iter9638) ([92m↓6.33%[0m) [0.12% of initial]
[Iter 9790/20000] Loss: 0.0002896 (Best: 0.0002503 @iter9784) ([92m↓2.24%[0m) [0.12% of initial]
[Iter 7390/20000] Loss: 0.0006972 (Best: 0.0004476 @iter5797) ([92m↓0.05%[0m) [0.28% of initial]
Iter:9799, L1 loss=0.0003406, Total loss=0.0002949, Time:91
[Iter 9800/20000] Loss: 0.0003158 (Best: 0.0002503 @iter9784) ([91m↑9.04%[0m) [0.13% of initial]
Iter:7399, L1 loss=0.000759, Total loss=0.0006636, Time:103
[Iter 7400/20000] Loss: 0.0007240 (Best: 0.0004476 @iter5797) ([91m↑3.83%[0m) [0.29% of initial]
[Iter 9810/20000] Loss: 0.0003027 (Best: 0.0002503 @iter9784) ([92m↓4.15%[0m) [0.12% of initial]
[Iter 9820/20000] Loss: 0.0002779 (Best: 0.0002503 @iter9784) ([92m↓8.17%[0m) [0.11% of initial]
[Iter 9830/20000] Loss: 0.0002996 (Best: 0.0002503 @iter9784) ([91m↑7.81%[0m) [0.12% of initial]
[Iter 7410/20000] Loss: 0.0012791 (Best: 0.0004476 @iter5797) ([91m↑76.68%[0m) [0.51% of initial]
[Iter 9840/20000] Loss: 0.0003141 (Best: 0.0002503 @iter9784) ([91m↑4.82%[0m) [0.12% of initial]
[Iter 9850/20000] Loss: 0.0002895 (Best: 0.0002503 @iter9784) ([92m↓7.81%[0m) [0.12% of initial]
[Iter 7420/20000] Loss: 0.0009749 (Best: 0.0004476 @iter5797) ([92m↓23.78%[0m) [0.39% of initial]
[Iter 9860/20000] Loss: 0.0002887 (Best: 0.0002503 @iter9784) ([92m↓0.30%[0m) [0.11% of initial]
[Iter 7430/20000] Loss: 0.0008097 (Best: 0.0004476 @iter5797) ([92m↓16.95%[0m) [0.32% of initial]
[Iter 9870/20000] Loss: 0.0003240 (Best: 0.0002503 @iter9784) ([91m↑12.24%[0m) [0.13% of initial]
[Iter 9880/20000] Loss: 0.0003365 (Best: 0.0002503 @iter9784) ([91m↑3.85%[0m) [0.13% of initial]
[Iter 7440/20000] Loss: 0.0007278 (Best: 0.0004476 @iter5797) ([92m↓10.11%[0m) [0.29% of initial]
[Iter 9890/20000] Loss: 0.0004800 (Best: 0.0002503 @iter9784) ([91m↑42.65%[0m) [0.19% of initial]
Iter:9899, L1 loss=0.0004486, Total loss=0.0004273, Time:89
[Iter 9900/20000] Loss: 0.0003946 (Best: 0.0002503 @iter9784) ([92m↓17.79%[0m) [0.16% of initial]
[Iter 7450/20000] Loss: 0.0006694 (Best: 0.0004476 @iter5797) ([92m↓8.03%[0m) [0.27% of initial]
[Iter 9910/20000] Loss: 0.0003062 (Best: 0.0002503 @iter9784) ([92m↓22.41%[0m) [0.12% of initial]
[Iter 9920/20000] Loss: 0.0003032 (Best: 0.0002503 @iter9784) ([92m↓0.97%[0m) [0.12% of initial]
[Iter 7460/20000] Loss: 0.0006592 (Best: 0.0004476 @iter5797) ([92m↓1.53%[0m) [0.26% of initial]
[Iter 9930/20000] Loss: 0.0003242 (Best: 0.0002503 @iter9784) ([91m↑6.92%[0m) [0.13% of initial]
[Iter 7470/20000] Loss: 0.0006196 (Best: 0.0004476 @iter5797) ([92m↓6.01%[0m) [0.25% of initial]
[Iter 9940/20000] Loss: 0.0003145 (Best: 0.0002503 @iter9784) ([92m↓3.00%[0m) [0.12% of initial]
[Iter 9950/20000] Loss: 0.0003611 (Best: 0.0002503 @iter9784) ([91m↑14.84%[0m) [0.14% of initial]
[Iter 7480/20000] Loss: 0.0006008 (Best: 0.0004476 @iter5797) ([92m↓3.03%[0m) [0.24% of initial]
[Iter 9960/20000] Loss: 0.0003561 (Best: 0.0002503 @iter9784) ([92m↓1.40%[0m) [0.14% of initial]
[Iter 9970/20000] Loss: 0.0003274 (Best: 0.0002503 @iter9784) ([92m↓8.04%[0m) [0.13% of initial]
[Iter 7490/20000] Loss: 0.0005499 (Best: 0.0004476 @iter5797) ([92m↓8.48%[0m) [0.22% of initial]
[Iter 9980/20000] Loss: 0.0003047 (Best: 0.0002503 @iter9784) ([92m↓6.94%[0m) [0.12% of initial]
[Iter 9990/20000] Loss: 0.0003292 (Best: 0.0002503 @iter9784) ([91m↑8.02%[0m) [0.13% of initial]
Iter:7499, L1 loss=0.0006218, Total loss=0.0005641, Time:104
[Iter 7500/20000] Loss: 0.0005906 (Best: 0.0004476 @iter5797) ([91m↑7.41%[0m) [0.23% of initial]
Iter:9999, L1 loss=0.0005033, Total loss=0.0004294, Time:77
Pruning 72 points (0.1%) from gaussian0 at iteration 7500
[Iter 10000/20000] Loss: 0.0003766 (Best: 0.0002503 @iter9784) ([91m↑14.41%[0m) [0.15% of initial]
Pruning 67 points (0.1%) from gaussian1 at iteration 7500
Pruning 15 points (0.0%) from gaussian0 at iteration 10000
Pruning 15 points (0.0%) from gaussian1 at iteration 10000
[Iter 7510/20000] Loss: 0.0013203 (Best: 0.0004476 @iter5797) ([91m↑123.55%[0m) [0.52% of initial]
[Iter 10010/20000] Loss: 0.0006779 (Best: 0.0002503 @iter9784) ([91m↑80.02%[0m) [0.27% of initial]
[Iter 10020/20000] Loss: 0.0004260 (Best: 0.0002503 @iter9784) ([92m↓37.16%[0m) [0.17% of initial]
[Iter 10030/20000] Loss: 0.0003296 (Best: 0.0002503 @iter9784) ([92m↓22.63%[0m) [0.13% of initial]
[Iter 7520/20000] Loss: 0.0009019 (Best: 0.0004476 @iter5797) ([92m↓31.69%[0m) [0.36% of initial]
[Iter 10040/20000] Loss: 0.0003109 (Best: 0.0002503 @iter9784) ([92m↓5.67%[0m) [0.12% of initial]
[Iter 10050/20000] Loss: 0.0003551 (Best: 0.0002503 @iter9784) ([91m↑14.21%[0m) [0.14% of initial]
[Iter 7530/20000] Loss: 0.0007250 (Best: 0.0004476 @iter5797) ([92m↓19.61%[0m) [0.29% of initial]
[Iter 10060/20000] Loss: 0.0003177 (Best: 0.0002503 @iter9784) ([92m↓10.53%[0m) [0.13% of initial]
[Iter 10070/20000] Loss: 0.0002839 (Best: 0.0002503 @iter9784) ([92m↓10.65%[0m) [0.11% of initial]
[Iter 10080/20000] Loss: 0.0002784 (Best: 0.0002473 @iter10078) ([92m↓1.93%[0m) [0.11% of initial]
[Iter 7540/20000] Loss: 0.0005637 (Best: 0.0004476 @iter5797) ([92m↓22.25%[0m) [0.22% of initial]
[Iter 10090/20000] Loss: 0.0002606 (Best: 0.0002432 @iter10087) ([92m↓6.38%[0m) [0.10% of initial]
Iter:10099, L1 loss=0.0003194, Total loss=0.0002668, Time:78
[Iter 10100/20000] Loss: 0.0002648 (Best: 0.0002432 @iter10087) ([91m↑1.58%[0m) [0.11% of initial]
[Iter 7550/20000] Loss: 0.0005577 (Best: 0.0004476 @iter5797) ([92m↓1.08%[0m) [0.22% of initial]
[Iter 10110/20000] Loss: 0.0003190 (Best: 0.0002432 @iter10087) ([91m↑20.49%[0m) [0.13% of initial]
[Iter 10120/20000] Loss: 0.0003099 (Best: 0.0002432 @iter10087) ([92m↓2.87%[0m) [0.12% of initial]
[Iter 10130/20000] Loss: 0.0003303 (Best: 0.0002432 @iter10087) ([91m↑6.58%[0m) [0.13% of initial]
[Iter 7560/20000] Loss: 0.0005496 (Best: 0.0004476 @iter5797) ([92m↓1.45%[0m) [0.22% of initial]
[Iter 10140/20000] Loss: 0.0003291 (Best: 0.0002432 @iter10087) ([92m↓0.34%[0m) [0.13% of initial]
[Iter 10150/20000] Loss: 0.0002979 (Best: 0.0002432 @iter10087) ([92m↓9.49%[0m) [0.12% of initial]
[Iter 7570/20000] Loss: 0.0005676 (Best: 0.0004476 @iter5797) ([91m↑3.28%[0m) [0.23% of initial]
[Iter 10160/20000] Loss: 0.0002996 (Best: 0.0002432 @iter10087) ([91m↑0.59%[0m) [0.12% of initial]
[Iter 10170/20000] Loss: 0.0002724 (Best: 0.0002432 @iter10087) ([92m↓9.11%[0m) [0.11% of initial]
[Iter 10180/20000] Loss: 0.0003113 (Best: 0.0002393 @iter10171) ([91m↑14.28%[0m) [0.12% of initial]
[Iter 7580/20000] Loss: 0.0005732 (Best: 0.0004476 @iter5797) ([91m↑0.98%[0m) [0.23% of initial]
[Iter 10190/20000] Loss: 0.0003092 (Best: 0.0002381 @iter10186) ([92m↓0.66%[0m) [0.12% of initial]
Iter:10199, L1 loss=0.0003069, Total loss=0.00027, Time:71
[Iter 10200/20000] Loss: 0.0002994 (Best: 0.0002381 @iter10186) ([92m↓3.19%[0m) [0.12% of initial]
[Iter 7590/20000] Loss: 0.0006059 (Best: 0.0004476 @iter5797) ([91m↑5.71%[0m) [0.24% of initial]
[Iter 10210/20000] Loss: 0.0002842 (Best: 0.0002381 @iter10186) ([92m↓5.07%[0m) [0.11% of initial]
[Iter 10220/20000] Loss: 0.0002909 (Best: 0.0002381 @iter10186) ([91m↑2.38%[0m) [0.12% of initial]
Iter:7599, L1 loss=0.0005906, Total loss=0.0005452, Time:104
[Iter 10230/20000] Loss: 0.0002610 (Best: 0.0002381 @iter10186) ([92m↓10.30%[0m) [0.10% of initial]
[Iter 7600/20000] Loss: 0.0005506 (Best: 0.0004476 @iter5797) ([92m↓9.13%[0m) [0.22% of initial]
[Iter 10240/20000] Loss: 0.0002521 (Best: 0.0002315 @iter10240) ([92m↓3.41%[0m) [0.10% of initial]
[Iter 10250/20000] Loss: 0.0003720 (Best: 0.0002315 @iter10240) ([91m↑47.59%[0m) [0.15% of initial]
[Iter 10260/20000] Loss: 0.0003536 (Best: 0.0002315 @iter10240) ([92m↓4.95%[0m) [0.14% of initial]
[Iter 7610/20000] Loss: 0.0011576 (Best: 0.0004476 @iter5797) ([91m↑110.26%[0m) [0.46% of initial]
[Iter 10270/20000] Loss: 0.0003050 (Best: 0.0002315 @iter10240) ([92m↓13.75%[0m) [0.12% of initial]
[Iter 10280/20000] Loss: 0.0003368 (Best: 0.0002315 @iter10240) ([91m↑10.44%[0m) [0.13% of initial]
[Iter 7620/20000] Loss: 0.0008876 (Best: 0.0004476 @iter5797) ([92m↓23.33%[0m) [0.35% of initial]
[Iter 10290/20000] Loss: 0.0004229 (Best: 0.0002315 @iter10240) ([91m↑25.56%[0m) [0.17% of initial]
Iter:10299, L1 loss=0.0004204, Total loss=0.0003253, Time:77
[Iter 10300/20000] Loss: 0.0003141 (Best: 0.0002315 @iter10240) ([92m↓25.73%[0m) [0.12% of initial]
[Iter 10310/20000] Loss: 0.0003146 (Best: 0.0002315 @iter10240) ([91m↑0.17%[0m) [0.13% of initial]
[Iter 7630/20000] Loss: 0.0007712 (Best: 0.0004476 @iter5797) ([92m↓13.11%[0m) [0.31% of initial]
[Iter 10320/20000] Loss: 0.0003623 (Best: 0.0002315 @iter10240) ([91m↑15.14%[0m) [0.14% of initial]
[Iter 10330/20000] Loss: 0.0003039 (Best: 0.0002315 @iter10240) ([92m↓16.12%[0m) [0.12% of initial]
[Iter 7640/20000] Loss: 0.0006571 (Best: 0.0004476 @iter5797) ([92m↓14.79%[0m) [0.26% of initial]
[Iter 10340/20000] Loss: 0.0003051 (Best: 0.0002315 @iter10240) ([91m↑0.41%[0m) [0.12% of initial]
[Iter 10350/20000] Loss: 0.0002898 (Best: 0.0002315 @iter10240) ([92m↓5.02%[0m) [0.12% of initial]
[Iter 10360/20000] Loss: 0.0002743 (Best: 0.0002315 @iter10240) ([92m↓5.34%[0m) [0.11% of initial]
[Iter 7650/20000] Loss: 0.0006042 (Best: 0.0004476 @iter5797) ([92m↓8.05%[0m) [0.24% of initial]
[Iter 10370/20000] Loss: 0.0002636 (Best: 0.0002315 @iter10240) ([92m↓3.92%[0m) [0.10% of initial]
[Iter 10380/20000] Loss: 0.0002991 (Best: 0.0002315 @iter10240) ([91m↑13.47%[0m) [0.12% of initial]
[Iter 7660/20000] Loss: 0.0005291 (Best: 0.0004476 @iter5797) ([92m↓12.44%[0m) [0.21% of initial]
[Iter 10390/20000] Loss: 0.0003073 (Best: 0.0002315 @iter10240) ([91m↑2.75%[0m) [0.12% of initial]
Iter:10399, L1 loss=0.0002867, Total loss=0.0002492, Time:68
[Iter 10400/20000] Loss: 0.0002714 (Best: 0.0002315 @iter10240) ([92m↓11.68%[0m) [0.11% of initial]
[Iter 10410/20000] Loss: 0.0002913 (Best: 0.0002315 @iter10240) ([91m↑7.31%[0m) [0.12% of initial]
[Iter 7670/20000] Loss: 0.0005118 (Best: 0.0004476 @iter5797) ([92m↓3.27%[0m) [0.20% of initial]
[Iter 10420/20000] Loss: 0.0002936 (Best: 0.0002315 @iter10240) ([91m↑0.81%[0m) [0.12% of initial]
[Iter 10430/20000] Loss: 0.0002549 (Best: 0.0002315 @iter10240) ([92m↓13.19%[0m) [0.10% of initial]
[Iter 7680/20000] Loss: 0.0005449 (Best: 0.0004476 @iter5797) ([91m↑6.47%[0m) [0.22% of initial]
[Iter 10440/20000] Loss: 0.0002791 (Best: 0.0002315 @iter10240) ([91m↑9.48%[0m) [0.11% of initial]
[Iter 10450/20000] Loss: 0.0003128 (Best: 0.0002315 @iter10240) ([91m↑12.09%[0m) [0.12% of initial]
[Iter 10460/20000] Loss: 0.0003015 (Best: 0.0002315 @iter10240) ([92m↓3.60%[0m) [0.12% of initial]
[Iter 7690/20000] Loss: 0.0005225 (Best: 0.0004476 @iter5797) ([92m↓4.11%[0m) [0.21% of initial]
[Iter 10470/20000] Loss: 0.0002903 (Best: 0.0002315 @iter10240) ([92m↓3.72%[0m) [0.12% of initial]
[Iter 10480/20000] Loss: 0.0002800 (Best: 0.0002315 @iter10240) ([92m↓3.55%[0m) [0.11% of initial]
Iter:7699, L1 loss=0.0005702, Total loss=0.0005136, Time:119
[Iter 7700/20000] Loss: 0.0005215 (Best: 0.0004476 @iter5797) ([92m↓0.20%[0m) [0.21% of initial]
[Iter 10490/20000] Loss: 0.0002488 (Best: 0.0002315 @iter10240) ([92m↓11.14%[0m) [0.10% of initial]
Iter:10499, L1 loss=0.0002802, Total loss=0.0002433, Time:60
[Iter 10500/20000] Loss: 0.0002712 (Best: 0.0002315 @iter10240) ([91m↑8.98%[0m) [0.11% of initial]
[Iter 7710/20000] Loss: 0.0005022 (Best: 0.0004476 @iter5797) ([92m↓3.70%[0m) [0.20% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 10500
Pruning 17 points (0.0%) from gaussian1 at iteration 10500
[Iter 10510/20000] Loss: 0.0007888 (Best: 0.0002315 @iter10240) ([91m↑190.86%[0m) [0.31% of initial]
[Iter 7720/20000] Loss: 0.0005066 (Best: 0.0004462 @iter7714) ([91m↑0.88%[0m) [0.20% of initial]
[Iter 10520/20000] Loss: 0.0004614 (Best: 0.0002315 @iter10240) ([92m↓41.51%[0m) [0.18% of initial]
[Iter 10530/20000] Loss: 0.0003713 (Best: 0.0002315 @iter10240) ([92m↓19.54%[0m) [0.15% of initial]
[Iter 10540/20000] Loss: 0.0003069 (Best: 0.0002315 @iter10240) ([92m↓17.34%[0m) [0.12% of initial]
[Iter 7730/20000] Loss: 0.0005063 (Best: 0.0004462 @iter7714) ([92m↓0.06%[0m) [0.20% of initial]
[Iter 10550/20000] Loss: 0.0002903 (Best: 0.0002315 @iter10240) ([92m↓5.39%[0m) [0.12% of initial]
[Iter 10560/20000] Loss: 0.0003045 (Best: 0.0002315 @iter10240) ([91m↑4.88%[0m) [0.12% of initial]
[Iter 7740/20000] Loss: 0.0005083 (Best: 0.0004401 @iter7738) ([91m↑0.40%[0m) [0.20% of initial]
[Iter 10570/20000] Loss: 0.0002932 (Best: 0.0002315 @iter10240) ([92m↓3.72%[0m) [0.12% of initial]
[Iter 10580/20000] Loss: 0.0002726 (Best: 0.0002315 @iter10240) ([92m↓7.02%[0m) [0.11% of initial]
[Iter 10590/20000] Loss: 0.0002706 (Best: 0.0002315 @iter10240) ([92m↓0.72%[0m) [0.11% of initial]
[Iter 7750/20000] Loss: 0.0005459 (Best: 0.0004401 @iter7738) ([91m↑7.39%[0m) [0.22% of initial]
Iter:10599, L1 loss=0.0003495, Total loss=0.0003253, Time:69
[Iter 10600/20000] Loss: 0.0002754 (Best: 0.0002315 @iter10240) ([91m↑1.75%[0m) [0.11% of initial]
[Iter 10610/20000] Loss: 0.0002949 (Best: 0.0002315 @iter10240) ([91m↑7.10%[0m) [0.12% of initial]
[Iter 7760/20000] Loss: 0.0005848 (Best: 0.0004401 @iter7738) ([91m↑7.11%[0m) [0.23% of initial]
[Iter 10620/20000] Loss: 0.0003359 (Best: 0.0002315 @iter10240) ([91m↑13.90%[0m) [0.13% of initial]
[Iter 10630/20000] Loss: 0.0003757 (Best: 0.0002315 @iter10240) ([91m↑11.84%[0m) [0.15% of initial]
[Iter 10640/20000] Loss: 0.0003555 (Best: 0.0002315 @iter10240) ([92m↓5.37%[0m) [0.14% of initial]
[Iter 7770/20000] Loss: 0.0005720 (Best: 0.0004401 @iter7738) ([92m↓2.19%[0m) [0.23% of initial]
[Iter 10650/20000] Loss: 0.0003267 (Best: 0.0002315 @iter10240) ([92m↓8.10%[0m) [0.13% of initial]
[Iter 10660/20000] Loss: 0.0003514 (Best: 0.0002315 @iter10240) ([91m↑7.57%[0m) [0.14% of initial]
[Iter 7780/20000] Loss: 0.0005659 (Best: 0.0004401 @iter7738) ([92m↓1.06%[0m) [0.22% of initial]
[Iter 10670/20000] Loss: 0.0003148 (Best: 0.0002315 @iter10240) ([92m↓10.44%[0m) [0.13% of initial]
[Iter 10680/20000] Loss: 0.0002935 (Best: 0.0002315 @iter10240) ([92m↓6.76%[0m) [0.12% of initial]
[Iter 10690/20000] Loss: 0.0003163 (Best: 0.0002315 @iter10240) ([91m↑7.76%[0m) [0.13% of initial]
[Iter 7790/20000] Loss: 0.0005592 (Best: 0.0004401 @iter7738) ([92m↓1.18%[0m) [0.22% of initial]
Iter:10699, L1 loss=0.0003364, Total loss=0.000291, Time:75
[Iter 10700/20000] Loss: 0.0002844 (Best: 0.0002315 @iter10240) ([92m↓10.08%[0m) [0.11% of initial]
[Iter 10710/20000] Loss: 0.0003549 (Best: 0.0002315 @iter10240) ([91m↑24.80%[0m) [0.14% of initial]
Iter:7799, L1 loss=0.0005697, Total loss=0.0005174, Time:109
[Iter 7800/20000] Loss: 0.0005712 (Best: 0.0004401 @iter7738) ([91m↑2.15%[0m) [0.23% of initial]
[Iter 10720/20000] Loss: 0.0003199 (Best: 0.0002315 @iter10240) ([92m↓9.86%[0m) [0.13% of initial]
[Iter 10730/20000] Loss: 0.0002855 (Best: 0.0002315 @iter10240) ([92m↓10.76%[0m) [0.11% of initial]
[Iter 10740/20000] Loss: 0.0003054 (Best: 0.0002315 @iter10240) ([91m↑6.97%[0m) [0.12% of initial]
[Iter 7810/20000] Loss: 0.0010354 (Best: 0.0004401 @iter7738) ([91m↑81.26%[0m) [0.41% of initial]
[Iter 10750/20000] Loss: 0.0002822 (Best: 0.0002315 @iter10240) ([92m↓7.59%[0m) [0.11% of initial]
[Iter 10760/20000] Loss: 0.0002977 (Best: 0.0002315 @iter10240) ([91m↑5.49%[0m) [0.12% of initial]
[Iter 10770/20000] Loss: 0.0003114 (Best: 0.0002315 @iter10240) ([91m↑4.60%[0m) [0.12% of initial]
[Iter 7820/20000] Loss: 0.0008559 (Best: 0.0004401 @iter7738) ([92m↓17.33%[0m) [0.34% of initial]
[Iter 10780/20000] Loss: 0.0002675 (Best: 0.0002315 @iter10240) ([92m↓14.11%[0m) [0.11% of initial]
[Iter 10790/20000] Loss: 0.0002519 (Best: 0.0002305 @iter10789) ([92m↓5.81%[0m) [0.10% of initial]
[Iter 7830/20000] Loss: 0.0007738 (Best: 0.0004401 @iter7738) ([92m↓9.60%[0m) [0.31% of initial]
Iter:10799, L1 loss=0.0003813, Total loss=0.0003132, Time:69
[Iter 10800/20000] Loss: 0.0003086 (Best: 0.0002305 @iter10789) ([91m↑22.51%[0m) [0.12% of initial]
[Iter 10810/20000] Loss: 0.0002729 (Best: 0.0002305 @iter10789) ([92m↓11.59%[0m) [0.11% of initial]
[Iter 10820/20000] Loss: 0.0002581 (Best: 0.0002257 @iter10813) ([92m↓5.41%[0m) [0.10% of initial]
[Iter 7840/20000] Loss: 0.0006908 (Best: 0.0004401 @iter7738) ([92m↓10.73%[0m) [0.27% of initial]
[Iter 10830/20000] Loss: 0.0002954 (Best: 0.0002257 @iter10813) ([91m↑14.46%[0m) [0.12% of initial]
[Iter 10840/20000] Loss: 0.0002774 (Best: 0.0002257 @iter10813) ([92m↓6.10%[0m) [0.11% of initial]
[Iter 7850/20000] Loss: 0.0006943 (Best: 0.0004401 @iter7738) ([91m↑0.51%[0m) [0.28% of initial]
[Iter 10850/20000] Loss: 0.0002501 (Best: 0.0002257 @iter10813) ([92m↓9.84%[0m) [0.10% of initial]
[Iter 10860/20000] Loss: 0.0002667 (Best: 0.0002257 @iter10813) ([91m↑6.62%[0m) [0.11% of initial]
[Iter 10870/20000] Loss: 0.0002759 (Best: 0.0002257 @iter10813) ([91m↑3.46%[0m) [0.11% of initial]
[Iter 7860/20000] Loss: 0.0006632 (Best: 0.0004401 @iter7738) ([92m↓4.48%[0m) [0.26% of initial]
[Iter 10880/20000] Loss: 0.0002825 (Best: 0.0002257 @iter10813) ([91m↑2.40%[0m) [0.11% of initial]
[Iter 10890/20000] Loss: 0.0002670 (Best: 0.0002257 @iter10813) ([92m↓5.50%[0m) [0.11% of initial]
[Iter 7870/20000] Loss: 0.0006157 (Best: 0.0004401 @iter7738) ([92m↓7.17%[0m) [0.24% of initial]
Iter:10899, L1 loss=0.0002755, Total loss=0.0002308, Time:74
[Iter 10900/20000] Loss: 0.0002485 (Best: 0.0002239 @iter10894) ([92m↓6.93%[0m) [0.10% of initial]
[Iter 10910/20000] Loss: 0.0002480 (Best: 0.0002176 @iter10903) ([92m↓0.20%[0m) [0.10% of initial]
[Iter 10920/20000] Loss: 0.0002555 (Best: 0.0002118 @iter10912) ([91m↑3.03%[0m) [0.10% of initial]
[Iter 7880/20000] Loss: 0.0005584 (Best: 0.0004401 @iter7738) ([92m↓9.30%[0m) [0.22% of initial]
[Iter 10930/20000] Loss: 0.0002512 (Best: 0.0002118 @iter10912) ([92m↓1.70%[0m) [0.10% of initial]
[Iter 10940/20000] Loss: 0.0002532 (Best: 0.0002118 @iter10912) ([91m↑0.81%[0m) [0.10% of initial]
[Iter 7890/20000] Loss: 0.0006242 (Best: 0.0004401 @iter7738) ([91m↑11.79%[0m) [0.25% of initial]
[Iter 10950/20000] Loss: 0.0002476 (Best: 0.0002118 @iter10912) ([92m↓2.19%[0m) [0.10% of initial]
[Iter 10960/20000] Loss: 0.0002513 (Best: 0.0002118 @iter10912) ([91m↑1.48%[0m) [0.10% of initial]
Iter:7899, L1 loss=0.000611, Total loss=0.0005739, Time:105
[Iter 10970/20000] Loss: 0.0002749 (Best: 0.0002118 @iter10912) ([91m↑9.40%[0m) [0.11% of initial]
[Iter 7900/20000] Loss: 0.0005656 (Best: 0.0004401 @iter7738) ([92m↓9.39%[0m) [0.22% of initial]
[Iter 10980/20000] Loss: 0.0002810 (Best: 0.0002118 @iter10912) ([91m↑2.20%[0m) [0.11% of initial]
[Iter 10990/20000] Loss: 0.0002960 (Best: 0.0002118 @iter10912) ([91m↑5.36%[0m) [0.12% of initial]
[Iter 7910/20000] Loss: 0.0005706 (Best: 0.0004401 @iter7738) ([91m↑0.88%[0m) [0.23% of initial]
Iter:10999, L1 loss=0.0002789, Total loss=0.0002516, Time:59
[Iter 11000/20000] Loss: 0.0002865 (Best: 0.0002118 @iter10912) ([92m↓3.21%[0m) [0.11% of initial]
Pruning 13 points (0.0%) from gaussian0 at iteration 11000
Pruning 7 points (0.0%) from gaussian1 at iteration 11000
[Iter 7920/20000] Loss: 0.0006602 (Best: 0.0004401 @iter7738) ([91m↑15.70%[0m) [0.26% of initial]
[Iter 11010/20000] Loss: 0.0006303 (Best: 0.0002118 @iter10912) ([91m↑119.97%[0m) [0.25% of initial]
[Iter 11020/20000] Loss: 0.0004332 (Best: 0.0002118 @iter10912) ([92m↓31.27%[0m) [0.17% of initial]
[Iter 7930/20000] Loss: 0.0005645 (Best: 0.0004401 @iter7738) ([92m↓14.49%[0m) [0.22% of initial]
[Iter 11030/20000] Loss: 0.0003245 (Best: 0.0002118 @iter10912) ([92m↓25.10%[0m) [0.13% of initial]
[Iter 11040/20000] Loss: 0.0002649 (Best: 0.0002118 @iter10912) ([92m↓18.36%[0m) [0.11% of initial]
[Iter 11050/20000] Loss: 0.0002882 (Best: 0.0002118 @iter10912) ([91m↑8.79%[0m) [0.11% of initial]
[Iter 7940/20000] Loss: 0.0005256 (Best: 0.0004401 @iter7738) ([92m↓6.90%[0m) [0.21% of initial]
[Iter 11060/20000] Loss: 0.0002742 (Best: 0.0002118 @iter10912) ([92m↓4.86%[0m) [0.11% of initial]
[Iter 11070/20000] Loss: 0.0002722 (Best: 0.0002118 @iter10912) ([92m↓0.73%[0m) [0.11% of initial]
[Iter 7950/20000] Loss: 0.0005087 (Best: 0.0004401 @iter7738) ([92m↓3.22%[0m) [0.20% of initial]
[Iter 11080/20000] Loss: 0.0002504 (Best: 0.0002118 @iter10912) ([92m↓8.03%[0m) [0.10% of initial]
[Iter 11090/20000] Loss: 0.0002331 (Best: 0.0002118 @iter10912) ([92m↓6.91%[0m) [0.09% of initial]
Iter:11099, L1 loss=0.0002789, Total loss=0.0002462, Time:71
[Iter 11100/20000] Loss: 0.0002507 (Best: 0.0002118 @iter10912) ([91m↑7.55%[0m) [0.10% of initial]
[Iter 7960/20000] Loss: 0.0005688 (Best: 0.0004401 @iter7738) ([91m↑11.82%[0m) [0.23% of initial]
[Iter 11110/20000] Loss: 0.0003137 (Best: 0.0002118 @iter10912) ([91m↑25.14%[0m) [0.12% of initial]
[Iter 11120/20000] Loss: 0.0002837 (Best: 0.0002118 @iter10912) ([92m↓9.58%[0m) [0.11% of initial]
[Iter 7970/20000] Loss: 0.0005620 (Best: 0.0004401 @iter7738) ([92m↓1.19%[0m) [0.22% of initial]
[Iter 11130/20000] Loss: 0.0002716 (Best: 0.0002118 @iter10912) ([92m↓4.24%[0m) [0.11% of initial]
[Iter 11140/20000] Loss: 0.0002708 (Best: 0.0002118 @iter10912) ([92m↓0.29%[0m) [0.11% of initial]
[Iter 11150/20000] Loss: 0.0002675 (Best: 0.0002118 @iter10912) ([92m↓1.24%[0m) [0.11% of initial]
[Iter 7980/20000] Loss: 0.0005717 (Best: 0.0004401 @iter7738) ([91m↑1.73%[0m) [0.23% of initial]
[Iter 11160/20000] Loss: 0.0002495 (Best: 0.0002118 @iter10912) ([92m↓6.74%[0m) [0.10% of initial]
[Iter 11170/20000] Loss: 0.0002479 (Best: 0.0002095 @iter11168) ([92m↓0.63%[0m) [0.10% of initial]
[Iter 7990/20000] Loss: 0.0005295 (Best: 0.0004401 @iter7738) ([92m↓7.38%[0m) [0.21% of initial]
[Iter 11180/20000] Loss: 0.0002381 (Best: 0.0002095 @iter11168) ([92m↓3.96%[0m) [0.09% of initial]
[Iter 11190/20000] Loss: 0.0002522 (Best: 0.0002095 @iter11168) ([91m↑5.93%[0m) [0.10% of initial]
Iter:11199, L1 loss=0.0002979, Total loss=0.0002619, Time:66
Iter:7999, L1 loss=0.0005669, Total loss=0.0005261, Time:104
[Iter 11200/20000] Loss: 0.0002345 (Best: 0.0002095 @iter11168) ([92m↓7.03%[0m) [0.09% of initial]
[Iter 8000/20000] Loss: 0.0005230 (Best: 0.0004401 @iter7738) ([92m↓1.23%[0m) [0.21% of initial]
[Iter 11210/20000] Loss: 0.0002606 (Best: 0.0002095 @iter11168) ([91m↑11.13%[0m) [0.10% of initial]
Pruning 49 points (0.0%) from gaussian0 at iteration 8000
Pruning 59 points (0.0%) from gaussian1 at iteration 8000
[Iter 11220/20000] Loss: 0.0002544 (Best: 0.0002095 @iter11168) ([92m↓2.37%[0m) [0.10% of initial]
[Iter 11230/20000] Loss: 0.0002365 (Best: 0.0002095 @iter11168) ([92m↓7.02%[0m) [0.09% of initial]
[Iter 8010/20000] Loss: 0.0009688 (Best: 0.0004401 @iter7738) ([91m↑85.23%[0m) [0.38% of initial]
[Iter 11240/20000] Loss: 0.0002359 (Best: 0.0002095 @iter11168) ([92m↓0.26%[0m) [0.09% of initial]
[Iter 8020/20000] Loss: 0.0007088 (Best: 0.0004401 @iter7738) ([92m↓26.84%[0m) [0.28% of initial]
[Iter 11250/20000] Loss: 0.0002332 (Best: 0.0002095 @iter11168) ([92m↓1.16%[0m) [0.09% of initial]
[Iter 8030/20000] Loss: 0.0006127 (Best: 0.0004401 @iter7738) ([92m↓13.56%[0m) [0.24% of initial]
[Iter 11260/20000] Loss: 0.0002710 (Best: 0.0002095 @iter11168) ([91m↑16.20%[0m) [0.11% of initial]
[Iter 11270/20000] Loss: 0.0002570 (Best: 0.0002095 @iter11168) ([92m↓5.13%[0m) [0.10% of initial]
[Iter 8040/20000] Loss: 0.0005996 (Best: 0.0004401 @iter7738) ([92m↓2.13%[0m) [0.24% of initial]
[Iter 11280/20000] Loss: 0.0003266 (Best: 0.0002095 @iter11168) ([91m↑27.06%[0m) [0.13% of initial]
[Iter 8050/20000] Loss: 0.0005405 (Best: 0.0004401 @iter7738) ([92m↓9.85%[0m) [0.21% of initial]
[Iter 11290/20000] Loss: 0.0002585 (Best: 0.0002095 @iter11168) ([92m↓20.85%[0m) [0.10% of initial]
[Iter 8060/20000] Loss: 0.0004967 (Best: 0.0004401 @iter7738) ([92m↓8.10%[0m) [0.20% of initial]
Iter:11299, L1 loss=0.0003678, Total loss=0.0003227, Time:78
[Iter 11300/20000] Loss: 0.0003112 (Best: 0.0002095 @iter11168) ([91m↑20.40%[0m) [0.12% of initial]
[Iter 11310/20000] Loss: 0.0003333 (Best: 0.0002095 @iter11168) ([91m↑7.10%[0m) [0.13% of initial]
[Iter 8070/20000] Loss: 0.0005010 (Best: 0.0004401 @iter7738) ([91m↑0.86%[0m) [0.20% of initial]
[Iter 11320/20000] Loss: 0.0003849 (Best: 0.0002095 @iter11168) ([91m↑15.47%[0m) [0.15% of initial]
[Iter 8080/20000] Loss: 0.0004925 (Best: 0.0004375 @iter8074) ([92m↓1.71%[0m) [0.20% of initial]
[Iter 11330/20000] Loss: 0.0003630 (Best: 0.0002095 @iter11168) ([92m↓5.69%[0m) [0.14% of initial]
[Iter 8090/20000] Loss: 0.0004692 (Best: 0.0004375 @iter8074) ([92m↓4.72%[0m) [0.19% of initial]
[Iter 11340/20000] Loss: 0.0003084 (Best: 0.0002095 @iter11168) ([92m↓15.06%[0m) [0.12% of initial]
Iter:8099, L1 loss=0.0005395, Total loss=0.000493, Time:117
[Iter 11350/20000] Loss: 0.0002666 (Best: 0.0002095 @iter11168) ([92m↓13.53%[0m) [0.11% of initial]
[Iter 8100/20000] Loss: 0.0005038 (Best: 0.0004246 @iter8092) ([91m↑7.37%[0m) [0.20% of initial]
[Iter 11360/20000] Loss: 0.0002587 (Best: 0.0002095 @iter11168) ([92m↓2.98%[0m) [0.10% of initial]
[Iter 8110/20000] Loss: 0.0005071 (Best: 0.0004246 @iter8092) ([91m↑0.66%[0m) [0.20% of initial]
[Iter 11370/20000] Loss: 0.0002511 (Best: 0.0002095 @iter11168) ([92m↓2.94%[0m) [0.10% of initial]
[Iter 8120/20000] Loss: 0.0004877 (Best: 0.0004246 @iter8092) ([92m↓3.83%[0m) [0.19% of initial]
[Iter 11380/20000] Loss: 0.0002494 (Best: 0.0002095 @iter11168) ([92m↓0.65%[0m) [0.10% of initial]
[Iter 11390/20000] Loss: 0.0003002 (Best: 0.0002095 @iter11168) ([91m↑20.36%[0m) [0.12% of initial]
[Iter 8130/20000] Loss: 0.0005379 (Best: 0.0004246 @iter8092) ([91m↑10.29%[0m) [0.21% of initial]
Iter:11399, L1 loss=0.0002993, Total loss=0.0002638, Time:69
[Iter 11400/20000] Loss: 0.0002706 (Best: 0.0002095 @iter11168) ([92m↓9.87%[0m) [0.11% of initial]
[Iter 8140/20000] Loss: 0.0005176 (Best: 0.0004246 @iter8092) ([92m↓3.78%[0m) [0.21% of initial]
[Iter 11410/20000] Loss: 0.0002502 (Best: 0.0002095 @iter11168) ([92m↓7.56%[0m) [0.10% of initial]
[Iter 8150/20000] Loss: 0.0005268 (Best: 0.0004246 @iter8092) ([91m↑1.79%[0m) [0.21% of initial]
[Iter 11420/20000] Loss: 0.0002658 (Best: 0.0002095 @iter11168) ([91m↑6.26%[0m) [0.11% of initial]
[Iter 11430/20000] Loss: 0.0002664 (Best: 0.0002095 @iter11168) ([91m↑0.20%[0m) [0.11% of initial]
[Iter 8160/20000] Loss: 0.0005246 (Best: 0.0004246 @iter8092) ([92m↓0.42%[0m) [0.21% of initial]
[Iter 11440/20000] Loss: 0.0003370 (Best: 0.0002095 @iter11168) ([91m↑26.53%[0m) [0.13% of initial]
[Iter 8170/20000] Loss: 0.0005278 (Best: 0.0004246 @iter8092) ([91m↑0.61%[0m) [0.21% of initial]
[Iter 11450/20000] Loss: 0.0003471 (Best: 0.0002095 @iter11168) ([91m↑3.00%[0m) [0.14% of initial]
[Iter 8180/20000] Loss: 0.0005424 (Best: 0.0004246 @iter8092) ([91m↑2.76%[0m) [0.22% of initial]
[Iter 11460/20000] Loss: 0.0002778 (Best: 0.0002095 @iter11168) ([92m↓19.97%[0m) [0.11% of initial]
[Iter 11470/20000] Loss: 0.0002539 (Best: 0.0002095 @iter11168) ([92m↓8.60%[0m) [0.10% of initial]
[Iter 8190/20000] Loss: 0.0005703 (Best: 0.0004246 @iter8092) ([91m↑5.14%[0m) [0.23% of initial]
[Iter 11480/20000] Loss: 0.0002565 (Best: 0.0002095 @iter11168) ([91m↑1.01%[0m) [0.10% of initial]
Iter:8199, L1 loss=0.0006073, Total loss=0.0005562, Time:103
[Iter 8200/20000] Loss: 0.0005430 (Best: 0.0004246 @iter8092) ([92m↓4.79%[0m) [0.22% of initial]
[Iter 11490/20000] Loss: 0.0002332 (Best: 0.0002095 @iter11168) ([92m↓9.09%[0m) [0.09% of initial]
[Iter 8210/20000] Loss: 0.0005407 (Best: 0.0004246 @iter8092) ([92m↓0.42%[0m) [0.21% of initial]
Iter:11499, L1 loss=0.0002477, Total loss=0.0002109, Time:69
[Iter 11500/20000] Loss: 0.0002263 (Best: 0.0002095 @iter11168) ([92m↓2.93%[0m) [0.09% of initial]
[Iter 8220/20000] Loss: 0.0005432 (Best: 0.0004246 @iter8092) ([91m↑0.47%[0m) [0.22% of initial]
Pruning 18 points (0.0%) from gaussian0 at iteration 11500
Pruning 12 points (0.0%) from gaussian1 at iteration 11500
[Iter 8230/20000] Loss: 0.0005304 (Best: 0.0004246 @iter8092) ([92m↓2.35%[0m) [0.21% of initial]
[Iter 11510/20000] Loss: 0.0004858 (Best: 0.0002038 @iter11501) ([91m↑114.62%[0m) [0.19% of initial]
[Iter 8240/20000] Loss: 0.0005129 (Best: 0.0004246 @iter8092) ([92m↓3.30%[0m) [0.20% of initial]
[Iter 11520/20000] Loss: 0.0003772 (Best: 0.0002038 @iter11501) ([92m↓22.34%[0m) [0.15% of initial]
[Iter 11530/20000] Loss: 0.0003157 (Best: 0.0002038 @iter11501) ([92m↓16.31%[0m) [0.13% of initial]
[Iter 8250/20000] Loss: 0.0005507 (Best: 0.0004246 @iter8092) ([91m↑7.36%[0m) [0.22% of initial]
[Iter 11540/20000] Loss: 0.0002825 (Best: 0.0002038 @iter11501) ([92m↓10.53%[0m) [0.11% of initial]
[Iter 8260/20000] Loss: 0.0005391 (Best: 0.0004246 @iter8092) ([92m↓2.09%[0m) [0.21% of initial]
[Iter 11550/20000] Loss: 0.0002788 (Best: 0.0002038 @iter11501) ([92m↓1.31%[0m) [0.11% of initial]
[Iter 8270/20000] Loss: 0.0005645 (Best: 0.0004246 @iter8092) ([91m↑4.71%[0m) [0.22% of initial]
[Iter 11560/20000] Loss: 0.0002757 (Best: 0.0002038 @iter11501) ([92m↓1.09%[0m) [0.11% of initial]
[Iter 8280/20000] Loss: 0.0005400 (Best: 0.0004246 @iter8092) ([92m↓4.34%[0m) [0.21% of initial]
[Iter 11570/20000] Loss: 0.0002728 (Best: 0.0002038 @iter11501) ([92m↓1.07%[0m) [0.11% of initial]
[Iter 11580/20000] Loss: 0.0002356 (Best: 0.0002038 @iter11501) ([92m↓13.61%[0m) [0.09% of initial]
[Iter 8290/20000] Loss: 0.0005496 (Best: 0.0004246 @iter8092) ([91m↑1.78%[0m) [0.22% of initial]
[Iter 11590/20000] Loss: 0.0002265 (Best: 0.0002037 @iter11584) ([92m↓3.88%[0m) [0.09% of initial]
Iter:8299, L1 loss=0.0005191, Total loss=0.0004686, Time:107
[Iter 8300/20000] Loss: 0.0005157 (Best: 0.0004246 @iter8092) ([92m↓6.17%[0m) [0.20% of initial]
Iter:11599, L1 loss=0.0002511, Total loss=0.0002163, Time:90
[Iter 11600/20000] Loss: 0.0002244 (Best: 0.0001958 @iter11593) ([92m↓0.93%[0m) [0.09% of initial]
[Iter 8310/20000] Loss: 0.0005083 (Best: 0.0004246 @iter8092) ([92m↓1.43%[0m) [0.20% of initial]
[Iter 11610/20000] Loss: 0.0002284 (Best: 0.0001958 @iter11593) ([91m↑1.77%[0m) [0.09% of initial]
[Iter 11620/20000] Loss: 0.0002246 (Best: 0.0001958 @iter11593) ([92m↓1.65%[0m) [0.09% of initial]
[Iter 8320/20000] Loss: 0.0004744 (Best: 0.0004246 @iter8092) ([92m↓6.67%[0m) [0.19% of initial]
[Iter 11630/20000] Loss: 0.0002371 (Best: 0.0001958 @iter11593) ([91m↑5.55%[0m) [0.09% of initial]
[Iter 8330/20000] Loss: 0.0004724 (Best: 0.0004246 @iter8092) ([92m↓0.43%[0m) [0.19% of initial]
[Iter 11640/20000] Loss: 0.0002524 (Best: 0.0001958 @iter11593) ([91m↑6.49%[0m) [0.10% of initial]
[Iter 8340/20000] Loss: 0.0004999 (Best: 0.0004246 @iter8092) ([91m↑5.82%[0m) [0.20% of initial]
[Iter 11650/20000] Loss: 0.0002703 (Best: 0.0001958 @iter11593) ([91m↑7.06%[0m) [0.11% of initial]
[Iter 11660/20000] Loss: 0.0002785 (Best: 0.0001958 @iter11593) ([91m↑3.05%[0m) [0.11% of initial]
[Iter 8350/20000] Loss: 0.0004560 (Best: 0.0004246 @iter8092) ([92m↓8.77%[0m) [0.18% of initial]
[Iter 11670/20000] Loss: 0.0002621 (Best: 0.0001958 @iter11593) ([92m↓5.89%[0m) [0.10% of initial]
[Iter 8360/20000] Loss: 0.0004578 (Best: 0.0004231 @iter8359) ([91m↑0.38%[0m) [0.18% of initial]
[Iter 11680/20000] Loss: 0.0002499 (Best: 0.0001958 @iter11593) ([92m↓4.64%[0m) [0.10% of initial]
[Iter 8370/20000] Loss: 0.0004528 (Best: 0.0004231 @iter8359) ([92m↓1.09%[0m) [0.18% of initial]
[Iter 11690/20000] Loss: 0.0002600 (Best: 0.0001958 @iter11593) ([91m↑4.05%[0m) [0.10% of initial]
Iter:11699, L1 loss=0.0003032, Total loss=0.0002707, Time:75
[Iter 8380/20000] Loss: 0.0004888 (Best: 0.0004231 @iter8359) ([91m↑7.94%[0m) [0.19% of initial]
[Iter 11700/20000] Loss: 0.0002714 (Best: 0.0001958 @iter11593) ([91m↑4.37%[0m) [0.11% of initial]
[Iter 11710/20000] Loss: 0.0002506 (Best: 0.0001958 @iter11593) ([92m↓7.68%[0m) [0.10% of initial]
[Iter 8390/20000] Loss: 0.0004397 (Best: 0.0004231 @iter8359) ([92m↓10.03%[0m) [0.17% of initial]
[Iter 11720/20000] Loss: 0.0002543 (Best: 0.0001958 @iter11593) ([91m↑1.48%[0m) [0.10% of initial]
Iter:8399, L1 loss=0.0005011, Total loss=0.0004375, Time:102
[Iter 8400/20000] Loss: 0.0004752 (Best: 0.0004210 @iter8392) ([91m↑8.07%[0m) [0.19% of initial]
[Iter 11730/20000] Loss: 0.0002483 (Best: 0.0001958 @iter11593) ([92m↓2.36%[0m) [0.10% of initial]
[Iter 8410/20000] Loss: 0.0004555 (Best: 0.0004158 @iter8407) ([92m↓4.13%[0m) [0.18% of initial]
[Iter 11740/20000] Loss: 0.0002432 (Best: 0.0001958 @iter11593) ([92m↓2.06%[0m) [0.10% of initial]
[Iter 11750/20000] Loss: 0.0002283 (Best: 0.0001958 @iter11593) ([92m↓6.12%[0m) [0.09% of initial]
[Iter 8420/20000] Loss: 0.0004547 (Best: 0.0004158 @iter8407) ([92m↓0.20%[0m) [0.18% of initial]
[Iter 11760/20000] Loss: 0.0002342 (Best: 0.0001958 @iter11593) ([91m↑2.59%[0m) [0.09% of initial]
[Iter 8430/20000] Loss: 0.0004809 (Best: 0.0003979 @iter8425) ([91m↑5.76%[0m) [0.19% of initial]
[Iter 11770/20000] Loss: 0.0002410 (Best: 0.0001958 @iter11593) ([91m↑2.92%[0m) [0.10% of initial]
[Iter 8440/20000] Loss: 0.0004675 (Best: 0.0003979 @iter8425) ([92m↓2.78%[0m) [0.19% of initial]
[Iter 11780/20000] Loss: 0.0002541 (Best: 0.0001958 @iter11593) ([91m↑5.44%[0m) [0.10% of initial]
[Iter 11790/20000] Loss: 0.0002400 (Best: 0.0001958 @iter11593) ([92m↓5.57%[0m) [0.10% of initial]
[Iter 8450/20000] Loss: 0.0004943 (Best: 0.0003979 @iter8425) ([91m↑5.73%[0m) [0.20% of initial]
Iter:11799, L1 loss=0.0003275, Total loss=0.0002762, Time:66
[Iter 11800/20000] Loss: 0.0002698 (Best: 0.0001958 @iter11593) ([91m↑12.44%[0m) [0.11% of initial]
[Iter 8460/20000] Loss: 0.0004790 (Best: 0.0003979 @iter8425) ([92m↓3.08%[0m) [0.19% of initial]
[Iter 11810/20000] Loss: 0.0002483 (Best: 0.0001958 @iter11593) ([92m↓7.99%[0m) [0.10% of initial]
[Iter 8470/20000] Loss: 0.0004926 (Best: 0.0003979 @iter8425) ([91m↑2.84%[0m) [0.20% of initial]
[Iter 11820/20000] Loss: 0.0002342 (Best: 0.0001958 @iter11593) ([92m↓5.67%[0m) [0.09% of initial]
[Iter 8480/20000] Loss: 0.0004718 (Best: 0.0003979 @iter8425) ([92m↓4.23%[0m) [0.19% of initial]
[Iter 11830/20000] Loss: 0.0002451 (Best: 0.0001958 @iter11593) ([91m↑4.66%[0m) [0.10% of initial]
[Iter 11840/20000] Loss: 0.0002826 (Best: 0.0001958 @iter11593) ([91m↑15.32%[0m) [0.11% of initial]
[Iter 8490/20000] Loss: 0.0005022 (Best: 0.0003979 @iter8425) ([91m↑6.45%[0m) [0.20% of initial]
[Iter 11850/20000] Loss: 0.0002661 (Best: 0.0001958 @iter11593) ([92m↓5.84%[0m) [0.11% of initial]
Iter:8499, L1 loss=0.0006343, Total loss=0.0005647, Time:109
[Iter 8500/20000] Loss: 0.0005501 (Best: 0.0003979 @iter8425) ([91m↑9.52%[0m) [0.22% of initial]
[Iter 11860/20000] Loss: 0.0002790 (Best: 0.0001958 @iter11593) ([91m↑4.85%[0m) [0.11% of initial]
Pruning 46 points (0.0%) from gaussian0 at iteration 8500
Pruning 41 points (0.0%) from gaussian1 at iteration 8500
[Iter 11870/20000] Loss: 0.0003123 (Best: 0.0001958 @iter11593) ([91m↑11.93%[0m) [0.12% of initial]
[Iter 11880/20000] Loss: 0.0002928 (Best: 0.0001958 @iter11593) ([92m↓6.24%[0m) [0.12% of initial]
[Iter 8510/20000] Loss: 0.0009970 (Best: 0.0003979 @iter8425) ([91m↑81.25%[0m) [0.40% of initial]
[Iter 11890/20000] Loss: 0.0003102 (Best: 0.0001958 @iter11593) ([91m↑5.95%[0m) [0.12% of initial]
[Iter 8520/20000] Loss: 0.0007086 (Best: 0.0003979 @iter8425) ([92m↓28.93%[0m) [0.28% of initial]
Iter:11899, L1 loss=0.0003626, Total loss=0.0003222, Time:69
[Iter 11900/20000] Loss: 0.0002792 (Best: 0.0001958 @iter11593) ([92m↓10.01%[0m) [0.11% of initial]
[Iter 8530/20000] Loss: 0.0005590 (Best: 0.0003979 @iter8425) ([92m↓21.10%[0m) [0.22% of initial]
[Iter 11910/20000] Loss: 0.0002646 (Best: 0.0001958 @iter11593) ([92m↓5.24%[0m) [0.11% of initial]
[Iter 8540/20000] Loss: 0.0005007 (Best: 0.0003979 @iter8425) ([92m↓10.43%[0m) [0.20% of initial]
[Iter 11920/20000] Loss: 0.0002601 (Best: 0.0001958 @iter11593) ([92m↓1.67%[0m) [0.10% of initial]
[Iter 11930/20000] Loss: 0.0002501 (Best: 0.0001958 @iter11593) ([92m↓3.86%[0m) [0.10% of initial]
[Iter 8550/20000] Loss: 0.0004789 (Best: 0.0003979 @iter8425) ([92m↓4.35%[0m) [0.19% of initial]
[Iter 11940/20000] Loss: 0.0002816 (Best: 0.0001958 @iter11593) ([91m↑12.57%[0m) [0.11% of initial]
[Iter 8560/20000] Loss: 0.0004669 (Best: 0.0003979 @iter8425) ([92m↓2.51%[0m) [0.19% of initial]
[Iter 11950/20000] Loss: 0.0002574 (Best: 0.0001958 @iter11593) ([92m↓8.59%[0m) [0.10% of initial]
[Iter 8570/20000] Loss: 0.0004606 (Best: 0.0003979 @iter8425) ([92m↓1.36%[0m) [0.18% of initial]
[Iter 11960/20000] Loss: 0.0002859 (Best: 0.0001958 @iter11593) ([91m↑11.10%[0m) [0.11% of initial]
[Iter 11970/20000] Loss: 0.0003307 (Best: 0.0001958 @iter11593) ([91m↑15.68%[0m) [0.13% of initial]
[Iter 8580/20000] Loss: 0.0004608 (Best: 0.0003979 @iter8425) ([91m↑0.06%[0m) [0.18% of initial]
[Iter 11980/20000] Loss: 0.0002822 (Best: 0.0001958 @iter11593) ([92m↓14.69%[0m) [0.11% of initial]
[Iter 8590/20000] Loss: 0.0004552 (Best: 0.0003979 @iter8425) ([92m↓1.23%[0m) [0.18% of initial]
[Iter 11990/20000] Loss: 0.0002881 (Best: 0.0001958 @iter11593) ([91m↑2.09%[0m) [0.11% of initial]
Iter:8599, L1 loss=0.0004549, Total loss=0.0004121, Time:103
[Iter 8600/20000] Loss: 0.0004416 (Best: 0.0003979 @iter8425) ([92m↓2.98%[0m) [0.18% of initial]
Iter:11999, L1 loss=0.000298, Total loss=0.0002594, Time:72
[Iter 12000/20000] Loss: 0.0002537 (Best: 0.0001958 @iter11593) ([92m↓11.94%[0m) [0.10% of initial]
[Iter 8610/20000] Loss: 0.0004604 (Best: 0.0003979 @iter8425) ([91m↑4.26%[0m) [0.18% of initial]
Pruning 10 points (0.0%) from gaussian0 at iteration 12000
Pruning 8 points (0.0%) from gaussian1 at iteration 12000
[Iter 8620/20000] Loss: 0.0004516 (Best: 0.0003979 @iter8425) ([92m↓1.90%[0m) [0.18% of initial]
[Iter 12010/20000] Loss: 0.0004511 (Best: 0.0001958 @iter11593) ([91m↑77.84%[0m) [0.18% of initial]
[Iter 8630/20000] Loss: 0.0004489 (Best: 0.0003979 @iter8425) ([92m↓0.60%[0m) [0.18% of initial]
[Iter 12020/20000] Loss: 0.0003457 (Best: 0.0001958 @iter11593) ([92m↓23.37%[0m) [0.14% of initial]
[Iter 12030/20000] Loss: 0.0002875 (Best: 0.0001958 @iter11593) ([92m↓16.83%[0m) [0.11% of initial]
[Iter 8640/20000] Loss: 0.0004284 (Best: 0.0003979 @iter8425) ([92m↓4.58%[0m) [0.17% of initial]
[Iter 12040/20000] Loss: 0.0002531 (Best: 0.0001958 @iter11593) ([92m↓11.98%[0m) [0.10% of initial]
[Iter 8650/20000] Loss: 0.0004454 (Best: 0.0003927 @iter8644) ([91m↑3.98%[0m) [0.18% of initial]
[Iter 12050/20000] Loss: 0.0002482 (Best: 0.0001958 @iter11593) ([92m↓1.91%[0m) [0.10% of initial]
[Iter 8660/20000] Loss: 0.0004922 (Best: 0.0003927 @iter8644) ([91m↑10.50%[0m) [0.20% of initial]
[Iter 12060/20000] Loss: 0.0002256 (Best: 0.0001958 @iter11593) ([92m↓9.13%[0m) [0.09% of initial]
[Iter 12070/20000] Loss: 0.0002237 (Best: 0.0001958 @iter11593) ([92m↓0.82%[0m) [0.09% of initial]
[Iter 8670/20000] Loss: 0.0004946 (Best: 0.0003927 @iter8644) ([91m↑0.48%[0m) [0.20% of initial]
[Iter 12080/20000] Loss: 0.0002228 (Best: 0.0001958 @iter11593) ([92m↓0.41%[0m) [0.09% of initial]
[Iter 8680/20000] Loss: 0.0004707 (Best: 0.0003927 @iter8644) ([92m↓4.83%[0m) [0.19% of initial]
[Iter 12090/20000] Loss: 0.0002408 (Best: 0.0001958 @iter11593) ([91m↑8.07%[0m) [0.10% of initial]
[Iter 8690/20000] Loss: 0.0005557 (Best: 0.0003927 @iter8644) ([91m↑18.06%[0m) [0.22% of initial]
Iter:12099, L1 loss=0.0002532, Total loss=0.000224, Time:66
[Iter 12100/20000] Loss: 0.0002241 (Best: 0.0001958 @iter11593) ([92m↓6.93%[0m) [0.09% of initial]
Iter:8699, L1 loss=0.0005204, Total loss=0.0004684, Time:102
[Iter 12110/20000] Loss: 0.0002601 (Best: 0.0001958 @iter11593) ([91m↑16.03%[0m) [0.10% of initial]
[Iter 8700/20000] Loss: 0.0004901 (Best: 0.0003927 @iter8644) ([92m↓11.81%[0m) [0.19% of initial]
[Iter 12120/20000] Loss: 0.0002466 (Best: 0.0001958 @iter11593) ([92m↓5.16%[0m) [0.10% of initial]
[Iter 8710/20000] Loss: 0.0004725 (Best: 0.0003927 @iter8644) ([92m↓3.58%[0m) [0.19% of initial]
[Iter 12130/20000] Loss: 0.0002519 (Best: 0.0001958 @iter11593) ([91m↑2.15%[0m) [0.10% of initial]
[Iter 8720/20000] Loss: 0.0004557 (Best: 0.0003927 @iter8644) ([92m↓3.56%[0m) [0.18% of initial]
[Iter 12140/20000] Loss: 0.0002749 (Best: 0.0001958 @iter11593) ([91m↑9.13%[0m) [0.11% of initial]
[Iter 12150/20000] Loss: 0.0002639 (Best: 0.0001958 @iter11593) ([92m↓4.00%[0m) [0.10% of initial]
[Iter 8730/20000] Loss: 0.0004889 (Best: 0.0003927 @iter8644) ([91m↑7.29%[0m) [0.19% of initial]
[Iter 12160/20000] Loss: 0.0002417 (Best: 0.0001958 @iter11593) ([92m↓8.41%[0m) [0.10% of initial]
[Iter 8740/20000] Loss: 0.0004567 (Best: 0.0003927 @iter8644) ([92m↓6.59%[0m) [0.18% of initial]
[Iter 12170/20000] Loss: 0.0002440 (Best: 0.0001958 @iter11593) ([91m↑0.94%[0m) [0.10% of initial]
[Iter 8750/20000] Loss: 0.0005416 (Best: 0.0003927 @iter8644) ([91m↑18.59%[0m) [0.22% of initial]
[Iter 12180/20000] Loss: 0.0002376 (Best: 0.0001958 @iter11593) ([92m↓2.62%[0m) [0.09% of initial]
[Iter 12190/20000] Loss: 0.0002255 (Best: 0.0001958 @iter11593) ([92m↓5.12%[0m) [0.09% of initial]
[Iter 8760/20000] Loss: 0.0005103 (Best: 0.0003927 @iter8644) ([92m↓5.77%[0m) [0.20% of initial]
Iter:12199, L1 loss=0.0002651, Total loss=0.0002289, Time:78
[Iter 12200/20000] Loss: 0.0002237 (Best: 0.0001958 @iter11593) ([92m↓0.78%[0m) [0.09% of initial]
[Iter 8770/20000] Loss: 0.0005055 (Best: 0.0003927 @iter8644) ([92m↓0.95%[0m) [0.20% of initial]
[Iter 12210/20000] Loss: 0.0002370 (Best: 0.0001958 @iter11593) ([91m↑5.93%[0m) [0.09% of initial]
[Iter 8780/20000] Loss: 0.0004960 (Best: 0.0003927 @iter8644) ([92m↓1.88%[0m) [0.20% of initial]
[Iter 12220/20000] Loss: 0.0002527 (Best: 0.0001958 @iter11593) ([91m↑6.65%[0m) [0.10% of initial]
[Iter 12230/20000] Loss: 0.0002691 (Best: 0.0001958 @iter11593) ([91m↑6.47%[0m) [0.11% of initial]
[Iter 8790/20000] Loss: 0.0004922 (Best: 0.0003927 @iter8644) ([92m↓0.76%[0m) [0.20% of initial]
[Iter 12240/20000] Loss: 0.0002496 (Best: 0.0001958 @iter11593) ([92m↓7.24%[0m) [0.10% of initial]
Iter:8799, L1 loss=0.0006135, Total loss=0.0005305, Time:104
[Iter 8800/20000] Loss: 0.0004676 (Best: 0.0003927 @iter8644) ([92m↓5.01%[0m) [0.19% of initial]
[Iter 12250/20000] Loss: 0.0002594 (Best: 0.0001958 @iter11593) ([91m↑3.90%[0m) [0.10% of initial]
[Iter 8810/20000] Loss: 0.0004276 (Best: 0.0003927 @iter8644) ([92m↓8.55%[0m) [0.17% of initial]
[Iter 12260/20000] Loss: 0.0002648 (Best: 0.0001958 @iter11593) ([91m↑2.08%[0m) [0.11% of initial]
[Iter 12270/20000] Loss: 0.0002307 (Best: 0.0001958 @iter11593) ([92m↓12.87%[0m) [0.09% of initial]
[Iter 8820/20000] Loss: 0.0004908 (Best: 0.0003927 @iter8644) ([91m↑14.78%[0m) [0.19% of initial]
[Iter 12280/20000] Loss: 0.0002246 (Best: 0.0001946 @iter12274) ([92m↓2.64%[0m) [0.09% of initial]
[Iter 8830/20000] Loss: 0.0005716 (Best: 0.0003927 @iter8644) ([91m↑16.47%[0m) [0.23% of initial]
[Iter 12290/20000] Loss: 0.0003125 (Best: 0.0001946 @iter12274) ([91m↑39.14%[0m) [0.12% of initial]
[Iter 8840/20000] Loss: 0.0005387 (Best: 0.0003927 @iter8644) ([92m↓5.77%[0m) [0.21% of initial]
Iter:12299, L1 loss=0.0003155, Total loss=0.0002777, Time:65
[Iter 12300/20000] Loss: 0.0003032 (Best: 0.0001946 @iter12274) ([92m↓2.98%[0m) [0.12% of initial]
[Iter 12310/20000] Loss: 0.0002794 (Best: 0.0001946 @iter12274) ([92m↓7.85%[0m) [0.11% of initial]
[Iter 8850/20000] Loss: 0.0005280 (Best: 0.0003927 @iter8644) ([92m↓1.99%[0m) [0.21% of initial]
[Iter 12320/20000] Loss: 0.0002515 (Best: 0.0001946 @iter12274) ([92m↓9.96%[0m) [0.10% of initial]
[Iter 8860/20000] Loss: 0.0004627 (Best: 0.0003927 @iter8644) ([92m↓12.35%[0m) [0.18% of initial]
[Iter 12330/20000] Loss: 0.0002659 (Best: 0.0001946 @iter12274) ([91m↑5.69%[0m) [0.11% of initial]
[Iter 8870/20000] Loss: 0.0004481 (Best: 0.0003927 @iter8644) ([92m↓3.18%[0m) [0.18% of initial]
[Iter 12340/20000] Loss: 0.0002845 (Best: 0.0001946 @iter12274) ([91m↑7.02%[0m) [0.11% of initial]
[Iter 12350/20000] Loss: 0.0002423 (Best: 0.0001946 @iter12274) ([92m↓14.83%[0m) [0.10% of initial]
[Iter 8880/20000] Loss: 0.0004403 (Best: 0.0003927 @iter8644) ([92m↓1.72%[0m) [0.17% of initial]
[Iter 12360/20000] Loss: 0.0002393 (Best: 0.0001946 @iter12274) ([92m↓1.24%[0m) [0.10% of initial]
[Iter 8890/20000] Loss: 0.0004215 (Best: 0.0003927 @iter8644) ([92m↓4.29%[0m) [0.17% of initial]
[Iter 12370/20000] Loss: 0.0002898 (Best: 0.0001946 @iter12274) ([91m↑21.07%[0m) [0.12% of initial]
Iter:8899, L1 loss=0.0004762, Total loss=0.0004251, Time:104
[Iter 8900/20000] Loss: 0.0004499 (Best: 0.0003823 @iter8893) ([91m↑6.75%[0m) [0.18% of initial]
[Iter 12380/20000] Loss: 0.0002441 (Best: 0.0001946 @iter12274) ([92m↓15.76%[0m) [0.10% of initial]
[Iter 12390/20000] Loss: 0.0002664 (Best: 0.0001946 @iter12274) ([91m↑9.14%[0m) [0.11% of initial]
[Iter 8910/20000] Loss: 0.0004443 (Best: 0.0003823 @iter8893) ([92m↓1.26%[0m) [0.18% of initial]
Iter:12399, L1 loss=0.0003216, Total loss=0.0002986, Time:76
[Iter 12400/20000] Loss: 0.0002559 (Best: 0.0001946 @iter12274) ([92m↓3.95%[0m) [0.10% of initial]
[Iter 8920/20000] Loss: 0.0004383 (Best: 0.0003823 @iter8893) ([92m↓1.34%[0m) [0.17% of initial]
[Iter 12410/20000] Loss: 0.0002232 (Best: 0.0001946 @iter12274) ([92m↓12.76%[0m) [0.09% of initial]
[Iter 8930/20000] Loss: 0.0004463 (Best: 0.0003823 @iter8893) ([91m↑1.83%[0m) [0.18% of initial]
[Iter 12420/20000] Loss: 0.0002185 (Best: 0.0001946 @iter12274) ([92m↓2.12%[0m) [0.09% of initial]
[Iter 12430/20000] Loss: 0.0002195 (Best: 0.0001946 @iter12274) ([91m↑0.46%[0m) [0.09% of initial]
[Iter 8940/20000] Loss: 0.0004522 (Best: 0.0003823 @iter8893) ([91m↑1.32%[0m) [0.18% of initial]
[Iter 12440/20000] Loss: 0.0002346 (Best: 0.0001946 @iter12274) ([91m↑6.90%[0m) [0.09% of initial]
[Iter 8950/20000] Loss: 0.0004718 (Best: 0.0003823 @iter8893) ([91m↑4.33%[0m) [0.19% of initial]
[Iter 12450/20000] Loss: 0.0002287 (Best: 0.0001920 @iter12442) ([92m↓2.51%[0m) [0.09% of initial]
[Iter 8960/20000] Loss: 0.0004689 (Best: 0.0003823 @iter8893) ([92m↓0.60%[0m) [0.19% of initial]
[Iter 12460/20000] Loss: 0.0002831 (Best: 0.0001920 @iter12442) ([91m↑23.78%[0m) [0.11% of initial]
[Iter 12470/20000] Loss: 0.0002541 (Best: 0.0001920 @iter12442) ([92m↓10.27%[0m) [0.10% of initial]
[Iter 8970/20000] Loss: 0.0005281 (Best: 0.0003823 @iter8893) ([91m↑12.61%[0m) [0.21% of initial]
[Iter 12480/20000] Loss: 0.0002218 (Best: 0.0001920 @iter12442) ([92m↓12.68%[0m) [0.09% of initial]
[Iter 8980/20000] Loss: 0.0005159 (Best: 0.0003823 @iter8893) ([92m↓2.30%[0m) [0.20% of initial]
[Iter 12490/20000] Loss: 0.0002107 (Best: 0.0001900 @iter12485) ([92m↓5.02%[0m) [0.08% of initial]
[Iter 8990/20000] Loss: 0.0004944 (Best: 0.0003823 @iter8893) ([92m↓4.18%[0m) [0.20% of initial]
Iter:12499, L1 loss=0.0002271, Total loss=0.0001859, Time:70
[Iter 12500/20000] Loss: 0.0002070 (Best: 0.0001808 @iter12497) ([92m↓1.77%[0m) [0.08% of initial]
Iter:8999, L1 loss=0.000469, Total loss=0.0004066, Time:74
[Iter 9000/20000] Loss: 0.0004464 (Best: 0.0003823 @iter8893) ([92m↓9.71%[0m) [0.18% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 12500
Pruning 13 points (0.0%) from gaussian1 at iteration 12500
Pruning 44 points (0.0%) from gaussian0 at iteration 9000
Pruning 32 points (0.0%) from gaussian1 at iteration 9000
[Iter 12510/20000] Loss: 0.0004651 (Best: 0.0001808 @iter12497) ([91m↑124.70%[0m) [0.18% of initial]
[Iter 12520/20000] Loss: 0.0003291 (Best: 0.0001808 @iter12497) ([92m↓29.24%[0m) [0.13% of initial]
[Iter 9010/20000] Loss: 0.0008079 (Best: 0.0003823 @iter8893) ([91m↑80.98%[0m) [0.32% of initial]
[Iter 12530/20000] Loss: 0.0002656 (Best: 0.0001808 @iter12497) ([92m↓19.28%[0m) [0.11% of initial]
[Iter 9020/20000] Loss: 0.0006095 (Best: 0.0003823 @iter8893) ([92m↓24.56%[0m) [0.24% of initial]
[Iter 12540/20000] Loss: 0.0002385 (Best: 0.0001808 @iter12497) ([92m↓10.22%[0m) [0.09% of initial]
[Iter 9030/20000] Loss: 0.0005119 (Best: 0.0003823 @iter8893) ([92m↓16.00%[0m) [0.20% of initial]
[Iter 12550/20000] Loss: 0.0002469 (Best: 0.0001808 @iter12497) ([91m↑3.54%[0m) [0.10% of initial]
[Iter 12560/20000] Loss: 0.0002396 (Best: 0.0001808 @iter12497) ([92m↓2.98%[0m) [0.10% of initial]
[Iter 9040/20000] Loss: 0.0004650 (Best: 0.0003823 @iter8893) ([92m↓9.17%[0m) [0.18% of initial]
[Iter 12570/20000] Loss: 0.0002537 (Best: 0.0001808 @iter12497) ([91m↑5.88%[0m) [0.10% of initial]
[Iter 9050/20000] Loss: 0.0004430 (Best: 0.0003823 @iter8893) ([92m↓4.74%[0m) [0.18% of initial]
[Iter 12580/20000] Loss: 0.0002218 (Best: 0.0001808 @iter12497) ([92m↓12.55%[0m) [0.09% of initial]
[Iter 9060/20000] Loss: 0.0004576 (Best: 0.0003823 @iter8893) ([91m↑3.30%[0m) [0.18% of initial]
[Iter 12590/20000] Loss: 0.0002214 (Best: 0.0001808 @iter12497) ([92m↓0.19%[0m) [0.09% of initial]
Iter:12599, L1 loss=0.0002263, Total loss=0.0001969, Time:71
[Iter 12600/20000] Loss: 0.0002105 (Best: 0.0001808 @iter12497) ([92m↓4.92%[0m) [0.08% of initial]
[Iter 9070/20000] Loss: 0.0004652 (Best: 0.0003823 @iter8893) ([91m↑1.66%[0m) [0.18% of initial]
[Iter 12610/20000] Loss: 0.0002160 (Best: 0.0001808 @iter12497) ([91m↑2.60%[0m) [0.09% of initial]
[Iter 9080/20000] Loss: 0.0004991 (Best: 0.0003823 @iter8893) ([91m↑7.30%[0m) [0.20% of initial]
[Iter 12620/20000] Loss: 0.0002123 (Best: 0.0001808 @iter12497) ([92m↓1.71%[0m) [0.08% of initial]
[Iter 9090/20000] Loss: 0.0004743 (Best: 0.0003823 @iter8893) ([92m↓4.98%[0m) [0.19% of initial]
[Iter 12630/20000] Loss: 0.0002341 (Best: 0.0001808 @iter12497) ([91m↑10.29%[0m) [0.09% of initial]
[Iter 12640/20000] Loss: 0.0002181 (Best: 0.0001808 @iter12497) ([92m↓6.85%[0m) [0.09% of initial]
Iter:9099, L1 loss=0.0005831, Total loss=0.0005105, Time:103
[Iter 9100/20000] Loss: 0.0004725 (Best: 0.0003823 @iter8893) ([92m↓0.36%[0m) [0.19% of initial]
[Iter 12650/20000] Loss: 0.0002280 (Best: 0.0001808 @iter12497) ([91m↑4.55%[0m) [0.09% of initial]
[Iter 9110/20000] Loss: 0.0005502 (Best: 0.0003823 @iter8893) ([91m↑16.43%[0m) [0.22% of initial]
[Iter 12660/20000] Loss: 0.0002176 (Best: 0.0001808 @iter12497) ([92m↓4.57%[0m) [0.09% of initial]
[Iter 9120/20000] Loss: 0.0004760 (Best: 0.0003823 @iter8893) ([92m↓13.49%[0m) [0.19% of initial]
[Iter 12670/20000] Loss: 0.0002158 (Best: 0.0001808 @iter12497) ([92m↓0.82%[0m) [0.09% of initial]
[Iter 12680/20000] Loss: 0.0002136 (Best: 0.0001808 @iter12497) ([92m↓1.02%[0m) [0.08% of initial]
[Iter 9130/20000] Loss: 0.0004604 (Best: 0.0003823 @iter8893) ([92m↓3.28%[0m) [0.18% of initial]
[Iter 12690/20000] Loss: 0.0002189 (Best: 0.0001808 @iter12497) ([91m↑2.47%[0m) [0.09% of initial]
[Iter 9140/20000] Loss: 0.0004605 (Best: 0.0003823 @iter8893) ([91m↑0.03%[0m) [0.18% of initial]
Iter:12699, L1 loss=0.0002375, Total loss=0.0001988, Time:67
[Iter 12700/20000] Loss: 0.0002018 (Best: 0.0001808 @iter12497) ([92m↓7.78%[0m) [0.08% of initial]
[Iter 9150/20000] Loss: 0.0004213 (Best: 0.0003823 @iter8893) ([92m↓8.51%[0m) [0.17% of initial]
[Iter 12710/20000] Loss: 0.0002471 (Best: 0.0001808 @iter12497) ([91m↑22.42%[0m) [0.10% of initial]
[Iter 12720/20000] Loss: 0.0002416 (Best: 0.0001808 @iter12497) ([92m↓2.24%[0m) [0.10% of initial]
[Iter 9160/20000] Loss: 0.0004610 (Best: 0.0003823 @iter8893) ([91m↑9.41%[0m) [0.18% of initial]
[Iter 12730/20000] Loss: 0.0002419 (Best: 0.0001808 @iter12497) ([91m↑0.16%[0m) [0.10% of initial]
[Iter 9170/20000] Loss: 0.0004270 (Best: 0.0003823 @iter8893) ([92m↓7.38%[0m) [0.17% of initial]
[Iter 12740/20000] Loss: 0.0002329 (Best: 0.0001808 @iter12497) ([92m↓3.72%[0m) [0.09% of initial]
[Iter 9180/20000] Loss: 0.0004320 (Best: 0.0003823 @iter8893) ([91m↑1.18%[0m) [0.17% of initial]
[Iter 12750/20000] Loss: 0.0002596 (Best: 0.0001808 @iter12497) ([91m↑11.44%[0m) [0.10% of initial]
[Iter 12760/20000] Loss: 0.0002376 (Best: 0.0001808 @iter12497) ([92m↓8.45%[0m) [0.09% of initial]
[Iter 9190/20000] Loss: 0.0004004 (Best: 0.0003722 @iter9187) ([92m↓7.32%[0m) [0.16% of initial]
[Iter 12770/20000] Loss: 0.0002491 (Best: 0.0001808 @iter12497) ([91m↑4.80%[0m) [0.10% of initial]
Iter:9199, L1 loss=0.0004611, Total loss=0.0004144, Time:100
[Iter 9200/20000] Loss: 0.0004147 (Best: 0.0003722 @iter9187) ([91m↑3.58%[0m) [0.16% of initial]
[Iter 12780/20000] Loss: 0.0002296 (Best: 0.0001808 @iter12497) ([92m↓7.80%[0m) [0.09% of initial]
[Iter 9210/20000] Loss: 0.0004213 (Best: 0.0003722 @iter9187) ([91m↑1.59%[0m) [0.17% of initial]
[Iter 12790/20000] Loss: 0.0002157 (Best: 0.0001808 @iter12497) ([92m↓6.05%[0m) [0.09% of initial]
Iter:12799, L1 loss=0.0002575, Total loss=0.0002192, Time:76
[Iter 12800/20000] Loss: 0.0002341 (Best: 0.0001808 @iter12497) ([91m↑8.51%[0m) [0.09% of initial]
[Iter 9220/20000] Loss: 0.0004178 (Best: 0.0003722 @iter9187) ([92m↓0.83%[0m) [0.17% of initial]
[Iter 12810/20000] Loss: 0.0002410 (Best: 0.0001808 @iter12497) ([91m↑2.94%[0m) [0.10% of initial]
[Iter 9230/20000] Loss: 0.0004136 (Best: 0.0003647 @iter9223) ([92m↓1.02%[0m) [0.16% of initial]
[Iter 12820/20000] Loss: 0.0002299 (Best: 0.0001808 @iter12497) ([92m↓4.60%[0m) [0.09% of initial]
[Iter 9240/20000] Loss: 0.0004341 (Best: 0.0003647 @iter9223) ([91m↑4.96%[0m) [0.17% of initial]
[Iter 12830/20000] Loss: 0.0003073 (Best: 0.0001808 @iter12497) ([91m↑33.66%[0m) [0.12% of initial]
[Iter 12840/20000] Loss: 0.0002606 (Best: 0.0001808 @iter12497) ([92m↓15.19%[0m) [0.10% of initial]
[Iter 9250/20000] Loss: 0.0004273 (Best: 0.0003647 @iter9223) ([92m↓1.56%[0m) [0.17% of initial]
[Iter 12850/20000] Loss: 0.0002528 (Best: 0.0001808 @iter12497) ([92m↓2.99%[0m) [0.10% of initial]
[Iter 9260/20000] Loss: 0.0004252 (Best: 0.0003647 @iter9223) ([92m↓0.50%[0m) [0.17% of initial]
[Iter 12860/20000] Loss: 0.0002221 (Best: 0.0001808 @iter12497) ([92m↓12.17%[0m) [0.09% of initial]
[Iter 9270/20000] Loss: 0.0004198 (Best: 0.0003647 @iter9223) ([92m↓1.27%[0m) [0.17% of initial]
[Iter 12870/20000] Loss: 0.0002353 (Best: 0.0001808 @iter12497) ([91m↑5.95%[0m) [0.09% of initial]
[Iter 12880/20000] Loss: 0.0002209 (Best: 0.0001808 @iter12497) ([92m↓6.11%[0m) [0.09% of initial]
[Iter 9280/20000] Loss: 0.0003934 (Best: 0.0003647 @iter9223) ([92m↓6.29%[0m) [0.16% of initial]
[Iter 12890/20000] Loss: 0.0002310 (Best: 0.0001808 @iter12497) ([91m↑4.55%[0m) [0.09% of initial]
[Iter 9290/20000] Loss: 0.0003937 (Best: 0.0003647 @iter9223) ([91m↑0.09%[0m) [0.16% of initial]
Iter:12899, L1 loss=0.0003369, Total loss=0.0002775, Time:94
[Iter 12900/20000] Loss: 0.0002808 (Best: 0.0001808 @iter12497) ([91m↑21.58%[0m) [0.11% of initial]
Iter:9299, L1 loss=0.0004338, Total loss=0.0003758, Time:103
[Iter 9300/20000] Loss: 0.0004188 (Best: 0.0003647 @iter9223) ([91m↑6.36%[0m) [0.17% of initial]
[Iter 12910/20000] Loss: 0.0003027 (Best: 0.0001808 @iter12497) ([91m↑7.79%[0m) [0.12% of initial]
[Iter 9310/20000] Loss: 0.0004345 (Best: 0.0003647 @iter9223) ([91m↑3.75%[0m) [0.17% of initial]
[Iter 12920/20000] Loss: 0.0002623 (Best: 0.0001808 @iter12497) ([92m↓13.32%[0m) [0.10% of initial]
[Iter 9320/20000] Loss: 0.0004413 (Best: 0.0003647 @iter9223) ([91m↑1.58%[0m) [0.18% of initial]
[Iter 12930/20000] Loss: 0.0002590 (Best: 0.0001808 @iter12497) ([92m↓1.28%[0m) [0.10% of initial]
[Iter 12940/20000] Loss: 0.0002531 (Best: 0.0001808 @iter12497) ([92m↓2.26%[0m) [0.10% of initial]
[Iter 9330/20000] Loss: 0.0004773 (Best: 0.0003647 @iter9223) ([91m↑8.14%[0m) [0.19% of initial]
[Iter 12950/20000] Loss: 0.0002642 (Best: 0.0001808 @iter12497) ([91m↑4.37%[0m) [0.10% of initial]
[Iter 9340/20000] Loss: 0.0004717 (Best: 0.0003647 @iter9223) ([92m↓1.17%[0m) [0.19% of initial]
[Iter 12960/20000] Loss: 0.0002517 (Best: 0.0001808 @iter12497) ([92m↓4.72%[0m) [0.10% of initial]
[Iter 9350/20000] Loss: 0.0004285 (Best: 0.0003647 @iter9223) ([92m↓9.15%[0m) [0.17% of initial]
[Iter 12970/20000] Loss: 0.0002256 (Best: 0.0001808 @iter12497) ([92m↓10.39%[0m) [0.09% of initial]
[Iter 12980/20000] Loss: 0.0002219 (Best: 0.0001808 @iter12497) ([92m↓1.62%[0m) [0.09% of initial]
[Iter 9360/20000] Loss: 0.0004546 (Best: 0.0003647 @iter9223) ([91m↑6.09%[0m) [0.18% of initial]
[Iter 12990/20000] Loss: 0.0002298 (Best: 0.0001808 @iter12497) ([91m↑3.54%[0m) [0.09% of initial]
[Iter 9370/20000] Loss: 0.0004068 (Best: 0.0003647 @iter9223) ([92m↓10.52%[0m) [0.16% of initial]
Iter:12999, L1 loss=0.0003119, Total loss=0.0002511, Time:66
[Iter 13000/20000] Loss: 0.0002372 (Best: 0.0001808 @iter12497) ([91m↑3.22%[0m) [0.09% of initial]
[Iter 9380/20000] Loss: 0.0004311 (Best: 0.0003647 @iter9223) ([91m↑5.97%[0m) [0.17% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 13000
Pruning 8 points (0.0%) from gaussian1 at iteration 13000
[Iter 9390/20000] Loss: 0.0004399 (Best: 0.0003647 @iter9223) ([91m↑2.03%[0m) [0.17% of initial]
[Iter 13010/20000] Loss: 0.0004198 (Best: 0.0001808 @iter12497) ([91m↑77.01%[0m) [0.17% of initial]
Iter:9399, L1 loss=0.0005841, Total loss=0.000533, Time:105
[Iter 9400/20000] Loss: 0.0004367 (Best: 0.0003647 @iter9223) ([92m↓0.73%[0m) [0.17% of initial]
[Iter 13020/20000] Loss: 0.0003291 (Best: 0.0001808 @iter12497) ([92m↓21.62%[0m) [0.13% of initial]
[Iter 9410/20000] Loss: 0.0004379 (Best: 0.0003647 @iter9223) ([91m↑0.27%[0m) [0.17% of initial]
[Iter 13030/20000] Loss: 0.0002551 (Best: 0.0001808 @iter12497) ([92m↓22.47%[0m) [0.10% of initial]
[Iter 13040/20000] Loss: 0.0002181 (Best: 0.0001808 @iter12497) ([92m↓14.53%[0m) [0.09% of initial]
[Iter 9420/20000] Loss: 0.0004539 (Best: 0.0003647 @iter9223) ([91m↑3.66%[0m) [0.18% of initial]
[Iter 13050/20000] Loss: 0.0002131 (Best: 0.0001808 @iter12497) ([92m↓2.27%[0m) [0.08% of initial]
[Iter 9430/20000] Loss: 0.0004144 (Best: 0.0003647 @iter9223) ([92m↓8.70%[0m) [0.16% of initial]
[Iter 13060/20000] Loss: 0.0002157 (Best: 0.0001808 @iter12497) ([91m↑1.20%[0m) [0.09% of initial]
[Iter 9440/20000] Loss: 0.0004418 (Best: 0.0003647 @iter9223) ([91m↑6.62%[0m) [0.18% of initial]
[Iter 13070/20000] Loss: 0.0002345 (Best: 0.0001808 @iter12497) ([91m↑8.76%[0m) [0.09% of initial]
[Iter 13080/20000] Loss: 0.0002307 (Best: 0.0001808 @iter12497) ([92m↓1.65%[0m) [0.09% of initial]
[Iter 9450/20000] Loss: 0.0004326 (Best: 0.0003647 @iter9223) ([92m↓2.09%[0m) [0.17% of initial]
[Iter 13090/20000] Loss: 0.0002129 (Best: 0.0001808 @iter12497) ([92m↓7.72%[0m) [0.08% of initial]
[Iter 9460/20000] Loss: 0.0003881 (Best: 0.0003647 @iter9223) ([92m↓10.27%[0m) [0.15% of initial]
Iter:13099, L1 loss=0.0003044, Total loss=0.0002511, Time:78
[Iter 13100/20000] Loss: 0.0002366 (Best: 0.0001808 @iter12497) ([91m↑11.13%[0m) [0.09% of initial]
[Iter 9470/20000] Loss: 0.0003863 (Best: 0.0003647 @iter9223) ([92m↓0.47%[0m) [0.15% of initial]
[Iter 13110/20000] Loss: 0.0002445 (Best: 0.0001808 @iter12497) ([91m↑3.37%[0m) [0.10% of initial]
[Iter 13120/20000] Loss: 0.0002259 (Best: 0.0001808 @iter12497) ([92m↓7.60%[0m) [0.09% of initial]
[Iter 9480/20000] Loss: 0.0004413 (Best: 0.0003647 @iter9223) ([91m↑14.24%[0m) [0.18% of initial]
[Iter 13130/20000] Loss: 0.0002694 (Best: 0.0001808 @iter12497) ([91m↑19.26%[0m) [0.11% of initial]
[Iter 9490/20000] Loss: 0.0003982 (Best: 0.0003647 @iter9223) ([92m↓9.77%[0m) [0.16% of initial]
[Iter 13140/20000] Loss: 0.0002403 (Best: 0.0001808 @iter12497) ([92m↓10.80%[0m) [0.10% of initial]
Iter:9499, L1 loss=0.0004803, Total loss=0.0004041, Time:101
[Iter 9500/20000] Loss: 0.0004157 (Best: 0.0003647 @iter9223) ([91m↑4.41%[0m) [0.17% of initial]
[Iter 13150/20000] Loss: 0.0002615 (Best: 0.0001808 @iter12497) ([91m↑8.79%[0m) [0.10% of initial]
Pruning 32 points (0.0%) from gaussian0 at iteration 9500
Pruning 36 points (0.0%) from gaussian1 at iteration 9500
[Iter 13160/20000] Loss: 0.0002161 (Best: 0.0001808 @iter12497) ([92m↓17.36%[0m) [0.09% of initial]
[Iter 13170/20000] Loss: 0.0002014 (Best: 0.0001808 @iter12497) ([92m↓6.77%[0m) [0.08% of initial]
[Iter 9510/20000] Loss: 0.0007390 (Best: 0.0003647 @iter9223) ([91m↑77.75%[0m) [0.29% of initial]
[Iter 13180/20000] Loss: 0.0002334 (Best: 0.0001808 @iter12497) ([91m↑15.86%[0m) [0.09% of initial]
[Iter 9520/20000] Loss: 0.0005481 (Best: 0.0003647 @iter9223) ([92m↓25.83%[0m) [0.22% of initial]
[Iter 13190/20000] Loss: 0.0002190 (Best: 0.0001808 @iter12497) ([92m↓6.14%[0m) [0.09% of initial]
[Iter 9530/20000] Loss: 0.0005603 (Best: 0.0003647 @iter9223) ([91m↑2.22%[0m) [0.22% of initial]
Iter:13199, L1 loss=0.0002397, Total loss=0.0002101, Time:75
[Iter 13200/20000] Loss: 0.0002139 (Best: 0.0001808 @iter12497) ([92m↓2.34%[0m) [0.08% of initial]
[Iter 13210/20000] Loss: 0.0002657 (Best: 0.0001808 @iter12497) ([91m↑24.23%[0m) [0.11% of initial]
[Iter 9540/20000] Loss: 0.0004524 (Best: 0.0003647 @iter9223) ([92m↓19.25%[0m) [0.18% of initial]
[Iter 13220/20000] Loss: 0.0002540 (Best: 0.0001808 @iter12497) ([92m↓4.41%[0m) [0.10% of initial]
[Iter 9550/20000] Loss: 0.0004065 (Best: 0.0003647 @iter9223) ([92m↓10.15%[0m) [0.16% of initial]
[Iter 13230/20000] Loss: 0.0002503 (Best: 0.0001808 @iter12497) ([92m↓1.45%[0m) [0.10% of initial]
[Iter 9560/20000] Loss: 0.0003933 (Best: 0.0003647 @iter9223) ([92m↓3.24%[0m) [0.16% of initial]
[Iter 13240/20000] Loss: 0.0002236 (Best: 0.0001808 @iter12497) ([92m↓10.69%[0m) [0.09% of initial]
[Iter 13250/20000] Loss: 0.0002128 (Best: 0.0001808 @iter12497) ([92m↓4.81%[0m) [0.08% of initial]
[Iter 9570/20000] Loss: 0.0003864 (Best: 0.0003647 @iter9223) ([92m↓1.75%[0m) [0.15% of initial]
[Iter 13260/20000] Loss: 0.0002078 (Best: 0.0001808 @iter12497) ([92m↓2.38%[0m) [0.08% of initial]
[Iter 9580/20000] Loss: 0.0003662 (Best: 0.0003448 @iter9575) ([92m↓5.23%[0m) [0.15% of initial]
[Iter 13270/20000] Loss: 0.0002101 (Best: 0.0001808 @iter12497) ([91m↑1.11%[0m) [0.08% of initial]
[Iter 9590/20000] Loss: 0.0003680 (Best: 0.0003448 @iter9575) ([91m↑0.48%[0m) [0.15% of initial]
[Iter 13280/20000] Loss: 0.0001878 (Best: 0.0001764 @iter13279) ([92m↓10.58%[0m) [0.07% of initial]
Iter:9599, L1 loss=0.0005133, Total loss=0.0004444, Time:94
[Iter 13290/20000] Loss: 0.0002046 (Best: 0.0001764 @iter13279) ([91m↑8.91%[0m) [0.08% of initial]
[Iter 9600/20000] Loss: 0.0004038 (Best: 0.0003448 @iter9575) ([91m↑9.73%[0m) [0.16% of initial]
Iter:13299, L1 loss=0.0003115, Total loss=0.0002585, Time:81
[Iter 13300/20000] Loss: 0.0002452 (Best: 0.0001764 @iter13279) ([91m↑19.85%[0m) [0.10% of initial]
[Iter 9610/20000] Loss: 0.0003830 (Best: 0.0003448 @iter9575) ([92m↓5.14%[0m) [0.15% of initial]
[Iter 13310/20000] Loss: 0.0002569 (Best: 0.0001764 @iter13279) ([91m↑4.77%[0m) [0.10% of initial]
[Iter 9620/20000] Loss: 0.0003892 (Best: 0.0003448 @iter9575) ([91m↑1.61%[0m) [0.15% of initial]
[Iter 13320/20000] Loss: 0.0002964 (Best: 0.0001764 @iter13279) ([91m↑15.38%[0m) [0.12% of initial]
[Iter 9630/20000] Loss: 0.0003713 (Best: 0.0003368 @iter9628) ([92m↓4.59%[0m) [0.15% of initial]
[Iter 13330/20000] Loss: 0.0002245 (Best: 0.0001764 @iter13279) ([92m↓24.25%[0m) [0.09% of initial]
[Iter 13340/20000] Loss: 0.0002494 (Best: 0.0001764 @iter13279) ([91m↑11.12%[0m) [0.10% of initial]
[Iter 9640/20000] Loss: 0.0003680 (Best: 0.0003326 @iter9638) ([92m↓0.90%[0m) [0.15% of initial]
[Iter 13350/20000] Loss: 0.0002261 (Best: 0.0001764 @iter13279) ([92m↓9.35%[0m) [0.09% of initial]
[Iter 9650/20000] Loss: 0.0004061 (Best: 0.0003326 @iter9638) ([91m↑10.37%[0m) [0.16% of initial]
[Iter 13360/20000] Loss: 0.0002174 (Best: 0.0001764 @iter13279) ([92m↓3.85%[0m) [0.09% of initial]
[Iter 13370/20000] Loss: 0.0002013 (Best: 0.0001764 @iter13279) ([92m↓7.39%[0m) [0.08% of initial]
[Iter 9660/20000] Loss: 0.0003984 (Best: 0.0003326 @iter9638) ([92m↓1.91%[0m) [0.16% of initial]
[Iter 13380/20000] Loss: 0.0002112 (Best: 0.0001764 @iter13279) ([91m↑4.91%[0m) [0.08% of initial]
[Iter 9670/20000] Loss: 0.0004317 (Best: 0.0003326 @iter9638) ([91m↑8.38%[0m) [0.17% of initial]
[Iter 13390/20000] Loss: 0.0001959 (Best: 0.0001746 @iter13387) ([92m↓7.24%[0m) [0.08% of initial]
[Iter 9680/20000] Loss: 0.0004469 (Best: 0.0003326 @iter9638) ([91m↑3.51%[0m) [0.18% of initial]
Iter:13399, L1 loss=0.000243, Total loss=0.0002, Time:66
[Iter 13400/20000] Loss: 0.0002055 (Best: 0.0001746 @iter13387) ([91m↑4.90%[0m) [0.08% of initial]
[Iter 13410/20000] Loss: 0.0003404 (Best: 0.0001746 @iter13387) ([91m↑65.61%[0m) [0.14% of initial]
[Iter 9690/20000] Loss: 0.0004983 (Best: 0.0003326 @iter9638) ([91m↑11.50%[0m) [0.20% of initial]
[Iter 13420/20000] Loss: 0.0003290 (Best: 0.0001746 @iter13387) ([92m↓3.34%[0m) [0.13% of initial]
Iter:9699, L1 loss=0.0006183, Total loss=0.0005767, Time:103
[Iter 9700/20000] Loss: 0.0004802 (Best: 0.0003326 @iter9638) ([92m↓3.64%[0m) [0.19% of initial]
[Iter 13430/20000] Loss: 0.0002821 (Best: 0.0001746 @iter13387) ([92m↓14.27%[0m) [0.11% of initial]
[Iter 9710/20000] Loss: 0.0004606 (Best: 0.0003326 @iter9638) ([92m↓4.08%[0m) [0.18% of initial]
[Iter 13440/20000] Loss: 0.0002740 (Best: 0.0001746 @iter13387) ([92m↓2.88%[0m) [0.11% of initial]
[Iter 13450/20000] Loss: 0.0002167 (Best: 0.0001746 @iter13387) ([92m↓20.91%[0m) [0.09% of initial]
[Iter 9720/20000] Loss: 0.0004324 (Best: 0.0003326 @iter9638) ([92m↓6.12%[0m) [0.17% of initial]
[Iter 13460/20000] Loss: 0.0002223 (Best: 0.0001746 @iter13387) ([91m↑2.58%[0m) [0.09% of initial]
[Iter 9730/20000] Loss: 0.0003945 (Best: 0.0003326 @iter9638) ([92m↓8.77%[0m) [0.16% of initial]
[Iter 13470/20000] Loss: 0.0002045 (Best: 0.0001746 @iter13387) ([92m↓7.99%[0m) [0.08% of initial]
[Iter 9740/20000] Loss: 0.0004101 (Best: 0.0003326 @iter9638) ([91m↑3.96%[0m) [0.16% of initial]
[Iter 13480/20000] Loss: 0.0002538 (Best: 0.0001746 @iter13387) ([91m↑24.09%[0m) [0.10% of initial]
[Iter 13490/20000] Loss: 0.0002642 (Best: 0.0001746 @iter13387) ([91m↑4.11%[0m) [0.10% of initial]
[Iter 9750/20000] Loss: 0.0004027 (Best: 0.0003326 @iter9638) ([92m↓1.80%[0m) [0.16% of initial]
Iter:13499, L1 loss=0.0002638, Total loss=0.0002279, Time:72
[Iter 13500/20000] Loss: 0.0002549 (Best: 0.0001746 @iter13387) ([92m↓3.50%[0m) [0.10% of initial]
[Iter 9760/20000] Loss: 0.0003763 (Best: 0.0003326 @iter9638) ([92m↓6.55%[0m) [0.15% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 13500
Pruning 4 points (0.0%) from gaussian1 at iteration 13500
[Iter 9770/20000] Loss: 0.0003806 (Best: 0.0003326 @iter9638) ([91m↑1.15%[0m) [0.15% of initial]
[Iter 13510/20000] Loss: 0.0005611 (Best: 0.0001746 @iter13387) ([91m↑120.11%[0m) [0.22% of initial]
[Iter 9780/20000] Loss: 0.0003711 (Best: 0.0003326 @iter9638) ([92m↓2.50%[0m) [0.15% of initial]
[Iter 13520/20000] Loss: 0.0003633 (Best: 0.0001746 @iter13387) ([92m↓35.26%[0m) [0.14% of initial]
[Iter 9790/20000] Loss: 0.0003732 (Best: 0.0003250 @iter9784) ([91m↑0.55%[0m) [0.15% of initial]
[Iter 13530/20000] Loss: 0.0002893 (Best: 0.0001746 @iter13387) ([92m↓20.36%[0m) [0.11% of initial]
Iter:9799, L1 loss=0.0004406, Total loss=0.0003805, Time:107
[Iter 9800/20000] Loss: 0.0004058 (Best: 0.0003250 @iter9784) ([91m↑8.74%[0m) [0.16% of initial]
[Iter 13540/20000] Loss: 0.0002514 (Best: 0.0001746 @iter13387) ([92m↓13.10%[0m) [0.10% of initial]
[Iter 13550/20000] Loss: 0.0002555 (Best: 0.0001746 @iter13387) ([91m↑1.62%[0m) [0.10% of initial]
[Iter 9810/20000] Loss: 0.0003764 (Best: 0.0003250 @iter9784) ([92m↓7.24%[0m) [0.15% of initial]
[Iter 13560/20000] Loss: 0.0002556 (Best: 0.0001746 @iter13387) ([91m↑0.02%[0m) [0.10% of initial]
[Iter 9820/20000] Loss: 0.0003641 (Best: 0.0003250 @iter9784) ([92m↓3.28%[0m) [0.14% of initial]
[Iter 13570/20000] Loss: 0.0002104 (Best: 0.0001746 @iter13387) ([92m↓17.68%[0m) [0.08% of initial]
[Iter 9830/20000] Loss: 0.0003900 (Best: 0.0003250 @iter9784) ([91m↑7.13%[0m) [0.15% of initial]
[Iter 13580/20000] Loss: 0.0002380 (Best: 0.0001746 @iter13387) ([91m↑13.14%[0m) [0.09% of initial]
[Iter 13590/20000] Loss: 0.0001917 (Best: 0.0001746 @iter13387) ([92m↓19.47%[0m) [0.08% of initial]
[Iter 9840/20000] Loss: 0.0004015 (Best: 0.0003250 @iter9784) ([91m↑2.94%[0m) [0.16% of initial]
Iter:13599, L1 loss=0.0002677, Total loss=0.0002314, Time:83
[Iter 13600/20000] Loss: 0.0002001 (Best: 0.0001709 @iter13594) ([91m↑4.37%[0m) [0.08% of initial]
[Iter 9850/20000] Loss: 0.0003739 (Best: 0.0003250 @iter9784) ([92m↓6.87%[0m) [0.15% of initial]
[Iter 13610/20000] Loss: 0.0001890 (Best: 0.0001709 @iter13594) ([92m↓5.54%[0m) [0.08% of initial]
[Iter 9860/20000] Loss: 0.0003764 (Best: 0.0003250 @iter9784) ([91m↑0.66%[0m) [0.15% of initial]
[Iter 13620/20000] Loss: 0.0001930 (Best: 0.0001709 @iter13594) ([91m↑2.15%[0m) [0.08% of initial]
[Iter 9870/20000] Loss: 0.0004011 (Best: 0.0003250 @iter9784) ([91m↑6.57%[0m) [0.16% of initial]
[Iter 13630/20000] Loss: 0.0001911 (Best: 0.0001709 @iter13594) ([92m↓0.98%[0m) [0.08% of initial]
[Iter 9880/20000] Loss: 0.0004186 (Best: 0.0003250 @iter9784) ([91m↑4.35%[0m) [0.17% of initial]
[Iter 13640/20000] Loss: 0.0002009 (Best: 0.0001709 @iter13594) ([91m↑5.13%[0m) [0.08% of initial]
[Iter 9890/20000] Loss: 0.0005384 (Best: 0.0003250 @iter9784) ([91m↑28.64%[0m) [0.21% of initial]
[Iter 13650/20000] Loss: 0.0002187 (Best: 0.0001709 @iter13594) ([91m↑8.86%[0m) [0.09% of initial]
Iter:9899, L1 loss=0.0005815, Total loss=0.0005123, Time:106
[Iter 9900/20000] Loss: 0.0004964 (Best: 0.0003250 @iter9784) ([92m↓7.80%[0m) [0.20% of initial]
[Iter 13660/20000] Loss: 0.0002135 (Best: 0.0001709 @iter13594) ([92m↓2.39%[0m) [0.08% of initial]
[Iter 13670/20000] Loss: 0.0002075 (Best: 0.0001709 @iter13594) ([92m↓2.82%[0m) [0.08% of initial]
[Iter 9910/20000] Loss: 0.0004039 (Best: 0.0003250 @iter9784) ([92m↓18.65%[0m) [0.16% of initial]
[Iter 13680/20000] Loss: 0.0002188 (Best: 0.0001709 @iter13594) ([91m↑5.44%[0m) [0.09% of initial]
[Iter 9920/20000] Loss: 0.0003843 (Best: 0.0003250 @iter9784) ([92m↓4.84%[0m) [0.15% of initial]
[Iter 13690/20000] Loss: 0.0002337 (Best: 0.0001709 @iter13594) ([91m↑6.84%[0m) [0.09% of initial]
[Iter 9930/20000] Loss: 0.0004039 (Best: 0.0003250 @iter9784) ([91m↑5.10%[0m) [0.16% of initial]
Iter:13699, L1 loss=0.0002509, Total loss=0.0002064, Time:86
[Iter 13700/20000] Loss: 0.0002228 (Best: 0.0001709 @iter13594) ([92m↓4.68%[0m) [0.09% of initial]
[Iter 9940/20000] Loss: 0.0003877 (Best: 0.0003250 @iter9784) ([92m↓4.03%[0m) [0.15% of initial]
[Iter 13710/20000] Loss: 0.0002199 (Best: 0.0001709 @iter13594) ([92m↓1.28%[0m) [0.09% of initial]
[Iter 9950/20000] Loss: 0.0004252 (Best: 0.0003250 @iter9784) ([91m↑9.68%[0m) [0.17% of initial]
[Iter 13720/20000] Loss: 0.0002064 (Best: 0.0001709 @iter13594) ([92m↓6.18%[0m) [0.08% of initial]
[Iter 9960/20000] Loss: 0.0004174 (Best: 0.0003250 @iter9784) ([92m↓1.82%[0m) [0.17% of initial]
[Iter 13730/20000] Loss: 0.0001918 (Best: 0.0001709 @iter13594) ([92m↓7.04%[0m) [0.08% of initial]
[Iter 9970/20000] Loss: 0.0003997 (Best: 0.0003250 @iter9784) ([92m↓4.23%[0m) [0.16% of initial]
[Iter 13740/20000] Loss: 0.0001935 (Best: 0.0001709 @iter13594) ([91m↑0.88%[0m) [0.08% of initial]
[Iter 9980/20000] Loss: 0.0003868 (Best: 0.0003250 @iter9784) ([92m↓3.23%[0m) [0.15% of initial]
[Iter 13750/20000] Loss: 0.0002189 (Best: 0.0001709 @iter13594) ([91m↑13.12%[0m) [0.09% of initial]
[Iter 9990/20000] Loss: 0.0004008 (Best: 0.0003250 @iter9784) ([91m↑3.62%[0m) [0.16% of initial]
[Iter 13760/20000] Loss: 0.0002277 (Best: 0.0001709 @iter13594) ([91m↑3.99%[0m) [0.09% of initial]
Iter:9999, L1 loss=0.0005826, Total loss=0.0005244, Time:103
[Iter 10000/20000] Loss: 0.0004643 (Best: 0.0003250 @iter9784) ([91m↑15.83%[0m) [0.18% of initial]
[Iter 13770/20000] Loss: 0.0002426 (Best: 0.0001709 @iter13594) ([91m↑6.56%[0m) [0.10% of initial]
Pruning 32 points (0.0%) from gaussian0 at iteration 10000
Pruning 27 points (0.0%) from gaussian1 at iteration 10000
[Iter 13780/20000] Loss: 0.0002157 (Best: 0.0001709 @iter13594) ([92m↓11.10%[0m) [0.09% of initial]
[Iter 10010/20000] Loss: 0.0385818 (Best: 0.0003250 @iter9784) ([91m↑8210.00%[0m) [15.33% of initial]
[Iter 13790/20000] Loss: 0.0002044 (Best: 0.0001709 @iter13594) ([92m↓5.21%[0m) [0.08% of initial]
[Iter 10020/20000] Loss: 0.0135830 (Best: 0.0003250 @iter9784) ([92m↓64.79%[0m) [5.40% of initial]
Iter:13799, L1 loss=0.0002358, Total loss=0.0002135, Time:95
[Iter 13800/20000] Loss: 0.0002025 (Best: 0.0001709 @iter13594) ([92m↓0.96%[0m) [0.08% of initial]
[Iter 10030/20000] Loss: 0.0060414 (Best: 0.0003250 @iter9784) ([92m↓55.52%[0m) [2.40% of initial]
[Iter 13810/20000] Loss: 0.0002006 (Best: 0.0001709 @iter13594) ([92m↓0.93%[0m) [0.08% of initial]
[Iter 10040/20000] Loss: 0.0035729 (Best: 0.0003250 @iter9784) ([92m↓40.86%[0m) [1.42% of initial]
[Iter 13820/20000] Loss: 0.0002022 (Best: 0.0001709 @iter13594) ([91m↑0.81%[0m) [0.08% of initial]
[Iter 10050/20000] Loss: 0.0023049 (Best: 0.0003250 @iter9784) ([92m↓35.49%[0m) [0.92% of initial]
[Iter 13830/20000] Loss: 0.0002702 (Best: 0.0001709 @iter13594) ([91m↑33.64%[0m) [0.11% of initial]
[Iter 10060/20000] Loss: 0.0015873 (Best: 0.0003250 @iter9784) ([92m↓31.14%[0m) [0.63% of initial]
[Iter 13840/20000] Loss: 0.0002933 (Best: 0.0001709 @iter13594) ([91m↑8.55%[0m) [0.12% of initial]
[Iter 10070/20000] Loss: 0.0012594 (Best: 0.0003250 @iter9784) ([92m↓20.66%[0m) [0.50% of initial]
[Iter 13850/20000] Loss: 0.0002465 (Best: 0.0001709 @iter13594) ([92m↓15.97%[0m) [0.10% of initial]
[Iter 10080/20000] Loss: 0.0010032 (Best: 0.0003250 @iter9784) ([92m↓20.34%[0m) [0.40% of initial]
[Iter 13860/20000] Loss: 0.0002617 (Best: 0.0001709 @iter13594) ([91m↑6.16%[0m) [0.10% of initial]
[Iter 10090/20000] Loss: 0.0008812 (Best: 0.0003250 @iter9784) ([92m↓12.16%[0m) [0.35% of initial]
Iter:10099, L1 loss=0.0007233, Total loss=0.0007035, Time:88
[Iter 13870/20000] Loss: 0.0002265 (Best: 0.0001709 @iter13594) ([92m↓13.46%[0m) [0.09% of initial]
[Iter 10100/20000] Loss: 0.0007678 (Best: 0.0003250 @iter9784) ([92m↓12.87%[0m) [0.31% of initial]
[Iter 10110/20000] Loss: 0.0007113 (Best: 0.0003250 @iter9784) ([92m↓7.36%[0m) [0.28% of initial]
[Iter 13880/20000] Loss: 0.0002007 (Best: 0.0001709 @iter13594) ([92m↓11.38%[0m) [0.08% of initial]
[Iter 10120/20000] Loss: 0.0006847 (Best: 0.0003250 @iter9784) ([92m↓3.74%[0m) [0.27% of initial]
[Iter 13890/20000] Loss: 0.0002013 (Best: 0.0001709 @iter13594) ([91m↑0.29%[0m) [0.08% of initial]
[Iter 10130/20000] Loss: 0.0006325 (Best: 0.0003250 @iter9784) ([92m↓7.63%[0m) [0.25% of initial]
Iter:13899, L1 loss=0.0002295, Total loss=0.0002033, Time:75
[Iter 13900/20000] Loss: 0.0001899 (Best: 0.0001700 @iter13897) ([92m↓5.64%[0m) [0.08% of initial]
[Iter 10140/20000] Loss: 0.0006114 (Best: 0.0003250 @iter9784) ([92m↓3.33%[0m) [0.24% of initial]
[Iter 13910/20000] Loss: 0.0002264 (Best: 0.0001700 @iter13897) ([91m↑19.18%[0m) [0.09% of initial]
[Iter 10150/20000] Loss: 0.0005807 (Best: 0.0003250 @iter9784) ([92m↓5.02%[0m) [0.23% of initial]
[Iter 13920/20000] Loss: 0.0002657 (Best: 0.0001700 @iter13897) ([91m↑17.37%[0m) [0.11% of initial]
[Iter 10160/20000] Loss: 0.0005564 (Best: 0.0003250 @iter9784) ([92m↓4.19%[0m) [0.22% of initial]
[Iter 13930/20000] Loss: 0.0002858 (Best: 0.0001700 @iter13897) ([91m↑7.58%[0m) [0.11% of initial]
[Iter 10170/20000] Loss: 0.0005317 (Best: 0.0003250 @iter9784) ([92m↓4.44%[0m) [0.21% of initial]
[Iter 13940/20000] Loss: 0.0002229 (Best: 0.0001700 @iter13897) ([92m↓22.02%[0m) [0.09% of initial]
[Iter 10180/20000] Loss: 0.0005386 (Best: 0.0003250 @iter9784) ([91m↑1.30%[0m) [0.21% of initial]
[Iter 13950/20000] Loss: 0.0002262 (Best: 0.0001700 @iter13897) ([91m↑1.48%[0m) [0.09% of initial]
[Iter 10190/20000] Loss: 0.0005199 (Best: 0.0003250 @iter9784) ([92m↓3.47%[0m) [0.21% of initial]
Iter:10199, L1 loss=0.0005287, Total loss=0.000489, Time:78
[Iter 13960/20000] Loss: 0.0002094 (Best: 0.0001700 @iter13897) ([92m↓7.41%[0m) [0.08% of initial]
[Iter 10200/20000] Loss: 0.0005289 (Best: 0.0003250 @iter9784) ([91m↑1.72%[0m) [0.21% of initial]
[Iter 10210/20000] Loss: 0.0005195 (Best: 0.0003250 @iter9784) ([92m↓1.77%[0m) [0.21% of initial]
[Iter 13970/20000] Loss: 0.0001927 (Best: 0.0001700 @iter13897) ([92m↓7.96%[0m) [0.08% of initial]
[Iter 10220/20000] Loss: 0.0005168 (Best: 0.0003250 @iter9784) ([92m↓0.52%[0m) [0.21% of initial]
[Iter 13980/20000] Loss: 0.0002199 (Best: 0.0001700 @iter13897) ([91m↑14.08%[0m) [0.09% of initial]
[Iter 10230/20000] Loss: 0.0004974 (Best: 0.0003250 @iter9784) ([92m↓3.75%[0m) [0.20% of initial]
[Iter 13990/20000] Loss: 0.0002111 (Best: 0.0001700 @iter13897) ([92m↓3.98%[0m) [0.08% of initial]
[Iter 10240/20000] Loss: 0.0004803 (Best: 0.0003250 @iter9784) ([92m↓3.45%[0m) [0.19% of initial]
Iter:13999, L1 loss=0.0002438, Total loss=0.000208, Time:72
[Iter 14000/20000] Loss: 0.0002126 (Best: 0.0001700 @iter13897) ([91m↑0.71%[0m) [0.08% of initial]
[Iter 10250/20000] Loss: 0.0005122 (Best: 0.0003250 @iter9784) ([91m↑6.65%[0m) [0.20% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 14000
Pruning 2 points (0.0%) from gaussian1 at iteration 14000
[Iter 10260/20000] Loss: 0.0005040 (Best: 0.0003250 @iter9784) ([92m↓1.61%[0m) [0.20% of initial]
[Iter 10270/20000] Loss: 0.0004751 (Best: 0.0003250 @iter9784) ([92m↓5.73%[0m) [0.19% of initial]
[Iter 14010/20000] Loss: 0.0004122 (Best: 0.0001700 @iter13897) ([91m↑93.90%[0m) [0.16% of initial]
[Iter 10280/20000] Loss: 0.0004931 (Best: 0.0003250 @iter9784) ([91m↑3.78%[0m) [0.20% of initial]
[Iter 14020/20000] Loss: 0.0002832 (Best: 0.0001700 @iter13897) ([92m↓31.29%[0m) [0.11% of initial]
[Iter 10290/20000] Loss: 0.0005339 (Best: 0.0003250 @iter9784) ([91m↑8.28%[0m) [0.21% of initial]
[Iter 14030/20000] Loss: 0.0002374 (Best: 0.0001700 @iter13897) ([92m↓16.17%[0m) [0.09% of initial]
Iter:10299, L1 loss=0.0005355, Total loss=0.0004937, Time:68
[Iter 10300/20000] Loss: 0.0004891 (Best: 0.0003250 @iter9784) ([92m↓8.40%[0m) [0.19% of initial]
[Iter 14040/20000] Loss: 0.0002114 (Best: 0.0001700 @iter13897) ([92m↓10.96%[0m) [0.08% of initial]
[Iter 10310/20000] Loss: 0.0004877 (Best: 0.0003250 @iter9784) ([92m↓0.27%[0m) [0.19% of initial]
[Iter 14050/20000] Loss: 0.0002329 (Best: 0.0001700 @iter13897) ([91m↑10.14%[0m) [0.09% of initial]
[Iter 10320/20000] Loss: 0.0005074 (Best: 0.0003250 @iter9784) ([91m↑4.02%[0m) [0.20% of initial]
[Iter 14060/20000] Loss: 0.0002401 (Best: 0.0001700 @iter13897) ([91m↑3.12%[0m) [0.10% of initial]
[Iter 10330/20000] Loss: 0.0004807 (Best: 0.0003250 @iter9784) ([92m↓5.25%[0m) [0.19% of initial]
[Iter 14070/20000] Loss: 0.0002777 (Best: 0.0001700 @iter13897) ([91m↑15.66%[0m) [0.11% of initial]
[Iter 10340/20000] Loss: 0.0004813 (Best: 0.0003250 @iter9784) ([91m↑0.11%[0m) [0.19% of initial]
[Iter 14080/20000] Loss: 0.0002182 (Best: 0.0001700 @iter13897) ([92m↓21.43%[0m) [0.09% of initial]
[Iter 10350/20000] Loss: 0.0004605 (Best: 0.0003250 @iter9784) ([92m↓4.32%[0m) [0.18% of initial]
[Iter 10360/20000] Loss: 0.0004547 (Best: 0.0003250 @iter9784) ([92m↓1.25%[0m) [0.18% of initial]
[Iter 14090/20000] Loss: 0.0002245 (Best: 0.0001700 @iter13897) ([91m↑2.87%[0m) [0.09% of initial]
[Iter 10370/20000] Loss: 0.0004537 (Best: 0.0003250 @iter9784) ([92m↓0.22%[0m) [0.18% of initial]
Iter:14099, L1 loss=0.0002848, Total loss=0.0002214, Time:71
[Iter 14100/20000] Loss: 0.0002214 (Best: 0.0001700 @iter13897) ([92m↓1.36%[0m) [0.09% of initial]
[Iter 10380/20000] Loss: 0.0004748 (Best: 0.0003250 @iter9784) ([91m↑4.64%[0m) [0.19% of initial]
[Iter 14110/20000] Loss: 0.0001902 (Best: 0.0001700 @iter13897) ([92m↓14.10%[0m) [0.08% of initial]
[Iter 10390/20000] Loss: 0.0004646 (Best: 0.0003250 @iter9784) ([92m↓2.14%[0m) [0.18% of initial]
[Iter 14120/20000] Loss: 0.0001944 (Best: 0.0001700 @iter13897) ([91m↑2.21%[0m) [0.08% of initial]
Iter:10399, L1 loss=0.0004804, Total loss=0.0004329, Time:91
[Iter 10400/20000] Loss: 0.0004599 (Best: 0.0003250 @iter9784) ([92m↓1.02%[0m) [0.18% of initial]
[Iter 14130/20000] Loss: 0.0002253 (Best: 0.0001700 @iter13897) ([91m↑15.89%[0m) [0.09% of initial]
[Iter 10410/20000] Loss: 0.0004589 (Best: 0.0003250 @iter9784) ([92m↓0.22%[0m) [0.18% of initial]
[Iter 14140/20000] Loss: 0.0002610 (Best: 0.0001700 @iter13897) ([91m↑15.81%[0m) [0.10% of initial]
[Iter 10420/20000] Loss: 0.0004604 (Best: 0.0003250 @iter9784) ([91m↑0.33%[0m) [0.18% of initial]
[Iter 14150/20000] Loss: 0.0002359 (Best: 0.0001700 @iter13897) ([92m↓9.62%[0m) [0.09% of initial]
[Iter 10430/20000] Loss: 0.0004432 (Best: 0.0003250 @iter9784) ([92m↓3.74%[0m) [0.18% of initial]
[Iter 14160/20000] Loss: 0.0002201 (Best: 0.0001700 @iter13897) ([92m↓6.70%[0m) [0.09% of initial]
[Iter 10440/20000] Loss: 0.0004526 (Best: 0.0003250 @iter9784) ([91m↑2.14%[0m) [0.18% of initial]
[Iter 14170/20000] Loss: 0.0001945 (Best: 0.0001700 @iter13897) ([92m↓11.60%[0m) [0.08% of initial]
[Iter 10450/20000] Loss: 0.0004657 (Best: 0.0003250 @iter9784) ([91m↑2.89%[0m) [0.19% of initial]
[Iter 14180/20000] Loss: 0.0001834 (Best: 0.0001657 @iter14176) ([92m↓5.70%[0m) [0.07% of initial]
[Iter 10460/20000] Loss: 0.0004614 (Best: 0.0003250 @iter9784) ([92m↓0.93%[0m) [0.18% of initial]
[Iter 14190/20000] Loss: 0.0001843 (Best: 0.0001647 @iter14185) ([91m↑0.47%[0m) [0.07% of initial]
[Iter 10470/20000] Loss: 0.0004656 (Best: 0.0003250 @iter9784) ([91m↑0.92%[0m) [0.18% of initial]
Iter:14199, L1 loss=0.0002029, Total loss=0.0001757, Time:72
[Iter 14200/20000] Loss: 0.0001692 (Best: 0.0001590 @iter14200) ([92m↓8.22%[0m) [0.07% of initial]
[Iter 10480/20000] Loss: 0.0004591 (Best: 0.0003250 @iter9784) ([92m↓1.39%[0m) [0.18% of initial]
[Iter 10490/20000] Loss: 0.0004290 (Best: 0.0003250 @iter9784) ([92m↓6.56%[0m) [0.17% of initial]
[Iter 14210/20000] Loss: 0.0001926 (Best: 0.0001590 @iter14200) ([91m↑13.83%[0m) [0.08% of initial]
Iter:10499, L1 loss=0.000496, Total loss=0.0004523, Time:76
[Iter 10500/20000] Loss: 0.0004616 (Best: 0.0003250 @iter9784) ([91m↑7.58%[0m) [0.18% of initial]
[Iter 14220/20000] Loss: 0.0002330 (Best: 0.0001590 @iter14200) ([91m↑21.01%[0m) [0.09% of initial]
Pruning 49 points (0.0%) from gaussian0 at iteration 10500
[Iter 14230/20000] Loss: 0.0002348 (Best: 0.0001590 @iter14200) ([91m↑0.78%[0m) [0.09% of initial]
Pruning 40 points (0.0%) from gaussian1 at iteration 10500
[Iter 14240/20000] Loss: 0.0002061 (Best: 0.0001590 @iter14200) ([92m↓12.24%[0m) [0.08% of initial]
[Iter 10510/20000] Loss: 0.0010333 (Best: 0.0003250 @iter9784) ([91m↑123.86%[0m) [0.41% of initial]
[Iter 14250/20000] Loss: 0.0001926 (Best: 0.0001590 @iter14200) ([92m↓6.57%[0m) [0.08% of initial]
[Iter 10520/20000] Loss: 0.0007113 (Best: 0.0003250 @iter9784) ([92m↓31.16%[0m) [0.28% of initial]
[Iter 10530/20000] Loss: 0.0005965 (Best: 0.0003250 @iter9784) ([92m↓16.14%[0m) [0.24% of initial]
[Iter 14260/20000] Loss: 0.0002013 (Best: 0.0001590 @iter14200) ([91m↑4.55%[0m) [0.08% of initial]
[Iter 10540/20000] Loss: 0.0005189 (Best: 0.0003250 @iter9784) ([92m↓13.00%[0m) [0.21% of initial]
[Iter 14270/20000] Loss: 0.0001935 (Best: 0.0001590 @iter14200) ([92m↓3.90%[0m) [0.08% of initial]
[Iter 10550/20000] Loss: 0.0004915 (Best: 0.0003250 @iter9784) ([92m↓5.28%[0m) [0.20% of initial]
[Iter 14280/20000] Loss: 0.0002053 (Best: 0.0001590 @iter14200) ([91m↑6.13%[0m) [0.08% of initial]
[Iter 10560/20000] Loss: 0.0004914 (Best: 0.0003250 @iter9784) ([92m↓0.01%[0m) [0.20% of initial]
[Iter 14290/20000] Loss: 0.0002218 (Best: 0.0001590 @iter14200) ([91m↑8.04%[0m) [0.09% of initial]
[Iter 10570/20000] Loss: 0.0004718 (Best: 0.0003250 @iter9784) ([92m↓4.00%[0m) [0.19% of initial]
Iter:14299, L1 loss=0.0002424, Total loss=0.0002097, Time:84
[Iter 14300/20000] Loss: 0.0001933 (Best: 0.0001590 @iter14200) ([92m↓12.84%[0m) [0.08% of initial]
[Iter 10580/20000] Loss: 0.0004564 (Best: 0.0003250 @iter9784) ([92m↓3.25%[0m) [0.18% of initial]
[Iter 14310/20000] Loss: 0.0002316 (Best: 0.0001590 @iter14200) ([91m↑19.80%[0m) [0.09% of initial]
[Iter 10590/20000] Loss: 0.0004620 (Best: 0.0003250 @iter9784) ([91m↑1.21%[0m) [0.18% of initial]
[Iter 14320/20000] Loss: 0.0002030 (Best: 0.0001590 @iter14200) ([92m↓12.37%[0m) [0.08% of initial]
Iter:10599, L1 loss=0.0005458, Total loss=0.0005032, Time:65
[Iter 10600/20000] Loss: 0.0004569 (Best: 0.0003250 @iter9784) ([92m↓1.09%[0m) [0.18% of initial]
[Iter 14330/20000] Loss: 0.0002031 (Best: 0.0001590 @iter14200) ([91m↑0.07%[0m) [0.08% of initial]
[Iter 10610/20000] Loss: 0.0004657 (Best: 0.0003250 @iter9784) ([91m↑1.92%[0m) [0.19% of initial]
[Iter 14340/20000] Loss: 0.0002394 (Best: 0.0001590 @iter14200) ([91m↑17.85%[0m) [0.10% of initial]
[Iter 10620/20000] Loss: 0.0004992 (Best: 0.0003250 @iter9784) ([91m↑7.19%[0m) [0.20% of initial]
[Iter 14350/20000] Loss: 0.0002176 (Best: 0.0001590 @iter14200) ([92m↓9.09%[0m) [0.09% of initial]
[Iter 10630/20000] Loss: 0.0005113 (Best: 0.0003250 @iter9784) ([91m↑2.43%[0m) [0.20% of initial]
[Iter 14360/20000] Loss: 0.0002020 (Best: 0.0001590 @iter14200) ([92m↓7.16%[0m) [0.08% of initial]
[Iter 10640/20000] Loss: 0.0005079 (Best: 0.0003250 @iter9784) ([92m↓0.68%[0m) [0.20% of initial]
[Iter 14370/20000] Loss: 0.0002252 (Best: 0.0001590 @iter14200) ([91m↑11.47%[0m) [0.09% of initial]
[Iter 10650/20000] Loss: 0.0004915 (Best: 0.0003250 @iter9784) ([92m↓3.21%[0m) [0.20% of initial]
[Iter 14380/20000] Loss: 0.0002467 (Best: 0.0001590 @iter14200) ([91m↑9.56%[0m) [0.10% of initial]
[Iter 10660/20000] Loss: 0.0005011 (Best: 0.0003250 @iter9784) ([91m↑1.94%[0m) [0.20% of initial]
[Iter 10670/20000] Loss: 0.0004835 (Best: 0.0003250 @iter9784) ([92m↓3.50%[0m) [0.19% of initial]
[Iter 14390/20000] Loss: 0.0002972 (Best: 0.0001590 @iter14200) ([91m↑20.46%[0m) [0.12% of initial]
[Iter 10680/20000] Loss: 0.0004710 (Best: 0.0003250 @iter9784) ([92m↓2.59%[0m) [0.19% of initial]
Iter:14399, L1 loss=0.0002561, Total loss=0.0002181, Time:67
[Iter 14400/20000] Loss: 0.0002385 (Best: 0.0001590 @iter14200) ([92m↓19.76%[0m) [0.09% of initial]
[Iter 10690/20000] Loss: 0.0004906 (Best: 0.0003250 @iter9784) ([91m↑4.16%[0m) [0.19% of initial]
[Iter 14410/20000] Loss: 0.0002232 (Best: 0.0001590 @iter14200) ([92m↓6.41%[0m) [0.09% of initial]
Iter:10699, L1 loss=0.0005387, Total loss=0.0004892, Time:82
[Iter 10700/20000] Loss: 0.0004717 (Best: 0.0003250 @iter9784) ([92m↓3.84%[0m) [0.19% of initial]
[Iter 14420/20000] Loss: 0.0002044 (Best: 0.0001590 @iter14200) ([92m↓8.42%[0m) [0.08% of initial]
[Iter 10710/20000] Loss: 0.0005208 (Best: 0.0003250 @iter9784) ([91m↑10.40%[0m) [0.21% of initial]
[Iter 14430/20000] Loss: 0.0002254 (Best: 0.0001590 @iter14200) ([91m↑10.27%[0m) [0.09% of initial]
[Iter 10720/20000] Loss: 0.0004845 (Best: 0.0003250 @iter9784) ([92m↓6.97%[0m) [0.19% of initial]
[Iter 14440/20000] Loss: 0.0001925 (Best: 0.0001590 @iter14200) ([92m↓14.57%[0m) [0.08% of initial]
[Iter 10730/20000] Loss: 0.0004650 (Best: 0.0003250 @iter9784) ([92m↓4.03%[0m) [0.18% of initial]
[Iter 14450/20000] Loss: 0.0001983 (Best: 0.0001590 @iter14200) ([91m↑3.01%[0m) [0.08% of initial]
[Iter 10740/20000] Loss: 0.0004805 (Best: 0.0003250 @iter9784) ([91m↑3.33%[0m) [0.19% of initial]
[Iter 14460/20000] Loss: 0.0002016 (Best: 0.0001590 @iter14200) ([91m↑1.66%[0m) [0.08% of initial]
[Iter 10750/20000] Loss: 0.0004670 (Best: 0.0003250 @iter9784) ([92m↓2.81%[0m) [0.19% of initial]
[Iter 14470/20000] Loss: 0.0002340 (Best: 0.0001590 @iter14200) ([91m↑16.05%[0m) [0.09% of initial]
[Iter 10760/20000] Loss: 0.0004692 (Best: 0.0003250 @iter9784) ([91m↑0.46%[0m) [0.19% of initial]
[Iter 14480/20000] Loss: 0.0002163 (Best: 0.0001590 @iter14200) ([92m↓7.55%[0m) [0.09% of initial]
[Iter 10770/20000] Loss: 0.0005001 (Best: 0.0003250 @iter9784) ([91m↑6.60%[0m) [0.20% of initial]
[Iter 14490/20000] Loss: 0.0002181 (Best: 0.0001590 @iter14200) ([91m↑0.83%[0m) [0.09% of initial]
[Iter 10780/20000] Loss: 0.0004457 (Best: 0.0003250 @iter9784) ([92m↓10.87%[0m) [0.18% of initial]
Iter:14499, L1 loss=0.0002516, Total loss=0.0002317, Time:89
[Iter 14500/20000] Loss: 0.0002385 (Best: 0.0001590 @iter14200) ([91m↑9.35%[0m) [0.09% of initial]
[Iter 10790/20000] Loss: 0.0004439 (Best: 0.0003250 @iter9784) ([92m↓0.41%[0m) [0.18% of initial]
Iter:10799, L1 loss=0.0005313, Total loss=0.000477, Time:68
[Iter 10800/20000] Loss: 0.0004847 (Best: 0.0003250 @iter9784) ([91m↑9.18%[0m) [0.19% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 14500
Pruning 5 points (0.0%) from gaussian1 at iteration 14500
[Iter 10810/20000] Loss: 0.0004549 (Best: 0.0003250 @iter9784) ([92m↓6.15%[0m) [0.18% of initial]
[Iter 14510/20000] Loss: 0.0004446 (Best: 0.0001590 @iter14200) ([91m↑86.40%[0m) [0.18% of initial]
[Iter 10820/20000] Loss: 0.0004424 (Best: 0.0003250 @iter9784) ([92m↓2.73%[0m) [0.18% of initial]
[Iter 14520/20000] Loss: 0.0003222 (Best: 0.0001590 @iter14200) ([92m↓27.53%[0m) [0.13% of initial]
[Iter 10830/20000] Loss: 0.0004725 (Best: 0.0003250 @iter9784) ([91m↑6.79%[0m) [0.19% of initial]
[Iter 14530/20000] Loss: 0.0002511 (Best: 0.0001590 @iter14200) ([92m↓22.06%[0m) [0.10% of initial]
[Iter 10840/20000] Loss: 0.0004553 (Best: 0.0003250 @iter9784) ([92m↓3.64%[0m) [0.18% of initial]
[Iter 14540/20000] Loss: 0.0001959 (Best: 0.0001590 @iter14200) ([92m↓21.98%[0m) [0.08% of initial]
[Iter 10850/20000] Loss: 0.0004365 (Best: 0.0003250 @iter9784) ([92m↓4.14%[0m) [0.17% of initial]
[Iter 14550/20000] Loss: 0.0001953 (Best: 0.0001590 @iter14200) ([92m↓0.30%[0m) [0.08% of initial]
[Iter 10860/20000] Loss: 0.0004569 (Best: 0.0003250 @iter9784) ([91m↑4.68%[0m) [0.18% of initial]
[Iter 14560/20000] Loss: 0.0001860 (Best: 0.0001590 @iter14200) ([92m↓4.80%[0m) [0.07% of initial]
[Iter 10870/20000] Loss: 0.0004867 (Best: 0.0003250 @iter9784) ([91m↑6.52%[0m) [0.19% of initial]
[Iter 14570/20000] Loss: 0.0001780 (Best: 0.0001574 @iter14566) ([92m↓4.31%[0m) [0.07% of initial]
[Iter 10880/20000] Loss: 0.0005098 (Best: 0.0003250 @iter9784) ([91m↑4.76%[0m) [0.20% of initial]
[Iter 10890/20000] Loss: 0.0004588 (Best: 0.0003250 @iter9784) ([92m↓10.01%[0m) [0.18% of initial]
[Iter 14580/20000] Loss: 0.0001888 (Best: 0.0001574 @iter14566) ([91m↑6.12%[0m) [0.08% of initial]
Iter:10899, L1 loss=0.000466, Total loss=0.0004345, Time:71
[Iter 10900/20000] Loss: 0.0004384 (Best: 0.0003250 @iter9784) ([92m↓4.45%[0m) [0.17% of initial]
[Iter 14590/20000] Loss: 0.0001898 (Best: 0.0001574 @iter14566) ([91m↑0.48%[0m) [0.08% of initial]
[Iter 10910/20000] Loss: 0.0004382 (Best: 0.0003250 @iter9784) ([92m↓0.04%[0m) [0.17% of initial]
Iter:14599, L1 loss=0.0002488, Total loss=0.0002034, Time:76
[Iter 14600/20000] Loss: 0.0002124 (Best: 0.0001574 @iter14566) ([91m↑11.93%[0m) [0.08% of initial]
[Iter 10920/20000] Loss: 0.0004640 (Best: 0.0003250 @iter9784) ([91m↑5.89%[0m) [0.18% of initial]
[Iter 14610/20000] Loss: 0.0002282 (Best: 0.0001574 @iter14566) ([91m↑7.46%[0m) [0.09% of initial]
[Iter 10930/20000] Loss: 0.0004422 (Best: 0.0003250 @iter9784) ([92m↓4.70%[0m) [0.18% of initial]
[Iter 14620/20000] Loss: 0.0002253 (Best: 0.0001574 @iter14566) ([92m↓1.30%[0m) [0.09% of initial]
[Iter 10940/20000] Loss: 0.0004310 (Best: 0.0003250 @iter9784) ([92m↓2.53%[0m) [0.17% of initial]
[Iter 14630/20000] Loss: 0.0002445 (Best: 0.0001574 @iter14566) ([91m↑8.54%[0m) [0.10% of initial]
[Iter 10950/20000] Loss: 0.0004300 (Best: 0.0003250 @iter9784) ([92m↓0.23%[0m) [0.17% of initial]
[Iter 14640/20000] Loss: 0.0002143 (Best: 0.0001574 @iter14566) ([92m↓12.36%[0m) [0.09% of initial]
[Iter 10960/20000] Loss: 0.0004269 (Best: 0.0003250 @iter9784) ([92m↓0.73%[0m) [0.17% of initial]
[Iter 14650/20000] Loss: 0.0002108 (Best: 0.0001574 @iter14566) ([92m↓1.62%[0m) [0.08% of initial]
[Iter 10970/20000] Loss: 0.0004360 (Best: 0.0003250 @iter9784) ([91m↑2.15%[0m) [0.17% of initial]
[Iter 14660/20000] Loss: 0.0002598 (Best: 0.0001574 @iter14566) ([91m↑23.23%[0m) [0.10% of initial]
[Iter 10980/20000] Loss: 0.0004445 (Best: 0.0003250 @iter9784) ([91m↑1.95%[0m) [0.18% of initial]
[Iter 14670/20000] Loss: 0.0002574 (Best: 0.0001574 @iter14566) ([92m↓0.94%[0m) [0.10% of initial]
[Iter 10990/20000] Loss: 0.0004415 (Best: 0.0003250 @iter9784) ([92m↓0.70%[0m) [0.18% of initial]
[Iter 14680/20000] Loss: 0.0002140 (Best: 0.0001574 @iter14566) ([92m↓16.85%[0m) [0.09% of initial]
Iter:10999, L1 loss=0.0004759, Total loss=0.0004203, Time:76
[Iter 11000/20000] Loss: 0.0004480 (Best: 0.0003250 @iter9784) ([91m↑1.48%[0m) [0.18% of initial]
[Iter 14690/20000] Loss: 0.0002567 (Best: 0.0001574 @iter14566) ([91m↑19.97%[0m) [0.10% of initial]
Pruning 24 points (0.0%) from gaussian0 at iteration 11000
Pruning 32 points (0.0%) from gaussian1 at iteration 11000
Iter:14699, L1 loss=0.0002476, Total loss=0.0002134, Time:75
[Iter 14700/20000] Loss: 0.0002283 (Best: 0.0001574 @iter14566) ([92m↓11.08%[0m) [0.09% of initial]
[Iter 11010/20000] Loss: 0.0009240 (Best: 0.0003250 @iter9784) ([91m↑106.27%[0m) [0.37% of initial]
[Iter 14710/20000] Loss: 0.0002517 (Best: 0.0001574 @iter14566) ([91m↑10.27%[0m) [0.10% of initial]
[Iter 11020/20000] Loss: 0.0006626 (Best: 0.0003250 @iter9784) ([92m↓28.29%[0m) [0.26% of initial]
[Iter 14720/20000] Loss: 0.0002410 (Best: 0.0001574 @iter14566) ([92m↓4.27%[0m) [0.10% of initial]
[Iter 11030/20000] Loss: 0.0005261 (Best: 0.0003250 @iter9784) ([92m↓20.61%[0m) [0.21% of initial]
[Iter 14730/20000] Loss: 0.0002079 (Best: 0.0001574 @iter14566) ([92m↓13.73%[0m) [0.08% of initial]
[Iter 11040/20000] Loss: 0.0004507 (Best: 0.0003250 @iter9784) ([92m↓14.32%[0m) [0.18% of initial]
[Iter 14740/20000] Loss: 0.0002035 (Best: 0.0001574 @iter14566) ([92m↓2.10%[0m) [0.08% of initial]
[Iter 11050/20000] Loss: 0.0004599 (Best: 0.0003250 @iter9784) ([91m↑2.05%[0m) [0.18% of initial]
[Iter 14750/20000] Loss: 0.0002210 (Best: 0.0001574 @iter14566) ([91m↑8.60%[0m) [0.09% of initial]
[Iter 11060/20000] Loss: 0.0004358 (Best: 0.0003250 @iter9784) ([92m↓5.24%[0m) [0.17% of initial]
[Iter 14760/20000] Loss: 0.0002129 (Best: 0.0001574 @iter14566) ([92m↓3.66%[0m) [0.08% of initial]
[Iter 11070/20000] Loss: 0.0004334 (Best: 0.0003250 @iter9784) ([92m↓0.57%[0m) [0.17% of initial]
[Iter 14770/20000] Loss: 0.0002328 (Best: 0.0001574 @iter14566) ([91m↑9.35%[0m) [0.09% of initial]
[Iter 11080/20000] Loss: 0.0004103 (Best: 0.0003250 @iter9784) ([92m↓5.33%[0m) [0.16% of initial]
[Iter 14780/20000] Loss: 0.0001930 (Best: 0.0001574 @iter14566) ([92m↓17.12%[0m) [0.08% of initial]
[Iter 11090/20000] Loss: 0.0003947 (Best: 0.0003250 @iter9784) ([92m↓3.79%[0m) [0.16% of initial]
Iter:11099, L1 loss=0.0004486, Total loss=0.0004163, Time:78
[Iter 14790/20000] Loss: 0.0001973 (Best: 0.0001574 @iter14566) ([91m↑2.25%[0m) [0.08% of initial]
[Iter 11100/20000] Loss: 0.0004080 (Best: 0.0003250 @iter9784) ([91m↑3.37%[0m) [0.16% of initial]
Iter:14799, L1 loss=0.0002116, Total loss=0.0001828, Time:71
[Iter 11110/20000] Loss: 0.0004419 (Best: 0.0003250 @iter9784) ([91m↑8.30%[0m) [0.18% of initial]
[Iter 14800/20000] Loss: 0.0001907 (Best: 0.0001574 @iter14566) ([92m↓3.37%[0m) [0.08% of initial]
[Iter 11120/20000] Loss: 0.0004391 (Best: 0.0003250 @iter9784) ([92m↓0.62%[0m) [0.17% of initial]
[Iter 14810/20000] Loss: 0.0001679 (Best: 0.0001571 @iter14810) ([92m↓11.95%[0m) [0.07% of initial]
[Iter 11130/20000] Loss: 0.0004340 (Best: 0.0003250 @iter9784) ([92m↓1.16%[0m) [0.17% of initial]
[Iter 14820/20000] Loss: 0.0001848 (Best: 0.0001571 @iter14810) ([91m↑10.11%[0m) [0.07% of initial]
[Iter 11140/20000] Loss: 0.0004295 (Best: 0.0003250 @iter9784) ([92m↓1.03%[0m) [0.17% of initial]
[Iter 14830/20000] Loss: 0.0001762 (Best: 0.0001571 @iter14810) ([92m↓4.69%[0m) [0.07% of initial]
[Iter 11150/20000] Loss: 0.0004251 (Best: 0.0003250 @iter9784) ([92m↓1.03%[0m) [0.17% of initial]
[Iter 14840/20000] Loss: 0.0001856 (Best: 0.0001535 @iter14836) ([91m↑5.34%[0m) [0.07% of initial]
[Iter 11160/20000] Loss: 0.0004230 (Best: 0.0003250 @iter9784) ([92m↓0.49%[0m) [0.17% of initial]
[Iter 14850/20000] Loss: 0.0001935 (Best: 0.0001535 @iter14836) ([91m↑4.29%[0m) [0.08% of initial]
[Iter 11170/20000] Loss: 0.0004166 (Best: 0.0003250 @iter9784) ([92m↓1.53%[0m) [0.17% of initial]
[Iter 14860/20000] Loss: 0.0001856 (Best: 0.0001535 @iter14836) ([92m↓4.11%[0m) [0.07% of initial]
[Iter 11180/20000] Loss: 0.0004183 (Best: 0.0003250 @iter9784) ([91m↑0.41%[0m) [0.17% of initial]
[Iter 14870/20000] Loss: 0.0001807 (Best: 0.0001535 @iter14836) ([92m↓2.64%[0m) [0.07% of initial]
[Iter 11190/20000] Loss: 0.0004268 (Best: 0.0003250 @iter9784) ([91m↑2.04%[0m) [0.17% of initial]
[Iter 14880/20000] Loss: 0.0001886 (Best: 0.0001535 @iter14836) ([91m↑4.38%[0m) [0.07% of initial]
Iter:11199, L1 loss=0.0004899, Total loss=0.0004431, Time:75
[Iter 11200/20000] Loss: 0.0004134 (Best: 0.0003250 @iter9784) ([92m↓3.15%[0m) [0.16% of initial]
[Iter 14890/20000] Loss: 0.0001926 (Best: 0.0001535 @iter14836) ([91m↑2.11%[0m) [0.08% of initial]
[Iter 11210/20000] Loss: 0.0004228 (Best: 0.0003250 @iter9784) ([91m↑2.28%[0m) [0.17% of initial]
Iter:14899, L1 loss=0.000231, Total loss=0.0001943, Time:74
[Iter 14900/20000] Loss: 0.0002067 (Best: 0.0001535 @iter14836) ([91m↑7.32%[0m) [0.08% of initial]
[Iter 11220/20000] Loss: 0.0004246 (Best: 0.0003250 @iter9784) ([91m↑0.44%[0m) [0.17% of initial]
[Iter 11230/20000] Loss: 0.0004094 (Best: 0.0003250 @iter9784) ([92m↓3.59%[0m) [0.16% of initial]
[Iter 14910/20000] Loss: 0.0002137 (Best: 0.0001535 @iter14836) ([91m↑3.41%[0m) [0.08% of initial]
[Iter 11240/20000] Loss: 0.0004054 (Best: 0.0003250 @iter9784) ([92m↓0.96%[0m) [0.16% of initial]
[Iter 14920/20000] Loss: 0.0002135 (Best: 0.0001535 @iter14836) ([92m↓0.11%[0m) [0.08% of initial]
[Iter 11250/20000] Loss: 0.0004084 (Best: 0.0003250 @iter9784) ([91m↑0.73%[0m) [0.16% of initial]
[Iter 14930/20000] Loss: 0.0002096 (Best: 0.0001535 @iter14836) ([92m↓1.81%[0m) [0.08% of initial]
[Iter 11260/20000] Loss: 0.0004424 (Best: 0.0003250 @iter9784) ([91m↑8.32%[0m) [0.18% of initial]
[Iter 14940/20000] Loss: 0.0002159 (Best: 0.0001535 @iter14836) ([91m↑2.97%[0m) [0.09% of initial]
[Iter 11270/20000] Loss: 0.0004251 (Best: 0.0003250 @iter9784) ([92m↓3.92%[0m) [0.17% of initial]
[Iter 14950/20000] Loss: 0.0001955 (Best: 0.0001535 @iter14836) ([92m↓9.44%[0m) [0.08% of initial]
[Iter 11280/20000] Loss: 0.0004986 (Best: 0.0003250 @iter9784) ([91m↑17.29%[0m) [0.20% of initial]
[Iter 14960/20000] Loss: 0.0001828 (Best: 0.0001535 @iter14836) ([92m↓6.49%[0m) [0.07% of initial]
[Iter 11290/20000] Loss: 0.0004391 (Best: 0.0003250 @iter9784) ([92m↓11.93%[0m) [0.17% of initial]
[Iter 14970/20000] Loss: 0.0002062 (Best: 0.0001535 @iter14836) ([91m↑12.82%[0m) [0.08% of initial]
Iter:11299, L1 loss=0.0005136, Total loss=0.0004709, Time:72
[Iter 11300/20000] Loss: 0.0004718 (Best: 0.0003250 @iter9784) ([91m↑7.45%[0m) [0.19% of initial]
[Iter 14980/20000] Loss: 0.0002339 (Best: 0.0001535 @iter14836) ([91m↑13.41%[0m) [0.09% of initial]
[Iter 11310/20000] Loss: 0.0005008 (Best: 0.0003250 @iter9784) ([91m↑6.15%[0m) [0.20% of initial]
[Iter 14990/20000] Loss: 0.0002197 (Best: 0.0001535 @iter14836) ([92m↓6.04%[0m) [0.09% of initial]
[Iter 11320/20000] Loss: 0.0005297 (Best: 0.0003250 @iter9784) ([91m↑5.76%[0m) [0.21% of initial]
Iter:14999, L1 loss=0.000235, Total loss=0.0001959, Time:77
[Iter 15000/20000] Loss: 0.0002106 (Best: 0.0001535 @iter14836) ([92m↓4.18%[0m) [0.08% of initial]
[Iter 11330/20000] Loss: 0.0005348 (Best: 0.0003250 @iter9784) ([91m↑0.97%[0m) [0.21% of initial]
[Iter 11340/20000] Loss: 0.0004818 (Best: 0.0003250 @iter9784) ([92m↓9.92%[0m) [0.19% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 15000
Pruning 2 points (0.0%) from gaussian1 at iteration 15000
[Iter 11350/20000] Loss: 0.0004359 (Best: 0.0003250 @iter9784) ([92m↓9.52%[0m) [0.17% of initial]
[Iter 15010/20000] Loss: 0.0004583 (Best: 0.0001535 @iter14836) ([91m↑117.66%[0m) [0.18% of initial]
[Iter 11360/20000] Loss: 0.0004327 (Best: 0.0003250 @iter9784) ([92m↓0.74%[0m) [0.17% of initial]
[Iter 15020/20000] Loss: 0.0002757 (Best: 0.0001535 @iter14836) ([92m↓39.83%[0m) [0.11% of initial]
[Iter 11370/20000] Loss: 0.0004175 (Best: 0.0003250 @iter9784) ([92m↓3.50%[0m) [0.17% of initial]
[Iter 15030/20000] Loss: 0.0002320 (Best: 0.0001535 @iter14836) ([92m↓15.87%[0m) [0.09% of initial]
[Iter 11380/20000] Loss: 0.0004122 (Best: 0.0003250 @iter9784) ([92m↓1.27%[0m) [0.16% of initial]
[Iter 15040/20000] Loss: 0.0002111 (Best: 0.0001535 @iter14836) ([92m↓9.01%[0m) [0.08% of initial]
[Iter 11390/20000] Loss: 0.0004604 (Best: 0.0003250 @iter9784) ([91m↑11.68%[0m) [0.18% of initial]
[Iter 15050/20000] Loss: 0.0002048 (Best: 0.0001535 @iter14836) ([92m↓2.98%[0m) [0.08% of initial]
Iter:11399, L1 loss=0.0004724, Total loss=0.0004258, Time:76
[Iter 11400/20000] Loss: 0.0004306 (Best: 0.0003250 @iter9784) ([92m↓6.47%[0m) [0.17% of initial]
[Iter 15060/20000] Loss: 0.0001870 (Best: 0.0001535 @iter14836) ([92m↓8.70%[0m) [0.07% of initial]
[Iter 11410/20000] Loss: 0.0004177 (Best: 0.0003250 @iter9784) ([92m↓3.00%[0m) [0.17% of initial]
[Iter 11420/20000] Loss: 0.0004180 (Best: 0.0003250 @iter9784) ([91m↑0.09%[0m) [0.17% of initial]
[Iter 15070/20000] Loss: 0.0001851 (Best: 0.0001535 @iter14836) ([92m↓0.99%[0m) [0.07% of initial]
[Iter 11430/20000] Loss: 0.0004162 (Best: 0.0003250 @iter9784) ([92m↓0.44%[0m) [0.17% of initial]
[Iter 15080/20000] Loss: 0.0001913 (Best: 0.0001535 @iter14836) ([91m↑3.35%[0m) [0.08% of initial]
[Iter 11440/20000] Loss: 0.0004450 (Best: 0.0003250 @iter9784) ([91m↑6.92%[0m) [0.18% of initial]
[Iter 15090/20000] Loss: 0.0002192 (Best: 0.0001535 @iter14836) ([91m↑14.54%[0m) [0.09% of initial]
[Iter 11450/20000] Loss: 0.0004665 (Best: 0.0003250 @iter9784) ([91m↑4.84%[0m) [0.19% of initial]
Iter:15099, L1 loss=0.0002643, Total loss=0.0002274, Time:71
[Iter 15100/20000] Loss: 0.0002155 (Best: 0.0001535 @iter14836) ([92m↓1.70%[0m) [0.09% of initial]
[Iter 11460/20000] Loss: 0.0004295 (Best: 0.0003250 @iter9784) ([92m↓7.93%[0m) [0.17% of initial]
[Iter 15110/20000] Loss: 0.0002126 (Best: 0.0001535 @iter14836) ([92m↓1.34%[0m) [0.08% of initial]
[Iter 11470/20000] Loss: 0.0004190 (Best: 0.0003250 @iter9784) ([92m↓2.45%[0m) [0.17% of initial]
[Iter 15120/20000] Loss: 0.0002094 (Best: 0.0001535 @iter14836) ([92m↓1.48%[0m) [0.08% of initial]
[Iter 11480/20000] Loss: 0.0004460 (Best: 0.0003250 @iter9784) ([91m↑6.44%[0m) [0.18% of initial]
[Iter 15130/20000] Loss: 0.0001949 (Best: 0.0001535 @iter14836) ([92m↓6.91%[0m) [0.08% of initial]
[Iter 11490/20000] Loss: 0.0004165 (Best: 0.0003250 @iter9784) ([92m↓6.61%[0m) [0.17% of initial]
[Iter 15140/20000] Loss: 0.0002099 (Best: 0.0001535 @iter14836) ([91m↑7.69%[0m) [0.08% of initial]
Iter:11499, L1 loss=0.0004299, Total loss=0.0003948, Time:73
[Iter 11500/20000] Loss: 0.0003955 (Best: 0.0003250 @iter9784) ([92m↓5.04%[0m) [0.16% of initial]
[Iter 15150/20000] Loss: 0.0001927 (Best: 0.0001535 @iter14836) ([92m↓8.22%[0m) [0.08% of initial]
Pruning 22 points (0.0%) from gaussian0 at iteration 11500
Pruning 25 points (0.0%) from gaussian1 at iteration 11500
[Iter 15160/20000] Loss: 0.0001868 (Best: 0.0001535 @iter14836) ([92m↓3.06%[0m) [0.07% of initial]
[Iter 11510/20000] Loss: 0.0006772 (Best: 0.0003250 @iter9784) ([91m↑71.23%[0m) [0.27% of initial]
[Iter 15170/20000] Loss: 0.0001682 (Best: 0.0001535 @iter15169) ([92m↓9.95%[0m) [0.07% of initial]
[Iter 11520/20000] Loss: 0.0005270 (Best: 0.0003250 @iter9784) ([92m↓22.17%[0m) [0.21% of initial]
[Iter 15180/20000] Loss: 0.0002064 (Best: 0.0001535 @iter15169) ([91m↑22.74%[0m) [0.08% of initial]
[Iter 11530/20000] Loss: 0.0004626 (Best: 0.0003250 @iter9784) ([92m↓12.22%[0m) [0.18% of initial]
[Iter 15190/20000] Loss: 0.0001996 (Best: 0.0001535 @iter15169) ([92m↓3.32%[0m) [0.08% of initial]
[Iter 11540/20000] Loss: 0.0004232 (Best: 0.0003250 @iter9784) ([92m↓8.52%[0m) [0.17% of initial]
Iter:15199, L1 loss=0.0002203, Total loss=0.0001893, Time:74
[Iter 15200/20000] Loss: 0.0001897 (Best: 0.0001535 @iter15169) ([92m↓4.94%[0m) [0.08% of initial]
[Iter 11550/20000] Loss: 0.0004219 (Best: 0.0003250 @iter9784) ([92m↓0.30%[0m) [0.17% of initial]
[Iter 15210/20000] Loss: 0.0002027 (Best: 0.0001535 @iter15169) ([91m↑6.83%[0m) [0.08% of initial]
[Iter 11560/20000] Loss: 0.0004201 (Best: 0.0003250 @iter9784) ([92m↓0.43%[0m) [0.17% of initial]
[Iter 15220/20000] Loss: 0.0001892 (Best: 0.0001535 @iter15169) ([92m↓6.66%[0m) [0.08% of initial]
[Iter 11570/20000] Loss: 0.0004154 (Best: 0.0003250 @iter9784) ([92m↓1.12%[0m) [0.17% of initial]
[Iter 15230/20000] Loss: 0.0001913 (Best: 0.0001535 @iter15169) ([91m↑1.09%[0m) [0.08% of initial]
[Iter 11580/20000] Loss: 0.0003882 (Best: 0.0003250 @iter9784) ([92m↓6.55%[0m) [0.15% of initial]
[Iter 15240/20000] Loss: 0.0002089 (Best: 0.0001535 @iter15169) ([91m↑9.21%[0m) [0.08% of initial]
[Iter 11590/20000] Loss: 0.0003899 (Best: 0.0003250 @iter9784) ([91m↑0.43%[0m) [0.15% of initial]
Iter:11599, L1 loss=0.000405, Total loss=0.0003598, Time:79
[Iter 11600/20000] Loss: 0.0003761 (Best: 0.0003250 @iter9784) ([92m↓3.55%[0m) [0.15% of initial]
[Iter 15250/20000] Loss: 0.0002005 (Best: 0.0001535 @iter15169) ([92m↓4.02%[0m) [0.08% of initial]
[Iter 11610/20000] Loss: 0.0003783 (Best: 0.0003250 @iter9784) ([91m↑0.60%[0m) [0.15% of initial]
[Iter 15260/20000] Loss: 0.0002075 (Best: 0.0001535 @iter15169) ([91m↑3.52%[0m) [0.08% of initial]
[Iter 11620/20000] Loss: 0.0003767 (Best: 0.0003250 @iter9784) ([92m↓0.41%[0m) [0.15% of initial]
[Iter 15270/20000] Loss: 0.0002343 (Best: 0.0001535 @iter15169) ([91m↑12.91%[0m) [0.09% of initial]
[Iter 11630/20000] Loss: 0.0003768 (Best: 0.0003250 @iter9784) ([91m↑0.03%[0m) [0.15% of initial]
[Iter 15280/20000] Loss: 0.0003132 (Best: 0.0001535 @iter15169) ([91m↑33.66%[0m) [0.12% of initial]
[Iter 11640/20000] Loss: 0.0003944 (Best: 0.0003250 @iter9784) ([91m↑4.66%[0m) [0.16% of initial]
[Iter 15290/20000] Loss: 0.0002516 (Best: 0.0001535 @iter15169) ([92m↓19.67%[0m) [0.10% of initial]
[Iter 11650/20000] Loss: 0.0004082 (Best: 0.0003250 @iter9784) ([91m↑3.49%[0m) [0.16% of initial]
Iter:15299, L1 loss=0.0002189, Total loss=0.0001801, Time:67
[Iter 15300/20000] Loss: 0.0002130 (Best: 0.0001535 @iter15169) ([92m↓15.35%[0m) [0.08% of initial]
[Iter 11660/20000] Loss: 0.0004124 (Best: 0.0003250 @iter9784) ([91m↑1.05%[0m) [0.16% of initial]
[Iter 15310/20000] Loss: 0.0001966 (Best: 0.0001535 @iter15169) ([92m↓7.68%[0m) [0.08% of initial]
[Iter 11670/20000] Loss: 0.0004032 (Best: 0.0003250 @iter9784) ([92m↓2.23%[0m) [0.16% of initial]
[Iter 15320/20000] Loss: 0.0001701 (Best: 0.0001535 @iter15169) ([92m↓13.47%[0m) [0.07% of initial]
[Iter 11680/20000] Loss: 0.0003949 (Best: 0.0003250 @iter9784) ([92m↓2.07%[0m) [0.16% of initial]
[Iter 15330/20000] Loss: 0.0002114 (Best: 0.0001535 @iter15169) ([91m↑24.25%[0m) [0.08% of initial]
[Iter 11690/20000] Loss: 0.0004149 (Best: 0.0003250 @iter9784) ([91m↑5.06%[0m) [0.16% of initial]
[Iter 15340/20000] Loss: 0.0002385 (Best: 0.0001535 @iter15169) ([91m↑12.84%[0m) [0.09% of initial]
Iter:11699, L1 loss=0.0005096, Total loss=0.0004433, Time:80
[Iter 11700/20000] Loss: 0.0004483 (Best: 0.0003250 @iter9784) ([91m↑8.05%[0m) [0.18% of initial]
[Iter 15350/20000] Loss: 0.0002070 (Best: 0.0001535 @iter15169) ([92m↓13.22%[0m) [0.08% of initial]
[Iter 11710/20000] Loss: 0.0004265 (Best: 0.0003250 @iter9784) ([92m↓4.87%[0m) [0.17% of initial]
[Iter 15360/20000] Loss: 0.0001932 (Best: 0.0001535 @iter15169) ([92m↓6.66%[0m) [0.08% of initial]
[Iter 11720/20000] Loss: 0.0004177 (Best: 0.0003250 @iter9784) ([92m↓2.06%[0m) [0.17% of initial]
[Iter 15370/20000] Loss: 0.0001846 (Best: 0.0001535 @iter15169) ([92m↓4.47%[0m) [0.07% of initial]
[Iter 11730/20000] Loss: 0.0004079 (Best: 0.0003250 @iter9784) ([92m↓2.35%[0m) [0.16% of initial]
[Iter 15380/20000] Loss: 0.0001771 (Best: 0.0001535 @iter15169) ([92m↓4.02%[0m) [0.07% of initial]
[Iter 11740/20000] Loss: 0.0004085 (Best: 0.0003250 @iter9784) ([91m↑0.15%[0m) [0.16% of initial]
[Iter 11750/20000] Loss: 0.0003939 (Best: 0.0003250 @iter9784) ([92m↓3.58%[0m) [0.16% of initial]
[Iter 15390/20000] Loss: 0.0001776 (Best: 0.0001535 @iter15169) ([91m↑0.28%[0m) [0.07% of initial]
Iter:15399, L1 loss=0.0002211, Total loss=0.0001865, Time:76
[Iter 11760/20000] Loss: 0.0003932 (Best: 0.0003250 @iter9784) ([92m↓0.16%[0m) [0.16% of initial]
[Iter 15400/20000] Loss: 0.0001881 (Best: 0.0001535 @iter15169) ([91m↑5.90%[0m) [0.07% of initial]
[Iter 11770/20000] Loss: 0.0004102 (Best: 0.0003250 @iter9784) ([91m↑4.31%[0m) [0.16% of initial]
[Iter 15410/20000] Loss: 0.0001869 (Best: 0.0001535 @iter15169) ([92m↓0.65%[0m) [0.07% of initial]
[Iter 11780/20000] Loss: 0.0004130 (Best: 0.0003250 @iter9784) ([91m↑0.68%[0m) [0.16% of initial]
[Iter 15420/20000] Loss: 0.0001878 (Best: 0.0001535 @iter15169) ([91m↑0.50%[0m) [0.07% of initial]
[Iter 11790/20000] Loss: 0.0003920 (Best: 0.0003250 @iter9784) ([92m↓5.08%[0m) [0.16% of initial]
[Iter 15430/20000] Loss: 0.0001680 (Best: 0.0001535 @iter15169) ([92m↓10.56%[0m) [0.07% of initial]
Iter:11799, L1 loss=0.0004759, Total loss=0.0004282, Time:64
[Iter 11800/20000] Loss: 0.0004252 (Best: 0.0003250 @iter9784) ([91m↑8.46%[0m) [0.17% of initial]
[Iter 15440/20000] Loss: 0.0001839 (Best: 0.0001535 @iter15169) ([91m↑9.47%[0m) [0.07% of initial]
[Iter 11810/20000] Loss: 0.0004018 (Best: 0.0003250 @iter9784) ([92m↓5.50%[0m) [0.16% of initial]
[Iter 15450/20000] Loss: 0.0001803 (Best: 0.0001535 @iter15169) ([92m↓1.97%[0m) [0.07% of initial]
[Iter 11820/20000] Loss: 0.0003914 (Best: 0.0003250 @iter9784) ([92m↓2.58%[0m) [0.16% of initial]
[Iter 15460/20000] Loss: 0.0002019 (Best: 0.0001535 @iter15169) ([91m↑12.00%[0m) [0.08% of initial]
[Iter 11830/20000] Loss: 0.0004016 (Best: 0.0003250 @iter9784) ([91m↑2.62%[0m) [0.16% of initial]
[Iter 15470/20000] Loss: 0.0001774 (Best: 0.0001535 @iter15169) ([92m↓12.13%[0m) [0.07% of initial]
[Iter 11840/20000] Loss: 0.0004329 (Best: 0.0003250 @iter9784) ([91m↑7.79%[0m) [0.17% of initial]
[Iter 15480/20000] Loss: 0.0001881 (Best: 0.0001535 @iter15169) ([91m↑6.04%[0m) [0.07% of initial]
[Iter 11850/20000] Loss: 0.0004168 (Best: 0.0003250 @iter9784) ([92m↓3.72%[0m) [0.17% of initial]
[Iter 15490/20000] Loss: 0.0001829 (Best: 0.0001535 @iter15169) ([92m↓2.80%[0m) [0.07% of initial]
[Iter 11860/20000] Loss: 0.0004267 (Best: 0.0003250 @iter9784) ([91m↑2.37%[0m) [0.17% of initial]
Iter:15499, L1 loss=0.0002414, Total loss=0.0002158, Time:73
[Iter 15500/20000] Loss: 0.0002011 (Best: 0.0001535 @iter15169) ([91m↑9.97%[0m) [0.08% of initial]
[Iter 11870/20000] Loss: 0.0004544 (Best: 0.0003250 @iter9784) ([91m↑6.48%[0m) [0.18% of initial]
[Iter 11880/20000] Loss: 0.0004373 (Best: 0.0003250 @iter9784) ([92m↓3.76%[0m) [0.17% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 15500
Pruning 5 points (0.0%) from gaussian1 at iteration 15500
[Iter 11890/20000] Loss: 0.0004408 (Best: 0.0003250 @iter9784) ([91m↑0.80%[0m) [0.18% of initial]
[Iter 15510/20000] Loss: 0.0004388 (Best: 0.0001535 @iter15169) ([91m↑118.21%[0m) [0.17% of initial]
Iter:11899, L1 loss=0.0005331, Total loss=0.000439, Time:64
[Iter 11900/20000] Loss: 0.0004170 (Best: 0.0003250 @iter9784) ([92m↓5.41%[0m) [0.17% of initial]
[Iter 15520/20000] Loss: 0.0002974 (Best: 0.0001535 @iter15169) ([92m↓32.21%[0m) [0.12% of initial]
[Iter 11910/20000] Loss: 0.0004054 (Best: 0.0003250 @iter9784) ([92m↓2.76%[0m) [0.16% of initial]
[Iter 15530/20000] Loss: 0.0002562 (Best: 0.0001535 @iter15169) ([92m↓13.86%[0m) [0.10% of initial]
[Iter 11920/20000] Loss: 0.0004047 (Best: 0.0003250 @iter9784) ([92m↓0.17%[0m) [0.16% of initial]
[Iter 15540/20000] Loss: 0.0002602 (Best: 0.0001535 @iter15169) ([91m↑1.55%[0m) [0.10% of initial]
[Iter 11930/20000] Loss: 0.0003936 (Best: 0.0003250 @iter9784) ([92m↓2.74%[0m) [0.16% of initial]
[Iter 15550/20000] Loss: 0.0001983 (Best: 0.0001535 @iter15169) ([92m↓23.78%[0m) [0.08% of initial]
[Iter 11940/20000] Loss: 0.0004198 (Best: 0.0003250 @iter9784) ([91m↑6.64%[0m) [0.17% of initial]
[Iter 15560/20000] Loss: 0.0001879 (Best: 0.0001535 @iter15169) ([92m↓5.28%[0m) [0.07% of initial]
[Iter 11950/20000] Loss: 0.0003916 (Best: 0.0003250 @iter9784) ([92m↓6.70%[0m) [0.16% of initial]
[Iter 11960/20000] Loss: 0.0004257 (Best: 0.0003250 @iter9784) ([91m↑8.70%[0m) [0.17% of initial]
[Iter 15570/20000] Loss: 0.0001921 (Best: 0.0001535 @iter15169) ([91m↑2.25%[0m) [0.08% of initial]
[Iter 11970/20000] Loss: 0.0004533 (Best: 0.0003250 @iter9784) ([91m↑6.49%[0m) [0.18% of initial]
[Iter 15580/20000] Loss: 0.0001674 (Best: 0.0001535 @iter15169) ([92m↓12.84%[0m) [0.07% of initial]
[Iter 11980/20000] Loss: 0.0004096 (Best: 0.0003250 @iter9784) ([92m↓9.65%[0m) [0.16% of initial]
[Iter 15590/20000] Loss: 0.0001586 (Best: 0.0001492 @iter15586) ([92m↓5.28%[0m) [0.06% of initial]
[Iter 11990/20000] Loss: 0.0004114 (Best: 0.0003250 @iter9784) ([91m↑0.45%[0m) [0.16% of initial]
Iter:15599, L1 loss=0.0001912, Total loss=0.0001603, Time:89
[Iter 15600/20000] Loss: 0.0001691 (Best: 0.0001456 @iter15598) ([91m↑6.63%[0m) [0.07% of initial]
Iter:11999, L1 loss=0.0004605, Total loss=0.0003884, Time:74
[Iter 12000/20000] Loss: 0.0003860 (Best: 0.0003250 @iter9784) ([92m↓6.19%[0m) [0.15% of initial]
[Iter 15610/20000] Loss: 0.0001628 (Best: 0.0001456 @iter15598) ([92m↓3.70%[0m) [0.06% of initial]
Pruning 19 points (0.0%) from gaussian0 at iteration 12000
Pruning 23 points (0.0%) from gaussian1 at iteration 12000
[Iter 15620/20000] Loss: 0.0001944 (Best: 0.0001456 @iter15598) ([91m↑19.36%[0m) [0.08% of initial]
[Iter 15630/20000] Loss: 0.0002019 (Best: 0.0001456 @iter15598) ([91m↑3.86%[0m) [0.08% of initial]
[Iter 12010/20000] Loss: 0.0006519 (Best: 0.0003250 @iter9784) ([91m↑68.91%[0m) [0.26% of initial]
[Iter 12020/20000] Loss: 0.0004993 (Best: 0.0003250 @iter9784) ([92m↓23.41%[0m) [0.20% of initial]
[Iter 15640/20000] Loss: 0.0001733 (Best: 0.0001456 @iter15598) ([92m↓14.14%[0m) [0.07% of initial]
[Iter 12030/20000] Loss: 0.0004271 (Best: 0.0003250 @iter9784) ([92m↓14.46%[0m) [0.17% of initial]
[Iter 15650/20000] Loss: 0.0001876 (Best: 0.0001456 @iter15598) ([91m↑8.23%[0m) [0.07% of initial]
[Iter 12040/20000] Loss: 0.0003993 (Best: 0.0003250 @iter9784) ([92m↓6.52%[0m) [0.16% of initial]
[Iter 15660/20000] Loss: 0.0001783 (Best: 0.0001456 @iter15598) ([92m↓4.94%[0m) [0.07% of initial]
[Iter 12050/20000] Loss: 0.0003859 (Best: 0.0003250 @iter9784) ([92m↓3.34%[0m) [0.15% of initial]
[Iter 15670/20000] Loss: 0.0002210 (Best: 0.0001456 @iter15598) ([91m↑23.95%[0m) [0.09% of initial]
[Iter 12060/20000] Loss: 0.0003702 (Best: 0.0003250 @iter9784) ([92m↓4.08%[0m) [0.15% of initial]
[Iter 15680/20000] Loss: 0.0001943 (Best: 0.0001456 @iter15598) ([92m↓12.09%[0m) [0.08% of initial]
[Iter 12070/20000] Loss: 0.0003671 (Best: 0.0003250 @iter9784) ([92m↓0.84%[0m) [0.15% of initial]
[Iter 15690/20000] Loss: 0.0001930 (Best: 0.0001456 @iter15598) ([92m↓0.68%[0m) [0.08% of initial]
[Iter 12080/20000] Loss: 0.0003611 (Best: 0.0003250 @iter9784) ([92m↓1.63%[0m) [0.14% of initial]
Iter:15699, L1 loss=0.0002242, Total loss=0.0001998, Time:75
[Iter 15700/20000] Loss: 0.0001797 (Best: 0.0001456 @iter15598) ([92m↓6.88%[0m) [0.07% of initial]
[Iter 12090/20000] Loss: 0.0003678 (Best: 0.0003250 @iter9784) ([91m↑1.87%[0m) [0.15% of initial]
[Iter 15710/20000] Loss: 0.0001740 (Best: 0.0001456 @iter15598) ([92m↓3.19%[0m) [0.07% of initial]
Iter:12099, L1 loss=0.0004064, Total loss=0.0003562, Time:68
[Iter 12100/20000] Loss: 0.0003487 (Best: 0.0003250 @iter9784) ([92m↓5.19%[0m) [0.14% of initial]
[Iter 15720/20000] Loss: 0.0002075 (Best: 0.0001456 @iter15598) ([91m↑19.26%[0m) [0.08% of initial]
[Iter 12110/20000] Loss: 0.0003804 (Best: 0.0003250 @iter9784) ([91m↑9.08%[0m) [0.15% of initial]
[Iter 15730/20000] Loss: 0.0002025 (Best: 0.0001456 @iter15598) ([92m↓2.39%[0m) [0.08% of initial]
[Iter 12120/20000] Loss: 0.0003890 (Best: 0.0003250 @iter9784) ([91m↑2.26%[0m) [0.15% of initial]
[Iter 15740/20000] Loss: 0.0002224 (Best: 0.0001456 @iter15598) ([91m↑9.81%[0m) [0.09% of initial]
[Iter 12130/20000] Loss: 0.0003852 (Best: 0.0003250 @iter9784) ([92m↓0.95%[0m) [0.15% of initial]
[Iter 15750/20000] Loss: 0.0001902 (Best: 0.0001456 @iter15598) ([92m↓14.49%[0m) [0.08% of initial]
[Iter 12140/20000] Loss: 0.0004119 (Best: 0.0003250 @iter9784) ([91m↑6.91%[0m) [0.16% of initial]
[Iter 15760/20000] Loss: 0.0001939 (Best: 0.0001456 @iter15598) ([91m↑1.98%[0m) [0.08% of initial]
[Iter 12150/20000] Loss: 0.0003982 (Best: 0.0003250 @iter9784) ([92m↓3.32%[0m) [0.16% of initial]
[Iter 15770/20000] Loss: 0.0002354 (Best: 0.0001456 @iter15598) ([91m↑21.38%[0m) [0.09% of initial]
[Iter 12160/20000] Loss: 0.0003870 (Best: 0.0003250 @iter9784) ([92m↓2.81%[0m) [0.15% of initial]
[Iter 15780/20000] Loss: 0.0001969 (Best: 0.0001456 @iter15598) ([92m↓16.33%[0m) [0.08% of initial]
[Iter 12170/20000] Loss: 0.0003900 (Best: 0.0003250 @iter9784) ([91m↑0.78%[0m) [0.15% of initial]
[Iter 15790/20000] Loss: 0.0001821 (Best: 0.0001456 @iter15598) ([92m↓7.52%[0m) [0.07% of initial]
[Iter 12180/20000] Loss: 0.0003829 (Best: 0.0003250 @iter9784) ([92m↓1.83%[0m) [0.15% of initial]
Iter:15799, L1 loss=0.0002131, Total loss=0.0001861, Time:72
[Iter 15800/20000] Loss: 0.0001719 (Best: 0.0001456 @iter15598) ([92m↓5.62%[0m) [0.07% of initial]
[Iter 12190/20000] Loss: 0.0003746 (Best: 0.0003250 @iter9784) ([92m↓2.16%[0m) [0.15% of initial]
Iter:12199, L1 loss=0.0004345, Total loss=0.0003836, Time:85
[Iter 12200/20000] Loss: 0.0003705 (Best: 0.0003250 @iter9784) ([92m↓1.09%[0m) [0.15% of initial]
[Iter 15810/20000] Loss: 0.0001716 (Best: 0.0001456 @iter15598) ([92m↓0.15%[0m) [0.07% of initial]
[Iter 12210/20000] Loss: 0.0003872 (Best: 0.0003250 @iter9784) ([91m↑4.49%[0m) [0.15% of initial]
[Iter 15820/20000] Loss: 0.0001772 (Best: 0.0001456 @iter15598) ([91m↑3.23%[0m) [0.07% of initial]
[Iter 12220/20000] Loss: 0.0004100 (Best: 0.0003250 @iter9784) ([91m↑5.90%[0m) [0.16% of initial]
[Iter 15830/20000] Loss: 0.0001805 (Best: 0.0001456 @iter15598) ([91m↑1.90%[0m) [0.07% of initial]
[Iter 12230/20000] Loss: 0.0004339 (Best: 0.0003250 @iter9784) ([91m↑5.84%[0m) [0.17% of initial]
[Iter 15840/20000] Loss: 0.0002026 (Best: 0.0001456 @iter15598) ([91m↑12.23%[0m) [0.08% of initial]
[Iter 12240/20000] Loss: 0.0003969 (Best: 0.0003250 @iter9784) ([92m↓8.54%[0m) [0.16% of initial]
[Iter 15850/20000] Loss: 0.0002003 (Best: 0.0001456 @iter15598) ([92m↓1.16%[0m) [0.08% of initial]
[Iter 12250/20000] Loss: 0.0004100 (Best: 0.0003250 @iter9784) ([91m↑3.31%[0m) [0.16% of initial]
[Iter 15860/20000] Loss: 0.0002578 (Best: 0.0001456 @iter15598) ([91m↑28.71%[0m) [0.10% of initial]
[Iter 12260/20000] Loss: 0.0003994 (Best: 0.0003250 @iter9784) ([92m↓2.59%[0m) [0.16% of initial]
[Iter 15870/20000] Loss: 0.0002113 (Best: 0.0001456 @iter15598) ([92m↓18.01%[0m) [0.08% of initial]
[Iter 12270/20000] Loss: 0.0003740 (Best: 0.0003250 @iter9784) ([92m↓6.35%[0m) [0.15% of initial]
[Iter 15880/20000] Loss: 0.0002193 (Best: 0.0001456 @iter15598) ([91m↑3.79%[0m) [0.09% of initial]
[Iter 12280/20000] Loss: 0.0003692 (Best: 0.0003250 @iter9784) ([92m↓1.30%[0m) [0.15% of initial]
[Iter 15890/20000] Loss: 0.0002815 (Best: 0.0001456 @iter15598) ([91m↑28.36%[0m) [0.11% of initial]
[Iter 12290/20000] Loss: 0.0004599 (Best: 0.0003250 @iter9784) ([91m↑24.58%[0m) [0.18% of initial]
Iter:15899, L1 loss=0.0002738, Total loss=0.0002217, Time:72
[Iter 15900/20000] Loss: 0.0002350 (Best: 0.0001456 @iter15598) ([92m↓16.53%[0m) [0.09% of initial]
Iter:12299, L1 loss=0.0004835, Total loss=0.0004353, Time:71
[Iter 12300/20000] Loss: 0.0004459 (Best: 0.0003250 @iter9784) ([92m↓3.04%[0m) [0.18% of initial]
[Iter 15910/20000] Loss: 0.0001858 (Best: 0.0001456 @iter15598) ([92m↓20.92%[0m) [0.07% of initial]
[Iter 12310/20000] Loss: 0.0004361 (Best: 0.0003250 @iter9784) ([92m↓2.19%[0m) [0.17% of initial]
[Iter 15920/20000] Loss: 0.0001919 (Best: 0.0001456 @iter15598) ([91m↑3.30%[0m) [0.08% of initial]
[Iter 12320/20000] Loss: 0.0004002 (Best: 0.0003250 @iter9784) ([92m↓8.23%[0m) [0.16% of initial]
[Iter 12330/20000] Loss: 0.0004181 (Best: 0.0003250 @iter9784) ([91m↑4.47%[0m) [0.17% of initial]
[Iter 15930/20000] Loss: 0.0002481 (Best: 0.0001456 @iter15598) ([91m↑29.26%[0m) [0.10% of initial]
[Iter 12340/20000] Loss: 0.0004301 (Best: 0.0003250 @iter9784) ([91m↑2.88%[0m) [0.17% of initial]
[Iter 15940/20000] Loss: 0.0001850 (Best: 0.0001456 @iter15598) ([92m↓25.44%[0m) [0.07% of initial]
[Iter 12350/20000] Loss: 0.0003859 (Best: 0.0003250 @iter9784) ([92m↓10.29%[0m) [0.15% of initial]
[Iter 15950/20000] Loss: 0.0001830 (Best: 0.0001456 @iter15598) ([92m↓1.09%[0m) [0.07% of initial]
[Iter 12360/20000] Loss: 0.0003803 (Best: 0.0003250 @iter9784) ([92m↓1.45%[0m) [0.15% of initial]
[Iter 15960/20000] Loss: 0.0001932 (Best: 0.0001456 @iter15598) ([91m↑5.58%[0m) [0.08% of initial]
[Iter 12370/20000] Loss: 0.0004284 (Best: 0.0003250 @iter9784) ([91m↑12.64%[0m) [0.17% of initial]
[Iter 15970/20000] Loss: 0.0001709 (Best: 0.0001456 @iter15598) ([92m↓11.55%[0m) [0.07% of initial]
[Iter 12380/20000] Loss: 0.0003870 (Best: 0.0003250 @iter9784) ([92m↓9.66%[0m) [0.15% of initial]
[Iter 15980/20000] Loss: 0.0001934 (Best: 0.0001456 @iter15598) ([91m↑13.16%[0m) [0.08% of initial]
[Iter 12390/20000] Loss: 0.0003970 (Best: 0.0003250 @iter9784) ([91m↑2.58%[0m) [0.16% of initial]
[Iter 15990/20000] Loss: 0.0001714 (Best: 0.0001456 @iter15598) ([92m↓11.35%[0m) [0.07% of initial]
Iter:12399, L1 loss=0.0004678, Total loss=0.000419, Time:61
[Iter 12400/20000] Loss: 0.0003827 (Best: 0.0003250 @iter9784) ([92m↓3.58%[0m) [0.15% of initial]
Iter:15999, L1 loss=0.0002146, Total loss=0.0001848, Time:77
[Iter 16000/20000] Loss: 0.0001676 (Best: 0.0001452 @iter15997) ([92m↓2.26%[0m) [0.07% of initial]
[Iter 12410/20000] Loss: 0.0003570 (Best: 0.0003250 @iter9784) ([92m↓6.72%[0m) [0.14% of initial]
[Iter 12420/20000] Loss: 0.0003532 (Best: 0.0003250 @iter9784) ([92m↓1.08%[0m) [0.14% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 16000
Pruning 4 points (0.0%) from gaussian1 at iteration 16000
[Iter 12430/20000] Loss: 0.0003489 (Best: 0.0003250 @iter9784) ([92m↓1.22%[0m) [0.14% of initial]
[Iter 16010/20000] Loss: 0.0003257 (Best: 0.0001452 @iter15997) ([91m↑94.38%[0m) [0.13% of initial]
[Iter 12440/20000] Loss: 0.0003655 (Best: 0.0003250 @iter9784) ([91m↑4.77%[0m) [0.15% of initial]
[Iter 16020/20000] Loss: 0.0002901 (Best: 0.0001452 @iter15997) ([92m↓10.92%[0m) [0.12% of initial]
[Iter 12450/20000] Loss: 0.0003745 (Best: 0.0003250 @iter9784) ([91m↑2.45%[0m) [0.15% of initial]
[Iter 16030/20000] Loss: 0.0002271 (Best: 0.0001452 @iter15997) ([92m↓21.72%[0m) [0.09% of initial]
[Iter 12460/20000] Loss: 0.0003962 (Best: 0.0003250 @iter9784) ([91m↑5.81%[0m) [0.16% of initial]
[Iter 16040/20000] Loss: 0.0002063 (Best: 0.0001452 @iter15997) ([92m↓9.18%[0m) [0.08% of initial]
[Iter 12470/20000] Loss: 0.0004030 (Best: 0.0003250 @iter9784) ([91m↑1.73%[0m) [0.16% of initial]
[Iter 16050/20000] Loss: 0.0001786 (Best: 0.0001452 @iter15997) ([92m↓13.43%[0m) [0.07% of initial]
[Iter 12480/20000] Loss: 0.0003690 (Best: 0.0003250 @iter9784) ([92m↓8.44%[0m) [0.15% of initial]
[Iter 12490/20000] Loss: 0.0003480 (Best: 0.0003250 @iter9784) ([92m↓5.71%[0m) [0.14% of initial]
[Iter 16060/20000] Loss: 0.0001690 (Best: 0.0001452 @iter15997) ([92m↓5.35%[0m) [0.07% of initial]
Iter:12499, L1 loss=0.0003609, Total loss=0.0003211, Time:77
[Iter 12500/20000] Loss: 0.0003439 (Best: 0.0003211 @iter12499) ([92m↓1.17%[0m) [0.14% of initial]
[Iter 16070/20000] Loss: 0.0001580 (Best: 0.0001452 @iter15997) ([92m↓6.51%[0m) [0.06% of initial]
Pruning 20 points (0.0%) from gaussian0 at iteration 12500
[Iter 16080/20000] Loss: 0.0001649 (Best: 0.0001452 @iter15997) ([91m↑4.37%[0m) [0.07% of initial]
Pruning 18 points (0.0%) from gaussian1 at iteration 12500
[Iter 16090/20000] Loss: 0.0001719 (Best: 0.0001452 @iter15997) ([91m↑4.23%[0m) [0.07% of initial]
[Iter 12510/20000] Loss: 0.0006574 (Best: 0.0003211 @iter12499) ([91m↑91.16%[0m) [0.26% of initial]
Iter:16099, L1 loss=0.0002386, Total loss=0.000205, Time:76
[Iter 16100/20000] Loss: 0.0001847 (Best: 0.0001452 @iter15997) ([91m↑7.46%[0m) [0.07% of initial]
[Iter 12520/20000] Loss: 0.0004808 (Best: 0.0003211 @iter12499) ([92m↓26.87%[0m) [0.19% of initial]
[Iter 16110/20000] Loss: 0.0002065 (Best: 0.0001452 @iter15997) ([91m↑11.76%[0m) [0.08% of initial]
[Iter 12530/20000] Loss: 0.0003978 (Best: 0.0003211 @iter12499) ([92m↓17.26%[0m) [0.16% of initial]
[Iter 12540/20000] Loss: 0.0003675 (Best: 0.0003211 @iter12499) ([92m↓7.62%[0m) [0.15% of initial]
[Iter 16120/20000] Loss: 0.0001827 (Best: 0.0001452 @iter15997) ([92m↓11.50%[0m) [0.07% of initial]
[Iter 12550/20000] Loss: 0.0003614 (Best: 0.0003211 @iter12499) ([92m↓1.66%[0m) [0.14% of initial]
[Iter 16130/20000] Loss: 0.0002140 (Best: 0.0001452 @iter15997) ([91m↑17.14%[0m) [0.09% of initial]
[Iter 12560/20000] Loss: 0.0003551 (Best: 0.0003211 @iter12499) ([92m↓1.73%[0m) [0.14% of initial]
[Iter 16140/20000] Loss: 0.0002024 (Best: 0.0001452 @iter15997) ([92m↓5.41%[0m) [0.08% of initial]
[Iter 12570/20000] Loss: 0.0003674 (Best: 0.0003211 @iter12499) ([91m↑3.47%[0m) [0.15% of initial]
[Iter 16150/20000] Loss: 0.0002005 (Best: 0.0001452 @iter15997) ([92m↓0.95%[0m) [0.08% of initial]
[Iter 12580/20000] Loss: 0.0003454 (Best: 0.0003211 @iter12499) ([92m↓6.01%[0m) [0.14% of initial]
[Iter 16160/20000] Loss: 0.0001804 (Best: 0.0001452 @iter15997) ([92m↓10.01%[0m) [0.07% of initial]
[Iter 12590/20000] Loss: 0.0003348 (Best: 0.0003178 @iter12590) ([92m↓3.06%[0m) [0.13% of initial]
[Iter 16170/20000] Loss: 0.0001693 (Best: 0.0001452 @iter15997) ([92m↓6.19%[0m) [0.07% of initial]
Iter:12599, L1 loss=0.0003561, Total loss=0.0003182, Time:68
[Iter 12600/20000] Loss: 0.0003375 (Best: 0.0003178 @iter12590) ([91m↑0.81%[0m) [0.13% of initial]
[Iter 16180/20000] Loss: 0.0001965 (Best: 0.0001452 @iter15997) ([91m↑16.05%[0m) [0.08% of initial]
[Iter 12610/20000] Loss: 0.0003419 (Best: 0.0003067 @iter12601) ([91m↑1.30%[0m) [0.14% of initial]
[Iter 16190/20000] Loss: 0.0001681 (Best: 0.0001452 @iter15997) ([92m↓14.44%[0m) [0.07% of initial]
[Iter 12620/20000] Loss: 0.0003526 (Best: 0.0003067 @iter12601) ([91m↑3.14%[0m) [0.14% of initial]
Iter:16199, L1 loss=0.0002072, Total loss=0.000182, Time:76
[Iter 16200/20000] Loss: 0.0001892 (Best: 0.0001452 @iter15997) ([91m↑12.58%[0m) [0.08% of initial]
[Iter 12630/20000] Loss: 0.0003868 (Best: 0.0003067 @iter12601) ([91m↑9.68%[0m) [0.15% of initial]
[Iter 16210/20000] Loss: 0.0001795 (Best: 0.0001452 @iter15997) ([92m↓5.16%[0m) [0.07% of initial]
[Iter 12640/20000] Loss: 0.0003634 (Best: 0.0003067 @iter12601) ([92m↓6.04%[0m) [0.14% of initial]
[Iter 16220/20000] Loss: 0.0001686 (Best: 0.0001452 @iter15997) ([92m↓6.07%[0m) [0.07% of initial]
[Iter 12650/20000] Loss: 0.0003595 (Best: 0.0003067 @iter12601) ([92m↓1.06%[0m) [0.14% of initial]
[Iter 16230/20000] Loss: 0.0002001 (Best: 0.0001452 @iter15997) ([91m↑18.72%[0m) [0.08% of initial]
[Iter 12660/20000] Loss: 0.0003536 (Best: 0.0003067 @iter12601) ([92m↓1.66%[0m) [0.14% of initial]
[Iter 16240/20000] Loss: 0.0001811 (Best: 0.0001452 @iter15997) ([92m↓9.51%[0m) [0.07% of initial]
[Iter 12670/20000] Loss: 0.0003525 (Best: 0.0003067 @iter12601) ([92m↓0.30%[0m) [0.14% of initial]
[Iter 12680/20000] Loss: 0.0003431 (Best: 0.0003067 @iter12601) ([92m↓2.65%[0m) [0.14% of initial]
[Iter 16250/20000] Loss: 0.0002163 (Best: 0.0001452 @iter15997) ([91m↑19.44%[0m) [0.09% of initial]
[Iter 12690/20000] Loss: 0.0003461 (Best: 0.0003067 @iter12601) ([91m↑0.85%[0m) [0.14% of initial]
[Iter 16260/20000] Loss: 0.0002118 (Best: 0.0001452 @iter15997) ([92m↓2.07%[0m) [0.08% of initial]
Iter:12699, L1 loss=0.0003919, Total loss=0.0003364, Time:72
[Iter 12700/20000] Loss: 0.0003347 (Best: 0.0003067 @iter12601) ([92m↓3.28%[0m) [0.13% of initial]
[Iter 16270/20000] Loss: 0.0001937 (Best: 0.0001452 @iter15997) ([92m↓8.56%[0m) [0.08% of initial]
[Iter 12710/20000] Loss: 0.0003565 (Best: 0.0003067 @iter12601) ([91m↑6.51%[0m) [0.14% of initial]
[Iter 16280/20000] Loss: 0.0001835 (Best: 0.0001452 @iter15997) ([92m↓5.29%[0m) [0.07% of initial]
[Iter 12720/20000] Loss: 0.0003893 (Best: 0.0003067 @iter12601) ([91m↑9.21%[0m) [0.15% of initial]
[Iter 16290/20000] Loss: 0.0002401 (Best: 0.0001452 @iter15997) ([91m↑30.88%[0m) [0.10% of initial]
[Iter 12730/20000] Loss: 0.0003802 (Best: 0.0003067 @iter12601) ([92m↓2.34%[0m) [0.15% of initial]
Iter:16299, L1 loss=0.0002887, Total loss=0.0002058, Time:71
[Iter 16300/20000] Loss: 0.0002015 (Best: 0.0001452 @iter15997) ([92m↓16.08%[0m) [0.08% of initial]
[Iter 12740/20000] Loss: 0.0003761 (Best: 0.0003067 @iter12601) ([92m↓1.06%[0m) [0.15% of initial]
[Iter 16310/20000] Loss: 0.0002066 (Best: 0.0001452 @iter15997) ([91m↑2.54%[0m) [0.08% of initial]
[Iter 12750/20000] Loss: 0.0003802 (Best: 0.0003067 @iter12601) ([91m↑1.07%[0m) [0.15% of initial]
[Iter 16320/20000] Loss: 0.0001875 (Best: 0.0001452 @iter15997) ([92m↓9.25%[0m) [0.07% of initial]
[Iter 12760/20000] Loss: 0.0003688 (Best: 0.0003067 @iter12601) ([92m↓2.99%[0m) [0.15% of initial]
[Iter 16330/20000] Loss: 0.0001860 (Best: 0.0001452 @iter15997) ([92m↓0.80%[0m) [0.07% of initial]
[Iter 12770/20000] Loss: 0.0003688 (Best: 0.0003067 @iter12601) ([91m↑0.01%[0m) [0.15% of initial]
[Iter 16340/20000] Loss: 0.0001685 (Best: 0.0001452 @iter15997) ([92m↓9.40%[0m) [0.07% of initial]
[Iter 12780/20000] Loss: 0.0003566 (Best: 0.0003067 @iter12601) ([92m↓3.33%[0m) [0.14% of initial]
[Iter 16350/20000] Loss: 0.0002153 (Best: 0.0001452 @iter15997) ([91m↑27.76%[0m) [0.09% of initial]
[Iter 12790/20000] Loss: 0.0003510 (Best: 0.0003067 @iter12601) ([92m↓1.55%[0m) [0.14% of initial]
Iter:12799, L1 loss=0.0003818, Total loss=0.0003395, Time:77
[Iter 12800/20000] Loss: 0.0003696 (Best: 0.0003067 @iter12601) ([91m↑5.29%[0m) [0.15% of initial]
[Iter 16360/20000] Loss: 0.0001889 (Best: 0.0001452 @iter15997) ([92m↓12.24%[0m) [0.08% of initial]
[Iter 12810/20000] Loss: 0.0003646 (Best: 0.0003067 @iter12601) ([92m↓1.36%[0m) [0.14% of initial]
[Iter 16370/20000] Loss: 0.0002525 (Best: 0.0001452 @iter15997) ([91m↑33.62%[0m) [0.10% of initial]
[Iter 12820/20000] Loss: 0.0003627 (Best: 0.0003067 @iter12601) ([92m↓0.52%[0m) [0.14% of initial]
[Iter 16380/20000] Loss: 0.0002220 (Best: 0.0001452 @iter15997) ([92m↓12.05%[0m) [0.09% of initial]
[Iter 12830/20000] Loss: 0.0004048 (Best: 0.0003067 @iter12601) ([91m↑11.60%[0m) [0.16% of initial]
[Iter 16390/20000] Loss: 0.0001934 (Best: 0.0001452 @iter15997) ([92m↓12.88%[0m) [0.08% of initial]
[Iter 12840/20000] Loss: 0.0003795 (Best: 0.0003067 @iter12601) ([92m↓6.23%[0m) [0.15% of initial]
Iter:16399, L1 loss=0.0002099, Total loss=0.0001778, Time:73
[Iter 16400/20000] Loss: 0.0001710 (Best: 0.0001452 @iter15997) ([92m↓11.60%[0m) [0.07% of initial]
[Iter 12850/20000] Loss: 0.0003789 (Best: 0.0003067 @iter12601) ([92m↓0.18%[0m) [0.15% of initial]
[Iter 16410/20000] Loss: 0.0001700 (Best: 0.0001452 @iter15997) ([92m↓0.59%[0m) [0.07% of initial]
[Iter 12860/20000] Loss: 0.0003519 (Best: 0.0003067 @iter12601) ([92m↓7.11%[0m) [0.14% of initial]
[Iter 16420/20000] Loss: 0.0001728 (Best: 0.0001452 @iter15997) ([91m↑1.66%[0m) [0.07% of initial]
[Iter 12870/20000] Loss: 0.0003691 (Best: 0.0003067 @iter12601) ([91m↑4.87%[0m) [0.15% of initial]
[Iter 16430/20000] Loss: 0.0001720 (Best: 0.0001452 @iter15997) ([92m↓0.47%[0m) [0.07% of initial]
[Iter 12880/20000] Loss: 0.0003481 (Best: 0.0003067 @iter12601) ([92m↓5.67%[0m) [0.14% of initial]
[Iter 16440/20000] Loss: 0.0002321 (Best: 0.0001452 @iter15997) ([91m↑34.93%[0m) [0.09% of initial]
[Iter 12890/20000] Loss: 0.0003591 (Best: 0.0003067 @iter12601) ([91m↑3.14%[0m) [0.14% of initial]
[Iter 16450/20000] Loss: 0.0002201 (Best: 0.0001452 @iter15997) ([92m↓5.14%[0m) [0.09% of initial]
Iter:12899, L1 loss=0.0004729, Total loss=0.0003865, Time:73
[Iter 12900/20000] Loss: 0.0004159 (Best: 0.0003067 @iter12601) ([91m↑15.83%[0m) [0.17% of initial]
[Iter 16460/20000] Loss: 0.0002092 (Best: 0.0001452 @iter15997) ([92m↓4.96%[0m) [0.08% of initial]
[Iter 12910/20000] Loss: 0.0004346 (Best: 0.0003067 @iter12601) ([91m↑4.50%[0m) [0.17% of initial]
[Iter 12920/20000] Loss: 0.0003821 (Best: 0.0003067 @iter12601) ([92m↓12.08%[0m) [0.15% of initial]
[Iter 16470/20000] Loss: 0.0001745 (Best: 0.0001452 @iter15997) ([92m↓16.61%[0m) [0.07% of initial]
[Iter 12930/20000] Loss: 0.0003880 (Best: 0.0003067 @iter12601) ([91m↑1.55%[0m) [0.15% of initial]
[Iter 16480/20000] Loss: 0.0001907 (Best: 0.0001452 @iter15997) ([91m↑9.34%[0m) [0.08% of initial]
[Iter 12940/20000] Loss: 0.0004344 (Best: 0.0003067 @iter12601) ([91m↑11.94%[0m) [0.17% of initial]
[Iter 16490/20000] Loss: 0.0001694 (Best: 0.0001452 @iter15997) ([92m↓11.19%[0m) [0.07% of initial]
[Iter 12950/20000] Loss: 0.0004037 (Best: 0.0003067 @iter12601) ([92m↓7.06%[0m) [0.16% of initial]
Iter:16499, L1 loss=0.0001778, Total loss=0.0001556, Time:69
[Iter 16500/20000] Loss: 0.0001597 (Best: 0.0001452 @iter15997) ([92m↓5.72%[0m) [0.06% of initial]
[Iter 12960/20000] Loss: 0.0003878 (Best: 0.0003067 @iter12601) ([92m↓3.94%[0m) [0.15% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 16500
[Iter 12970/20000] Loss: 0.0003687 (Best: 0.0003067 @iter12601) ([92m↓4.94%[0m) [0.15% of initial]
Pruning 5 points (0.0%) from gaussian1 at iteration 16500
[Iter 12980/20000] Loss: 0.0003589 (Best: 0.0003067 @iter12601) ([92m↓2.65%[0m) [0.14% of initial]
[Iter 16510/20000] Loss: 0.0003725 (Best: 0.0001452 @iter15997) ([91m↑133.22%[0m) [0.15% of initial]
[Iter 12990/20000] Loss: 0.0003618 (Best: 0.0003067 @iter12601) ([91m↑0.81%[0m) [0.14% of initial]
[Iter 16520/20000] Loss: 0.0002603 (Best: 0.0001452 @iter15997) ([92m↓30.10%[0m) [0.10% of initial]
Iter:12999, L1 loss=0.0004384, Total loss=0.0004242, Time:75
[Iter 13000/20000] Loss: 0.0003821 (Best: 0.0003067 @iter12601) ([91m↑5.60%[0m) [0.15% of initial]
[Iter 16530/20000] Loss: 0.0002499 (Best: 0.0001452 @iter15997) ([92m↓4.00%[0m) [0.10% of initial]
Pruning 15 points (0.0%) from gaussian0 at iteration 13000
Pruning 16 points (0.0%) from gaussian1 at iteration 13000
[Iter 16540/20000] Loss: 0.0002162 (Best: 0.0001452 @iter15997) ([92m↓13.49%[0m) [0.09% of initial]
[Iter 13010/20000] Loss: 0.0006249 (Best: 0.0003067 @iter12601) ([91m↑63.54%[0m) [0.25% of initial]
[Iter 16550/20000] Loss: 0.0001775 (Best: 0.0001452 @iter15997) ([92m↓17.90%[0m) [0.07% of initial]
[Iter 13020/20000] Loss: 0.0004673 (Best: 0.0003067 @iter12601) ([92m↓25.22%[0m) [0.19% of initial]
[Iter 16560/20000] Loss: 0.0001683 (Best: 0.0001452 @iter15997) ([92m↓5.18%[0m) [0.07% of initial]
[Iter 13030/20000] Loss: 0.0003799 (Best: 0.0003067 @iter12601) ([92m↓18.71%[0m) [0.15% of initial]
[Iter 16570/20000] Loss: 0.0001594 (Best: 0.0001452 @iter15997) ([92m↓5.31%[0m) [0.06% of initial]
[Iter 13040/20000] Loss: 0.0003468 (Best: 0.0003067 @iter12601) ([92m↓8.69%[0m) [0.14% of initial]
[Iter 16580/20000] Loss: 0.0001574 (Best: 0.0001440 @iter16574) ([92m↓1.21%[0m) [0.06% of initial]
[Iter 13050/20000] Loss: 0.0003345 (Best: 0.0003067 @iter12601) ([92m↓3.57%[0m) [0.13% of initial]
[Iter 16590/20000] Loss: 0.0001720 (Best: 0.0001440 @iter16574) ([91m↑9.24%[0m) [0.07% of initial]
[Iter 13060/20000] Loss: 0.0003285 (Best: 0.0003067 @iter12601) ([92m↓1.79%[0m) [0.13% of initial]
Iter:16599, L1 loss=0.0002775, Total loss=0.0002378, Time:72
[Iter 16600/20000] Loss: 0.0002079 (Best: 0.0001440 @iter16574) ([91m↑20.90%[0m) [0.08% of initial]
[Iter 13070/20000] Loss: 0.0003420 (Best: 0.0003067 @iter12601) ([91m↑4.12%[0m) [0.14% of initial]
[Iter 16610/20000] Loss: 0.0001883 (Best: 0.0001440 @iter16574) ([92m↓9.46%[0m) [0.07% of initial]
[Iter 13080/20000] Loss: 0.0003354 (Best: 0.0003067 @iter12601) ([92m↓1.95%[0m) [0.13% of initial]
[Iter 16620/20000] Loss: 0.0002038 (Best: 0.0001440 @iter16574) ([91m↑8.26%[0m) [0.08% of initial]
[Iter 13090/20000] Loss: 0.0003292 (Best: 0.0003001 @iter13087) ([92m↓1.84%[0m) [0.13% of initial]
[Iter 16630/20000] Loss: 0.0002348 (Best: 0.0001440 @iter16574) ([91m↑15.21%[0m) [0.09% of initial]
Iter:13099, L1 loss=0.0003759, Total loss=0.0003265, Time:76
[Iter 13100/20000] Loss: 0.0003342 (Best: 0.0003001 @iter13087) ([91m↑1.52%[0m) [0.13% of initial]
[Iter 16640/20000] Loss: 0.0001929 (Best: 0.0001440 @iter16574) ([92m↓17.84%[0m) [0.08% of initial]
[Iter 13110/20000] Loss: 0.0003389 (Best: 0.0003001 @iter13087) ([91m↑1.41%[0m) [0.13% of initial]
[Iter 16650/20000] Loss: 0.0001791 (Best: 0.0001440 @iter16574) ([92m↓7.19%[0m) [0.07% of initial]
[Iter 13120/20000] Loss: 0.0003309 (Best: 0.0003001 @iter13087) ([92m↓2.35%[0m) [0.13% of initial]
[Iter 13130/20000] Loss: 0.0003556 (Best: 0.0003001 @iter13087) ([91m↑7.44%[0m) [0.14% of initial]
[Iter 16660/20000] Loss: 0.0001700 (Best: 0.0001440 @iter16574) ([92m↓5.09%[0m) [0.07% of initial]
[Iter 13140/20000] Loss: 0.0003597 (Best: 0.0003001 @iter13087) ([91m↑1.17%[0m) [0.14% of initial]
[Iter 16670/20000] Loss: 0.0001695 (Best: 0.0001440 @iter16574) ([92m↓0.29%[0m) [0.07% of initial]
[Iter 13150/20000] Loss: 0.0003976 (Best: 0.0003001 @iter13087) ([91m↑10.54%[0m) [0.16% of initial]
[Iter 16680/20000] Loss: 0.0001578 (Best: 0.0001434 @iter16679) ([92m↓6.87%[0m) [0.06% of initial]
[Iter 13160/20000] Loss: 0.0003437 (Best: 0.0003001 @iter13087) ([92m↓13.55%[0m) [0.14% of initial]
[Iter 16690/20000] Loss: 0.0001710 (Best: 0.0001434 @iter16679) ([91m↑8.35%[0m) [0.07% of initial]
[Iter 13170/20000] Loss: 0.0003376 (Best: 0.0003001 @iter13087) ([92m↓1.77%[0m) [0.13% of initial]
Iter:16699, L1 loss=0.0001944, Total loss=0.0001592, Time:72
[Iter 16700/20000] Loss: 0.0001610 (Best: 0.0001434 @iter16679) ([92m↓5.84%[0m) [0.06% of initial]
[Iter 13180/20000] Loss: 0.0003556 (Best: 0.0003001 @iter13087) ([91m↑5.31%[0m) [0.14% of initial]
[Iter 16710/20000] Loss: 0.0001741 (Best: 0.0001434 @iter16679) ([91m↑8.15%[0m) [0.07% of initial]
[Iter 13190/20000] Loss: 0.0003347 (Best: 0.0003001 @iter13087) ([92m↓5.86%[0m) [0.13% of initial]
[Iter 16720/20000] Loss: 0.0001665 (Best: 0.0001434 @iter16679) ([92m↓4.37%[0m) [0.07% of initial]
Iter:13199, L1 loss=0.0003677, Total loss=0.0003268, Time:75
[Iter 13200/20000] Loss: 0.0003378 (Best: 0.0003001 @iter13087) ([91m↑0.93%[0m) [0.13% of initial]
[Iter 16730/20000] Loss: 0.0001780 (Best: 0.0001434 @iter16679) ([91m↑6.91%[0m) [0.07% of initial]
[Iter 13210/20000] Loss: 0.0003696 (Best: 0.0003001 @iter13087) ([91m↑9.40%[0m) [0.15% of initial]
[Iter 16740/20000] Loss: 0.0002215 (Best: 0.0001434 @iter16679) ([91m↑24.42%[0m) [0.09% of initial]
[Iter 13220/20000] Loss: 0.0003657 (Best: 0.0003001 @iter13087) ([92m↓1.07%[0m) [0.15% of initial]
[Iter 16750/20000] Loss: 0.0001743 (Best: 0.0001434 @iter16679) ([92m↓21.30%[0m) [0.07% of initial]
[Iter 13230/20000] Loss: 0.0003755 (Best: 0.0003001 @iter13087) ([91m↑2.70%[0m) [0.15% of initial]
[Iter 16760/20000] Loss: 0.0001955 (Best: 0.0001434 @iter16679) ([91m↑12.13%[0m) [0.08% of initial]
[Iter 13240/20000] Loss: 0.0003529 (Best: 0.0003001 @iter13087) ([92m↓6.03%[0m) [0.14% of initial]
[Iter 16770/20000] Loss: 0.0002004 (Best: 0.0001434 @iter16679) ([91m↑2.55%[0m) [0.08% of initial]
[Iter 13250/20000] Loss: 0.0003414 (Best: 0.0003001 @iter13087) ([92m↓3.25%[0m) [0.14% of initial]
[Iter 13260/20000] Loss: 0.0003337 (Best: 0.0003001 @iter13087) ([92m↓2.26%[0m) [0.13% of initial]
[Iter 16780/20000] Loss: 0.0001862 (Best: 0.0001434 @iter16679) ([92m↓7.11%[0m) [0.07% of initial]
[Iter 13270/20000] Loss: 0.0003332 (Best: 0.0003001 @iter13087) ([92m↓0.16%[0m) [0.13% of initial]
[Iter 16790/20000] Loss: 0.0001723 (Best: 0.0001434 @iter16679) ([92m↓7.48%[0m) [0.07% of initial]
[Iter 13280/20000] Loss: 0.0003156 (Best: 0.0003001 @iter13087) ([92m↓5.27%[0m) [0.13% of initial]
Iter:16799, L1 loss=0.0002176, Total loss=0.0001739, Time:73
[Iter 16800/20000] Loss: 0.0001895 (Best: 0.0001434 @iter16679) ([91m↑9.99%[0m) [0.08% of initial]
[Iter 13290/20000] Loss: 0.0003453 (Best: 0.0003001 @iter13087) ([91m↑9.40%[0m) [0.14% of initial]
[Iter 16810/20000] Loss: 0.0001816 (Best: 0.0001434 @iter16679) ([92m↓4.17%[0m) [0.07% of initial]
Iter:13299, L1 loss=0.000469, Total loss=0.0004212, Time:73
[Iter 13300/20000] Loss: 0.0003987 (Best: 0.0003001 @iter13087) ([91m↑15.48%[0m) [0.16% of initial]
[Iter 16820/20000] Loss: 0.0001819 (Best: 0.0001434 @iter16679) ([91m↑0.20%[0m) [0.07% of initial]
[Iter 13310/20000] Loss: 0.0003866 (Best: 0.0003001 @iter13087) ([92m↓3.05%[0m) [0.15% of initial]
[Iter 16830/20000] Loss: 0.0001873 (Best: 0.0001434 @iter16679) ([91m↑2.97%[0m) [0.07% of initial]
[Iter 13320/20000] Loss: 0.0004012 (Best: 0.0003001 @iter13087) ([91m↑3.80%[0m) [0.16% of initial]
[Iter 16840/20000] Loss: 0.0001756 (Best: 0.0001434 @iter16679) ([92m↓6.28%[0m) [0.07% of initial]
[Iter 13330/20000] Loss: 0.0003441 (Best: 0.0003001 @iter13087) ([92m↓14.23%[0m) [0.14% of initial]
[Iter 16850/20000] Loss: 0.0001995 (Best: 0.0001434 @iter16679) ([91m↑13.65%[0m) [0.08% of initial]
[Iter 13340/20000] Loss: 0.0003514 (Best: 0.0003001 @iter13087) ([91m↑2.10%[0m) [0.14% of initial]
[Iter 16860/20000] Loss: 0.0002081 (Best: 0.0001434 @iter16679) ([91m↑4.30%[0m) [0.08% of initial]
[Iter 13350/20000] Loss: 0.0003424 (Best: 0.0003001 @iter13087) ([92m↓2.56%[0m) [0.14% of initial]
[Iter 16870/20000] Loss: 0.0001772 (Best: 0.0001434 @iter16679) ([92m↓14.88%[0m) [0.07% of initial]
[Iter 13360/20000] Loss: 0.0003358 (Best: 0.0003001 @iter13087) ([92m↓1.93%[0m) [0.13% of initial]
[Iter 16880/20000] Loss: 0.0001692 (Best: 0.0001434 @iter16679) ([92m↓4.48%[0m) [0.07% of initial]
[Iter 13370/20000] Loss: 0.0003205 (Best: 0.0003001 @iter13087) ([92m↓4.55%[0m) [0.13% of initial]
[Iter 16890/20000] Loss: 0.0001698 (Best: 0.0001434 @iter16679) ([91m↑0.32%[0m) [0.07% of initial]
[Iter 13380/20000] Loss: 0.0003300 (Best: 0.0003001 @iter13087) ([91m↑2.96%[0m) [0.13% of initial]
Iter:16899, L1 loss=0.0002157, Total loss=0.0001863, Time:76
[Iter 13390/20000] Loss: 0.0003232 (Best: 0.0002945 @iter13387) ([92m↓2.06%[0m) [0.13% of initial]
[Iter 16900/20000] Loss: 0.0001982 (Best: 0.0001434 @iter16679) ([91m↑16.71%[0m) [0.08% of initial]
Iter:13399, L1 loss=0.0003756, Total loss=0.0003281, Time:75
[Iter 13400/20000] Loss: 0.0003293 (Best: 0.0002945 @iter13387) ([91m↑1.91%[0m) [0.13% of initial]
[Iter 16910/20000] Loss: 0.0001649 (Best: 0.0001434 @iter16679) ([92m↓16.77%[0m) [0.07% of initial]
[Iter 13410/20000] Loss: 0.0004217 (Best: 0.0002945 @iter13387) ([91m↑28.04%[0m) [0.17% of initial]
[Iter 16920/20000] Loss: 0.0001642 (Best: 0.0001434 @iter16679) ([92m↓0.42%[0m) [0.07% of initial]
[Iter 13420/20000] Loss: 0.0004595 (Best: 0.0002945 @iter13387) ([91m↑8.97%[0m) [0.18% of initial]
[Iter 16930/20000] Loss: 0.0001578 (Best: 0.0001434 @iter16679) ([92m↓3.92%[0m) [0.06% of initial]
[Iter 13430/20000] Loss: 0.0004323 (Best: 0.0002945 @iter13387) ([92m↓5.92%[0m) [0.17% of initial]
[Iter 16940/20000] Loss: 0.0001796 (Best: 0.0001434 @iter16679) ([91m↑13.81%[0m) [0.07% of initial]
[Iter 13440/20000] Loss: 0.0004053 (Best: 0.0002945 @iter13387) ([92m↓6.25%[0m) [0.16% of initial]
[Iter 16950/20000] Loss: 0.0001863 (Best: 0.0001434 @iter16679) ([91m↑3.74%[0m) [0.07% of initial]
[Iter 13450/20000] Loss: 0.0003482 (Best: 0.0002945 @iter13387) ([92m↓14.07%[0m) [0.14% of initial]
[Iter 16960/20000] Loss: 0.0001932 (Best: 0.0001434 @iter16679) ([91m↑3.70%[0m) [0.08% of initial]
[Iter 13460/20000] Loss: 0.0003402 (Best: 0.0002945 @iter13387) ([92m↓2.31%[0m) [0.14% of initial]
[Iter 16970/20000] Loss: 0.0001768 (Best: 0.0001434 @iter16679) ([92m↓8.49%[0m) [0.07% of initial]
[Iter 13470/20000] Loss: 0.0003201 (Best: 0.0002945 @iter13387) ([92m↓5.90%[0m) [0.13% of initial]
[Iter 16980/20000] Loss: 0.0001701 (Best: 0.0001434 @iter16679) ([92m↓3.77%[0m) [0.07% of initial]
[Iter 13480/20000] Loss: 0.0003573 (Best: 0.0002945 @iter13387) ([91m↑11.61%[0m) [0.14% of initial]
[Iter 16990/20000] Loss: 0.0001666 (Best: 0.0001434 @iter16679) ([92m↓2.08%[0m) [0.07% of initial]
[Iter 13490/20000] Loss: 0.0004040 (Best: 0.0002945 @iter13387) ([91m↑13.09%[0m) [0.16% of initial]
Iter:16999, L1 loss=0.0001997, Total loss=0.000176, Time:75
[Iter 17000/20000] Loss: 0.0001597 (Best: 0.0001434 @iter16679) ([92m↓4.16%[0m) [0.06% of initial]
Iter:13499, L1 loss=0.0003894, Total loss=0.000359, Time:72
[Iter 13500/20000] Loss: 0.0003730 (Best: 0.0002945 @iter13387) ([92m↓7.67%[0m) [0.15% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 13500
Pruning 13 points (0.0%) from gaussian1 at iteration 13500
Pruning 3 points (0.0%) from gaussian0 at iteration 17000
Pruning 3 points (0.0%) from gaussian1 at iteration 17000
[Iter 13510/20000] Loss: 0.0007736 (Best: 0.0002945 @iter13387) ([91m↑107.39%[0m) [0.31% of initial]
[Iter 17010/20000] Loss: 0.0004410 (Best: 0.0001434 @iter16679) ([91m↑176.22%[0m) [0.18% of initial]
[Iter 13520/20000] Loss: 0.0004978 (Best: 0.0002945 @iter13387) ([92m↓35.64%[0m) [0.20% of initial]
[Iter 17020/20000] Loss: 0.0002884 (Best: 0.0001434 @iter16679) ([92m↓34.61%[0m) [0.11% of initial]
[Iter 13530/20000] Loss: 0.0004071 (Best: 0.0002945 @iter13387) ([92m↓18.22%[0m) [0.16% of initial]
[Iter 17030/20000] Loss: 0.0002364 (Best: 0.0001434 @iter16679) ([92m↓18.01%[0m) [0.09% of initial]
[Iter 13540/20000] Loss: 0.0003707 (Best: 0.0002945 @iter13387) ([92m↓8.94%[0m) [0.15% of initial]
[Iter 17040/20000] Loss: 0.0002443 (Best: 0.0001434 @iter16679) ([91m↑3.35%[0m) [0.10% of initial]
[Iter 13550/20000] Loss: 0.0003802 (Best: 0.0002945 @iter13387) ([91m↑2.57%[0m) [0.15% of initial]
[Iter 17050/20000] Loss: 0.0002001 (Best: 0.0001434 @iter16679) ([92m↓18.11%[0m) [0.08% of initial]
[Iter 13560/20000] Loss: 0.0003755 (Best: 0.0002945 @iter13387) ([92m↓1.24%[0m) [0.15% of initial]
[Iter 17060/20000] Loss: 0.0001695 (Best: 0.0001434 @iter16679) ([92m↓15.28%[0m) [0.07% of initial]
[Iter 13570/20000] Loss: 0.0003236 (Best: 0.0002945 @iter13387) ([92m↓13.83%[0m) [0.13% of initial]
[Iter 17070/20000] Loss: 0.0001756 (Best: 0.0001434 @iter16679) ([91m↑3.61%[0m) [0.07% of initial]
[Iter 13580/20000] Loss: 0.0003536 (Best: 0.0002945 @iter13387) ([91m↑9.28%[0m) [0.14% of initial]
[Iter 17080/20000] Loss: 0.0001585 (Best: 0.0001434 @iter16679) ([92m↓9.77%[0m) [0.06% of initial]
[Iter 13590/20000] Loss: 0.0003049 (Best: 0.0002945 @iter13387) ([92m↓13.78%[0m) [0.12% of initial]
Iter:13599, L1 loss=0.0003624, Total loss=0.0003184, Time:79
[Iter 17090/20000] Loss: 0.0001686 (Best: 0.0001434 @iter16679) ([91m↑6.36%[0m) [0.07% of initial]
[Iter 13600/20000] Loss: 0.0003041 (Best: 0.0002772 @iter13594) ([92m↓0.27%[0m) [0.12% of initial]
Iter:17099, L1 loss=0.0002132, Total loss=0.0001713, Time:77
[Iter 13610/20000] Loss: 0.0002973 (Best: 0.0002772 @iter13594) ([92m↓2.23%[0m) [0.12% of initial]
[Iter 17100/20000] Loss: 0.0001875 (Best: 0.0001434 @iter16679) ([91m↑11.25%[0m) [0.07% of initial]
[Iter 13620/20000] Loss: 0.0003046 (Best: 0.0002772 @iter13594) ([91m↑2.46%[0m) [0.12% of initial]
[Iter 17110/20000] Loss: 0.0001807 (Best: 0.0001434 @iter16679) ([92m↓3.62%[0m) [0.07% of initial]
[Iter 13630/20000] Loss: 0.0003060 (Best: 0.0002772 @iter13594) ([91m↑0.47%[0m) [0.12% of initial]
[Iter 17120/20000] Loss: 0.0001923 (Best: 0.0001434 @iter16679) ([91m↑6.40%[0m) [0.08% of initial]
[Iter 13640/20000] Loss: 0.0003103 (Best: 0.0002772 @iter13594) ([91m↑1.40%[0m) [0.12% of initial]
[Iter 17130/20000] Loss: 0.0001686 (Best: 0.0001434 @iter16679) ([92m↓12.30%[0m) [0.07% of initial]
[Iter 13650/20000] Loss: 0.0003144 (Best: 0.0002772 @iter13594) ([91m↑1.34%[0m) [0.12% of initial]
[Iter 17140/20000] Loss: 0.0001665 (Best: 0.0001434 @iter16679) ([92m↓1.25%[0m) [0.07% of initial]
[Iter 13660/20000] Loss: 0.0003140 (Best: 0.0002772 @iter13594) ([92m↓0.14%[0m) [0.12% of initial]
[Iter 17150/20000] Loss: 0.0001638 (Best: 0.0001434 @iter16679) ([92m↓1.67%[0m) [0.07% of initial]
[Iter 13670/20000] Loss: 0.0003104 (Best: 0.0002772 @iter13594) ([92m↓1.15%[0m) [0.12% of initial]
[Iter 17160/20000] Loss: 0.0001769 (Best: 0.0001434 @iter16679) ([91m↑8.01%[0m) [0.07% of initial]
[Iter 13680/20000] Loss: 0.0003318 (Best: 0.0002772 @iter13594) ([91m↑6.90%[0m) [0.13% of initial]
[Iter 17170/20000] Loss: 0.0001753 (Best: 0.0001434 @iter16679) ([92m↓0.88%[0m) [0.07% of initial]
[Iter 13690/20000] Loss: 0.0003446 (Best: 0.0002772 @iter13594) ([91m↑3.86%[0m) [0.14% of initial]
[Iter 17180/20000] Loss: 0.0002170 (Best: 0.0001434 @iter16679) ([91m↑23.75%[0m) [0.09% of initial]
Iter:13699, L1 loss=0.000377, Total loss=0.000316, Time:76
[Iter 13700/20000] Loss: 0.0003357 (Best: 0.0002772 @iter13594) ([92m↓2.57%[0m) [0.13% of initial]
[Iter 17190/20000] Loss: 0.0001823 (Best: 0.0001434 @iter16679) ([92m↓15.97%[0m) [0.07% of initial]
[Iter 13710/20000] Loss: 0.0003467 (Best: 0.0002772 @iter13594) ([91m↑3.26%[0m) [0.14% of initial]
Iter:17199, L1 loss=0.0002551, Total loss=0.0001811, Time:70
[Iter 17200/20000] Loss: 0.0001712 (Best: 0.0001434 @iter16679) ([92m↓6.12%[0m) [0.07% of initial]
[Iter 13720/20000] Loss: 0.0003409 (Best: 0.0002772 @iter13594) ([92m↓1.68%[0m) [0.14% of initial]
[Iter 17210/20000] Loss: 0.0001641 (Best: 0.0001434 @iter16679) ([92m↓4.15%[0m) [0.07% of initial]
[Iter 13730/20000] Loss: 0.0003193 (Best: 0.0002772 @iter13594) ([92m↓6.31%[0m) [0.13% of initial]
[Iter 13740/20000] Loss: 0.0003203 (Best: 0.0002772 @iter13594) ([91m↑0.28%[0m) [0.13% of initial]
[Iter 17220/20000] Loss: 0.0001764 (Best: 0.0001431 @iter17212) ([91m↑7.54%[0m) [0.07% of initial]
[Iter 13750/20000] Loss: 0.0003432 (Best: 0.0002772 @iter13594) ([91m↑7.17%[0m) [0.14% of initial]
[Iter 17230/20000] Loss: 0.0001625 (Best: 0.0001431 @iter17212) ([92m↓7.91%[0m) [0.06% of initial]
[Iter 13760/20000] Loss: 0.0003611 (Best: 0.0002772 @iter13594) ([91m↑5.22%[0m) [0.14% of initial]
[Iter 17240/20000] Loss: 0.0001596 (Best: 0.0001431 @iter17212) ([92m↓1.74%[0m) [0.06% of initial]
[Iter 13770/20000] Loss: 0.0003587 (Best: 0.0002772 @iter13594) ([92m↓0.66%[0m) [0.14% of initial]
[Iter 17250/20000] Loss: 0.0001606 (Best: 0.0001414 @iter17248) ([91m↑0.62%[0m) [0.06% of initial]
[Iter 13780/20000] Loss: 0.0003314 (Best: 0.0002772 @iter13594) ([92m↓7.61%[0m) [0.13% of initial]
[Iter 17260/20000] Loss: 0.0001598 (Best: 0.0001410 @iter17257) ([92m↓0.51%[0m) [0.06% of initial]
[Iter 13790/20000] Loss: 0.0003237 (Best: 0.0002772 @iter13594) ([92m↓2.33%[0m) [0.13% of initial]
[Iter 17270/20000] Loss: 0.0001777 (Best: 0.0001410 @iter17257) ([91m↑11.17%[0m) [0.07% of initial]
Iter:13799, L1 loss=0.00037, Total loss=0.0003298, Time:68
[Iter 13800/20000] Loss: 0.0003186 (Best: 0.0002772 @iter13594) ([92m↓1.60%[0m) [0.13% of initial]
[Iter 17280/20000] Loss: 0.0001717 (Best: 0.0001410 @iter17257) ([92m↓3.34%[0m) [0.07% of initial]
[Iter 13810/20000] Loss: 0.0003219 (Best: 0.0002772 @iter13594) ([91m↑1.04%[0m) [0.13% of initial]
[Iter 17290/20000] Loss: 0.0001590 (Best: 0.0001410 @iter17257) ([92m↓7.42%[0m) [0.06% of initial]
[Iter 13820/20000] Loss: 0.0003277 (Best: 0.0002772 @iter13594) ([91m↑1.80%[0m) [0.13% of initial]
Iter:17299, L1 loss=0.0001875, Total loss=0.0001558, Time:75
[Iter 17300/20000] Loss: 0.0001662 (Best: 0.0001410 @iter17257) ([91m↑4.56%[0m) [0.07% of initial]
[Iter 13830/20000] Loss: 0.0004162 (Best: 0.0002772 @iter13594) ([91m↑27.02%[0m) [0.17% of initial]
[Iter 17310/20000] Loss: 0.0002219 (Best: 0.0001410 @iter17257) ([91m↑33.47%[0m) [0.09% of initial]
[Iter 13840/20000] Loss: 0.0004567 (Best: 0.0002772 @iter13594) ([91m↑9.75%[0m) [0.18% of initial]
[Iter 17320/20000] Loss: 0.0001871 (Best: 0.0001410 @iter17257) ([92m↓15.69%[0m) [0.07% of initial]
[Iter 13850/20000] Loss: 0.0004024 (Best: 0.0002772 @iter13594) ([92m↓11.89%[0m) [0.16% of initial]
[Iter 17330/20000] Loss: 0.0001908 (Best: 0.0001410 @iter17257) ([91m↑2.00%[0m) [0.08% of initial]
[Iter 13860/20000] Loss: 0.0003795 (Best: 0.0002772 @iter13594) ([92m↓5.69%[0m) [0.15% of initial]
[Iter 13870/20000] Loss: 0.0003367 (Best: 0.0002772 @iter13594) ([92m↓11.28%[0m) [0.13% of initial]
[Iter 17340/20000] Loss: 0.0002157 (Best: 0.0001410 @iter17257) ([91m↑13.06%[0m) [0.09% of initial]
[Iter 13880/20000] Loss: 0.0003160 (Best: 0.0002772 @iter13594) ([92m↓6.16%[0m) [0.13% of initial]
[Iter 17350/20000] Loss: 0.0001967 (Best: 0.0001410 @iter17257) ([92m↓8.85%[0m) [0.08% of initial]
[Iter 13890/20000] Loss: 0.0003165 (Best: 0.0002772 @iter13594) ([91m↑0.17%[0m) [0.13% of initial]
[Iter 17360/20000] Loss: 0.0002008 (Best: 0.0001410 @iter17257) ([91m↑2.12%[0m) [0.08% of initial]
Iter:13899, L1 loss=0.0003838, Total loss=0.0003208, Time:73
[Iter 13900/20000] Loss: 0.0003054 (Best: 0.0002772 @iter13594) ([92m↓3.52%[0m) [0.12% of initial]
[Iter 17370/20000] Loss: 0.0001794 (Best: 0.0001410 @iter17257) ([92m↓10.69%[0m) [0.07% of initial]
[Iter 13910/20000] Loss: 0.0003247 (Best: 0.0002772 @iter13594) ([91m↑6.32%[0m) [0.13% of initial]
[Iter 17380/20000] Loss: 0.0001596 (Best: 0.0001410 @iter17257) ([92m↓11.04%[0m) [0.06% of initial]
[Iter 13920/20000] Loss: 0.0003713 (Best: 0.0002772 @iter13594) ([91m↑14.37%[0m) [0.15% of initial]
[Iter 17390/20000] Loss: 0.0001701 (Best: 0.0001410 @iter17257) ([91m↑6.58%[0m) [0.07% of initial]
[Iter 13930/20000] Loss: 0.0003961 (Best: 0.0002772 @iter13594) ([91m↑6.69%[0m) [0.16% of initial]
Iter:17399, L1 loss=0.000195, Total loss=0.0001764, Time:73
[Iter 17400/20000] Loss: 0.0001705 (Best: 0.0001410 @iter17257) ([91m↑0.29%[0m) [0.07% of initial]
[Iter 13940/20000] Loss: 0.0003322 (Best: 0.0002772 @iter13594) ([92m↓16.13%[0m) [0.13% of initial]
[Iter 17410/20000] Loss: 0.0001721 (Best: 0.0001410 @iter17257) ([91m↑0.92%[0m) [0.07% of initial]
[Iter 13950/20000] Loss: 0.0003448 (Best: 0.0002772 @iter13594) ([91m↑3.77%[0m) [0.14% of initial]
[Iter 17420/20000] Loss: 0.0001749 (Best: 0.0001410 @iter17257) ([91m↑1.64%[0m) [0.07% of initial]
[Iter 13960/20000] Loss: 0.0003317 (Best: 0.0002772 @iter13594) ([92m↓3.79%[0m) [0.13% of initial]
[Iter 17430/20000] Loss: 0.0001602 (Best: 0.0001410 @iter17257) ([92m↓8.43%[0m) [0.06% of initial]
[Iter 13970/20000] Loss: 0.0003201 (Best: 0.0002772 @iter13594) ([92m↓3.48%[0m) [0.13% of initial]
[Iter 17440/20000] Loss: 0.0001717 (Best: 0.0001410 @iter17257) ([91m↑7.19%[0m) [0.07% of initial]
[Iter 13980/20000] Loss: 0.0003398 (Best: 0.0002772 @iter13594) ([91m↑6.14%[0m) [0.13% of initial]
[Iter 13990/20000] Loss: 0.0003233 (Best: 0.0002772 @iter13594) ([92m↓4.85%[0m) [0.13% of initial]
[Iter 17450/20000] Loss: 0.0002084 (Best: 0.0001410 @iter17257) ([91m↑21.38%[0m) [0.08% of initial]
Iter:13999, L1 loss=0.0003735, Total loss=0.000326, Time:74
[Iter 14000/20000] Loss: 0.0003269 (Best: 0.0002772 @iter13594) ([91m↑1.10%[0m) [0.13% of initial]
[Iter 17460/20000] Loss: 0.0002101 (Best: 0.0001410 @iter17257) ([91m↑0.81%[0m) [0.08% of initial]
Pruning 5 points (0.0%) from gaussian0 at iteration 14000
[Iter 17470/20000] Loss: 0.0001692 (Best: 0.0001410 @iter17257) ([92m↓19.45%[0m) [0.07% of initial]
Pruning 14 points (0.0%) from gaussian1 at iteration 14000
[Iter 17480/20000] Loss: 0.0001727 (Best: 0.0001410 @iter17257) ([91m↑2.07%[0m) [0.07% of initial]
[Iter 14010/20000] Loss: 0.0293716 (Best: 0.0002772 @iter13594) ([91m↑8885.50%[0m) [11.67% of initial]
[Iter 17490/20000] Loss: 0.0001938 (Best: 0.0001410 @iter17257) ([91m↑12.19%[0m) [0.08% of initial]
[Iter 14020/20000] Loss: 0.0090976 (Best: 0.0002772 @iter13594) ([92m↓69.03%[0m) [3.61% of initial]
Iter:17499, L1 loss=0.000261, Total loss=0.0002159, Time:78
[Iter 17500/20000] Loss: 0.0001931 (Best: 0.0001410 @iter17257) ([92m↓0.35%[0m) [0.08% of initial]
[Iter 14030/20000] Loss: 0.0051719 (Best: 0.0002772 @iter13594) ([92m↓43.15%[0m) [2.05% of initial]
[Iter 14040/20000] Loss: 0.0029205 (Best: 0.0002772 @iter13594) ([92m↓43.53%[0m) [1.16% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 17500
Pruning 1 points (0.0%) from gaussian1 at iteration 17500
[Iter 14050/20000] Loss: 0.0018236 (Best: 0.0002772 @iter13594) ([92m↓37.56%[0m) [0.72% of initial]
[Iter 17510/20000] Loss: 0.0003536 (Best: 0.0001410 @iter17257) ([91m↑83.08%[0m) [0.14% of initial]
[Iter 14060/20000] Loss: 0.0013418 (Best: 0.0002772 @iter13594) ([92m↓26.42%[0m) [0.53% of initial]
[Iter 17520/20000] Loss: 0.0002866 (Best: 0.0001410 @iter17257) ([92m↓18.93%[0m) [0.11% of initial]
[Iter 14070/20000] Loss: 0.0011091 (Best: 0.0002772 @iter13594) ([92m↓17.34%[0m) [0.44% of initial]
[Iter 14080/20000] Loss: 0.0009272 (Best: 0.0002772 @iter13594) ([92m↓16.40%[0m) [0.37% of initial]
[Iter 17530/20000] Loss: 0.0002372 (Best: 0.0001410 @iter17257) ([92m↓17.25%[0m) [0.09% of initial]
[Iter 14090/20000] Loss: 0.0007914 (Best: 0.0002772 @iter13594) ([92m↓14.65%[0m) [0.31% of initial]
[Iter 17540/20000] Loss: 0.0001919 (Best: 0.0001410 @iter17257) ([92m↓19.10%[0m) [0.08% of initial]
Iter:14099, L1 loss=0.0007191, Total loss=0.0007004, Time:77
[Iter 14100/20000] Loss: 0.0007135 (Best: 0.0002772 @iter13594) ([92m↓9.84%[0m) [0.28% of initial]
[Iter 17550/20000] Loss: 0.0001769 (Best: 0.0001410 @iter17257) ([92m↓7.80%[0m) [0.07% of initial]
[Iter 14110/20000] Loss: 0.0006441 (Best: 0.0002772 @iter13594) ([92m↓9.72%[0m) [0.26% of initial]
[Iter 17560/20000] Loss: 0.0001999 (Best: 0.0001410 @iter17257) ([91m↑13.02%[0m) [0.08% of initial]
[Iter 14120/20000] Loss: 0.0005949 (Best: 0.0002772 @iter13594) ([92m↓7.64%[0m) [0.24% of initial]
[Iter 17570/20000] Loss: 0.0001821 (Best: 0.0001410 @iter17257) ([92m↓8.94%[0m) [0.07% of initial]
[Iter 14130/20000] Loss: 0.0005746 (Best: 0.0002772 @iter13594) ([92m↓3.42%[0m) [0.23% of initial]
[Iter 17580/20000] Loss: 0.0001714 (Best: 0.0001410 @iter17257) ([92m↓5.85%[0m) [0.07% of initial]
[Iter 14140/20000] Loss: 0.0005366 (Best: 0.0002772 @iter13594) ([92m↓6.61%[0m) [0.21% of initial]
[Iter 17590/20000] Loss: 0.0001729 (Best: 0.0001410 @iter17257) ([91m↑0.86%[0m) [0.07% of initial]
[Iter 14150/20000] Loss: 0.0005142 (Best: 0.0002772 @iter13594) ([92m↓4.17%[0m) [0.20% of initial]
Iter:17599, L1 loss=0.0002363, Total loss=0.0002338, Time:75
[Iter 17600/20000] Loss: 0.0001883 (Best: 0.0001410 @iter17257) ([91m↑8.90%[0m) [0.07% of initial]
[Iter 14160/20000] Loss: 0.0004990 (Best: 0.0002772 @iter13594) ([92m↓2.96%[0m) [0.20% of initial]
[Iter 17610/20000] Loss: 0.0001612 (Best: 0.0001410 @iter17257) ([92m↓14.37%[0m) [0.06% of initial]
[Iter 14170/20000] Loss: 0.0004731 (Best: 0.0002772 @iter13594) ([92m↓5.20%[0m) [0.19% of initial]
[Iter 17620/20000] Loss: 0.0001460 (Best: 0.0001378 @iter17620) ([92m↓9.46%[0m) [0.06% of initial]
[Iter 14180/20000] Loss: 0.0004556 (Best: 0.0002772 @iter13594) ([92m↓3.68%[0m) [0.18% of initial]
[Iter 17630/20000] Loss: 0.0001537 (Best: 0.0001378 @iter17620) ([91m↑5.27%[0m) [0.06% of initial]
[Iter 14190/20000] Loss: 0.0004459 (Best: 0.0002772 @iter13594) ([92m↓2.14%[0m) [0.18% of initial]
Iter:14199, L1 loss=0.0004708, Total loss=0.0004277, Time:69
[Iter 17640/20000] Loss: 0.0001584 (Best: 0.0001355 @iter17633) ([91m↑3.09%[0m) [0.06% of initial]
[Iter 14200/20000] Loss: 0.0004270 (Best: 0.0002772 @iter13594) ([92m↓4.25%[0m) [0.17% of initial]
[Iter 14210/20000] Loss: 0.0004387 (Best: 0.0002772 @iter13594) ([91m↑2.76%[0m) [0.17% of initial]
[Iter 17650/20000] Loss: 0.0001692 (Best: 0.0001355 @iter17633) ([91m↑6.78%[0m) [0.07% of initial]
[Iter 14220/20000] Loss: 0.0004347 (Best: 0.0002772 @iter13594) ([92m↓0.91%[0m) [0.17% of initial]
[Iter 17660/20000] Loss: 0.0001489 (Best: 0.0001355 @iter17633) ([92m↓12.00%[0m) [0.06% of initial]
[Iter 14230/20000] Loss: 0.0004307 (Best: 0.0002772 @iter13594) ([92m↓0.94%[0m) [0.17% of initial]
[Iter 17670/20000] Loss: 0.0001567 (Best: 0.0001355 @iter17633) ([91m↑5.28%[0m) [0.06% of initial]
[Iter 14240/20000] Loss: 0.0004235 (Best: 0.0002772 @iter13594) ([92m↓1.67%[0m) [0.17% of initial]
[Iter 17680/20000] Loss: 0.0001531 (Best: 0.0001355 @iter17633) ([92m↓2.28%[0m) [0.06% of initial]
[Iter 14250/20000] Loss: 0.0004228 (Best: 0.0002772 @iter13594) ([92m↓0.16%[0m) [0.17% of initial]
[Iter 17690/20000] Loss: 0.0002625 (Best: 0.0001355 @iter17633) ([91m↑71.44%[0m) [0.10% of initial]
[Iter 14260/20000] Loss: 0.0004220 (Best: 0.0002772 @iter13594) ([92m↓0.19%[0m) [0.17% of initial]
Iter:17699, L1 loss=0.0002681, Total loss=0.0002342, Time:77
[Iter 17700/20000] Loss: 0.0002683 (Best: 0.0001355 @iter17633) ([91m↑2.20%[0m) [0.11% of initial]
[Iter 14270/20000] Loss: 0.0004199 (Best: 0.0002772 @iter13594) ([92m↓0.49%[0m) [0.17% of initial]
[Iter 17710/20000] Loss: 0.0002251 (Best: 0.0001355 @iter17633) ([92m↓16.12%[0m) [0.09% of initial]
[Iter 14280/20000] Loss: 0.0004150 (Best: 0.0002772 @iter13594) ([92m↓1.16%[0m) [0.16% of initial]
[Iter 17720/20000] Loss: 0.0001968 (Best: 0.0001355 @iter17633) ([92m↓12.54%[0m) [0.08% of initial]
[Iter 14290/20000] Loss: 0.0004093 (Best: 0.0002772 @iter13594) ([92m↓1.39%[0m) [0.16% of initial]
[Iter 17730/20000] Loss: 0.0002006 (Best: 0.0001355 @iter17633) ([91m↑1.89%[0m) [0.08% of initial]
Iter:14299, L1 loss=0.0004466, Total loss=0.0003989, Time:79
[Iter 14300/20000] Loss: 0.0004011 (Best: 0.0002772 @iter13594) ([92m↓2.00%[0m) [0.16% of initial]
[Iter 17740/20000] Loss: 0.0001910 (Best: 0.0001355 @iter17633) ([92m↓4.76%[0m) [0.08% of initial]
[Iter 14310/20000] Loss: 0.0004056 (Best: 0.0002772 @iter13594) ([91m↑1.13%[0m) [0.16% of initial]
[Iter 17750/20000] Loss: 0.0001628 (Best: 0.0001355 @iter17633) ([92m↓14.80%[0m) [0.06% of initial]
[Iter 14320/20000] Loss: 0.0003963 (Best: 0.0002772 @iter13594) ([92m↓2.28%[0m) [0.16% of initial]
[Iter 17760/20000] Loss: 0.0001606 (Best: 0.0001355 @iter17633) ([92m↓1.35%[0m) [0.06% of initial]
[Iter 14330/20000] Loss: 0.0004042 (Best: 0.0002772 @iter13594) ([91m↑1.99%[0m) [0.16% of initial]
[Iter 17770/20000] Loss: 0.0001514 (Best: 0.0001355 @iter17633) ([92m↓5.69%[0m) [0.06% of initial]
[Iter 14340/20000] Loss: 0.0004154 (Best: 0.0002772 @iter13594) ([91m↑2.77%[0m) [0.17% of initial]
[Iter 14350/20000] Loss: 0.0004024 (Best: 0.0002772 @iter13594) ([92m↓3.13%[0m) [0.16% of initial]
[Iter 17780/20000] Loss: 0.0001690 (Best: 0.0001355 @iter17633) ([91m↑11.60%[0m) [0.07% of initial]
[Iter 14360/20000] Loss: 0.0003952 (Best: 0.0002772 @iter13594) ([92m↓1.79%[0m) [0.16% of initial]
[Iter 17790/20000] Loss: 0.0001692 (Best: 0.0001355 @iter17633) ([91m↑0.16%[0m) [0.07% of initial]
[Iter 14370/20000] Loss: 0.0004009 (Best: 0.0002772 @iter13594) ([91m↑1.45%[0m) [0.16% of initial]
Iter:17799, L1 loss=0.0002073, Total loss=0.0001843, Time:74
[Iter 17800/20000] Loss: 0.0001580 (Best: 0.0001355 @iter17633) ([92m↓6.65%[0m) [0.06% of initial]
[Iter 14380/20000] Loss: 0.0004196 (Best: 0.0002772 @iter13594) ([91m↑4.67%[0m) [0.17% of initial]
[Iter 17810/20000] Loss: 0.0001669 (Best: 0.0001355 @iter17633) ([91m↑5.65%[0m) [0.07% of initial]
[Iter 14390/20000] Loss: 0.0004394 (Best: 0.0002772 @iter13594) ([91m↑4.71%[0m) [0.17% of initial]
[Iter 17820/20000] Loss: 0.0001763 (Best: 0.0001355 @iter17633) ([91m↑5.64%[0m) [0.07% of initial]
Iter:14399, L1 loss=0.0004471, Total loss=0.0003923, Time:72
[Iter 14400/20000] Loss: 0.0004062 (Best: 0.0002772 @iter13594) ([92m↓7.56%[0m) [0.16% of initial]
[Iter 17830/20000] Loss: 0.0001632 (Best: 0.0001355 @iter17633) ([92m↓7.47%[0m) [0.06% of initial]
[Iter 14410/20000] Loss: 0.0003947 (Best: 0.0002772 @iter13594) ([92m↓2.83%[0m) [0.16% of initial]
[Iter 17840/20000] Loss: 0.0001611 (Best: 0.0001355 @iter17633) ([92m↓1.27%[0m) [0.06% of initial]
[Iter 14420/20000] Loss: 0.0003894 (Best: 0.0002772 @iter13594) ([92m↓1.34%[0m) [0.15% of initial]
[Iter 17850/20000] Loss: 0.0001816 (Best: 0.0001355 @iter17633) ([91m↑12.75%[0m) [0.07% of initial]
[Iter 14430/20000] Loss: 0.0004014 (Best: 0.0002772 @iter13594) ([91m↑3.09%[0m) [0.16% of initial]
[Iter 17860/20000] Loss: 0.0001582 (Best: 0.0001355 @iter17633) ([92m↓12.91%[0m) [0.06% of initial]
[Iter 14440/20000] Loss: 0.0003875 (Best: 0.0002772 @iter13594) ([92m↓3.46%[0m) [0.15% of initial]
[Iter 17870/20000] Loss: 0.0001487 (Best: 0.0001355 @iter17633) ([92m↓6.00%[0m) [0.06% of initial]
[Iter 14450/20000] Loss: 0.0003866 (Best: 0.0002772 @iter13594) ([92m↓0.24%[0m) [0.15% of initial]
[Iter 17880/20000] Loss: 0.0002025 (Best: 0.0001355 @iter17633) ([91m↑36.21%[0m) [0.08% of initial]
[Iter 14460/20000] Loss: 0.0003964 (Best: 0.0002772 @iter13594) ([91m↑2.53%[0m) [0.16% of initial]
[Iter 17890/20000] Loss: 0.0001753 (Best: 0.0001355 @iter17633) ([92m↓13.43%[0m) [0.07% of initial]
[Iter 14470/20000] Loss: 0.0004098 (Best: 0.0002772 @iter13594) ([91m↑3.39%[0m) [0.16% of initial]
Iter:17899, L1 loss=0.0002114, Total loss=0.0001694, Time:74
[Iter 14480/20000] Loss: 0.0003999 (Best: 0.0002772 @iter13594) ([92m↓2.44%[0m) [0.16% of initial]
[Iter 17900/20000] Loss: 0.0001979 (Best: 0.0001355 @iter17633) ([91m↑12.88%[0m) [0.08% of initial]
[Iter 14490/20000] Loss: 0.0004017 (Best: 0.0002772 @iter13594) ([91m↑0.45%[0m) [0.16% of initial]
[Iter 17910/20000] Loss: 0.0001843 (Best: 0.0001355 @iter17633) ([92m↓6.88%[0m) [0.07% of initial]
Iter:14499, L1 loss=0.0004646, Total loss=0.0003945, Time:75
[Iter 14500/20000] Loss: 0.0004071 (Best: 0.0002772 @iter13594) ([91m↑1.36%[0m) [0.16% of initial]
[Iter 17920/20000] Loss: 0.0001892 (Best: 0.0001355 @iter17633) ([91m↑2.64%[0m) [0.08% of initial]
Pruning 16 points (0.0%) from gaussian0 at iteration 14500
[Iter 17930/20000] Loss: 0.0001906 (Best: 0.0001355 @iter17633) ([91m↑0.73%[0m) [0.08% of initial]
Pruning 16 points (0.0%) from gaussian1 at iteration 14500
[Iter 17940/20000] Loss: 0.0001704 (Best: 0.0001355 @iter17633) ([92m↓10.58%[0m) [0.07% of initial]
[Iter 14510/20000] Loss: 0.0007008 (Best: 0.0002772 @iter13594) ([91m↑72.14%[0m) [0.28% of initial]
[Iter 17950/20000] Loss: 0.0001850 (Best: 0.0001355 @iter17633) ([91m↑8.54%[0m) [0.07% of initial]
[Iter 14520/20000] Loss: 0.0005350 (Best: 0.0002772 @iter13594) ([92m↓23.66%[0m) [0.21% of initial]
[Iter 14530/20000] Loss: 0.0004422 (Best: 0.0002772 @iter13594) ([92m↓17.35%[0m) [0.18% of initial]
[Iter 17960/20000] Loss: 0.0001743 (Best: 0.0001355 @iter17633) ([92m↓5.75%[0m) [0.07% of initial]
[Iter 14540/20000] Loss: 0.0003911 (Best: 0.0002772 @iter13594) ([92m↓11.55%[0m) [0.16% of initial]
[Iter 17970/20000] Loss: 0.0001713 (Best: 0.0001355 @iter17633) ([92m↓1.71%[0m) [0.07% of initial]
[Iter 14550/20000] Loss: 0.0003899 (Best: 0.0002772 @iter13594) ([92m↓0.32%[0m) [0.15% of initial]
[Iter 17980/20000] Loss: 0.0001605 (Best: 0.0001355 @iter17633) ([92m↓6.34%[0m) [0.06% of initial]
[Iter 14560/20000] Loss: 0.0003754 (Best: 0.0002772 @iter13594) ([92m↓3.70%[0m) [0.15% of initial]
[Iter 17990/20000] Loss: 0.0001710 (Best: 0.0001355 @iter17633) ([91m↑6.57%[0m) [0.07% of initial]
[Iter 14570/20000] Loss: 0.0003774 (Best: 0.0002772 @iter13594) ([91m↑0.52%[0m) [0.15% of initial]
Iter:17999, L1 loss=0.0002709, Total loss=0.0002002, Time:74
[Iter 18000/20000] Loss: 0.0001898 (Best: 0.0001355 @iter17633) ([91m↑10.99%[0m) [0.08% of initial]
[Iter 14580/20000] Loss: 0.0003872 (Best: 0.0002772 @iter13594) ([91m↑2.60%[0m) [0.15% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 18000
[Iter 14590/20000] Loss: 0.0003890 (Best: 0.0002772 @iter13594) ([91m↑0.47%[0m) [0.15% of initial]
Pruning 0 points (0.0%) from gaussian1 at iteration 18000
Iter:14599, L1 loss=0.000421, Total loss=0.0003948, Time:68
[Iter 14600/20000] Loss: 0.0003938 (Best: 0.0002772 @iter13594) ([91m↑1.23%[0m) [0.16% of initial]
[Iter 18010/20000] Loss: 0.0003467 (Best: 0.0001355 @iter17633) ([91m↑82.67%[0m) [0.14% of initial]
[Iter 14610/20000] Loss: 0.0004257 (Best: 0.0002772 @iter13594) ([91m↑8.11%[0m) [0.17% of initial]
[Iter 18020/20000] Loss: 0.0003182 (Best: 0.0001355 @iter17633) ([92m↓8.23%[0m) [0.13% of initial]
[Iter 14620/20000] Loss: 0.0004346 (Best: 0.0002772 @iter13594) ([91m↑2.09%[0m) [0.17% of initial]
[Iter 18030/20000] Loss: 0.0002464 (Best: 0.0001355 @iter17633) ([92m↓22.56%[0m) [0.10% of initial]
[Iter 14630/20000] Loss: 0.0004865 (Best: 0.0002772 @iter13594) ([91m↑11.93%[0m) [0.19% of initial]
[Iter 18040/20000] Loss: 0.0002088 (Best: 0.0001355 @iter17633) ([92m↓15.27%[0m) [0.08% of initial]
[Iter 14640/20000] Loss: 0.0004347 (Best: 0.0002772 @iter13594) ([92m↓10.65%[0m) [0.17% of initial]
[Iter 18050/20000] Loss: 0.0001869 (Best: 0.0001355 @iter17633) ([92m↓10.48%[0m) [0.07% of initial]
[Iter 14650/20000] Loss: 0.0004008 (Best: 0.0002772 @iter13594) ([92m↓7.78%[0m) [0.16% of initial]
[Iter 18060/20000] Loss: 0.0001738 (Best: 0.0001355 @iter17633) ([92m↓7.01%[0m) [0.07% of initial]
[Iter 14660/20000] Loss: 0.0004366 (Best: 0.0002772 @iter13594) ([91m↑8.93%[0m) [0.17% of initial]
[Iter 18070/20000] Loss: 0.0001621 (Best: 0.0001355 @iter17633) ([92m↓6.73%[0m) [0.06% of initial]
[Iter 14670/20000] Loss: 0.0004724 (Best: 0.0002772 @iter13594) ([91m↑8.20%[0m) [0.19% of initial]
[Iter 18080/20000] Loss: 0.0001537 (Best: 0.0001355 @iter17633) ([92m↓5.20%[0m) [0.06% of initial]
[Iter 14680/20000] Loss: 0.0004355 (Best: 0.0002772 @iter13594) ([92m↓7.82%[0m) [0.17% of initial]
[Iter 18090/20000] Loss: 0.0001703 (Best: 0.0001355 @iter17633) ([91m↑10.79%[0m) [0.07% of initial]
[Iter 14690/20000] Loss: 0.0005055 (Best: 0.0002772 @iter13594) ([91m↑16.08%[0m) [0.20% of initial]
Iter:14699, L1 loss=0.000458, Total loss=0.000416, Time:70
Iter:18099, L1 loss=0.0002264, Total loss=0.0001956, Time:72
[Iter 14700/20000] Loss: 0.0004546 (Best: 0.0002772 @iter13594) ([92m↓10.06%[0m) [0.18% of initial]
[Iter 18100/20000] Loss: 0.0001728 (Best: 0.0001355 @iter17633) ([91m↑1.48%[0m) [0.07% of initial]
[Iter 14710/20000] Loss: 0.0004393 (Best: 0.0002772 @iter13594) ([92m↓3.38%[0m) [0.17% of initial]
[Iter 18110/20000] Loss: 0.0001847 (Best: 0.0001355 @iter17633) ([91m↑6.88%[0m) [0.07% of initial]
[Iter 14720/20000] Loss: 0.0004256 (Best: 0.0002772 @iter13594) ([92m↓3.12%[0m) [0.17% of initial]
[Iter 18120/20000] Loss: 0.0001569 (Best: 0.0001355 @iter17633) ([92m↓15.02%[0m) [0.06% of initial]
[Iter 14730/20000] Loss: 0.0004015 (Best: 0.0002772 @iter13594) ([92m↓5.66%[0m) [0.16% of initial]
[Iter 18130/20000] Loss: 0.0001596 (Best: 0.0001355 @iter17633) ([91m↑1.68%[0m) [0.06% of initial]
[Iter 14740/20000] Loss: 0.0003885 (Best: 0.0002772 @iter13594) ([92m↓3.25%[0m) [0.15% of initial]
[Iter 18140/20000] Loss: 0.0001507 (Best: 0.0001355 @iter17633) ([92m↓5.55%[0m) [0.06% of initial]
[Iter 14750/20000] Loss: 0.0003863 (Best: 0.0002772 @iter13594) ([92m↓0.56%[0m) [0.15% of initial]
[Iter 18150/20000] Loss: 0.0001723 (Best: 0.0001355 @iter17633) ([91m↑14.30%[0m) [0.07% of initial]
[Iter 14760/20000] Loss: 0.0003851 (Best: 0.0002772 @iter13594) ([92m↓0.32%[0m) [0.15% of initial]
[Iter 18160/20000] Loss: 0.0001690 (Best: 0.0001355 @iter17633) ([92m↓1.90%[0m) [0.07% of initial]
[Iter 14770/20000] Loss: 0.0004038 (Best: 0.0002772 @iter13594) ([91m↑4.86%[0m) [0.16% of initial]
[Iter 18170/20000] Loss: 0.0001492 (Best: 0.0001355 @iter17633) ([92m↓11.70%[0m) [0.06% of initial]
[Iter 14780/20000] Loss: 0.0003813 (Best: 0.0002772 @iter13594) ([92m↓5.57%[0m) [0.15% of initial]
[Iter 18180/20000] Loss: 0.0001690 (Best: 0.0001355 @iter17633) ([91m↑13.27%[0m) [0.07% of initial]
[Iter 14790/20000] Loss: 0.0003853 (Best: 0.0002772 @iter13594) ([91m↑1.05%[0m) [0.15% of initial]
[Iter 18190/20000] Loss: 0.0001581 (Best: 0.0001355 @iter17633) ([92m↓6.46%[0m) [0.06% of initial]
Iter:14799, L1 loss=0.0004296, Total loss=0.0003807, Time:72
[Iter 14800/20000] Loss: 0.0003783 (Best: 0.0002772 @iter13594) ([92m↓1.81%[0m) [0.15% of initial]
Iter:18199, L1 loss=0.0001893, Total loss=0.0001596, Time:72
[Iter 18200/20000] Loss: 0.0001640 (Best: 0.0001355 @iter17633) ([91m↑3.70%[0m) [0.07% of initial]
[Iter 14810/20000] Loss: 0.0003572 (Best: 0.0002772 @iter13594) ([92m↓5.59%[0m) [0.14% of initial]
[Iter 18210/20000] Loss: 0.0002005 (Best: 0.0001355 @iter17633) ([91m↑22.27%[0m) [0.08% of initial]
[Iter 14820/20000] Loss: 0.0003690 (Best: 0.0002772 @iter13594) ([91m↑3.33%[0m) [0.15% of initial]
[Iter 14830/20000] Loss: 0.0003608 (Best: 0.0002772 @iter13594) ([92m↓2.25%[0m) [0.14% of initial]
[Iter 18220/20000] Loss: 0.0001815 (Best: 0.0001355 @iter17633) ([92m↓9.48%[0m) [0.07% of initial]
[Iter 14840/20000] Loss: 0.0003638 (Best: 0.0002772 @iter13594) ([91m↑0.85%[0m) [0.14% of initial]
[Iter 18230/20000] Loss: 0.0001765 (Best: 0.0001355 @iter17633) ([92m↓2.75%[0m) [0.07% of initial]
[Iter 14850/20000] Loss: 0.0003762 (Best: 0.0002772 @iter13594) ([91m↑3.40%[0m) [0.15% of initial]
[Iter 18240/20000] Loss: 0.0001623 (Best: 0.0001355 @iter17633) ([92m↓8.04%[0m) [0.06% of initial]
[Iter 14860/20000] Loss: 0.0003695 (Best: 0.0002772 @iter13594) ([92m↓1.78%[0m) [0.15% of initial]
[Iter 18250/20000] Loss: 0.0001450 (Best: 0.0001355 @iter17633) ([92m↓10.65%[0m) [0.06% of initial]
[Iter 14870/20000] Loss: 0.0003764 (Best: 0.0002772 @iter13594) ([91m↑1.87%[0m) [0.15% of initial]
[Iter 18260/20000] Loss: 0.0001880 (Best: 0.0001354 @iter18251) ([91m↑29.69%[0m) [0.07% of initial]
[Iter 14880/20000] Loss: 0.0003791 (Best: 0.0002772 @iter13594) ([91m↑0.71%[0m) [0.15% of initial]
[Iter 18270/20000] Loss: 0.0001744 (Best: 0.0001354 @iter18251) ([92m↓7.26%[0m) [0.07% of initial]
[Iter 14890/20000] Loss: 0.0003851 (Best: 0.0002772 @iter13594) ([91m↑1.58%[0m) [0.15% of initial]
[Iter 18280/20000] Loss: 0.0002133 (Best: 0.0001354 @iter18251) ([91m↑22.31%[0m) [0.08% of initial]
Iter:14899, L1 loss=0.0004363, Total loss=0.0004069, Time:74
[Iter 14900/20000] Loss: 0.0004196 (Best: 0.0002772 @iter13594) ([91m↑8.95%[0m) [0.17% of initial]
[Iter 18290/20000] Loss: 0.0001966 (Best: 0.0001354 @iter18251) ([92m↓7.83%[0m) [0.08% of initial]
[Iter 14910/20000] Loss: 0.0004351 (Best: 0.0002772 @iter13594) ([91m↑3.70%[0m) [0.17% of initial]
Iter:18299, L1 loss=0.0002623, Total loss=0.000208, Time:73
[Iter 18300/20000] Loss: 0.0001981 (Best: 0.0001354 @iter18251) ([91m↑0.74%[0m) [0.08% of initial]
[Iter 14920/20000] Loss: 0.0004321 (Best: 0.0002772 @iter13594) ([92m↓0.69%[0m) [0.17% of initial]
[Iter 18310/20000] Loss: 0.0001756 (Best: 0.0001354 @iter18251) ([92m↓11.33%[0m) [0.07% of initial]
[Iter 14930/20000] Loss: 0.0004212 (Best: 0.0002772 @iter13594) ([92m↓2.51%[0m) [0.17% of initial]
[Iter 18320/20000] Loss: 0.0001814 (Best: 0.0001354 @iter18251) ([91m↑3.31%[0m) [0.07% of initial]
[Iter 14940/20000] Loss: 0.0004068 (Best: 0.0002772 @iter13594) ([92m↓3.43%[0m) [0.16% of initial]
[Iter 18330/20000] Loss: 0.0002024 (Best: 0.0001354 @iter18251) ([91m↑11.59%[0m) [0.08% of initial]
[Iter 14950/20000] Loss: 0.0003836 (Best: 0.0002772 @iter13594) ([92m↓5.71%[0m) [0.15% of initial]
[Iter 14960/20000] Loss: 0.0003687 (Best: 0.0002772 @iter13594) ([92m↓3.89%[0m) [0.15% of initial]
[Iter 18340/20000] Loss: 0.0001682 (Best: 0.0001354 @iter18251) ([92m↓16.94%[0m) [0.07% of initial]
[Iter 14970/20000] Loss: 0.0003949 (Best: 0.0002772 @iter13594) ([91m↑7.11%[0m) [0.16% of initial]
[Iter 18350/20000] Loss: 0.0001620 (Best: 0.0001354 @iter18251) ([92m↓3.63%[0m) [0.06% of initial]
[Iter 14980/20000] Loss: 0.0004238 (Best: 0.0002772 @iter13594) ([91m↑7.32%[0m) [0.17% of initial]
[Iter 18360/20000] Loss: 0.0001599 (Best: 0.0001333 @iter18358) ([92m↓1.32%[0m) [0.06% of initial]
[Iter 14990/20000] Loss: 0.0004116 (Best: 0.0002772 @iter13594) ([92m↓2.89%[0m) [0.16% of initial]
[Iter 18370/20000] Loss: 0.0001673 (Best: 0.0001333 @iter18358) ([91m↑4.63%[0m) [0.07% of initial]
Iter:14999, L1 loss=0.0004394, Total loss=0.0004048, Time:68
[Iter 15000/20000] Loss: 0.0004096 (Best: 0.0002772 @iter13594) ([92m↓0.47%[0m) [0.16% of initial]
[Iter 18380/20000] Loss: 0.0001642 (Best: 0.0001333 @iter18358) ([92m↓1.87%[0m) [0.07% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 15000
Pruning 9 points (0.0%) from gaussian1 at iteration 15000
[Iter 18390/20000] Loss: 0.0001656 (Best: 0.0001333 @iter18358) ([91m↑0.84%[0m) [0.07% of initial]
Iter:18399, L1 loss=0.0001767, Total loss=0.0001544, Time:73
[Iter 15010/20000] Loss: 0.0006750 (Best: 0.0002772 @iter13594) ([91m↑64.77%[0m) [0.27% of initial]
[Iter 18400/20000] Loss: 0.0001681 (Best: 0.0001333 @iter18358) ([91m↑1.53%[0m) [0.07% of initial]
[Iter 15020/20000] Loss: 0.0004692 (Best: 0.0002772 @iter13594) ([92m↓30.48%[0m) [0.19% of initial]
[Iter 18410/20000] Loss: 0.0002638 (Best: 0.0001333 @iter18358) ([91m↑56.94%[0m) [0.10% of initial]
[Iter 15030/20000] Loss: 0.0004175 (Best: 0.0002772 @iter13594) ([92m↓11.03%[0m) [0.17% of initial]
[Iter 18420/20000] Loss: 0.0002236 (Best: 0.0001333 @iter18358) ([92m↓15.25%[0m) [0.09% of initial]
[Iter 15040/20000] Loss: 0.0004032 (Best: 0.0002772 @iter13594) ([92m↓3.42%[0m) [0.16% of initial]
[Iter 18430/20000] Loss: 0.0002566 (Best: 0.0001333 @iter18358) ([91m↑14.77%[0m) [0.10% of initial]
[Iter 15050/20000] Loss: 0.0003820 (Best: 0.0002772 @iter13594) ([92m↓5.27%[0m) [0.15% of initial]
[Iter 18440/20000] Loss: 0.0002244 (Best: 0.0001333 @iter18358) ([92m↓12.53%[0m) [0.09% of initial]
[Iter 15060/20000] Loss: 0.0003698 (Best: 0.0002772 @iter13594) ([92m↓3.17%[0m) [0.15% of initial]
[Iter 18450/20000] Loss: 0.0001856 (Best: 0.0001333 @iter18358) ([92m↓17.32%[0m) [0.07% of initial]
[Iter 15070/20000] Loss: 0.0003651 (Best: 0.0002772 @iter13594) ([92m↓1.29%[0m) [0.15% of initial]
[Iter 18460/20000] Loss: 0.0001878 (Best: 0.0001333 @iter18358) ([91m↑1.20%[0m) [0.07% of initial]
[Iter 15080/20000] Loss: 0.0003609 (Best: 0.0002772 @iter13594) ([92m↓1.15%[0m) [0.14% of initial]
[Iter 18470/20000] Loss: 0.0001749 (Best: 0.0001333 @iter18358) ([92m↓6.89%[0m) [0.07% of initial]
[Iter 15090/20000] Loss: 0.0003744 (Best: 0.0002772 @iter13594) ([91m↑3.74%[0m) [0.15% of initial]
[Iter 18480/20000] Loss: 0.0001776 (Best: 0.0001333 @iter18358) ([91m↑1.55%[0m) [0.07% of initial]
Iter:15099, L1 loss=0.0004582, Total loss=0.0004007, Time:66
[Iter 15100/20000] Loss: 0.0003868 (Best: 0.0002772 @iter13594) ([91m↑3.32%[0m) [0.15% of initial]
[Iter 18490/20000] Loss: 0.0001942 (Best: 0.0001333 @iter18358) ([91m↑9.38%[0m) [0.08% of initial]
[Iter 15110/20000] Loss: 0.0003840 (Best: 0.0002772 @iter13594) ([92m↓0.73%[0m) [0.15% of initial]
Iter:18499, L1 loss=0.000209, Total loss=0.0001649, Time:76
[Iter 18500/20000] Loss: 0.0001808 (Best: 0.0001333 @iter18358) ([92m↓6.93%[0m) [0.07% of initial]
[Iter 15120/20000] Loss: 0.0003828 (Best: 0.0002772 @iter13594) ([92m↓0.30%[0m) [0.15% of initial]
[Iter 15130/20000] Loss: 0.0003835 (Best: 0.0002772 @iter13594) ([91m↑0.18%[0m) [0.15% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 18500
Pruning 0 points (0.0%) from gaussian1 at iteration 18500
[Iter 15140/20000] Loss: 0.0003960 (Best: 0.0002772 @iter13594) ([91m↑3.26%[0m) [0.16% of initial]
[Iter 18510/20000] Loss: 0.0003492 (Best: 0.0001333 @iter18358) ([91m↑93.20%[0m) [0.14% of initial]
[Iter 15150/20000] Loss: 0.0003932 (Best: 0.0002772 @iter13594) ([92m↓0.71%[0m) [0.16% of initial]
[Iter 15160/20000] Loss: 0.0003640 (Best: 0.0002772 @iter13594) ([92m↓7.43%[0m) [0.14% of initial]
[Iter 18520/20000] Loss: 0.0002386 (Best: 0.0001333 @iter18358) ([92m↓31.69%[0m) [0.09% of initial]
[Iter 15170/20000] Loss: 0.0003531 (Best: 0.0002772 @iter13594) ([92m↓2.98%[0m) [0.14% of initial]
[Iter 18530/20000] Loss: 0.0001825 (Best: 0.0001333 @iter18358) ([92m↓23.48%[0m) [0.07% of initial]
[Iter 15180/20000] Loss: 0.0003760 (Best: 0.0002772 @iter13594) ([91m↑6.47%[0m) [0.15% of initial]
[Iter 18540/20000] Loss: 0.0002018 (Best: 0.0001333 @iter18358) ([91m↑10.57%[0m) [0.08% of initial]
[Iter 15190/20000] Loss: 0.0003892 (Best: 0.0002772 @iter13594) ([91m↑3.51%[0m) [0.15% of initial]
[Iter 18550/20000] Loss: 0.0001752 (Best: 0.0001333 @iter18358) ([92m↓13.19%[0m) [0.07% of initial]
Iter:15199, L1 loss=0.0004226, Total loss=0.0003779, Time:74
[Iter 15200/20000] Loss: 0.0003682 (Best: 0.0002772 @iter13594) ([92m↓5.40%[0m) [0.15% of initial]
[Iter 18560/20000] Loss: 0.0001613 (Best: 0.0001333 @iter18358) ([92m↓7.96%[0m) [0.06% of initial]
[Iter 15210/20000] Loss: 0.0003705 (Best: 0.0002772 @iter13594) ([91m↑0.63%[0m) [0.15% of initial]
[Iter 18570/20000] Loss: 0.0001454 (Best: 0.0001333 @iter18358) ([92m↓9.85%[0m) [0.06% of initial]
[Iter 15220/20000] Loss: 0.0003606 (Best: 0.0002772 @iter13594) ([92m↓2.68%[0m) [0.14% of initial]
[Iter 18580/20000] Loss: 0.0001428 (Best: 0.0001291 @iter18571) ([92m↓1.76%[0m) [0.06% of initial]
[Iter 15230/20000] Loss: 0.0003673 (Best: 0.0002772 @iter13594) ([91m↑1.86%[0m) [0.15% of initial]
[Iter 18590/20000] Loss: 0.0001473 (Best: 0.0001291 @iter18571) ([91m↑3.13%[0m) [0.06% of initial]
[Iter 15240/20000] Loss: 0.0003779 (Best: 0.0002772 @iter13594) ([91m↑2.90%[0m) [0.15% of initial]
Iter:18599, L1 loss=0.0002087, Total loss=0.0001864, Time:69
[Iter 18600/20000] Loss: 0.0001821 (Best: 0.0001291 @iter18571) ([91m↑23.65%[0m) [0.07% of initial]
[Iter 15250/20000] Loss: 0.0003646 (Best: 0.0002772 @iter13594) ([92m↓3.54%[0m) [0.14% of initial]
[Iter 18610/20000] Loss: 0.0001568 (Best: 0.0001291 @iter18571) ([92m↓13.93%[0m) [0.06% of initial]
[Iter 15260/20000] Loss: 0.0003783 (Best: 0.0002772 @iter13594) ([91m↑3.77%[0m) [0.15% of initial]
[Iter 18620/20000] Loss: 0.0001453 (Best: 0.0001291 @iter18571) ([92m↓7.29%[0m) [0.06% of initial]
[Iter 15270/20000] Loss: 0.0003911 (Best: 0.0002772 @iter13594) ([91m↑3.39%[0m) [0.16% of initial]
[Iter 15280/20000] Loss: 0.0004454 (Best: 0.0002772 @iter13594) ([91m↑13.87%[0m) [0.18% of initial]
[Iter 18630/20000] Loss: 0.0001667 (Best: 0.0001291 @iter18571) ([91m↑14.73%[0m) [0.07% of initial]
[Iter 15290/20000] Loss: 0.0004025 (Best: 0.0002772 @iter13594) ([92m↓9.63%[0m) [0.16% of initial]
[Iter 18640/20000] Loss: 0.0001540 (Best: 0.0001291 @iter18571) ([92m↓7.66%[0m) [0.06% of initial]
Iter:15299, L1 loss=0.0004087, Total loss=0.0003629, Time:85
[Iter 15300/20000] Loss: 0.0003842 (Best: 0.0002772 @iter13594) ([92m↓4.54%[0m) [0.15% of initial]
[Iter 18650/20000] Loss: 0.0001661 (Best: 0.0001291 @iter18571) ([91m↑7.87%[0m) [0.07% of initial]
[Iter 15310/20000] Loss: 0.0003621 (Best: 0.0002772 @iter13594) ([92m↓5.75%[0m) [0.14% of initial]
[Iter 18660/20000] Loss: 0.0001615 (Best: 0.0001291 @iter18571) ([92m↓2.78%[0m) [0.06% of initial]
[Iter 15320/20000] Loss: 0.0003541 (Best: 0.0002772 @iter13594) ([92m↓2.23%[0m) [0.14% of initial]
[Iter 18670/20000] Loss: 0.0001776 (Best: 0.0001291 @iter18571) ([91m↑9.96%[0m) [0.07% of initial]
[Iter 15330/20000] Loss: 0.0003799 (Best: 0.0002772 @iter13594) ([91m↑7.31%[0m) [0.15% of initial]
[Iter 18680/20000] Loss: 0.0001841 (Best: 0.0001291 @iter18571) ([91m↑3.71%[0m) [0.07% of initial]
[Iter 15340/20000] Loss: 0.0003998 (Best: 0.0002772 @iter13594) ([91m↑5.23%[0m) [0.16% of initial]
[Iter 18690/20000] Loss: 0.0001694 (Best: 0.0001291 @iter18571) ([92m↓7.99%[0m) [0.07% of initial]
[Iter 15350/20000] Loss: 0.0003861 (Best: 0.0002772 @iter13594) ([92m↓3.43%[0m) [0.15% of initial]
Iter:18699, L1 loss=0.0002344, Total loss=0.0002151, Time:72
[Iter 18700/20000] Loss: 0.0001850 (Best: 0.0001291 @iter18571) ([91m↑9.17%[0m) [0.07% of initial]
[Iter 15360/20000] Loss: 0.0003817 (Best: 0.0002772 @iter13594) ([92m↓1.14%[0m) [0.15% of initial]
[Iter 18710/20000] Loss: 0.0001731 (Best: 0.0001291 @iter18571) ([92m↓6.41%[0m) [0.07% of initial]
[Iter 15370/20000] Loss: 0.0003887 (Best: 0.0002772 @iter13594) ([91m↑1.82%[0m) [0.15% of initial]
[Iter 18720/20000] Loss: 0.0001851 (Best: 0.0001291 @iter18571) ([91m↑6.91%[0m) [0.07% of initial]
[Iter 15380/20000] Loss: 0.0003684 (Best: 0.0002772 @iter13594) ([92m↓5.22%[0m) [0.15% of initial]
[Iter 18730/20000] Loss: 0.0001675 (Best: 0.0001291 @iter18571) ([92m↓9.48%[0m) [0.07% of initial]
[Iter 15390/20000] Loss: 0.0003745 (Best: 0.0002772 @iter13594) ([91m↑1.65%[0m) [0.15% of initial]
Iter:15399, L1 loss=0.0004267, Total loss=0.0003647, Time:76
[Iter 18740/20000] Loss: 0.0001490 (Best: 0.0001291 @iter18571) ([92m↓11.06%[0m) [0.06% of initial]
[Iter 15400/20000] Loss: 0.0003774 (Best: 0.0002772 @iter13594) ([91m↑0.78%[0m) [0.15% of initial]
[Iter 15410/20000] Loss: 0.0003641 (Best: 0.0002772 @iter13594) ([92m↓3.52%[0m) [0.14% of initial]
[Iter 18750/20000] Loss: 0.0001635 (Best: 0.0001291 @iter18571) ([91m↑9.70%[0m) [0.06% of initial]
[Iter 15420/20000] Loss: 0.0003670 (Best: 0.0002772 @iter13594) ([91m↑0.77%[0m) [0.15% of initial]
[Iter 18760/20000] Loss: 0.0001805 (Best: 0.0001291 @iter18571) ([91m↑10.43%[0m) [0.07% of initial]
[Iter 15430/20000] Loss: 0.0003459 (Best: 0.0002772 @iter13594) ([92m↓5.75%[0m) [0.14% of initial]
[Iter 18770/20000] Loss: 0.0001636 (Best: 0.0001291 @iter18571) ([92m↓9.36%[0m) [0.06% of initial]
[Iter 15440/20000] Loss: 0.0003599 (Best: 0.0002772 @iter13594) ([91m↑4.06%[0m) [0.14% of initial]
[Iter 18780/20000] Loss: 0.0001445 (Best: 0.0001291 @iter18571) ([92m↓11.65%[0m) [0.06% of initial]
[Iter 15450/20000] Loss: 0.0003556 (Best: 0.0002772 @iter13594) ([92m↓1.19%[0m) [0.14% of initial]
[Iter 18790/20000] Loss: 0.0001516 (Best: 0.0001291 @iter18571) ([91m↑4.90%[0m) [0.06% of initial]
[Iter 15460/20000] Loss: 0.0003632 (Best: 0.0002772 @iter13594) ([91m↑2.13%[0m) [0.14% of initial]
Iter:18799, L1 loss=0.0001848, Total loss=0.0001566, Time:69
[Iter 18800/20000] Loss: 0.0001453 (Best: 0.0001291 @iter18571) ([92m↓4.15%[0m) [0.06% of initial]
[Iter 15470/20000] Loss: 0.0003482 (Best: 0.0002772 @iter13594) ([92m↓4.14%[0m) [0.14% of initial]
[Iter 18810/20000] Loss: 0.0001540 (Best: 0.0001291 @iter18571) ([91m↑5.96%[0m) [0.06% of initial]
[Iter 15480/20000] Loss: 0.0003608 (Best: 0.0002772 @iter13594) ([91m↑3.62%[0m) [0.14% of initial]
[Iter 18820/20000] Loss: 0.0001712 (Best: 0.0001291 @iter18571) ([91m↑11.20%[0m) [0.07% of initial]
[Iter 15490/20000] Loss: 0.0003639 (Best: 0.0002772 @iter13594) ([91m↑0.86%[0m) [0.14% of initial]
[Iter 18830/20000] Loss: 0.0001655 (Best: 0.0001291 @iter18571) ([92m↓3.34%[0m) [0.07% of initial]
Iter:15499, L1 loss=0.000426, Total loss=0.0003833, Time:67
[Iter 15500/20000] Loss: 0.0003709 (Best: 0.0002772 @iter13594) ([91m↑1.95%[0m) [0.15% of initial]
[Iter 18840/20000] Loss: 0.0001566 (Best: 0.0001291 @iter18571) ([92m↓5.39%[0m) [0.06% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 15500
Pruning 9 points (0.0%) from gaussian1 at iteration 15500
[Iter 18850/20000] Loss: 0.0001739 (Best: 0.0001291 @iter18571) ([91m↑11.08%[0m) [0.07% of initial]
[Iter 15510/20000] Loss: 0.0006565 (Best: 0.0002772 @iter13594) ([91m↑76.97%[0m) [0.26% of initial]
[Iter 18860/20000] Loss: 0.0001870 (Best: 0.0001291 @iter18571) ([91m↑7.49%[0m) [0.07% of initial]
[Iter 15520/20000] Loss: 0.0004690 (Best: 0.0002772 @iter13594) ([92m↓28.56%[0m) [0.19% of initial]
[Iter 18870/20000] Loss: 0.0001730 (Best: 0.0001291 @iter18571) ([92m↓7.46%[0m) [0.07% of initial]
[Iter 15530/20000] Loss: 0.0004110 (Best: 0.0002772 @iter13594) ([92m↓12.37%[0m) [0.16% of initial]
[Iter 18880/20000] Loss: 0.0001830 (Best: 0.0001291 @iter18571) ([91m↑5.76%[0m) [0.07% of initial]
[Iter 15540/20000] Loss: 0.0004001 (Best: 0.0002772 @iter13594) ([92m↓2.63%[0m) [0.16% of initial]
[Iter 18890/20000] Loss: 0.0001536 (Best: 0.0001291 @iter18571) ([92m↓16.07%[0m) [0.06% of initial]
[Iter 15550/20000] Loss: 0.0003601 (Best: 0.0002772 @iter13594) ([92m↓10.02%[0m) [0.14% of initial]
Iter:18899, L1 loss=0.0001905, Total loss=0.0001604, Time:63
[Iter 18900/20000] Loss: 0.0001825 (Best: 0.0001291 @iter18571) ([91m↑18.82%[0m) [0.07% of initial]
[Iter 15560/20000] Loss: 0.0003477 (Best: 0.0002772 @iter13594) ([92m↓3.42%[0m) [0.14% of initial]
[Iter 18910/20000] Loss: 0.0001657 (Best: 0.0001291 @iter18571) ([92m↓9.18%[0m) [0.07% of initial]
[Iter 15570/20000] Loss: 0.0003524 (Best: 0.0002772 @iter13594) ([91m↑1.36%[0m) [0.14% of initial]
[Iter 18920/20000] Loss: 0.0001497 (Best: 0.0001291 @iter18571) ([92m↓9.65%[0m) [0.06% of initial]
[Iter 15580/20000] Loss: 0.0003368 (Best: 0.0002772 @iter13594) ([92m↓4.43%[0m) [0.13% of initial]
[Iter 18930/20000] Loss: 0.0001644 (Best: 0.0001291 @iter18571) ([91m↑9.80%[0m) [0.07% of initial]
[Iter 15590/20000] Loss: 0.0003270 (Best: 0.0002772 @iter13594) ([92m↓2.92%[0m) [0.13% of initial]
[Iter 18940/20000] Loss: 0.0001700 (Best: 0.0001291 @iter18571) ([91m↑3.40%[0m) [0.07% of initial]
Iter:15599, L1 loss=0.0003722, Total loss=0.0003316, Time:68
[Iter 15600/20000] Loss: 0.0003418 (Best: 0.0002772 @iter13594) ([91m↑4.54%[0m) [0.14% of initial]
[Iter 18950/20000] Loss: 0.0001650 (Best: 0.0001291 @iter18571) ([92m↓2.93%[0m) [0.07% of initial]
[Iter 15610/20000] Loss: 0.0003357 (Best: 0.0002772 @iter13594) ([92m↓1.79%[0m) [0.13% of initial]
[Iter 18960/20000] Loss: 0.0001496 (Best: 0.0001291 @iter18571) ([92m↓9.32%[0m) [0.06% of initial]
[Iter 15620/20000] Loss: 0.0003486 (Best: 0.0002772 @iter13594) ([91m↑3.83%[0m) [0.14% of initial]
[Iter 15630/20000] Loss: 0.0003582 (Best: 0.0002772 @iter13594) ([91m↑2.77%[0m) [0.14% of initial]
[Iter 18970/20000] Loss: 0.0001499 (Best: 0.0001291 @iter18571) ([91m↑0.16%[0m) [0.06% of initial]
[Iter 15640/20000] Loss: 0.0003438 (Best: 0.0002772 @iter13594) ([92m↓4.02%[0m) [0.14% of initial]
[Iter 18980/20000] Loss: 0.0001424 (Best: 0.0001274 @iter18979) ([92m↓4.95%[0m) [0.06% of initial]
[Iter 15650/20000] Loss: 0.0003632 (Best: 0.0002772 @iter13594) ([91m↑5.64%[0m) [0.14% of initial]
[Iter 18990/20000] Loss: 0.0001591 (Best: 0.0001274 @iter18979) ([91m↑11.70%[0m) [0.06% of initial]
[Iter 15660/20000] Loss: 0.0003546 (Best: 0.0002772 @iter13594) ([92m↓2.37%[0m) [0.14% of initial]
Iter:18999, L1 loss=0.0001963, Total loss=0.0001677, Time:66
[Iter 19000/20000] Loss: 0.0001688 (Best: 0.0001274 @iter18979) ([91m↑6.08%[0m) [0.07% of initial]
[Iter 15670/20000] Loss: 0.0003761 (Best: 0.0002772 @iter13594) ([91m↑6.07%[0m) [0.15% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 19000
[Iter 15680/20000] Loss: 0.0003662 (Best: 0.0002772 @iter13594) ([92m↓2.65%[0m) [0.15% of initial]
Pruning 0 points (0.0%) from gaussian1 at iteration 19000
[Iter 15690/20000] Loss: 0.0003616 (Best: 0.0002772 @iter13594) ([92m↓1.24%[0m) [0.14% of initial]
[Iter 19010/20000] Loss: 0.0004029 (Best: 0.0001274 @iter18979) ([91m↑138.69%[0m) [0.16% of initial]
Iter:15699, L1 loss=0.000422, Total loss=0.0003827, Time:69
[Iter 15700/20000] Loss: 0.0003568 (Best: 0.0002772 @iter13594) ([92m↓1.33%[0m) [0.14% of initial]
[Iter 19020/20000] Loss: 0.0002720 (Best: 0.0001274 @iter18979) ([92m↓32.48%[0m) [0.11% of initial]
[Iter 15710/20000] Loss: 0.0003499 (Best: 0.0002772 @iter13594) ([92m↓1.92%[0m) [0.14% of initial]
[Iter 19030/20000] Loss: 0.0002288 (Best: 0.0001274 @iter18979) ([92m↓15.88%[0m) [0.09% of initial]
[Iter 15720/20000] Loss: 0.0004121 (Best: 0.0002772 @iter13594) ([91m↑17.76%[0m) [0.16% of initial]
[Iter 19040/20000] Loss: 0.0002026 (Best: 0.0001274 @iter18979) ([92m↓11.45%[0m) [0.08% of initial]
[Iter 15730/20000] Loss: 0.0004276 (Best: 0.0002772 @iter13594) ([91m↑3.77%[0m) [0.17% of initial]
[Iter 19050/20000] Loss: 0.0001774 (Best: 0.0001274 @iter18979) ([92m↓12.47%[0m) [0.07% of initial]
[Iter 15740/20000] Loss: 0.0004439 (Best: 0.0002772 @iter13594) ([91m↑3.81%[0m) [0.18% of initial]
[Iter 19060/20000] Loss: 0.0001558 (Best: 0.0001274 @iter18979) ([92m↓12.17%[0m) [0.06% of initial]
[Iter 15750/20000] Loss: 0.0003887 (Best: 0.0002772 @iter13594) ([92m↓12.44%[0m) [0.15% of initial]
[Iter 19070/20000] Loss: 0.0001649 (Best: 0.0001274 @iter18979) ([91m↑5.87%[0m) [0.07% of initial]
[Iter 15760/20000] Loss: 0.0003871 (Best: 0.0002772 @iter13594) ([92m↓0.42%[0m) [0.15% of initial]
[Iter 19080/20000] Loss: 0.0001499 (Best: 0.0001274 @iter18979) ([92m↓9.09%[0m) [0.06% of initial]
[Iter 15770/20000] Loss: 0.0004309 (Best: 0.0002772 @iter13594) ([91m↑11.31%[0m) [0.17% of initial]
[Iter 19090/20000] Loss: 0.0001432 (Best: 0.0001274 @iter18979) ([92m↓4.51%[0m) [0.06% of initial]
[Iter 15780/20000] Loss: 0.0003873 (Best: 0.0002772 @iter13594) ([92m↓10.12%[0m) [0.15% of initial]
Iter:19099, L1 loss=0.0001743, Total loss=0.0001445, Time:66
[Iter 19100/20000] Loss: 0.0001608 (Best: 0.0001274 @iter18979) ([91m↑12.31%[0m) [0.06% of initial]
[Iter 15790/20000] Loss: 0.0003719 (Best: 0.0002772 @iter13594) ([92m↓3.98%[0m) [0.15% of initial]
[Iter 19110/20000] Loss: 0.0001768 (Best: 0.0001274 @iter18979) ([91m↑9.99%[0m) [0.07% of initial]
Iter:15799, L1 loss=0.0003784, Total loss=0.0003349, Time:81
[Iter 15800/20000] Loss: 0.0003425 (Best: 0.0002772 @iter13594) ([92m↓7.90%[0m) [0.14% of initial]
[Iter 19120/20000] Loss: 0.0001679 (Best: 0.0001274 @iter18979) ([92m↓5.03%[0m) [0.07% of initial]
[Iter 15810/20000] Loss: 0.0003406 (Best: 0.0002772 @iter13594) ([92m↓0.54%[0m) [0.14% of initial]
[Iter 15820/20000] Loss: 0.0003376 (Best: 0.0002772 @iter13594) ([92m↓0.89%[0m) [0.13% of initial]
[Iter 19130/20000] Loss: 0.0001627 (Best: 0.0001274 @iter18979) ([92m↓3.10%[0m) [0.06% of initial]
[Iter 15830/20000] Loss: 0.0003375 (Best: 0.0002772 @iter13594) ([92m↓0.04%[0m) [0.13% of initial]
[Iter 19140/20000] Loss: 0.0001647 (Best: 0.0001274 @iter18979) ([91m↑1.20%[0m) [0.07% of initial]
[Iter 15840/20000] Loss: 0.0003596 (Best: 0.0002772 @iter13594) ([91m↑6.57%[0m) [0.14% of initial]
[Iter 19150/20000] Loss: 0.0001456 (Best: 0.0001274 @iter18979) ([92m↓11.58%[0m) [0.06% of initial]
[Iter 15850/20000] Loss: 0.0003558 (Best: 0.0002772 @iter13594) ([92m↓1.06%[0m) [0.14% of initial]
[Iter 19160/20000] Loss: 0.0001924 (Best: 0.0001274 @iter18979) ([91m↑32.13%[0m) [0.08% of initial]
[Iter 15860/20000] Loss: 0.0003646 (Best: 0.0002772 @iter13594) ([91m↑2.45%[0m) [0.14% of initial]
[Iter 19170/20000] Loss: 0.0001720 (Best: 0.0001274 @iter18979) ([92m↓10.61%[0m) [0.07% of initial]
[Iter 15870/20000] Loss: 0.0003586 (Best: 0.0002772 @iter13594) ([92m↓1.63%[0m) [0.14% of initial]
[Iter 19180/20000] Loss: 0.0001786 (Best: 0.0001274 @iter18979) ([91m↑3.86%[0m) [0.07% of initial]
[Iter 15880/20000] Loss: 0.0003860 (Best: 0.0002772 @iter13594) ([91m↑7.63%[0m) [0.15% of initial]
[Iter 19190/20000] Loss: 0.0001598 (Best: 0.0001274 @iter18979) ([92m↓10.53%[0m) [0.06% of initial]
[Iter 15890/20000] Loss: 0.0004357 (Best: 0.0002772 @iter13594) ([91m↑12.88%[0m) [0.17% of initial]
Iter:19199, L1 loss=0.0001901, Total loss=0.0001646, Time:67
[Iter 19200/20000] Loss: 0.0001580 (Best: 0.0001274 @iter18979) ([92m↓1.13%[0m) [0.06% of initial]
Iter:15899, L1 loss=0.0004469, Total loss=0.0003953, Time:71
[Iter 15900/20000] Loss: 0.0004081 (Best: 0.0002772 @iter13594) ([92m↓6.34%[0m) [0.16% of initial]
[Iter 19210/20000] Loss: 0.0001577 (Best: 0.0001274 @iter18979) ([92m↓0.21%[0m) [0.06% of initial]
[Iter 15910/20000] Loss: 0.0003689 (Best: 0.0002772 @iter13594) ([92m↓9.60%[0m) [0.15% of initial]
[Iter 19220/20000] Loss: 0.0002155 (Best: 0.0001274 @iter18979) ([91m↑36.66%[0m) [0.09% of initial]
[Iter 15920/20000] Loss: 0.0003688 (Best: 0.0002772 @iter13594) ([92m↓0.02%[0m) [0.15% of initial]
[Iter 19230/20000] Loss: 0.0002183 (Best: 0.0001274 @iter18979) ([91m↑1.32%[0m) [0.09% of initial]
[Iter 15930/20000] Loss: 0.0004677 (Best: 0.0002772 @iter13594) ([91m↑26.82%[0m) [0.19% of initial]
[Iter 19240/20000] Loss: 0.0002986 (Best: 0.0001274 @iter18979) ([91m↑36.75%[0m) [0.12% of initial]
[Iter 15940/20000] Loss: 0.0003750 (Best: 0.0002772 @iter13594) ([92m↓19.82%[0m) [0.15% of initial]
[Iter 19250/20000] Loss: 0.0002281 (Best: 0.0001274 @iter18979) ([92m↓23.59%[0m) [0.09% of initial]
[Iter 15950/20000] Loss: 0.0003499 (Best: 0.0002772 @iter13594) ([92m↓6.71%[0m) [0.14% of initial]
[Iter 19260/20000] Loss: 0.0001885 (Best: 0.0001274 @iter18979) ([92m↓17.39%[0m) [0.07% of initial]
[Iter 15960/20000] Loss: 0.0003716 (Best: 0.0002772 @iter13594) ([91m↑6.21%[0m) [0.15% of initial]
[Iter 15970/20000] Loss: 0.0003542 (Best: 0.0002772 @iter13594) ([92m↓4.69%[0m) [0.14% of initial]
[Iter 19270/20000] Loss: 0.0001781 (Best: 0.0001274 @iter18979) ([92m↓5.49%[0m) [0.07% of initial]
[Iter 15980/20000] Loss: 0.0003498 (Best: 0.0002772 @iter13594) ([92m↓1.23%[0m) [0.14% of initial]
[Iter 19280/20000] Loss: 0.0001737 (Best: 0.0001274 @iter18979) ([92m↓2.50%[0m) [0.07% of initial]
[Iter 15990/20000] Loss: 0.0003397 (Best: 0.0002772 @iter13594) ([92m↓2.90%[0m) [0.13% of initial]
[Iter 19290/20000] Loss: 0.0001481 (Best: 0.0001274 @iter18979) ([92m↓14.73%[0m) [0.06% of initial]
Iter:15999, L1 loss=0.000415, Total loss=0.000349, Time:66
[Iter 16000/20000] Loss: 0.0003353 (Best: 0.0002772 @iter13594) ([92m↓1.30%[0m) [0.13% of initial]
Iter:19299, L1 loss=0.000172, Total loss=0.0001428, Time:63
[Iter 19300/20000] Loss: 0.0001418 (Best: 0.0001274 @iter18979) ([92m↓4.26%[0m) [0.06% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 16000
Pruning 5 points (0.0%) from gaussian1 at iteration 16000
[Iter 19310/20000] Loss: 0.0001539 (Best: 0.0001274 @iter18979) ([91m↑8.56%[0m) [0.06% of initial]
[Iter 16010/20000] Loss: 0.0005459 (Best: 0.0002772 @iter13594) ([91m↑62.82%[0m) [0.22% of initial]
[Iter 19320/20000] Loss: 0.0001851 (Best: 0.0001274 @iter18979) ([91m↑20.31%[0m) [0.07% of initial]
[Iter 16020/20000] Loss: 0.0005183 (Best: 0.0002772 @iter13594) ([92m↓5.06%[0m) [0.21% of initial]
[Iter 19330/20000] Loss: 0.0001776 (Best: 0.0001274 @iter18979) ([92m↓4.07%[0m) [0.07% of initial]
[Iter 16030/20000] Loss: 0.0004292 (Best: 0.0002772 @iter13594) ([92m↓17.19%[0m) [0.17% of initial]
[Iter 19340/20000] Loss: 0.0001565 (Best: 0.0001274 @iter18979) ([92m↓11.86%[0m) [0.06% of initial]
[Iter 16040/20000] Loss: 0.0003840 (Best: 0.0002772 @iter13594) ([92m↓10.55%[0m) [0.15% of initial]
[Iter 19350/20000] Loss: 0.0001536 (Best: 0.0001262 @iter19345) ([92m↓1.89%[0m) [0.06% of initial]
[Iter 16050/20000] Loss: 0.0003417 (Best: 0.0002772 @iter13594) ([92m↓11.00%[0m) [0.14% of initial]
[Iter 19360/20000] Loss: 0.0001396 (Best: 0.0001262 @iter19345) ([92m↓9.11%[0m) [0.06% of initial]
[Iter 16060/20000] Loss: 0.0003214 (Best: 0.0002772 @iter13594) ([92m↓5.93%[0m) [0.13% of initial]
[Iter 19370/20000] Loss: 0.0001463 (Best: 0.0001262 @iter19345) ([91m↑4.79%[0m) [0.06% of initial]
[Iter 16070/20000] Loss: 0.0003091 (Best: 0.0002772 @iter13594) ([92m↓3.84%[0m) [0.12% of initial]
[Iter 19380/20000] Loss: 0.0001586 (Best: 0.0001262 @iter19345) ([91m↑8.41%[0m) [0.06% of initial]
[Iter 16080/20000] Loss: 0.0003219 (Best: 0.0002772 @iter13594) ([91m↑4.14%[0m) [0.13% of initial]
[Iter 19390/20000] Loss: 0.0001720 (Best: 0.0001262 @iter19345) ([91m↑8.50%[0m) [0.07% of initial]
[Iter 16090/20000] Loss: 0.0003229 (Best: 0.0002772 @iter13594) ([91m↑0.31%[0m) [0.13% of initial]
Iter:19399, L1 loss=0.0002429, Total loss=0.0001913, Time:61
[Iter 19400/20000] Loss: 0.0001751 (Best: 0.0001262 @iter19345) ([91m↑1.76%[0m) [0.07% of initial]
Iter:16099, L1 loss=0.0003852, Total loss=0.0003416, Time:75
[Iter 16100/20000] Loss: 0.0003253 (Best: 0.0002772 @iter13594) ([91m↑0.73%[0m) [0.13% of initial]
[Iter 19410/20000] Loss: 0.0001984 (Best: 0.0001262 @iter19345) ([91m↑13.34%[0m) [0.08% of initial]
[Iter 16110/20000] Loss: 0.0003403 (Best: 0.0002772 @iter13594) ([91m↑4.63%[0m) [0.14% of initial]
[Iter 19420/20000] Loss: 0.0001877 (Best: 0.0001262 @iter19345) ([92m↓5.40%[0m) [0.07% of initial]
[Iter 16120/20000] Loss: 0.0003256 (Best: 0.0002772 @iter13594) ([92m↓4.34%[0m) [0.13% of initial]
[Iter 19430/20000] Loss: 0.0002166 (Best: 0.0001262 @iter19345) ([91m↑15.38%[0m) [0.09% of initial]
[Iter 16130/20000] Loss: 0.0003453 (Best: 0.0002772 @iter13594) ([91m↑6.06%[0m) [0.14% of initial]
[Iter 19440/20000] Loss: 0.0001792 (Best: 0.0001262 @iter19345) ([92m↓17.25%[0m) [0.07% of initial]
[Iter 16140/20000] Loss: 0.0003463 (Best: 0.0002772 @iter13594) ([91m↑0.29%[0m) [0.14% of initial]
[Iter 16150/20000] Loss: 0.0003401 (Best: 0.0002772 @iter13594) ([92m↓1.77%[0m) [0.14% of initial]
[Iter 19450/20000] Loss: 0.0001534 (Best: 0.0001262 @iter19345) ([92m↓14.39%[0m) [0.06% of initial]
[Iter 16160/20000] Loss: 0.0003292 (Best: 0.0002772 @iter13594) ([92m↓3.23%[0m) [0.13% of initial]
[Iter 19460/20000] Loss: 0.0001643 (Best: 0.0001262 @iter19345) ([91m↑7.06%[0m) [0.07% of initial]
[Iter 16170/20000] Loss: 0.0003359 (Best: 0.0002772 @iter13594) ([91m↑2.04%[0m) [0.13% of initial]
[Iter 19470/20000] Loss: 0.0001659 (Best: 0.0001262 @iter19345) ([91m↑0.99%[0m) [0.07% of initial]
[Iter 16180/20000] Loss: 0.0003420 (Best: 0.0002772 @iter13594) ([91m↑1.81%[0m) [0.14% of initial]
[Iter 19480/20000] Loss: 0.0001561 (Best: 0.0001262 @iter19345) ([92m↓5.92%[0m) [0.06% of initial]
[Iter 16190/20000] Loss: 0.0003282 (Best: 0.0002772 @iter13594) ([92m↓4.03%[0m) [0.13% of initial]
[Iter 19490/20000] Loss: 0.0001553 (Best: 0.0001262 @iter19345) ([92m↓0.52%[0m) [0.06% of initial]
Iter:16199, L1 loss=0.0003767, Total loss=0.0003279, Time:88
[Iter 16200/20000] Loss: 0.0003374 (Best: 0.0002772 @iter13594) ([91m↑2.80%[0m) [0.13% of initial]
Iter:19499, L1 loss=0.0001754, Total loss=0.0001455, Time:68
[Iter 19500/20000] Loss: 0.0001712 (Best: 0.0001262 @iter19345) ([91m↑10.24%[0m) [0.07% of initial]
[Iter 16210/20000] Loss: 0.0003327 (Best: 0.0002772 @iter13594) ([92m↓1.37%[0m) [0.13% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 19500
[Iter 16220/20000] Loss: 0.0003276 (Best: 0.0002772 @iter13594) ([92m↓1.56%[0m) [0.13% of initial]
Pruning 0 points (0.0%) from gaussian1 at iteration 19500
[Iter 16230/20000] Loss: 0.0003506 (Best: 0.0002772 @iter13594) ([91m↑7.03%[0m) [0.14% of initial]
[Iter 19510/20000] Loss: 0.0003847 (Best: 0.0001262 @iter19345) ([91m↑124.70%[0m) [0.15% of initial]
[Iter 16240/20000] Loss: 0.0003329 (Best: 0.0002772 @iter13594) ([92m↓5.05%[0m) [0.13% of initial]
[Iter 19520/20000] Loss: 0.0002353 (Best: 0.0001262 @iter19345) ([92m↓38.82%[0m) [0.09% of initial]
[Iter 16250/20000] Loss: 0.0003584 (Best: 0.0002772 @iter13594) ([91m↑7.67%[0m) [0.14% of initial]
[Iter 19530/20000] Loss: 0.0002392 (Best: 0.0001262 @iter19345) ([91m↑1.64%[0m) [0.10% of initial]
[Iter 16260/20000] Loss: 0.0003539 (Best: 0.0002772 @iter13594) ([92m↓1.27%[0m) [0.14% of initial]
[Iter 19540/20000] Loss: 0.0001858 (Best: 0.0001262 @iter19345) ([92m↓22.32%[0m) [0.07% of initial]
[Iter 16270/20000] Loss: 0.0003701 (Best: 0.0002772 @iter13594) ([91m↑4.59%[0m) [0.15% of initial]
[Iter 19550/20000] Loss: 0.0001521 (Best: 0.0001262 @iter19345) ([92m↓18.16%[0m) [0.06% of initial]
[Iter 16280/20000] Loss: 0.0003781 (Best: 0.0002772 @iter13594) ([91m↑2.15%[0m) [0.15% of initial]
[Iter 19560/20000] Loss: 0.0001504 (Best: 0.0001262 @iter19345) ([92m↓1.06%[0m) [0.06% of initial]
[Iter 16290/20000] Loss: 0.0004182 (Best: 0.0002772 @iter13594) ([91m↑10.63%[0m) [0.17% of initial]
[Iter 19570/20000] Loss: 0.0001423 (Best: 0.0001262 @iter19345) ([92m↓5.43%[0m) [0.06% of initial]
Iter:16299, L1 loss=0.00047, Total loss=0.0003923, Time:66
[Iter 16300/20000] Loss: 0.0003853 (Best: 0.0002772 @iter13594) ([92m↓7.87%[0m) [0.15% of initial]
[Iter 19580/20000] Loss: 0.0001559 (Best: 0.0001262 @iter19345) ([91m↑9.58%[0m) [0.06% of initial]
[Iter 16310/20000] Loss: 0.0003919 (Best: 0.0002772 @iter13594) ([91m↑1.70%[0m) [0.16% of initial]
[Iter 19590/20000] Loss: 0.0001586 (Best: 0.0001262 @iter19345) ([91m↑1.72%[0m) [0.06% of initial]
[Iter 16320/20000] Loss: 0.0003745 (Best: 0.0002772 @iter13594) ([92m↓4.42%[0m) [0.15% of initial]
Iter:19599, L1 loss=0.0001753, Total loss=0.0001486, Time:84
[Iter 16330/20000] Loss: 0.0003661 (Best: 0.0002772 @iter13594) ([92m↓2.25%[0m) [0.15% of initial]
[Iter 19600/20000] Loss: 0.0001444 (Best: 0.0001262 @iter19345) ([92m↓8.97%[0m) [0.06% of initial]
[Iter 16340/20000] Loss: 0.0003414 (Best: 0.0002772 @iter13594) ([92m↓6.75%[0m) [0.14% of initial]
[Iter 19610/20000] Loss: 0.0001472 (Best: 0.0001262 @iter19345) ([91m↑1.98%[0m) [0.06% of initial]
[Iter 16350/20000] Loss: 0.0003780 (Best: 0.0002772 @iter13594) ([91m↑10.71%[0m) [0.15% of initial]
[Iter 19620/20000] Loss: 0.0001435 (Best: 0.0001262 @iter19345) ([92m↓2.52%[0m) [0.06% of initial]
[Iter 16360/20000] Loss: 0.0003465 (Best: 0.0002772 @iter13594) ([92m↓8.33%[0m) [0.14% of initial]
[Iter 19630/20000] Loss: 0.0001447 (Best: 0.0001259 @iter19624) ([91m↑0.83%[0m) [0.06% of initial]
[Iter 16370/20000] Loss: 0.0003860 (Best: 0.0002772 @iter13594) ([91m↑11.41%[0m) [0.15% of initial]
[Iter 19640/20000] Loss: 0.0001831 (Best: 0.0001259 @iter19624) ([91m↑26.56%[0m) [0.07% of initial]
[Iter 16380/20000] Loss: 0.0003731 (Best: 0.0002772 @iter13594) ([92m↓3.36%[0m) [0.15% of initial]
[Iter 19650/20000] Loss: 0.0001819 (Best: 0.0001259 @iter19624) ([92m↓0.64%[0m) [0.07% of initial]
[Iter 16390/20000] Loss: 0.0003544 (Best: 0.0002772 @iter13594) ([92m↓5.01%[0m) [0.14% of initial]
[Iter 19660/20000] Loss: 0.0001619 (Best: 0.0001259 @iter19624) ([92m↓11.00%[0m) [0.06% of initial]
Iter:16399, L1 loss=0.0003753, Total loss=0.0003493, Time:64
[Iter 16400/20000] Loss: 0.0003367 (Best: 0.0002772 @iter13594) ([92m↓4.98%[0m) [0.13% of initial]
[Iter 19670/20000] Loss: 0.0001457 (Best: 0.0001259 @iter19624) ([92m↓10.02%[0m) [0.06% of initial]
[Iter 16410/20000] Loss: 0.0003330 (Best: 0.0002772 @iter13594) ([92m↓1.10%[0m) [0.13% of initial]
[Iter 19680/20000] Loss: 0.0001640 (Best: 0.0001259 @iter19624) ([91m↑12.56%[0m) [0.07% of initial]
[Iter 16420/20000] Loss: 0.0003487 (Best: 0.0002772 @iter13594) ([91m↑4.72%[0m) [0.14% of initial]
[Iter 19690/20000] Loss: 0.0001685 (Best: 0.0001259 @iter19624) ([91m↑2.77%[0m) [0.07% of initial]
[Iter 16430/20000] Loss: 0.0003408 (Best: 0.0002772 @iter13594) ([92m↓2.27%[0m) [0.14% of initial]
Iter:19699, L1 loss=0.0002293, Total loss=0.0001673, Time:73
[Iter 16440/20000] Loss: 0.0003905 (Best: 0.0002772 @iter13594) ([91m↑14.59%[0m) [0.16% of initial]
[Iter 19700/20000] Loss: 0.0001799 (Best: 0.0001259 @iter19624) ([91m↑6.72%[0m) [0.07% of initial]
[Iter 16450/20000] Loss: 0.0003736 (Best: 0.0002772 @iter13594) ([92m↓4.34%[0m) [0.15% of initial]
[Iter 19710/20000] Loss: 0.0001663 (Best: 0.0001259 @iter19624) ([92m↓7.53%[0m) [0.07% of initial]
[Iter 16460/20000] Loss: 0.0003657 (Best: 0.0002772 @iter13594) ([92m↓2.11%[0m) [0.15% of initial]
[Iter 19720/20000] Loss: 0.0001671 (Best: 0.0001259 @iter19624) ([91m↑0.48%[0m) [0.07% of initial]
[Iter 16470/20000] Loss: 0.0003368 (Best: 0.0002772 @iter13594) ([92m↓7.90%[0m) [0.13% of initial]
[Iter 19730/20000] Loss: 0.0001462 (Best: 0.0001259 @iter19624) ([92m↓12.52%[0m) [0.06% of initial]
[Iter 16480/20000] Loss: 0.0003519 (Best: 0.0002772 @iter13594) ([91m↑4.48%[0m) [0.14% of initial]
[Iter 19740/20000] Loss: 0.0001579 (Best: 0.0001259 @iter19624) ([91m↑7.98%[0m) [0.06% of initial]
[Iter 16490/20000] Loss: 0.0003351 (Best: 0.0002772 @iter13594) ([92m↓4.76%[0m) [0.13% of initial]
[Iter 19750/20000] Loss: 0.0002128 (Best: 0.0001259 @iter19624) ([91m↑34.79%[0m) [0.08% of initial]
Iter:16499, L1 loss=0.0003485, Total loss=0.0003204, Time:76
[Iter 16500/20000] Loss: 0.0003225 (Best: 0.0002772 @iter13594) ([92m↓3.76%[0m) [0.13% of initial]
[Iter 19760/20000] Loss: 0.0002331 (Best: 0.0001259 @iter19624) ([91m↑9.54%[0m) [0.09% of initial]
Pruning 6 points (0.0%) from gaussian0 at iteration 16500
Pruning 4 points (0.0%) from gaussian1 at iteration 16500
[Iter 19770/20000] Loss: 0.0002152 (Best: 0.0001259 @iter19624) ([92m↓7.65%[0m) [0.09% of initial]
[Iter 16510/20000] Loss: 0.0005864 (Best: 0.0002772 @iter13594) ([91m↑81.81%[0m) [0.23% of initial]
[Iter 19780/20000] Loss: 0.0001899 (Best: 0.0001259 @iter19624) ([92m↓11.78%[0m) [0.08% of initial]
[Iter 16520/20000] Loss: 0.0004521 (Best: 0.0002772 @iter13594) ([92m↓22.90%[0m) [0.18% of initial]
[Iter 19790/20000] Loss: 0.0001661 (Best: 0.0001259 @iter19624) ([92m↓12.53%[0m) [0.07% of initial]
[Iter 16530/20000] Loss: 0.0004181 (Best: 0.0002772 @iter13594) ([92m↓7.52%[0m) [0.17% of initial]
Iter:19799, L1 loss=0.0001999, Total loss=0.0001604, Time:74
[Iter 19800/20000] Loss: 0.0001639 (Best: 0.0001259 @iter19624) ([92m↓1.29%[0m) [0.07% of initial]
[Iter 16540/20000] Loss: 0.0003549 (Best: 0.0002772 @iter13594) ([92m↓15.11%[0m) [0.14% of initial]
[Iter 19810/20000] Loss: 0.0001635 (Best: 0.0001259 @iter19624) ([92m↓0.28%[0m) [0.06% of initial]
[Iter 16550/20000] Loss: 0.0003244 (Best: 0.0002772 @iter13594) ([92m↓8.60%[0m) [0.13% of initial]
[Iter 19820/20000] Loss: 0.0001912 (Best: 0.0001259 @iter19624) ([91m↑16.98%[0m) [0.08% of initial]
[Iter 16560/20000] Loss: 0.0003163 (Best: 0.0002772 @iter13594) ([92m↓2.51%[0m) [0.13% of initial]
[Iter 19830/20000] Loss: 0.0002005 (Best: 0.0001259 @iter19624) ([91m↑4.85%[0m) [0.08% of initial]
[Iter 16570/20000] Loss: 0.0003077 (Best: 0.0002772 @iter13594) ([92m↓2.72%[0m) [0.12% of initial]
[Iter 19840/20000] Loss: 0.0001584 (Best: 0.0001259 @iter19624) ([92m↓21.01%[0m) [0.06% of initial]
[Iter 16580/20000] Loss: 0.0003017 (Best: 0.0002772 @iter13594) ([92m↓1.96%[0m) [0.12% of initial]
[Iter 19850/20000] Loss: 0.0001497 (Best: 0.0001259 @iter19624) ([92m↓5.49%[0m) [0.06% of initial]
[Iter 16590/20000] Loss: 0.0003123 (Best: 0.0002772 @iter13594) ([91m↑3.53%[0m) [0.12% of initial]
Iter:16599, L1 loss=0.0003932, Total loss=0.0003498, Time:81
[Iter 16600/20000] Loss: 0.0003272 (Best: 0.0002772 @iter13594) ([91m↑4.79%[0m) [0.13% of initial]
[Iter 19860/20000] Loss: 0.0001820 (Best: 0.0001259 @iter19624) ([91m↑21.57%[0m) [0.07% of initial]
[Iter 16610/20000] Loss: 0.0003234 (Best: 0.0002772 @iter13594) ([92m↓1.18%[0m) [0.13% of initial]
[Iter 19870/20000] Loss: 0.0001781 (Best: 0.0001259 @iter19624) ([92m↓2.15%[0m) [0.07% of initial]
[Iter 16620/20000] Loss: 0.0003311 (Best: 0.0002772 @iter13594) ([91m↑2.37%[0m) [0.13% of initial]
[Iter 19880/20000] Loss: 0.0001784 (Best: 0.0001259 @iter19624) ([91m↑0.19%[0m) [0.07% of initial]
[Iter 16630/20000] Loss: 0.0003414 (Best: 0.0002772 @iter13594) ([91m↑3.12%[0m) [0.14% of initial]
[Iter 19890/20000] Loss: 0.0001726 (Best: 0.0001259 @iter19624) ([92m↓3.23%[0m) [0.07% of initial]
[Iter 16640/20000] Loss: 0.0003295 (Best: 0.0002772 @iter13594) ([92m↓3.47%[0m) [0.13% of initial]
Iter:19899, L1 loss=0.0002437, Total loss=0.0002146, Time:70
[Iter 19900/20000] Loss: 0.0002039 (Best: 0.0001259 @iter19624) ([91m↑18.08%[0m) [0.08% of initial]
[Iter 16650/20000] Loss: 0.0003247 (Best: 0.0002772 @iter13594) ([92m↓1.47%[0m) [0.13% of initial]
[Iter 19910/20000] Loss: 0.0001957 (Best: 0.0001259 @iter19624) ([92m↓4.02%[0m) [0.08% of initial]
[Iter 16660/20000] Loss: 0.0003152 (Best: 0.0002772 @iter13594) ([92m↓2.93%[0m) [0.13% of initial]
[Iter 19920/20000] Loss: 0.0001836 (Best: 0.0001259 @iter19624) ([92m↓6.15%[0m) [0.07% of initial]
[Iter 16670/20000] Loss: 0.0003164 (Best: 0.0002772 @iter13594) ([91m↑0.39%[0m) [0.13% of initial]
[Iter 19930/20000] Loss: 0.0001796 (Best: 0.0001259 @iter19624) ([92m↓2.18%[0m) [0.07% of initial]
[Iter 16680/20000] Loss: 0.0003160 (Best: 0.0002772 @iter13594) ([92m↓0.12%[0m) [0.13% of initial]
[Iter 19940/20000] Loss: 0.0001640 (Best: 0.0001259 @iter19624) ([92m↓8.68%[0m) [0.07% of initial]
[Iter 16690/20000] Loss: 0.0003232 (Best: 0.0002772 @iter13594) ([91m↑2.25%[0m) [0.13% of initial]
[Iter 19950/20000] Loss: 0.0001446 (Best: 0.0001259 @iter19624) ([92m↓11.87%[0m) [0.06% of initial]
Iter:16699, L1 loss=0.0003501, Total loss=0.0003185, Time:68
[Iter 16700/20000] Loss: 0.0003176 (Best: 0.0002772 @iter13594) ([92m↓1.73%[0m) [0.13% of initial]
[Iter 19960/20000] Loss: 0.0001504 (Best: 0.0001259 @iter19624) ([91m↑4.02%[0m) [0.06% of initial]
[Iter 16710/20000] Loss: 0.0003338 (Best: 0.0002772 @iter13594) ([91m↑5.10%[0m) [0.13% of initial]
[Iter 19970/20000] Loss: 0.0001541 (Best: 0.0001259 @iter19624) ([91m↑2.50%[0m) [0.06% of initial]
[Iter 16720/20000] Loss: 0.0003293 (Best: 0.0002772 @iter13594) ([92m↓1.33%[0m) [0.13% of initial]
[Iter 19980/20000] Loss: 0.0001567 (Best: 0.0001259 @iter19624) ([91m↑1.65%[0m) [0.06% of initial]
[Iter 16730/20000] Loss: 0.0003394 (Best: 0.0002772 @iter13594) ([91m↑3.06%[0m) [0.13% of initial]
[Iter 19990/20000] Loss: 0.0001526 (Best: 0.0001259 @iter19624) ([92m↓2.61%[0m) [0.06% of initial]
[Iter 16740/20000] Loss: 0.0003863 (Best: 0.0002772 @iter13594) ([91m↑13.81%[0m) [0.15% of initial]
Iter:19999, L1 loss=0.0001747, Total loss=0.0001589, Time:84
[Iter 20000/20000] Loss: 0.0001838 (Best: 0.0001259 @iter19624) ([91m↑20.46%[0m) [0.07% of initial]
[Iter 16750/20000] Loss: 0.0003410 (Best: 0.0002772 @iter13594) ([92m↓11.72%[0m) [0.14% of initial]
[Iter 16760/20000] Loss: 0.0003644 (Best: 0.0002772 @iter13594) ([91m↑6.86%[0m) [0.14% of initial]
Testing Speed: 43.61787933053384 fps
Testing Time: 1.1463189125061035 s

[ITER 20000] Evaluating test: SSIM = 0.8716900336742401, PSNR = 18.551101684570312
Testing Speed: 44.83760641122035 fps
Testing Time: 0.06690812110900879 s

[ITER 20000] Evaluating train: SSIM = 0.9999995032946268, PSNR = 67.52206166585286
Iter:20000, total_points:185393

[ITER 20000] Saving Gaussians
[Iter 16770/20000] Loss: 0.0003630 (Best: 0.0002772 @iter13594) ([92m↓0.40%[0m) [0.14% of initial]
[Iter 16780/20000] Loss: 0.0003579 (Best: 0.0002772 @iter13594) ([92m↓1.39%[0m) [0.14% of initial]
[Iter 16790/20000] Loss: 0.0003379 (Best: 0.0002772 @iter13594) ([92m↓5.58%[0m) [0.13% of initial]
Iter:16799, L1 loss=0.0003673, Total loss=0.0003242, Time:67
[Iter 16800/20000] Loss: 0.0003433 (Best: 0.0002772 @iter13594) ([91m↑1.59%[0m) [0.14% of initial]
[Iter 16810/20000] Loss: 0.0003437 (Best: 0.0002772 @iter13594) ([91m↑0.12%[0m) [0.14% of initial]
[Iter 16820/20000] Loss: 0.0003351 (Best: 0.0002772 @iter13594) ([92m↓2.52%[0m) [0.13% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 20000
Pruning 1 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 43 fps
Total time: 39.43 minutes
Test SSIM: 0.8717
Test PSNR: 18.551
Gaussian0 final points count: 185391
Gaussian1 final points count: 182062
Final loss: 0.0001838 (0.07% of initial)
Save path: 2024_11_26_20_30_04
Initial loss: 0.2517052
Best loss: 0.0001259 @iteration 19624 (0.05% of initial)
Train SSIM: 1.0000
Train PSNR: 67.522
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
[Iter 16830/20000] Loss: 0.0003344 (Best: 0.0002772 @iter13594) ([92m↓0.21%[0m) [0.13% of initial]
[Iter 16840/20000] Loss: 0.0003208 (Best: 0.0002772 @iter13594) ([92m↓4.05%[0m) [0.13% of initial]
[Iter 16850/20000] Loss: 0.0003617 (Best: 0.0002772 @iter13594) ([91m↑12.73%[0m) [0.14% of initial]
[Iter 16860/20000] Loss: 0.0003960 (Best: 0.0002772 @iter13594) ([91m↑9.48%[0m) [0.16% of initial]
[Iter 16870/20000] Loss: 0.0003528 (Best: 0.0002772 @iter13594) ([92m↓10.91%[0m) [0.14% of initial]
[Iter 16880/20000] Loss: 0.0003422 (Best: 0.0002772 @iter13594) ([92m↓3.01%[0m) [0.14% of initial]
[Iter 16890/20000] Loss: 0.0003250 (Best: 0.0002772 @iter13594) ([92m↓5.03%[0m) [0.13% of initial]
Iter:16899, L1 loss=0.0003795, Total loss=0.000326, Time:49
[Iter 16900/20000] Loss: 0.0003303 (Best: 0.0002772 @iter13594) ([91m↑1.64%[0m) [0.13% of initial]
[Iter 16910/20000] Loss: 0.0003235 (Best: 0.0002772 @iter13594) ([92m↓2.05%[0m) [0.13% of initial]
[Iter 16920/20000] Loss: 0.0003135 (Best: 0.0002772 @iter13594) ([92m↓3.10%[0m) [0.12% of initial]
[Iter 16930/20000] Loss: 0.0003051 (Best: 0.0002772 @iter13594) ([92m↓2.67%[0m) [0.12% of initial]
[Iter 16940/20000] Loss: 0.0003153 (Best: 0.0002772 @iter13594) ([91m↑3.33%[0m) [0.13% of initial]
[Iter 16950/20000] Loss: 0.0003225 (Best: 0.0002772 @iter13594) ([91m↑2.30%[0m) [0.13% of initial]
[Iter 16960/20000] Loss: 0.0003312 (Best: 0.0002772 @iter13594) ([91m↑2.68%[0m) [0.13% of initial]
[Iter 16970/20000] Loss: 0.0003222 (Best: 0.0002772 @iter13594) ([92m↓2.69%[0m) [0.13% of initial]
[Iter 16980/20000] Loss: 0.0003221 (Best: 0.0002772 @iter13594) ([92m↓0.03%[0m) [0.13% of initial]
[Iter 16990/20000] Loss: 0.0003185 (Best: 0.0002772 @iter13594) ([92m↓1.13%[0m) [0.13% of initial]
Iter:16999, L1 loss=0.0003687, Total loss=0.0003139, Time:72
[Iter 17000/20000] Loss: 0.0003098 (Best: 0.0002772 @iter13594) ([92m↓2.74%[0m) [0.12% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 17000
Pruning 3 points (0.0%) from gaussian1 at iteration 17000
[Iter 17010/20000] Loss: 0.0006357 (Best: 0.0002772 @iter13594) ([91m↑105.21%[0m) [0.25% of initial]
[Iter 17020/20000] Loss: 0.0004475 (Best: 0.0002772 @iter13594) ([92m↓29.60%[0m) [0.18% of initial]
[Iter 17030/20000] Loss: 0.0003768 (Best: 0.0002772 @iter13594) ([92m↓15.81%[0m) [0.15% of initial]
[Iter 17040/20000] Loss: 0.0003673 (Best: 0.0002772 @iter13594) ([92m↓2.51%[0m) [0.15% of initial]
[Iter 17050/20000] Loss: 0.0003269 (Best: 0.0002772 @iter13594) ([92m↓11.00%[0m) [0.13% of initial]
[Iter 17060/20000] Loss: 0.0003041 (Best: 0.0002772 @iter13594) ([92m↓6.96%[0m) [0.12% of initial]
[Iter 17070/20000] Loss: 0.0003109 (Best: 0.0002772 @iter13594) ([91m↑2.23%[0m) [0.12% of initial]
[Iter 17080/20000] Loss: 0.0003014 (Best: 0.0002772 @iter13594) ([92m↓3.05%[0m) [0.12% of initial]
[Iter 17090/20000] Loss: 0.0003071 (Best: 0.0002772 @iter13594) ([91m↑1.88%[0m) [0.12% of initial]
Iter:17099, L1 loss=0.0003384, Total loss=0.0003049, Time:50
[Iter 17100/20000] Loss: 0.0003279 (Best: 0.0002772 @iter13594) ([91m↑6.78%[0m) [0.13% of initial]
[Iter 17110/20000] Loss: 0.0003130 (Best: 0.0002772 @iter13594) ([92m↓4.55%[0m) [0.12% of initial]
[Iter 17120/20000] Loss: 0.0003259 (Best: 0.0002772 @iter13594) ([91m↑4.10%[0m) [0.13% of initial]
[Iter 17130/20000] Loss: 0.0003101 (Best: 0.0002772 @iter13594) ([92m↓4.84%[0m) [0.12% of initial]
[Iter 17140/20000] Loss: 0.0003035 (Best: 0.0002772 @iter13594) ([92m↓2.14%[0m) [0.12% of initial]
[Iter 17150/20000] Loss: 0.0003027 (Best: 0.0002772 @iter13594) ([92m↓0.25%[0m) [0.12% of initial]
[Iter 17160/20000] Loss: 0.0003127 (Best: 0.0002772 @iter13594) ([91m↑3.31%[0m) [0.12% of initial]
[Iter 17170/20000] Loss: 0.0003065 (Best: 0.0002772 @iter13594) ([92m↓2.01%[0m) [0.12% of initial]
[Iter 17180/20000] Loss: 0.0003329 (Best: 0.0002772 @iter13594) ([91m↑8.64%[0m) [0.13% of initial]
[Iter 17190/20000] Loss: 0.0003257 (Best: 0.0002772 @iter13594) ([92m↓2.18%[0m) [0.13% of initial]
Iter:17199, L1 loss=0.0004203, Total loss=0.0003829, Time:64
[Iter 17200/20000] Loss: 0.0003325 (Best: 0.0002772 @iter13594) ([91m↑2.10%[0m) [0.13% of initial]
[Iter 17210/20000] Loss: 0.0003152 (Best: 0.0002772 @iter13594) ([92m↓5.21%[0m) [0.13% of initial]
[Iter 17220/20000] Loss: 0.0003251 (Best: 0.0002772 @iter13594) ([91m↑3.13%[0m) [0.13% of initial]
[Iter 17230/20000] Loss: 0.0003253 (Best: 0.0002772 @iter13594) ([91m↑0.07%[0m) [0.13% of initial]
[Iter 17240/20000] Loss: 0.0003279 (Best: 0.0002772 @iter13594) ([91m↑0.82%[0m) [0.13% of initial]
[Iter 17250/20000] Loss: 0.0003171 (Best: 0.0002772 @iter13594) ([92m↓3.32%[0m) [0.13% of initial]
[Iter 17260/20000] Loss: 0.0003112 (Best: 0.0002772 @iter13594) ([92m↓1.84%[0m) [0.12% of initial]
[Iter 17270/20000] Loss: 0.0003187 (Best: 0.0002772 @iter13594) ([91m↑2.42%[0m) [0.13% of initial]
[Iter 17280/20000] Loss: 0.0003226 (Best: 0.0002772 @iter13594) ([91m↑1.21%[0m) [0.13% of initial]
[Iter 17290/20000] Loss: 0.0003152 (Best: 0.0002772 @iter13594) ([92m↓2.30%[0m) [0.13% of initial]
Iter:17299, L1 loss=0.0003469, Total loss=0.0003075, Time:62
[Iter 17300/20000] Loss: 0.0003255 (Best: 0.0002772 @iter13594) ([91m↑3.26%[0m) [0.13% of initial]
[Iter 17310/20000] Loss: 0.0003709 (Best: 0.0002772 @iter13594) ([91m↑13.95%[0m) [0.15% of initial]
[Iter 17320/20000] Loss: 0.0003644 (Best: 0.0002772 @iter13594) ([92m↓1.74%[0m) [0.14% of initial]
[Iter 17330/20000] Loss: 0.0003504 (Best: 0.0002772 @iter13594) ([92m↓3.86%[0m) [0.14% of initial]
[Iter 17340/20000] Loss: 0.0003775 (Best: 0.0002772 @iter13594) ([91m↑7.76%[0m) [0.15% of initial]
[Iter 17350/20000] Loss: 0.0003589 (Best: 0.0002772 @iter13594) ([92m↓4.94%[0m) [0.14% of initial]
[Iter 17360/20000] Loss: 0.0003665 (Best: 0.0002772 @iter13594) ([91m↑2.12%[0m) [0.15% of initial]
[Iter 17370/20000] Loss: 0.0003448 (Best: 0.0002772 @iter13594) ([92m↓5.94%[0m) [0.14% of initial]
[Iter 17380/20000] Loss: 0.0003251 (Best: 0.0002772 @iter13594) ([92m↓5.71%[0m) [0.13% of initial]
[Iter 17390/20000] Loss: 0.0003139 (Best: 0.0002772 @iter13594) ([92m↓3.43%[0m) [0.12% of initial]
Iter:17399, L1 loss=0.0003858, Total loss=0.0003217, Time:62
[Iter 17400/20000] Loss: 0.0003018 (Best: 0.0002772 @iter13594) ([92m↓3.86%[0m) [0.12% of initial]
[Iter 17410/20000] Loss: 0.0003086 (Best: 0.0002772 @iter13594) ([91m↑2.25%[0m) [0.12% of initial]
[Iter 17420/20000] Loss: 0.0003065 (Best: 0.0002772 @iter13594) ([92m↓0.69%[0m) [0.12% of initial]
[Iter 17430/20000] Loss: 0.0002997 (Best: 0.0002772 @iter13594) ([92m↓2.21%[0m) [0.12% of initial]
[Iter 17440/20000] Loss: 0.0003036 (Best: 0.0002772 @iter13594) ([91m↑1.28%[0m) [0.12% of initial]
[Iter 17450/20000] Loss: 0.0003558 (Best: 0.0002772 @iter13594) ([91m↑17.21%[0m) [0.14% of initial]
[Iter 17460/20000] Loss: 0.0003333 (Best: 0.0002772 @iter13594) ([92m↓6.32%[0m) [0.13% of initial]
[Iter 17470/20000] Loss: 0.0003110 (Best: 0.0002772 @iter13594) ([92m↓6.69%[0m) [0.12% of initial]
[Iter 17480/20000] Loss: 0.0003163 (Best: 0.0002772 @iter13594) ([91m↑1.70%[0m) [0.13% of initial]
[Iter 17490/20000] Loss: 0.0003500 (Best: 0.0002772 @iter13594) ([91m↑10.66%[0m) [0.14% of initial]
Iter:17499, L1 loss=0.0004234, Total loss=0.0003708, Time:64
[Iter 17500/20000] Loss: 0.0003540 (Best: 0.0002772 @iter13594) ([91m↑1.13%[0m) [0.14% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 17500
Pruning 8 points (0.0%) from gaussian1 at iteration 17500
[Iter 17510/20000] Loss: 0.0005061 (Best: 0.0002772 @iter13594) ([91m↑42.98%[0m) [0.20% of initial]
[Iter 17520/20000] Loss: 0.0004472 (Best: 0.0002772 @iter13594) ([92m↓11.64%[0m) [0.18% of initial]
[Iter 17530/20000] Loss: 0.0003920 (Best: 0.0002772 @iter13594) ([92m↓12.34%[0m) [0.16% of initial]
[Iter 17540/20000] Loss: 0.0003464 (Best: 0.0002772 @iter13594) ([92m↓11.64%[0m) [0.14% of initial]
[Iter 17550/20000] Loss: 0.0003226 (Best: 0.0002772 @iter13594) ([92m↓6.86%[0m) [0.13% of initial]
[Iter 17560/20000] Loss: 0.0003414 (Best: 0.0002772 @iter13594) ([91m↑5.83%[0m) [0.14% of initial]
[Iter 17570/20000] Loss: 0.0003194 (Best: 0.0002772 @iter13594) ([92m↓6.45%[0m) [0.13% of initial]
[Iter 17580/20000] Loss: 0.0003072 (Best: 0.0002772 @iter13594) ([92m↓3.82%[0m) [0.12% of initial]
[Iter 17590/20000] Loss: 0.0003008 (Best: 0.0002772 @iter13594) ([92m↓2.08%[0m) [0.12% of initial]
Iter:17599, L1 loss=0.0003543, Total loss=0.0003568, Time:48
[Iter 17600/20000] Loss: 0.0003157 (Best: 0.0002772 @iter13594) ([91m↑4.96%[0m) [0.13% of initial]
[Iter 17610/20000] Loss: 0.0002972 (Best: 0.0002772 @iter13594) ([92m↓5.87%[0m) [0.12% of initial]
[Iter 17620/20000] Loss: 0.0002871 (Best: 0.0002772 @iter13594) ([92m↓3.39%[0m) [0.11% of initial]
[Iter 17630/20000] Loss: 0.0002895 (Best: 0.0002736 @iter17623) ([91m↑0.83%[0m) [0.12% of initial]
[Iter 17640/20000] Loss: 0.0002937 (Best: 0.0002736 @iter17623) ([91m↑1.44%[0m) [0.12% of initial]
[Iter 17650/20000] Loss: 0.0002976 (Best: 0.0002736 @iter17623) ([91m↑1.32%[0m) [0.12% of initial]
[Iter 17660/20000] Loss: 0.0002962 (Best: 0.0002736 @iter17623) ([92m↓0.45%[0m) [0.12% of initial]
[Iter 17670/20000] Loss: 0.0003066 (Best: 0.0002736 @iter17623) ([91m↑3.50%[0m) [0.12% of initial]
[Iter 17680/20000] Loss: 0.0003062 (Best: 0.0002736 @iter17623) ([92m↓0.12%[0m) [0.12% of initial]
[Iter 17690/20000] Loss: 0.0004059 (Best: 0.0002736 @iter17623) ([91m↑32.54%[0m) [0.16% of initial]
Iter:17699, L1 loss=0.0005796, Total loss=0.0005038, Time:53
[Iter 17700/20000] Loss: 0.0005082 (Best: 0.0002736 @iter17623) ([91m↑25.22%[0m) [0.20% of initial]
[Iter 17710/20000] Loss: 0.0004955 (Best: 0.0002736 @iter17623) ([92m↓2.51%[0m) [0.20% of initial]
[Iter 17720/20000] Loss: 0.0004165 (Best: 0.0002736 @iter17623) ([92m↓15.93%[0m) [0.17% of initial]
[Iter 17730/20000] Loss: 0.0003748 (Best: 0.0002736 @iter17623) ([92m↓10.02%[0m) [0.15% of initial]
[Iter 17740/20000] Loss: 0.0003492 (Best: 0.0002736 @iter17623) ([92m↓6.82%[0m) [0.14% of initial]
[Iter 17750/20000] Loss: 0.0003058 (Best: 0.0002736 @iter17623) ([92m↓12.45%[0m) [0.12% of initial]
[Iter 17760/20000] Loss: 0.0002995 (Best: 0.0002736 @iter17623) ([92m↓2.06%[0m) [0.12% of initial]
[Iter 17770/20000] Loss: 0.0002941 (Best: 0.0002736 @iter17623) ([92m↓1.79%[0m) [0.12% of initial]
[Iter 17780/20000] Loss: 0.0003079 (Best: 0.0002736 @iter17623) ([91m↑4.68%[0m) [0.12% of initial]
[Iter 17790/20000] Loss: 0.0003080 (Best: 0.0002736 @iter17623) ([91m↑0.02%[0m) [0.12% of initial]
Iter:17799, L1 loss=0.0003619, Total loss=0.0003199, Time:65
[Iter 17800/20000] Loss: 0.0002966 (Best: 0.0002736 @iter17623) ([92m↓3.70%[0m) [0.12% of initial]
[Iter 17810/20000] Loss: 0.0003013 (Best: 0.0002736 @iter17623) ([91m↑1.58%[0m) [0.12% of initial]
[Iter 17820/20000] Loss: 0.0003088 (Best: 0.0002736 @iter17623) ([91m↑2.51%[0m) [0.12% of initial]
[Iter 17830/20000] Loss: 0.0002931 (Best: 0.0002736 @iter17623) ([92m↓5.10%[0m) [0.12% of initial]
[Iter 17840/20000] Loss: 0.0002893 (Best: 0.0002736 @iter17623) ([92m↓1.30%[0m) [0.11% of initial]
[Iter 17850/20000] Loss: 0.0003030 (Best: 0.0002736 @iter17623) ([91m↑4.74%[0m) [0.12% of initial]
[Iter 17860/20000] Loss: 0.0002895 (Best: 0.0002736 @iter17623) ([92m↓4.47%[0m) [0.12% of initial]
[Iter 17870/20000] Loss: 0.0002840 (Best: 0.0002702 @iter17867) ([92m↓1.89%[0m) [0.11% of initial]
[Iter 17880/20000] Loss: 0.0003248 (Best: 0.0002702 @iter17867) ([91m↑14.37%[0m) [0.13% of initial]
[Iter 17890/20000] Loss: 0.0003114 (Best: 0.0002702 @iter17867) ([92m↓4.13%[0m) [0.12% of initial]
Iter:17899, L1 loss=0.000364, Total loss=0.0003164, Time:67
[Iter 17900/20000] Loss: 0.0003326 (Best: 0.0002702 @iter17867) ([91m↑6.81%[0m) [0.13% of initial]
[Iter 17910/20000] Loss: 0.0003209 (Best: 0.0002702 @iter17867) ([92m↓3.53%[0m) [0.13% of initial]
[Iter 17920/20000] Loss: 0.0003335 (Best: 0.0002702 @iter17867) ([91m↑3.92%[0m) [0.13% of initial]
[Iter 17930/20000] Loss: 0.0003285 (Best: 0.0002702 @iter17867) ([92m↓1.49%[0m) [0.13% of initial]
[Iter 17940/20000] Loss: 0.0003023 (Best: 0.0002702 @iter17867) ([92m↓7.97%[0m) [0.12% of initial]
[Iter 17950/20000] Loss: 0.0003110 (Best: 0.0002702 @iter17867) ([91m↑2.87%[0m) [0.12% of initial]
[Iter 17960/20000] Loss: 0.0003050 (Best: 0.0002702 @iter17867) ([92m↓1.93%[0m) [0.12% of initial]
[Iter 17970/20000] Loss: 0.0003028 (Best: 0.0002702 @iter17867) ([92m↓0.72%[0m) [0.12% of initial]
[Iter 17980/20000] Loss: 0.0003050 (Best: 0.0002702 @iter17867) ([91m↑0.72%[0m) [0.12% of initial]
[Iter 17990/20000] Loss: 0.0003155 (Best: 0.0002702 @iter17867) ([91m↑3.46%[0m) [0.13% of initial]
Iter:17999, L1 loss=0.0003692, Total loss=0.0003288, Time:64
[Iter 18000/20000] Loss: 0.0003273 (Best: 0.0002702 @iter17867) ([91m↑3.73%[0m) [0.13% of initial]
Pruning 2 points (0.0%) from gaussian0 at iteration 18000
Pruning 6 points (0.0%) from gaussian1 at iteration 18000
[Iter 18010/20000] Loss: 0.0259794 (Best: 0.0002702 @iter17867) ([91m↑7837.50%[0m) [10.32% of initial]
[Iter 18020/20000] Loss: 0.0082700 (Best: 0.0002702 @iter17867) ([92m↓68.17%[0m) [3.29% of initial]
[Iter 18030/20000] Loss: 0.0051539 (Best: 0.0002702 @iter17867) ([92m↓37.68%[0m) [2.05% of initial]
[Iter 18040/20000] Loss: 0.0028010 (Best: 0.0002702 @iter17867) ([92m↓45.65%[0m) [1.11% of initial]
[Iter 18050/20000] Loss: 0.0018950 (Best: 0.0002702 @iter17867) ([92m↓32.35%[0m) [0.75% of initial]
[Iter 18060/20000] Loss: 0.0015225 (Best: 0.0002702 @iter17867) ([92m↓19.66%[0m) [0.60% of initial]
[Iter 18070/20000] Loss: 0.0011664 (Best: 0.0002702 @iter17867) ([92m↓23.39%[0m) [0.46% of initial]
[Iter 18080/20000] Loss: 0.0009442 (Best: 0.0002702 @iter17867) ([92m↓19.05%[0m) [0.38% of initial]
[Iter 18090/20000] Loss: 0.0008239 (Best: 0.0002702 @iter17867) ([92m↓12.75%[0m) [0.33% of initial]
Iter:18099, L1 loss=0.0007561, Total loss=0.000757, Time:63
[Iter 18100/20000] Loss: 0.0007496 (Best: 0.0002702 @iter17867) ([92m↓9.01%[0m) [0.30% of initial]
[Iter 18110/20000] Loss: 0.0006736 (Best: 0.0002702 @iter17867) ([92m↓10.14%[0m) [0.27% of initial]
[Iter 18120/20000] Loss: 0.0006208 (Best: 0.0002702 @iter17867) ([92m↓7.85%[0m) [0.25% of initial]
[Iter 18130/20000] Loss: 0.0005698 (Best: 0.0002702 @iter17867) ([92m↓8.21%[0m) [0.23% of initial]
[Iter 18140/20000] Loss: 0.0005444 (Best: 0.0002702 @iter17867) ([92m↓4.45%[0m) [0.22% of initial]
[Iter 18150/20000] Loss: 0.0005270 (Best: 0.0002702 @iter17867) ([92m↓3.19%[0m) [0.21% of initial]
[Iter 18160/20000] Loss: 0.0005013 (Best: 0.0002702 @iter17867) ([92m↓4.89%[0m) [0.20% of initial]
[Iter 18170/20000] Loss: 0.0004867 (Best: 0.0002702 @iter17867) ([92m↓2.90%[0m) [0.19% of initial]
[Iter 18180/20000] Loss: 0.0004761 (Best: 0.0002702 @iter17867) ([92m↓2.18%[0m) [0.19% of initial]
[Iter 18190/20000] Loss: 0.0004578 (Best: 0.0002702 @iter17867) ([92m↓3.85%[0m) [0.18% of initial]
Iter:18199, L1 loss=0.0004673, Total loss=0.0004367, Time:68
[Iter 18200/20000] Loss: 0.0004509 (Best: 0.0002702 @iter17867) ([92m↓1.52%[0m) [0.18% of initial]
[Iter 18210/20000] Loss: 0.0004468 (Best: 0.0002702 @iter17867) ([92m↓0.90%[0m) [0.18% of initial]
[Iter 18220/20000] Loss: 0.0004395 (Best: 0.0002702 @iter17867) ([92m↓1.64%[0m) [0.17% of initial]
[Iter 18230/20000] Loss: 0.0004254 (Best: 0.0002702 @iter17867) ([92m↓3.20%[0m) [0.17% of initial]
[Iter 18240/20000] Loss: 0.0004173 (Best: 0.0002702 @iter17867) ([92m↓1.91%[0m) [0.17% of initial]
[Iter 18250/20000] Loss: 0.0004025 (Best: 0.0002702 @iter17867) ([92m↓3.55%[0m) [0.16% of initial]
[Iter 18260/20000] Loss: 0.0004300 (Best: 0.0002702 @iter17867) ([91m↑6.84%[0m) [0.17% of initial]
[Iter 18270/20000] Loss: 0.0004174 (Best: 0.0002702 @iter17867) ([92m↓2.93%[0m) [0.17% of initial]
[Iter 18280/20000] Loss: 0.0004635 (Best: 0.0002702 @iter17867) ([91m↑11.04%[0m) [0.18% of initial]
[Iter 18290/20000] Loss: 0.0004193 (Best: 0.0002702 @iter17867) ([92m↓9.54%[0m) [0.17% of initial]
Iter:18299, L1 loss=0.000505, Total loss=0.0004202, Time:56
[Iter 18300/20000] Loss: 0.0004112 (Best: 0.0002702 @iter17867) ([92m↓1.93%[0m) [0.16% of initial]
[Iter 18310/20000] Loss: 0.0004036 (Best: 0.0002702 @iter17867) ([92m↓1.84%[0m) [0.16% of initial]
[Iter 18320/20000] Loss: 0.0003943 (Best: 0.0002702 @iter17867) ([92m↓2.32%[0m) [0.16% of initial]
[Iter 18330/20000] Loss: 0.0003951 (Best: 0.0002702 @iter17867) ([91m↑0.21%[0m) [0.16% of initial]
[Iter 18340/20000] Loss: 0.0003845 (Best: 0.0002702 @iter17867) ([92m↓2.69%[0m) [0.15% of initial]
[Iter 18350/20000] Loss: 0.0003822 (Best: 0.0002702 @iter17867) ([92m↓0.59%[0m) [0.15% of initial]
[Iter 18360/20000] Loss: 0.0003798 (Best: 0.0002702 @iter17867) ([92m↓0.64%[0m) [0.15% of initial]
[Iter 18370/20000] Loss: 0.0003745 (Best: 0.0002702 @iter17867) ([92m↓1.38%[0m) [0.15% of initial]
[Iter 18380/20000] Loss: 0.0003756 (Best: 0.0002702 @iter17867) ([91m↑0.30%[0m) [0.15% of initial]
[Iter 18390/20000] Loss: 0.0003774 (Best: 0.0002702 @iter17867) ([91m↑0.47%[0m) [0.15% of initial]
Iter:18399, L1 loss=0.0004194, Total loss=0.0003843, Time:68
[Iter 18400/20000] Loss: 0.0003803 (Best: 0.0002702 @iter17867) ([91m↑0.77%[0m) [0.15% of initial]
[Iter 18410/20000] Loss: 0.0003947 (Best: 0.0002702 @iter17867) ([91m↑3.77%[0m) [0.16% of initial]
[Iter 18420/20000] Loss: 0.0003929 (Best: 0.0002702 @iter17867) ([92m↓0.44%[0m) [0.16% of initial]
[Iter 18430/20000] Loss: 0.0004026 (Best: 0.0002702 @iter17867) ([91m↑2.46%[0m) [0.16% of initial]
[Iter 18440/20000] Loss: 0.0003913 (Best: 0.0002702 @iter17867) ([92m↓2.79%[0m) [0.16% of initial]
[Iter 18450/20000] Loss: 0.0003807 (Best: 0.0002702 @iter17867) ([92m↓2.72%[0m) [0.15% of initial]
[Iter 18460/20000] Loss: 0.0003846 (Best: 0.0002702 @iter17867) ([91m↑1.01%[0m) [0.15% of initial]
[Iter 18470/20000] Loss: 0.0003710 (Best: 0.0002702 @iter17867) ([92m↓3.53%[0m) [0.15% of initial]
[Iter 18480/20000] Loss: 0.0003809 (Best: 0.0002702 @iter17867) ([91m↑2.67%[0m) [0.15% of initial]
[Iter 18490/20000] Loss: 0.0003863 (Best: 0.0002702 @iter17867) ([91m↑1.42%[0m) [0.15% of initial]
Iter:18499, L1 loss=0.0004188, Total loss=0.0003618, Time:62
[Iter 18500/20000] Loss: 0.0003804 (Best: 0.0002702 @iter17867) ([92m↓1.54%[0m) [0.15% of initial]
Pruning 8 points (0.0%) from gaussian0 at iteration 18500
Pruning 6 points (0.0%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0006758 (Best: 0.0002702 @iter17867) ([91m↑77.68%[0m) [0.27% of initial]
[Iter 18520/20000] Loss: 0.0004859 (Best: 0.0002702 @iter17867) ([92m↓28.11%[0m) [0.19% of initial]
[Iter 18530/20000] Loss: 0.0004124 (Best: 0.0002702 @iter17867) ([92m↓15.11%[0m) [0.16% of initial]
[Iter 18540/20000] Loss: 0.0004234 (Best: 0.0002702 @iter17867) ([91m↑2.65%[0m) [0.17% of initial]
[Iter 18550/20000] Loss: 0.0003964 (Best: 0.0002702 @iter17867) ([92m↓6.37%[0m) [0.16% of initial]
[Iter 18560/20000] Loss: 0.0003768 (Best: 0.0002702 @iter17867) ([92m↓4.94%[0m) [0.15% of initial]
[Iter 18570/20000] Loss: 0.0003608 (Best: 0.0002702 @iter17867) ([92m↓4.25%[0m) [0.14% of initial]
[Iter 18580/20000] Loss: 0.0003567 (Best: 0.0002702 @iter17867) ([92m↓1.14%[0m) [0.14% of initial]
[Iter 18590/20000] Loss: 0.0003585 (Best: 0.0002702 @iter17867) ([91m↑0.51%[0m) [0.14% of initial]
Iter:18599, L1 loss=0.0004202, Total loss=0.0003823, Time:49
[Iter 18600/20000] Loss: 0.0003826 (Best: 0.0002702 @iter17867) ([91m↑6.70%[0m) [0.15% of initial]
[Iter 18610/20000] Loss: 0.0003619 (Best: 0.0002702 @iter17867) ([92m↓5.39%[0m) [0.14% of initial]
[Iter 18620/20000] Loss: 0.0003575 (Best: 0.0002702 @iter17867) ([92m↓1.22%[0m) [0.14% of initial]
[Iter 18630/20000] Loss: 0.0003693 (Best: 0.0002702 @iter17867) ([91m↑3.29%[0m) [0.15% of initial]
[Iter 18640/20000] Loss: 0.0003688 (Best: 0.0002702 @iter17867) ([92m↓0.12%[0m) [0.15% of initial]
[Iter 18650/20000] Loss: 0.0003759 (Best: 0.0002702 @iter17867) ([91m↑1.91%[0m) [0.15% of initial]
[Iter 18660/20000] Loss: 0.0003798 (Best: 0.0002702 @iter17867) ([91m↑1.04%[0m) [0.15% of initial]
[Iter 18670/20000] Loss: 0.0003852 (Best: 0.0002702 @iter17867) ([91m↑1.43%[0m) [0.15% of initial]
[Iter 18680/20000] Loss: 0.0004005 (Best: 0.0002702 @iter17867) ([91m↑3.95%[0m) [0.16% of initial]
[Iter 18690/20000] Loss: 0.0003890 (Best: 0.0002702 @iter17867) ([92m↓2.85%[0m) [0.15% of initial]
Iter:18699, L1 loss=0.0004267, Total loss=0.0003928, Time:68
[Iter 18700/20000] Loss: 0.0003806 (Best: 0.0002702 @iter17867) ([92m↓2.17%[0m) [0.15% of initial]
[Iter 18710/20000] Loss: 0.0003835 (Best: 0.0002702 @iter17867) ([91m↑0.76%[0m) [0.15% of initial]
[Iter 18720/20000] Loss: 0.0003907 (Best: 0.0002702 @iter17867) ([91m↑1.88%[0m) [0.16% of initial]
[Iter 18730/20000] Loss: 0.0004033 (Best: 0.0002702 @iter17867) ([91m↑3.22%[0m) [0.16% of initial]
[Iter 18740/20000] Loss: 0.0003884 (Best: 0.0002702 @iter17867) ([92m↓3.69%[0m) [0.15% of initial]
[Iter 18750/20000] Loss: 0.0004102 (Best: 0.0002702 @iter17867) ([91m↑5.62%[0m) [0.16% of initial]
[Iter 18760/20000] Loss: 0.0004055 (Best: 0.0002702 @iter17867) ([92m↓1.15%[0m) [0.16% of initial]
[Iter 18770/20000] Loss: 0.0003832 (Best: 0.0002702 @iter17867) ([92m↓5.50%[0m) [0.15% of initial]
[Iter 18780/20000] Loss: 0.0003698 (Best: 0.0002702 @iter17867) ([92m↓3.50%[0m) [0.15% of initial]
[Iter 18790/20000] Loss: 0.0003678 (Best: 0.0002702 @iter17867) ([92m↓0.55%[0m) [0.15% of initial]
Iter:18799, L1 loss=0.0004153, Total loss=0.0003692, Time:70
[Iter 18800/20000] Loss: 0.0003602 (Best: 0.0002702 @iter17867) ([92m↓2.06%[0m) [0.14% of initial]
[Iter 18810/20000] Loss: 0.0003583 (Best: 0.0002702 @iter17867) ([92m↓0.53%[0m) [0.14% of initial]
[Iter 18820/20000] Loss: 0.0003630 (Best: 0.0002702 @iter17867) ([91m↑1.31%[0m) [0.14% of initial]
[Iter 18830/20000] Loss: 0.0003693 (Best: 0.0002702 @iter17867) ([91m↑1.73%[0m) [0.15% of initial]
[Iter 18840/20000] Loss: 0.0003627 (Best: 0.0002702 @iter17867) ([92m↓1.77%[0m) [0.14% of initial]
[Iter 18850/20000] Loss: 0.0003879 (Best: 0.0002702 @iter17867) ([91m↑6.92%[0m) [0.15% of initial]
[Iter 18860/20000] Loss: 0.0003904 (Best: 0.0002702 @iter17867) ([91m↑0.64%[0m) [0.16% of initial]
[Iter 18870/20000] Loss: 0.0003876 (Best: 0.0002702 @iter17867) ([92m↓0.70%[0m) [0.15% of initial]
[Iter 18880/20000] Loss: 0.0003811 (Best: 0.0002702 @iter17867) ([92m↓1.67%[0m) [0.15% of initial]
[Iter 18890/20000] Loss: 0.0003628 (Best: 0.0002702 @iter17867) ([92m↓4.80%[0m) [0.14% of initial]
Iter:18899, L1 loss=0.0004231, Total loss=0.0003892, Time:65
[Iter 18900/20000] Loss: 0.0003943 (Best: 0.0002702 @iter17867) ([91m↑8.67%[0m) [0.16% of initial]
[Iter 18910/20000] Loss: 0.0003789 (Best: 0.0002702 @iter17867) ([92m↓3.91%[0m) [0.15% of initial]
[Iter 18920/20000] Loss: 0.0003644 (Best: 0.0002702 @iter17867) ([92m↓3.82%[0m) [0.14% of initial]
[Iter 18930/20000] Loss: 0.0003681 (Best: 0.0002702 @iter17867) ([91m↑1.03%[0m) [0.15% of initial]
[Iter 18940/20000] Loss: 0.0003668 (Best: 0.0002702 @iter17867) ([92m↓0.36%[0m) [0.15% of initial]
[Iter 18950/20000] Loss: 0.0003714 (Best: 0.0002702 @iter17867) ([91m↑1.25%[0m) [0.15% of initial]
[Iter 18960/20000] Loss: 0.0003622 (Best: 0.0002702 @iter17867) ([92m↓2.48%[0m) [0.14% of initial]
[Iter 18970/20000] Loss: 0.0003633 (Best: 0.0002702 @iter17867) ([91m↑0.30%[0m) [0.14% of initial]
[Iter 18980/20000] Loss: 0.0003634 (Best: 0.0002702 @iter17867) ([91m↑0.04%[0m) [0.14% of initial]
[Iter 18990/20000] Loss: 0.0003654 (Best: 0.0002702 @iter17867) ([91m↑0.54%[0m) [0.15% of initial]
Iter:18999, L1 loss=0.0004525, Total loss=0.0003685, Time:52
[Iter 19000/20000] Loss: 0.0003708 (Best: 0.0002702 @iter17867) ([91m↑1.49%[0m) [0.15% of initial]
Pruning 0 points (0.0%) from gaussian0 at iteration 19000
Pruning 6 points (0.0%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0007215 (Best: 0.0002702 @iter17867) ([91m↑94.57%[0m) [0.29% of initial]
[Iter 19020/20000] Loss: 0.0004862 (Best: 0.0002702 @iter17867) ([92m↓32.61%[0m) [0.19% of initial]
[Iter 19030/20000] Loss: 0.0004478 (Best: 0.0002702 @iter17867) ([92m↓7.89%[0m) [0.18% of initial]
[Iter 19040/20000] Loss: 0.0003900 (Best: 0.0002702 @iter17867) ([92m↓12.92%[0m) [0.15% of initial]
[Iter 19050/20000] Loss: 0.0003633 (Best: 0.0002702 @iter17867) ([92m↓6.83%[0m) [0.14% of initial]
[Iter 19060/20000] Loss: 0.0003525 (Best: 0.0002702 @iter17867) ([92m↓2.98%[0m) [0.14% of initial]
[Iter 19070/20000] Loss: 0.0003543 (Best: 0.0002702 @iter17867) ([91m↑0.49%[0m) [0.14% of initial]
[Iter 19080/20000] Loss: 0.0003442 (Best: 0.0002702 @iter17867) ([92m↓2.84%[0m) [0.14% of initial]
[Iter 19090/20000] Loss: 0.0003512 (Best: 0.0002702 @iter17867) ([91m↑2.02%[0m) [0.14% of initial]
Iter:19099, L1 loss=0.0003633, Total loss=0.0003457, Time:53
[Iter 19100/20000] Loss: 0.0003572 (Best: 0.0002702 @iter17867) ([91m↑1.71%[0m) [0.14% of initial]
[Iter 19110/20000] Loss: 0.0003908 (Best: 0.0002702 @iter17867) ([91m↑9.42%[0m) [0.16% of initial]
[Iter 19120/20000] Loss: 0.0003736 (Best: 0.0002702 @iter17867) ([92m↓4.41%[0m) [0.15% of initial]
[Iter 19130/20000] Loss: 0.0003784 (Best: 0.0002702 @iter17867) ([91m↑1.29%[0m) [0.15% of initial]
[Iter 19140/20000] Loss: 0.0003671 (Best: 0.0002702 @iter17867) ([92m↓2.99%[0m) [0.15% of initial]
[Iter 19150/20000] Loss: 0.0003442 (Best: 0.0002702 @iter17867) ([92m↓6.24%[0m) [0.14% of initial]
[Iter 19160/20000] Loss: 0.0003556 (Best: 0.0002702 @iter17867) ([91m↑3.34%[0m) [0.14% of initial]
[Iter 19170/20000] Loss: 0.0003585 (Best: 0.0002702 @iter17867) ([91m↑0.80%[0m) [0.14% of initial]
[Iter 19180/20000] Loss: 0.0003643 (Best: 0.0002702 @iter17867) ([91m↑1.61%[0m) [0.14% of initial]
[Iter 19190/20000] Loss: 0.0003694 (Best: 0.0002702 @iter17867) ([91m↑1.42%[0m) [0.15% of initial]
Iter:19199, L1 loss=0.0004392, Total loss=0.0003802, Time:56
[Iter 19200/20000] Loss: 0.0003636 (Best: 0.0002702 @iter17867) ([92m↓1.59%[0m) [0.14% of initial]
[Iter 19210/20000] Loss: 0.0003505 (Best: 0.0002702 @iter17867) ([92m↓3.59%[0m) [0.14% of initial]
[Iter 19220/20000] Loss: 0.0003758 (Best: 0.0002702 @iter17867) ([91m↑7.20%[0m) [0.15% of initial]
[Iter 19230/20000] Loss: 0.0003787 (Best: 0.0002702 @iter17867) ([91m↑0.79%[0m) [0.15% of initial]
[Iter 19240/20000] Loss: 0.0004079 (Best: 0.0002702 @iter17867) ([91m↑7.70%[0m) [0.16% of initial]
[Iter 19250/20000] Loss: 0.0004153 (Best: 0.0002702 @iter17867) ([91m↑1.82%[0m) [0.17% of initial]
[Iter 19260/20000] Loss: 0.0003742 (Best: 0.0002702 @iter17867) ([92m↓9.89%[0m) [0.15% of initial]
[Iter 19270/20000] Loss: 0.0003626 (Best: 0.0002702 @iter17867) ([92m↓3.10%[0m) [0.14% of initial]
[Iter 19280/20000] Loss: 0.0003533 (Best: 0.0002702 @iter17867) ([92m↓2.58%[0m) [0.14% of initial]
[Iter 19290/20000] Loss: 0.0003442 (Best: 0.0002702 @iter17867) ([92m↓2.56%[0m) [0.14% of initial]
Iter:19299, L1 loss=0.0003847, Total loss=0.0003429, Time:54
[Iter 19300/20000] Loss: 0.0003410 (Best: 0.0002702 @iter17867) ([92m↓0.94%[0m) [0.14% of initial]
[Iter 19310/20000] Loss: 0.0003496 (Best: 0.0002702 @iter17867) ([91m↑2.52%[0m) [0.14% of initial]
[Iter 19320/20000] Loss: 0.0003753 (Best: 0.0002702 @iter17867) ([91m↑7.37%[0m) [0.15% of initial]
[Iter 19330/20000] Loss: 0.0003681 (Best: 0.0002702 @iter17867) ([92m↓1.93%[0m) [0.15% of initial]
[Iter 19340/20000] Loss: 0.0003649 (Best: 0.0002702 @iter17867) ([92m↓0.87%[0m) [0.14% of initial]
[Iter 19350/20000] Loss: 0.0003478 (Best: 0.0002702 @iter17867) ([92m↓4.68%[0m) [0.14% of initial]
[Iter 19360/20000] Loss: 0.0003399 (Best: 0.0002702 @iter17867) ([92m↓2.28%[0m) [0.14% of initial]
[Iter 19370/20000] Loss: 0.0003467 (Best: 0.0002702 @iter17867) ([91m↑2.02%[0m) [0.14% of initial]
[Iter 19380/20000] Loss: 0.0003513 (Best: 0.0002702 @iter17867) ([91m↑1.33%[0m) [0.14% of initial]
[Iter 19390/20000] Loss: 0.0003581 (Best: 0.0002702 @iter17867) ([91m↑1.92%[0m) [0.14% of initial]
Iter:19399, L1 loss=0.0004088, Total loss=0.0003827, Time:57
[Iter 19400/20000] Loss: 0.0003786 (Best: 0.0002702 @iter17867) ([91m↑5.73%[0m) [0.15% of initial]
[Iter 19410/20000] Loss: 0.0004380 (Best: 0.0002702 @iter17867) ([91m↑15.67%[0m) [0.17% of initial]
[Iter 19420/20000] Loss: 0.0004549 (Best: 0.0002702 @iter17867) ([91m↑3.86%[0m) [0.18% of initial]
[Iter 19430/20000] Loss: 0.0003891 (Best: 0.0002702 @iter17867) ([92m↓14.45%[0m) [0.15% of initial]
[Iter 19440/20000] Loss: 0.0003750 (Best: 0.0002702 @iter17867) ([92m↓3.65%[0m) [0.15% of initial]
[Iter 19450/20000] Loss: 0.0003502 (Best: 0.0002702 @iter17867) ([92m↓6.60%[0m) [0.14% of initial]
[Iter 19460/20000] Loss: 0.0003556 (Best: 0.0002702 @iter17867) ([91m↑1.54%[0m) [0.14% of initial]
[Iter 19470/20000] Loss: 0.0003616 (Best: 0.0002702 @iter17867) ([91m↑1.70%[0m) [0.14% of initial]
[Iter 19480/20000] Loss: 0.0003558 (Best: 0.0002702 @iter17867) ([92m↓1.62%[0m) [0.14% of initial]
[Iter 19490/20000] Loss: 0.0003503 (Best: 0.0002702 @iter17867) ([92m↓1.53%[0m) [0.14% of initial]
Iter:19499, L1 loss=0.0003857, Total loss=0.0003353, Time:54
[Iter 19500/20000] Loss: 0.0003579 (Best: 0.0002702 @iter17867) ([91m↑2.16%[0m) [0.14% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 19500
Pruning 8 points (0.0%) from gaussian1 at iteration 19500
[Iter 19510/20000] Loss: 0.0006223 (Best: 0.0002702 @iter17867) ([91m↑73.87%[0m) [0.25% of initial]
[Iter 19520/20000] Loss: 0.0004291 (Best: 0.0002702 @iter17867) ([92m↓31.05%[0m) [0.17% of initial]
[Iter 19530/20000] Loss: 0.0004150 (Best: 0.0002702 @iter17867) ([92m↓3.28%[0m) [0.16% of initial]
[Iter 19540/20000] Loss: 0.0003695 (Best: 0.0002702 @iter17867) ([92m↓10.96%[0m) [0.15% of initial]
[Iter 19550/20000] Loss: 0.0003348 (Best: 0.0002702 @iter17867) ([92m↓9.41%[0m) [0.13% of initial]
[Iter 19560/20000] Loss: 0.0003431 (Best: 0.0002702 @iter17867) ([91m↑2.49%[0m) [0.14% of initial]
[Iter 19570/20000] Loss: 0.0003349 (Best: 0.0002702 @iter17867) ([92m↓2.39%[0m) [0.13% of initial]
[Iter 19580/20000] Loss: 0.0003410 (Best: 0.0002702 @iter17867) ([91m↑1.83%[0m) [0.14% of initial]
[Iter 19590/20000] Loss: 0.0003363 (Best: 0.0002702 @iter17867) ([92m↓1.40%[0m) [0.13% of initial]
Iter:19599, L1 loss=0.0003779, Total loss=0.0003303, Time:57
[Iter 19600/20000] Loss: 0.0003272 (Best: 0.0002702 @iter17867) ([92m↓2.71%[0m) [0.13% of initial]
[Iter 19610/20000] Loss: 0.0003473 (Best: 0.0002702 @iter17867) ([91m↑6.17%[0m) [0.14% of initial]
[Iter 19620/20000] Loss: 0.0003569 (Best: 0.0002702 @iter17867) ([91m↑2.76%[0m) [0.14% of initial]
[Iter 19630/20000] Loss: 0.0003398 (Best: 0.0002702 @iter17867) ([92m↓4.79%[0m) [0.14% of initial]
[Iter 19640/20000] Loss: 0.0003909 (Best: 0.0002702 @iter17867) ([91m↑15.05%[0m) [0.16% of initial]
[Iter 19650/20000] Loss: 0.0003920 (Best: 0.0002702 @iter17867) ([91m↑0.27%[0m) [0.16% of initial]
[Iter 19660/20000] Loss: 0.0003691 (Best: 0.0002702 @iter17867) ([92m↓5.85%[0m) [0.15% of initial]
[Iter 19670/20000] Loss: 0.0003441 (Best: 0.0002702 @iter17867) ([92m↓6.77%[0m) [0.14% of initial]
[Iter 19680/20000] Loss: 0.0003413 (Best: 0.0002702 @iter17867) ([92m↓0.81%[0m) [0.14% of initial]
[Iter 19690/20000] Loss: 0.0003482 (Best: 0.0002702 @iter17867) ([91m↑2.02%[0m) [0.14% of initial]
Iter:19699, L1 loss=0.0004378, Total loss=0.0003413, Time:55
[Iter 19700/20000] Loss: 0.0003659 (Best: 0.0002702 @iter17867) ([91m↑5.09%[0m) [0.15% of initial]
[Iter 19710/20000] Loss: 0.0003580 (Best: 0.0002702 @iter17867) ([92m↓2.17%[0m) [0.14% of initial]
[Iter 19720/20000] Loss: 0.0003470 (Best: 0.0002702 @iter17867) ([92m↓3.07%[0m) [0.14% of initial]
[Iter 19730/20000] Loss: 0.0003408 (Best: 0.0002702 @iter17867) ([92m↓1.77%[0m) [0.14% of initial]
[Iter 19740/20000] Loss: 0.0003530 (Best: 0.0002702 @iter17867) ([91m↑3.56%[0m) [0.14% of initial]
[Iter 19750/20000] Loss: 0.0003854 (Best: 0.0002702 @iter17867) ([91m↑9.19%[0m) [0.15% of initial]
[Iter 19760/20000] Loss: 0.0004533 (Best: 0.0002702 @iter17867) ([91m↑17.63%[0m) [0.18% of initial]
[Iter 19770/20000] Loss: 0.0004548 (Best: 0.0002702 @iter17867) ([91m↑0.32%[0m) [0.18% of initial]
[Iter 19780/20000] Loss: 0.0003876 (Best: 0.0002702 @iter17867) ([92m↓14.76%[0m) [0.15% of initial]
[Iter 19790/20000] Loss: 0.0003550 (Best: 0.0002702 @iter17867) ([92m↓8.41%[0m) [0.14% of initial]
Iter:19799, L1 loss=0.0004054, Total loss=0.0003646, Time:57
[Iter 19800/20000] Loss: 0.0003706 (Best: 0.0002702 @iter17867) ([91m↑4.38%[0m) [0.15% of initial]
[Iter 19810/20000] Loss: 0.0003562 (Best: 0.0002702 @iter17867) ([92m↓3.89%[0m) [0.14% of initial]
[Iter 19820/20000] Loss: 0.0003935 (Best: 0.0002702 @iter17867) ([91m↑10.49%[0m) [0.16% of initial]
[Iter 19830/20000] Loss: 0.0003906 (Best: 0.0002702 @iter17867) ([92m↓0.75%[0m) [0.16% of initial]
[Iter 19840/20000] Loss: 0.0003492 (Best: 0.0002702 @iter17867) ([92m↓10.60%[0m) [0.14% of initial]
[Iter 19850/20000] Loss: 0.0003454 (Best: 0.0002702 @iter17867) ([92m↓1.08%[0m) [0.14% of initial]
[Iter 19860/20000] Loss: 0.0003732 (Best: 0.0002702 @iter17867) ([91m↑8.04%[0m) [0.15% of initial]
[Iter 19870/20000] Loss: 0.0003889 (Best: 0.0002702 @iter17867) ([91m↑4.22%[0m) [0.15% of initial]
[Iter 19880/20000] Loss: 0.0003989 (Best: 0.0002702 @iter17867) ([91m↑2.55%[0m) [0.16% of initial]
[Iter 19890/20000] Loss: 0.0003674 (Best: 0.0002702 @iter17867) ([92m↓7.89%[0m) [0.15% of initial]
Iter:19899, L1 loss=0.0003966, Total loss=0.0004231, Time:50
[Iter 19900/20000] Loss: 0.0004331 (Best: 0.0002702 @iter17867) ([91m↑17.90%[0m) [0.17% of initial]
[Iter 19910/20000] Loss: 0.0003945 (Best: 0.0002702 @iter17867) ([92m↓8.92%[0m) [0.16% of initial]
[Iter 19920/20000] Loss: 0.0004284 (Best: 0.0002702 @iter17867) ([91m↑8.60%[0m) [0.17% of initial]
[Iter 19930/20000] Loss: 0.0003995 (Best: 0.0002702 @iter17867) ([92m↓6.75%[0m) [0.16% of initial]
[Iter 19940/20000] Loss: 0.0003678 (Best: 0.0002702 @iter17867) ([92m↓7.95%[0m) [0.15% of initial]
[Iter 19950/20000] Loss: 0.0003467 (Best: 0.0002702 @iter17867) ([92m↓5.71%[0m) [0.14% of initial]
[Iter 19960/20000] Loss: 0.0003348 (Best: 0.0002702 @iter17867) ([92m↓3.44%[0m) [0.13% of initial]
[Iter 19970/20000] Loss: 0.0003308 (Best: 0.0002702 @iter17867) ([92m↓1.21%[0m) [0.13% of initial]
[Iter 19980/20000] Loss: 0.0003326 (Best: 0.0002702 @iter17867) ([91m↑0.57%[0m) [0.13% of initial]
[Iter 19990/20000] Loss: 0.0003246 (Best: 0.0002702 @iter17867) ([92m↓2.43%[0m) [0.13% of initial]
Iter:19999, L1 loss=0.0003749, Total loss=0.0003305, Time:65
[Iter 20000/20000] Loss: 0.0003368 (Best: 0.0002702 @iter17867) ([91m↑3.77%[0m) [0.13% of initial]
Testing Speed: 53.84152074198867 fps
Testing Time: 0.9286513328552246 s

[ITER 20000] Evaluating test: SSIM = 0.9249796664714813, PSNR = 21.326136150360107
Testing Speed: 66.98668029514167 fps
Testing Time: 0.0447850227355957 s

[ITER 20000] Evaluating train: SSIM = 0.9999985098838806, PSNR = 63.32564798990885
Iter:20000, total_points:131455

[ITER 20000] Saving Gaussians
Pruning 1 points (0.0%) from gaussian0 at iteration 20000
Pruning 5 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 53 fps
Total time: 39.33 minutes
Test SSIM: 0.9250
Test PSNR: 21.326
Gaussian0 final points count: 131454
Gaussian1 final points count: 127772
Final loss: 0.0003368 (0.13% of initial)
Save path: 2024_11_26_20_33_48
Initial loss: 0.2517052
Best loss: 0.0002702 @iteration 17867 (0.11% of initial)
Train SSIM: 1.0000
Train PSNR: 63.326
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693032 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374909 (Best: 0.1327886 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123932 (Best: 0.1098384 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993461 (Best: 0.0965438 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936764 (Best: 0.0908514 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884516 (Best: 0.0869362 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851866 (Best: 0.0831007 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824130 (Best: 0.0801503 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05724, Total loss=0.07877, Time:33
[Iter 100/20000] Loss: 0.0786726 (Best: 0.0766296 @iter97) ([92m↓4.54%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753180 (Best: 0.0731418 @iter106) ([92m↓4.26%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714391 (Best: 0.0685554 @iter118) ([92m↓5.15%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0667068 (Best: 0.0641966 @iter130) ([92m↓6.62%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635509 (Best: 0.0613020 @iter140) ([92m↓4.73%[0m) [25.25% of initial]
[Iter 150/20000] Loss: 0.0612864 (Best: 0.0584050 @iter148) ([92m↓3.56%[0m) [24.35% of initial]
[Iter 160/20000] Loss: 0.0590713 (Best: 0.0559731 @iter157) ([92m↓3.61%[0m) [23.47% of initial]
[Iter 170/20000] Loss: 0.0563614 (Best: 0.0534824 @iter167) ([92m↓4.59%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523734 (Best: 0.0500661 @iter179) ([92m↓7.08%[0m) [20.81% of initial]
[Iter 190/20000] Loss: 0.0495688 (Best: 0.0479158 @iter188) ([92m↓5.35%[0m) [19.69% of initial]
Iter:199, L1 loss=0.03443, Total loss=0.0498, Time:30
[Iter 200/20000] Loss: 0.0477873 (Best: 0.0457997 @iter198) ([92m↓3.59%[0m) [18.99% of initial]
[Iter 210/20000] Loss: 0.0451096 (Best: 0.0429257 @iter209) ([92m↓5.60%[0m) [17.92% of initial]
[Iter 220/20000] Loss: 0.0440741 (Best: 0.0411953 @iter219) ([92m↓2.30%[0m) [17.51% of initial]
[Iter 230/20000] Loss: 0.0423151 (Best: 0.0397284 @iter227) ([92m↓3.99%[0m) [16.81% of initial]
[Iter 240/20000] Loss: 0.0402369 (Best: 0.0379310 @iter238) ([92m↓4.91%[0m) [15.99% of initial]
[Iter 250/20000] Loss: 0.0379989 (Best: 0.0362939 @iter248) ([92m↓5.56%[0m) [15.10% of initial]
[Iter 260/20000] Loss: 0.0358434 (Best: 0.0342482 @iter260) ([92m↓5.67%[0m) [14.24% of initial]
[Iter 270/20000] Loss: 0.0349363 (Best: 0.0328880 @iter269) ([92m↓2.53%[0m) [13.88% of initial]
[Iter 280/20000] Loss: 0.0347462 (Best: 0.0318864 @iter277) ([92m↓0.54%[0m) [13.80% of initial]
[Iter 290/20000] Loss: 0.0331630 (Best: 0.0305521 @iter287) ([92m↓4.56%[0m) [13.18% of initial]
Iter:299, L1 loss=0.02223, Total loss=0.03339, Time:33
[Iter 300/20000] Loss: 0.0308408 (Best: 0.0289926 @iter300) ([92m↓7.00%[0m) [12.25% of initial]
[Iter 310/20000] Loss: 0.0292211 (Best: 0.0272794 @iter310) ([92m↓5.25%[0m) [11.61% of initial]
[Iter 320/20000] Loss: 0.0277466 (Best: 0.0263636 @iter320) ([92m↓5.05%[0m) [11.02% of initial]
[Iter 330/20000] Loss: 0.0273586 (Best: 0.0255264 @iter330) ([92m↓1.40%[0m) [10.87% of initial]
[Iter 340/20000] Loss: 0.0253041 (Best: 0.0241385 @iter340) ([92m↓7.51%[0m) [10.05% of initial]
[Iter 350/20000] Loss: 0.0258972 (Best: 0.0232690 @iter349) ([91m↑2.34%[0m) [10.29% of initial]
[Iter 360/20000] Loss: 0.0242840 (Best: 0.0223875 @iter358) ([92m↓6.23%[0m) [9.65% of initial]
[Iter 370/20000] Loss: 0.0239727 (Best: 0.0218331 @iter368) ([92m↓1.28%[0m) [9.52% of initial]
[Iter 380/20000] Loss: 0.0217506 (Best: 0.0206478 @iter379) ([92m↓9.27%[0m) [8.64% of initial]
[Iter 390/20000] Loss: 0.0211698 (Best: 0.0197348 @iter390) ([92m↓2.67%[0m) [8.41% of initial]
Iter:399, L1 loss=0.01409, Total loss=0.02047, Time:36
[Iter 400/20000] Loss: 0.0199672 (Best: 0.0185544 @iter400) ([92m↓5.68%[0m) [7.93% of initial]
[Iter 410/20000] Loss: 0.0189986 (Best: 0.0179810 @iter410) ([92m↓4.85%[0m) [7.55% of initial]
[Iter 420/20000] Loss: 0.0191478 (Best: 0.0171465 @iter418) ([91m↑0.79%[0m) [7.61% of initial]
[Iter 430/20000] Loss: 0.0171513 (Best: 0.0163245 @iter430) ([92m↓10.43%[0m) [6.81% of initial]
[Iter 440/20000] Loss: 0.0174511 (Best: 0.0157454 @iter438) ([91m↑1.75%[0m) [6.93% of initial]
[Iter 450/20000] Loss: 0.0162995 (Best: 0.0143451 @iter449) ([92m↓6.60%[0m) [6.48% of initial]
[Iter 460/20000] Loss: 0.0156282 (Best: 0.0136848 @iter458) ([92m↓4.12%[0m) [6.21% of initial]
[Iter 470/20000] Loss: 0.0141225 (Best: 0.0131301 @iter470) ([92m↓9.63%[0m) [5.61% of initial]
[Iter 480/20000] Loss: 0.0143140 (Best: 0.0129869 @iter479) ([91m↑1.36%[0m) [5.69% of initial]
[Iter 490/20000] Loss: 0.0137874 (Best: 0.0126254 @iter490) ([92m↓3.68%[0m) [5.48% of initial]
Iter:499, L1 loss=0.008394, Total loss=0.01473, Time:36
[Iter 500/20000] Loss: 0.0137048 (Best: 0.0123783 @iter498) ([92m↓0.60%[0m) [5.44% of initial]
[Iter 510/20000] Loss: 0.0136775 (Best: 0.0121652 @iter508) ([92m↓0.20%[0m) [5.43% of initial]
[Iter 520/20000] Loss: 0.0128650 (Best: 0.0116757 @iter514) ([92m↓5.94%[0m) [5.11% of initial]
[Iter 530/20000] Loss: 0.0125205 (Best: 0.0112409 @iter529) ([92m↓2.68%[0m) [4.97% of initial]
[Iter 540/20000] Loss: 0.0127494 (Best: 0.0110998 @iter532) ([91m↑1.83%[0m) [5.07% of initial]
[Iter 550/20000] Loss: 0.0122643 (Best: 0.0109641 @iter548) ([92m↓3.80%[0m) [4.87% of initial]
[Iter 560/20000] Loss: 0.0127571 (Best: 0.0109641 @iter548) ([91m↑4.02%[0m) [5.07% of initial]
[Iter 570/20000] Loss: 0.0127229 (Best: 0.0109641 @iter548) ([92m↓0.27%[0m) [5.05% of initial]
[Iter 580/20000] Loss: 0.0115807 (Best: 0.0109365 @iter574) ([92m↓8.98%[0m) [4.60% of initial]
[Iter 590/20000] Loss: 0.0124682 (Best: 0.0105566 @iter581) ([91m↑7.66%[0m) [4.95% of initial]
Iter:599, L1 loss=0.007013, Total loss=0.0126, Time:36
[Iter 600/20000] Loss: 0.0117126 (Best: 0.0105566 @iter581) ([92m↓6.06%[0m) [4.65% of initial]
[Iter 610/20000] Loss: 0.0210284 (Best: 0.0105566 @iter581) ([91m↑79.54%[0m) [8.35% of initial]
[Iter 620/20000] Loss: 0.0137114 (Best: 0.0105566 @iter581) ([92m↓34.80%[0m) [5.45% of initial]
[Iter 630/20000] Loss: 0.0116725 (Best: 0.0105566 @iter581) ([92m↓14.87%[0m) [4.64% of initial]
[Iter 640/20000] Loss: 0.0100385 (Best: 0.0090899 @iter640) ([92m↓14.00%[0m) [3.99% of initial]
[Iter 650/20000] Loss: 0.0105694 (Best: 0.0090899 @iter640) ([91m↑5.29%[0m) [4.20% of initial]
[Iter 660/20000] Loss: 0.0100575 (Best: 0.0087826 @iter655) ([92m↓4.84%[0m) [4.00% of initial]
[Iter 670/20000] Loss: 0.0095922 (Best: 0.0084378 @iter667) ([92m↓4.63%[0m) [3.81% of initial]
[Iter 680/20000] Loss: 0.0089626 (Best: 0.0082934 @iter678) ([92m↓6.56%[0m) [3.56% of initial]
[Iter 690/20000] Loss: 0.0090904 (Best: 0.0079252 @iter685) ([91m↑1.43%[0m) [3.61% of initial]
Iter:699, L1 loss=0.005815, Total loss=0.009819, Time:37
[Iter 700/20000] Loss: 0.0090461 (Best: 0.0079252 @iter685) ([92m↓0.49%[0m) [3.59% of initial]
[Iter 710/20000] Loss: 0.0083323 (Best: 0.0077049 @iter710) ([92m↓7.89%[0m) [3.31% of initial]
[Iter 720/20000] Loss: 0.0084629 (Best: 0.0077049 @iter710) ([91m↑1.57%[0m) [3.36% of initial]
[Iter 730/20000] Loss: 0.0084433 (Best: 0.0075358 @iter724) ([92m↓0.23%[0m) [3.35% of initial]
[Iter 740/20000] Loss: 0.0084043 (Best: 0.0073040 @iter736) ([92m↓0.46%[0m) [3.34% of initial]
[Iter 750/20000] Loss: 0.0079913 (Best: 0.0069526 @iter748) ([92m↓4.91%[0m) [3.17% of initial]
[Iter 760/20000] Loss: 0.0073852 (Best: 0.0069211 @iter751) ([92m↓7.59%[0m) [2.93% of initial]
[Iter 770/20000] Loss: 0.0078397 (Best: 0.0069211 @iter751) ([91m↑6.16%[0m) [3.11% of initial]
[Iter 780/20000] Loss: 0.0079407 (Best: 0.0069211 @iter751) ([91m↑1.29%[0m) [3.15% of initial]
[Iter 790/20000] Loss: 0.0076805 (Best: 0.0066661 @iter787) ([92m↓3.28%[0m) [3.05% of initial]
Iter:799, L1 loss=0.00507, Total loss=0.008163, Time:35
[Iter 800/20000] Loss: 0.0074534 (Best: 0.0066661 @iter787) ([92m↓2.96%[0m) [2.96% of initial]
[Iter 810/20000] Loss: 0.0152243 (Best: 0.0066661 @iter787) ([91m↑104.26%[0m) [6.05% of initial]
[Iter 820/20000] Loss: 0.0107607 (Best: 0.0066661 @iter787) ([92m↓29.32%[0m) [4.28% of initial]
[Iter 830/20000] Loss: 0.0088814 (Best: 0.0066661 @iter787) ([92m↓17.46%[0m) [3.53% of initial]
[Iter 840/20000] Loss: 0.0081368 (Best: 0.0066661 @iter787) ([92m↓8.38%[0m) [3.23% of initial]
[Iter 850/20000] Loss: 0.0074592 (Best: 0.0066661 @iter787) ([92m↓8.33%[0m) [2.96% of initial]
[Iter 860/20000] Loss: 0.0070425 (Best: 0.0063040 @iter859) ([92m↓5.59%[0m) [2.80% of initial]
[Iter 870/20000] Loss: 0.0067074 (Best: 0.0061018 @iter862) ([92m↓4.76%[0m) [2.66% of initial]
[Iter 880/20000] Loss: 0.0066818 (Best: 0.0060128 @iter875) ([92m↓0.38%[0m) [2.65% of initial]
[Iter 890/20000] Loss: 0.0062968 (Best: 0.0057141 @iter884) ([92m↓5.76%[0m) [2.50% of initial]
Iter:899, L1 loss=0.003643, Total loss=0.005644, Time:35
[Iter 900/20000] Loss: 0.0064442 (Best: 0.0056437 @iter899) ([91m↑2.34%[0m) [2.56% of initial]
[Iter 910/20000] Loss: 0.0065477 (Best: 0.0054868 @iter907) ([91m↑1.61%[0m) [2.60% of initial]
[Iter 920/20000] Loss: 0.0059515 (Best: 0.0053957 @iter919) ([92m↓9.11%[0m) [2.36% of initial]
[Iter 930/20000] Loss: 0.0062741 (Best: 0.0053496 @iter928) ([91m↑5.42%[0m) [2.49% of initial]
[Iter 940/20000] Loss: 0.0062854 (Best: 0.0051977 @iter938) ([91m↑0.18%[0m) [2.50% of initial]
[Iter 950/20000] Loss: 0.0058878 (Best: 0.0051977 @iter938) ([92m↓6.32%[0m) [2.34% of initial]
[Iter 960/20000] Loss: 0.0059649 (Best: 0.0051977 @iter938) ([91m↑1.31%[0m) [2.37% of initial]
[Iter 970/20000] Loss: 0.0059426 (Best: 0.0051185 @iter964) ([92m↓0.37%[0m) [2.36% of initial]
[Iter 980/20000] Loss: 0.0060405 (Best: 0.0051185 @iter964) ([91m↑1.65%[0m) [2.40% of initial]
[Iter 990/20000] Loss: 0.0062094 (Best: 0.0051185 @iter964) ([91m↑2.80%[0m) [2.47% of initial]
Iter:999, L1 loss=0.004362, Total loss=0.006859, Time:36
[Iter 1000/20000] Loss: 0.0064105 (Best: 0.0051185 @iter964) ([91m↑3.24%[0m) [2.55% of initial]
Pruning 1065 points (7.7%) from gaussian0 at iteration 1000
Pruning 1026 points (7.4%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0133728 (Best: 0.0051185 @iter964) ([91m↑108.61%[0m) [5.31% of initial]
[Iter 1020/20000] Loss: 0.0095718 (Best: 0.0051185 @iter964) ([92m↓28.42%[0m) [3.80% of initial]
[Iter 1030/20000] Loss: 0.0077816 (Best: 0.0051185 @iter964) ([92m↓18.70%[0m) [3.09% of initial]
[Iter 1040/20000] Loss: 0.0070478 (Best: 0.0051185 @iter964) ([92m↓9.43%[0m) [2.80% of initial]
[Iter 1050/20000] Loss: 0.0067467 (Best: 0.0051185 @iter964) ([92m↓4.27%[0m) [2.68% of initial]
[Iter 1060/20000] Loss: 0.0063785 (Best: 0.0051185 @iter964) ([92m↓5.46%[0m) [2.53% of initial]
[Iter 1070/20000] Loss: 0.0062074 (Best: 0.0051185 @iter964) ([92m↓2.68%[0m) [2.47% of initial]
[Iter 1080/20000] Loss: 0.0059170 (Best: 0.0051185 @iter964) ([92m↓4.68%[0m) [2.35% of initial]
[Iter 1090/20000] Loss: 0.0058937 (Best: 0.0051185 @iter964) ([92m↓0.39%[0m) [2.34% of initial]
Iter:1099, L1 loss=0.003849, Total loss=0.005967, Time:33
[Iter 1100/20000] Loss: 0.0057707 (Best: 0.0051185 @iter964) ([92m↓2.09%[0m) [2.29% of initial]
[Iter 1110/20000] Loss: 0.0056435 (Best: 0.0051185 @iter964) ([92m↓2.21%[0m) [2.24% of initial]
[Iter 1120/20000] Loss: 0.0057695 (Best: 0.0049221 @iter1117) ([91m↑2.23%[0m) [2.29% of initial]
[Iter 1130/20000] Loss: 0.0058191 (Best: 0.0049221 @iter1117) ([91m↑0.86%[0m) [2.31% of initial]
[Iter 1140/20000] Loss: 0.0055997 (Best: 0.0049221 @iter1117) ([92m↓3.77%[0m) [2.22% of initial]
[Iter 1150/20000] Loss: 0.0052077 (Best: 0.0048621 @iter1150) ([92m↓7.00%[0m) [2.07% of initial]
[Iter 1160/20000] Loss: 0.0056177 (Best: 0.0047458 @iter1156) ([91m↑7.87%[0m) [2.23% of initial]
[Iter 1170/20000] Loss: 0.0052240 (Best: 0.0047458 @iter1156) ([92m↓7.01%[0m) [2.08% of initial]
[Iter 1180/20000] Loss: 0.0049853 (Best: 0.0046691 @iter1180) ([92m↓4.57%[0m) [1.98% of initial]
[Iter 1190/20000] Loss: 0.0052911 (Best: 0.0046158 @iter1183) ([91m↑6.13%[0m) [2.10% of initial]
Iter:1199, L1 loss=0.003781, Total loss=0.005471, Time:29
[Iter 1200/20000] Loss: 0.0052041 (Best: 0.0044540 @iter1198) ([92m↓1.64%[0m) [2.07% of initial]
[Iter 1210/20000] Loss: 0.0120021 (Best: 0.0044540 @iter1198) ([91m↑130.63%[0m) [4.77% of initial]
[Iter 1220/20000] Loss: 0.0079924 (Best: 0.0044540 @iter1198) ([92m↓33.41%[0m) [3.18% of initial]
[Iter 1230/20000] Loss: 0.0066666 (Best: 0.0044540 @iter1198) ([92m↓16.59%[0m) [2.65% of initial]
[Iter 1240/20000] Loss: 0.0060283 (Best: 0.0044540 @iter1198) ([92m↓9.57%[0m) [2.39% of initial]
[Iter 1250/20000] Loss: 0.0053172 (Best: 0.0044540 @iter1198) ([92m↓11.80%[0m) [2.11% of initial]
[Iter 1260/20000] Loss: 0.0051439 (Best: 0.0044069 @iter1255) ([92m↓3.26%[0m) [2.04% of initial]
[Iter 1270/20000] Loss: 0.0047211 (Best: 0.0043867 @iter1269) ([92m↓8.22%[0m) [1.88% of initial]
[Iter 1280/20000] Loss: 0.0050724 (Best: 0.0040309 @iter1273) ([91m↑7.44%[0m) [2.02% of initial]
[Iter 1290/20000] Loss: 0.0048673 (Best: 0.0039976 @iter1288) ([92m↓4.04%[0m) [1.93% of initial]
Iter:1299, L1 loss=0.003044, Total loss=0.004199, Time:42
[Iter 1300/20000] Loss: 0.0045488 (Best: 0.0039859 @iter1294) ([92m↓6.54%[0m) [1.81% of initial]
[Iter 1310/20000] Loss: 0.0045804 (Best: 0.0039397 @iter1301) ([91m↑0.70%[0m) [1.82% of initial]
[Iter 1320/20000] Loss: 0.0044444 (Best: 0.0038092 @iter1319) ([92m↓2.97%[0m) [1.77% of initial]
[Iter 1330/20000] Loss: 0.0044087 (Best: 0.0036193 @iter1321) ([92m↓0.80%[0m) [1.75% of initial]
[Iter 1340/20000] Loss: 0.0041446 (Best: 0.0036193 @iter1321) ([92m↓5.99%[0m) [1.65% of initial]
[Iter 1350/20000] Loss: 0.0042068 (Best: 0.0036193 @iter1321) ([91m↑1.50%[0m) [1.67% of initial]
[Iter 1360/20000] Loss: 0.0042386 (Best: 0.0036193 @iter1321) ([91m↑0.76%[0m) [1.68% of initial]
[Iter 1370/20000] Loss: 0.0040856 (Best: 0.0036193 @iter1321) ([92m↓3.61%[0m) [1.62% of initial]
[Iter 1380/20000] Loss: 0.0043048 (Best: 0.0035986 @iter1375) ([91m↑5.37%[0m) [1.71% of initial]
[Iter 1390/20000] Loss: 0.0041424 (Best: 0.0035986 @iter1375) ([92m↓3.77%[0m) [1.65% of initial]
Iter:1399, L1 loss=0.002538, Total loss=0.003391, Time:36
[Iter 1400/20000] Loss: 0.0038671 (Best: 0.0033912 @iter1399) ([92m↓6.64%[0m) [1.54% of initial]
[Iter 1410/20000] Loss: 0.0096106 (Best: 0.0033912 @iter1399) ([91m↑148.52%[0m) [3.82% of initial]
[Iter 1420/20000] Loss: 0.0066151 (Best: 0.0033912 @iter1399) ([92m↓31.17%[0m) [2.63% of initial]
[Iter 1430/20000] Loss: 0.0052681 (Best: 0.0033912 @iter1399) ([92m↓20.36%[0m) [2.09% of initial]
[Iter 1440/20000] Loss: 0.0048069 (Best: 0.0033912 @iter1399) ([92m↓8.76%[0m) [1.91% of initial]
[Iter 1450/20000] Loss: 0.0039627 (Best: 0.0033912 @iter1399) ([92m↓17.56%[0m) [1.57% of initial]
[Iter 1460/20000] Loss: 0.0038646 (Best: 0.0033571 @iter1459) ([92m↓2.48%[0m) [1.54% of initial]
[Iter 1470/20000] Loss: 0.0038049 (Best: 0.0033571 @iter1459) ([92m↓1.54%[0m) [1.51% of initial]
[Iter 1480/20000] Loss: 0.0036252 (Best: 0.0032176 @iter1480) ([92m↓4.72%[0m) [1.44% of initial]
[Iter 1490/20000] Loss: 0.0035800 (Best: 0.0032176 @iter1480) ([92m↓1.25%[0m) [1.42% of initial]
Iter:1499, L1 loss=0.002839, Total loss=0.003734, Time:33
[Iter 1500/20000] Loss: 0.0035474 (Best: 0.0032176 @iter1480) ([92m↓0.91%[0m) [1.41% of initial]
Pruning 760 points (3.1%) from gaussian0 at iteration 1500
Pruning 732 points (3.0%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0049352 (Best: 0.0032176 @iter1480) ([91m↑39.12%[0m) [1.96% of initial]
[Iter 1520/20000] Loss: 0.0041484 (Best: 0.0032176 @iter1480) ([92m↓15.94%[0m) [1.65% of initial]
[Iter 1530/20000] Loss: 0.0038370 (Best: 0.0032176 @iter1480) ([92m↓7.51%[0m) [1.52% of initial]
[Iter 1540/20000] Loss: 0.0036620 (Best: 0.0032176 @iter1480) ([92m↓4.56%[0m) [1.45% of initial]
[Iter 1550/20000] Loss: 0.0033756 (Best: 0.0031121 @iter1543) ([92m↓7.82%[0m) [1.34% of initial]
[Iter 1560/20000] Loss: 0.0035760 (Best: 0.0029486 @iter1558) ([91m↑5.94%[0m) [1.42% of initial]
[Iter 1570/20000] Loss: 0.0031994 (Best: 0.0028878 @iter1569) ([92m↓10.53%[0m) [1.27% of initial]
[Iter 1580/20000] Loss: 0.0032324 (Best: 0.0027685 @iter1573) ([91m↑1.03%[0m) [1.28% of initial]
[Iter 1590/20000] Loss: 0.0031088 (Best: 0.0027685 @iter1573) ([92m↓3.83%[0m) [1.24% of initial]
Iter:1599, L1 loss=0.002921, Total loss=0.003675, Time:34
[Iter 1600/20000] Loss: 0.0033872 (Best: 0.0027226 @iter1591) ([91m↑8.96%[0m) [1.35% of initial]
[Iter 1610/20000] Loss: 0.0094878 (Best: 0.0027226 @iter1591) ([91m↑180.10%[0m) [3.77% of initial]
[Iter 1620/20000] Loss: 0.0063410 (Best: 0.0027226 @iter1591) ([92m↓33.17%[0m) [2.52% of initial]
[Iter 1630/20000] Loss: 0.0046762 (Best: 0.0027226 @iter1591) ([92m↓26.26%[0m) [1.86% of initial]
[Iter 1640/20000] Loss: 0.0041047 (Best: 0.0027226 @iter1591) ([92m↓12.22%[0m) [1.63% of initial]
[Iter 1650/20000] Loss: 0.0037083 (Best: 0.0027226 @iter1591) ([92m↓9.66%[0m) [1.47% of initial]
[Iter 1660/20000] Loss: 0.0032737 (Best: 0.0027226 @iter1591) ([92m↓11.72%[0m) [1.30% of initial]
[Iter 1670/20000] Loss: 0.0031186 (Best: 0.0027167 @iter1669) ([92m↓4.74%[0m) [1.24% of initial]
[Iter 1680/20000] Loss: 0.0031903 (Best: 0.0027167 @iter1669) ([91m↑2.30%[0m) [1.27% of initial]
[Iter 1690/20000] Loss: 0.0032574 (Best: 0.0027167 @iter1669) ([91m↑2.10%[0m) [1.29% of initial]
Iter:1699, L1 loss=0.002647, Total loss=0.003301, Time:40
[Iter 1700/20000] Loss: 0.0029736 (Best: 0.0026370 @iter1700) ([92m↓8.71%[0m) [1.18% of initial]
[Iter 1710/20000] Loss: 0.0032008 (Best: 0.0025906 @iter1705) ([91m↑7.64%[0m) [1.27% of initial]
[Iter 1720/20000] Loss: 0.0027603 (Best: 0.0025764 @iter1720) ([92m↓13.76%[0m) [1.10% of initial]
[Iter 1730/20000] Loss: 0.0028393 (Best: 0.0025220 @iter1726) ([91m↑2.86%[0m) [1.13% of initial]
[Iter 1740/20000] Loss: 0.0027760 (Best: 0.0025188 @iter1738) ([92m↓2.23%[0m) [1.10% of initial]
[Iter 1750/20000] Loss: 0.0025447 (Best: 0.0023072 @iter1750) ([92m↓8.33%[0m) [1.01% of initial]
[Iter 1760/20000] Loss: 0.0027929 (Best: 0.0023072 @iter1750) ([91m↑9.75%[0m) [1.11% of initial]
[Iter 1770/20000] Loss: 0.0026507 (Best: 0.0023072 @iter1750) ([92m↓5.09%[0m) [1.05% of initial]
[Iter 1780/20000] Loss: 0.0027340 (Best: 0.0023072 @iter1750) ([91m↑3.14%[0m) [1.09% of initial]
[Iter 1790/20000] Loss: 0.0024723 (Best: 0.0020832 @iter1789) ([92m↓9.57%[0m) [0.98% of initial]
Iter:1799, L1 loss=0.001887, Total loss=0.00225, Time:43
[Iter 1800/20000] Loss: 0.0024900 (Best: 0.0020832 @iter1789) ([91m↑0.72%[0m) [0.99% of initial]
[Iter 1810/20000] Loss: 0.0082930 (Best: 0.0020832 @iter1789) ([91m↑233.06%[0m) [3.29% of initial]
[Iter 1820/20000] Loss: 0.0049097 (Best: 0.0020832 @iter1789) ([92m↓40.80%[0m) [1.95% of initial]
[Iter 1830/20000] Loss: 0.0042456 (Best: 0.0020832 @iter1789) ([92m↓13.53%[0m) [1.69% of initial]
[Iter 1840/20000] Loss: 0.0030863 (Best: 0.0020832 @iter1789) ([92m↓27.31%[0m) [1.23% of initial]
[Iter 1850/20000] Loss: 0.0029150 (Best: 0.0020832 @iter1789) ([92m↓5.55%[0m) [1.16% of initial]
[Iter 1860/20000] Loss: 0.0026639 (Best: 0.0020832 @iter1789) ([92m↓8.61%[0m) [1.06% of initial]
[Iter 1870/20000] Loss: 0.0024706 (Best: 0.0020832 @iter1789) ([92m↓7.26%[0m) [0.98% of initial]
[Iter 1880/20000] Loss: 0.0023769 (Best: 0.0020832 @iter1789) ([92m↓3.79%[0m) [0.94% of initial]
[Iter 1890/20000] Loss: 0.0021769 (Best: 0.0020348 @iter1890) ([92m↓8.41%[0m) [0.86% of initial]
Iter:1899, L1 loss=0.001876, Total loss=0.002227, Time:43
[Iter 1900/20000] Loss: 0.0022833 (Best: 0.0019069 @iter1891) ([91m↑4.89%[0m) [0.91% of initial]
[Iter 1910/20000] Loss: 0.0022777 (Best: 0.0019069 @iter1891) ([92m↓0.25%[0m) [0.90% of initial]
[Iter 1920/20000] Loss: 0.0023128 (Best: 0.0019069 @iter1891) ([91m↑1.54%[0m) [0.92% of initial]
[Iter 1930/20000] Loss: 0.0019803 (Best: 0.0018119 @iter1930) ([92m↓14.37%[0m) [0.79% of initial]
[Iter 1940/20000] Loss: 0.0020744 (Best: 0.0017630 @iter1939) ([91m↑4.75%[0m) [0.82% of initial]
[Iter 1950/20000] Loss: 0.0022853 (Best: 0.0017630 @iter1939) ([91m↑10.17%[0m) [0.91% of initial]
[Iter 1960/20000] Loss: 0.0020866 (Best: 0.0017630 @iter1939) ([92m↓8.69%[0m) [0.83% of initial]
[Iter 1970/20000] Loss: 0.0019434 (Best: 0.0017630 @iter1939) ([92m↓6.86%[0m) [0.77% of initial]
[Iter 1980/20000] Loss: 0.0022684 (Best: 0.0017630 @iter1939) ([91m↑16.73%[0m) [0.90% of initial]
[Iter 1990/20000] Loss: 0.0020079 (Best: 0.0017630 @iter1939) ([92m↓11.49%[0m) [0.80% of initial]
Iter:1999, L1 loss=0.001669, Total loss=0.001906, Time:43
[Iter 2000/20000] Loss: 0.0021066 (Best: 0.0016499 @iter1996) ([91m↑4.92%[0m) [0.84% of initial]
Testing Speed: 99.85653508176739 fps
Testing Time: 0.500718355178833 s

[ITER 2000] Evaluating test: SSIM = 0.8669557511806488, PSNR = 17.7071270942688
Testing Speed: 96.18492585231616 fps
Testing Time: 0.031189918518066406 s

[ITER 2000] Evaluating train: SSIM = 0.9999516606330872, PSNR = 48.691043853759766
Iter:2000, total_points:42968
Pruning 664 points (1.2%) from gaussian0 at iteration 2000
Pruning 714 points (1.3%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.2052622 (Best: 0.0016499 @iter1996) ([91m↑9643.60%[0m) [81.55% of initial]
[Iter 2020/20000] Loss: 0.1572146 (Best: 0.0016499 @iter1996) ([92m↓23.41%[0m) [62.46% of initial]
[Iter 2030/20000] Loss: 0.1083710 (Best: 0.0016499 @iter1996) ([92m↓31.07%[0m) [43.05% of initial]
[Iter 2040/20000] Loss: 0.0715854 (Best: 0.0016499 @iter1996) ([92m↓33.94%[0m) [28.44% of initial]
[Iter 2050/20000] Loss: 0.0416306 (Best: 0.0016499 @iter1996) ([92m↓41.84%[0m) [16.54% of initial]
[Iter 2060/20000] Loss: 0.0206738 (Best: 0.0016499 @iter1996) ([92m↓50.34%[0m) [8.21% of initial]
[Iter 2070/20000] Loss: 0.0128815 (Best: 0.0016499 @iter1996) ([92m↓37.69%[0m) [5.12% of initial]
[Iter 2080/20000] Loss: 0.0078579 (Best: 0.0016499 @iter1996) ([92m↓39.00%[0m) [3.12% of initial]
[Iter 2090/20000] Loss: 0.0061557 (Best: 0.0016499 @iter1996) ([92m↓21.66%[0m) [2.45% of initial]
Iter:2099, L1 loss=0.003806, Total loss=0.004619, Time:46
[Iter 2100/20000] Loss: 0.0049827 (Best: 0.0016499 @iter1996) ([92m↓19.06%[0m) [1.98% of initial]
[Iter 2110/20000] Loss: 0.0042787 (Best: 0.0016499 @iter1996) ([92m↓14.13%[0m) [1.70% of initial]
[Iter 2120/20000] Loss: 0.0037034 (Best: 0.0016499 @iter1996) ([92m↓13.45%[0m) [1.47% of initial]
[Iter 2130/20000] Loss: 0.0036418 (Best: 0.0016499 @iter1996) ([92m↓1.66%[0m) [1.45% of initial]
[Iter 2140/20000] Loss: 0.0034842 (Best: 0.0016499 @iter1996) ([92m↓4.33%[0m) [1.38% of initial]
[Iter 2150/20000] Loss: 0.0031900 (Best: 0.0016499 @iter1996) ([92m↓8.44%[0m) [1.27% of initial]
[Iter 2160/20000] Loss: 0.0030479 (Best: 0.0016499 @iter1996) ([92m↓4.46%[0m) [1.21% of initial]
[Iter 2170/20000] Loss: 0.0030648 (Best: 0.0016499 @iter1996) ([91m↑0.55%[0m) [1.22% of initial]
[Iter 2180/20000] Loss: 0.0026630 (Best: 0.0016499 @iter1996) ([92m↓13.11%[0m) [1.06% of initial]
[Iter 2190/20000] Loss: 0.0028229 (Best: 0.0016499 @iter1996) ([91m↑6.00%[0m) [1.12% of initial]
Iter:2199, L1 loss=0.00216, Total loss=0.002671, Time:43
[Iter 2200/20000] Loss: 0.0027994 (Best: 0.0016499 @iter1996) ([92m↓0.83%[0m) [1.11% of initial]
[Iter 2210/20000] Loss: 0.0079089 (Best: 0.0016499 @iter1996) ([91m↑182.52%[0m) [3.14% of initial]
[Iter 2220/20000] Loss: 0.0048813 (Best: 0.0016499 @iter1996) ([92m↓38.28%[0m) [1.94% of initial]
[Iter 2230/20000] Loss: 0.0034554 (Best: 0.0016499 @iter1996) ([92m↓29.21%[0m) [1.37% of initial]
[Iter 2240/20000] Loss: 0.0030807 (Best: 0.0016499 @iter1996) ([92m↓10.84%[0m) [1.22% of initial]
[Iter 2250/20000] Loss: 0.0027904 (Best: 0.0016499 @iter1996) ([92m↓9.42%[0m) [1.11% of initial]
[Iter 2260/20000] Loss: 0.0024449 (Best: 0.0016499 @iter1996) ([92m↓12.38%[0m) [0.97% of initial]
[Iter 2270/20000] Loss: 0.0025544 (Best: 0.0016499 @iter1996) ([91m↑4.48%[0m) [1.01% of initial]
[Iter 2280/20000] Loss: 0.0021948 (Best: 0.0016499 @iter1996) ([92m↓14.08%[0m) [0.87% of initial]
[Iter 2290/20000] Loss: 0.0021841 (Best: 0.0016499 @iter1996) ([92m↓0.49%[0m) [0.87% of initial]
Iter:2299, L1 loss=0.001759, Total loss=0.0021, Time:60
[Iter 2300/20000] Loss: 0.0023453 (Best: 0.0016499 @iter1996) ([91m↑7.38%[0m) [0.93% of initial]
[Iter 2310/20000] Loss: 0.0021808 (Best: 0.0016499 @iter1996) ([92m↓7.01%[0m) [0.87% of initial]
[Iter 2320/20000] Loss: 0.0019314 (Best: 0.0016499 @iter1996) ([92m↓11.44%[0m) [0.77% of initial]
[Iter 2330/20000] Loss: 0.0019233 (Best: 0.0016499 @iter1996) ([92m↓0.42%[0m) [0.76% of initial]
[Iter 2340/20000] Loss: 0.0020078 (Best: 0.0016499 @iter1996) ([91m↑4.39%[0m) [0.80% of initial]
[Iter 2350/20000] Loss: 0.0019537 (Best: 0.0016499 @iter1996) ([92m↓2.69%[0m) [0.78% of initial]
[Iter 2360/20000] Loss: 0.0018485 (Best: 0.0016499 @iter1996) ([92m↓5.38%[0m) [0.73% of initial]
[Iter 2370/20000] Loss: 0.0018974 (Best: 0.0016499 @iter1996) ([91m↑2.64%[0m) [0.75% of initial]
[Iter 2380/20000] Loss: 0.0019730 (Best: 0.0016499 @iter1996) ([91m↑3.98%[0m) [0.78% of initial]
[Iter 2390/20000] Loss: 0.0019825 (Best: 0.0016499 @iter1996) ([91m↑0.48%[0m) [0.79% of initial]
Iter:2399, L1 loss=0.001546, Total loss=0.001739, Time:50
[Iter 2400/20000] Loss: 0.0017995 (Best: 0.0016499 @iter1996) ([92m↓9.23%[0m) [0.71% of initial]
[Iter 2410/20000] Loss: 0.0050832 (Best: 0.0016499 @iter1996) ([91m↑182.48%[0m) [2.02% of initial]
[Iter 2420/20000] Loss: 0.0034705 (Best: 0.0016499 @iter1996) ([92m↓31.73%[0m) [1.38% of initial]
[Iter 2430/20000] Loss: 0.0027151 (Best: 0.0016499 @iter1996) ([92m↓21.77%[0m) [1.08% of initial]
[Iter 2440/20000] Loss: 0.0023485 (Best: 0.0016499 @iter1996) ([92m↓13.50%[0m) [0.93% of initial]
[Iter 2450/20000] Loss: 0.0022335 (Best: 0.0016499 @iter1996) ([92m↓4.90%[0m) [0.89% of initial]
[Iter 2460/20000] Loss: 0.0020505 (Best: 0.0016499 @iter1996) ([92m↓8.19%[0m) [0.81% of initial]
[Iter 2470/20000] Loss: 0.0020477 (Best: 0.0016459 @iter2464) ([92m↓0.14%[0m) [0.81% of initial]
[Iter 2480/20000] Loss: 0.0019604 (Best: 0.0016459 @iter2464) ([92m↓4.26%[0m) [0.78% of initial]
[Iter 2490/20000] Loss: 0.0017963 (Best: 0.0016038 @iter2489) ([92m↓8.37%[0m) [0.71% of initial]
Iter:2499, L1 loss=0.001559, Total loss=0.001628, Time:59
[Iter 2500/20000] Loss: 0.0017030 (Best: 0.0016038 @iter2489) ([92m↓5.20%[0m) [0.68% of initial]
Pruning 455 points (0.7%) from gaussian0 at iteration 2500
Pruning 487 points (0.7%) from gaussian1 at iteration 2500
[Iter 2510/20000] Loss: 0.0029518 (Best: 0.0016038 @iter2489) ([91m↑73.33%[0m) [1.17% of initial]
[Iter 2520/20000] Loss: 0.0022005 (Best: 0.0016038 @iter2489) ([92m↓25.45%[0m) [0.87% of initial]
[Iter 2530/20000] Loss: 0.0018129 (Best: 0.0016038 @iter2489) ([92m↓17.62%[0m) [0.72% of initial]
[Iter 2540/20000] Loss: 0.0017477 (Best: 0.0015870 @iter2533) ([92m↓3.60%[0m) [0.69% of initial]
[Iter 2550/20000] Loss: 0.0017842 (Best: 0.0014748 @iter2548) ([91m↑2.09%[0m) [0.71% of initial]
[Iter 2560/20000] Loss: 0.0016332 (Best: 0.0014554 @iter2558) ([92m↓8.46%[0m) [0.65% of initial]
[Iter 2570/20000] Loss: 0.0018181 (Best: 0.0014554 @iter2558) ([91m↑11.32%[0m) [0.72% of initial]
[Iter 2580/20000] Loss: 0.0016726 (Best: 0.0013832 @iter2578) ([92m↓8.00%[0m) [0.66% of initial]
[Iter 2590/20000] Loss: 0.0016874 (Best: 0.0013832 @iter2578) ([91m↑0.89%[0m) [0.67% of initial]
Iter:2599, L1 loss=0.001351, Total loss=0.001415, Time:53
[Iter 2600/20000] Loss: 0.0016167 (Best: 0.0013832 @iter2578) ([92m↓4.19%[0m) [0.64% of initial]
[Iter 2610/20000] Loss: 0.0047641 (Best: 0.0013832 @iter2578) ([91m↑194.67%[0m) [1.89% of initial]
[Iter 2620/20000] Loss: 0.0033394 (Best: 0.0013832 @iter2578) ([92m↓29.90%[0m) [1.33% of initial]
[Iter 2630/20000] Loss: 0.0023534 (Best: 0.0013832 @iter2578) ([92m↓29.53%[0m) [0.93% of initial]
[Iter 2640/20000] Loss: 0.0020152 (Best: 0.0013832 @iter2578) ([92m↓14.37%[0m) [0.80% of initial]
[Iter 2650/20000] Loss: 0.0017338 (Best: 0.0013832 @iter2578) ([92m↓13.96%[0m) [0.69% of initial]
[Iter 2660/20000] Loss: 0.0018302 (Best: 0.0013832 @iter2578) ([91m↑5.56%[0m) [0.73% of initial]
[Iter 2670/20000] Loss: 0.0017604 (Best: 0.0013832 @iter2578) ([92m↓3.82%[0m) [0.70% of initial]
[Iter 2680/20000] Loss: 0.0015001 (Best: 0.0013554 @iter2677) ([92m↓14.78%[0m) [0.60% of initial]
[Iter 2690/20000] Loss: 0.0014687 (Best: 0.0013192 @iter2686) ([92m↓2.10%[0m) [0.58% of initial]
Iter:2699, L1 loss=0.001383, Total loss=0.001439, Time:56
[Iter 2700/20000] Loss: 0.0016635 (Best: 0.0013192 @iter2686) ([91m↑13.26%[0m) [0.66% of initial]
[Iter 2710/20000] Loss: 0.0014675 (Best: 0.0013192 @iter2686) ([92m↓11.78%[0m) [0.58% of initial]
[Iter 2720/20000] Loss: 0.0013923 (Best: 0.0012544 @iter2715) ([92m↓5.12%[0m) [0.55% of initial]
[Iter 2730/20000] Loss: 0.0013023 (Best: 0.0011649 @iter2725) ([92m↓6.46%[0m) [0.52% of initial]
[Iter 2740/20000] Loss: 0.0011907 (Best: 0.0011181 @iter2740) ([92m↓8.57%[0m) [0.47% of initial]
[Iter 2750/20000] Loss: 0.0013850 (Best: 0.0011181 @iter2740) ([91m↑16.32%[0m) [0.55% of initial]
[Iter 2760/20000] Loss: 0.0014828 (Best: 0.0011181 @iter2740) ([91m↑7.06%[0m) [0.59% of initial]
[Iter 2770/20000] Loss: 0.0015007 (Best: 0.0011181 @iter2740) ([91m↑1.21%[0m) [0.60% of initial]
[Iter 2780/20000] Loss: 0.0013663 (Best: 0.0011181 @iter2740) ([92m↓8.96%[0m) [0.54% of initial]
[Iter 2790/20000] Loss: 0.0014240 (Best: 0.0011181 @iter2740) ([91m↑4.22%[0m) [0.57% of initial]
Iter:2799, L1 loss=0.001436, Total loss=0.001478, Time:61
[Iter 2800/20000] Loss: 0.0013901 (Best: 0.0011181 @iter2740) ([92m↓2.38%[0m) [0.55% of initial]
[Iter 2810/20000] Loss: 0.0044075 (Best: 0.0011181 @iter2740) ([91m↑217.07%[0m) [1.75% of initial]
[Iter 2820/20000] Loss: 0.0029026 (Best: 0.0011181 @iter2740) ([92m↓34.14%[0m) [1.15% of initial]
[Iter 2830/20000] Loss: 0.0020340 (Best: 0.0011181 @iter2740) ([92m↓29.93%[0m) [0.81% of initial]
[Iter 2840/20000] Loss: 0.0017368 (Best: 0.0011181 @iter2740) ([92m↓14.61%[0m) [0.69% of initial]
[Iter 2850/20000] Loss: 0.0015753 (Best: 0.0011181 @iter2740) ([92m↓9.30%[0m) [0.63% of initial]
[Iter 2860/20000] Loss: 0.0015822 (Best: 0.0011181 @iter2740) ([91m↑0.44%[0m) [0.63% of initial]
[Iter 2870/20000] Loss: 0.0014554 (Best: 0.0011181 @iter2740) ([92m↓8.02%[0m) [0.58% of initial]
[Iter 2880/20000] Loss: 0.0014093 (Best: 0.0011181 @iter2740) ([92m↓3.16%[0m) [0.56% of initial]
[Iter 2890/20000] Loss: 0.0013151 (Best: 0.0011181 @iter2740) ([92m↓6.69%[0m) [0.52% of initial]
Iter:2899, L1 loss=0.001152, Total loss=0.00114, Time:69
[Iter 2900/20000] Loss: 0.0012783 (Best: 0.0011181 @iter2740) ([92m↓2.80%[0m) [0.51% of initial]
[Iter 2910/20000] Loss: 0.0013785 (Best: 0.0011181 @iter2740) ([91m↑7.84%[0m) [0.55% of initial]
[Iter 2920/20000] Loss: 0.0014110 (Best: 0.0011181 @iter2740) ([91m↑2.36%[0m) [0.56% of initial]
[Iter 2930/20000] Loss: 0.0013353 (Best: 0.0011181 @iter2740) ([92m↓5.36%[0m) [0.53% of initial]
[Iter 2940/20000] Loss: 0.0012364 (Best: 0.0010872 @iter2932) ([92m↓7.41%[0m) [0.49% of initial]
[Iter 2950/20000] Loss: 0.0011700 (Best: 0.0010691 @iter2950) ([92m↓5.37%[0m) [0.46% of initial]
[Iter 2960/20000] Loss: 0.0012533 (Best: 0.0010691 @iter2950) ([91m↑7.12%[0m) [0.50% of initial]
[Iter 2970/20000] Loss: 0.0011549 (Best: 0.0009975 @iter2969) ([92m↓7.85%[0m) [0.46% of initial]
[Iter 2980/20000] Loss: 0.0010879 (Best: 0.0009975 @iter2969) ([92m↓5.80%[0m) [0.43% of initial]
[Iter 2990/20000] Loss: 0.0011037 (Best: 0.0009631 @iter2983) ([91m↑1.45%[0m) [0.44% of initial]
Iter:2999, L1 loss=0.000968, Total loss=0.0009445, Time:67
[Iter 3000/20000] Loss: 0.0010955 (Best: 0.0009445 @iter2999) ([92m↓0.74%[0m) [0.44% of initial]
Pruning 294 points (0.4%) from gaussian0 at iteration 3000
Pruning 280 points (0.3%) from gaussian1 at iteration 3000
[Iter 3010/20000] Loss: 0.0040916 (Best: 0.0009445 @iter2999) ([91m↑273.49%[0m) [1.63% of initial]
[Iter 3020/20000] Loss: 0.0028465 (Best: 0.0009445 @iter2999) ([92m↓30.43%[0m) [1.13% of initial]
[Iter 3030/20000] Loss: 0.0020926 (Best: 0.0009445 @iter2999) ([92m↓26.49%[0m) [0.83% of initial]
[Iter 3040/20000] Loss: 0.0016676 (Best: 0.0009445 @iter2999) ([92m↓20.31%[0m) [0.66% of initial]
[Iter 3050/20000] Loss: 0.0015799 (Best: 0.0009445 @iter2999) ([92m↓5.26%[0m) [0.63% of initial]
[Iter 3060/20000] Loss: 0.0014835 (Best: 0.0009445 @iter2999) ([92m↓6.10%[0m) [0.59% of initial]
[Iter 3070/20000] Loss: 0.0013430 (Best: 0.0009445 @iter2999) ([92m↓9.47%[0m) [0.53% of initial]
[Iter 3080/20000] Loss: 0.0013414 (Best: 0.0009445 @iter2999) ([92m↓0.12%[0m) [0.53% of initial]
[Iter 3090/20000] Loss: 0.0013063 (Best: 0.0009445 @iter2999) ([92m↓2.62%[0m) [0.52% of initial]
Iter:3099, L1 loss=0.00121, Total loss=0.001179, Time:67
[Iter 3100/20000] Loss: 0.0012287 (Best: 0.0009445 @iter2999) ([92m↓5.94%[0m) [0.49% of initial]
[Iter 3110/20000] Loss: 0.0013036 (Best: 0.0009445 @iter2999) ([91m↑6.10%[0m) [0.52% of initial]
[Iter 3120/20000] Loss: 0.0012761 (Best: 0.0009445 @iter2999) ([92m↓2.11%[0m) [0.51% of initial]
[Iter 3130/20000] Loss: 0.0011522 (Best: 0.0009445 @iter2999) ([92m↓9.71%[0m) [0.46% of initial]
[Iter 3140/20000] Loss: 0.0011300 (Best: 0.0009445 @iter2999) ([92m↓1.93%[0m) [0.45% of initial]
[Iter 3150/20000] Loss: 0.0011577 (Best: 0.0009445 @iter2999) ([91m↑2.45%[0m) [0.46% of initial]
[Iter 3160/20000] Loss: 0.0011135 (Best: 0.0009445 @iter2999) ([92m↓3.82%[0m) [0.44% of initial]
[Iter 3170/20000] Loss: 0.0011046 (Best: 0.0009445 @iter2999) ([92m↓0.80%[0m) [0.44% of initial]
[Iter 3180/20000] Loss: 0.0012005 (Best: 0.0009445 @iter2999) ([91m↑8.68%[0m) [0.48% of initial]
[Iter 3190/20000] Loss: 0.0011513 (Best: 0.0009445 @iter2999) ([92m↓4.10%[0m) [0.46% of initial]
Iter:3199, L1 loss=0.001096, Total loss=0.001062, Time:55
[Iter 3200/20000] Loss: 0.0010924 (Best: 0.0009445 @iter2999) ([92m↓5.11%[0m) [0.43% of initial]
[Iter 3210/20000] Loss: 0.0038672 (Best: 0.0009445 @iter2999) ([91m↑254.01%[0m) [1.54% of initial]
[Iter 3220/20000] Loss: 0.0026233 (Best: 0.0009445 @iter2999) ([92m↓32.16%[0m) [1.04% of initial]
[Iter 3230/20000] Loss: 0.0018338 (Best: 0.0009445 @iter2999) ([92m↓30.10%[0m) [0.73% of initial]
[Iter 3240/20000] Loss: 0.0017110 (Best: 0.0009445 @iter2999) ([92m↓6.70%[0m) [0.68% of initial]
[Iter 3250/20000] Loss: 0.0013663 (Best: 0.0009445 @iter2999) ([92m↓20.14%[0m) [0.54% of initial]
[Iter 3260/20000] Loss: 0.0012533 (Best: 0.0009445 @iter2999) ([92m↓8.27%[0m) [0.50% of initial]
[Iter 3270/20000] Loss: 0.0012254 (Best: 0.0009445 @iter2999) ([92m↓2.22%[0m) [0.49% of initial]
[Iter 3280/20000] Loss: 0.0012541 (Best: 0.0009445 @iter2999) ([91m↑2.34%[0m) [0.50% of initial]
[Iter 3290/20000] Loss: 0.0010664 (Best: 0.0009445 @iter2999) ([92m↓14.97%[0m) [0.42% of initial]
Iter:3299, L1 loss=0.00143, Total loss=0.001492, Time:60
[Iter 3300/20000] Loss: 0.0013047 (Best: 0.0009445 @iter2999) ([91m↑22.35%[0m) [0.52% of initial]
[Iter 3310/20000] Loss: 0.0010550 (Best: 0.0009445 @iter2999) ([92m↓19.14%[0m) [0.42% of initial]
[Iter 3320/20000] Loss: 0.0011408 (Best: 0.0009445 @iter2999) ([91m↑8.13%[0m) [0.45% of initial]
[Iter 3330/20000] Loss: 0.0012055 (Best: 0.0009445 @iter2999) ([91m↑5.67%[0m) [0.48% of initial]
[Iter 3340/20000] Loss: 0.0012489 (Best: 0.0009445 @iter2999) ([91m↑3.60%[0m) [0.50% of initial]
[Iter 3350/20000] Loss: 0.0011252 (Best: 0.0009445 @iter2999) ([92m↓9.91%[0m) [0.45% of initial]
[Iter 3360/20000] Loss: 0.0012984 (Best: 0.0009445 @iter2999) ([91m↑15.40%[0m) [0.52% of initial]
[Iter 3370/20000] Loss: 0.0010493 (Best: 0.0009445 @iter2999) ([92m↓19.18%[0m) [0.42% of initial]
[Iter 3380/20000] Loss: 0.0010029 (Best: 0.0009238 @iter3379) ([92m↓4.43%[0m) [0.40% of initial]
[Iter 3390/20000] Loss: 0.0012388 (Best: 0.0009238 @iter3379) ([91m↑23.53%[0m) [0.49% of initial]
Iter:3399, L1 loss=0.001322, Total loss=0.001341, Time:68
[Iter 3400/20000] Loss: 0.0012485 (Best: 0.0009238 @iter3379) ([91m↑0.78%[0m) [0.50% of initial]
[Iter 3410/20000] Loss: 0.0033795 (Best: 0.0009238 @iter3379) ([91m↑170.69%[0m) [1.34% of initial]
[Iter 3420/20000] Loss: 0.0021517 (Best: 0.0009238 @iter3379) ([92m↓36.33%[0m) [0.85% of initial]
[Iter 3430/20000] Loss: 0.0014794 (Best: 0.0009238 @iter3379) ([92m↓31.25%[0m) [0.59% of initial]
[Iter 3440/20000] Loss: 0.0014329 (Best: 0.0009238 @iter3379) ([92m↓3.14%[0m) [0.57% of initial]
[Iter 3450/20000] Loss: 0.0013269 (Best: 0.0009238 @iter3379) ([92m↓7.40%[0m) [0.53% of initial]
[Iter 3460/20000] Loss: 0.0012277 (Best: 0.0009238 @iter3379) ([92m↓7.48%[0m) [0.49% of initial]
[Iter 3470/20000] Loss: 0.0012052 (Best: 0.0009238 @iter3379) ([92m↓1.83%[0m) [0.48% of initial]
[Iter 3480/20000] Loss: 0.0011442 (Best: 0.0009238 @iter3379) ([92m↓5.06%[0m) [0.45% of initial]
[Iter 3490/20000] Loss: 0.0010917 (Best: 0.0009141 @iter3487) ([92m↓4.58%[0m) [0.43% of initial]
Iter:3499, L1 loss=0.0008838, Total loss=0.0008491, Time:65
[Iter 3500/20000] Loss: 0.0009192 (Best: 0.0008491 @iter3499) ([92m↓15.80%[0m) [0.37% of initial]
Pruning 202 points (0.2%) from gaussian0 at iteration 3500
Pruning 217 points (0.2%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0020241 (Best: 0.0008491 @iter3499) ([91m↑120.20%[0m) [0.80% of initial]
[Iter 3520/20000] Loss: 0.0014488 (Best: 0.0008491 @iter3499) ([92m↓28.42%[0m) [0.58% of initial]
[Iter 3530/20000] Loss: 0.0011962 (Best: 0.0008491 @iter3499) ([92m↓17.43%[0m) [0.48% of initial]
[Iter 3540/20000] Loss: 0.0012884 (Best: 0.0008491 @iter3499) ([91m↑7.70%[0m) [0.51% of initial]
[Iter 3550/20000] Loss: 0.0011903 (Best: 0.0008491 @iter3499) ([92m↓7.61%[0m) [0.47% of initial]
[Iter 3560/20000] Loss: 0.0010863 (Best: 0.0008491 @iter3499) ([92m↓8.74%[0m) [0.43% of initial]
[Iter 3570/20000] Loss: 0.0011577 (Best: 0.0008491 @iter3499) ([91m↑6.57%[0m) [0.46% of initial]
[Iter 3580/20000] Loss: 0.0009526 (Best: 0.0008491 @iter3499) ([92m↓17.72%[0m) [0.38% of initial]
[Iter 3590/20000] Loss: 0.0009575 (Best: 0.0008491 @iter3499) ([91m↑0.52%[0m) [0.38% of initial]
Iter:3599, L1 loss=0.000907, Total loss=0.0008648, Time:66
[Iter 3600/20000] Loss: 0.0009364 (Best: 0.0008264 @iter3598) ([92m↓2.21%[0m) [0.37% of initial]
[Iter 3610/20000] Loss: 0.0035620 (Best: 0.0008264 @iter3598) ([91m↑280.40%[0m) [1.42% of initial]
[Iter 3620/20000] Loss: 0.0025233 (Best: 0.0008264 @iter3598) ([92m↓29.16%[0m) [1.00% of initial]
[Iter 3630/20000] Loss: 0.0016125 (Best: 0.0008264 @iter3598) ([92m↓36.10%[0m) [0.64% of initial]
[Iter 3640/20000] Loss: 0.0012789 (Best: 0.0008264 @iter3598) ([92m↓20.69%[0m) [0.51% of initial]
[Iter 3650/20000] Loss: 0.0012724 (Best: 0.0008264 @iter3598) ([92m↓0.51%[0m) [0.51% of initial]
[Iter 3660/20000] Loss: 0.0011176 (Best: 0.0008264 @iter3598) ([92m↓12.16%[0m) [0.44% of initial]
[Iter 3670/20000] Loss: 0.0009972 (Best: 0.0008264 @iter3598) ([92m↓10.77%[0m) [0.40% of initial]
[Iter 3680/20000] Loss: 0.0011029 (Best: 0.0008264 @iter3598) ([91m↑10.59%[0m) [0.44% of initial]
[Iter 3690/20000] Loss: 0.0012684 (Best: 0.0008264 @iter3598) ([91m↑15.01%[0m) [0.50% of initial]
Iter:3699, L1 loss=0.001134, Total loss=0.001121, Time:68
[Iter 3700/20000] Loss: 0.0011394 (Best: 0.0008264 @iter3598) ([92m↓10.17%[0m) [0.45% of initial]
[Iter 3710/20000] Loss: 0.0009797 (Best: 0.0008264 @iter3598) ([92m↓14.02%[0m) [0.39% of initial]
[Iter 3720/20000] Loss: 0.0010753 (Best: 0.0008017 @iter3712) ([91m↑9.76%[0m) [0.43% of initial]
[Iter 3730/20000] Loss: 0.0009218 (Best: 0.0008017 @iter3712) ([92m↓14.28%[0m) [0.37% of initial]
[Iter 3740/20000] Loss: 0.0009471 (Best: 0.0008017 @iter3712) ([91m↑2.74%[0m) [0.38% of initial]
[Iter 3750/20000] Loss: 0.0009942 (Best: 0.0008017 @iter3712) ([91m↑4.97%[0m) [0.39% of initial]
[Iter 3760/20000] Loss: 0.0009463 (Best: 0.0008017 @iter3712) ([92m↓4.82%[0m) [0.38% of initial]
[Iter 3770/20000] Loss: 0.0009621 (Best: 0.0008017 @iter3712) ([91m↑1.67%[0m) [0.38% of initial]
[Iter 3780/20000] Loss: 0.0009364 (Best: 0.0007667 @iter3775) ([92m↓2.67%[0m) [0.37% of initial]
[Iter 3790/20000] Loss: 0.0008047 (Best: 0.0007441 @iter3787) ([92m↓14.07%[0m) [0.32% of initial]
Iter:3799, L1 loss=0.0009854, Total loss=0.0009054, Time:68
[Iter 3800/20000] Loss: 0.0008938 (Best: 0.0007441 @iter3787) ([91m↑11.08%[0m) [0.36% of initial]
[Iter 3810/20000] Loss: 0.0031767 (Best: 0.0007441 @iter3787) ([91m↑255.40%[0m) [1.26% of initial]
[Iter 3820/20000] Loss: 0.0020031 (Best: 0.0007441 @iter3787) ([92m↓36.94%[0m) [0.80% of initial]
[Iter 3830/20000] Loss: 0.0013735 (Best: 0.0007441 @iter3787) ([92m↓31.43%[0m) [0.55% of initial]
[Iter 3840/20000] Loss: 0.0014614 (Best: 0.0007441 @iter3787) ([91m↑6.40%[0m) [0.58% of initial]
[Iter 3850/20000] Loss: 0.0011506 (Best: 0.0007441 @iter3787) ([92m↓21.27%[0m) [0.46% of initial]
[Iter 3860/20000] Loss: 0.0010955 (Best: 0.0007441 @iter3787) ([92m↓4.78%[0m) [0.44% of initial]
[Iter 3870/20000] Loss: 0.0009317 (Best: 0.0007441 @iter3787) ([92m↓14.96%[0m) [0.37% of initial]
[Iter 3880/20000] Loss: 0.0009738 (Best: 0.0007441 @iter3787) ([91m↑4.52%[0m) [0.39% of initial]
[Iter 3890/20000] Loss: 0.0008567 (Best: 0.0007441 @iter3787) ([92m↓12.03%[0m) [0.34% of initial]
Iter:3899, L1 loss=0.0009392, Total loss=0.0009164, Time:63
[Iter 3900/20000] Loss: 0.0008444 (Best: 0.0007177 @iter3898) ([92m↓1.44%[0m) [0.34% of initial]
[Iter 3910/20000] Loss: 0.0009548 (Best: 0.0007177 @iter3898) ([91m↑13.07%[0m) [0.38% of initial]
[Iter 3920/20000] Loss: 0.0009499 (Best: 0.0007177 @iter3898) ([92m↓0.51%[0m) [0.38% of initial]
[Iter 3930/20000] Loss: 0.0009436 (Best: 0.0007177 @iter3898) ([92m↓0.66%[0m) [0.37% of initial]
[Iter 3940/20000] Loss: 0.0008567 (Best: 0.0007177 @iter3898) ([92m↓9.21%[0m) [0.34% of initial]
[Iter 3950/20000] Loss: 0.0008862 (Best: 0.0007177 @iter3898) ([91m↑3.45%[0m) [0.35% of initial]
[Iter 3960/20000] Loss: 0.0009232 (Best: 0.0007177 @iter3898) ([91m↑4.17%[0m) [0.37% of initial]
[Iter 3970/20000] Loss: 0.0008973 (Best: 0.0007177 @iter3898) ([92m↓2.81%[0m) [0.36% of initial]
[Iter 3980/20000] Loss: 0.0011360 (Best: 0.0007177 @iter3898) ([91m↑26.61%[0m) [0.45% of initial]
[Iter 3990/20000] Loss: 0.0009115 (Best: 0.0007177 @iter3898) ([92m↓19.76%[0m) [0.36% of initial]
Iter:3999, L1 loss=0.0009487, Total loss=0.0008932, Time:74
[Iter 4000/20000] Loss: 0.0008657 (Best: 0.0007177 @iter3898) ([92m↓5.02%[0m) [0.34% of initial]
Pruning 195 points (0.2%) from gaussian0 at iteration 4000
Pruning 177 points (0.2%) from gaussian1 at iteration 4000
[Iter 4010/20000] Loss: 0.0034584 (Best: 0.0007177 @iter3898) ([91m↑299.48%[0m) [1.37% of initial]
[Iter 4020/20000] Loss: 0.0022445 (Best: 0.0007177 @iter3898) ([92m↓35.10%[0m) [0.89% of initial]
[Iter 4030/20000] Loss: 0.0014091 (Best: 0.0007177 @iter3898) ([92m↓37.22%[0m) [0.56% of initial]
[Iter 4040/20000] Loss: 0.0011433 (Best: 0.0007177 @iter3898) ([92m↓18.86%[0m) [0.45% of initial]
[Iter 4050/20000] Loss: 0.0010371 (Best: 0.0007177 @iter3898) ([92m↓9.29%[0m) [0.41% of initial]
[Iter 4060/20000] Loss: 0.0009751 (Best: 0.0007177 @iter3898) ([92m↓5.98%[0m) [0.39% of initial]
[Iter 4070/20000] Loss: 0.0008606 (Best: 0.0007177 @iter3898) ([92m↓11.74%[0m) [0.34% of initial]
[Iter 4080/20000] Loss: 0.0009421 (Best: 0.0007177 @iter3898) ([91m↑9.46%[0m) [0.37% of initial]
[Iter 4090/20000] Loss: 0.0008208 (Best: 0.0007177 @iter3898) ([92m↓12.87%[0m) [0.33% of initial]
Iter:4099, L1 loss=0.0008803, Total loss=0.0008038, Time:73
[Iter 4100/20000] Loss: 0.0007983 (Best: 0.0007177 @iter3898) ([92m↓2.75%[0m) [0.32% of initial]
[Iter 4110/20000] Loss: 0.0008920 (Best: 0.0007177 @iter3898) ([91m↑11.74%[0m) [0.35% of initial]
[Iter 4120/20000] Loss: 0.0008957 (Best: 0.0007177 @iter3898) ([91m↑0.41%[0m) [0.36% of initial]
[Iter 4130/20000] Loss: 0.0009898 (Best: 0.0007177 @iter3898) ([91m↑10.51%[0m) [0.39% of initial]
[Iter 4140/20000] Loss: 0.0009581 (Best: 0.0007177 @iter3898) ([92m↓3.21%[0m) [0.38% of initial]
[Iter 4150/20000] Loss: 0.0008176 (Best: 0.0007177 @iter3898) ([92m↓14.66%[0m) [0.32% of initial]
[Iter 4160/20000] Loss: 0.0009639 (Best: 0.0006997 @iter4153) ([91m↑17.90%[0m) [0.38% of initial]
[Iter 4170/20000] Loss: 0.0008510 (Best: 0.0006997 @iter4153) ([92m↓11.72%[0m) [0.34% of initial]
[Iter 4180/20000] Loss: 0.0008726 (Best: 0.0006997 @iter4153) ([91m↑2.53%[0m) [0.35% of initial]
[Iter 4190/20000] Loss: 0.0009119 (Best: 0.0006997 @iter4153) ([91m↑4.51%[0m) [0.36% of initial]
Iter:4199, L1 loss=0.0009046, Total loss=0.0008495, Time:55
[Iter 4200/20000] Loss: 0.0009580 (Best: 0.0006997 @iter4153) ([91m↑5.05%[0m) [0.38% of initial]
[Iter 4210/20000] Loss: 0.0029061 (Best: 0.0006997 @iter4153) ([91m↑203.36%[0m) [1.15% of initial]
[Iter 4220/20000] Loss: 0.0017979 (Best: 0.0006997 @iter4153) ([92m↓38.14%[0m) [0.71% of initial]
[Iter 4230/20000] Loss: 0.0012399 (Best: 0.0006997 @iter4153) ([92m↓31.03%[0m) [0.49% of initial]
[Iter 4240/20000] Loss: 0.0010123 (Best: 0.0006997 @iter4153) ([92m↓18.36%[0m) [0.40% of initial]
[Iter 4250/20000] Loss: 0.0010058 (Best: 0.0006997 @iter4153) ([92m↓0.64%[0m) [0.40% of initial]
[Iter 4260/20000] Loss: 0.0010925 (Best: 0.0006997 @iter4153) ([91m↑8.62%[0m) [0.43% of initial]
[Iter 4270/20000] Loss: 0.0009838 (Best: 0.0006997 @iter4153) ([92m↓9.95%[0m) [0.39% of initial]
[Iter 4280/20000] Loss: 0.0008463 (Best: 0.0006997 @iter4153) ([92m↓13.98%[0m) [0.34% of initial]
[Iter 4290/20000] Loss: 0.0008118 (Best: 0.0006997 @iter4153) ([92m↓4.08%[0m) [0.32% of initial]
Iter:4299, L1 loss=0.000924, Total loss=0.0008649, Time:73
[Iter 4300/20000] Loss: 0.0008148 (Best: 0.0006997 @iter4153) ([91m↑0.38%[0m) [0.32% of initial]
[Iter 4310/20000] Loss: 0.0007842 (Best: 0.0006997 @iter4153) ([92m↓3.75%[0m) [0.31% of initial]
[Iter 4320/20000] Loss: 0.0009302 (Best: 0.0006997 @iter4153) ([91m↑18.61%[0m) [0.37% of initial]
[Iter 4330/20000] Loss: 0.0008087 (Best: 0.0006997 @iter4153) ([92m↓13.06%[0m) [0.32% of initial]
[Iter 4340/20000] Loss: 0.0007705 (Best: 0.0006634 @iter4336) ([92m↓4.73%[0m) [0.31% of initial]
[Iter 4350/20000] Loss: 0.0007532 (Best: 0.0006634 @iter4336) ([92m↓2.24%[0m) [0.30% of initial]
[Iter 4360/20000] Loss: 0.0007656 (Best: 0.0006634 @iter4336) ([91m↑1.65%[0m) [0.30% of initial]
[Iter 4370/20000] Loss: 0.0007654 (Best: 0.0006634 @iter4336) ([92m↓0.03%[0m) [0.30% of initial]
[Iter 4380/20000] Loss: 0.0008289 (Best: 0.0006634 @iter4336) ([91m↑8.30%[0m) [0.33% of initial]
[Iter 4390/20000] Loss: 0.0007338 (Best: 0.0006634 @iter4336) ([92m↓11.48%[0m) [0.29% of initial]
Iter:4399, L1 loss=0.0007518, Total loss=0.0007015, Time:77
[Iter 4400/20000] Loss: 0.0007298 (Best: 0.0006402 @iter4396) ([92m↓0.54%[0m) [0.29% of initial]
[Iter 4410/20000] Loss: 0.0026286 (Best: 0.0006402 @iter4396) ([91m↑260.17%[0m) [1.04% of initial]
[Iter 4420/20000] Loss: 0.0015065 (Best: 0.0006402 @iter4396) ([92m↓42.69%[0m) [0.60% of initial]
[Iter 4430/20000] Loss: 0.0012103 (Best: 0.0006402 @iter4396) ([92m↓19.66%[0m) [0.48% of initial]
[Iter 4440/20000] Loss: 0.0009680 (Best: 0.0006402 @iter4396) ([92m↓20.02%[0m) [0.38% of initial]
[Iter 4450/20000] Loss: 0.0008580 (Best: 0.0006402 @iter4396) ([92m↓11.37%[0m) [0.34% of initial]
[Iter 4460/20000] Loss: 0.0008525 (Best: 0.0006402 @iter4396) ([92m↓0.63%[0m) [0.34% of initial]
[Iter 4470/20000] Loss: 0.0009031 (Best: 0.0006402 @iter4396) ([91m↑5.94%[0m) [0.36% of initial]
[Iter 4480/20000] Loss: 0.0008695 (Best: 0.0006402 @iter4396) ([92m↓3.72%[0m) [0.35% of initial]
[Iter 4490/20000] Loss: 0.0008538 (Best: 0.0006402 @iter4396) ([92m↓1.81%[0m) [0.34% of initial]
Iter:4499, L1 loss=0.0009628, Total loss=0.0009231, Time:64
[Iter 4500/20000] Loss: 0.0009694 (Best: 0.0006402 @iter4396) ([91m↑13.54%[0m) [0.39% of initial]
Pruning 170 points (0.2%) from gaussian0 at iteration 4500
Pruning 169 points (0.2%) from gaussian1 at iteration 4500
[Iter 4510/20000] Loss: 0.0015468 (Best: 0.0006402 @iter4396) ([91m↑59.56%[0m) [0.61% of initial]
[Iter 4520/20000] Loss: 0.0012257 (Best: 0.0006402 @iter4396) ([92m↓20.76%[0m) [0.49% of initial]
[Iter 4530/20000] Loss: 0.0011603 (Best: 0.0006402 @iter4396) ([92m↓5.33%[0m) [0.46% of initial]
[Iter 4540/20000] Loss: 0.0009371 (Best: 0.0006402 @iter4396) ([92m↓19.23%[0m) [0.37% of initial]
[Iter 4550/20000] Loss: 0.0008331 (Best: 0.0006402 @iter4396) ([92m↓11.10%[0m) [0.33% of initial]
[Iter 4560/20000] Loss: 0.0008439 (Best: 0.0006402 @iter4396) ([91m↑1.30%[0m) [0.34% of initial]
[Iter 4570/20000] Loss: 0.0007430 (Best: 0.0006402 @iter4396) ([92m↓11.96%[0m) [0.30% of initial]
[Iter 4580/20000] Loss: 0.0007258 (Best: 0.0006402 @iter4396) ([92m↓2.31%[0m) [0.29% of initial]
[Iter 4590/20000] Loss: 0.0007939 (Best: 0.0006402 @iter4396) ([91m↑9.38%[0m) [0.32% of initial]
Iter:4599, L1 loss=0.0008698, Total loss=0.0008082, Time:60
[Iter 4600/20000] Loss: 0.0007740 (Best: 0.0006402 @iter4396) ([92m↓2.51%[0m) [0.31% of initial]
[Iter 4610/20000] Loss: 0.0030821 (Best: 0.0006402 @iter4396) ([91m↑298.21%[0m) [1.22% of initial]
[Iter 4620/20000] Loss: 0.0018678 (Best: 0.0006402 @iter4396) ([92m↓39.40%[0m) [0.74% of initial]
[Iter 4630/20000] Loss: 0.0012499 (Best: 0.0006402 @iter4396) ([92m↓33.08%[0m) [0.50% of initial]
[Iter 4640/20000] Loss: 0.0010087 (Best: 0.0006402 @iter4396) ([92m↓19.29%[0m) [0.40% of initial]
[Iter 4650/20000] Loss: 0.0008631 (Best: 0.0006402 @iter4396) ([92m↓14.43%[0m) [0.34% of initial]
[Iter 4660/20000] Loss: 0.0007590 (Best: 0.0006402 @iter4396) ([92m↓12.06%[0m) [0.30% of initial]
[Iter 4670/20000] Loss: 0.0007327 (Best: 0.0006402 @iter4396) ([92m↓3.46%[0m) [0.29% of initial]
[Iter 4680/20000] Loss: 0.0007124 (Best: 0.0006362 @iter4672) ([92m↓2.78%[0m) [0.28% of initial]
[Iter 4690/20000] Loss: 0.0006836 (Best: 0.0006164 @iter4681) ([92m↓4.03%[0m) [0.27% of initial]
Iter:4699, L1 loss=0.0007834, Total loss=0.0007305, Time:60
[Iter 4700/20000] Loss: 0.0007440 (Best: 0.0006164 @iter4681) ([91m↑8.83%[0m) [0.30% of initial]
[Iter 4710/20000] Loss: 0.0006689 (Best: 0.0006164 @iter4681) ([92m↓10.10%[0m) [0.27% of initial]
[Iter 4720/20000] Loss: 0.0007303 (Best: 0.0005829 @iter4711) ([91m↑9.19%[0m) [0.29% of initial]
[Iter 4730/20000] Loss: 0.0007145 (Best: 0.0005829 @iter4711) ([92m↓2.17%[0m) [0.28% of initial]
[Iter 4740/20000] Loss: 0.0007862 (Best: 0.0005829 @iter4711) ([91m↑10.04%[0m) [0.31% of initial]
[Iter 4750/20000] Loss: 0.0007815 (Best: 0.0005829 @iter4711) ([92m↓0.59%[0m) [0.31% of initial]
[Iter 4760/20000] Loss: 0.0007122 (Best: 0.0005829 @iter4711) ([92m↓8.87%[0m) [0.28% of initial]
[Iter 4770/20000] Loss: 0.0007633 (Best: 0.0005829 @iter4711) ([91m↑7.17%[0m) [0.30% of initial]
[Iter 4780/20000] Loss: 0.0008318 (Best: 0.0005829 @iter4711) ([91m↑8.98%[0m) [0.33% of initial]
[Iter 4790/20000] Loss: 0.0007333 (Best: 0.0005829 @iter4711) ([92m↓11.85%[0m) [0.29% of initial]
Iter:4799, L1 loss=0.0007655, Total loss=0.0007249, Time:62
[Iter 4800/20000] Loss: 0.0008329 (Best: 0.0005829 @iter4711) ([91m↑13.58%[0m) [0.33% of initial]
[Iter 4810/20000] Loss: 0.0023158 (Best: 0.0005829 @iter4711) ([91m↑178.05%[0m) [0.92% of initial]
[Iter 4820/20000] Loss: 0.0014912 (Best: 0.0005829 @iter4711) ([92m↓35.61%[0m) [0.59% of initial]
[Iter 4830/20000] Loss: 0.0012015 (Best: 0.0005829 @iter4711) ([92m↓19.43%[0m) [0.48% of initial]
[Iter 4840/20000] Loss: 0.0008977 (Best: 0.0005829 @iter4711) ([92m↓25.29%[0m) [0.36% of initial]
[Iter 4850/20000] Loss: 0.0007490 (Best: 0.0005829 @iter4711) ([92m↓16.57%[0m) [0.30% of initial]
[Iter 4860/20000] Loss: 0.0007767 (Best: 0.0005829 @iter4711) ([91m↑3.71%[0m) [0.31% of initial]
[Iter 4870/20000] Loss: 0.0007032 (Best: 0.0005829 @iter4711) ([92m↓9.47%[0m) [0.28% of initial]
[Iter 4880/20000] Loss: 0.0007427 (Best: 0.0005829 @iter4711) ([91m↑5.61%[0m) [0.30% of initial]
[Iter 4890/20000] Loss: 0.0006970 (Best: 0.0005829 @iter4711) ([92m↓6.15%[0m) [0.28% of initial]
Iter:4899, L1 loss=0.0008576, Total loss=0.0007864, Time:77
[Iter 4900/20000] Loss: 0.0007031 (Best: 0.0005829 @iter4711) ([91m↑0.88%[0m) [0.28% of initial]
[Iter 4910/20000] Loss: 0.0008465 (Best: 0.0005829 @iter4711) ([91m↑20.39%[0m) [0.34% of initial]
[Iter 4920/20000] Loss: 0.0007553 (Best: 0.0005829 @iter4711) ([92m↓10.77%[0m) [0.30% of initial]
[Iter 4930/20000] Loss: 0.0006740 (Best: 0.0005829 @iter4711) ([92m↓10.76%[0m) [0.27% of initial]
[Iter 4940/20000] Loss: 0.0007029 (Best: 0.0005829 @iter4711) ([91m↑4.28%[0m) [0.28% of initial]
[Iter 4950/20000] Loss: 0.0006186 (Best: 0.0005544 @iter4949) ([92m↓11.99%[0m) [0.25% of initial]
[Iter 4960/20000] Loss: 0.0006474 (Best: 0.0005457 @iter4957) ([91m↑4.66%[0m) [0.26% of initial]
[Iter 4970/20000] Loss: 0.0006835 (Best: 0.0005457 @iter4957) ([91m↑5.57%[0m) [0.27% of initial]
[Iter 4980/20000] Loss: 0.0006991 (Best: 0.0005457 @iter4957) ([91m↑2.28%[0m) [0.28% of initial]
[Iter 4990/20000] Loss: 0.0006555 (Best: 0.0005457 @iter4957) ([92m↓6.23%[0m) [0.26% of initial]
Iter:4999, L1 loss=0.0006656, Total loss=0.0006216, Time:59
[Iter 5000/20000] Loss: 0.0006129 (Best: 0.0005457 @iter4957) ([92m↓6.49%[0m) [0.24% of initial]
Pruning 121 points (0.1%) from gaussian0 at iteration 5000
Pruning 166 points (0.1%) from gaussian1 at iteration 5000
[Iter 5010/20000] Loss: 0.0025425 (Best: 0.0005457 @iter4957) ([91m↑314.82%[0m) [1.01% of initial]
[Iter 5020/20000] Loss: 0.0016495 (Best: 0.0005457 @iter4957) ([92m↓35.12%[0m) [0.66% of initial]
[Iter 5030/20000] Loss: 0.0010886 (Best: 0.0005457 @iter4957) ([92m↓34.00%[0m) [0.43% of initial]
[Iter 5040/20000] Loss: 0.0010380 (Best: 0.0005457 @iter4957) ([92m↓4.65%[0m) [0.41% of initial]
[Iter 5050/20000] Loss: 0.0008907 (Best: 0.0005457 @iter4957) ([92m↓14.19%[0m) [0.35% of initial]
[Iter 5060/20000] Loss: 0.0007362 (Best: 0.0005457 @iter4957) ([92m↓17.35%[0m) [0.29% of initial]
[Iter 5070/20000] Loss: 0.0007859 (Best: 0.0005457 @iter4957) ([91m↑6.76%[0m) [0.31% of initial]
[Iter 5080/20000] Loss: 0.0006913 (Best: 0.0005457 @iter4957) ([92m↓12.05%[0m) [0.27% of initial]
[Iter 5090/20000] Loss: 0.0007179 (Best: 0.0005457 @iter4957) ([91m↑3.86%[0m) [0.29% of initial]
Iter:5099, L1 loss=0.0007721, Total loss=0.0007147, Time:61
[Iter 5100/20000] Loss: 0.0007605 (Best: 0.0005457 @iter4957) ([91m↑5.93%[0m) [0.30% of initial]
[Iter 5110/20000] Loss: 0.0007387 (Best: 0.0005457 @iter4957) ([92m↓2.86%[0m) [0.29% of initial]
[Iter 5120/20000] Loss: 0.0007436 (Best: 0.0005457 @iter4957) ([91m↑0.67%[0m) [0.30% of initial]
[Iter 5130/20000] Loss: 0.0007626 (Best: 0.0005457 @iter4957) ([91m↑2.55%[0m) [0.30% of initial]
[Iter 5140/20000] Loss: 0.0006607 (Best: 0.0005457 @iter4957) ([92m↓13.36%[0m) [0.26% of initial]
[Iter 5150/20000] Loss: 0.0006769 (Best: 0.0005457 @iter4957) ([91m↑2.44%[0m) [0.27% of initial]
[Iter 5160/20000] Loss: 0.0006724 (Best: 0.0005457 @iter4957) ([92m↓0.66%[0m) [0.27% of initial]
[Iter 5170/20000] Loss: 0.0007103 (Best: 0.0005457 @iter4957) ([91m↑5.64%[0m) [0.28% of initial]
[Iter 5180/20000] Loss: 0.0006586 (Best: 0.0005457 @iter4957) ([92m↓7.28%[0m) [0.26% of initial]
[Iter 5190/20000] Loss: 0.0006750 (Best: 0.0005457 @iter4957) ([91m↑2.49%[0m) [0.27% of initial]
Iter:5199, L1 loss=0.0007835, Total loss=0.0007122, Time:64
[Iter 5200/20000] Loss: 0.0006586 (Best: 0.0005457 @iter4957) ([92m↓2.44%[0m) [0.26% of initial]
[Iter 5210/20000] Loss: 0.0024886 (Best: 0.0005457 @iter4957) ([91m↑277.88%[0m) [0.99% of initial]
[Iter 5220/20000] Loss: 0.0015668 (Best: 0.0005457 @iter4957) ([92m↓37.04%[0m) [0.62% of initial]
[Iter 5230/20000] Loss: 0.0010920 (Best: 0.0005457 @iter4957) ([92m↓30.30%[0m) [0.43% of initial]
[Iter 5240/20000] Loss: 0.0008241 (Best: 0.0005457 @iter4957) ([92m↓24.54%[0m) [0.33% of initial]
[Iter 5250/20000] Loss: 0.0010187 (Best: 0.0005457 @iter4957) ([91m↑23.62%[0m) [0.40% of initial]
[Iter 5260/20000] Loss: 0.0008320 (Best: 0.0005457 @iter4957) ([92m↓18.33%[0m) [0.33% of initial]
[Iter 5270/20000] Loss: 0.0007519 (Best: 0.0005457 @iter4957) ([92m↓9.62%[0m) [0.30% of initial]
[Iter 5280/20000] Loss: 0.0008294 (Best: 0.0005457 @iter4957) ([91m↑10.29%[0m) [0.33% of initial]
[Iter 5290/20000] Loss: 0.0007792 (Best: 0.0005457 @iter4957) ([92m↓6.05%[0m) [0.31% of initial]
Iter:5299, L1 loss=0.000858, Total loss=0.0008308, Time:73
[Iter 5300/20000] Loss: 0.0008520 (Best: 0.0005457 @iter4957) ([91m↑9.34%[0m) [0.34% of initial]
[Iter 5310/20000] Loss: 0.0008354 (Best: 0.0005457 @iter4957) ([92m↓1.95%[0m) [0.33% of initial]
[Iter 5320/20000] Loss: 0.0007286 (Best: 0.0005457 @iter4957) ([92m↓12.78%[0m) [0.29% of initial]
[Iter 5330/20000] Loss: 0.0006322 (Best: 0.0005457 @iter4957) ([92m↓13.23%[0m) [0.25% of initial]
[Iter 5340/20000] Loss: 0.0006618 (Best: 0.0005457 @iter4957) ([91m↑4.68%[0m) [0.26% of initial]
[Iter 5350/20000] Loss: 0.0006759 (Best: 0.0005360 @iter5344) ([91m↑2.13%[0m) [0.27% of initial]
[Iter 5360/20000] Loss: 0.0006989 (Best: 0.0005360 @iter5344) ([91m↑3.40%[0m) [0.28% of initial]
[Iter 5370/20000] Loss: 0.0006946 (Best: 0.0005360 @iter5344) ([92m↓0.61%[0m) [0.28% of initial]
[Iter 5380/20000] Loss: 0.0006899 (Best: 0.0005360 @iter5344) ([92m↓0.69%[0m) [0.27% of initial]
[Iter 5390/20000] Loss: 0.0007058 (Best: 0.0005360 @iter5344) ([91m↑2.31%[0m) [0.28% of initial]
Iter:5399, L1 loss=0.0006957, Total loss=0.0006265, Time:68
[Iter 5400/20000] Loss: 0.0007003 (Best: 0.0005360 @iter5344) ([92m↓0.77%[0m) [0.28% of initial]
[Iter 5410/20000] Loss: 0.0019882 (Best: 0.0005360 @iter5344) ([91m↑183.89%[0m) [0.79% of initial]
[Iter 5420/20000] Loss: 0.0013780 (Best: 0.0005360 @iter5344) ([92m↓30.69%[0m) [0.55% of initial]
[Iter 5430/20000] Loss: 0.0009150 (Best: 0.0005360 @iter5344) ([92m↓33.60%[0m) [0.36% of initial]
[Iter 5440/20000] Loss: 0.0008175 (Best: 0.0005360 @iter5344) ([92m↓10.65%[0m) [0.32% of initial]
[Iter 5450/20000] Loss: 0.0007010 (Best: 0.0005360 @iter5344) ([92m↓14.24%[0m) [0.28% of initial]
[Iter 5460/20000] Loss: 0.0007717 (Best: 0.0005360 @iter5344) ([91m↑10.08%[0m) [0.31% of initial]
[Iter 5470/20000] Loss: 0.0006650 (Best: 0.0005360 @iter5344) ([92m↓13.83%[0m) [0.26% of initial]
[Iter 5480/20000] Loss: 0.0006407 (Best: 0.0005289 @iter5476) ([92m↓3.65%[0m) [0.25% of initial]
[Iter 5490/20000] Loss: 0.0006503 (Best: 0.0005289 @iter5476) ([91m↑1.49%[0m) [0.26% of initial]
Iter:5499, L1 loss=0.0007358, Total loss=0.0006752, Time:68
[Iter 5500/20000] Loss: 0.0006256 (Best: 0.0005289 @iter5476) ([92m↓3.79%[0m) [0.25% of initial]
Pruning 179 points (0.1%) from gaussian0 at iteration 5500
Pruning 168 points (0.1%) from gaussian1 at iteration 5500
[Iter 5510/20000] Loss: 0.0011516 (Best: 0.0005289 @iter5476) ([91m↑84.07%[0m) [0.46% of initial]
[Iter 5520/20000] Loss: 0.0008689 (Best: 0.0005289 @iter5476) ([92m↓24.55%[0m) [0.35% of initial]
[Iter 5530/20000] Loss: 0.0007871 (Best: 0.0005289 @iter5476) ([92m↓9.42%[0m) [0.31% of initial]
[Iter 5540/20000] Loss: 0.0007215 (Best: 0.0005289 @iter5476) ([92m↓8.32%[0m) [0.29% of initial]
[Iter 5550/20000] Loss: 0.0006900 (Best: 0.0005289 @iter5476) ([92m↓4.38%[0m) [0.27% of initial]
[Iter 5560/20000] Loss: 0.0006420 (Best: 0.0005289 @iter5476) ([92m↓6.96%[0m) [0.26% of initial]
[Iter 5570/20000] Loss: 0.0006363 (Best: 0.0005289 @iter5476) ([92m↓0.89%[0m) [0.25% of initial]
[Iter 5580/20000] Loss: 0.0007389 (Best: 0.0005289 @iter5476) ([91m↑16.13%[0m) [0.29% of initial]
[Iter 5590/20000] Loss: 0.0007740 (Best: 0.0005289 @iter5476) ([91m↑4.75%[0m) [0.31% of initial]
Iter:5599, L1 loss=0.0006753, Total loss=0.0005938, Time:79
[Iter 5600/20000] Loss: 0.0006120 (Best: 0.0005289 @iter5476) ([92m↓20.93%[0m) [0.24% of initial]
[Iter 5610/20000] Loss: 0.0023311 (Best: 0.0005289 @iter5476) ([91m↑280.93%[0m) [0.93% of initial]
[Iter 5620/20000] Loss: 0.0013441 (Best: 0.0005289 @iter5476) ([92m↓42.34%[0m) [0.53% of initial]
[Iter 5630/20000] Loss: 0.0010130 (Best: 0.0005289 @iter5476) ([92m↓24.63%[0m) [0.40% of initial]
[Iter 5640/20000] Loss: 0.0008405 (Best: 0.0005289 @iter5476) ([92m↓17.03%[0m) [0.33% of initial]
[Iter 5650/20000] Loss: 0.0007003 (Best: 0.0005289 @iter5476) ([92m↓16.69%[0m) [0.28% of initial]
[Iter 5660/20000] Loss: 0.0006747 (Best: 0.0005289 @iter5476) ([92m↓3.65%[0m) [0.27% of initial]
[Iter 5670/20000] Loss: 0.0006752 (Best: 0.0005289 @iter5476) ([91m↑0.07%[0m) [0.27% of initial]
[Iter 5680/20000] Loss: 0.0006321 (Best: 0.0005289 @iter5476) ([92m↓6.38%[0m) [0.25% of initial]
[Iter 5690/20000] Loss: 0.0006816 (Best: 0.0005289 @iter5476) ([91m↑7.83%[0m) [0.27% of initial]
Iter:5699, L1 loss=0.0006363, Total loss=0.0005674, Time:84
[Iter 5700/20000] Loss: 0.0005776 (Best: 0.0005289 @iter5476) ([92m↓15.26%[0m) [0.23% of initial]
[Iter 5710/20000] Loss: 0.0007309 (Best: 0.0004985 @iter5701) ([91m↑26.55%[0m) [0.29% of initial]
[Iter 5720/20000] Loss: 0.0006535 (Best: 0.0004985 @iter5701) ([92m↓10.59%[0m) [0.26% of initial]
[Iter 5730/20000] Loss: 0.0006730 (Best: 0.0004985 @iter5701) ([91m↑2.99%[0m) [0.27% of initial]
[Iter 5740/20000] Loss: 0.0005782 (Best: 0.0004985 @iter5701) ([92m↓14.09%[0m) [0.23% of initial]
[Iter 5750/20000] Loss: 0.0005862 (Best: 0.0004985 @iter5701) ([91m↑1.38%[0m) [0.23% of initial]
[Iter 5760/20000] Loss: 0.0005864 (Best: 0.0004985 @iter5701) ([91m↑0.03%[0m) [0.23% of initial]
[Iter 5770/20000] Loss: 0.0005306 (Best: 0.0004737 @iter5770) ([92m↓9.51%[0m) [0.21% of initial]
[Iter 5780/20000] Loss: 0.0005498 (Best: 0.0004737 @iter5770) ([91m↑3.61%[0m) [0.22% of initial]
[Iter 5790/20000] Loss: 0.0005794 (Best: 0.0004737 @iter5770) ([91m↑5.39%[0m) [0.23% of initial]
Iter:5799, L1 loss=0.0006319, Total loss=0.0005699, Time:87
[Iter 5800/20000] Loss: 0.0005557 (Best: 0.0004584 @iter5797) ([92m↓4.10%[0m) [0.22% of initial]
[Iter 5810/20000] Loss: 0.0017046 (Best: 0.0004584 @iter5797) ([91m↑206.77%[0m) [0.68% of initial]
[Iter 5820/20000] Loss: 0.0012550 (Best: 0.0004584 @iter5797) ([92m↓26.38%[0m) [0.50% of initial]
[Iter 5830/20000] Loss: 0.0008723 (Best: 0.0004584 @iter5797) ([92m↓30.50%[0m) [0.35% of initial]
[Iter 5840/20000] Loss: 0.0007224 (Best: 0.0004584 @iter5797) ([92m↓17.18%[0m) [0.29% of initial]
[Iter 5850/20000] Loss: 0.0007216 (Best: 0.0004584 @iter5797) ([92m↓0.12%[0m) [0.29% of initial]
[Iter 5860/20000] Loss: 0.0005902 (Best: 0.0004584 @iter5797) ([92m↓18.21%[0m) [0.23% of initial]
[Iter 5870/20000] Loss: 0.0006876 (Best: 0.0004584 @iter5797) ([91m↑16.51%[0m) [0.27% of initial]
[Iter 5880/20000] Loss: 0.0006274 (Best: 0.0004584 @iter5797) ([92m↓8.76%[0m) [0.25% of initial]
[Iter 5890/20000] Loss: 0.0005982 (Best: 0.0004584 @iter5797) ([92m↓4.65%[0m) [0.24% of initial]
Iter:5899, L1 loss=0.0006723, Total loss=0.0005768, Time:77
[Iter 5900/20000] Loss: 0.0005778 (Best: 0.0004584 @iter5797) ([92m↓3.42%[0m) [0.23% of initial]
[Iter 5910/20000] Loss: 0.0006095 (Best: 0.0004584 @iter5797) ([91m↑5.49%[0m) [0.24% of initial]
[Iter 5920/20000] Loss: 0.0005809 (Best: 0.0004584 @iter5797) ([92m↓4.69%[0m) [0.23% of initial]
[Iter 5930/20000] Loss: 0.0004983 (Best: 0.0004584 @iter5797) ([92m↓14.22%[0m) [0.20% of initial]
[Iter 5940/20000] Loss: 0.0006509 (Best: 0.0004584 @iter5797) ([91m↑30.61%[0m) [0.26% of initial]
[Iter 5950/20000] Loss: 0.0005292 (Best: 0.0004584 @iter5797) ([92m↓18.70%[0m) [0.21% of initial]
[Iter 5960/20000] Loss: 0.0005732 (Best: 0.0004584 @iter5797) ([91m↑8.31%[0m) [0.23% of initial]
[Iter 5970/20000] Loss: 0.0006688 (Best: 0.0004584 @iter5797) ([91m↑16.69%[0m) [0.27% of initial]
[Iter 5980/20000] Loss: 0.0005813 (Best: 0.0004584 @iter5797) ([92m↓13.09%[0m) [0.23% of initial]
[Iter 5990/20000] Loss: 0.0005938 (Best: 0.0004584 @iter5797) ([91m↑2.16%[0m) [0.24% of initial]
Iter:5999, L1 loss=0.0006835, Total loss=0.000614, Time:88
[Iter 6000/20000] Loss: 0.0006064 (Best: 0.0004584 @iter5797) ([91m↑2.12%[0m) [0.24% of initial]
Pruning 144 points (0.1%) from gaussian0 at iteration 6000
Pruning 197 points (0.1%) from gaussian1 at iteration 6000
[Iter 6010/20000] Loss: 0.0591033 (Best: 0.0004584 @iter5797) ([91m↑9646.52%[0m) [23.48% of initial]
[Iter 6020/20000] Loss: 0.0306218 (Best: 0.0004584 @iter5797) ([92m↓48.19%[0m) [12.17% of initial]
[Iter 6030/20000] Loss: 0.0111053 (Best: 0.0004584 @iter5797) ([92m↓63.73%[0m) [4.41% of initial]
[Iter 6040/20000] Loss: 0.0055395 (Best: 0.0004584 @iter5797) ([92m↓50.12%[0m) [2.20% of initial]
[Iter 6050/20000] Loss: 0.0034456 (Best: 0.0004584 @iter5797) ([92m↓37.80%[0m) [1.37% of initial]
[Iter 6060/20000] Loss: 0.0025222 (Best: 0.0004584 @iter5797) ([92m↓26.80%[0m) [1.00% of initial]
[Iter 6070/20000] Loss: 0.0018298 (Best: 0.0004584 @iter5797) ([92m↓27.45%[0m) [0.73% of initial]
[Iter 6080/20000] Loss: 0.0015839 (Best: 0.0004584 @iter5797) ([92m↓13.44%[0m) [0.63% of initial]
[Iter 6090/20000] Loss: 0.0013141 (Best: 0.0004584 @iter5797) ([92m↓17.03%[0m) [0.52% of initial]
Iter:6099, L1 loss=0.001205, Total loss=0.001216, Time:73
[Iter 6100/20000] Loss: 0.0011563 (Best: 0.0004584 @iter5797) ([92m↓12.01%[0m) [0.46% of initial]
[Iter 6110/20000] Loss: 0.0011181 (Best: 0.0004584 @iter5797) ([92m↓3.30%[0m) [0.44% of initial]
[Iter 6120/20000] Loss: 0.0010612 (Best: 0.0004584 @iter5797) ([92m↓5.09%[0m) [0.42% of initial]
[Iter 6130/20000] Loss: 0.0009851 (Best: 0.0004584 @iter5797) ([92m↓7.17%[0m) [0.39% of initial]
[Iter 6140/20000] Loss: 0.0009125 (Best: 0.0004584 @iter5797) ([92m↓7.37%[0m) [0.36% of initial]
[Iter 6150/20000] Loss: 0.0009046 (Best: 0.0004584 @iter5797) ([92m↓0.87%[0m) [0.36% of initial]
[Iter 6160/20000] Loss: 0.0008245 (Best: 0.0004584 @iter5797) ([92m↓8.86%[0m) [0.33% of initial]
[Iter 6170/20000] Loss: 0.0008835 (Best: 0.0004584 @iter5797) ([91m↑7.16%[0m) [0.35% of initial]
[Iter 6180/20000] Loss: 0.0009111 (Best: 0.0004584 @iter5797) ([91m↑3.11%[0m) [0.36% of initial]
[Iter 6190/20000] Loss: 0.0007887 (Best: 0.0004584 @iter5797) ([92m↓13.43%[0m) [0.31% of initial]
Iter:6199, L1 loss=0.0008196, Total loss=0.0007809, Time:73
[Iter 6200/20000] Loss: 0.0007974 (Best: 0.0004584 @iter5797) ([91m↑1.10%[0m) [0.32% of initial]
[Iter 6210/20000] Loss: 0.0018040 (Best: 0.0004584 @iter5797) ([91m↑126.24%[0m) [0.72% of initial]
[Iter 6220/20000] Loss: 0.0013139 (Best: 0.0004584 @iter5797) ([92m↓27.17%[0m) [0.52% of initial]
[Iter 6230/20000] Loss: 0.0011445 (Best: 0.0004584 @iter5797) ([92m↓12.89%[0m) [0.45% of initial]
[Iter 6240/20000] Loss: 0.0009567 (Best: 0.0004584 @iter5797) ([92m↓16.41%[0m) [0.38% of initial]
[Iter 6250/20000] Loss: 0.0008577 (Best: 0.0004584 @iter5797) ([92m↓10.35%[0m) [0.34% of initial]
[Iter 6260/20000] Loss: 0.0009232 (Best: 0.0004584 @iter5797) ([91m↑7.64%[0m) [0.37% of initial]
[Iter 6270/20000] Loss: 0.0008391 (Best: 0.0004584 @iter5797) ([92m↓9.10%[0m) [0.33% of initial]
[Iter 6280/20000] Loss: 0.0008408 (Best: 0.0004584 @iter5797) ([91m↑0.20%[0m) [0.33% of initial]
[Iter 6290/20000] Loss: 0.0007795 (Best: 0.0004584 @iter5797) ([92m↓7.29%[0m) [0.31% of initial]
Iter:6299, L1 loss=0.0008459, Total loss=0.0007874, Time:75
[Iter 6300/20000] Loss: 0.0008734 (Best: 0.0004584 @iter5797) ([91m↑12.04%[0m) [0.35% of initial]
[Iter 6310/20000] Loss: 0.0007837 (Best: 0.0004584 @iter5797) ([92m↓10.27%[0m) [0.31% of initial]
[Iter 6320/20000] Loss: 0.0008132 (Best: 0.0004584 @iter5797) ([91m↑3.77%[0m) [0.32% of initial]
[Iter 6330/20000] Loss: 0.0008049 (Best: 0.0004584 @iter5797) ([92m↓1.02%[0m) [0.32% of initial]
[Iter 6340/20000] Loss: 0.0007003 (Best: 0.0004584 @iter5797) ([92m↓13.00%[0m) [0.28% of initial]
[Iter 6350/20000] Loss: 0.0007259 (Best: 0.0004584 @iter5797) ([91m↑3.66%[0m) [0.29% of initial]
[Iter 6360/20000] Loss: 0.0007657 (Best: 0.0004584 @iter5797) ([91m↑5.48%[0m) [0.30% of initial]
[Iter 6370/20000] Loss: 0.0007527 (Best: 0.0004584 @iter5797) ([92m↓1.70%[0m) [0.30% of initial]
[Iter 6380/20000] Loss: 0.0006951 (Best: 0.0004584 @iter5797) ([92m↓7.66%[0m) [0.28% of initial]
[Iter 6390/20000] Loss: 0.0007297 (Best: 0.0004584 @iter5797) ([91m↑4.98%[0m) [0.29% of initial]
Iter:6399, L1 loss=0.0007415, Total loss=0.0006971, Time:76
[Iter 6400/20000] Loss: 0.0007467 (Best: 0.0004584 @iter5797) ([91m↑2.32%[0m) [0.30% of initial]
[Iter 6410/20000] Loss: 0.0011691 (Best: 0.0004584 @iter5797) ([91m↑56.58%[0m) [0.46% of initial]
[Iter 6420/20000] Loss: 0.0011187 (Best: 0.0004584 @iter5797) ([92m↓4.31%[0m) [0.44% of initial]
[Iter 6430/20000] Loss: 0.0010257 (Best: 0.0004584 @iter5797) ([92m↓8.31%[0m) [0.41% of initial]
[Iter 6440/20000] Loss: 0.0008705 (Best: 0.0004584 @iter5797) ([92m↓15.13%[0m) [0.35% of initial]
[Iter 6450/20000] Loss: 0.0008127 (Best: 0.0004584 @iter5797) ([92m↓6.65%[0m) [0.32% of initial]
[Iter 6460/20000] Loss: 0.0007481 (Best: 0.0004584 @iter5797) ([92m↓7.94%[0m) [0.30% of initial]
[Iter 6470/20000] Loss: 0.0007369 (Best: 0.0004584 @iter5797) ([92m↓1.50%[0m) [0.29% of initial]
[Iter 6480/20000] Loss: 0.0007417 (Best: 0.0004584 @iter5797) ([91m↑0.65%[0m) [0.29% of initial]
[Iter 6490/20000] Loss: 0.0006937 (Best: 0.0004584 @iter5797) ([92m↓6.48%[0m) [0.28% of initial]
Iter:6499, L1 loss=0.0008291, Total loss=0.0007687, Time:82
[Iter 6500/20000] Loss: 0.0007493 (Best: 0.0004584 @iter5797) ([91m↑8.02%[0m) [0.30% of initial]
Pruning 130 points (0.1%) from gaussian0 at iteration 6500
Pruning 175 points (0.1%) from gaussian1 at iteration 6500
[Iter 6510/20000] Loss: 0.0015922 (Best: 0.0004584 @iter5797) ([91m↑112.50%[0m) [0.63% of initial]
[Iter 6520/20000] Loss: 0.0011316 (Best: 0.0004584 @iter5797) ([92m↓28.93%[0m) [0.45% of initial]
[Iter 6530/20000] Loss: 0.0010285 (Best: 0.0004584 @iter5797) ([92m↓9.11%[0m) [0.41% of initial]
[Iter 6540/20000] Loss: 0.0008381 (Best: 0.0004584 @iter5797) ([92m↓18.52%[0m) [0.33% of initial]
[Iter 6550/20000] Loss: 0.0007563 (Best: 0.0004584 @iter5797) ([92m↓9.76%[0m) [0.30% of initial]
[Iter 6560/20000] Loss: 0.0006798 (Best: 0.0004584 @iter5797) ([92m↓10.12%[0m) [0.27% of initial]
[Iter 6570/20000] Loss: 0.0007650 (Best: 0.0004584 @iter5797) ([91m↑12.54%[0m) [0.30% of initial]
[Iter 6580/20000] Loss: 0.0007309 (Best: 0.0004584 @iter5797) ([92m↓4.46%[0m) [0.29% of initial]
[Iter 6590/20000] Loss: 0.0006665 (Best: 0.0004584 @iter5797) ([92m↓8.81%[0m) [0.26% of initial]
Iter:6599, L1 loss=0.0007538, Total loss=0.0006938, Time:88
[Iter 6600/20000] Loss: 0.0006964 (Best: 0.0004584 @iter5797) ([91m↑4.49%[0m) [0.28% of initial]
[Iter 6610/20000] Loss: 0.0011022 (Best: 0.0004584 @iter5797) ([91m↑58.27%[0m) [0.44% of initial]
[Iter 6620/20000] Loss: 0.0008693 (Best: 0.0004584 @iter5797) ([92m↓21.13%[0m) [0.35% of initial]
[Iter 6630/20000] Loss: 0.0007702 (Best: 0.0004584 @iter5797) ([92m↓11.40%[0m) [0.31% of initial]
[Iter 6640/20000] Loss: 0.0007005 (Best: 0.0004584 @iter5797) ([92m↓9.04%[0m) [0.28% of initial]
[Iter 6650/20000] Loss: 0.0007024 (Best: 0.0004584 @iter5797) ([91m↑0.27%[0m) [0.28% of initial]
[Iter 6660/20000] Loss: 0.0007567 (Best: 0.0004584 @iter5797) ([91m↑7.73%[0m) [0.30% of initial]
[Iter 6670/20000] Loss: 0.0007411 (Best: 0.0004584 @iter5797) ([92m↓2.07%[0m) [0.29% of initial]
[Iter 6680/20000] Loss: 0.0007396 (Best: 0.0004584 @iter5797) ([92m↓0.20%[0m) [0.29% of initial]
[Iter 6690/20000] Loss: 0.0007156 (Best: 0.0004584 @iter5797) ([92m↓3.25%[0m) [0.28% of initial]
Iter:6699, L1 loss=0.0007477, Total loss=0.0007099, Time:87
[Iter 6700/20000] Loss: 0.0006862 (Best: 0.0004584 @iter5797) ([92m↓4.10%[0m) [0.27% of initial]
[Iter 6710/20000] Loss: 0.0007246 (Best: 0.0004584 @iter5797) ([91m↑5.60%[0m) [0.29% of initial]
[Iter 6720/20000] Loss: 0.0006772 (Best: 0.0004584 @iter5797) ([92m↓6.55%[0m) [0.27% of initial]
[Iter 6730/20000] Loss: 0.0006331 (Best: 0.0004584 @iter5797) ([92m↓6.50%[0m) [0.25% of initial]
[Iter 6740/20000] Loss: 0.0006779 (Best: 0.0004584 @iter5797) ([91m↑7.07%[0m) [0.27% of initial]
[Iter 6750/20000] Loss: 0.0007055 (Best: 0.0004584 @iter5797) ([91m↑4.06%[0m) [0.28% of initial]
[Iter 6760/20000] Loss: 0.0006630 (Best: 0.0004584 @iter5797) ([92m↓6.02%[0m) [0.26% of initial]
[Iter 6770/20000] Loss: 0.0006619 (Best: 0.0004584 @iter5797) ([92m↓0.17%[0m) [0.26% of initial]
[Iter 6780/20000] Loss: 0.0006129 (Best: 0.0004584 @iter5797) ([92m↓7.39%[0m) [0.24% of initial]
[Iter 6790/20000] Loss: 0.0006681 (Best: 0.0004584 @iter5797) ([91m↑9.00%[0m) [0.27% of initial]
Iter:6799, L1 loss=0.000669, Total loss=0.0006134, Time:88
[Iter 6800/20000] Loss: 0.0006134 (Best: 0.0004584 @iter5797) ([92m↓8.19%[0m) [0.24% of initial]
[Iter 6810/20000] Loss: 0.0009915 (Best: 0.0004584 @iter5797) ([91m↑61.63%[0m) [0.39% of initial]
[Iter 6820/20000] Loss: 0.0008901 (Best: 0.0004584 @iter5797) ([92m↓10.22%[0m) [0.35% of initial]
[Iter 6830/20000] Loss: 0.0007532 (Best: 0.0004584 @iter5797) ([92m↓15.39%[0m) [0.30% of initial]
[Iter 6840/20000] Loss: 0.0007110 (Best: 0.0004584 @iter5797) ([92m↓5.60%[0m) [0.28% of initial]
[Iter 6850/20000] Loss: 0.0007084 (Best: 0.0004584 @iter5797) ([92m↓0.36%[0m) [0.28% of initial]
[Iter 6860/20000] Loss: 0.0006682 (Best: 0.0004584 @iter5797) ([92m↓5.68%[0m) [0.27% of initial]
[Iter 6870/20000] Loss: 0.0006625 (Best: 0.0004584 @iter5797) ([92m↓0.85%[0m) [0.26% of initial]
[Iter 6880/20000] Loss: 0.0006365 (Best: 0.0004584 @iter5797) ([92m↓3.93%[0m) [0.25% of initial]
[Iter 6890/20000] Loss: 0.0007059 (Best: 0.0004584 @iter5797) ([91m↑10.91%[0m) [0.28% of initial]
Iter:6899, L1 loss=0.0007719, Total loss=0.0007281, Time:84
[Iter 6900/20000] Loss: 0.0007164 (Best: 0.0004584 @iter5797) ([91m↑1.48%[0m) [0.28% of initial]
[Iter 6910/20000] Loss: 0.0007247 (Best: 0.0004584 @iter5797) ([91m↑1.17%[0m) [0.29% of initial]
[Iter 6920/20000] Loss: 0.0006726 (Best: 0.0004584 @iter5797) ([92m↓7.20%[0m) [0.27% of initial]
[Iter 6930/20000] Loss: 0.0006663 (Best: 0.0004584 @iter5797) ([92m↓0.94%[0m) [0.26% of initial]
[Iter 6940/20000] Loss: 0.0006108 (Best: 0.0004584 @iter5797) ([92m↓8.32%[0m) [0.24% of initial]
[Iter 6950/20000] Loss: 0.0006258 (Best: 0.0004584 @iter5797) ([91m↑2.45%[0m) [0.25% of initial]
[Iter 6960/20000] Loss: 0.0005969 (Best: 0.0004584 @iter5797) ([92m↓4.61%[0m) [0.24% of initial]
[Iter 6970/20000] Loss: 0.0006664 (Best: 0.0004584 @iter5797) ([91m↑11.65%[0m) [0.26% of initial]
[Iter 6980/20000] Loss: 0.0006862 (Best: 0.0004584 @iter5797) ([91m↑2.97%[0m) [0.27% of initial]
[Iter 6990/20000] Loss: 0.0006379 (Best: 0.0004584 @iter5797) ([92m↓7.05%[0m) [0.25% of initial]
Iter:6999, L1 loss=0.0008031, Total loss=0.0007416, Time:83
[Iter 7000/20000] Loss: 0.0006466 (Best: 0.0004584 @iter5797) ([91m↑1.37%[0m) [0.26% of initial]
Pruning 81 points (0.1%) from gaussian0 at iteration 7000
Pruning 99 points (0.1%) from gaussian1 at iteration 7000
[Iter 7010/20000] Loss: 0.0014806 (Best: 0.0004584 @iter5797) ([91m↑128.97%[0m) [0.59% of initial]
[Iter 7020/20000] Loss: 0.0010392 (Best: 0.0004584 @iter5797) ([92m↓29.81%[0m) [0.41% of initial]
[Iter 7030/20000] Loss: 0.0008239 (Best: 0.0004584 @iter5797) ([92m↓20.72%[0m) [0.33% of initial]
[Iter 7040/20000] Loss: 0.0007101 (Best: 0.0004584 @iter5797) ([92m↓13.81%[0m) [0.28% of initial]
[Iter 7050/20000] Loss: 0.0006870 (Best: 0.0004584 @iter5797) ([92m↓3.26%[0m) [0.27% of initial]
[Iter 7060/20000] Loss: 0.0007086 (Best: 0.0004584 @iter5797) ([91m↑3.15%[0m) [0.28% of initial]
[Iter 7070/20000] Loss: 0.0006510 (Best: 0.0004584 @iter5797) ([92m↓8.13%[0m) [0.26% of initial]
[Iter 7080/20000] Loss: 0.0006584 (Best: 0.0004584 @iter5797) ([91m↑1.14%[0m) [0.26% of initial]
[Iter 7090/20000] Loss: 0.0006691 (Best: 0.0004584 @iter5797) ([91m↑1.62%[0m) [0.27% of initial]
Iter:7099, L1 loss=0.0006672, Total loss=0.0005997, Time:81
[Iter 7100/20000] Loss: 0.0006310 (Best: 0.0004584 @iter5797) ([92m↓5.69%[0m) [0.25% of initial]
[Iter 7110/20000] Loss: 0.0006494 (Best: 0.0004584 @iter5797) ([91m↑2.92%[0m) [0.26% of initial]
[Iter 7120/20000] Loss: 0.0006145 (Best: 0.0004584 @iter5797) ([92m↓5.37%[0m) [0.24% of initial]
[Iter 7130/20000] Loss: 0.0006141 (Best: 0.0004584 @iter5797) ([92m↓0.07%[0m) [0.24% of initial]
[Iter 7140/20000] Loss: 0.0006919 (Best: 0.0004584 @iter5797) ([91m↑12.67%[0m) [0.27% of initial]
[Iter 7150/20000] Loss: 0.0006519 (Best: 0.0004584 @iter5797) ([92m↓5.79%[0m) [0.26% of initial]
[Iter 7160/20000] Loss: 0.0006200 (Best: 0.0004584 @iter5797) ([92m↓4.90%[0m) [0.25% of initial]
[Iter 7170/20000] Loss: 0.0006281 (Best: 0.0004584 @iter5797) ([91m↑1.32%[0m) [0.25% of initial]
[Iter 7180/20000] Loss: 0.0006450 (Best: 0.0004584 @iter5797) ([91m↑2.68%[0m) [0.26% of initial]
[Iter 7190/20000] Loss: 0.0005760 (Best: 0.0004584 @iter5797) ([92m↓10.70%[0m) [0.23% of initial]
Iter:7199, L1 loss=0.0006816, Total loss=0.0006035, Time:84
[Iter 7200/20000] Loss: 0.0006083 (Best: 0.0004584 @iter5797) ([91m↑5.61%[0m) [0.24% of initial]
[Iter 7210/20000] Loss: 0.0010989 (Best: 0.0004584 @iter5797) ([91m↑80.65%[0m) [0.44% of initial]
[Iter 7220/20000] Loss: 0.0009720 (Best: 0.0004584 @iter5797) ([92m↓11.55%[0m) [0.39% of initial]
[Iter 7230/20000] Loss: 0.0008161 (Best: 0.0004584 @iter5797) ([92m↓16.03%[0m) [0.32% of initial]
[Iter 7240/20000] Loss: 0.0007125 (Best: 0.0004584 @iter5797) ([92m↓12.70%[0m) [0.28% of initial]
[Iter 7250/20000] Loss: 0.0006401 (Best: 0.0004584 @iter5797) ([92m↓10.16%[0m) [0.25% of initial]
[Iter 7260/20000] Loss: 0.0006178 (Best: 0.0004584 @iter5797) ([92m↓3.49%[0m) [0.25% of initial]
[Iter 7270/20000] Loss: 0.0005856 (Best: 0.0004584 @iter5797) ([92m↓5.20%[0m) [0.23% of initial]
[Iter 7280/20000] Loss: 0.0005622 (Best: 0.0004584 @iter5797) ([92m↓4.00%[0m) [0.22% of initial]
[Iter 7290/20000] Loss: 0.0005970 (Best: 0.0004584 @iter5797) ([91m↑6.20%[0m) [0.24% of initial]
Iter:7299, L1 loss=0.0007497, Total loss=0.000703, Time:89
[Iter 7300/20000] Loss: 0.0006117 (Best: 0.0004584 @iter5797) ([91m↑2.45%[0m) [0.24% of initial]
[Iter 7310/20000] Loss: 0.0006021 (Best: 0.0004584 @iter5797) ([92m↓1.56%[0m) [0.24% of initial]
[Iter 7320/20000] Loss: 0.0006711 (Best: 0.0004584 @iter5797) ([91m↑11.46%[0m) [0.27% of initial]
[Iter 7330/20000] Loss: 0.0006474 (Best: 0.0004584 @iter5797) ([92m↓3.53%[0m) [0.26% of initial]
[Iter 7340/20000] Loss: 0.0006022 (Best: 0.0004584 @iter5797) ([92m↓6.99%[0m) [0.24% of initial]
[Iter 7350/20000] Loss: 0.0006302 (Best: 0.0004584 @iter5797) ([91m↑4.65%[0m) [0.25% of initial]
[Iter 7360/20000] Loss: 0.0006289 (Best: 0.0004584 @iter5797) ([92m↓0.20%[0m) [0.25% of initial]
[Iter 7370/20000] Loss: 0.0005794 (Best: 0.0004584 @iter5797) ([92m↓7.88%[0m) [0.23% of initial]
[Iter 7380/20000] Loss: 0.0006833 (Best: 0.0004584 @iter5797) ([91m↑17.93%[0m) [0.27% of initial]
[Iter 7390/20000] Loss: 0.0006911 (Best: 0.0004584 @iter5797) ([91m↑1.14%[0m) [0.27% of initial]
Iter:7399, L1 loss=0.0007452, Total loss=0.0006702, Time:82
[Iter 7400/20000] Loss: 0.0007184 (Best: 0.0004584 @iter5797) ([91m↑3.96%[0m) [0.29% of initial]
[Iter 7410/20000] Loss: 0.0010093 (Best: 0.0004584 @iter5797) ([91m↑40.49%[0m) [0.40% of initial]
[Iter 7420/20000] Loss: 0.0008251 (Best: 0.0004584 @iter5797) ([92m↓18.25%[0m) [0.33% of initial]
[Iter 7430/20000] Loss: 0.0007378 (Best: 0.0004584 @iter5797) ([92m↓10.59%[0m) [0.29% of initial]
[Iter 7440/20000] Loss: 0.0006979 (Best: 0.0004584 @iter5797) ([92m↓5.40%[0m) [0.28% of initial]
[Iter 7450/20000] Loss: 0.0006664 (Best: 0.0004584 @iter5797) ([92m↓4.51%[0m) [0.26% of initial]
[Iter 7460/20000] Loss: 0.0006511 (Best: 0.0004584 @iter5797) ([92m↓2.29%[0m) [0.26% of initial]
[Iter 7470/20000] Loss: 0.0006190 (Best: 0.0004584 @iter5797) ([92m↓4.94%[0m) [0.25% of initial]
[Iter 7480/20000] Loss: 0.0005946 (Best: 0.0004584 @iter5797) ([92m↓3.93%[0m) [0.24% of initial]
[Iter 7490/20000] Loss: 0.0005480 (Best: 0.0004584 @iter5797) ([92m↓7.85%[0m) [0.22% of initial]
Iter:7499, L1 loss=0.000621, Total loss=0.0005557, Time:86
[Iter 7500/20000] Loss: 0.0005848 (Best: 0.0004584 @iter5797) ([91m↑6.72%[0m) [0.23% of initial]
Pruning 89 points (0.1%) from gaussian0 at iteration 7500
Pruning 98 points (0.1%) from gaussian1 at iteration 7500
[Iter 7510/20000] Loss: 0.0013203 (Best: 0.0004584 @iter5797) ([91m↑125.76%[0m) [0.52% of initial]
[Iter 7520/20000] Loss: 0.0008992 (Best: 0.0004584 @iter5797) ([92m↓31.89%[0m) [0.36% of initial]
[Iter 7530/20000] Loss: 0.0007248 (Best: 0.0004584 @iter5797) ([92m↓19.39%[0m) [0.29% of initial]
[Iter 7540/20000] Loss: 0.0005656 (Best: 0.0004584 @iter5797) ([92m↓21.97%[0m) [0.22% of initial]
[Iter 7550/20000] Loss: 0.0005604 (Best: 0.0004584 @iter5797) ([92m↓0.92%[0m) [0.22% of initial]
[Iter 7560/20000] Loss: 0.0005520 (Best: 0.0004584 @iter5797) ([92m↓1.50%[0m) [0.22% of initial]
[Iter 7570/20000] Loss: 0.0005707 (Best: 0.0004584 @iter5797) ([91m↑3.39%[0m) [0.23% of initial]
[Iter 7580/20000] Loss: 0.0005734 (Best: 0.0004584 @iter5797) ([91m↑0.48%[0m) [0.23% of initial]
[Iter 7590/20000] Loss: 0.0005906 (Best: 0.0004584 @iter5797) ([91m↑3.01%[0m) [0.23% of initial]
Iter:7599, L1 loss=0.0005914, Total loss=0.0005436, Time:72
[Iter 7600/20000] Loss: 0.0005484 (Best: 0.0004584 @iter5797) ([92m↓7.14%[0m) [0.22% of initial]
[Iter 7610/20000] Loss: 0.0010858 (Best: 0.0004584 @iter5797) ([91m↑97.98%[0m) [0.43% of initial]
[Iter 7620/20000] Loss: 0.0008095 (Best: 0.0004584 @iter5797) ([92m↓25.45%[0m) [0.32% of initial]
[Iter 7630/20000] Loss: 0.0007336 (Best: 0.0004584 @iter5797) ([92m↓9.38%[0m) [0.29% of initial]
[Iter 7640/20000] Loss: 0.0006423 (Best: 0.0004584 @iter5797) ([92m↓12.44%[0m) [0.26% of initial]
[Iter 7650/20000] Loss: 0.0006011 (Best: 0.0004584 @iter5797) ([92m↓6.42%[0m) [0.24% of initial]
[Iter 7660/20000] Loss: 0.0005281 (Best: 0.0004584 @iter5797) ([92m↓12.14%[0m) [0.21% of initial]
[Iter 7670/20000] Loss: 0.0005093 (Best: 0.0004584 @iter5797) ([92m↓3.55%[0m) [0.20% of initial]
[Iter 7680/20000] Loss: 0.0005409 (Best: 0.0004584 @iter5797) ([91m↑6.20%[0m) [0.21% of initial]
[Iter 7690/20000] Loss: 0.0005086 (Best: 0.0004584 @iter5797) ([92m↓5.96%[0m) [0.20% of initial]
Iter:7699, L1 loss=0.0005662, Total loss=0.0005061, Time:74
[Iter 7700/20000] Loss: 0.0005143 (Best: 0.0004584 @iter5797) ([91m↑1.10%[0m) [0.20% of initial]
[Iter 7710/20000] Loss: 0.0005023 (Best: 0.0004584 @iter5797) ([92m↓2.32%[0m) [0.20% of initial]
[Iter 7720/20000] Loss: 0.0004970 (Best: 0.0004427 @iter7714) ([92m↓1.05%[0m) [0.20% of initial]
[Iter 7730/20000] Loss: 0.0005053 (Best: 0.0004427 @iter7714) ([91m↑1.67%[0m) [0.20% of initial]
[Iter 7740/20000] Loss: 0.0005092 (Best: 0.0004427 @iter7714) ([91m↑0.77%[0m) [0.20% of initial]
[Iter 7750/20000] Loss: 0.0005435 (Best: 0.0004427 @iter7714) ([91m↑6.73%[0m) [0.22% of initial]
[Iter 7760/20000] Loss: 0.0005765 (Best: 0.0004427 @iter7714) ([91m↑6.07%[0m) [0.23% of initial]
[Iter 7770/20000] Loss: 0.0005667 (Best: 0.0004427 @iter7714) ([92m↓1.70%[0m) [0.23% of initial]
[Iter 7780/20000] Loss: 0.0005588 (Best: 0.0004427 @iter7714) ([92m↓1.39%[0m) [0.22% of initial]
[Iter 7790/20000] Loss: 0.0005724 (Best: 0.0004427 @iter7714) ([91m↑2.44%[0m) [0.23% of initial]
Iter:7799, L1 loss=0.0005679, Total loss=0.0005162, Time:86
[Iter 7800/20000] Loss: 0.0005679 (Best: 0.0004427 @iter7714) ([92m↓0.79%[0m) [0.23% of initial]
[Iter 7810/20000] Loss: 0.0008991 (Best: 0.0004427 @iter7714) ([91m↑58.31%[0m) [0.36% of initial]
[Iter 7820/20000] Loss: 0.0007530 (Best: 0.0004427 @iter7714) ([92m↓16.24%[0m) [0.30% of initial]
[Iter 7830/20000] Loss: 0.0007095 (Best: 0.0004427 @iter7714) ([92m↓5.78%[0m) [0.28% of initial]
[Iter 7840/20000] Loss: 0.0006585 (Best: 0.0004427 @iter7714) ([92m↓7.19%[0m) [0.26% of initial]
[Iter 7850/20000] Loss: 0.0006382 (Best: 0.0004427 @iter7714) ([92m↓3.08%[0m) [0.25% of initial]
[Iter 7860/20000] Loss: 0.0006420 (Best: 0.0004427 @iter7714) ([91m↑0.59%[0m) [0.26% of initial]
[Iter 7870/20000] Loss: 0.0006055 (Best: 0.0004427 @iter7714) ([92m↓5.68%[0m) [0.24% of initial]
[Iter 7880/20000] Loss: 0.0005609 (Best: 0.0004427 @iter7714) ([92m↓7.37%[0m) [0.22% of initial]
[Iter 7890/20000] Loss: 0.0006122 (Best: 0.0004427 @iter7714) ([91m↑9.15%[0m) [0.24% of initial]
Iter:7899, L1 loss=0.0006366, Total loss=0.0005783, Time:84
[Iter 7900/20000] Loss: 0.0005635 (Best: 0.0004427 @iter7714) ([92m↓7.96%[0m) [0.22% of initial]
[Iter 7910/20000] Loss: 0.0005703 (Best: 0.0004427 @iter7714) ([91m↑1.21%[0m) [0.23% of initial]
[Iter 7920/20000] Loss: 0.0006518 (Best: 0.0004427 @iter7714) ([91m↑14.28%[0m) [0.26% of initial]
[Iter 7930/20000] Loss: 0.0005566 (Best: 0.0004427 @iter7714) ([92m↓14.61%[0m) [0.22% of initial]
[Iter 7940/20000] Loss: 0.0005121 (Best: 0.0004427 @iter7714) ([92m↓7.98%[0m) [0.20% of initial]
[Iter 7950/20000] Loss: 0.0005021 (Best: 0.0004427 @iter7714) ([92m↓1.95%[0m) [0.20% of initial]
[Iter 7960/20000] Loss: 0.0005723 (Best: 0.0004427 @iter7714) ([91m↑13.97%[0m) [0.23% of initial]
[Iter 7970/20000] Loss: 0.0005541 (Best: 0.0004427 @iter7714) ([92m↓3.19%[0m) [0.22% of initial]
[Iter 7980/20000] Loss: 0.0005621 (Best: 0.0004427 @iter7714) ([91m↑1.45%[0m) [0.22% of initial]
[Iter 7990/20000] Loss: 0.0005268 (Best: 0.0004427 @iter7714) ([92m↓6.28%[0m) [0.21% of initial]
Iter:7999, L1 loss=0.0005845, Total loss=0.0005082, Time:88
[Iter 8000/20000] Loss: 0.0005172 (Best: 0.0004427 @iter7714) ([92m↓1.82%[0m) [0.21% of initial]
Pruning 53 points (0.0%) from gaussian0 at iteration 8000
Pruning 100 points (0.1%) from gaussian1 at iteration 8000
[Iter 8010/20000] Loss: 0.0009495 (Best: 0.0004427 @iter7714) ([91m↑83.57%[0m) [0.38% of initial]
[Iter 8020/20000] Loss: 0.0006973 (Best: 0.0004427 @iter7714) ([92m↓26.56%[0m) [0.28% of initial]
[Iter 8030/20000] Loss: 0.0006015 (Best: 0.0004427 @iter7714) ([92m↓13.73%[0m) [0.24% of initial]
[Iter 8040/20000] Loss: 0.0005902 (Best: 0.0004427 @iter7714) ([92m↓1.89%[0m) [0.23% of initial]
[Iter 8050/20000] Loss: 0.0005375 (Best: 0.0004427 @iter7714) ([92m↓8.94%[0m) [0.21% of initial]
[Iter 8060/20000] Loss: 0.0004923 (Best: 0.0004427 @iter7714) ([92m↓8.40%[0m) [0.20% of initial]
[Iter 8070/20000] Loss: 0.0004989 (Best: 0.0004427 @iter7714) ([91m↑1.34%[0m) [0.20% of initial]
[Iter 8080/20000] Loss: 0.0004799 (Best: 0.0004397 @iter8074) ([92m↓3.80%[0m) [0.19% of initial]
[Iter 8090/20000] Loss: 0.0004641 (Best: 0.0004397 @iter8074) ([92m↓3.31%[0m) [0.18% of initial]
Iter:8099, L1 loss=0.0005434, Total loss=0.0004867, Time:74
[Iter 8100/20000] Loss: 0.0004953 (Best: 0.0004242 @iter8092) ([91m↑6.74%[0m) [0.20% of initial]
[Iter 8110/20000] Loss: 0.0005000 (Best: 0.0004242 @iter8092) ([91m↑0.94%[0m) [0.20% of initial]
[Iter 8120/20000] Loss: 0.0004810 (Best: 0.0004242 @iter8092) ([92m↓3.79%[0m) [0.19% of initial]
[Iter 8130/20000] Loss: 0.0005292 (Best: 0.0004242 @iter8092) ([91m↑10.00%[0m) [0.21% of initial]
[Iter 8140/20000] Loss: 0.0005104 (Best: 0.0004242 @iter8092) ([92m↓3.55%[0m) [0.20% of initial]
[Iter 8150/20000] Loss: 0.0005209 (Best: 0.0004242 @iter8092) ([91m↑2.07%[0m) [0.21% of initial]
[Iter 8160/20000] Loss: 0.0005230 (Best: 0.0004242 @iter8092) ([91m↑0.40%[0m) [0.21% of initial]
[Iter 8170/20000] Loss: 0.0005161 (Best: 0.0004242 @iter8092) ([92m↓1.32%[0m) [0.21% of initial]
[Iter 8180/20000] Loss: 0.0005403 (Best: 0.0004242 @iter8092) ([91m↑4.67%[0m) [0.21% of initial]
[Iter 8190/20000] Loss: 0.0005563 (Best: 0.0004242 @iter8092) ([91m↑2.97%[0m) [0.22% of initial]
Iter:8199, L1 loss=0.0006122, Total loss=0.000547, Time:72
[Iter 8200/20000] Loss: 0.0005279 (Best: 0.0004242 @iter8092) ([92m↓5.11%[0m) [0.21% of initial]
[Iter 8210/20000] Loss: 0.0005161 (Best: 0.0004242 @iter8092) ([92m↓2.23%[0m) [0.21% of initial]
[Iter 8220/20000] Loss: 0.0005275 (Best: 0.0004242 @iter8092) ([91m↑2.21%[0m) [0.21% of initial]
[Iter 8230/20000] Loss: 0.0005173 (Best: 0.0004242 @iter8092) ([92m↓1.93%[0m) [0.21% of initial]
[Iter 8240/20000] Loss: 0.0005036 (Best: 0.0004242 @iter8092) ([92m↓2.66%[0m) [0.20% of initial]
[Iter 8250/20000] Loss: 0.0005453 (Best: 0.0004242 @iter8092) ([91m↑8.29%[0m) [0.22% of initial]
[Iter 8260/20000] Loss: 0.0005394 (Best: 0.0004242 @iter8092) ([92m↓1.10%[0m) [0.21% of initial]
[Iter 8270/20000] Loss: 0.0005663 (Best: 0.0004242 @iter8092) ([91m↑4.99%[0m) [0.22% of initial]
[Iter 8280/20000] Loss: 0.0005437 (Best: 0.0004242 @iter8092) ([92m↓3.99%[0m) [0.22% of initial]
[Iter 8290/20000] Loss: 0.0005534 (Best: 0.0004242 @iter8092) ([91m↑1.79%[0m) [0.22% of initial]
Iter:8299, L1 loss=0.0005386, Total loss=0.0004666, Time:67
[Iter 8300/20000] Loss: 0.0005095 (Best: 0.0004242 @iter8092) ([92m↓7.94%[0m) [0.20% of initial]
[Iter 8310/20000] Loss: 0.0005019 (Best: 0.0004242 @iter8092) ([92m↓1.49%[0m) [0.20% of initial]
[Iter 8320/20000] Loss: 0.0004761 (Best: 0.0004242 @iter8092) ([92m↓5.14%[0m) [0.19% of initial]
[Iter 8330/20000] Loss: 0.0004762 (Best: 0.0004242 @iter8092) ([91m↑0.02%[0m) [0.19% of initial]
[Iter 8340/20000] Loss: 0.0005010 (Best: 0.0004242 @iter8092) ([91m↑5.22%[0m) [0.20% of initial]
[Iter 8350/20000] Loss: 0.0004602 (Best: 0.0004242 @iter8092) ([92m↓8.15%[0m) [0.18% of initial]
[Iter 8360/20000] Loss: 0.0004590 (Best: 0.0004242 @iter8092) ([92m↓0.26%[0m) [0.18% of initial]
[Iter 8370/20000] Loss: 0.0004592 (Best: 0.0004242 @iter8092) ([91m↑0.03%[0m) [0.18% of initial]
[Iter 8380/20000] Loss: 0.0004921 (Best: 0.0004242 @iter8092) ([91m↑7.17%[0m) [0.20% of initial]
[Iter 8390/20000] Loss: 0.0004459 (Best: 0.0004242 @iter8092) ([92m↓9.38%[0m) [0.18% of initial]
Iter:8399, L1 loss=0.0005067, Total loss=0.0004565, Time:69
[Iter 8400/20000] Loss: 0.0004819 (Best: 0.0004242 @iter8092) ([91m↑8.07%[0m) [0.19% of initial]
[Iter 8410/20000] Loss: 0.0004566 (Best: 0.0004109 @iter8407) ([92m↓5.25%[0m) [0.18% of initial]
[Iter 8420/20000] Loss: 0.0004593 (Best: 0.0004109 @iter8407) ([91m↑0.59%[0m) [0.18% of initial]
[Iter 8430/20000] Loss: 0.0004865 (Best: 0.0004032 @iter8425) ([91m↑5.93%[0m) [0.19% of initial]
[Iter 8440/20000] Loss: 0.0004711 (Best: 0.0004032 @iter8425) ([92m↓3.16%[0m) [0.19% of initial]
[Iter 8450/20000] Loss: 0.0004958 (Best: 0.0004032 @iter8425) ([91m↑5.25%[0m) [0.20% of initial]
[Iter 8460/20000] Loss: 0.0004767 (Best: 0.0004032 @iter8425) ([92m↓3.87%[0m) [0.19% of initial]
[Iter 8470/20000] Loss: 0.0004836 (Best: 0.0004032 @iter8425) ([91m↑1.45%[0m) [0.19% of initial]
[Iter 8480/20000] Loss: 0.0004643 (Best: 0.0004032 @iter8425) ([92m↓4.00%[0m) [0.18% of initial]
[Iter 8490/20000] Loss: 0.0005044 (Best: 0.0004032 @iter8425) ([91m↑8.66%[0m) [0.20% of initial]
Iter:8499, L1 loss=0.0006161, Total loss=0.0005512, Time:72
[Iter 8500/20000] Loss: 0.0005568 (Best: 0.0004032 @iter8425) ([91m↑10.38%[0m) [0.22% of initial]
Pruning 45 points (0.0%) from gaussian0 at iteration 8500
Pruning 44 points (0.0%) from gaussian1 at iteration 8500
[Iter 8510/20000] Loss: 0.0010167 (Best: 0.0004032 @iter8425) ([91m↑82.61%[0m) [0.40% of initial]
[Iter 8520/20000] Loss: 0.0007200 (Best: 0.0004032 @iter8425) ([92m↓29.18%[0m) [0.29% of initial]
[Iter 8530/20000] Loss: 0.0005681 (Best: 0.0004032 @iter8425) ([92m↓21.10%[0m) [0.23% of initial]
[Iter 8540/20000] Loss: 0.0005089 (Best: 0.0004032 @iter8425) ([92m↓10.42%[0m) [0.20% of initial]
[Iter 8550/20000] Loss: 0.0004865 (Best: 0.0004032 @iter8425) ([92m↓4.40%[0m) [0.19% of initial]
[Iter 8560/20000] Loss: 0.0004672 (Best: 0.0004032 @iter8425) ([92m↓3.96%[0m) [0.19% of initial]
[Iter 8570/20000] Loss: 0.0004575 (Best: 0.0004032 @iter8425) ([92m↓2.09%[0m) [0.18% of initial]
[Iter 8580/20000] Loss: 0.0004584 (Best: 0.0004032 @iter8425) ([91m↑0.21%[0m) [0.18% of initial]
[Iter 8590/20000] Loss: 0.0004474 (Best: 0.0004032 @iter8425) ([92m↓2.40%[0m) [0.18% of initial]
Iter:8599, L1 loss=0.0004589, Total loss=0.0004029, Time:99
[Iter 8600/20000] Loss: 0.0004366 (Best: 0.0004029 @iter8599) ([92m↓2.41%[0m) [0.17% of initial]
[Iter 8610/20000] Loss: 0.0004539 (Best: 0.0004029 @iter8599) ([91m↑3.97%[0m) [0.18% of initial]
[Iter 8620/20000] Loss: 0.0004484 (Best: 0.0004029 @iter8599) ([92m↓1.23%[0m) [0.18% of initial]
[Iter 8630/20000] Loss: 0.0004442 (Best: 0.0004029 @iter8599) ([92m↓0.93%[0m) [0.18% of initial]
[Iter 8640/20000] Loss: 0.0004248 (Best: 0.0003995 @iter8639) ([92m↓4.37%[0m) [0.17% of initial]
[Iter 8650/20000] Loss: 0.0004445 (Best: 0.0003810 @iter8644) ([91m↑4.64%[0m) [0.18% of initial]
[Iter 8660/20000] Loss: 0.0004913 (Best: 0.0003810 @iter8644) ([91m↑10.53%[0m) [0.20% of initial]
[Iter 8670/20000] Loss: 0.0004877 (Best: 0.0003810 @iter8644) ([92m↓0.73%[0m) [0.19% of initial]
[Iter 8680/20000] Loss: 0.0004577 (Best: 0.0003810 @iter8644) ([92m↓6.15%[0m) [0.18% of initial]
[Iter 8690/20000] Loss: 0.0005527 (Best: 0.0003810 @iter8644) ([91m↑20.74%[0m) [0.22% of initial]
Iter:8699, L1 loss=0.0005231, Total loss=0.0004604, Time:70
[Iter 8700/20000] Loss: 0.0004881 (Best: 0.0003810 @iter8644) ([92m↓11.69%[0m) [0.19% of initial]
[Iter 8710/20000] Loss: 0.0004696 (Best: 0.0003810 @iter8644) ([92m↓3.78%[0m) [0.19% of initial]
[Iter 8720/20000] Loss: 0.0004507 (Best: 0.0003810 @iter8644) ([92m↓4.04%[0m) [0.18% of initial]
[Iter 8730/20000] Loss: 0.0004728 (Best: 0.0003810 @iter8644) ([91m↑4.91%[0m) [0.19% of initial]
[Iter 8740/20000] Loss: 0.0004497 (Best: 0.0003810 @iter8644) ([92m↓4.88%[0m) [0.18% of initial]
[Iter 8750/20000] Loss: 0.0005057 (Best: 0.0003810 @iter8644) ([91m↑12.43%[0m) [0.20% of initial]
[Iter 8760/20000] Loss: 0.0004859 (Best: 0.0003810 @iter8644) ([92m↓3.92%[0m) [0.19% of initial]
[Iter 8770/20000] Loss: 0.0005040 (Best: 0.0003810 @iter8644) ([91m↑3.73%[0m) [0.20% of initial]
[Iter 8780/20000] Loss: 0.0004941 (Best: 0.0003810 @iter8644) ([92m↓1.97%[0m) [0.20% of initial]
[Iter 8790/20000] Loss: 0.0004926 (Best: 0.0003810 @iter8644) ([92m↓0.30%[0m) [0.20% of initial]
Iter:8799, L1 loss=0.0006011, Total loss=0.0005271, Time:72
[Iter 8800/20000] Loss: 0.0004740 (Best: 0.0003810 @iter8644) ([92m↓3.77%[0m) [0.19% of initial]
[Iter 8810/20000] Loss: 0.0004318 (Best: 0.0003810 @iter8644) ([92m↓8.91%[0m) [0.17% of initial]
[Iter 8820/20000] Loss: 0.0004854 (Best: 0.0003810 @iter8644) ([91m↑12.42%[0m) [0.19% of initial]
[Iter 8830/20000] Loss: 0.0006332 (Best: 0.0003810 @iter8644) ([91m↑30.45%[0m) [0.25% of initial]
[Iter 8840/20000] Loss: 0.0006145 (Best: 0.0003810 @iter8644) ([92m↓2.96%[0m) [0.24% of initial]
[Iter 8850/20000] Loss: 0.0006645 (Best: 0.0003810 @iter8644) ([91m↑8.13%[0m) [0.26% of initial]
[Iter 8860/20000] Loss: 0.0005524 (Best: 0.0003810 @iter8644) ([92m↓16.86%[0m) [0.22% of initial]
[Iter 8870/20000] Loss: 0.0004967 (Best: 0.0003810 @iter8644) ([92m↓10.09%[0m) [0.20% of initial]
[Iter 8880/20000] Loss: 0.0004570 (Best: 0.0003810 @iter8644) ([92m↓7.99%[0m) [0.18% of initial]
[Iter 8890/20000] Loss: 0.0004278 (Best: 0.0003810 @iter8644) ([92m↓6.40%[0m) [0.17% of initial]
Iter:8899, L1 loss=0.0004811, Total loss=0.0004338, Time:67
[Iter 8900/20000] Loss: 0.0004565 (Best: 0.0003810 @iter8644) ([91m↑6.72%[0m) [0.18% of initial]
[Iter 8910/20000] Loss: 0.0004451 (Best: 0.0003810 @iter8644) ([92m↓2.51%[0m) [0.18% of initial]
[Iter 8920/20000] Loss: 0.0004277 (Best: 0.0003810 @iter8644) ([92m↓3.90%[0m) [0.17% of initial]
[Iter 8930/20000] Loss: 0.0004318 (Best: 0.0003810 @iter8644) ([91m↑0.96%[0m) [0.17% of initial]
[Iter 8940/20000] Loss: 0.0004415 (Best: 0.0003810 @iter8644) ([91m↑2.24%[0m) [0.18% of initial]
[Iter 8950/20000] Loss: 0.0004629 (Best: 0.0003810 @iter8644) ([91m↑4.84%[0m) [0.18% of initial]
[Iter 8960/20000] Loss: 0.0004674 (Best: 0.0003810 @iter8644) ([91m↑0.98%[0m) [0.19% of initial]
[Iter 8970/20000] Loss: 0.0005106 (Best: 0.0003810 @iter8644) ([91m↑9.23%[0m) [0.20% of initial]
[Iter 8980/20000] Loss: 0.0004894 (Best: 0.0003810 @iter8644) ([92m↓4.14%[0m) [0.19% of initial]
[Iter 8990/20000] Loss: 0.0004507 (Best: 0.0003810 @iter8644) ([92m↓7.91%[0m) [0.18% of initial]
Iter:8999, L1 loss=0.00046, Total loss=0.0003989, Time:99
[Iter 9000/20000] Loss: 0.0004369 (Best: 0.0003810 @iter8644) ([92m↓3.06%[0m) [0.17% of initial]
Pruning 40 points (0.0%) from gaussian0 at iteration 9000
Pruning 52 points (0.0%) from gaussian1 at iteration 9000
[Iter 9010/20000] Loss: 0.0007985 (Best: 0.0003810 @iter8644) ([91m↑82.74%[0m) [0.32% of initial]
[Iter 9020/20000] Loss: 0.0006097 (Best: 0.0003810 @iter8644) ([92m↓23.64%[0m) [0.24% of initial]
[Iter 9030/20000] Loss: 0.0005133 (Best: 0.0003810 @iter8644) ([92m↓15.82%[0m) [0.20% of initial]
[Iter 9040/20000] Loss: 0.0004704 (Best: 0.0003810 @iter8644) ([92m↓8.34%[0m) [0.19% of initial]
[Iter 9050/20000] Loss: 0.0004400 (Best: 0.0003810 @iter8644) ([92m↓6.47%[0m) [0.17% of initial]
[Iter 9060/20000] Loss: 0.0004548 (Best: 0.0003810 @iter8644) ([91m↑3.37%[0m) [0.18% of initial]
[Iter 9070/20000] Loss: 0.0004554 (Best: 0.0003810 @iter8644) ([91m↑0.13%[0m) [0.18% of initial]
[Iter 9080/20000] Loss: 0.0004754 (Best: 0.0003810 @iter8644) ([91m↑4.39%[0m) [0.19% of initial]
[Iter 9090/20000] Loss: 0.0004593 (Best: 0.0003810 @iter8644) ([92m↓3.38%[0m) [0.18% of initial]
Iter:9099, L1 loss=0.0005835, Total loss=0.000501, Time:93
[Iter 9100/20000] Loss: 0.0004615 (Best: 0.0003810 @iter8644) ([91m↑0.47%[0m) [0.18% of initial]
[Iter 9110/20000] Loss: 0.0005191 (Best: 0.0003810 @iter8644) ([91m↑12.49%[0m) [0.21% of initial]
[Iter 9120/20000] Loss: 0.0004671 (Best: 0.0003810 @iter8644) ([92m↓10.02%[0m) [0.19% of initial]
[Iter 9130/20000] Loss: 0.0004540 (Best: 0.0003810 @iter8644) ([92m↓2.81%[0m) [0.18% of initial]
[Iter 9140/20000] Loss: 0.0004468 (Best: 0.0003810 @iter8644) ([92m↓1.58%[0m) [0.18% of initial]
[Iter 9150/20000] Loss: 0.0004209 (Best: 0.0003792 @iter9145) ([92m↓5.79%[0m) [0.17% of initial]
[Iter 9160/20000] Loss: 0.0004399 (Best: 0.0003792 @iter9145) ([91m↑4.51%[0m) [0.17% of initial]
[Iter 9170/20000] Loss: 0.0004180 (Best: 0.0003792 @iter9145) ([92m↓4.99%[0m) [0.17% of initial]
[Iter 9180/20000] Loss: 0.0004358 (Best: 0.0003792 @iter9145) ([91m↑4.26%[0m) [0.17% of initial]
[Iter 9190/20000] Loss: 0.0004005 (Best: 0.0003784 @iter9187) ([92m↓8.10%[0m) [0.16% of initial]
Iter:9199, L1 loss=0.0004633, Total loss=0.0004291, Time:89
[Iter 9200/20000] Loss: 0.0004278 (Best: 0.0003784 @iter9187) ([91m↑6.82%[0m) [0.17% of initial]
[Iter 9210/20000] Loss: 0.0004317 (Best: 0.0003784 @iter9187) ([91m↑0.92%[0m) [0.17% of initial]
[Iter 9220/20000] Loss: 0.0004264 (Best: 0.0003784 @iter9187) ([92m↓1.23%[0m) [0.17% of initial]
[Iter 9230/20000] Loss: 0.0004181 (Best: 0.0003647 @iter9223) ([92m↓1.96%[0m) [0.17% of initial]
[Iter 9240/20000] Loss: 0.0004348 (Best: 0.0003647 @iter9223) ([91m↑4.01%[0m) [0.17% of initial]
[Iter 9250/20000] Loss: 0.0004294 (Best: 0.0003647 @iter9223) ([92m↓1.24%[0m) [0.17% of initial]
[Iter 9260/20000] Loss: 0.0004319 (Best: 0.0003647 @iter9223) ([91m↑0.57%[0m) [0.17% of initial]
[Iter 9270/20000] Loss: 0.0004292 (Best: 0.0003647 @iter9223) ([92m↓0.63%[0m) [0.17% of initial]
[Iter 9280/20000] Loss: 0.0004036 (Best: 0.0003647 @iter9223) ([92m↓5.95%[0m) [0.16% of initial]
[Iter 9290/20000] Loss: 0.0004047 (Best: 0.0003647 @iter9223) ([91m↑0.28%[0m) [0.16% of initial]
Iter:9299, L1 loss=0.0004317, Total loss=0.0003832, Time:75
[Iter 9300/20000] Loss: 0.0004295 (Best: 0.0003647 @iter9223) ([91m↑6.12%[0m) [0.17% of initial]
[Iter 9310/20000] Loss: 0.0004333 (Best: 0.0003647 @iter9223) ([91m↑0.89%[0m) [0.17% of initial]
[Iter 9320/20000] Loss: 0.0004438 (Best: 0.0003647 @iter9223) ([91m↑2.41%[0m) [0.18% of initial]
[Iter 9330/20000] Loss: 0.0004836 (Best: 0.0003647 @iter9223) ([91m↑8.97%[0m) [0.19% of initial]
[Iter 9340/20000] Loss: 0.0004752 (Best: 0.0003647 @iter9223) ([92m↓1.74%[0m) [0.19% of initial]
[Iter 9350/20000] Loss: 0.0004433 (Best: 0.0003647 @iter9223) ([92m↓6.71%[0m) [0.18% of initial]
[Iter 9360/20000] Loss: 0.0005037 (Best: 0.0003647 @iter9223) ([91m↑13.62%[0m) [0.20% of initial]
[Iter 9370/20000] Loss: 0.0004482 (Best: 0.0003647 @iter9223) ([92m↓11.01%[0m) [0.18% of initial]
[Iter 9380/20000] Loss: 0.0004937 (Best: 0.0003647 @iter9223) ([91m↑10.14%[0m) [0.20% of initial]
[Iter 9390/20000] Loss: 0.0004848 (Best: 0.0003647 @iter9223) ([92m↓1.81%[0m) [0.19% of initial]
Iter:9399, L1 loss=0.0005854, Total loss=0.0005543, Time:94
[Iter 9400/20000] Loss: 0.0004485 (Best: 0.0003647 @iter9223) ([92m↓7.48%[0m) [0.18% of initial]
[Iter 9410/20000] Loss: 0.0004439 (Best: 0.0003647 @iter9223) ([92m↓1.01%[0m) [0.18% of initial]
[Iter 9420/20000] Loss: 0.0004571 (Best: 0.0003647 @iter9223) ([91m↑2.98%[0m) [0.18% of initial]
[Iter 9430/20000] Loss: 0.0004043 (Best: 0.0003647 @iter9223) ([92m↓11.55%[0m) [0.16% of initial]
[Iter 9440/20000] Loss: 0.0004414 (Best: 0.0003647 @iter9223) ([91m↑9.17%[0m) [0.18% of initial]
[Iter 9450/20000] Loss: 0.0004212 (Best: 0.0003647 @iter9223) ([92m↓4.59%[0m) [0.17% of initial]
[Iter 9460/20000] Loss: 0.0003821 (Best: 0.0003595 @iter9457) ([92m↓9.27%[0m) [0.15% of initial]
[Iter 9470/20000] Loss: 0.0003729 (Best: 0.0003540 @iter9470) ([92m↓2.40%[0m) [0.15% of initial]
[Iter 9480/20000] Loss: 0.0004306 (Best: 0.0003540 @iter9470) ([91m↑15.45%[0m) [0.17% of initial]
[Iter 9490/20000] Loss: 0.0003870 (Best: 0.0003537 @iter9484) ([92m↓10.11%[0m) [0.15% of initial]
Iter:9499, L1 loss=0.0004779, Total loss=0.0003998, Time:96
[Iter 9500/20000] Loss: 0.0003991 (Best: 0.0003537 @iter9484) ([91m↑3.12%[0m) [0.16% of initial]
Pruning 26 points (0.0%) from gaussian0 at iteration 9500
Pruning 29 points (0.0%) from gaussian1 at iteration 9500
[Iter 9510/20000] Loss: 0.0007463 (Best: 0.0003537 @iter9484) ([91m↑86.98%[0m) [0.30% of initial]
[Iter 9520/20000] Loss: 0.0005600 (Best: 0.0003537 @iter9484) ([92m↓24.96%[0m) [0.22% of initial]
[Iter 9530/20000] Loss: 0.0005518 (Best: 0.0003537 @iter9484) ([92m↓1.46%[0m) [0.22% of initial]
[Iter 9540/20000] Loss: 0.0004566 (Best: 0.0003537 @iter9484) ([92m↓17.26%[0m) [0.18% of initial]
[Iter 9550/20000] Loss: 0.0004019 (Best: 0.0003537 @iter9484) ([92m↓11.98%[0m) [0.16% of initial]
[Iter 9560/20000] Loss: 0.0003895 (Best: 0.0003537 @iter9484) ([92m↓3.08%[0m) [0.15% of initial]
[Iter 9570/20000] Loss: 0.0003856 (Best: 0.0003537 @iter9484) ([92m↓1.01%[0m) [0.15% of initial]
[Iter 9580/20000] Loss: 0.0003627 (Best: 0.0003448 @iter9575) ([92m↓5.93%[0m) [0.14% of initial]
[Iter 9590/20000] Loss: 0.0003701 (Best: 0.0003448 @iter9575) ([91m↑2.04%[0m) [0.15% of initial]
Iter:9599, L1 loss=0.0005315, Total loss=0.0004413, Time:96
[Iter 9600/20000] Loss: 0.0003965 (Best: 0.0003448 @iter9575) ([91m↑7.14%[0m) [0.16% of initial]
[Iter 9610/20000] Loss: 0.0003848 (Best: 0.0003448 @iter9575) ([92m↓2.95%[0m) [0.15% of initial]
[Iter 9620/20000] Loss: 0.0003918 (Best: 0.0003448 @iter9575) ([91m↑1.80%[0m) [0.16% of initial]
[Iter 9630/20000] Loss: 0.0003743 (Best: 0.0003343 @iter9628) ([92m↓4.47%[0m) [0.15% of initial]
[Iter 9640/20000] Loss: 0.0003655 (Best: 0.0003340 @iter9638) ([92m↓2.34%[0m) [0.15% of initial]
[Iter 9650/20000] Loss: 0.0004029 (Best: 0.0003340 @iter9638) ([91m↑10.22%[0m) [0.16% of initial]
[Iter 9660/20000] Loss: 0.0003939 (Best: 0.0003340 @iter9638) ([92m↓2.23%[0m) [0.16% of initial]
[Iter 9670/20000] Loss: 0.0004330 (Best: 0.0003340 @iter9638) ([91m↑9.93%[0m) [0.17% of initial]
[Iter 9680/20000] Loss: 0.0004379 (Best: 0.0003340 @iter9638) ([91m↑1.13%[0m) [0.17% of initial]
[Iter 9690/20000] Loss: 0.0004904 (Best: 0.0003340 @iter9638) ([91m↑12.00%[0m) [0.19% of initial]
Iter:9699, L1 loss=0.0006067, Total loss=0.000548, Time:94
[Iter 9700/20000] Loss: 0.0004605 (Best: 0.0003340 @iter9638) ([92m↓6.11%[0m) [0.18% of initial]
[Iter 9710/20000] Loss: 0.0004407 (Best: 0.0003340 @iter9638) ([92m↓4.30%[0m) [0.18% of initial]
[Iter 9720/20000] Loss: 0.0004222 (Best: 0.0003340 @iter9638) ([92m↓4.20%[0m) [0.17% of initial]
[Iter 9730/20000] Loss: 0.0004008 (Best: 0.0003340 @iter9638) ([92m↓5.05%[0m) [0.16% of initial]
[Iter 9740/20000] Loss: 0.0004119 (Best: 0.0003340 @iter9638) ([91m↑2.75%[0m) [0.16% of initial]
[Iter 9750/20000] Loss: 0.0004064 (Best: 0.0003340 @iter9638) ([92m↓1.33%[0m) [0.16% of initial]
[Iter 9760/20000] Loss: 0.0003777 (Best: 0.0003340 @iter9638) ([92m↓7.04%[0m) [0.15% of initial]
[Iter 9770/20000] Loss: 0.0003859 (Best: 0.0003340 @iter9638) ([91m↑2.17%[0m) [0.15% of initial]
[Iter 9780/20000] Loss: 0.0003745 (Best: 0.0003340 @iter9638) ([92m↓2.96%[0m) [0.15% of initial]
[Iter 9790/20000] Loss: 0.0003788 (Best: 0.0003340 @iter9638) ([91m↑1.15%[0m) [0.15% of initial]
Iter:9799, L1 loss=0.0004231, Total loss=0.0004033, Time:98
[Iter 9800/20000] Loss: 0.0004255 (Best: 0.0003340 @iter9638) ([91m↑12.33%[0m) [0.17% of initial]
[Iter 9810/20000] Loss: 0.0003952 (Best: 0.0003340 @iter9638) ([92m↓7.14%[0m) [0.16% of initial]
[Iter 9820/20000] Loss: 0.0003691 (Best: 0.0003340 @iter9638) ([92m↓6.60%[0m) [0.15% of initial]
[Iter 9830/20000] Loss: 0.0003976 (Best: 0.0003340 @iter9638) ([91m↑7.73%[0m) [0.16% of initial]
[Iter 9840/20000] Loss: 0.0004044 (Best: 0.0003340 @iter9638) ([91m↑1.70%[0m) [0.16% of initial]
[Iter 9850/20000] Loss: 0.0003775 (Best: 0.0003340 @iter9638) ([92m↓6.65%[0m) [0.15% of initial]
[Iter 9860/20000] Loss: 0.0003782 (Best: 0.0003340 @iter9638) ([91m↑0.18%[0m) [0.15% of initial]
[Iter 9870/20000] Loss: 0.0004062 (Best: 0.0003340 @iter9638) ([91m↑7.40%[0m) [0.16% of initial]
[Iter 9880/20000] Loss: 0.0004098 (Best: 0.0003340 @iter9638) ([91m↑0.90%[0m) [0.16% of initial]
[Iter 9890/20000] Loss: 0.0004981 (Best: 0.0003340 @iter9638) ([91m↑21.54%[0m) [0.20% of initial]
Iter:9899, L1 loss=0.000557, Total loss=0.0004949, Time:80
[Iter 9900/20000] Loss: 0.0004607 (Best: 0.0003340 @iter9638) ([92m↓7.52%[0m) [0.18% of initial]
[Iter 9910/20000] Loss: 0.0003903 (Best: 0.0003340 @iter9638) ([92m↓15.28%[0m) [0.16% of initial]
[Iter 9920/20000] Loss: 0.0003801 (Best: 0.0003340 @iter9638) ([92m↓2.61%[0m) [0.15% of initial]
[Iter 9930/20000] Loss: 0.0004038 (Best: 0.0003340 @iter9638) ([91m↑6.24%[0m) [0.16% of initial]
[Iter 9940/20000] Loss: 0.0003877 (Best: 0.0003340 @iter9638) ([92m↓4.00%[0m) [0.15% of initial]
[Iter 9950/20000] Loss: 0.0004255 (Best: 0.0003340 @iter9638) ([91m↑9.75%[0m) [0.17% of initial]
[Iter 9960/20000] Loss: 0.0004154 (Best: 0.0003340 @iter9638) ([92m↓2.35%[0m) [0.17% of initial]
[Iter 9970/20000] Loss: 0.0003841 (Best: 0.0003340 @iter9638) ([92m↓7.54%[0m) [0.15% of initial]
[Iter 9980/20000] Loss: 0.0003678 (Best: 0.0003340 @iter9638) ([92m↓4.25%[0m) [0.15% of initial]
[Iter 9990/20000] Loss: 0.0003816 (Best: 0.0003340 @iter9638) ([91m↑3.77%[0m) [0.15% of initial]
Iter:9999, L1 loss=0.0006591, Total loss=0.0004251, Time:83
[Iter 10000/20000] Loss: 0.0004056 (Best: 0.0003340 @iter9638) ([91m↑6.28%[0m) [0.16% of initial]
Pruning 23 points (0.0%) from gaussian0 at iteration 10000
Pruning 28 points (0.0%) from gaussian1 at iteration 10000
[Iter 10010/20000] Loss: 0.0361715 (Best: 0.0003340 @iter9638) ([91m↑8818.20%[0m) [14.37% of initial]
[Iter 10020/20000] Loss: 0.0123289 (Best: 0.0003340 @iter9638) ([92m↓65.92%[0m) [4.90% of initial]
[Iter 10030/20000] Loss: 0.0057464 (Best: 0.0003340 @iter9638) ([92m↓53.39%[0m) [2.28% of initial]
[Iter 10040/20000] Loss: 0.0032077 (Best: 0.0003340 @iter9638) ([92m↓44.18%[0m) [1.27% of initial]
[Iter 10050/20000] Loss: 0.0022476 (Best: 0.0003340 @iter9638) ([92m↓29.93%[0m) [0.89% of initial]
[Iter 10060/20000] Loss: 0.0015566 (Best: 0.0003340 @iter9638) ([92m↓30.75%[0m) [0.62% of initial]
[Iter 10070/20000] Loss: 0.0012307 (Best: 0.0003340 @iter9638) ([92m↓20.93%[0m) [0.49% of initial]
[Iter 10080/20000] Loss: 0.0009841 (Best: 0.0003340 @iter9638) ([92m↓20.04%[0m) [0.39% of initial]
[Iter 10090/20000] Loss: 0.0008653 (Best: 0.0003340 @iter9638) ([92m↓12.08%[0m) [0.34% of initial]
Iter:10099, L1 loss=0.0007275, Total loss=0.000697, Time:101
[Iter 10100/20000] Loss: 0.0007572 (Best: 0.0003340 @iter9638) ([92m↓12.49%[0m) [0.30% of initial]
[Iter 10110/20000] Loss: 0.0006999 (Best: 0.0003340 @iter9638) ([92m↓7.57%[0m) [0.28% of initial]
[Iter 10120/20000] Loss: 0.0006779 (Best: 0.0003340 @iter9638) ([92m↓3.15%[0m) [0.27% of initial]
[Iter 10130/20000] Loss: 0.0006235 (Best: 0.0003340 @iter9638) ([92m↓8.02%[0m) [0.25% of initial]
[Iter 10140/20000] Loss: 0.0006019 (Best: 0.0003340 @iter9638) ([92m↓3.47%[0m) [0.24% of initial]
[Iter 10150/20000] Loss: 0.0005682 (Best: 0.0003340 @iter9638) ([92m↓5.60%[0m) [0.23% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
[Iter 10160/20000] Loss: 0.0005501 (Best: 0.0003340 @iter9638) ([92m↓3.17%[0m) [0.22% of initial]
[Iter 10170/20000] Loss: 0.0005302 (Best: 0.0003340 @iter9638) ([92m↓3.62%[0m) [0.21% of initial]
[Iter 10180/20000] Loss: 0.0005276 (Best: 0.0003340 @iter9638) ([92m↓0.49%[0m) [0.21% of initial]
[Iter 10190/20000] Loss: 0.0005133 (Best: 0.0003340 @iter9638) ([92m↓2.71%[0m) [0.20% of initial]
Iter:10199, L1 loss=0.0005397, Total loss=0.0004912, Time:88
[Iter 10200/20000] Loss: 0.0005257 (Best: 0.0003340 @iter9638) ([91m↑2.43%[0m) [0.21% of initial]
[Iter 10210/20000] Loss: 0.0005112 (Best: 0.0003340 @iter9638) ([92m↓2.76%[0m) [0.20% of initial]
[Iter 10220/20000] Loss: 0.0005019 (Best: 0.0003340 @iter9638) ([92m↓1.82%[0m) [0.20% of initial]
[Iter 10230/20000] Loss: 0.0004899 (Best: 0.0003340 @iter9638) ([92m↓2.39%[0m) [0.19% of initial]
[Iter 10240/20000] Loss: 0.0004735 (Best: 0.0003340 @iter9638) ([92m↓3.37%[0m) [0.19% of initial]
[Iter 10250/20000] Loss: 0.0005072 (Best: 0.0003340 @iter9638) ([91m↑7.14%[0m) [0.20% of initial]
[Iter 10260/20000] Loss: 0.0004944 (Best: 0.0003340 @iter9638) ([92m↓2.53%[0m) [0.20% of initial]
[Iter 10270/20000] Loss: 0.0004671 (Best: 0.0003340 @iter9638) ([92m↓5.53%[0m) [0.19% of initial]
[Iter 10280/20000] Loss: 0.0004875 (Best: 0.0003340 @iter9638) ([91m↑4.37%[0m) [0.19% of initial]
[Iter 10290/20000] Loss: 0.0005273 (Best: 0.0003340 @iter9638) ([91m↑8.16%[0m) [0.21% of initial]
Iter:10299, L1 loss=0.0005379, Total loss=0.0004966, Time:80
[Iter 10300/20000] Loss: 0.0004865 (Best: 0.0003340 @iter9638) ([92m↓7.74%[0m) [0.19% of initial]
[Iter 10310/20000] Loss: 0.0004821 (Best: 0.0003340 @iter9638) ([92m↓0.91%[0m) [0.19% of initial]
[Iter 10320/20000] Loss: 0.0005033 (Best: 0.0003340 @iter9638) ([91m↑4.40%[0m) [0.20% of initial]
[Iter 10330/20000] Loss: 0.0004837 (Best: 0.0003340 @iter9638) ([92m↓3.88%[0m) [0.19% of initial]
[Iter 10340/20000] Loss: 0.0004847 (Best: 0.0003340 @iter9638) ([91m↑0.21%[0m) [0.19% of initial]
[Iter 10350/20000] Loss: 0.0004647 (Best: 0.0003340 @iter9638) ([92m↓4.13%[0m) [0.18% of initial]
[Iter 10360/20000] Loss: 0.0004527 (Best: 0.0003340 @iter9638) ([92m↓2.58%[0m) [0.18% of initial]
[Iter 10370/20000] Loss: 0.0004538 (Best: 0.0003340 @iter9638) ([91m↑0.25%[0m) [0.18% of initial]
[Iter 10380/20000] Loss: 0.0004779 (Best: 0.0003340 @iter9638) ([91m↑5.31%[0m) [0.19% of initial]
[Iter 10390/20000] Loss: 0.0004706 (Best: 0.0003340 @iter9638) ([92m↓1.54%[0m) [0.19% of initial]
Iter:10399, L1 loss=0.0004855, Total loss=0.0004354, Time:95
[Iter 10400/20000] Loss: 0.0004602 (Best: 0.0003340 @iter9638) ([92m↓2.20%[0m) [0.18% of initial]
[Iter 10410/20000] Loss: 0.0004598 (Best: 0.0003340 @iter9638) ([92m↓0.08%[0m) [0.18% of initial]
[Iter 10420/20000] Loss: 0.0004627 (Best: 0.0003340 @iter9638) ([91m↑0.62%[0m) [0.18% of initial]
[Iter 10430/20000] Loss: 0.0004408 (Best: 0.0003340 @iter9638) ([92m↓4.72%[0m) [0.18% of initial]
[Iter 10440/20000] Loss: 0.0004500 (Best: 0.0003340 @iter9638) ([91m↑2.09%[0m) [0.18% of initial]
[Iter 10450/20000] Loss: 0.0004621 (Best: 0.0003340 @iter9638) ([91m↑2.68%[0m) [0.18% of initial]
[Iter 10460/20000] Loss: 0.0004576 (Best: 0.0003340 @iter9638) ([92m↓0.97%[0m) [0.18% of initial]
[Iter 10470/20000] Loss: 0.0004707 (Best: 0.0003340 @iter9638) ([91m↑2.85%[0m) [0.19% of initial]
[Iter 10480/20000] Loss: 0.0004637 (Best: 0.0003340 @iter9638) ([92m↓1.48%[0m) [0.18% of initial]
[Iter 10490/20000] Loss: 0.0004282 (Best: 0.0003340 @iter9638) ([92m↓7.65%[0m) [0.17% of initial]
Iter:10499, L1 loss=0.0004996, Total loss=0.0004544, Time:84
[Iter 10500/20000] Loss: 0.0004643 (Best: 0.0003340 @iter9638) ([91m↑8.43%[0m) [0.18% of initial]
Pruning 42 points (0.0%) from gaussian0 at iteration 10500
Pruning 42 points (0.0%) from gaussian1 at iteration 10500
[Iter 10510/20000] Loss: 0.0009727 (Best: 0.0003340 @iter9638) ([91m↑109.49%[0m) [0.39% of initial]
[Iter 10520/20000] Loss: 0.0006808 (Best: 0.0003340 @iter9638) ([92m↓30.00%[0m) [0.27% of initial]
[Iter 10530/20000] Loss: 0.0005801 (Best: 0.0003340 @iter9638) ([92m↓14.79%[0m) [0.23% of initial]
[Iter 10540/20000] Loss: 0.0005036 (Best: 0.0003340 @iter9638) ([92m↓13.18%[0m) [0.20% of initial]
[Iter 10550/20000] Loss: 0.0004902 (Best: 0.0003340 @iter9638) ([92m↓2.67%[0m) [0.19% of initial]
[Iter 10560/20000] Loss: 0.0004886 (Best: 0.0003340 @iter9638) ([92m↓0.33%[0m) [0.19% of initial]
[Iter 10570/20000] Loss: 0.0004746 (Best: 0.0003340 @iter9638) ([92m↓2.86%[0m) [0.19% of initial]
[Iter 10580/20000] Loss: 0.0004611 (Best: 0.0003340 @iter9638) ([92m↓2.84%[0m) [0.18% of initial]
[Iter 10590/20000] Loss: 0.0004595 (Best: 0.0003340 @iter9638) ([92m↓0.35%[0m) [0.18% of initial]
Iter:10599, L1 loss=0.0005549, Total loss=0.000502, Time:86
[Iter 10600/20000] Loss: 0.0004566 (Best: 0.0003340 @iter9638) ([92m↓0.64%[0m) [0.18% of initial]
[Iter 10610/20000] Loss: 0.0004742 (Best: 0.0003340 @iter9638) ([91m↑3.86%[0m) [0.19% of initial]
[Iter 10620/20000] Loss: 0.0004964 (Best: 0.0003340 @iter9638) ([91m↑4.68%[0m) [0.20% of initial]
[Iter 10630/20000] Loss: 0.0005212 (Best: 0.0003340 @iter9638) ([91m↑5.01%[0m) [0.21% of initial]
[Iter 10640/20000] Loss: 0.0005199 (Best: 0.0003340 @iter9638) ([92m↓0.25%[0m) [0.21% of initial]
[Iter 10650/20000] Loss: 0.0004961 (Best: 0.0003340 @iter9638) ([92m↓4.59%[0m) [0.20% of initial]
[Iter 10660/20000] Loss: 0.0005081 (Best: 0.0003340 @iter9638) ([91m↑2.42%[0m) [0.20% of initial]
[Iter 10670/20000] Loss: 0.0004921 (Best: 0.0003340 @iter9638) ([92m↓3.15%[0m) [0.20% of initial]
[Iter 10680/20000] Loss: 0.0004750 (Best: 0.0003340 @iter9638) ([92m↓3.48%[0m) [0.19% of initial]
[Iter 10690/20000] Loss: 0.0004884 (Best: 0.0003340 @iter9638) ([91m↑2.82%[0m) [0.19% of initial]
Iter:10699, L1 loss=0.0005394, Total loss=0.0004887, Time:73
[Iter 10700/20000] Loss: 0.0004749 (Best: 0.0003340 @iter9638) ([92m↓2.75%[0m) [0.19% of initial]
[Iter 10710/20000] Loss: 0.0005296 (Best: 0.0003340 @iter9638) ([91m↑11.52%[0m) [0.21% of initial]
[Iter 10720/20000] Loss: 0.0005017 (Best: 0.0003340 @iter9638) ([92m↓5.27%[0m) [0.20% of initial]
[Iter 10730/20000] Loss: 0.0004720 (Best: 0.0003340 @iter9638) ([92m↓5.93%[0m) [0.19% of initial]
[Iter 10740/20000] Loss: 0.0004795 (Best: 0.0003340 @iter9638) ([91m↑1.60%[0m) [0.19% of initial]
[Iter 10750/20000] Loss: 0.0004851 (Best: 0.0003340 @iter9638) ([91m↑1.17%[0m) [0.19% of initial]
[Iter 10760/20000] Loss: 0.0004811 (Best: 0.0003340 @iter9638) ([92m↓0.82%[0m) [0.19% of initial]
[Iter 10770/20000] Loss: 0.0005127 (Best: 0.0003340 @iter9638) ([91m↑6.55%[0m) [0.20% of initial]
[Iter 10780/20000] Loss: 0.0004711 (Best: 0.0003340 @iter9638) ([92m↓8.11%[0m) [0.19% of initial]
[Iter 10790/20000] Loss: 0.0004590 (Best: 0.0003340 @iter9638) ([92m↓2.56%[0m) [0.18% of initial]
Iter:10799, L1 loss=0.0005629, Total loss=0.0004969, Time:78
[Iter 10800/20000] Loss: 0.0004862 (Best: 0.0003340 @iter9638) ([91m↑5.91%[0m) [0.19% of initial]
[Iter 10810/20000] Loss: 0.0004499 (Best: 0.0003340 @iter9638) ([92m↓7.45%[0m) [0.18% of initial]
[Iter 10820/20000] Loss: 0.0004411 (Best: 0.0003340 @iter9638) ([92m↓1.97%[0m) [0.18% of initial]
[Iter 10830/20000] Loss: 0.0004657 (Best: 0.0003340 @iter9638) ([91m↑5.59%[0m) [0.19% of initial]
[Iter 10840/20000] Loss: 0.0004431 (Best: 0.0003340 @iter9638) ([92m↓4.86%[0m) [0.18% of initial]
[Iter 10850/20000] Loss: 0.0004165 (Best: 0.0003340 @iter9638) ([92m↓6.01%[0m) [0.17% of initial]
[Iter 10860/20000] Loss: 0.0004453 (Best: 0.0003340 @iter9638) ([91m↑6.91%[0m) [0.18% of initial]
[Iter 10870/20000] Loss: 0.0004446 (Best: 0.0003340 @iter9638) ([92m↓0.15%[0m) [0.18% of initial]
[Iter 10880/20000] Loss: 0.0004491 (Best: 0.0003340 @iter9638) ([91m↑1.01%[0m) [0.18% of initial]
[Iter 10890/20000] Loss: 0.0004349 (Best: 0.0003340 @iter9638) ([92m↓3.16%[0m) [0.17% of initial]
Iter:10899, L1 loss=0.0004746, Total loss=0.0004187, Time:86
[Iter 10900/20000] Loss: 0.0004250 (Best: 0.0003340 @iter9638) ([92m↓2.29%[0m) [0.17% of initial]
[Iter 10910/20000] Loss: 0.0004237 (Best: 0.0003340 @iter9638) ([92m↓0.29%[0m) [0.17% of initial]
[Iter 10920/20000] Loss: 0.0004379 (Best: 0.0003340 @iter9638) ([91m↑3.35%[0m) [0.17% of initial]
[Iter 10930/20000] Loss: 0.0004256 (Best: 0.0003340 @iter9638) ([92m↓2.80%[0m) [0.17% of initial]
[Iter 10940/20000] Loss: 0.0004326 (Best: 0.0003340 @iter9638) ([91m↑1.63%[0m) [0.17% of initial]
[Iter 10950/20000] Loss: 0.0004348 (Best: 0.0003340 @iter9638) ([91m↑0.51%[0m) [0.17% of initial]
[Iter 10960/20000] Loss: 0.0004298 (Best: 0.0003340 @iter9638) ([92m↓1.14%[0m) [0.17% of initial]
[Iter 10970/20000] Loss: 0.0004438 (Best: 0.0003340 @iter9638) ([91m↑3.25%[0m) [0.18% of initial]
[Iter 10980/20000] Loss: 0.0004517 (Best: 0.0003340 @iter9638) ([91m↑1.79%[0m) [0.18% of initial]
[Iter 10990/20000] Loss: 0.0004469 (Best: 0.0003340 @iter9638) ([92m↓1.06%[0m) [0.18% of initial]
Iter:10999, L1 loss=0.0004881, Total loss=0.0004217, Time:75
[Iter 11000/20000] Loss: 0.0004472 (Best: 0.0003340 @iter9638) ([91m↑0.07%[0m) [0.18% of initial]
Pruning 24 points (0.0%) from gaussian0 at iteration 11000
Pruning 35 points (0.0%) from gaussian1 at iteration 11000
[Iter 11010/20000] Loss: 0.0008957 (Best: 0.0003340 @iter9638) ([91m↑100.28%[0m) [0.36% of initial]
[Iter 11020/20000] Loss: 0.0006281 (Best: 0.0003340 @iter9638) ([92m↓29.88%[0m) [0.25% of initial]
[Iter 11030/20000] Loss: 0.0005187 (Best: 0.0003340 @iter9638) ([92m↓17.42%[0m) [0.21% of initial]
[Iter 11040/20000] Loss: 0.0004511 (Best: 0.0003340 @iter9638) ([92m↓13.02%[0m) [0.18% of initial]
[Iter 11050/20000] Loss: 0.0004615 (Best: 0.0003340 @iter9638) ([91m↑2.30%[0m) [0.18% of initial]
[Iter 11060/20000] Loss: 0.0004379 (Best: 0.0003340 @iter9638) ([92m↓5.10%[0m) [0.17% of initial]
[Iter 11070/20000] Loss: 0.0004363 (Best: 0.0003340 @iter9638) ([92m↓0.38%[0m) [0.17% of initial]
[Iter 11080/20000] Loss: 0.0004065 (Best: 0.0003340 @iter9638) ([92m↓6.83%[0m) [0.16% of initial]
[Iter 11090/20000] Loss: 0.0003945 (Best: 0.0003340 @iter9638) ([92m↓2.96%[0m) [0.16% of initial]
Iter:11099, L1 loss=0.0004542, Total loss=0.0004084, Time:73
[Iter 11100/20000] Loss: 0.0004071 (Best: 0.0003340 @iter9638) ([91m↑3.19%[0m) [0.16% of initial]
[Iter 11110/20000] Loss: 0.0004294 (Best: 0.0003340 @iter9638) ([91m↑5.50%[0m) [0.17% of initial]
[Iter 11120/20000] Loss: 0.0004454 (Best: 0.0003340 @iter9638) ([91m↑3.70%[0m) [0.18% of initial]
[Iter 11130/20000] Loss: 0.0004428 (Best: 0.0003340 @iter9638) ([92m↓0.58%[0m) [0.18% of initial]
[Iter 11140/20000] Loss: 0.0004414 (Best: 0.0003340 @iter9638) ([92m↓0.31%[0m) [0.18% of initial]
[Iter 11150/20000] Loss: 0.0004295 (Best: 0.0003340 @iter9638) ([92m↓2.71%[0m) [0.17% of initial]
[Iter 11160/20000] Loss: 0.0004211 (Best: 0.0003340 @iter9638) ([92m↓1.95%[0m) [0.17% of initial]
[Iter 11170/20000] Loss: 0.0004135 (Best: 0.0003340 @iter9638) ([92m↓1.81%[0m) [0.16% of initial]
[Iter 11180/20000] Loss: 0.0004128 (Best: 0.0003340 @iter9638) ([92m↓0.15%[0m) [0.16% of initial]
[Iter 11190/20000] Loss: 0.0004175 (Best: 0.0003340 @iter9638) ([91m↑1.13%[0m) [0.17% of initial]
Iter:11199, L1 loss=0.000487, Total loss=0.0004421, Time:75
[Iter 11200/20000] Loss: 0.0004100 (Best: 0.0003340 @iter9638) ([92m↓1.79%[0m) [0.16% of initial]
[Iter 11210/20000] Loss: 0.0004256 (Best: 0.0003340 @iter9638) ([91m↑3.80%[0m) [0.17% of initial]
[Iter 11220/20000] Loss: 0.0004252 (Best: 0.0003340 @iter9638) ([92m↓0.08%[0m) [0.17% of initial]
[Iter 11230/20000] Loss: 0.0004074 (Best: 0.0003340 @iter9638) ([92m↓4.19%[0m) [0.16% of initial]
[Iter 11240/20000] Loss: 0.0004014 (Best: 0.0003340 @iter9638) ([92m↓1.48%[0m) [0.16% of initial]
[Iter 11250/20000] Loss: 0.0004001 (Best: 0.0003340 @iter9638) ([92m↓0.33%[0m) [0.16% of initial]
[Iter 11260/20000] Loss: 0.0004377 (Best: 0.0003340 @iter9638) ([91m↑9.40%[0m) [0.17% of initial]
[Iter 11270/20000] Loss: 0.0004283 (Best: 0.0003340 @iter9638) ([92m↓2.15%[0m) [0.17% of initial]
[Iter 11280/20000] Loss: 0.0004936 (Best: 0.0003340 @iter9638) ([91m↑15.27%[0m) [0.20% of initial]
[Iter 11290/20000] Loss: 0.0004243 (Best: 0.0003340 @iter9638) ([92m↓14.05%[0m) [0.17% of initial]
Iter:11299, L1 loss=0.0005152, Total loss=0.0004936, Time:74
[Iter 11300/20000] Loss: 0.0004991 (Best: 0.0003340 @iter9638) ([91m↑17.63%[0m) [0.20% of initial]
[Iter 11310/20000] Loss: 0.0005718 (Best: 0.0003340 @iter9638) ([91m↑14.57%[0m) [0.23% of initial]
[Iter 11320/20000] Loss: 0.0005841 (Best: 0.0003340 @iter9638) ([91m↑2.16%[0m) [0.23% of initial]
[Iter 11330/20000] Loss: 0.0005653 (Best: 0.0003340 @iter9638) ([92m↓3.22%[0m) [0.22% of initial]
[Iter 11340/20000] Loss: 0.0005049 (Best: 0.0003340 @iter9638) ([92m↓10.69%[0m) [0.20% of initial]
[Iter 11350/20000] Loss: 0.0004620 (Best: 0.0003340 @iter9638) ([92m↓8.49%[0m) [0.18% of initial]
[Iter 11360/20000] Loss: 0.0004433 (Best: 0.0003340 @iter9638) ([92m↓4.05%[0m) [0.18% of initial]
[Iter 11370/20000] Loss: 0.0004277 (Best: 0.0003340 @iter9638) ([92m↓3.52%[0m) [0.17% of initial]
[Iter 11380/20000] Loss: 0.0004136 (Best: 0.0003340 @iter9638) ([92m↓3.31%[0m) [0.16% of initial]
[Iter 11390/20000] Loss: 0.0004624 (Best: 0.0003340 @iter9638) ([91m↑11.81%[0m) [0.18% of initial]
Iter:11399, L1 loss=0.0004987, Total loss=0.0004247, Time:93
[Iter 11400/20000] Loss: 0.0004374 (Best: 0.0003340 @iter9638) ([92m↓5.43%[0m) [0.17% of initial]
[Iter 11410/20000] Loss: 0.0004217 (Best: 0.0003340 @iter9638) ([92m↓3.57%[0m) [0.17% of initial]
[Iter 11420/20000] Loss: 0.0004322 (Best: 0.0003340 @iter9638) ([91m↑2.47%[0m) [0.17% of initial]
[Iter 11430/20000] Loss: 0.0004171 (Best: 0.0003340 @iter9638) ([92m↓3.49%[0m) [0.17% of initial]
[Iter 11440/20000] Loss: 0.0004390 (Best: 0.0003340 @iter9638) ([91m↑5.25%[0m) [0.17% of initial]
[Iter 11450/20000] Loss: 0.0004486 (Best: 0.0003340 @iter9638) ([91m↑2.19%[0m) [0.18% of initial]
[Iter 11460/20000] Loss: 0.0004207 (Best: 0.0003340 @iter9638) ([92m↓6.22%[0m) [0.17% of initial]
[Iter 11470/20000] Loss: 0.0003987 (Best: 0.0003340 @iter9638) ([92m↓5.22%[0m) [0.16% of initial]
[Iter 11480/20000] Loss: 0.0004100 (Best: 0.0003340 @iter9638) ([91m↑2.83%[0m) [0.16% of initial]
[Iter 11490/20000] Loss: 0.0003947 (Best: 0.0003340 @iter9638) ([92m↓3.73%[0m) [0.16% of initial]
Iter:11499, L1 loss=0.0004219, Total loss=0.0003773, Time:73
[Iter 11500/20000] Loss: 0.0003861 (Best: 0.0003340 @iter9638) ([92m↓2.19%[0m) [0.15% of initial]
Pruning 25 points (0.0%) from gaussian0 at iteration 11500
Pruning 21 points (0.0%) from gaussian1 at iteration 11500
[Iter 11510/20000] Loss: 0.0007119 (Best: 0.0003340 @iter9638) ([91m↑84.41%[0m) [0.28% of initial]
[Iter 11520/20000] Loss: 0.0005403 (Best: 0.0003340 @iter9638) ([92m↓24.10%[0m) [0.21% of initial]
[Iter 11530/20000] Loss: 0.0004580 (Best: 0.0003340 @iter9638) ([92m↓15.23%[0m) [0.18% of initial]
[Iter 11540/20000] Loss: 0.0004243 (Best: 0.0003340 @iter9638) ([92m↓7.36%[0m) [0.17% of initial]
[Iter 11550/20000] Loss: 0.0004209 (Best: 0.0003340 @iter9638) ([92m↓0.82%[0m) [0.17% of initial]
[Iter 11560/20000] Loss: 0.0004093 (Best: 0.0003340 @iter9638) ([92m↓2.76%[0m) [0.16% of initial]
[Iter 11570/20000] Loss: 0.0004040 (Best: 0.0003340 @iter9638) ([92m↓1.28%[0m) [0.16% of initial]
[Iter 11580/20000] Loss: 0.0003771 (Best: 0.0003340 @iter9638) ([92m↓6.67%[0m) [0.15% of initial]
[Iter 11590/20000] Loss: 0.0003809 (Best: 0.0003340 @iter9638) ([91m↑1.02%[0m) [0.15% of initial]
Iter:11599, L1 loss=0.0004216, Total loss=0.0003599, Time:74
[Iter 11600/20000] Loss: 0.0003711 (Best: 0.0003340 @iter9638) ([92m↓2.58%[0m) [0.15% of initial]
[Iter 11610/20000] Loss: 0.0003831 (Best: 0.0003340 @iter9638) ([91m↑3.22%[0m) [0.15% of initial]
[Iter 11620/20000] Loss: 0.0003805 (Best: 0.0003340 @iter9638) ([92m↓0.67%[0m) [0.15% of initial]
[Iter 11630/20000] Loss: 0.0003817 (Best: 0.0003340 @iter9638) ([91m↑0.30%[0m) [0.15% of initial]
[Iter 11640/20000] Loss: 0.0004009 (Best: 0.0003340 @iter9638) ([91m↑5.04%[0m) [0.16% of initial]
[Iter 11650/20000] Loss: 0.0004168 (Best: 0.0003340 @iter9638) ([91m↑3.97%[0m) [0.17% of initial]
[Iter 11660/20000] Loss: 0.0004188 (Best: 0.0003340 @iter9638) ([91m↑0.47%[0m) [0.17% of initial]
[Iter 11670/20000] Loss: 0.0004043 (Best: 0.0003340 @iter9638) ([92m↓3.46%[0m) [0.16% of initial]
[Iter 11680/20000] Loss: 0.0003940 (Best: 0.0003340 @iter9638) ([92m↓2.56%[0m) [0.16% of initial]
[Iter 11690/20000] Loss: 0.0004131 (Best: 0.0003340 @iter9638) ([91m↑4.86%[0m) [0.16% of initial]
Iter:11699, L1 loss=0.0004734, Total loss=0.0004255, Time:64
[Iter 11700/20000] Loss: 0.0004462 (Best: 0.0003340 @iter9638) ([91m↑8.01%[0m) [0.18% of initial]
[Iter 11710/20000] Loss: 0.0004239 (Best: 0.0003340 @iter9638) ([92m↓5.01%[0m) [0.17% of initial]
[Iter 11720/20000] Loss: 0.0004094 (Best: 0.0003340 @iter9638) ([92m↓3.42%[0m) [0.16% of initial]
[Iter 11730/20000] Loss: 0.0004048 (Best: 0.0003340 @iter9638) ([92m↓1.13%[0m) [0.16% of initial]
[Iter 11740/20000] Loss: 0.0003922 (Best: 0.0003340 @iter9638) ([92m↓3.09%[0m) [0.16% of initial]
[Iter 11750/20000] Loss: 0.0003809 (Best: 0.0003340 @iter9638) ([92m↓2.88%[0m) [0.15% of initial]
[Iter 11760/20000] Loss: 0.0003972 (Best: 0.0003340 @iter9638) ([91m↑4.28%[0m) [0.16% of initial]
[Iter 11770/20000] Loss: 0.0003932 (Best: 0.0003340 @iter9638) ([92m↓1.01%[0m) [0.16% of initial]
[Iter 11780/20000] Loss: 0.0004097 (Best: 0.0003340 @iter9638) ([91m↑4.18%[0m) [0.16% of initial]
[Iter 11790/20000] Loss: 0.0003889 (Best: 0.0003340 @iter9638) ([92m↓5.08%[0m) [0.15% of initial]
Iter:11799, L1 loss=0.00047, Total loss=0.000416, Time:54
[Iter 11800/20000] Loss: 0.0004178 (Best: 0.0003340 @iter9638) ([91m↑7.44%[0m) [0.17% of initial]
[Iter 11810/20000] Loss: 0.0003926 (Best: 0.0003340 @iter9638) ([92m↓6.03%[0m) [0.16% of initial]
[Iter 11820/20000] Loss: 0.0003845 (Best: 0.0003340 @iter9638) ([92m↓2.08%[0m) [0.15% of initial]
[Iter 11830/20000] Loss: 0.0003899 (Best: 0.0003340 @iter9638) ([91m↑1.40%[0m) [0.15% of initial]
[Iter 11840/20000] Loss: 0.0004116 (Best: 0.0003340 @iter9638) ([91m↑5.57%[0m) [0.16% of initial]
[Iter 11850/20000] Loss: 0.0004076 (Best: 0.0003340 @iter9638) ([92m↓0.97%[0m) [0.16% of initial]
[Iter 11860/20000] Loss: 0.0004111 (Best: 0.0003340 @iter9638) ([91m↑0.86%[0m) [0.16% of initial]
[Iter 11870/20000] Loss: 0.0004462 (Best: 0.0003340 @iter9638) ([91m↑8.54%[0m) [0.18% of initial]
[Iter 11880/20000] Loss: 0.0004424 (Best: 0.0003340 @iter9638) ([92m↓0.86%[0m) [0.18% of initial]
[Iter 11890/20000] Loss: 0.0004542 (Best: 0.0003340 @iter9638) ([91m↑2.69%[0m) [0.18% of initial]
Iter:11899, L1 loss=0.0005132, Total loss=0.0004355, Time:54
[Iter 11900/20000] Loss: 0.0004083 (Best: 0.0003340 @iter9638) ([92m↓10.11%[0m) [0.16% of initial]
[Iter 11910/20000] Loss: 0.0004058 (Best: 0.0003340 @iter9638) ([92m↓0.62%[0m) [0.16% of initial]
[Iter 11920/20000] Loss: 0.0004013 (Best: 0.0003340 @iter9638) ([92m↓1.10%[0m) [0.16% of initial]
[Iter 11930/20000] Loss: 0.0003973 (Best: 0.0003340 @iter9638) ([92m↓1.00%[0m) [0.16% of initial]
[Iter 11940/20000] Loss: 0.0004417 (Best: 0.0003340 @iter9638) ([91m↑11.17%[0m) [0.18% of initial]
[Iter 11950/20000] Loss: 0.0003991 (Best: 0.0003340 @iter9638) ([92m↓9.65%[0m) [0.16% of initial]
[Iter 11960/20000] Loss: 0.0004279 (Best: 0.0003340 @iter9638) ([91m↑7.23%[0m) [0.17% of initial]
[Iter 11970/20000] Loss: 0.0004854 (Best: 0.0003340 @iter9638) ([91m↑13.44%[0m) [0.19% of initial]
[Iter 11980/20000] Loss: 0.0004367 (Best: 0.0003340 @iter9638) ([92m↓10.04%[0m) [0.17% of initial]
[Iter 11990/20000] Loss: 0.0004299 (Best: 0.0003340 @iter9638) ([92m↓1.56%[0m) [0.17% of initial]
Iter:11999, L1 loss=0.0004724, Total loss=0.0004109, Time:62
[Iter 12000/20000] Loss: 0.0004031 (Best: 0.0003340 @iter9638) ([92m↓6.22%[0m) [0.16% of initial]
Pruning 18 points (0.0%) from gaussian0 at iteration 12000
Pruning 27 points (0.0%) from gaussian1 at iteration 12000
[Iter 12010/20000] Loss: 0.0006525 (Best: 0.0003340 @iter9638) ([91m↑61.86%[0m) [0.26% of initial]
[Iter 12020/20000] Loss: 0.0005050 (Best: 0.0003340 @iter9638) ([92m↓22.61%[0m) [0.20% of initial]
[Iter 12030/20000] Loss: 0.0004291 (Best: 0.0003340 @iter9638) ([92m↓15.03%[0m) [0.17% of initial]
[Iter 12040/20000] Loss: 0.0004006 (Best: 0.0003340 @iter9638) ([92m↓6.63%[0m) [0.16% of initial]
[Iter 12050/20000] Loss: 0.0003878 (Best: 0.0003340 @iter9638) ([92m↓3.21%[0m) [0.15% of initial]
[Iter 12060/20000] Loss: 0.0003638 (Best: 0.0003340 @iter9638) ([92m↓6.19%[0m) [0.14% of initial]
[Iter 12070/20000] Loss: 0.0003608 (Best: 0.0003340 @iter9638) ([92m↓0.81%[0m) [0.14% of initial]
[Iter 12080/20000] Loss: 0.0003636 (Best: 0.0003317 @iter12073) ([91m↑0.77%[0m) [0.14% of initial]
[Iter 12090/20000] Loss: 0.0003707 (Best: 0.0003317 @iter12073) ([91m↑1.93%[0m) [0.15% of initial]
Iter:12099, L1 loss=0.0004187, Total loss=0.0003719, Time:62
[Iter 12100/20000] Loss: 0.0003597 (Best: 0.0003317 @iter12073) ([92m↓2.96%[0m) [0.14% of initial]
[Iter 12110/20000] Loss: 0.0003944 (Best: 0.0003317 @iter12073) ([91m↑9.64%[0m) [0.16% of initial]
[Iter 12120/20000] Loss: 0.0004041 (Best: 0.0003317 @iter12073) ([91m↑2.45%[0m) [0.16% of initial]
[Iter 12130/20000] Loss: 0.0003982 (Best: 0.0003317 @iter12073) ([92m↓1.44%[0m) [0.16% of initial]
[Iter 12140/20000] Loss: 0.0004240 (Best: 0.0003317 @iter12073) ([91m↑6.46%[0m) [0.17% of initial]
[Iter 12150/20000] Loss: 0.0004122 (Best: 0.0003317 @iter12073) ([92m↓2.77%[0m) [0.16% of initial]
[Iter 12160/20000] Loss: 0.0003958 (Best: 0.0003317 @iter12073) ([92m↓3.98%[0m) [0.16% of initial]
[Iter 12170/20000] Loss: 0.0003818 (Best: 0.0003317 @iter12073) ([92m↓3.53%[0m) [0.15% of initial]
[Iter 12180/20000] Loss: 0.0003770 (Best: 0.0003317 @iter12073) ([92m↓1.27%[0m) [0.15% of initial]
[Iter 12190/20000] Loss: 0.0003647 (Best: 0.0003317 @iter12073) ([92m↓3.25%[0m) [0.14% of initial]
Iter:12199, L1 loss=0.0004385, Total loss=0.0003774, Time:67
[Iter 12200/20000] Loss: 0.0003644 (Best: 0.0003317 @iter12073) ([92m↓0.09%[0m) [0.14% of initial]
[Iter 12210/20000] Loss: 0.0003787 (Best: 0.0003317 @iter12073) ([91m↑3.91%[0m) [0.15% of initial]
[Iter 12220/20000] Loss: 0.0003911 (Best: 0.0003317 @iter12073) ([91m↑3.28%[0m) [0.16% of initial]
[Iter 12230/20000] Loss: 0.0004035 (Best: 0.0003317 @iter12073) ([91m↑3.17%[0m) [0.16% of initial]
[Iter 12240/20000] Loss: 0.0003941 (Best: 0.0003317 @iter12073) ([92m↓2.34%[0m) [0.16% of initial]
[Iter 12250/20000] Loss: 0.0004136 (Best: 0.0003317 @iter12073) ([91m↑4.97%[0m) [0.16% of initial]
[Iter 12260/20000] Loss: 0.0004075 (Best: 0.0003317 @iter12073) ([92m↓1.48%[0m) [0.16% of initial]
[Iter 12270/20000] Loss: 0.0003858 (Best: 0.0003317 @iter12073) ([92m↓5.32%[0m) [0.15% of initial]
[Iter 12280/20000] Loss: 0.0003783 (Best: 0.0003317 @iter12073) ([92m↓1.95%[0m) [0.15% of initial]
[Iter 12290/20000] Loss: 0.0004794 (Best: 0.0003317 @iter12073) ([91m↑26.71%[0m) [0.19% of initial]
Iter:12299, L1 loss=0.0004871, Total loss=0.0004425, Time:56
[Iter 12300/20000] Loss: 0.0004643 (Best: 0.0003317 @iter12073) ([92m↓3.15%[0m) [0.18% of initial]
[Iter 12310/20000] Loss: 0.0004807 (Best: 0.0003317 @iter12073) ([91m↑3.53%[0m) [0.19% of initial]
[Iter 12320/20000] Loss: 0.0004258 (Best: 0.0003317 @iter12073) ([92m↓11.41%[0m) [0.17% of initial]
[Iter 12330/20000] Loss: 0.0004212 (Best: 0.0003317 @iter12073) ([92m↓1.10%[0m) [0.17% of initial]
[Iter 12340/20000] Loss: 0.0004377 (Best: 0.0003317 @iter12073) ([91m↑3.93%[0m) [0.17% of initial]
[Iter 12350/20000] Loss: 0.0003864 (Best: 0.0003317 @iter12073) ([92m↓11.71%[0m) [0.15% of initial]
[Iter 12360/20000] Loss: 0.0003861 (Best: 0.0003317 @iter12073) ([92m↓0.10%[0m) [0.15% of initial]
[Iter 12370/20000] Loss: 0.0004276 (Best: 0.0003317 @iter12073) ([91m↑10.76%[0m) [0.17% of initial]
[Iter 12380/20000] Loss: 0.0003825 (Best: 0.0003317 @iter12073) ([92m↓10.55%[0m) [0.15% of initial]
[Iter 12390/20000] Loss: 0.0004005 (Best: 0.0003317 @iter12073) ([91m↑4.71%[0m) [0.16% of initial]
Iter:12399, L1 loss=0.0004732, Total loss=0.0004232, Time:54
[Iter 12400/20000] Loss: 0.0003764 (Best: 0.0003317 @iter12073) ([92m↓6.02%[0m) [0.15% of initial]
[Iter 12410/20000] Loss: 0.0003561 (Best: 0.0003317 @iter12073) ([92m↓5.38%[0m) [0.14% of initial]
[Iter 12420/20000] Loss: 0.0003562 (Best: 0.0003314 @iter12412) ([91m↑0.01%[0m) [0.14% of initial]
[Iter 12430/20000] Loss: 0.0003596 (Best: 0.0003314 @iter12412) ([91m↑0.96%[0m) [0.14% of initial]
[Iter 12440/20000] Loss: 0.0003743 (Best: 0.0003314 @iter12412) ([91m↑4.08%[0m) [0.15% of initial]
[Iter 12450/20000] Loss: 0.0004012 (Best: 0.0003314 @iter12412) ([91m↑7.19%[0m) [0.16% of initial]
[Iter 12460/20000] Loss: 0.0003942 (Best: 0.0003314 @iter12412) ([92m↓1.73%[0m) [0.16% of initial]
[Iter 12470/20000] Loss: 0.0004419 (Best: 0.0003314 @iter12412) ([91m↑12.08%[0m) [0.18% of initial]
[Iter 12480/20000] Loss: 0.0003861 (Best: 0.0003314 @iter12412) ([92m↓12.63%[0m) [0.15% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 12490/20000] Loss: 0.0003484 (Best: 0.0003314 @iter12412) ([92m↓9.74%[0m) [0.14% of initial]
Iter:12499, L1 loss=0.0003724, Total loss=0.0003269, Time:59
[Iter 12500/20000] Loss: 0.0003458 (Best: 0.0003245 @iter12497) ([92m↓0.77%[0m) [0.14% of initial]
Pruning 12 points (0.0%) from gaussian0 at iteration 12500
Pruning 11 points (0.0%) from gaussian1 at iteration 12500
[Iter 12510/20000] Loss: 0.0007227 (Best: 0.0003245 @iter12497) ([91m↑109.02%[0m) [0.29% of initial]
[Iter 12520/20000] Loss: 0.0005173 (Best: 0.0003245 @iter12497) ([92m↓28.42%[0m) [0.21% of initial]
[Iter 12530/20000] Loss: 0.0004053 (Best: 0.0003245 @iter12497) ([92m↓21.66%[0m) [0.16% of initial]
[Iter 12540/20000] Loss: 0.0003696 (Best: 0.0003245 @iter12497) ([92m↓8.79%[0m) [0.15% of initial]
[Iter 12550/20000] Loss: 0.0003703 (Best: 0.0003245 @iter12497) ([91m↑0.18%[0m) [0.15% of initial]
[Iter 12560/20000] Loss: 0.0003589 (Best: 0.0003245 @iter12497) ([92m↓3.09%[0m) [0.14% of initial]
[Iter 12570/20000] Loss: 0.0003775 (Best: 0.0003245 @iter12497) ([91m↑5.19%[0m) [0.15% of initial]
[Iter 12580/20000] Loss: 0.0003447 (Best: 0.0003245 @iter12497) ([92m↓8.69%[0m) [0.14% of initial]
[Iter 12590/20000] Loss: 0.0003355 (Best: 0.0003180 @iter12590) ([92m↓2.65%[0m) [0.13% of initial]
Iter:12599, L1 loss=0.0003608, Total loss=0.0003188, Time:76
[Iter 12600/20000] Loss: 0.0003367 (Best: 0.0003161 @iter12595) ([91m↑0.35%[0m) [0.13% of initial]
[Iter 12610/20000] Loss: 0.0003379 (Best: 0.0003058 @iter12601) ([91m↑0.34%[0m) [0.13% of initial]
[Iter 12620/20000] Loss: 0.0003374 (Best: 0.0003058 @iter12601) ([92m↓0.15%[0m) [0.13% of initial]
[Iter 12630/20000] Loss: 0.0003567 (Best: 0.0003058 @iter12601) ([91m↑5.73%[0m) [0.14% of initial]
[Iter 12640/20000] Loss: 0.0003401 (Best: 0.0003058 @iter12601) ([92m↓4.65%[0m) [0.14% of initial]
[Iter 12650/20000] Loss: 0.0003435 (Best: 0.0003058 @iter12601) ([91m↑1.00%[0m) [0.14% of initial]
[Iter 12660/20000] Loss: 0.0003438 (Best: 0.0003058 @iter12601) ([91m↑0.08%[0m) [0.14% of initial]
[Iter 12670/20000] Loss: 0.0003490 (Best: 0.0003058 @iter12601) ([91m↑1.51%[0m) [0.14% of initial]
[Iter 12680/20000] Loss: 0.0003444 (Best: 0.0003058 @iter12601) ([92m↓1.32%[0m) [0.14% of initial]
[Iter 12690/20000] Loss: 0.0003470 (Best: 0.0003058 @iter12601) ([91m↑0.78%[0m) [0.14% of initial]
Iter:12699, L1 loss=0.0003865, Total loss=0.0003474, Time:62
[Iter 12700/20000] Loss: 0.0003437 (Best: 0.0003058 @iter12601) ([92m↓0.98%[0m) [0.14% of initial]
[Iter 12710/20000] Loss: 0.0003739 (Best: 0.0003058 @iter12601) ([91m↑8.81%[0m) [0.15% of initial]
[Iter 12720/20000] Loss: 0.0003949 (Best: 0.0003058 @iter12601) ([91m↑5.60%[0m) [0.16% of initial]
[Iter 12730/20000] Loss: 0.0003722 (Best: 0.0003058 @iter12601) ([92m↓5.75%[0m) [0.15% of initial]
[Iter 12740/20000] Loss: 0.0003645 (Best: 0.0003058 @iter12601) ([92m↓2.05%[0m) [0.14% of initial]
[Iter 12750/20000] Loss: 0.0003781 (Best: 0.0003058 @iter12601) ([91m↑3.73%[0m) [0.15% of initial]
[Iter 12760/20000] Loss: 0.0003729 (Best: 0.0003058 @iter12601) ([92m↓1.38%[0m) [0.15% of initial]
[Iter 12770/20000] Loss: 0.0003805 (Best: 0.0003058 @iter12601) ([91m↑2.04%[0m) [0.15% of initial]
[Iter 12780/20000] Loss: 0.0003666 (Best: 0.0003058 @iter12601) ([92m↓3.66%[0m) [0.15% of initial]
[Iter 12790/20000] Loss: 0.0003559 (Best: 0.0003058 @iter12601) ([92m↓2.90%[0m) [0.14% of initial]
Iter:12799, L1 loss=0.000389, Total loss=0.0003517, Time:86
[Iter 12800/20000] Loss: 0.0003735 (Best: 0.0003058 @iter12601) ([91m↑4.95%[0m) [0.15% of initial]
[Iter 12810/20000] Loss: 0.0003828 (Best: 0.0003058 @iter12601) ([91m↑2.48%[0m) [0.15% of initial]
[Iter 12820/20000] Loss: 0.0003722 (Best: 0.0003058 @iter12601) ([92m↓2.77%[0m) [0.15% of initial]
[Iter 12830/20000] Loss: 0.0004308 (Best: 0.0003058 @iter12601) ([91m↑15.75%[0m) [0.17% of initial]
[Iter 12840/20000] Loss: 0.0003850 (Best: 0.0003058 @iter12601) ([92m↓10.62%[0m) [0.15% of initial]
[Iter 12850/20000] Loss: 0.0003852 (Best: 0.0003058 @iter12601) ([91m↑0.04%[0m) [0.15% of initial]
[Iter 12860/20000] Loss: 0.0003547 (Best: 0.0003058 @iter12601) ([92m↓7.91%[0m) [0.14% of initial]
[Iter 12870/20000] Loss: 0.0003613 (Best: 0.0003058 @iter12601) ([91m↑1.84%[0m) [0.14% of initial]
[Iter 12880/20000] Loss: 0.0003421 (Best: 0.0003058 @iter12601) ([92m↓5.31%[0m) [0.14% of initial]
[Iter 12890/20000] Loss: 0.0003553 (Best: 0.0003058 @iter12601) ([91m↑3.87%[0m) [0.14% of initial]
Iter:12899, L1 loss=0.0004345, Total loss=0.000373, Time:55
[Iter 12900/20000] Loss: 0.0004175 (Best: 0.0003058 @iter12601) ([91m↑17.48%[0m) [0.17% of initial]
[Iter 12910/20000] Loss: 0.0004298 (Best: 0.0003058 @iter12601) ([91m↑2.96%[0m) [0.17% of initial]
[Iter 12920/20000] Loss: 0.0003793 (Best: 0.0003058 @iter12601) ([92m↓11.76%[0m) [0.15% of initial]
[Iter 12930/20000] Loss: 0.0003849 (Best: 0.0003058 @iter12601) ([91m↑1.49%[0m) [0.15% of initial]
[Iter 12940/20000] Loss: 0.0003884 (Best: 0.0003058 @iter12601) ([91m↑0.91%[0m) [0.15% of initial]
[Iter 12950/20000] Loss: 0.0003779 (Best: 0.0003058 @iter12601) ([92m↓2.70%[0m) [0.15% of initial]
[Iter 12960/20000] Loss: 0.0003795 (Best: 0.0003058 @iter12601) ([91m↑0.41%[0m) [0.15% of initial]
[Iter 12970/20000] Loss: 0.0003660 (Best: 0.0003058 @iter12601) ([92m↓3.57%[0m) [0.15% of initial]
[Iter 12980/20000] Loss: 0.0003641 (Best: 0.0003058 @iter12601) ([92m↓0.52%[0m) [0.14% of initial]
[Iter 12990/20000] Loss: 0.0003625 (Best: 0.0003058 @iter12601) ([92m↓0.42%[0m) [0.14% of initial]
Iter:12999, L1 loss=0.0004675, Total loss=0.0004236, Time:88
[Iter 13000/20000] Loss: 0.0003782 (Best: 0.0003058 @iter12601) ([91m↑4.31%[0m) [0.15% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 13000
Pruning 13 points (0.0%) from gaussian1 at iteration 13000
[Iter 13010/20000] Loss: 0.0006033 (Best: 0.0003058 @iter12601) ([91m↑59.55%[0m) [0.24% of initial]
[Iter 13020/20000] Loss: 0.0004624 (Best: 0.0003058 @iter12601) ([92m↓23.37%[0m) [0.18% of initial]
[Iter 13030/20000] Loss: 0.0003752 (Best: 0.0003058 @iter12601) ([92m↓18.85%[0m) [0.15% of initial]
[Iter 13040/20000] Loss: 0.0003438 (Best: 0.0003058 @iter12601) ([92m↓8.38%[0m) [0.14% of initial]
[Iter 13050/20000] Loss: 0.0003356 (Best: 0.0003058 @iter12601) ([92m↓2.38%[0m) [0.13% of initial]
[Iter 13060/20000] Loss: 0.0003300 (Best: 0.0003031 @iter13054) ([92m↓1.66%[0m) [0.13% of initial]
[Iter 13070/20000] Loss: 0.0003344 (Best: 0.0003031 @iter13054) ([91m↑1.34%[0m) [0.13% of initial]
[Iter 13080/20000] Loss: 0.0003343 (Best: 0.0003031 @iter13054) ([92m↓0.04%[0m) [0.13% of initial]
[Iter 13090/20000] Loss: 0.0003251 (Best: 0.0002972 @iter13087) ([92m↓2.75%[0m) [0.13% of initial]
Iter:13099, L1 loss=0.0003854, Total loss=0.0003303, Time:79
[Iter 13100/20000] Loss: 0.0003418 (Best: 0.0002972 @iter13087) ([91m↑5.14%[0m) [0.14% of initial]
[Iter 13110/20000] Loss: 0.0003490 (Best: 0.0002972 @iter13087) ([91m↑2.09%[0m) [0.14% of initial]
[Iter 13120/20000] Loss: 0.0003337 (Best: 0.0002972 @iter13087) ([92m↓4.38%[0m) [0.13% of initial]
[Iter 13130/20000] Loss: 0.0003688 (Best: 0.0002972 @iter13087) ([91m↑10.52%[0m) [0.15% of initial]
[Iter 13140/20000] Loss: 0.0003679 (Best: 0.0002972 @iter13087) ([92m↓0.25%[0m) [0.15% of initial]
[Iter 13150/20000] Loss: 0.0004448 (Best: 0.0002972 @iter13087) ([91m↑20.91%[0m) [0.18% of initial]
[Iter 13160/20000] Loss: 0.0003840 (Best: 0.0002972 @iter13087) ([92m↓13.67%[0m) [0.15% of initial]
[Iter 13170/20000] Loss: 0.0003534 (Best: 0.0002972 @iter13087) ([92m↓7.98%[0m) [0.14% of initial]
[Iter 13180/20000] Loss: 0.0003664 (Best: 0.0002972 @iter13087) ([91m↑3.69%[0m) [0.15% of initial]
[Iter 13190/20000] Loss: 0.0003469 (Best: 0.0002972 @iter13087) ([92m↓5.31%[0m) [0.14% of initial]
Iter:13199, L1 loss=0.0003745, Total loss=0.0003343, Time:75
[Iter 13200/20000] Loss: 0.0003455 (Best: 0.0002972 @iter13087) ([92m↓0.43%[0m) [0.14% of initial]
[Iter 13210/20000] Loss: 0.0003931 (Best: 0.0002972 @iter13087) ([91m↑13.80%[0m) [0.16% of initial]
[Iter 13220/20000] Loss: 0.0003947 (Best: 0.0002972 @iter13087) ([91m↑0.40%[0m) [0.16% of initial]
[Iter 13230/20000] Loss: 0.0003851 (Best: 0.0002972 @iter13087) ([92m↓2.42%[0m) [0.15% of initial]
[Iter 13240/20000] Loss: 0.0003495 (Best: 0.0002972 @iter13087) ([92m↓9.26%[0m) [0.14% of initial]
[Iter 13250/20000] Loss: 0.0003408 (Best: 0.0002972 @iter13087) ([92m↓2.48%[0m) [0.14% of initial]
[Iter 13260/20000] Loss: 0.0003294 (Best: 0.0002972 @iter13087) ([92m↓3.34%[0m) [0.13% of initial]
[Iter 13270/20000] Loss: 0.0003234 (Best: 0.0002972 @iter13087) ([92m↓1.84%[0m) [0.13% of initial]
[Iter 13280/20000] Loss: 0.0003096 (Best: 0.0002972 @iter13087) ([92m↓4.27%[0m) [0.12% of initial]
[Iter 13290/20000] Loss: 0.0003298 (Best: 0.0002972 @iter13087) ([91m↑6.54%[0m) [0.13% of initial]
Iter:13299, L1 loss=0.0004334, Total loss=0.0003795, Time:61
[Iter 13300/20000] Loss: 0.0003691 (Best: 0.0002972 @iter13087) ([91m↑11.92%[0m) [0.15% of initial]
[Iter 13310/20000] Loss: 0.0003994 (Best: 0.0002972 @iter13087) ([91m↑8.21%[0m) [0.16% of initial]
[Iter 13320/20000] Loss: 0.0003955 (Best: 0.0002972 @iter13087) ([92m↓0.98%[0m) [0.16% of initial]
[Iter 13330/20000] Loss: 0.0003396 (Best: 0.0002972 @iter13087) ([92m↓14.14%[0m) [0.13% of initial]
[Iter 13340/20000] Loss: 0.0003528 (Best: 0.0002972 @iter13087) ([91m↑3.90%[0m) [0.14% of initial]
[Iter 13350/20000] Loss: 0.0003463 (Best: 0.0002972 @iter13087) ([92m↓1.83%[0m) [0.14% of initial]
[Iter 13360/20000] Loss: 0.0003407 (Best: 0.0002972 @iter13087) ([92m↓1.63%[0m) [0.14% of initial]
[Iter 13370/20000] Loss: 0.0003331 (Best: 0.0002972 @iter13087) ([92m↓2.23%[0m) [0.13% of initial]
[Iter 13380/20000] Loss: 0.0003488 (Best: 0.0002972 @iter13087) ([91m↑4.71%[0m) [0.14% of initial]
[Iter 13390/20000] Loss: 0.0003284 (Best: 0.0002972 @iter13087) ([92m↓5.84%[0m) [0.13% of initial]
Iter:13399, L1 loss=0.0003742, Total loss=0.0003391, Time:74
[Iter 13400/20000] Loss: 0.0003331 (Best: 0.0002972 @iter13087) ([91m↑1.42%[0m) [0.13% of initial]
[Iter 13410/20000] Loss: 0.0004679 (Best: 0.0002972 @iter13087) ([91m↑40.47%[0m) [0.19% of initial]
[Iter 13420/20000] Loss: 0.0004666 (Best: 0.0002972 @iter13087) ([92m↓0.29%[0m) [0.19% of initial]
[Iter 13430/20000] Loss: 0.0004282 (Best: 0.0002972 @iter13087) ([92m↓8.24%[0m) [0.17% of initial]
[Iter 13440/20000] Loss: 0.0003962 (Best: 0.0002972 @iter13087) ([92m↓7.46%[0m) [0.16% of initial]
[Iter 13450/20000] Loss: 0.0003528 (Best: 0.0002972 @iter13087) ([92m↓10.96%[0m) [0.14% of initial]
[Iter 13460/20000] Loss: 0.0003557 (Best: 0.0002972 @iter13087) ([91m↑0.82%[0m) [0.14% of initial]
[Iter 13470/20000] Loss: 0.0003345 (Best: 0.0002972 @iter13087) ([92m↓5.98%[0m) [0.13% of initial]
[Iter 13480/20000] Loss: 0.0003813 (Best: 0.0002972 @iter13087) ([91m↑14.00%[0m) [0.15% of initial]
[Iter 13490/20000] Loss: 0.0004272 (Best: 0.0002972 @iter13087) ([91m↑12.03%[0m) [0.17% of initial]
Iter:13499, L1 loss=0.0004187, Total loss=0.0003633, Time:71
[Iter 13500/20000] Loss: 0.0003911 (Best: 0.0002972 @iter13087) ([92m↓8.44%[0m) [0.16% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 13500
Pruning 11 points (0.0%) from gaussian1 at iteration 13500
[Iter 13510/20000] Loss: 0.0007172 (Best: 0.0002972 @iter13087) ([91m↑83.36%[0m) [0.28% of initial]
[Iter 13520/20000] Loss: 0.0004739 (Best: 0.0002972 @iter13087) ([92m↓33.91%[0m) [0.19% of initial]
[Iter 13530/20000] Loss: 0.0003926 (Best: 0.0002972 @iter13087) ([92m↓17.17%[0m) [0.16% of initial]
[Iter 13540/20000] Loss: 0.0003567 (Best: 0.0002972 @iter13087) ([92m↓9.12%[0m) [0.14% of initial]
[Iter 13550/20000] Loss: 0.0003541 (Best: 0.0002972 @iter13087) ([92m↓0.73%[0m) [0.14% of initial]
[Iter 13560/20000] Loss: 0.0003493 (Best: 0.0002972 @iter13087) ([92m↓1.37%[0m) [0.14% of initial]
[Iter 13570/20000] Loss: 0.0003171 (Best: 0.0002972 @iter13087) ([92m↓9.21%[0m) [0.13% of initial]
[Iter 13580/20000] Loss: 0.0003364 (Best: 0.0002972 @iter13087) ([91m↑6.09%[0m) [0.13% of initial]
[Iter 13590/20000] Loss: 0.0002995 (Best: 0.0002906 @iter13590) ([92m↓10.96%[0m) [0.12% of initial]
Iter:13599, L1 loss=0.0003737, Total loss=0.0003168, Time:79
[Iter 13600/20000] Loss: 0.0003052 (Best: 0.0002800 @iter13594) ([91m↑1.89%[0m) [0.12% of initial]
[Iter 13610/20000] Loss: 0.0003007 (Best: 0.0002800 @iter13594) ([92m↓1.46%[0m) [0.12% of initial]
[Iter 13620/20000] Loss: 0.0003121 (Best: 0.0002800 @iter13594) ([91m↑3.77%[0m) [0.12% of initial]
[Iter 13630/20000] Loss: 0.0003172 (Best: 0.0002800 @iter13594) ([91m↑1.63%[0m) [0.13% of initial]
[Iter 13640/20000] Loss: 0.0003162 (Best: 0.0002800 @iter13594) ([92m↓0.32%[0m) [0.13% of initial]
[Iter 13650/20000] Loss: 0.0003218 (Best: 0.0002800 @iter13594) ([91m↑1.77%[0m) [0.13% of initial]
[Iter 13660/20000] Loss: 0.0003226 (Best: 0.0002800 @iter13594) ([91m↑0.25%[0m) [0.13% of initial]
[Iter 13670/20000] Loss: 0.0003168 (Best: 0.0002800 @iter13594) ([92m↓1.78%[0m) [0.13% of initial]
[Iter 13680/20000] Loss: 0.0003494 (Best: 0.0002800 @iter13594) ([91m↑10.27%[0m) [0.14% of initial]
[Iter 13690/20000] Loss: 0.0003707 (Best: 0.0002800 @iter13594) ([91m↑6.12%[0m) [0.15% of initial]
Iter:13699, L1 loss=0.0003736, Total loss=0.0003322, Time:83
[Iter 13700/20000] Loss: 0.0003502 (Best: 0.0002800 @iter13594) ([92m↓5.54%[0m) [0.14% of initial]
[Iter 13710/20000] Loss: 0.0003442 (Best: 0.0002800 @iter13594) ([92m↓1.71%[0m) [0.14% of initial]
[Iter 13720/20000] Loss: 0.0003281 (Best: 0.0002800 @iter13594) ([92m↓4.66%[0m) [0.13% of initial]
[Iter 13730/20000] Loss: 0.0003204 (Best: 0.0002800 @iter13594) ([92m↓2.35%[0m) [0.13% of initial]
[Iter 13740/20000] Loss: 0.0003206 (Best: 0.0002800 @iter13594) ([91m↑0.06%[0m) [0.13% of initial]
[Iter 13750/20000] Loss: 0.0003402 (Best: 0.0002800 @iter13594) ([91m↑6.11%[0m) [0.14% of initial]
[Iter 13760/20000] Loss: 0.0003940 (Best: 0.0002800 @iter13594) ([91m↑15.81%[0m) [0.16% of initial]
[Iter 13770/20000] Loss: 0.0003620 (Best: 0.0002800 @iter13594) ([92m↓8.12%[0m) [0.14% of initial]
[Iter 13780/20000] Loss: 0.0003440 (Best: 0.0002800 @iter13594) ([92m↓4.96%[0m) [0.14% of initial]
[Iter 13790/20000] Loss: 0.0003302 (Best: 0.0002800 @iter13594) ([92m↓4.03%[0m) [0.13% of initial]
Iter:13799, L1 loss=0.0003807, Total loss=0.0003405, Time:70
[Iter 13800/20000] Loss: 0.0003231 (Best: 0.0002800 @iter13594) ([92m↓2.16%[0m) [0.13% of initial]
[Iter 13810/20000] Loss: 0.0003340 (Best: 0.0002800 @iter13594) ([91m↑3.39%[0m) [0.13% of initial]
[Iter 13820/20000] Loss: 0.0003322 (Best: 0.0002800 @iter13594) ([92m↓0.54%[0m) [0.13% of initial]
[Iter 13830/20000] Loss: 0.0004322 (Best: 0.0002800 @iter13594) ([91m↑30.09%[0m) [0.17% of initial]
[Iter 13840/20000] Loss: 0.0004736 (Best: 0.0002800 @iter13594) ([91m↑9.58%[0m) [0.19% of initial]
[Iter 13850/20000] Loss: 0.0004069 (Best: 0.0002800 @iter13594) ([92m↓14.08%[0m) [0.16% of initial]
[Iter 13860/20000] Loss: 0.0003739 (Best: 0.0002800 @iter13594) ([92m↓8.10%[0m) [0.15% of initial]
[Iter 13870/20000] Loss: 0.0003338 (Best: 0.0002800 @iter13594) ([92m↓10.73%[0m) [0.13% of initial]
[Iter 13880/20000] Loss: 0.0003080 (Best: 0.0002800 @iter13594) ([92m↓7.72%[0m) [0.12% of initial]
[Iter 13890/20000] Loss: 0.0003160 (Best: 0.0002800 @iter13594) ([91m↑2.60%[0m) [0.13% of initial]
Iter:13899, L1 loss=0.0003666, Total loss=0.0003135, Time:66
[Iter 13900/20000] Loss: 0.0003010 (Best: 0.0002800 @iter13594) ([92m↓4.76%[0m) [0.12% of initial]
[Iter 13910/20000] Loss: 0.0003115 (Best: 0.0002800 @iter13594) ([91m↑3.50%[0m) [0.12% of initial]
[Iter 13920/20000] Loss: 0.0003377 (Best: 0.0002800 @iter13594) ([91m↑8.40%[0m) [0.13% of initial]
[Iter 13930/20000] Loss: 0.0003514 (Best: 0.0002800 @iter13594) ([91m↑4.07%[0m) [0.14% of initial]
[Iter 13940/20000] Loss: 0.0003256 (Best: 0.0002800 @iter13594) ([92m↓7.34%[0m) [0.13% of initial]
[Iter 13950/20000] Loss: 0.0003324 (Best: 0.0002800 @iter13594) ([91m↑2.10%[0m) [0.13% of initial]
[Iter 13960/20000] Loss: 0.0003239 (Best: 0.0002800 @iter13594) ([92m↓2.57%[0m) [0.13% of initial]
[Iter 13970/20000] Loss: 0.0003155 (Best: 0.0002800 @iter13594) ([92m↓2.60%[0m) [0.13% of initial]
[Iter 13980/20000] Loss: 0.0003512 (Best: 0.0002800 @iter13594) ([91m↑11.33%[0m) [0.14% of initial]
[Iter 13990/20000] Loss: 0.0003292 (Best: 0.0002800 @iter13594) ([92m↓6.25%[0m) [0.13% of initial]
Iter:13999, L1 loss=0.0003664, Total loss=0.0003323, Time:93
[Iter 14000/20000] Loss: 0.0003329 (Best: 0.0002800 @iter13594) ([91m↑1.10%[0m) [0.13% of initial]
Pruning 11 points (0.0%) from gaussian0 at iteration 14000
Pruning 10 points (0.0%) from gaussian1 at iteration 14000
[Iter 14010/20000] Loss: 0.0265617 (Best: 0.0002800 @iter13594) ([91m↑7879.69%[0m) [10.55% of initial]
[Iter 14020/20000] Loss: 0.0080054 (Best: 0.0002800 @iter13594) ([92m↓69.86%[0m) [3.18% of initial]
[Iter 14030/20000] Loss: 0.0051294 (Best: 0.0002800 @iter13594) ([92m↓35.93%[0m) [2.04% of initial]
[Iter 14040/20000] Loss: 0.0027681 (Best: 0.0002800 @iter13594) ([92m↓46.04%[0m) [1.10% of initial]
[Iter 14050/20000] Loss: 0.0017605 (Best: 0.0002800 @iter13594) ([92m↓36.40%[0m) [0.70% of initial]
[Iter 14060/20000] Loss: 0.0013248 (Best: 0.0002800 @iter13594) ([92m↓24.75%[0m) [0.53% of initial]
[Iter 14070/20000] Loss: 0.0010813 (Best: 0.0002800 @iter13594) ([92m↓18.38%[0m) [0.43% of initial]
[Iter 14080/20000] Loss: 0.0009062 (Best: 0.0002800 @iter13594) ([92m↓16.19%[0m) [0.36% of initial]
[Iter 14090/20000] Loss: 0.0007772 (Best: 0.0002800 @iter13594) ([92m↓14.23%[0m) [0.31% of initial]
Iter:14099, L1 loss=0.0007251, Total loss=0.0006873, Time:82
[Iter 14100/20000] Loss: 0.0007025 (Best: 0.0002800 @iter13594) ([92m↓9.61%[0m) [0.28% of initial]
[Iter 14110/20000] Loss: 0.0006315 (Best: 0.0002800 @iter13594) ([92m↓10.10%[0m) [0.25% of initial]
[Iter 14120/20000] Loss: 0.0005894 (Best: 0.0002800 @iter13594) ([92m↓6.66%[0m) [0.23% of initial]
[Iter 14130/20000] Loss: 0.0005680 (Best: 0.0002800 @iter13594) ([92m↓3.64%[0m) [0.23% of initial]
[Iter 14140/20000] Loss: 0.0005324 (Best: 0.0002800 @iter13594) ([92m↓6.26%[0m) [0.21% of initial]
[Iter 14150/20000] Loss: 0.0005118 (Best: 0.0002800 @iter13594) ([92m↓3.86%[0m) [0.20% of initial]
[Iter 14160/20000] Loss: 0.0004980 (Best: 0.0002800 @iter13594) ([92m↓2.70%[0m) [0.20% of initial]
[Iter 14170/20000] Loss: 0.0004724 (Best: 0.0002800 @iter13594) ([92m↓5.15%[0m) [0.19% of initial]
[Iter 14180/20000] Loss: 0.0004557 (Best: 0.0002800 @iter13594) ([92m↓3.54%[0m) [0.18% of initial]
[Iter 14190/20000] Loss: 0.0004497 (Best: 0.0002800 @iter13594) ([92m↓1.31%[0m) [0.18% of initial]
Iter:14199, L1 loss=0.0004692, Total loss=0.0004301, Time:65
[Iter 14200/20000] Loss: 0.0004296 (Best: 0.0002800 @iter13594) ([92m↓4.46%[0m) [0.17% of initial]
[Iter 14210/20000] Loss: 0.0004402 (Best: 0.0002800 @iter13594) ([91m↑2.47%[0m) [0.17% of initial]
[Iter 14220/20000] Loss: 0.0004394 (Best: 0.0002800 @iter13594) ([92m↓0.18%[0m) [0.17% of initial]
[Iter 14230/20000] Loss: 0.0004387 (Best: 0.0002800 @iter13594) ([92m↓0.17%[0m) [0.17% of initial]
[Iter 14240/20000] Loss: 0.0004318 (Best: 0.0002800 @iter13594) ([92m↓1.57%[0m) [0.17% of initial]
[Iter 14250/20000] Loss: 0.0004261 (Best: 0.0002800 @iter13594) ([92m↓1.33%[0m) [0.17% of initial]
[Iter 14260/20000] Loss: 0.0004191 (Best: 0.0002800 @iter13594) ([92m↓1.64%[0m) [0.17% of initial]
[Iter 14270/20000] Loss: 0.0004224 (Best: 0.0002800 @iter13594) ([91m↑0.78%[0m) [0.17% of initial]
[Iter 14280/20000] Loss: 0.0004174 (Best: 0.0002800 @iter13594) ([92m↓1.17%[0m) [0.17% of initial]
[Iter 14290/20000] Loss: 0.0004232 (Best: 0.0002800 @iter13594) ([91m↑1.38%[0m) [0.17% of initial]
Iter:14299, L1 loss=0.0004451, Total loss=0.0004023, Time:85
[Iter 14300/20000] Loss: 0.0004033 (Best: 0.0002800 @iter13594) ([92m↓4.69%[0m) [0.16% of initial]
[Iter 14310/20000] Loss: 0.0004163 (Best: 0.0002800 @iter13594) ([91m↑3.21%[0m) [0.17% of initial]
[Iter 14320/20000] Loss: 0.0004102 (Best: 0.0002800 @iter13594) ([92m↓1.47%[0m) [0.16% of initial]
[Iter 14330/20000] Loss: 0.0004090 (Best: 0.0002800 @iter13594) ([92m↓0.29%[0m) [0.16% of initial]
[Iter 14340/20000] Loss: 0.0004319 (Best: 0.0002800 @iter13594) ([91m↑5.61%[0m) [0.17% of initial]
[Iter 14350/20000] Loss: 0.0004195 (Best: 0.0002800 @iter13594) ([92m↓2.87%[0m) [0.17% of initial]
[Iter 14360/20000] Loss: 0.0004176 (Best: 0.0002800 @iter13594) ([92m↓0.45%[0m) [0.17% of initial]
[Iter 14370/20000] Loss: 0.0004324 (Best: 0.0002800 @iter13594) ([91m↑3.56%[0m) [0.17% of initial]
[Iter 14380/20000] Loss: 0.0004512 (Best: 0.0002800 @iter13594) ([91m↑4.35%[0m) [0.18% of initial]
[Iter 14390/20000] Loss: 0.0005931 (Best: 0.0002800 @iter13594) ([91m↑31.45%[0m) [0.24% of initial]
Iter:14399, L1 loss=0.0004474, Total loss=0.0004128, Time:85
[Iter 14400/20000] Loss: 0.0004689 (Best: 0.0002800 @iter13594) ([92m↓20.96%[0m) [0.19% of initial]
[Iter 14410/20000] Loss: 0.0004296 (Best: 0.0002800 @iter13594) ([92m↓8.37%[0m) [0.17% of initial]
[Iter 14420/20000] Loss: 0.0004150 (Best: 0.0002800 @iter13594) ([92m↓3.40%[0m) [0.16% of initial]
[Iter 14430/20000] Loss: 0.0004114 (Best: 0.0002800 @iter13594) ([92m↓0.86%[0m) [0.16% of initial]
[Iter 14440/20000] Loss: 0.0003874 (Best: 0.0002800 @iter13594) ([92m↓5.83%[0m) [0.15% of initial]
[Iter 14450/20000] Loss: 0.0003874 (Best: 0.0002800 @iter13594) ([92m↓0.02%[0m) [0.15% of initial]
[Iter 14460/20000] Loss: 0.0003945 (Best: 0.0002800 @iter13594) ([91m↑1.83%[0m) [0.16% of initial]
[Iter 14470/20000] Loss: 0.0004153 (Best: 0.0002800 @iter13594) ([91m↑5.27%[0m) [0.16% of initial]
[Iter 14480/20000] Loss: 0.0004006 (Best: 0.0002800 @iter13594) ([92m↓3.53%[0m) [0.16% of initial]
[Iter 14490/20000] Loss: 0.0004040 (Best: 0.0002800 @iter13594) ([91m↑0.86%[0m) [0.16% of initial]
Iter:14499, L1 loss=0.0004799, Total loss=0.0004033, Time:83
[Iter 14500/20000] Loss: 0.0004207 (Best: 0.0002800 @iter13594) ([91m↑4.14%[0m) [0.17% of initial]
Pruning 14 points (0.0%) from gaussian0 at iteration 14500
Pruning 21 points (0.0%) from gaussian1 at iteration 14500
[Iter 14510/20000] Loss: 0.0007899 (Best: 0.0002800 @iter13594) ([91m↑87.73%[0m) [0.31% of initial]
[Iter 14520/20000] Loss: 0.0005760 (Best: 0.0002800 @iter13594) ([92m↓27.08%[0m) [0.23% of initial]
[Iter 14530/20000] Loss: 0.0004607 (Best: 0.0002800 @iter13594) ([92m↓20.01%[0m) [0.18% of initial]
[Iter 14540/20000] Loss: 0.0003938 (Best: 0.0002800 @iter13594) ([92m↓14.52%[0m) [0.16% of initial]
[Iter 14550/20000] Loss: 0.0003900 (Best: 0.0002800 @iter13594) ([92m↓0.96%[0m) [0.15% of initial]
[Iter 14560/20000] Loss: 0.0003738 (Best: 0.0002800 @iter13594) ([92m↓4.17%[0m) [0.15% of initial]
[Iter 14570/20000] Loss: 0.0003747 (Best: 0.0002800 @iter13594) ([91m↑0.24%[0m) [0.15% of initial]
[Iter 14580/20000] Loss: 0.0003779 (Best: 0.0002800 @iter13594) ([91m↑0.87%[0m) [0.15% of initial]
[Iter 14590/20000] Loss: 0.0003772 (Best: 0.0002800 @iter13594) ([92m↓0.19%[0m) [0.15% of initial]
Iter:14599, L1 loss=0.000449, Total loss=0.0003686, Time:76
[Iter 14600/20000] Loss: 0.0003802 (Best: 0.0002800 @iter13594) ([91m↑0.81%[0m) [0.15% of initial]
[Iter 14610/20000] Loss: 0.0003954 (Best: 0.0002800 @iter13594) ([91m↑4.00%[0m) [0.16% of initial]
[Iter 14620/20000] Loss: 0.0003815 (Best: 0.0002800 @iter13594) ([92m↓3.51%[0m) [0.15% of initial]
[Iter 14630/20000] Loss: 0.0003941 (Best: 0.0002800 @iter13594) ([91m↑3.29%[0m) [0.16% of initial]
[Iter 14640/20000] Loss: 0.0003857 (Best: 0.0002800 @iter13594) ([92m↓2.12%[0m) [0.15% of initial]
[Iter 14650/20000] Loss: 0.0003883 (Best: 0.0002800 @iter13594) ([91m↑0.66%[0m) [0.15% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
[Iter 14660/20000] Loss: 0.0004181 (Best: 0.0002800 @iter13594) ([91m↑7.67%[0m) [0.17% of initial]
[Iter 14670/20000] Loss: 0.0004351 (Best: 0.0002800 @iter13594) ([91m↑4.08%[0m) [0.17% of initial]
[Iter 14680/20000] Loss: 0.0003951 (Best: 0.0002800 @iter13594) ([92m↓9.20%[0m) [0.16% of initial]
[Iter 14690/20000] Loss: 0.0004302 (Best: 0.0002800 @iter13594) ([91m↑8.90%[0m) [0.17% of initial]
Iter:14699, L1 loss=0.0004429, Total loss=0.0003994, Time:53
[Iter 14700/20000] Loss: 0.0004256 (Best: 0.0002800 @iter13594) ([92m↓1.08%[0m) [0.17% of initial]
[Iter 14710/20000] Loss: 0.0004232 (Best: 0.0002800 @iter13594) ([92m↓0.57%[0m) [0.17% of initial]
[Iter 14720/20000] Loss: 0.0004620 (Best: 0.0002800 @iter13594) ([91m↑9.17%[0m) [0.18% of initial]
[Iter 14730/20000] Loss: 0.0004457 (Best: 0.0002800 @iter13594) ([92m↓3.52%[0m) [0.18% of initial]
[Iter 14740/20000] Loss: 0.0004342 (Best: 0.0002800 @iter13594) ([92m↓2.59%[0m) [0.17% of initial]
[Iter 14750/20000] Loss: 0.0004416 (Best: 0.0002800 @iter13594) ([91m↑1.70%[0m) [0.18% of initial]
[Iter 14760/20000] Loss: 0.0004429 (Best: 0.0002800 @iter13594) ([91m↑0.29%[0m) [0.18% of initial]
[Iter 14770/20000] Loss: 0.0004723 (Best: 0.0002800 @iter13594) ([91m↑6.65%[0m) [0.19% of initial]
[Iter 14780/20000] Loss: 0.0004004 (Best: 0.0002800 @iter13594) ([92m↓15.24%[0m) [0.16% of initial]
[Iter 14790/20000] Loss: 0.0003929 (Best: 0.0002800 @iter13594) ([92m↓1.86%[0m) [0.16% of initial]
Iter:14799, L1 loss=0.0004276, Total loss=0.0003918, Time:81
[Iter 14800/20000] Loss: 0.0003895 (Best: 0.0002800 @iter13594) ([92m↓0.88%[0m) [0.15% of initial]
[Iter 14810/20000] Loss: 0.0003677 (Best: 0.0002800 @iter13594) ([92m↓5.58%[0m) [0.15% of initial]
[Iter 14820/20000] Loss: 0.0003738 (Best: 0.0002800 @iter13594) ([91m↑1.65%[0m) [0.15% of initial]
[Iter 14830/20000] Loss: 0.0003615 (Best: 0.0002800 @iter13594) ([92m↓3.28%[0m) [0.14% of initial]
[Iter 14840/20000] Loss: 0.0003606 (Best: 0.0002800 @iter13594) ([92m↓0.27%[0m) [0.14% of initial]
[Iter 14850/20000] Loss: 0.0003673 (Best: 0.0002800 @iter13594) ([91m↑1.88%[0m) [0.15% of initial]
[Iter 14860/20000] Loss: 0.0003633 (Best: 0.0002800 @iter13594) ([92m↓1.11%[0m) [0.14% of initial]
[Iter 14870/20000] Loss: 0.0003651 (Best: 0.0002800 @iter13594) ([91m↑0.52%[0m) [0.15% of initial]
[Iter 14880/20000] Loss: 0.0003666 (Best: 0.0002800 @iter13594) ([91m↑0.39%[0m) [0.15% of initial]
[Iter 14890/20000] Loss: 0.0003714 (Best: 0.0002800 @iter13594) ([91m↑1.32%[0m) [0.15% of initial]
Iter:14899, L1 loss=0.000437, Total loss=0.0003971, Time:65
[Iter 14900/20000] Loss: 0.0004052 (Best: 0.0002800 @iter13594) ([91m↑9.10%[0m) [0.16% of initial]
[Iter 14910/20000] Loss: 0.0004321 (Best: 0.0002800 @iter13594) ([91m↑6.63%[0m) [0.17% of initial]
[Iter 14920/20000] Loss: 0.0004446 (Best: 0.0002800 @iter13594) ([91m↑2.88%[0m) [0.18% of initial]
[Iter 14930/20000] Loss: 0.0004470 (Best: 0.0002800 @iter13594) ([91m↑0.55%[0m) [0.18% of initial]
[Iter 14940/20000] Loss: 0.0004313 (Best: 0.0002800 @iter13594) ([92m↓3.52%[0m) [0.17% of initial]
[Iter 14950/20000] Loss: 0.0003891 (Best: 0.0002800 @iter13594) ([92m↓9.78%[0m) [0.15% of initial]
[Iter 14960/20000] Loss: 0.0003820 (Best: 0.0002800 @iter13594) ([92m↓1.82%[0m) [0.15% of initial]
[Iter 14970/20000] Loss: 0.0004115 (Best: 0.0002800 @iter13594) ([91m↑7.71%[0m) [0.16% of initial]
[Iter 14980/20000] Loss: 0.0004850 (Best: 0.0002800 @iter13594) ([91m↑17.88%[0m) [0.19% of initial]
[Iter 14990/20000] Loss: 0.0004410 (Best: 0.0002800 @iter13594) ([92m↓9.08%[0m) [0.18% of initial]
Iter:14999, L1 loss=0.0004457, Total loss=0.0004118, Time:88
[Iter 15000/20000] Loss: 0.0004188 (Best: 0.0002800 @iter13594) ([92m↓5.04%[0m) [0.17% of initial]
Pruning 6 points (0.0%) from gaussian0 at iteration 15000
Pruning 9 points (0.0%) from gaussian1 at iteration 15000
[Iter 15010/20000] Loss: 0.0007185 (Best: 0.0002800 @iter13594) ([91m↑71.58%[0m) [0.29% of initial]
[Iter 15020/20000] Loss: 0.0004755 (Best: 0.0002800 @iter13594) ([92m↓33.82%[0m) [0.19% of initial]
[Iter 15030/20000] Loss: 0.0004142 (Best: 0.0002800 @iter13594) ([92m↓12.89%[0m) [0.16% of initial]
[Iter 15040/20000] Loss: 0.0003955 (Best: 0.0002800 @iter13594) ([92m↓4.51%[0m) [0.16% of initial]
[Iter 15050/20000] Loss: 0.0003729 (Best: 0.0002800 @iter13594) ([92m↓5.73%[0m) [0.15% of initial]
[Iter 15060/20000] Loss: 0.0003558 (Best: 0.0002800 @iter13594) ([92m↓4.57%[0m) [0.14% of initial]
[Iter 15070/20000] Loss: 0.0003564 (Best: 0.0002800 @iter13594) ([91m↑0.14%[0m) [0.14% of initial]
[Iter 15080/20000] Loss: 0.0003498 (Best: 0.0002800 @iter13594) ([92m↓1.85%[0m) [0.14% of initial]
[Iter 15090/20000] Loss: 0.0003651 (Best: 0.0002800 @iter13594) ([91m↑4.39%[0m) [0.15% of initial]
Iter:15099, L1 loss=0.0004665, Total loss=0.0003875, Time:83
[Iter 15100/20000] Loss: 0.0003727 (Best: 0.0002800 @iter13594) ([91m↑2.07%[0m) [0.15% of initial]
[Iter 15110/20000] Loss: 0.0003754 (Best: 0.0002800 @iter13594) ([91m↑0.75%[0m) [0.15% of initial]
[Iter 15120/20000] Loss: 0.0003722 (Best: 0.0002800 @iter13594) ([92m↓0.87%[0m) [0.15% of initial]
[Iter 15130/20000] Loss: 0.0003774 (Best: 0.0002800 @iter13594) ([91m↑1.41%[0m) [0.15% of initial]
[Iter 15140/20000] Loss: 0.0003883 (Best: 0.0002800 @iter13594) ([91m↑2.88%[0m) [0.15% of initial]
[Iter 15150/20000] Loss: 0.0003814 (Best: 0.0002800 @iter13594) ([92m↓1.77%[0m) [0.15% of initial]
[Iter 15160/20000] Loss: 0.0003616 (Best: 0.0002800 @iter13594) ([92m↓5.20%[0m) [0.14% of initial]
[Iter 15170/20000] Loss: 0.0003525 (Best: 0.0002800 @iter13594) ([92m↓2.49%[0m) [0.14% of initial]
[Iter 15180/20000] Loss: 0.0003726 (Best: 0.0002800 @iter13594) ([91m↑5.68%[0m) [0.15% of initial]
[Iter 15190/20000] Loss: 0.0003842 (Best: 0.0002800 @iter13594) ([91m↑3.13%[0m) [0.15% of initial]
Iter:15199, L1 loss=0.0004278, Total loss=0.0003763, Time:57
[Iter 15200/20000] Loss: 0.0003734 (Best: 0.0002800 @iter13594) ([92m↓2.83%[0m) [0.15% of initial]
[Iter 15210/20000] Loss: 0.0003736 (Best: 0.0002800 @iter13594) ([91m↑0.06%[0m) [0.15% of initial]
[Iter 15220/20000] Loss: 0.0003635 (Best: 0.0002800 @iter13594) ([92m↓2.70%[0m) [0.14% of initial]
[Iter 15230/20000] Loss: 0.0003694 (Best: 0.0002800 @iter13594) ([91m↑1.64%[0m) [0.15% of initial]
[Iter 15240/20000] Loss: 0.0003805 (Best: 0.0002800 @iter13594) ([91m↑3.01%[0m) [0.15% of initial]
[Iter 15250/20000] Loss: 0.0003753 (Best: 0.0002800 @iter13594) ([92m↓1.38%[0m) [0.15% of initial]
[Iter 15260/20000] Loss: 0.0003775 (Best: 0.0002800 @iter13594) ([91m↑0.61%[0m) [0.15% of initial]
[Iter 15270/20000] Loss: 0.0003904 (Best: 0.0002800 @iter13594) ([91m↑3.41%[0m) [0.16% of initial]
[Iter 15280/20000] Loss: 0.0004498 (Best: 0.0002800 @iter13594) ([91m↑15.20%[0m) [0.18% of initial]
[Iter 15290/20000] Loss: 0.0004009 (Best: 0.0002800 @iter13594) ([92m↓10.86%[0m) [0.16% of initial]
Iter:15299, L1 loss=0.0004108, Total loss=0.0003602, Time:72
[Iter 15300/20000] Loss: 0.0003828 (Best: 0.0002800 @iter13594) ([92m↓4.53%[0m) [0.15% of initial]
[Iter 15310/20000] Loss: 0.0003597 (Best: 0.0002800 @iter13594) ([92m↓6.02%[0m) [0.14% of initial]
[Iter 15320/20000] Loss: 0.0003468 (Best: 0.0002800 @iter13594) ([92m↓3.61%[0m) [0.14% of initial]
[Iter 15330/20000] Loss: 0.0003723 (Best: 0.0002800 @iter13594) ([91m↑7.36%[0m) [0.15% of initial]
[Iter 15340/20000] Loss: 0.0003933 (Best: 0.0002800 @iter13594) ([91m↑5.64%[0m) [0.16% of initial]
[Iter 15350/20000] Loss: 0.0003772 (Best: 0.0002800 @iter13594) ([92m↓4.09%[0m) [0.15% of initial]
[Iter 15360/20000] Loss: 0.0003749 (Best: 0.0002800 @iter13594) ([92m↓0.59%[0m) [0.15% of initial]
[Iter 15370/20000] Loss: 0.0003734 (Best: 0.0002800 @iter13594) ([92m↓0.41%[0m) [0.15% of initial]
[Iter 15380/20000] Loss: 0.0003564 (Best: 0.0002800 @iter13594) ([92m↓4.54%[0m) [0.14% of initial]
[Iter 15390/20000] Loss: 0.0003638 (Best: 0.0002800 @iter13594) ([91m↑2.06%[0m) [0.14% of initial]
Iter:15399, L1 loss=0.0004809, Total loss=0.0003701, Time:82
[Iter 15400/20000] Loss: 0.0003754 (Best: 0.0002800 @iter13594) ([91m↑3.20%[0m) [0.15% of initial]
[Iter 15410/20000] Loss: 0.0003686 (Best: 0.0002800 @iter13594) ([92m↓1.81%[0m) [0.15% of initial]
[Iter 15420/20000] Loss: 0.0003703 (Best: 0.0002800 @iter13594) ([91m↑0.46%[0m) [0.15% of initial]
[Iter 15430/20000] Loss: 0.0003557 (Best: 0.0002800 @iter13594) ([92m↓3.94%[0m) [0.14% of initial]
[Iter 15440/20000] Loss: 0.0003649 (Best: 0.0002800 @iter13594) ([91m↑2.59%[0m) [0.14% of initial]
[Iter 15450/20000] Loss: 0.0003678 (Best: 0.0002800 @iter13594) ([91m↑0.78%[0m) [0.15% of initial]
[Iter 15460/20000] Loss: 0.0003817 (Best: 0.0002800 @iter13594) ([91m↑3.78%[0m) [0.15% of initial]
[Iter 15470/20000] Loss: 0.0003554 (Best: 0.0002800 @iter13594) ([92m↓6.87%[0m) [0.14% of initial]
[Iter 15480/20000] Loss: 0.0003594 (Best: 0.0002800 @iter13594) ([91m↑1.10%[0m) [0.14% of initial]
[Iter 15490/20000] Loss: 0.0003579 (Best: 0.0002800 @iter13594) ([92m↓0.40%[0m) [0.14% of initial]
Iter:15499, L1 loss=0.0004334, Total loss=0.00039, Time:86
[Iter 15500/20000] Loss: 0.0003686 (Best: 0.0002800 @iter13594) ([91m↑2.98%[0m) [0.15% of initial]
Pruning 17 points (0.0%) from gaussian0 at iteration 15500
Pruning 9 points (0.0%) from gaussian1 at iteration 15500
[Iter 15510/20000] Loss: 0.0006837 (Best: 0.0002800 @iter13594) ([91m↑85.49%[0m) [0.27% of initial]
[Iter 15520/20000] Loss: 0.0004766 (Best: 0.0002800 @iter13594) ([92m↓30.29%[0m) [0.19% of initial]
[Iter 15530/20000] Loss: 0.0004233 (Best: 0.0002800 @iter13594) ([92m↓11.17%[0m) [0.17% of initial]
[Iter 15540/20000] Loss: 0.0004106 (Best: 0.0002800 @iter13594) ([92m↓3.01%[0m) [0.16% of initial]
[Iter 15550/20000] Loss: 0.0003618 (Best: 0.0002800 @iter13594) ([92m↓11.89%[0m) [0.14% of initial]
[Iter 15560/20000] Loss: 0.0003489 (Best: 0.0002800 @iter13594) ([92m↓3.56%[0m) [0.14% of initial]
[Iter 15570/20000] Loss: 0.0003573 (Best: 0.0002800 @iter13594) ([91m↑2.41%[0m) [0.14% of initial]
[Iter 15580/20000] Loss: 0.0003418 (Best: 0.0002800 @iter13594) ([92m↓4.34%[0m) [0.14% of initial]
[Iter 15590/20000] Loss: 0.0003323 (Best: 0.0002800 @iter13594) ([92m↓2.77%[0m) [0.13% of initial]
Iter:15599, L1 loss=0.0003709, Total loss=0.0003322, Time:82
[Iter 15600/20000] Loss: 0.0003445 (Best: 0.0002800 @iter13594) ([91m↑3.65%[0m) [0.14% of initial]
[Iter 15610/20000] Loss: 0.0003449 (Best: 0.0002800 @iter13594) ([91m↑0.11%[0m) [0.14% of initial]
[Iter 15620/20000] Loss: 0.0003555 (Best: 0.0002800 @iter13594) ([91m↑3.09%[0m) [0.14% of initial]
[Iter 15630/20000] Loss: 0.0003614 (Best: 0.0002800 @iter13594) ([91m↑1.63%[0m) [0.14% of initial]
[Iter 15640/20000] Loss: 0.0003451 (Best: 0.0002800 @iter13594) ([92m↓4.49%[0m) [0.14% of initial]
[Iter 15650/20000] Loss: 0.0003488 (Best: 0.0002800 @iter13594) ([91m↑1.07%[0m) [0.14% of initial]
[Iter 15660/20000] Loss: 0.0003509 (Best: 0.0002800 @iter13594) ([91m↑0.61%[0m) [0.14% of initial]
[Iter 15670/20000] Loss: 0.0003686 (Best: 0.0002800 @iter13594) ([91m↑5.03%[0m) [0.15% of initial]
[Iter 15680/20000] Loss: 0.0003644 (Best: 0.0002800 @iter13594) ([92m↓1.14%[0m) [0.14% of initial]
[Iter 15690/20000] Loss: 0.0003574 (Best: 0.0002800 @iter13594) ([92m↓1.93%[0m) [0.14% of initial]
Iter:15699, L1 loss=0.0004259, Total loss=0.0003776, Time:63
[Iter 15700/20000] Loss: 0.0003489 (Best: 0.0002800 @iter13594) ([92m↓2.36%[0m) [0.14% of initial]
[Iter 15710/20000] Loss: 0.0003580 (Best: 0.0002800 @iter13594) ([91m↑2.58%[0m) [0.14% of initial]
[Iter 15720/20000] Loss: 0.0003883 (Best: 0.0002800 @iter13594) ([91m↑8.48%[0m) [0.15% of initial]
[Iter 15730/20000] Loss: 0.0004155 (Best: 0.0002800 @iter13594) ([91m↑6.99%[0m) [0.17% of initial]
[Iter 15740/20000] Loss: 0.0004474 (Best: 0.0002800 @iter13594) ([91m↑7.69%[0m) [0.18% of initial]
[Iter 15750/20000] Loss: 0.0003984 (Best: 0.0002800 @iter13594) ([92m↓10.95%[0m) [0.16% of initial]
[Iter 15760/20000] Loss: 0.0003840 (Best: 0.0002800 @iter13594) ([92m↓3.61%[0m) [0.15% of initial]
[Iter 15770/20000] Loss: 0.0004087 (Best: 0.0002800 @iter13594) ([91m↑6.42%[0m) [0.16% of initial]
[Iter 15780/20000] Loss: 0.0003723 (Best: 0.0002800 @iter13594) ([92m↓8.90%[0m) [0.15% of initial]
[Iter 15790/20000] Loss: 0.0003617 (Best: 0.0002800 @iter13594) ([92m↓2.86%[0m) [0.14% of initial]
Iter:15799, L1 loss=0.000386, Total loss=0.0003721, Time:78
[Iter 15800/20000] Loss: 0.0003533 (Best: 0.0002800 @iter13594) ([92m↓2.32%[0m) [0.14% of initial]
[Iter 15810/20000] Loss: 0.0003497 (Best: 0.0002800 @iter13594) ([92m↓1.01%[0m) [0.14% of initial]
[Iter 15820/20000] Loss: 0.0003409 (Best: 0.0002800 @iter13594) ([92m↓2.52%[0m) [0.14% of initial]
[Iter 15830/20000] Loss: 0.0003401 (Best: 0.0002800 @iter13594) ([92m↓0.25%[0m) [0.14% of initial]
[Iter 15840/20000] Loss: 0.0003584 (Best: 0.0002800 @iter13594) ([91m↑5.39%[0m) [0.14% of initial]
[Iter 15850/20000] Loss: 0.0003538 (Best: 0.0002800 @iter13594) ([92m↓1.27%[0m) [0.14% of initial]
[Iter 15860/20000] Loss: 0.0003728 (Best: 0.0002800 @iter13594) ([91m↑5.37%[0m) [0.15% of initial]
[Iter 15870/20000] Loss: 0.0003755 (Best: 0.0002800 @iter13594) ([91m↑0.70%[0m) [0.15% of initial]
[Iter 15880/20000] Loss: 0.0004280 (Best: 0.0002800 @iter13594) ([91m↑13.99%[0m) [0.17% of initial]
[Iter 15890/20000] Loss: 0.0004219 (Best: 0.0002800 @iter13594) ([92m↓1.41%[0m) [0.17% of initial]
Iter:15899, L1 loss=0.000428, Total loss=0.0003725, Time:81
[Iter 15900/20000] Loss: 0.0004000 (Best: 0.0002800 @iter13594) ([92m↓5.21%[0m) [0.16% of initial]
[Iter 15910/20000] Loss: 0.0003716 (Best: 0.0002800 @iter13594) ([92m↓7.10%[0m) [0.15% of initial]
[Iter 15920/20000] Loss: 0.0003767 (Best: 0.0002800 @iter13594) ([91m↑1.38%[0m) [0.15% of initial]
[Iter 15930/20000] Loss: 0.0004885 (Best: 0.0002800 @iter13594) ([91m↑29.67%[0m) [0.19% of initial]
[Iter 15940/20000] Loss: 0.0003907 (Best: 0.0002800 @iter13594) ([92m↓20.03%[0m) [0.16% of initial]
[Iter 15950/20000] Loss: 0.0003663 (Best: 0.0002800 @iter13594) ([92m↓6.23%[0m) [0.15% of initial]
[Iter 15960/20000] Loss: 0.0003831 (Best: 0.0002800 @iter13594) ([91m↑4.58%[0m) [0.15% of initial]
[Iter 15970/20000] Loss: 0.0003560 (Best: 0.0002800 @iter13594) ([92m↓7.06%[0m) [0.14% of initial]
[Iter 15980/20000] Loss: 0.0003634 (Best: 0.0002800 @iter13594) ([91m↑2.08%[0m) [0.14% of initial]
[Iter 15990/20000] Loss: 0.0003595 (Best: 0.0002800 @iter13594) ([92m↓1.08%[0m) [0.14% of initial]
Iter:15999, L1 loss=0.0003965, Total loss=0.0003669, Time:59
[Iter 16000/20000] Loss: 0.0003447 (Best: 0.0002800 @iter13594) ([92m↓4.12%[0m) [0.14% of initial]
Pruning 9 points (0.0%) from gaussian0 at iteration 16000
Pruning 7 points (0.0%) from gaussian1 at iteration 16000
[Iter 16010/20000] Loss: 0.0005404 (Best: 0.0002800 @iter13594) ([91m↑56.78%[0m) [0.21% of initial]
[Iter 16020/20000] Loss: 0.0005178 (Best: 0.0002800 @iter13594) ([92m↓4.19%[0m) [0.21% of initial]
[Iter 16030/20000] Loss: 0.0004339 (Best: 0.0002800 @iter13594) ([92m↓16.21%[0m) [0.17% of initial]
[Iter 16040/20000] Loss: 0.0003716 (Best: 0.0002800 @iter13594) ([92m↓14.36%[0m) [0.15% of initial]
[Iter 16050/20000] Loss: 0.0003349 (Best: 0.0002800 @iter13594) ([92m↓9.87%[0m) [0.13% of initial]
[Iter 16060/20000] Loss: 0.0003212 (Best: 0.0002800 @iter13594) ([92m↓4.08%[0m) [0.13% of initial]
[Iter 16070/20000] Loss: 0.0003057 (Best: 0.0002800 @iter13594) ([92m↓4.84%[0m) [0.12% of initial]
[Iter 16080/20000] Loss: 0.0003182 (Best: 0.0002800 @iter13594) ([91m↑4.09%[0m) [0.13% of initial]
[Iter 16090/20000] Loss: 0.0003226 (Best: 0.0002800 @iter13594) ([91m↑1.38%[0m) [0.13% of initial]
Iter:16099, L1 loss=0.0003955, Total loss=0.000348, Time:82
[Iter 16100/20000] Loss: 0.0003304 (Best: 0.0002800 @iter13594) ([91m↑2.43%[0m) [0.13% of initial]
[Iter 16110/20000] Loss: 0.0003405 (Best: 0.0002800 @iter13594) ([91m↑3.05%[0m) [0.14% of initial]
[Iter 16120/20000] Loss: 0.0003306 (Best: 0.0002800 @iter13594) ([92m↓2.90%[0m) [0.13% of initial]
[Iter 16130/20000] Loss: 0.0003420 (Best: 0.0002800 @iter13594) ([91m↑3.45%[0m) [0.14% of initial]
[Iter 16140/20000] Loss: 0.0003408 (Best: 0.0002800 @iter13594) ([92m↓0.35%[0m) [0.14% of initial]
[Iter 16150/20000] Loss: 0.0003420 (Best: 0.0002800 @iter13594) ([91m↑0.35%[0m) [0.14% of initial]
[Iter 16160/20000] Loss: 0.0003299 (Best: 0.0002800 @iter13594) ([92m↓3.54%[0m) [0.13% of initial]
[Iter 16170/20000] Loss: 0.0003341 (Best: 0.0002800 @iter13594) ([91m↑1.27%[0m) [0.13% of initial]
[Iter 16180/20000] Loss: 0.0003433 (Best: 0.0002800 @iter13594) ([91m↑2.77%[0m) [0.14% of initial]
[Iter 16190/20000] Loss: 0.0003274 (Best: 0.0002800 @iter13594) ([92m↓4.65%[0m) [0.13% of initial]
Iter:16199, L1 loss=0.0003794, Total loss=0.0003306, Time:52
[Iter 16200/20000] Loss: 0.0003450 (Best: 0.0002800 @iter13594) ([91m↑5.39%[0m) [0.14% of initial]
[Iter 16210/20000] Loss: 0.0003389 (Best: 0.0002800 @iter13594) ([92m↓1.79%[0m) [0.13% of initial]
[Iter 16220/20000] Loss: 0.0003298 (Best: 0.0002800 @iter13594) ([92m↓2.66%[0m) [0.13% of initial]
[Iter 16230/20000] Loss: 0.0003584 (Best: 0.0002800 @iter13594) ([91m↑8.67%[0m) [0.14% of initial]
[Iter 16240/20000] Loss: 0.0003352 (Best: 0.0002800 @iter13594) ([92m↓6.48%[0m) [0.13% of initial]
[Iter 16250/20000] Loss: 0.0003570 (Best: 0.0002800 @iter13594) ([91m↑6.51%[0m) [0.14% of initial]
[Iter 16260/20000] Loss: 0.0003504 (Best: 0.0002800 @iter13594) ([92m↓1.85%[0m) [0.14% of initial]
[Iter 16270/20000] Loss: 0.0003509 (Best: 0.0002800 @iter13594) ([91m↑0.14%[0m) [0.14% of initial]
[Iter 16280/20000] Loss: 0.0003502 (Best: 0.0002800 @iter13594) ([92m↓0.21%[0m) [0.14% of initial]
[Iter 16290/20000] Loss: 0.0003887 (Best: 0.0002800 @iter13594) ([91m↑11.00%[0m) [0.15% of initial]
Iter:16299, L1 loss=0.000454, Total loss=0.0003627, Time:78
[Iter 16300/20000] Loss: 0.0003678 (Best: 0.0002800 @iter13594) ([92m↓5.37%[0m) [0.15% of initial]
[Iter 16310/20000] Loss: 0.0004022 (Best: 0.0002800 @iter13594) ([91m↑9.36%[0m) [0.16% of initial]
[Iter 16320/20000] Loss: 0.0003963 (Best: 0.0002800 @iter13594) ([92m↓1.46%[0m) [0.16% of initial]
[Iter 16330/20000] Loss: 0.0003707 (Best: 0.0002800 @iter13594) ([92m↓6.47%[0m) [0.15% of initial]
[Iter 16340/20000] Loss: 0.0003490 (Best: 0.0002800 @iter13594) ([92m↓5.85%[0m) [0.14% of initial]
[Iter 16350/20000] Loss: 0.0003851 (Best: 0.0002800 @iter13594) ([91m↑10.34%[0m) [0.15% of initial]
[Iter 16360/20000] Loss: 0.0003563 (Best: 0.0002800 @iter13594) ([92m↓7.48%[0m) [0.14% of initial]
[Iter 16370/20000] Loss: 0.0004065 (Best: 0.0002800 @iter13594) ([91m↑14.08%[0m) [0.16% of initial]
[Iter 16380/20000] Loss: 0.0003795 (Best: 0.0002800 @iter13594) ([92m↓6.64%[0m) [0.15% of initial]
[Iter 16390/20000] Loss: 0.0003589 (Best: 0.0002800 @iter13594) ([92m↓5.43%[0m) [0.14% of initial]
Iter:16399, L1 loss=0.0004305, Total loss=0.000332, Time:65
[Iter 16400/20000] Loss: 0.0003275 (Best: 0.0002800 @iter13594) ([92m↓8.74%[0m) [0.13% of initial]
[Iter 16410/20000] Loss: 0.0003250 (Best: 0.0002800 @iter13594) ([92m↓0.75%[0m) [0.13% of initial]
[Iter 16420/20000] Loss: 0.0003259 (Best: 0.0002800 @iter13594) ([91m↑0.28%[0m) [0.13% of initial]
[Iter 16430/20000] Loss: 0.0003264 (Best: 0.0002800 @iter13594) ([91m↑0.15%[0m) [0.13% of initial]
[Iter 16440/20000] Loss: 0.0003835 (Best: 0.0002800 @iter13594) ([91m↑17.50%[0m) [0.15% of initial]
[Iter 16450/20000] Loss: 0.0003716 (Best: 0.0002800 @iter13594) ([92m↓3.12%[0m) [0.15% of initial]
[Iter 16460/20000] Loss: 0.0003680 (Best: 0.0002800 @iter13594) ([92m↓0.95%[0m) [0.15% of initial]
[Iter 16470/20000] Loss: 0.0003326 (Best: 0.0002800 @iter13594) ([92m↓9.64%[0m) [0.13% of initial]
[Iter 16480/20000] Loss: 0.0003528 (Best: 0.0002800 @iter13594) ([91m↑6.10%[0m) [0.14% of initial]
[Iter 16490/20000] Loss: 0.0003361 (Best: 0.0002800 @iter13594) ([92m↓4.75%[0m) [0.13% of initial]
Iter:16499, L1 loss=0.0003536, Total loss=0.0003209, Time:87
[Iter 16500/20000] Loss: 0.0003268 (Best: 0.0002800 @iter13594) ([92m↓2.75%[0m) [0.13% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 16500
Pruning 3 points (0.0%) from gaussian1 at iteration 16500
[Iter 16510/20000] Loss: 0.0006127 (Best: 0.0002800 @iter13594) ([91m↑87.47%[0m) [0.24% of initial]
[Iter 16520/20000] Loss: 0.0004688 (Best: 0.0002800 @iter13594) ([92m↓23.49%[0m) [0.19% of initial]
[Iter 16530/20000] Loss: 0.0004299 (Best: 0.0002800 @iter13594) ([92m↓8.30%[0m) [0.17% of initial]
[Iter 16540/20000] Loss: 0.0003754 (Best: 0.0002800 @iter13594) ([92m↓12.67%[0m) [0.15% of initial]
[Iter 16550/20000] Loss: 0.0003283 (Best: 0.0002800 @iter13594) ([92m↓12.57%[0m) [0.13% of initial]
[Iter 16560/20000] Loss: 0.0003179 (Best: 0.0002800 @iter13594) ([92m↓3.15%[0m) [0.13% of initial]
[Iter 16570/20000] Loss: 0.0003086 (Best: 0.0002800 @iter13594) ([92m↓2.92%[0m) [0.12% of initial]
[Iter 16580/20000] Loss: 0.0002961 (Best: 0.0002800 @iter13594) ([92m↓4.07%[0m) [0.12% of initial]
[Iter 16590/20000] Loss: 0.0003079 (Best: 0.0002800 @iter13594) ([91m↑3.99%[0m) [0.12% of initial]
Iter:16599, L1 loss=0.0003997, Total loss=0.0003406, Time:64
[Iter 16600/20000] Loss: 0.0003180 (Best: 0.0002800 @iter13594) ([91m↑3.28%[0m) [0.13% of initial]
[Iter 16610/20000] Loss: 0.0003190 (Best: 0.0002800 @iter13594) ([91m↑0.31%[0m) [0.13% of initial]
[Iter 16620/20000] Loss: 0.0003267 (Best: 0.0002800 @iter13594) ([91m↑2.41%[0m) [0.13% of initial]
[Iter 16630/20000] Loss: 0.0003461 (Best: 0.0002800 @iter13594) ([91m↑5.96%[0m) [0.14% of initial]
[Iter 16640/20000] Loss: 0.0003308 (Best: 0.0002800 @iter13594) ([92m↓4.41%[0m) [0.13% of initial]
[Iter 16650/20000] Loss: 0.0003264 (Best: 0.0002800 @iter13594) ([92m↓1.35%[0m) [0.13% of initial]
[Iter 16660/20000] Loss: 0.0003153 (Best: 0.0002800 @iter13594) ([92m↓3.38%[0m) [0.13% of initial]
[Iter 16670/20000] Loss: 0.0003159 (Best: 0.0002800 @iter13594) ([91m↑0.17%[0m) [0.13% of initial]
[Iter 16680/20000] Loss: 0.0003121 (Best: 0.0002800 @iter13594) ([92m↓1.19%[0m) [0.12% of initial]
[Iter 16690/20000] Loss: 0.0003140 (Best: 0.0002800 @iter13594) ([91m↑0.58%[0m) [0.12% of initial]
Iter:16699, L1 loss=0.0003532, Total loss=0.0003068, Time:84
[Iter 16700/20000] Loss: 0.0003121 (Best: 0.0002800 @iter13594) ([92m↓0.58%[0m) [0.12% of initial]
[Iter 16710/20000] Loss: 0.0003250 (Best: 0.0002800 @iter13594) ([91m↑4.13%[0m) [0.13% of initial]
[Iter 16720/20000] Loss: 0.0003234 (Best: 0.0002800 @iter13594) ([92m↓0.51%[0m) [0.13% of initial]
[Iter 16730/20000] Loss: 0.0003288 (Best: 0.0002800 @iter13594) ([91m↑1.68%[0m) [0.13% of initial]
[Iter 16740/20000] Loss: 0.0003754 (Best: 0.0002800 @iter13594) ([91m↑14.17%[0m) [0.15% of initial]
[Iter 16750/20000] Loss: 0.0003414 (Best: 0.0002800 @iter13594) ([92m↓9.05%[0m) [0.14% of initial]
[Iter 16760/20000] Loss: 0.0003479 (Best: 0.0002800 @iter13594) ([91m↑1.89%[0m) [0.14% of initial]
[Iter 16770/20000] Loss: 0.0004284 (Best: 0.0002800 @iter13594) ([91m↑23.14%[0m) [0.17% of initial]
[Iter 16780/20000] Loss: 0.0003579 (Best: 0.0002800 @iter13594) ([92m↓16.45%[0m) [0.14% of initial]
[Iter 16790/20000] Loss: 0.0003350 (Best: 0.0002800 @iter13594) ([92m↓6.40%[0m) [0.13% of initial]
Iter:16799, L1 loss=0.0003793, Total loss=0.0003324, Time:61
[Iter 16800/20000] Loss: 0.0003419 (Best: 0.0002800 @iter13594) ([91m↑2.07%[0m) [0.14% of initial]
[Iter 16810/20000] Loss: 0.0003375 (Best: 0.0002800 @iter13594) ([92m↓1.28%[0m) [0.13% of initial]
[Iter 16820/20000] Loss: 0.0003342 (Best: 0.0002800 @iter13594) ([92m↓1.00%[0m) [0.13% of initial]
[Iter 16830/20000] Loss: 0.0003387 (Best: 0.0002800 @iter13594) ([91m↑1.37%[0m) [0.13% of initial]
[Iter 16840/20000] Loss: 0.0003273 (Best: 0.0002800 @iter13594) ([92m↓3.37%[0m) [0.13% of initial]
[Iter 16850/20000] Loss: 0.0003626 (Best: 0.0002800 @iter13594) ([91m↑10.78%[0m) [0.14% of initial]
[Iter 16860/20000] Loss: 0.0003821 (Best: 0.0002800 @iter13594) ([91m↑5.37%[0m) [0.15% of initial]
[Iter 16870/20000] Loss: 0.0003410 (Best: 0.0002800 @iter13594) ([92m↓10.75%[0m) [0.14% of initial]
[Iter 16880/20000] Loss: 0.0003383 (Best: 0.0002800 @iter13594) ([92m↓0.78%[0m) [0.13% of initial]
[Iter 16890/20000] Loss: 0.0003325 (Best: 0.0002800 @iter13594) ([92m↓1.73%[0m) [0.13% of initial]
Iter:16899, L1 loss=0.0003855, Total loss=0.0003254, Time:63
[Iter 16900/20000] Loss: 0.0003354 (Best: 0.0002800 @iter13594) ([91m↑0.89%[0m) [0.13% of initial]
[Iter 16910/20000] Loss: 0.0003179 (Best: 0.0002800 @iter13594) ([92m↓5.23%[0m) [0.13% of initial]
[Iter 16920/20000] Loss: 0.0003154 (Best: 0.0002800 @iter13594) ([92m↓0.79%[0m) [0.13% of initial]
[Iter 16930/20000] Loss: 0.0003074 (Best: 0.0002800 @iter13594) ([92m↓2.55%[0m) [0.12% of initial]
[Iter 16940/20000] Loss: 0.0003255 (Best: 0.0002800 @iter13594) ([91m↑5.91%[0m) [0.13% of initial]
[Iter 16950/20000] Loss: 0.0003314 (Best: 0.0002800 @iter13594) ([91m↑1.79%[0m) [0.13% of initial]
[Iter 16960/20000] Loss: 0.0003301 (Best: 0.0002800 @iter13594) ([92m↓0.39%[0m) [0.13% of initial]
[Iter 16970/20000] Loss: 0.0003200 (Best: 0.0002800 @iter13594) ([92m↓3.06%[0m) [0.13% of initial]
[Iter 16980/20000] Loss: 0.0003187 (Best: 0.0002800 @iter13594) ([92m↓0.39%[0m) [0.13% of initial]
[Iter 16990/20000] Loss: 0.0003214 (Best: 0.0002800 @iter13594) ([91m↑0.83%[0m) [0.13% of initial]
Iter:16999, L1 loss=0.0003683, Total loss=0.0003218, Time:78
[Iter 17000/20000] Loss: 0.0003133 (Best: 0.0002800 @iter13594) ([92m↓2.51%[0m) [0.12% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 17000
Pruning 7 points (0.0%) from gaussian1 at iteration 17000
[Iter 17010/20000] Loss: 0.0006699 (Best: 0.0002800 @iter13594) ([91m↑113.81%[0m) [0.27% of initial]
[Iter 17020/20000] Loss: 0.0004521 (Best: 0.0002800 @iter13594) ([92m↓32.51%[0m) [0.18% of initial]
[Iter 17030/20000] Loss: 0.0003778 (Best: 0.0002800 @iter13594) ([92m↓16.45%[0m) [0.15% of initial]
[Iter 17040/20000] Loss: 0.0003763 (Best: 0.0002800 @iter13594) ([92m↓0.38%[0m) [0.15% of initial]
[Iter 17050/20000] Loss: 0.0003404 (Best: 0.0002800 @iter13594) ([92m↓9.54%[0m) [0.14% of initial]
[Iter 17060/20000] Loss: 0.0003100 (Best: 0.0002800 @iter13594) ([92m↓8.94%[0m) [0.12% of initial]
[Iter 17070/20000] Loss: 0.0003164 (Best: 0.0002800 @iter13594) ([91m↑2.06%[0m) [0.13% of initial]
[Iter 17080/20000] Loss: 0.0003054 (Best: 0.0002800 @iter13594) ([92m↓3.46%[0m) [0.12% of initial]
[Iter 17090/20000] Loss: 0.0003091 (Best: 0.0002800 @iter13594) ([91m↑1.20%[0m) [0.12% of initial]
Iter:17099, L1 loss=0.0003701, Total loss=0.000315, Time:70
[Iter 17100/20000] Loss: 0.0003237 (Best: 0.0002800 @iter13594) ([91m↑4.71%[0m) [0.13% of initial]
[Iter 17110/20000] Loss: 0.0003228 (Best: 0.0002800 @iter13594) ([92m↓0.26%[0m) [0.13% of initial]
[Iter 17120/20000] Loss: 0.0003518 (Best: 0.0002800 @iter13594) ([91m↑8.98%[0m) [0.14% of initial]
[Iter 17130/20000] Loss: 0.0003222 (Best: 0.0002800 @iter13594) ([92m↓8.42%[0m) [0.13% of initial]
[Iter 17140/20000] Loss: 0.0003055 (Best: 0.0002800 @iter13594) ([92m↓5.16%[0m) [0.12% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 17150/20000] Loss: 0.0003072 (Best: 0.0002800 @iter13594) ([91m↑0.55%[0m) [0.12% of initial]
[Iter 17160/20000] Loss: 0.0003262 (Best: 0.0002800 @iter13594) ([91m↑6.16%[0m) [0.13% of initial]
[Iter 17170/20000] Loss: 0.0003176 (Best: 0.0002800 @iter13594) ([92m↓2.62%[0m) [0.13% of initial]
[Iter 17180/20000] Loss: 0.0003394 (Best: 0.0002800 @iter13594) ([91m↑6.86%[0m) [0.13% of initial]
[Iter 17190/20000] Loss: 0.0003252 (Best: 0.0002800 @iter13594) ([92m↓4.18%[0m) [0.13% of initial]
Iter:17199, L1 loss=0.0004013, Total loss=0.0003517, Time:63
[Iter 17200/20000] Loss: 0.0003186 (Best: 0.0002800 @iter13594) ([92m↓2.02%[0m) [0.13% of initial]
[Iter 17210/20000] Loss: 0.0003119 (Best: 0.0002800 @iter13594) ([92m↓2.12%[0m) [0.12% of initial]
[Iter 17220/20000] Loss: 0.0003201 (Best: 0.0002800 @iter13594) ([91m↑2.62%[0m) [0.13% of initial]
[Iter 17230/20000] Loss: 0.0003130 (Best: 0.0002800 @iter13594) ([92m↓2.19%[0m) [0.12% of initial]
[Iter 17240/20000] Loss: 0.0003143 (Best: 0.0002800 @iter13594) ([91m↑0.41%[0m) [0.12% of initial]
[Iter 17250/20000] Loss: 0.0003115 (Best: 0.0002800 @iter13594) ([92m↓0.89%[0m) [0.12% of initial]
[Iter 17260/20000] Loss: 0.0003130 (Best: 0.0002800 @iter13594) ([91m↑0.48%[0m) [0.12% of initial]
[Iter 17270/20000] Loss: 0.0003307 (Best: 0.0002800 @iter13594) ([91m↑5.66%[0m) [0.13% of initial]
[Iter 17280/20000] Loss: 0.0003132 (Best: 0.0002800 @iter13594) ([92m↓5.29%[0m) [0.12% of initial]
[Iter 17290/20000] Loss: 0.0003111 (Best: 0.0002800 @iter13594) ([92m↓0.67%[0m) [0.12% of initial]
Iter:17299, L1 loss=0.0003563, Total loss=0.000301, Time:79
[Iter 17300/20000] Loss: 0.0003128 (Best: 0.0002800 @iter13594) ([91m↑0.54%[0m) [0.12% of initial]
[Iter 17310/20000] Loss: 0.0003552 (Best: 0.0002800 @iter13594) ([91m↑13.54%[0m) [0.14% of initial]
[Iter 17320/20000] Loss: 0.0003425 (Best: 0.0002800 @iter13594) ([92m↓3.56%[0m) [0.14% of initial]
[Iter 17330/20000] Loss: 0.0003374 (Best: 0.0002800 @iter13594) ([92m↓1.49%[0m) [0.13% of initial]
[Iter 17340/20000] Loss: 0.0003571 (Best: 0.0002800 @iter13594) ([91m↑5.83%[0m) [0.14% of initial]
[Iter 17350/20000] Loss: 0.0003498 (Best: 0.0002800 @iter13594) ([92m↓2.05%[0m) [0.14% of initial]
[Iter 17360/20000] Loss: 0.0003642 (Best: 0.0002800 @iter13594) ([91m↑4.13%[0m) [0.14% of initial]
[Iter 17370/20000] Loss: 0.0003487 (Best: 0.0002800 @iter13594) ([92m↓4.26%[0m) [0.14% of initial]
[Iter 17380/20000] Loss: 0.0003191 (Best: 0.0002800 @iter13594) ([92m↓8.49%[0m) [0.13% of initial]
[Iter 17390/20000] Loss: 0.0003178 (Best: 0.0002800 @iter13594) ([92m↓0.43%[0m) [0.13% of initial]
Iter:17399, L1 loss=0.0003826, Total loss=0.0003373, Time:61
[Iter 17400/20000] Loss: 0.0003101 (Best: 0.0002800 @iter13594) ([92m↓2.42%[0m) [0.12% of initial]
[Iter 17410/20000] Loss: 0.0003208 (Best: 0.0002800 @iter13594) ([91m↑3.45%[0m) [0.13% of initial]
[Iter 17420/20000] Loss: 0.0003103 (Best: 0.0002800 @iter13594) ([92m↓3.26%[0m) [0.12% of initial]
[Iter 17430/20000] Loss: 0.0003043 (Best: 0.0002800 @iter13594) ([92m↓1.93%[0m) [0.12% of initial]
[Iter 17440/20000] Loss: 0.0003146 (Best: 0.0002800 @iter13594) ([91m↑3.36%[0m) [0.12% of initial]
[Iter 17450/20000] Loss: 0.0003779 (Best: 0.0002800 @iter13594) ([91m↑20.15%[0m) [0.15% of initial]
[Iter 17460/20000] Loss: 0.0003579 (Best: 0.0002800 @iter13594) ([92m↓5.30%[0m) [0.14% of initial]
[Iter 17470/20000] Loss: 0.0003165 (Best: 0.0002800 @iter13594) ([92m↓11.56%[0m) [0.13% of initial]
[Iter 17480/20000] Loss: 0.0003205 (Best: 0.0002800 @iter13594) ([91m↑1.27%[0m) [0.13% of initial]
[Iter 17490/20000] Loss: 0.0003467 (Best: 0.0002800 @iter13594) ([91m↑8.16%[0m) [0.14% of initial]
Iter:17499, L1 loss=0.000414, Total loss=0.0003772, Time:53
[Iter 17500/20000] Loss: 0.0003647 (Best: 0.0002800 @iter13594) ([91m↑5.20%[0m) [0.14% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 17500
Pruning 10 points (0.0%) from gaussian1 at iteration 17500
[Iter 17510/20000] Loss: 0.0005556 (Best: 0.0002800 @iter13594) ([91m↑52.33%[0m) [0.22% of initial]
[Iter 17520/20000] Loss: 0.0004696 (Best: 0.0002800 @iter13594) ([92m↓15.47%[0m) [0.19% of initial]
[Iter 17530/20000] Loss: 0.0003972 (Best: 0.0002800 @iter13594) ([92m↓15.42%[0m) [0.16% of initial]
[Iter 17540/20000] Loss: 0.0003308 (Best: 0.0002800 @iter13594) ([92m↓16.73%[0m) [0.13% of initial]
[Iter 17550/20000] Loss: 0.0003089 (Best: 0.0002800 @iter13594) ([92m↓6.61%[0m) [0.12% of initial]
[Iter 17560/20000] Loss: 0.0003122 (Best: 0.0002800 @iter13594) ([91m↑1.06%[0m) [0.12% of initial]
[Iter 17570/20000] Loss: 0.0003039 (Best: 0.0002800 @iter13594) ([92m↓2.63%[0m) [0.12% of initial]
[Iter 17580/20000] Loss: 0.0003052 (Best: 0.0002800 @iter13594) ([91m↑0.42%[0m) [0.12% of initial]
[Iter 17590/20000] Loss: 0.0002960 (Best: 0.0002800 @iter13594) ([92m↓3.02%[0m) [0.12% of initial]
Iter:17599, L1 loss=0.0003559, Total loss=0.0003077, Time:60
[Iter 17600/20000] Loss: 0.0003040 (Best: 0.0002800 @iter13594) ([91m↑2.71%[0m) [0.12% of initial]
[Iter 17610/20000] Loss: 0.0002964 (Best: 0.0002800 @iter13594) ([92m↓2.52%[0m) [0.12% of initial]
[Iter 17620/20000] Loss: 0.0002910 (Best: 0.0002767 @iter17620) ([92m↓1.81%[0m) [0.12% of initial]
[Iter 17630/20000] Loss: 0.0003075 (Best: 0.0002767 @iter17620) ([91m↑5.68%[0m) [0.12% of initial]
[Iter 17640/20000] Loss: 0.0003294 (Best: 0.0002767 @iter17620) ([91m↑7.12%[0m) [0.13% of initial]
[Iter 17650/20000] Loss: 0.0003212 (Best: 0.0002767 @iter17620) ([92m↓2.49%[0m) [0.13% of initial]
[Iter 17660/20000] Loss: 0.0003088 (Best: 0.0002767 @iter17620) ([92m↓3.87%[0m) [0.12% of initial]
[Iter 17670/20000] Loss: 0.0003113 (Best: 0.0002767 @iter17620) ([91m↑0.82%[0m) [0.12% of initial]
[Iter 17680/20000] Loss: 0.0003059 (Best: 0.0002767 @iter17620) ([92m↓1.74%[0m) [0.12% of initial]
[Iter 17690/20000] Loss: 0.0003967 (Best: 0.0002767 @iter17620) ([91m↑29.67%[0m) [0.16% of initial]
Iter:17699, L1 loss=0.0004638, Total loss=0.0004016, Time:75
[Iter 17700/20000] Loss: 0.0004134 (Best: 0.0002767 @iter17620) ([91m↑4.22%[0m) [0.16% of initial]
[Iter 17710/20000] Loss: 0.0004105 (Best: 0.0002767 @iter17620) ([92m↓0.69%[0m) [0.16% of initial]
[Iter 17720/20000] Loss: 0.0003777 (Best: 0.0002767 @iter17620) ([92m↓8.01%[0m) [0.15% of initial]
[Iter 17730/20000] Loss: 0.0003893 (Best: 0.0002767 @iter17620) ([91m↑3.07%[0m) [0.15% of initial]
[Iter 17740/20000] Loss: 0.0003607 (Best: 0.0002767 @iter17620) ([92m↓7.34%[0m) [0.14% of initial]
[Iter 17750/20000] Loss: 0.0003135 (Best: 0.0002767 @iter17620) ([92m↓13.10%[0m) [0.12% of initial]
[Iter 17760/20000] Loss: 0.0003004 (Best: 0.0002767 @iter17620) ([92m↓4.17%[0m) [0.12% of initial]
[Iter 17770/20000] Loss: 0.0002906 (Best: 0.0002767 @iter17620) ([92m↓3.26%[0m) [0.12% of initial]
[Iter 17780/20000] Loss: 0.0003083 (Best: 0.0002767 @iter17620) ([91m↑6.08%[0m) [0.12% of initial]
[Iter 17790/20000] Loss: 0.0003029 (Best: 0.0002767 @iter17620) ([92m↓1.75%[0m) [0.12% of initial]
Iter:17799, L1 loss=0.0003707, Total loss=0.000319, Time:54
[Iter 17800/20000] Loss: 0.0003004 (Best: 0.0002767 @iter17620) ([92m↓0.82%[0m) [0.12% of initial]
[Iter 17810/20000] Loss: 0.0002961 (Best: 0.0002767 @iter17620) ([92m↓1.42%[0m) [0.12% of initial]
[Iter 17820/20000] Loss: 0.0003077 (Best: 0.0002767 @iter17620) ([91m↑3.89%[0m) [0.12% of initial]
[Iter 17830/20000] Loss: 0.0002970 (Best: 0.0002767 @iter17620) ([92m↓3.48%[0m) [0.12% of initial]
[Iter 17840/20000] Loss: 0.0002961 (Best: 0.0002767 @iter17620) ([92m↓0.29%[0m) [0.12% of initial]
[Iter 17850/20000] Loss: 0.0003174 (Best: 0.0002767 @iter17620) ([91m↑7.19%[0m) [0.13% of initial]
[Iter 17860/20000] Loss: 0.0003002 (Best: 0.0002767 @iter17620) ([92m↓5.41%[0m) [0.12% of initial]
[Iter 17870/20000] Loss: 0.0002955 (Best: 0.0002767 @iter17620) ([92m↓1.58%[0m) [0.12% of initial]
[Iter 17880/20000] Loss: 0.0003325 (Best: 0.0002767 @iter17620) ([91m↑12.52%[0m) [0.13% of initial]
[Iter 17890/20000] Loss: 0.0003241 (Best: 0.0002767 @iter17620) ([92m↓2.51%[0m) [0.13% of initial]
Iter:17899, L1 loss=0.0004003, Total loss=0.0003126, Time:55
[Iter 17900/20000] Loss: 0.0003295 (Best: 0.0002767 @iter17620) ([91m↑1.66%[0m) [0.13% of initial]
[Iter 17910/20000] Loss: 0.0003278 (Best: 0.0002767 @iter17620) ([92m↓0.52%[0m) [0.13% of initial]
[Iter 17920/20000] Loss: 0.0003478 (Best: 0.0002767 @iter17620) ([91m↑6.09%[0m) [0.14% of initial]
[Iter 17930/20000] Loss: 0.0003484 (Best: 0.0002767 @iter17620) ([91m↑0.17%[0m) [0.14% of initial]
[Iter 17940/20000] Loss: 0.0003181 (Best: 0.0002767 @iter17620) ([92m↓8.68%[0m) [0.13% of initial]
[Iter 17950/20000] Loss: 0.0003267 (Best: 0.0002767 @iter17620) ([91m↑2.70%[0m) [0.13% of initial]
[Iter 17960/20000] Loss: 0.0003120 (Best: 0.0002767 @iter17620) ([92m↓4.51%[0m) [0.12% of initial]
[Iter 17970/20000] Loss: 0.0003074 (Best: 0.0002767 @iter17620) ([92m↓1.49%[0m) [0.12% of initial]
[Iter 17980/20000] Loss: 0.0002986 (Best: 0.0002767 @iter17620) ([92m↓2.85%[0m) [0.12% of initial]
[Iter 17990/20000] Loss: 0.0003059 (Best: 0.0002767 @iter17620) ([91m↑2.46%[0m) [0.12% of initial]
Iter:17999, L1 loss=0.0003577, Total loss=0.0003191, Time:59
[Iter 18000/20000] Loss: 0.0003193 (Best: 0.0002767 @iter17620) ([91m↑4.36%[0m) [0.13% of initial]
Pruning 7 points (0.0%) from gaussian0 at iteration 18000
Pruning 5 points (0.0%) from gaussian1 at iteration 18000
[Iter 18010/20000] Loss: 0.0234327 (Best: 0.0002767 @iter17620) ([91m↑7239.88%[0m) [9.31% of initial]
[Iter 18020/20000] Loss: 0.0072950 (Best: 0.0002767 @iter17620) ([92m↓68.87%[0m) [2.90% of initial]
[Iter 18030/20000] Loss: 0.0047635 (Best: 0.0002767 @iter17620) ([92m↓34.70%[0m) [1.89% of initial]
[Iter 18040/20000] Loss: 0.0027478 (Best: 0.0002767 @iter17620) ([92m↓42.32%[0m) [1.09% of initial]
[Iter 18050/20000] Loss: 0.0018392 (Best: 0.0002767 @iter17620) ([92m↓33.07%[0m) [0.73% of initial]
[Iter 18060/20000] Loss: 0.0014696 (Best: 0.0002767 @iter17620) ([92m↓20.09%[0m) [0.58% of initial]
[Iter 18070/20000] Loss: 0.0011121 (Best: 0.0002767 @iter17620) ([92m↓24.33%[0m) [0.44% of initial]
[Iter 18080/20000] Loss: 0.0009157 (Best: 0.0002767 @iter17620) ([92m↓17.66%[0m) [0.36% of initial]
[Iter 18090/20000] Loss: 0.0007967 (Best: 0.0002767 @iter17620) ([92m↓13.00%[0m) [0.32% of initial]
Iter:18099, L1 loss=0.000766, Total loss=0.0007283, Time:58
[Iter 18100/20000] Loss: 0.0007226 (Best: 0.0002767 @iter17620) ([92m↓9.30%[0m) [0.29% of initial]
[Iter 18110/20000] Loss: 0.0006548 (Best: 0.0002767 @iter17620) ([92m↓9.38%[0m) [0.26% of initial]
[Iter 18120/20000] Loss: 0.0006075 (Best: 0.0002767 @iter17620) ([92m↓7.23%[0m) [0.24% of initial]
[Iter 18130/20000] Loss: 0.0005615 (Best: 0.0002767 @iter17620) ([92m↓7.56%[0m) [0.22% of initial]
[Iter 18140/20000] Loss: 0.0005366 (Best: 0.0002767 @iter17620) ([92m↓4.45%[0m) [0.21% of initial]
[Iter 18150/20000] Loss: 0.0005238 (Best: 0.0002767 @iter17620) ([92m↓2.37%[0m) [0.21% of initial]
[Iter 18160/20000] Loss: 0.0005008 (Best: 0.0002767 @iter17620) ([92m↓4.40%[0m) [0.20% of initial]
[Iter 18170/20000] Loss: 0.0004848 (Best: 0.0002767 @iter17620) ([92m↓3.20%[0m) [0.19% of initial]
[Iter 18180/20000] Loss: 0.0004719 (Best: 0.0002767 @iter17620) ([92m↓2.64%[0m) [0.19% of initial]
[Iter 18190/20000] Loss: 0.0004511 (Best: 0.0002767 @iter17620) ([92m↓4.41%[0m) [0.18% of initial]
Iter:18199, L1 loss=0.000471, Total loss=0.0004267, Time:73
[Iter 18200/20000] Loss: 0.0004435 (Best: 0.0002767 @iter17620) ([92m↓1.68%[0m) [0.18% of initial]
[Iter 18210/20000] Loss: 0.0004410 (Best: 0.0002767 @iter17620) ([92m↓0.57%[0m) [0.18% of initial]
[Iter 18220/20000] Loss: 0.0004183 (Best: 0.0002767 @iter17620) ([92m↓5.16%[0m) [0.17% of initial]
[Iter 18230/20000] Loss: 0.0004225 (Best: 0.0002767 @iter17620) ([91m↑1.01%[0m) [0.17% of initial]
[Iter 18240/20000] Loss: 0.0004082 (Best: 0.0002767 @iter17620) ([92m↓3.38%[0m) [0.16% of initial]
[Iter 18250/20000] Loss: 0.0003980 (Best: 0.0002767 @iter17620) ([92m↓2.50%[0m) [0.16% of initial]
[Iter 18260/20000] Loss: 0.0004113 (Best: 0.0002767 @iter17620) ([91m↑3.34%[0m) [0.16% of initial]
[Iter 18270/20000] Loss: 0.0004101 (Best: 0.0002767 @iter17620) ([92m↓0.31%[0m) [0.16% of initial]
[Iter 18280/20000] Loss: 0.0004202 (Best: 0.0002767 @iter17620) ([91m↑2.47%[0m) [0.17% of initial]
[Iter 18290/20000] Loss: 0.0004292 (Best: 0.0002767 @iter17620) ([91m↑2.14%[0m) [0.17% of initial]
Iter:18299, L1 loss=0.0004779, Total loss=0.0004077, Time:69
[Iter 18300/20000] Loss: 0.0004150 (Best: 0.0002767 @iter17620) ([92m↓3.32%[0m) [0.16% of initial]
[Iter 18310/20000] Loss: 0.0004100 (Best: 0.0002767 @iter17620) ([92m↓1.19%[0m) [0.16% of initial]
[Iter 18320/20000] Loss: 0.0004019 (Best: 0.0002767 @iter17620) ([92m↓1.97%[0m) [0.16% of initial]
[Iter 18330/20000] Loss: 0.0003988 (Best: 0.0002767 @iter17620) ([92m↓0.78%[0m) [0.16% of initial]
[Iter 18340/20000] Loss: 0.0003863 (Best: 0.0002767 @iter17620) ([92m↓3.14%[0m) [0.15% of initial]
[Iter 18350/20000] Loss: 0.0003843 (Best: 0.0002767 @iter17620) ([92m↓0.52%[0m) [0.15% of initial]
[Iter 18360/20000] Loss: 0.0003801 (Best: 0.0002767 @iter17620) ([92m↓1.08%[0m) [0.15% of initial]
[Iter 18370/20000] Loss: 0.0003815 (Best: 0.0002767 @iter17620) ([91m↑0.38%[0m) [0.15% of initial]
[Iter 18380/20000] Loss: 0.0003791 (Best: 0.0002767 @iter17620) ([92m↓0.63%[0m) [0.15% of initial]
[Iter 18390/20000] Loss: 0.0003798 (Best: 0.0002767 @iter17620) ([91m↑0.17%[0m) [0.15% of initial]
Iter:18399, L1 loss=0.0004291, Total loss=0.0003775, Time:94
[Iter 18400/20000] Loss: 0.0003853 (Best: 0.0002767 @iter17620) ([91m↑1.46%[0m) [0.15% of initial]
[Iter 18410/20000] Loss: 0.0004044 (Best: 0.0002767 @iter17620) ([91m↑4.94%[0m) [0.16% of initial]
[Iter 18420/20000] Loss: 0.0004018 (Best: 0.0002767 @iter17620) ([92m↓0.62%[0m) [0.16% of initial]
[Iter 18430/20000] Loss: 0.0004081 (Best: 0.0002767 @iter17620) ([91m↑1.57%[0m) [0.16% of initial]
[Iter 18440/20000] Loss: 0.0003917 (Best: 0.0002767 @iter17620) ([92m↓4.02%[0m) [0.16% of initial]
[Iter 18450/20000] Loss: 0.0003813 (Best: 0.0002767 @iter17620) ([92m↓2.65%[0m) [0.15% of initial]
[Iter 18460/20000] Loss: 0.0003865 (Best: 0.0002767 @iter17620) ([91m↑1.34%[0m) [0.15% of initial]
[Iter 18470/20000] Loss: 0.0003768 (Best: 0.0002767 @iter17620) ([92m↓2.49%[0m) [0.15% of initial]
[Iter 18480/20000] Loss: 0.0003849 (Best: 0.0002767 @iter17620) ([91m↑2.15%[0m) [0.15% of initial]
[Iter 18490/20000] Loss: 0.0004014 (Best: 0.0002767 @iter17620) ([91m↑4.28%[0m) [0.16% of initial]
Iter:18499, L1 loss=0.0004273, Total loss=0.0003693, Time:74
[Iter 18500/20000] Loss: 0.0003854 (Best: 0.0002767 @iter17620) ([92m↓3.98%[0m) [0.15% of initial]
Pruning 4 points (0.0%) from gaussian0 at iteration 18500
Pruning 4 points (0.0%) from gaussian1 at iteration 18500
[Iter 18510/20000] Loss: 0.0006808 (Best: 0.0002767 @iter17620) ([91m↑76.63%[0m) [0.27% of initial]
[Iter 18520/20000] Loss: 0.0004765 (Best: 0.0002767 @iter17620) ([92m↓30.01%[0m) [0.19% of initial]
[Iter 18530/20000] Loss: 0.0004028 (Best: 0.0002767 @iter17620) ([92m↓15.46%[0m) [0.16% of initial]
[Iter 18540/20000] Loss: 0.0003943 (Best: 0.0002767 @iter17620) ([92m↓2.11%[0m) [0.16% of initial]
[Iter 18550/20000] Loss: 0.0003768 (Best: 0.0002767 @iter17620) ([92m↓4.43%[0m) [0.15% of initial]
[Iter 18560/20000] Loss: 0.0003674 (Best: 0.0002767 @iter17620) ([92m↓2.51%[0m) [0.15% of initial]
[Iter 18570/20000] Loss: 0.0003583 (Best: 0.0002767 @iter17620) ([92m↓2.46%[0m) [0.14% of initial]
[Iter 18580/20000] Loss: 0.0003585 (Best: 0.0002767 @iter17620) ([91m↑0.06%[0m) [0.14% of initial]
[Iter 18590/20000] Loss: 0.0003573 (Best: 0.0002767 @iter17620) ([92m↓0.34%[0m) [0.14% of initial]
Iter:18599, L1 loss=0.0004239, Total loss=0.0003779, Time:80
[Iter 18600/20000] Loss: 0.0003688 (Best: 0.0002767 @iter17620) ([91m↑3.21%[0m) [0.15% of initial]
[Iter 18610/20000] Loss: 0.0003568 (Best: 0.0002767 @iter17620) ([92m↓3.25%[0m) [0.14% of initial]
[Iter 18620/20000] Loss: 0.0003538 (Best: 0.0002767 @iter17620) ([92m↓0.83%[0m) [0.14% of initial]
[Iter 18630/20000] Loss: 0.0003669 (Best: 0.0002767 @iter17620) ([91m↑3.70%[0m) [0.15% of initial]
[Iter 18640/20000] Loss: 0.0003678 (Best: 0.0002767 @iter17620) ([91m↑0.24%[0m) [0.15% of initial]
[Iter 18650/20000] Loss: 0.0003745 (Best: 0.0002767 @iter17620) ([91m↑1.83%[0m) [0.15% of initial]
[Iter 18660/20000] Loss: 0.0003741 (Best: 0.0002767 @iter17620) ([92m↓0.11%[0m) [0.15% of initial]
[Iter 18670/20000] Loss: 0.0003761 (Best: 0.0002767 @iter17620) ([91m↑0.54%[0m) [0.15% of initial]
[Iter 18680/20000] Loss: 0.0003962 (Best: 0.0002767 @iter17620) ([91m↑5.35%[0m) [0.16% of initial]
[Iter 18690/20000] Loss: 0.0003866 (Best: 0.0002767 @iter17620) ([92m↓2.42%[0m) [0.15% of initial]
Iter:18699, L1 loss=0.000442, Total loss=0.0003885, Time:63
[Iter 18700/20000] Loss: 0.0003790 (Best: 0.0002767 @iter17620) ([92m↓1.98%[0m) [0.15% of initial]
[Iter 18710/20000] Loss: 0.0003804 (Best: 0.0002767 @iter17620) ([91m↑0.38%[0m) [0.15% of initial]
[Iter 18720/20000] Loss: 0.0003925 (Best: 0.0002767 @iter17620) ([91m↑3.17%[0m) [0.16% of initial]
[Iter 18730/20000] Loss: 0.0003974 (Best: 0.0002767 @iter17620) ([91m↑1.26%[0m) [0.16% of initial]
[Iter 18740/20000] Loss: 0.0003869 (Best: 0.0002767 @iter17620) ([92m↓2.63%[0m) [0.15% of initial]
[Iter 18750/20000] Loss: 0.0004203 (Best: 0.0002767 @iter17620) ([91m↑8.63%[0m) [0.17% of initial]
[Iter 18760/20000] Loss: 0.0004282 (Best: 0.0002767 @iter17620) ([91m↑1.87%[0m) [0.17% of initial]
[Iter 18770/20000] Loss: 0.0004093 (Best: 0.0002767 @iter17620) ([92m↓4.41%[0m) [0.16% of initial]
[Iter 18780/20000] Loss: 0.0003827 (Best: 0.0002767 @iter17620) ([92m↓6.50%[0m) [0.15% of initial]
[Iter 18790/20000] Loss: 0.0003808 (Best: 0.0002767 @iter17620) ([92m↓0.50%[0m) [0.15% of initial]
Iter:18799, L1 loss=0.0004237, Total loss=0.0003819, Time:76
[Iter 18800/20000] Loss: 0.0003716 (Best: 0.0002767 @iter17620) ([92m↓2.42%[0m) [0.15% of initial]
[Iter 18810/20000] Loss: 0.0003578 (Best: 0.0002767 @iter17620) ([92m↓3.72%[0m) [0.14% of initial]
[Iter 18820/20000] Loss: 0.0003579 (Best: 0.0002767 @iter17620) ([91m↑0.02%[0m) [0.14% of initial]
[Iter 18830/20000] Loss: 0.0003666 (Best: 0.0002767 @iter17620) ([91m↑2.45%[0m) [0.15% of initial]
[Iter 18840/20000] Loss: 0.0003689 (Best: 0.0002767 @iter17620) ([91m↑0.62%[0m) [0.15% of initial]
[Iter 18850/20000] Loss: 0.0003943 (Best: 0.0002767 @iter17620) ([91m↑6.88%[0m) [0.16% of initial]
[Iter 18860/20000] Loss: 0.0003859 (Best: 0.0002767 @iter17620) ([92m↓2.12%[0m) [0.15% of initial]
[Iter 18870/20000] Loss: 0.0003780 (Best: 0.0002767 @iter17620) ([92m↓2.05%[0m) [0.15% of initial]
[Iter 18880/20000] Loss: 0.0003821 (Best: 0.0002767 @iter17620) ([91m↑1.08%[0m) [0.15% of initial]
[Iter 18890/20000] Loss: 0.0003671 (Best: 0.0002767 @iter17620) ([92m↓3.93%[0m) [0.15% of initial]
Iter:18899, L1 loss=0.0004338, Total loss=0.0003659, Time:91
[Iter 18900/20000] Loss: 0.0003898 (Best: 0.0002767 @iter17620) ([91m↑6.18%[0m) [0.15% of initial]
[Iter 18910/20000] Loss: 0.0003823 (Best: 0.0002767 @iter17620) ([92m↓1.92%[0m) [0.15% of initial]
[Iter 18920/20000] Loss: 0.0003687 (Best: 0.0002767 @iter17620) ([92m↓3.55%[0m) [0.15% of initial]
[Iter 18930/20000] Loss: 0.0003754 (Best: 0.0002767 @iter17620) ([91m↑1.81%[0m) [0.15% of initial]
[Iter 18940/20000] Loss: 0.0003873 (Best: 0.0002767 @iter17620) ([91m↑3.18%[0m) [0.15% of initial]
[Iter 18950/20000] Loss: 0.0003949 (Best: 0.0002767 @iter17620) ([91m↑1.95%[0m) [0.16% of initial]
[Iter 18960/20000] Loss: 0.0003740 (Best: 0.0002767 @iter17620) ([92m↓5.28%[0m) [0.15% of initial]
[Iter 18970/20000] Loss: 0.0003712 (Best: 0.0002767 @iter17620) ([92m↓0.77%[0m) [0.15% of initial]
[Iter 18980/20000] Loss: 0.0003641 (Best: 0.0002767 @iter17620) ([92m↓1.90%[0m) [0.14% of initial]
[Iter 18990/20000] Loss: 0.0003661 (Best: 0.0002767 @iter17620) ([91m↑0.53%[0m) [0.15% of initial]
Iter:18999, L1 loss=0.0004541, Total loss=0.0003849, Time:85
[Iter 19000/20000] Loss: 0.0003809 (Best: 0.0002767 @iter17620) ([91m↑4.05%[0m) [0.15% of initial]
Pruning 3 points (0.0%) from gaussian0 at iteration 19000
Pruning 5 points (0.0%) from gaussian1 at iteration 19000
[Iter 19010/20000] Loss: 0.0007230 (Best: 0.0002767 @iter17620) ([91m↑89.82%[0m) [0.29% of initial]
[Iter 19020/20000] Loss: 0.0004850 (Best: 0.0002767 @iter17620) ([92m↓32.92%[0m) [0.19% of initial]
[Iter 19030/20000] Loss: 0.0004211 (Best: 0.0002767 @iter17620) ([92m↓13.17%[0m) [0.17% of initial]
[Iter 19040/20000] Loss: 0.0003960 (Best: 0.0002767 @iter17620) ([92m↓5.95%[0m) [0.16% of initial]
[Iter 19050/20000] Loss: 0.0003720 (Best: 0.0002767 @iter17620) ([92m↓6.06%[0m) [0.15% of initial]
[Iter 19060/20000] Loss: 0.0003576 (Best: 0.0002767 @iter17620) ([92m↓3.89%[0m) [0.14% of initial]
[Iter 19070/20000] Loss: 0.0003519 (Best: 0.0002767 @iter17620) ([92m↓1.58%[0m) [0.14% of initial]
[Iter 19080/20000] Loss: 0.0003445 (Best: 0.0002767 @iter17620) ([92m↓2.10%[0m) [0.14% of initial]
[Iter 19090/20000] Loss: 0.0003496 (Best: 0.0002767 @iter17620) ([91m↑1.48%[0m) [0.14% of initial]
Iter:19099, L1 loss=0.0003757, Total loss=0.0003327, Time:86
[Iter 19100/20000] Loss: 0.0003520 (Best: 0.0002767 @iter17620) ([91m↑0.68%[0m) [0.14% of initial]
[Iter 19110/20000] Loss: 0.0003701 (Best: 0.0002767 @iter17620) ([91m↑5.15%[0m) [0.15% of initial]
[Iter 19120/20000] Loss: 0.0003666 (Best: 0.0002767 @iter17620) ([92m↓0.94%[0m) [0.15% of initial]
[Iter 19130/20000] Loss: 0.0003469 (Best: 0.0002767 @iter17620) ([92m↓5.37%[0m) [0.14% of initial]
[Iter 19140/20000] Loss: 0.0003580 (Best: 0.0002767 @iter17620) ([91m↑3.18%[0m) [0.14% of initial]
[Iter 19150/20000] Loss: 0.0003499 (Best: 0.0002767 @iter17620) ([92m↓2.24%[0m) [0.14% of initial]
[Iter 19160/20000] Loss: 0.0003913 (Best: 0.0002767 @iter17620) ([91m↑11.81%[0m) [0.16% of initial]
[Iter 19170/20000] Loss: 0.0004052 (Best: 0.0002767 @iter17620) ([91m↑3.57%[0m) [0.16% of initial]
[Iter 19180/20000] Loss: 0.0004027 (Best: 0.0002767 @iter17620) ([92m↓0.63%[0m) [0.16% of initial]
[Iter 19190/20000] Loss: 0.0003616 (Best: 0.0002767 @iter17620) ([92m↓10.21%[0m) [0.14% of initial]
Iter:19199, L1 loss=0.0004324, Total loss=0.0003657, Time:91
[Iter 19200/20000] Loss: 0.0003592 (Best: 0.0002767 @iter17620) ([92m↓0.65%[0m) [0.14% of initial]
[Iter 19210/20000] Loss: 0.0003489 (Best: 0.0002767 @iter17620) ([92m↓2.87%[0m) [0.14% of initial]
[Iter 19220/20000] Loss: 0.0003700 (Best: 0.0002767 @iter17620) ([91m↑6.06%[0m) [0.15% of initial]
[Iter 19230/20000] Loss: 0.0003758 (Best: 0.0002767 @iter17620) ([91m↑1.55%[0m) [0.15% of initial]
[Iter 19240/20000] Loss: 0.0003883 (Best: 0.0002767 @iter17620) ([91m↑3.34%[0m) [0.15% of initial]
[Iter 19250/20000] Loss: 0.0003950 (Best: 0.0002767 @iter17620) ([91m↑1.72%[0m) [0.16% of initial]
[Iter 19260/20000] Loss: 0.0003719 (Best: 0.0002767 @iter17620) ([92m↓5.86%[0m) [0.15% of initial]
[Iter 19270/20000] Loss: 0.0003725 (Best: 0.0002767 @iter17620) ([91m↑0.16%[0m) [0.15% of initial]
[Iter 19280/20000] Loss: 0.0003654 (Best: 0.0002767 @iter17620) ([92m↓1.91%[0m) [0.15% of initial]
[Iter 19290/20000] Loss: 0.0003449 (Best: 0.0002767 @iter17620) ([92m↓5.60%[0m) [0.14% of initial]
Iter:19299, L1 loss=0.0003864, Total loss=0.0003514, Time:89
[Iter 19300/20000] Loss: 0.0003444 (Best: 0.0002767 @iter17620) ([92m↓0.13%[0m) [0.14% of initial]
[Iter 19310/20000] Loss: 0.0003643 (Best: 0.0002767 @iter17620) ([91m↑5.78%[0m) [0.14% of initial]
[Iter 19320/20000] Loss: 0.0003913 (Best: 0.0002767 @iter17620) ([91m↑7.39%[0m) [0.16% of initial]
[Iter 19330/20000] Loss: 0.0003850 (Best: 0.0002767 @iter17620) ([92m↓1.62%[0m) [0.15% of initial]
[Iter 19340/20000] Loss: 0.0003698 (Best: 0.0002767 @iter17620) ([92m↓3.92%[0m) [0.15% of initial]
[Iter 19350/20000] Loss: 0.0003473 (Best: 0.0002767 @iter17620) ([92m↓6.10%[0m) [0.14% of initial]
[Iter 19360/20000] Loss: 0.0003312 (Best: 0.0002767 @iter17620) ([92m↓4.64%[0m) [0.13% of initial]
[Iter 19370/20000] Loss: 0.0003400 (Best: 0.0002767 @iter17620) ([91m↑2.66%[0m) [0.14% of initial]
[Iter 19380/20000] Loss: 0.0003420 (Best: 0.0002767 @iter17620) ([91m↑0.59%[0m) [0.14% of initial]
[Iter 19390/20000] Loss: 0.0003425 (Best: 0.0002767 @iter17620) ([91m↑0.16%[0m) [0.14% of initial]
Iter:19399, L1 loss=0.0004687, Total loss=0.0003614, Time:63
[Iter 19400/20000] Loss: 0.0003573 (Best: 0.0002767 @iter17620) ([91m↑4.31%[0m) [0.14% of initial]
[Iter 19410/20000] Loss: 0.0004096 (Best: 0.0002767 @iter17620) ([91m↑14.64%[0m) [0.16% of initial]
[Iter 19420/20000] Loss: 0.0004010 (Best: 0.0002767 @iter17620) ([92m↓2.10%[0m) [0.16% of initial]
[Iter 19430/20000] Loss: 0.0004464 (Best: 0.0002767 @iter17620) ([91m↑11.32%[0m) [0.18% of initial]
[Iter 19440/20000] Loss: 0.0004069 (Best: 0.0002767 @iter17620) ([92m↓8.86%[0m) [0.16% of initial]
[Iter 19450/20000] Loss: 0.0003642 (Best: 0.0002767 @iter17620) ([92m↓10.50%[0m) [0.14% of initial]
[Iter 19460/20000] Loss: 0.0003680 (Best: 0.0002767 @iter17620) ([91m↑1.06%[0m) [0.15% of initial]
[Iter 19470/20000] Loss: 0.0003766 (Best: 0.0002767 @iter17620) ([91m↑2.33%[0m) [0.15% of initial]
[Iter 19480/20000] Loss: 0.0003623 (Best: 0.0002767 @iter17620) ([92m↓3.80%[0m) [0.14% of initial]
[Iter 19490/20000] Loss: 0.0003484 (Best: 0.0002767 @iter17620) ([92m↓3.82%[0m) [0.14% of initial]
Iter:19499, L1 loss=0.0003723, Total loss=0.000333, Time:66
[Iter 19500/20000] Loss: 0.0003560 (Best: 0.0002767 @iter17620) ([91m↑2.18%[0m) [0.14% of initial]
Pruning 1 points (0.0%) from gaussian0 at iteration 19500
Pruning 2 points (0.0%) from gaussian1 at iteration 19500
[Iter 19510/20000] Loss: 0.0006467 (Best: 0.0002767 @iter17620) ([91m↑81.65%[0m) [0.26% of initial]
[Iter 19520/20000] Loss: 0.0004355 (Best: 0.0002767 @iter17620) ([92m↓32.66%[0m) [0.17% of initial]
[Iter 19530/20000] Loss: 0.0004177 (Best: 0.0002767 @iter17620) ([92m↓4.09%[0m) [0.17% of initial]
[Iter 19540/20000] Loss: 0.0003716 (Best: 0.0002767 @iter17620) ([92m↓11.04%[0m) [0.15% of initial]
[Iter 19550/20000] Loss: 0.0003419 (Best: 0.0002767 @iter17620) ([92m↓8.00%[0m) [0.14% of initial]
[Iter 19560/20000] Loss: 0.0003660 (Best: 0.0002767 @iter17620) ([91m↑7.06%[0m) [0.15% of initial]
[Iter 19570/20000] Loss: 0.0003379 (Best: 0.0002767 @iter17620) ([92m↓7.69%[0m) [0.13% of initial]
[Iter 19580/20000] Loss: 0.0003534 (Best: 0.0002767 @iter17620) ([91m↑4.61%[0m) [0.14% of initial]
[Iter 19590/20000] Loss: 0.0003364 (Best: 0.0002767 @iter17620) ([92m↓4.81%[0m) [0.13% of initial]
Iter:19599, L1 loss=0.0003679, Total loss=0.0003298, Time:69
[Iter 19600/20000] Loss: 0.0003270 (Best: 0.0002767 @iter17620) ([92m↓2.82%[0m) [0.13% of initial]
[Iter 19610/20000] Loss: 0.0003415 (Best: 0.0002767 @iter17620) ([91m↑4.45%[0m) [0.14% of initial]
[Iter 19620/20000] Loss: 0.0003416 (Best: 0.0002767 @iter17620) ([91m↑0.03%[0m) [0.14% of initial]
[Iter 19630/20000] Loss: 0.0003345 (Best: 0.0002767 @iter17620) ([92m↓2.08%[0m) [0.13% of initial]
[Iter 19640/20000] Loss: 0.0003804 (Best: 0.0002767 @iter17620) ([91m↑13.73%[0m) [0.15% of initial]
[Iter 19650/20000] Loss: 0.0003633 (Best: 0.0002767 @iter17620) ([92m↓4.50%[0m) [0.14% of initial]
[Iter 19660/20000] Loss: 0.0003510 (Best: 0.0002767 @iter17620) ([92m↓3.39%[0m) [0.14% of initial]
[Iter 19670/20000] Loss: 0.0003406 (Best: 0.0002767 @iter17620) ([92m↓2.96%[0m) [0.14% of initial]
[Iter 19680/20000] Loss: 0.0003456 (Best: 0.0002767 @iter17620) ([91m↑1.48%[0m) [0.14% of initial]
[Iter 19690/20000] Loss: 0.0003499 (Best: 0.0002767 @iter17620) ([91m↑1.24%[0m) [0.14% of initial]
Iter:19699, L1 loss=0.000421, Total loss=0.0003866, Time:74
[Iter 19700/20000] Loss: 0.0003830 (Best: 0.0002767 @iter17620) ([91m↑9.47%[0m) [0.15% of initial]
[Iter 19710/20000] Loss: 0.0003707 (Best: 0.0002767 @iter17620) ([92m↓3.22%[0m) [0.15% of initial]
[Iter 19720/20000] Loss: 0.0003805 (Best: 0.0002767 @iter17620) ([91m↑2.65%[0m) [0.15% of initial]
[Iter 19730/20000] Loss: 0.0003424 (Best: 0.0002767 @iter17620) ([92m↓10.01%[0m) [0.14% of initial]
[Iter 19740/20000] Loss: 0.0003599 (Best: 0.0002767 @iter17620) ([91m↑5.10%[0m) [0.14% of initial]
[Iter 19750/20000] Loss: 0.0003872 (Best: 0.0002767 @iter17620) ([91m↑7.58%[0m) [0.15% of initial]
[Iter 19760/20000] Loss: 0.0004691 (Best: 0.0002767 @iter17620) ([91m↑21.16%[0m) [0.19% of initial]
[Iter 19770/20000] Loss: 0.0004434 (Best: 0.0002767 @iter17620) ([92m↓5.48%[0m) [0.18% of initial]
[Iter 19780/20000] Loss: 0.0003799 (Best: 0.0002767 @iter17620) ([92m↓14.32%[0m) [0.15% of initial]
[Iter 19790/20000] Loss: 0.0003619 (Best: 0.0002767 @iter17620) ([92m↓4.75%[0m) [0.14% of initial]
Iter:19799, L1 loss=0.0003981, Total loss=0.0003437, Time:80
[Iter 19800/20000] Loss: 0.0003648 (Best: 0.0002767 @iter17620) ([91m↑0.80%[0m) [0.14% of initial]
[Iter 19810/20000] Loss: 0.0003441 (Best: 0.0002767 @iter17620) ([92m↓5.66%[0m) [0.14% of initial]
[Iter 19820/20000] Loss: 0.0003821 (Best: 0.0002767 @iter17620) ([91m↑11.04%[0m) [0.15% of initial]
[Iter 19830/20000] Loss: 0.0003812 (Best: 0.0002767 @iter17620) ([92m↓0.23%[0m) [0.15% of initial]
[Iter 19840/20000] Loss: 0.0003442 (Best: 0.0002767 @iter17620) ([92m↓9.70%[0m) [0.14% of initial]
[Iter 19850/20000] Loss: 0.0003356 (Best: 0.0002767 @iter17620) ([92m↓2.51%[0m) [0.13% of initial]
[Iter 19860/20000] Loss: 0.0003675 (Best: 0.0002767 @iter17620) ([91m↑9.50%[0m) [0.15% of initial]
[Iter 19870/20000] Loss: 0.0003807 (Best: 0.0002767 @iter17620) ([91m↑3.60%[0m) [0.15% of initial]
[Iter 19880/20000] Loss: 0.0003856 (Best: 0.0002767 @iter17620) ([91m↑1.28%[0m) [0.15% of initial]
[Iter 19890/20000] Loss: 0.0003688 (Best: 0.0002767 @iter17620) ([92m↓4.37%[0m) [0.15% of initial]
Iter:19899, L1 loss=0.0004479, Total loss=0.0004054, Time:74
[Iter 19900/20000] Loss: 0.0004200 (Best: 0.0002767 @iter17620) ([91m↑13.91%[0m) [0.17% of initial]
[Iter 19910/20000] Loss: 0.0003786 (Best: 0.0002767 @iter17620) ([92m↓9.87%[0m) [0.15% of initial]
[Iter 19920/20000] Loss: 0.0003842 (Best: 0.0002767 @iter17620) ([91m↑1.48%[0m) [0.15% of initial]
[Iter 19930/20000] Loss: 0.0003862 (Best: 0.0002767 @iter17620) ([91m↑0.53%[0m) [0.15% of initial]
[Iter 19940/20000] Loss: 0.0003774 (Best: 0.0002767 @iter17620) ([92m↓2.28%[0m) [0.15% of initial]
[Iter 19950/20000] Loss: 0.0003443 (Best: 0.0002767 @iter17620) ([92m↓8.77%[0m) [0.14% of initial]
[Iter 19960/20000] Loss: 0.0003332 (Best: 0.0002767 @iter17620) ([92m↓3.22%[0m) [0.13% of initial]
[Iter 19970/20000] Loss: 0.0003318 (Best: 0.0002767 @iter17620) ([92m↓0.42%[0m) [0.13% of initial]
[Iter 19980/20000] Loss: 0.0003384 (Best: 0.0002767 @iter17620) ([91m↑1.98%[0m) [0.13% of initial]
[Iter 19990/20000] Loss: 0.0003287 (Best: 0.0002767 @iter17620) ([92m↓2.86%[0m) [0.13% of initial]
Iter:19999, L1 loss=0.0003816, Total loss=0.000336, Time:72
[Iter 20000/20000] Loss: 0.0003504 (Best: 0.0002767 @iter17620) ([91m↑6.61%[0m) [0.14% of initial]
Testing Speed: 45.28166631363778 fps
Testing Time: 1.1041996479034424 s

[ITER 20000] Evaluating test: SSIM = 0.9089721381664276, PSNR = 20.027616233825682
Testing Speed: 53.56345246811626 fps
Testing Time: 0.056008338928222656 s

[ITER 20000] Evaluating train: SSIM = 0.9999983906745911, PSNR = 62.97816848754883
Iter:20000, total_points:127815

[ITER 20000] Saving Gaussians
Pruning 7 points (0.0%) from gaussian0 at iteration 20000
Pruning 3 points (0.0%) from gaussian1 at iteration 20000

Training completed!
==================================================
Body part: chest
Testing Speed: 45 fps
Total time: 34.12 minutes
Test SSIM: 0.9090
Test PSNR: 20.028
Gaussian0 final points count: 127808
Gaussian1 final points count: 133177
Final loss: 0.0003504 (0.14% of initial)
Save path: 2024_11_26_21_25_37
Initial loss: 0.2517052
Best loss: 0.0002767 @iteration 17620 (0.11% of initial)
Train SSIM: 1.0000
Train PSNR: 62.978
==================================================
Final pseudo view loss: 0.0000000
==================================================

Training complete.
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126909 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693032 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374905 (Best: 0.1327878 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123921 (Best: 0.1098390 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993468 (Best: 0.0965489 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936753 (Best: 0.0908540 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884465 (Best: 0.0869364 @iter70) ([92m↓5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851848 (Best: 0.0830963 @iter80) ([92m↓3.69%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824058 (Best: 0.0801449 @iter88) ([92m↓3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05724, Total loss=0.07876, Time:42
[Iter 100/20000] Loss: 0.0786595 (Best: 0.0766087 @iter97) ([92m↓4.55%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753242 (Best: 0.0731252 @iter106) ([92m↓4.24%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714237 (Best: 0.0685585 @iter118) ([92m↓5.18%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0666986 (Best: 0.0641969 @iter130) ([92m↓6.62%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635370 (Best: 0.0612889 @iter140) ([92m↓4.74%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612764 (Best: 0.0584009 @iter148) ([92m↓3.56%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590557 (Best: 0.0559354 @iter157) ([92m↓3.62%[0m) [23.46% of initial]
[Iter 170/20000] Loss: 0.0563615 (Best: 0.0535022 @iter167) ([92m↓4.56%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523293 (Best: 0.0499921 @iter179) ([92m↓7.15%[0m) [20.79% of initial]
[Iter 190/20000] Loss: 0.0495401 (Best: 0.0478181 @iter188) ([92m↓5.33%[0m) [19.68% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126909 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693033 @iter20) ([92m↓19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327880 @iter30) ([92m↓21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123922 (Best: 0.1098371 @iter40) ([92m↓18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993454 (Best: 0.0965445 @iter49) ([92m↓11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936773 (Best: 0.0908497 @iter59) ([92m↓5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884554 (Best: 0.0869448 @iter70) ([92m↓5.57%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851861 (Best: 0.0831026 @iter80) ([92m↓3.70%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824191 (Best: 0.0801631 @iter88) ([92m↓3.25%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07877, Time:49
[Iter 100/20000] Loss: 0.0786740 (Best: 0.0766274 @iter97) ([92m↓4.54%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753382 (Best: 0.0731600 @iter106) ([92m↓4.24%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714443 (Best: 0.0685791 @iter118) ([92m↓5.17%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0667115 (Best: 0.0642208 @iter130) ([92m↓6.62%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635552 (Best: 0.0613071 @iter140) ([92m↓4.73%[0m) [25.25% of initial]
[Iter 150/20000] Loss: 0.0612762 (Best: 0.0584018 @iter148) ([92m↓3.59%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590746 (Best: 0.0559613 @iter157) ([92m↓3.59%[0m) [23.47% of initial]
[Iter 170/20000] Loss: 0.0563536 (Best: 0.0535317 @iter167) ([92m↓4.61%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523448 (Best: 0.0500114 @iter179) ([92m↓7.11%[0m) [20.80% of initial]
[Iter 190/20000] Loss: 0.0495236 (Best: 0.0478075 @iter188) ([92m↓5.39%[0m) [19.68% of initial]
Iter:199, L1 loss=0.03443, Total loss=0.04978, Time:42
[Iter 200/20000] Loss: 0.0478340 (Best: 0.0456763 @iter198) ([92m↓3.41%[0m) [19.00% of initial]
[Iter 210/20000] Loss: 0.0450546 (Best: 0.0428191 @iter209) ([92m↓5.81%[0m) [17.90% of initial]
[Iter 220/20000] Loss: 0.0440611 (Best: 0.0412072 @iter219) ([92m↓2.21%[0m) [17.51% of initial]
[Iter 230/20000] Loss: 0.0423382 (Best: 0.0399538 @iter227) ([92m↓3.91%[0m) [16.82% of initial]
[Iter 240/20000] Loss: 0.0402232 (Best: 0.0377267 @iter238) ([92m↓5.00%[0m) [15.98% of initial]
[Iter 250/20000] Loss: 0.0379732 (Best: 0.0362227 @iter248) ([92m↓5.59%[0m) [15.09% of initial]
[Iter 260/20000] Loss: 0.0358702 (Best: 0.0343281 @iter260) ([92m↓5.54%[0m) [14.25% of initial]
[Iter 270/20000] Loss: 0.0349383 (Best: 0.0327299 @iter269) ([92m↓2.60%[0m) [13.88% of initial]
[Iter 280/20000] Loss: 0.0347594 (Best: 0.0319442 @iter277) ([92m↓0.51%[0m) [13.81% of initial]
[Iter 290/20000] Loss: 0.0330733 (Best: 0.0305922 @iter287) ([92m↓4.85%[0m) [13.14% of initial]
Iter:299, L1 loss=0.02216, Total loss=0.03333, Time:43
[Iter 300/20000] Loss: 0.0307796 (Best: 0.0289305 @iter300) ([92m↓6.94%[0m) [12.23% of initial]
[Iter 310/20000] Loss: 0.0292822 (Best: 0.0272951 @iter310) ([92m↓4.86%[0m) [11.63% of initial]
[Iter 320/20000] Loss: 0.0278463 (Best: 0.0263901 @iter320) ([92m↓4.90%[0m) [11.06% of initial]
[Iter 330/20000] Loss: 0.0274392 (Best: 0.0254940 @iter330) ([92m↓1.46%[0m) [10.90% of initial]
[Iter 340/20000] Loss: 0.0252741 (Best: 0.0241836 @iter340) ([92m↓7.89%[0m) [10.04% of initial]
[Iter 350/20000] Loss: 0.0259192 (Best: 0.0232773 @iter349) ([91m↑2.55%[0m) [10.30% of initial]
[Iter 360/20000] Loss: 0.0243514 (Best: 0.0223177 @iter358) ([92m↓6.05%[0m) [9.67% of initial]
[Iter 370/20000] Loss: 0.0239472 (Best: 0.0217782 @iter368) ([92m↓1.66%[0m) [9.51% of initial]
[Iter 380/20000] Loss: 0.0218300 (Best: 0.0208768 @iter379) ([92m↓8.84%[0m) [8.67% of initial]
[Iter 390/20000] Loss: 0.0215281 (Best: 0.0201210 @iter390) ([92m↓1.38%[0m) [8.55% of initial]
Iter:399, L1 loss=0.0136, Total loss=0.02126, Time:50
[Iter 400/20000] Loss: 0.0204736 (Best: 0.0189553 @iter400) ([92m↓4.90%[0m) [8.13% of initial]
[Iter 410/20000] Loss: 0.0194721 (Best: 0.0183809 @iter410) ([92m↓4.89%[0m) [7.74% of initial]
[Iter 420/20000] Loss: 0.0198946 (Best: 0.0176958 @iter418) ([91m↑2.17%[0m) [7.90% of initial]
[Iter 430/20000] Loss: 0.0178757 (Best: 0.0169480 @iter430) ([92m↓10.15%[0m) [7.10% of initial]
[Iter 440/20000] Loss: 0.0187960 (Best: 0.0169480 @iter430) ([91m↑5.15%[0m) [7.47% of initial]
[Iter 450/20000] Loss: 0.0178307 (Best: 0.0159639 @iter449) ([92m↓5.14%[0m) [7.08% of initial]
[Iter 460/20000] Loss: 0.0172119 (Best: 0.0152655 @iter458) ([92m↓3.47%[0m) [6.84% of initial]
[Iter 470/20000] Loss: 0.0157201 (Best: 0.0145995 @iter470) ([92m↓8.67%[0m) [6.25% of initial]
[Iter 480/20000] Loss: 0.0155694 (Best: 0.0140138 @iter479) ([92m↓0.96%[0m) [6.19% of initial]
[Iter 490/20000] Loss: 0.0144224 (Best: 0.0131859 @iter490) ([92m↓7.37%[0m) [5.73% of initial]
Iter:499, L1 loss=0.008437, Total loss=0.01504, Time:45
[Iter 500/20000] Loss: 0.0140976 (Best: 0.0129135 @iter498) ([92m↓2.25%[0m) [5.60% of initial]
[Iter 510/20000] Loss: 0.0135258 (Best: 0.0122340 @iter508) ([92m↓4.06%[0m) [5.37% of initial]
[Iter 520/20000] Loss: 0.0127723 (Best: 0.0114265 @iter514) ([92m↓5.57%[0m) [5.07% of initial]
[Iter 530/20000] Loss: 0.0122189 (Best: 0.0110377 @iter529) ([92m↓4.33%[0m) [4.85% of initial]
[Iter 540/20000] Loss: 0.0123129 (Best: 0.0110377 @iter529) ([91m↑0.77%[0m) [4.89% of initial]
[Iter 550/20000] Loss: 0.0118798 (Best: 0.0109183 @iter548) ([92m↓3.52%[0m) [4.72% of initial]
[Iter 560/20000] Loss: 0.0119732 (Best: 0.0106121 @iter556) ([91m↑0.79%[0m) [4.76% of initial]
[Iter 570/20000] Loss: 0.0117074 (Best: 0.0104897 @iter569) ([92m↓2.22%[0m) [4.65% of initial]
[Iter 580/20000] Loss: 0.0111712 (Best: 0.0102734 @iter578) ([92m↓4.58%[0m) [4.44% of initial]
[Iter 590/20000] Loss: 0.0115627 (Best: 0.0100050 @iter583) ([91m↑3.50%[0m) [4.59% of initial]
Iter:599, L1 loss=0.00688, Total loss=0.01165, Time:38
[Iter 600/20000] Loss: 0.0108425 (Best: 0.0098876 @iter598) ([92m↓6.23%[0m) [4.31% of initial]
[Iter 610/20000] Loss: 0.0220194 (Best: 0.0098876 @iter598) ([91m↑103.08%[0m) [8.75% of initial]
[Iter 620/20000] Loss: 0.0141799 (Best: 0.0098876 @iter598) ([92m↓35.60%[0m) [5.63% of initial]
[Iter 630/20000] Loss: 0.0118721 (Best: 0.0098876 @iter598) ([92m↓16.27%[0m) [4.72% of initial]
[Iter 640/20000] Loss: 0.0102297 (Best: 0.0093458 @iter640) ([92m↓13.83%[0m) [4.06% of initial]
[Iter 650/20000] Loss: 0.0103943 (Best: 0.0091127 @iter646) ([91m↑1.61%[0m) [4.13% of initial]
[Iter 660/20000] Loss: 0.0100136 (Best: 0.0087797 @iter655) ([92m↓3.66%[0m) [3.98% of initial]
[Iter 670/20000] Loss: 0.0097753 (Best: 0.0086339 @iter667) ([92m↓2.38%[0m) [3.88% of initial]
[Iter 680/20000] Loss: 0.0088644 (Best: 0.0082000 @iter680) ([92m↓9.32%[0m) [3.52% of initial]
[Iter 690/20000] Loss: 0.0089932 (Best: 0.0079132 @iter682) ([91m↑1.45%[0m) [3.57% of initial]
Iter:699, L1 loss=0.005768, Total loss=0.009457, Time:25
[Iter 700/20000] Loss: 0.0088785 (Best: 0.0078090 @iter695) ([92m↓1.28%[0m) [3.53% of initial]
[Iter 710/20000] Loss: 0.0082749 (Best: 0.0075824 @iter703) ([92m↓6.80%[0m) [3.29% of initial]
[Iter 720/20000] Loss: 0.0082919 (Best: 0.0074732 @iter715) ([91m↑0.20%[0m) [3.29% of initial]
[Iter 730/20000] Loss: 0.0083916 (Best: 0.0072230 @iter727) ([91m↑1.20%[0m) [3.33% of initial]
[Iter 740/20000] Loss: 0.0083674 (Best: 0.0071262 @iter733) ([92m↓0.29%[0m) [3.32% of initial]
[Iter 750/20000] Loss: 0.0079368 (Best: 0.0068707 @iter748) ([92m↓5.15%[0m) [3.15% of initial]
[Iter 760/20000] Loss: 0.0073315 (Best: 0.0068035 @iter754) ([92m↓7.63%[0m) [2.91% of initial]
[Iter 770/20000] Loss: 0.0074857 (Best: 0.0068035 @iter754) ([91m↑2.10%[0m) [2.97% of initial]
[Iter 780/20000] Loss: 0.0076923 (Best: 0.0065667 @iter778) ([91m↑2.76%[0m) [3.06% of initial]
[Iter 790/20000] Loss: 0.0074879 (Best: 0.0064403 @iter787) ([92m↓2.66%[0m) [2.97% of initial]
Iter:799, L1 loss=0.005008, Total loss=0.008022, Time:43
[Iter 800/20000] Loss: 0.0073212 (Best: 0.0064403 @iter787) ([92m↓2.23%[0m) [2.91% of initial]
[Iter 810/20000] Loss: 0.0163199 (Best: 0.0064403 @iter787) ([91m↑122.91%[0m) [6.48% of initial]
[Iter 820/20000] Loss: 0.0108436 (Best: 0.0064403 @iter787) ([92m↓33.56%[0m) [4.31% of initial]
[Iter 830/20000] Loss: 0.0088138 (Best: 0.0064403 @iter787) ([92m↓18.72%[0m) [3.50% of initial]
[Iter 840/20000] Loss: 0.0080229 (Best: 0.0064403 @iter787) ([92m↓8.97%[0m) [3.19% of initial]
[Iter 850/20000] Loss: 0.0075827 (Best: 0.0064403 @iter787) ([92m↓5.49%[0m) [3.01% of initial]
[Iter 860/20000] Loss: 0.0070201 (Best: 0.0061577 @iter856) ([92m↓7.42%[0m) [2.79% of initial]
[Iter 870/20000] Loss: 0.0066773 (Best: 0.0060562 @iter862) ([92m↓4.88%[0m) [2.65% of initial]
[Iter 880/20000] Loss: 0.0066201 (Best: 0.0058128 @iter875) ([92m↓0.86%[0m) [2.63% of initial]
[Iter 890/20000] Loss: 0.0062248 (Best: 0.0056084 @iter884) ([92m↓5.97%[0m) [2.47% of initial]
Iter:899, L1 loss=0.003684, Total loss=0.005481, Time:40
[Iter 900/20000] Loss: 0.0064193 (Best: 0.0054810 @iter899) ([91m↑3.13%[0m) [2.55% of initial]
[Iter 910/20000] Loss: 0.0066303 (Best: 0.0054451 @iter907) ([91m↑3.29%[0m) [2.63% of initial]
[Iter 920/20000] Loss: 0.0059189 (Best: 0.0052704 @iter913) ([92m↓10.73%[0m) [2.35% of initial]
[Iter 930/20000] Loss: 0.0062128 (Best: 0.0051713 @iter928) ([91m↑4.97%[0m) [2.47% of initial]
[Iter 940/20000] Loss: 0.0062846 (Best: 0.0051174 @iter938) ([91m↑1.16%[0m) [2.50% of initial]
[Iter 950/20000] Loss: 0.0057157 (Best: 0.0050540 @iter946) ([92m↓9.05%[0m) [2.27% of initial]
[Iter 960/20000] Loss: 0.0058893 (Best: 0.0050540 @iter946) ([91m↑3.04%[0m) [2.34% of initial]
[Iter 970/20000] Loss: 0.0058231 (Best: 0.0049791 @iter964) ([92m↓1.13%[0m) [2.31% of initial]
[Iter 980/20000] Loss: 0.0059826 (Best: 0.0049716 @iter979) ([91m↑2.74%[0m) [2.38% of initial]
[Iter 990/20000] Loss: 0.0059295 (Best: 0.0049716 @iter979) ([92m↓0.89%[0m) [2.36% of initial]
Iter:999, L1 loss=0.004404, Total loss=0.006702, Time:42
[Iter 1000/20000] Loss: 0.0062697 (Best: 0.0049716 @iter979) ([91m↑5.74%[0m) [2.49% of initial]
Pruning 942 points (6.8%) from gaussian0 at iteration 1000
Pruning 1047 points (7.5%) from gaussian1 at iteration 1000
[Iter 1010/20000] Loss: 0.0141078 (Best: 0.0049716 @iter979) ([91m↑125.02%[0m) [5.60% of initial]
[Iter 1020/20000] Loss: 0.0100227 (Best: 0.0049716 @iter979) ([92m↓28.96%[0m) [3.98% of initial]
[Iter 1030/20000] Loss: 0.0080604 (Best: 0.0049716 @iter979) ([92m↓19.58%[0m) [3.20% of initial]
[Iter 1040/20000] Loss: 0.0072470 (Best: 0.0049716 @iter979) ([92m↓10.09%[0m) [2.88% of initial]
[Iter 1050/20000] Loss: 0.0069071 (Best: 0.0049716 @iter979) ([92m↓4.69%[0m) [2.74% of initial]
[Iter 1060/20000] Loss: 0.0065955 (Best: 0.0049716 @iter979) ([92m↓4.51%[0m) [2.62% of initial]
[Iter 1070/20000] Loss: 0.0064279 (Best: 0.0049716 @iter979) ([92m↓2.54%[0m) [2.55% of initial]
[Iter 1080/20000] Loss: 0.0060270 (Best: 0.0049716 @iter979) ([92m↓6.24%[0m) [2.39% of initial]
[Iter 1090/20000] Loss: 0.0058709 (Best: 0.0049716 @iter979) ([92m↓2.59%[0m) [2.33% of initial]
Iter:1099, L1 loss=0.003807, Total loss=0.005895, Time:37
[Iter 1100/20000] Loss: 0.0057581 (Best: 0.0049716 @iter979) ([92m↓1.92%[0m) [2.29% of initial]
[Iter 1110/20000] Loss: 0.0058645 (Best: 0.0049716 @iter979) ([91m↑1.85%[0m) [2.33% of initial]
[Iter 1120/20000] Loss: 0.0058043 (Best: 0.0049702 @iter1117) ([92m↓1.03%[0m) [2.31% of initial]
[Iter 1130/20000] Loss: 0.0058647 (Best: 0.0049702 @iter1117) ([91m↑1.04%[0m) [2.33% of initial]
[Iter 1140/20000] Loss: 0.0054611 (Best: 0.0048822 @iter1135) ([92m↓6.88%[0m) [2.17% of initial]
[Iter 1150/20000] Loss: 0.0051017 (Best: 0.0047669 @iter1145) ([92m↓6.58%[0m) [2.03% of initial]
[Iter 1160/20000] Loss: 0.0057117 (Best: 0.0047083 @iter1156) ([91m↑11.96%[0m) [2.27% of initial]
[Iter 1170/20000] Loss: 0.0053248 (Best: 0.0047083 @iter1156) ([92m↓6.77%[0m) [2.12% of initial]
[Iter 1180/20000] Loss: 0.0053737 (Best: 0.0047083 @iter1156) ([91m↑0.92%[0m) [2.13% of initial]
[Iter 1190/20000] Loss: 0.0053741 (Best: 0.0046863 @iter1186) ([91m↑0.01%[0m) [2.14% of initial]
Iter:1199, L1 loss=0.00381, Total loss=0.005655, Time:44
[Iter 1200/20000] Loss: 0.0052515 (Best: 0.0045070 @iter1198) ([92m↓2.28%[0m) [2.09% of initial]
[Iter 1210/20000] Loss: 0.0119301 (Best: 0.0045070 @iter1198) ([91m↑127.18%[0m) [4.74% of initial]
[Iter 1220/20000] Loss: 0.0078405 (Best: 0.0045070 @iter1198) ([92m↓34.28%[0m) [3.11% of initial]
[Iter 1230/20000] Loss: 0.0066335 (Best: 0.0045070 @iter1198) ([92m↓15.39%[0m) [2.64% of initial]
[Iter 1240/20000] Loss: 0.0060390 (Best: 0.0045070 @iter1198) ([92m↓8.96%[0m) [2.40% of initial]
[Iter 1250/20000] Loss: 0.0054138 (Best: 0.0045070 @iter1198) ([92m↓10.35%[0m) [2.15% of initial]
[Iter 1260/20000] Loss: 0.0052355 (Best: 0.0044630 @iter1258) ([92m↓3.29%[0m) [2.08% of initial]
[Iter 1270/20000] Loss: 0.0048235 (Best: 0.0044630 @iter1258) ([92m↓7.87%[0m) [1.92% of initial]
[Iter 1280/20000] Loss: 0.0050708 (Best: 0.0041541 @iter1273) ([91m↑5.13%[0m) [2.01% of initial]
[Iter 1290/20000] Loss: 0.0049251 (Best: 0.0040842 @iter1288) ([92m↓2.87%[0m) [1.96% of initial]
Iter:1299, L1 loss=0.002958, Total loss=0.00432, Time:36
[Iter 1300/20000] Loss: 0.0046642 (Best: 0.0040842 @iter1288) ([92m↓5.30%[0m) [1.85% of initial]
[Iter 1310/20000] Loss: 0.0046990 (Best: 0.0040131 @iter1301) ([91m↑0.75%[0m) [1.87% of initial]
[Iter 1320/20000] Loss: 0.0045859 (Best: 0.0039553 @iter1319) ([92m↓2.41%[0m) [1.82% of initial]
[Iter 1330/20000] Loss: 0.0045214 (Best: 0.0038913 @iter1321) ([92m↓1.41%[0m) [1.80% of initial]
[Iter 1340/20000] Loss: 0.0042784 (Best: 0.0038264 @iter1334) ([92m↓5.38%[0m) [1.70% of initial]
[Iter 1350/20000] Loss: 0.0043318 (Best: 0.0038264 @iter1334) ([91m↑1.25%[0m) [1.72% of initial]
[Iter 1360/20000] Loss: 0.0043683 (Best: 0.0038023 @iter1354) ([91m↑0.84%[0m) [1.74% of initial]
[Iter 1370/20000] Loss: 0.0041787 (Best: 0.0037827 @iter1363) ([92m↓4.34%[0m) [1.66% of initial]
[Iter 1380/20000] Loss: 0.0043627 (Best: 0.0035907 @iter1375) ([91m↑4.40%[0m) [1.73% of initial]
[Iter 1390/20000] Loss: 0.0042023 (Best: 0.0035907 @iter1375) ([92m↓3.68%[0m) [1.67% of initial]
Iter:1399, L1 loss=0.00244, Total loss=0.003436, Time:47
[Iter 1400/20000] Loss: 0.0039387 (Best: 0.0034364 @iter1399) ([92m↓6.27%[0m) [1.56% of initial]
[Iter 1410/20000] Loss: 0.0098863 (Best: 0.0034364 @iter1399) ([91m↑151.01%[0m) [3.93% of initial]
[Iter 1420/20000] Loss: 0.0068687 (Best: 0.0034364 @iter1399) ([92m↓30.52%[0m) [2.73% of initial]
[Iter 1430/20000] Loss: 0.0055580 (Best: 0.0034364 @iter1399) ([92m↓19.08%[0m) [2.21% of initial]
[Iter 1440/20000] Loss: 0.0049844 (Best: 0.0034364 @iter1399) ([92m↓10.32%[0m) [1.98% of initial]
[Iter 1450/20000] Loss: 0.0041792 (Best: 0.0034364 @iter1399) ([92m↓16.16%[0m) [1.66% of initial]
[Iter 1460/20000] Loss: 0.0041257 (Best: 0.0034364 @iter1399) ([92m↓1.28%[0m) [1.64% of initial]
[Iter 1470/20000] Loss: 0.0039558 (Best: 0.0034364 @iter1399) ([92m↓4.12%[0m) [1.57% of initial]
[Iter 1480/20000] Loss: 0.0037231 (Best: 0.0032333 @iter1480) ([92m↓5.88%[0m) [1.48% of initial]
[Iter 1490/20000] Loss: 0.0036765 (Best: 0.0032333 @iter1480) ([92m↓1.25%[0m) [1.46% of initial]
Iter:1499, L1 loss=0.002794, Total loss=0.003849, Time:39
[Iter 1500/20000] Loss: 0.0036680 (Best: 0.0032333 @iter1480) ([92m↓0.23%[0m) [1.46% of initial]
Pruning 691 points (2.8%) from gaussian0 at iteration 1500
Pruning 759 points (3.0%) from gaussian1 at iteration 1500
[Iter 1510/20000] Loss: 0.0048964 (Best: 0.0032333 @iter1480) ([91m↑33.49%[0m) [1.95% of initial]
[Iter 1520/20000] Loss: 0.0041939 (Best: 0.0032333 @iter1480) ([92m↓14.35%[0m) [1.67% of initial]
[Iter 1530/20000] Loss: 0.0039515 (Best: 0.0032333 @iter1480) ([92m↓5.78%[0m) [1.57% of initial]
[Iter 1540/20000] Loss: 0.0037346 (Best: 0.0032333 @iter1480) ([92m↓5.49%[0m) [1.48% of initial]
[Iter 1550/20000] Loss: 0.0034844 (Best: 0.0031939 @iter1543) ([92m↓6.70%[0m) [1.38% of initial]
[Iter 1560/20000] Loss: 0.0036810 (Best: 0.0030724 @iter1558) ([91m↑5.64%[0m) [1.46% of initial]
[Iter 1570/20000] Loss: 0.0032711 (Best: 0.0030057 @iter1569) ([92m↓11.14%[0m) [1.30% of initial]
[Iter 1580/20000] Loss: 0.0032848 (Best: 0.0028243 @iter1573) ([91m↑0.42%[0m) [1.31% of initial]
[Iter 1590/20000] Loss: 0.0031944 (Best: 0.0028243 @iter1573) ([92m↓2.75%[0m) [1.27% of initial]
Iter:1599, L1 loss=0.002862, Total loss=0.003768, Time:51
[Iter 1600/20000] Loss: 0.0034715 (Best: 0.0028243 @iter1573) ([91m↑8.67%[0m) [1.38% of initial]
[Iter 1610/20000] Loss: 0.0097769 (Best: 0.0028243 @iter1573) ([91m↑181.63%[0m) [3.88% of initial]
[Iter 1620/20000] Loss: 0.0064648 (Best: 0.0028243 @iter1573) ([92m↓33.88%[0m) [2.57% of initial]
[Iter 1630/20000] Loss: 0.0048379 (Best: 0.0028243 @iter1573) ([92m↓25.17%[0m) [1.92% of initial]
[Iter 1640/20000] Loss: 0.0042338 (Best: 0.0028243 @iter1573) ([92m↓12.49%[0m) [1.68% of initial]
[Iter 1650/20000] Loss: 0.0037337 (Best: 0.0028243 @iter1573) ([92m↓11.81%[0m) [1.48% of initial]
[Iter 1660/20000] Loss: 0.0033360 (Best: 0.0028243 @iter1573) ([92m↓10.65%[0m) [1.33% of initial]
[Iter 1670/20000] Loss: 0.0031904 (Best: 0.0027721 @iter1669) ([92m↓4.37%[0m) [1.27% of initial]
[Iter 1680/20000] Loss: 0.0032439 (Best: 0.0027721 @iter1669) ([91m↑1.68%[0m) [1.29% of initial]
[Iter 1690/20000] Loss: 0.0033144 (Best: 0.0027385 @iter1684) ([91m↑2.17%[0m) [1.32% of initial]
Iter:1699, L1 loss=0.002588, Total loss=0.003453, Time:54
[Iter 1700/20000] Loss: 0.0031229 (Best: 0.0027385 @iter1684) ([92m↓5.78%[0m) [1.24% of initial]
[Iter 1710/20000] Loss: 0.0032882 (Best: 0.0027344 @iter1705) ([91m↑5.29%[0m) [1.31% of initial]
[Iter 1720/20000] Loss: 0.0028604 (Best: 0.0026924 @iter1715) ([92m↓13.01%[0m) [1.14% of initial]
[Iter 1730/20000] Loss: 0.0029133 (Best: 0.0026060 @iter1726) ([91m↑1.85%[0m) [1.16% of initial]
[Iter 1740/20000] Loss: 0.0028626 (Best: 0.0025537 @iter1738) ([92m↓1.74%[0m) [1.14% of initial]
[Iter 1750/20000] Loss: 0.0026271 (Best: 0.0023975 @iter1750) ([92m↓8.23%[0m) [1.04% of initial]
[Iter 1760/20000] Loss: 0.0028722 (Best: 0.0023975 @iter1750) ([91m↑9.33%[0m) [1.14% of initial]
[Iter 1770/20000] Loss: 0.0026991 (Best: 0.0023896 @iter1762) ([92m↓6.03%[0m) [1.07% of initial]
[Iter 1780/20000] Loss: 0.0027672 (Best: 0.0023895 @iter1771) ([91m↑2.52%[0m) [1.10% of initial]
[Iter 1790/20000] Loss: 0.0024739 (Best: 0.0021094 @iter1789) ([92m↓10.60%[0m) [0.98% of initial]
Iter:1799, L1 loss=0.001851, Total loss=0.002297, Time:52
[Iter 1800/20000] Loss: 0.0025090 (Best: 0.0021094 @iter1789) ([91m↑1.42%[0m) [1.00% of initial]
[Iter 1810/20000] Loss: 0.0083412 (Best: 0.0021094 @iter1789) ([91m↑232.45%[0m) [3.31% of initial]
[Iter 1820/20000] Loss: 0.0050465 (Best: 0.0021094 @iter1789) ([92m↓39.50%[0m) [2.00% of initial]
[Iter 1830/20000] Loss: 0.0042781 (Best: 0.0021094 @iter1789) ([92m↓15.23%[0m) [1.70% of initial]
[Iter 1840/20000] Loss: 0.0031523 (Best: 0.0021094 @iter1789) ([92m↓26.32%[0m) [1.25% of initial]
[Iter 1850/20000] Loss: 0.0030083 (Best: 0.0021094 @iter1789) ([92m↓4.57%[0m) [1.20% of initial]
[Iter 1860/20000] Loss: 0.0027131 (Best: 0.0021094 @iter1789) ([92m↓9.81%[0m) [1.08% of initial]
[Iter 1870/20000] Loss: 0.0024994 (Best: 0.0021094 @iter1789) ([92m↓7.88%[0m) [0.99% of initial]
[Iter 1880/20000] Loss: 0.0024060 (Best: 0.0021094 @iter1789) ([92m↓3.73%[0m) [0.96% of initial]
[Iter 1890/20000] Loss: 0.0022559 (Best: 0.0020878 @iter1890) ([92m↓6.24%[0m) [0.90% of initial]
Iter:1899, L1 loss=0.001879, Total loss=0.00225, Time:40
[Iter 1900/20000] Loss: 0.0022946 (Best: 0.0019537 @iter1891) ([91m↑1.71%[0m) [0.91% of initial]
[Iter 1910/20000] Loss: 0.0023177 (Best: 0.0019469 @iter1903) ([91m↑1.01%[0m) [0.92% of initial]
[Iter 1920/20000] Loss: 0.0023481 (Best: 0.0019469 @iter1903) ([91m↑1.31%[0m) [0.93% of initial]
[Iter 1930/20000] Loss: 0.0020316 (Best: 0.0018475 @iter1930) ([92m↓13.48%[0m) [0.81% of initial]
[Iter 1940/20000] Loss: 0.0021283 (Best: 0.0017948 @iter1939) ([91m↑4.76%[0m) [0.85% of initial]
[Iter 1950/20000] Loss: 0.0022919 (Best: 0.0017948 @iter1939) ([91m↑7.68%[0m) [0.91% of initial]
[Iter 1960/20000] Loss: 0.0020996 (Best: 0.0017948 @iter1939) ([92m↓8.39%[0m) [0.83% of initial]
[Iter 1970/20000] Loss: 0.0019570 (Best: 0.0017363 @iter1963) ([92m↓6.79%[0m) [0.78% of initial]
[Iter 1980/20000] Loss: 0.0022900 (Best: 0.0017363 @iter1963) ([91m↑17.01%[0m) [0.91% of initial]
[Iter 1990/20000] Loss: 0.0020263 (Best: 0.0017363 @iter1963) ([92m↓11.52%[0m) [0.81% of initial]
Iter:1999, L1 loss=0.001663, Total loss=0.001856, Time:61
[Iter 2000/20000] Loss: 0.0021468 (Best: 0.0016791 @iter1996) ([91m↑5.95%[0m) [0.85% of initial]
Testing Speed: 78.33732213356423 fps
Testing Time: 0.6382653713226318 s

[ITER 2000] Evaluating test: SSIM = 0.8674797630310058, PSNR = 17.974885540008547
Testing Speed: 122.11084477655393 fps
Testing Time: 0.024567842483520508 s

[ITER 2000] Evaluating train: SSIM = 0.99995352824529, PSNR = 48.960670471191406
Iter:2000, total_points:43502
Pruning 685 points (1.2%) from gaussian0 at iteration 2000
Pruning 653 points (1.2%) from gaussian1 at iteration 2000
[Iter 2010/20000] Loss: 0.2067917 (Best: 0.0016791 @iter1996) ([91m↑9532.47%[0m) [82.16% of initial]
[Iter 2020/20000] Loss: 0.1581856 (Best: 0.0016791 @iter1996) ([92m↓23.50%[0m) [62.85% of initial]
[Iter 2030/20000] Loss: 0.1088945 (Best: 0.0016791 @iter1996) ([92m↓31.16%[0m) [43.26% of initial]
[Iter 2040/20000] Loss: 0.0715990 (Best: 0.0016791 @iter1996) ([92m↓34.25%[0m) [28.45% of initial]
[Iter 2050/20000] Loss: 0.0420707 (Best: 0.0016791 @iter1996) ([92m↓41.24%[0m) [16.71% of initial]
[Iter 2060/20000] Loss: 0.0204815 (Best: 0.0016791 @iter1996) ([92m↓51.32%[0m) [8.14% of initial]
[Iter 2070/20000] Loss: 0.0127348 (Best: 0.0016791 @iter1996) ([92m↓37.82%[0m) [5.06% of initial]
[Iter 2080/20000] Loss: 0.0077401 (Best: 0.0016791 @iter1996) ([92m↓39.22%[0m) [3.08% of initial]
[Iter 2090/20000] Loss: 0.0060703 (Best: 0.0016791 @iter1996) ([92m↓21.57%[0m) [2.41% of initial]
Iter:2099, L1 loss=0.00347, Total loss=0.004613, Time:54
[Iter 2100/20000] Loss: 0.0048697 (Best: 0.0016791 @iter1996) ([92m↓19.78%[0m) [1.93% of initial]
[Iter 2110/20000] Loss: 0.0042503 (Best: 0.0016791 @iter1996) ([92m↓12.72%[0m) [1.69% of initial]
[Iter 2120/20000] Loss: 0.0037128 (Best: 0.0016791 @iter1996) ([92m↓12.65%[0m) [1.48% of initial]
[Iter 2130/20000] Loss: 0.0036536 (Best: 0.0016791 @iter1996) ([92m↓1.60%[0m) [1.45% of initial]
[Iter 2140/20000] Loss: 0.0034935 (Best: 0.0016791 @iter1996) ([92m↓4.38%[0m) [1.39% of initial]
[Iter 2150/20000] Loss: 0.0032322 (Best: 0.0016791 @iter1996) ([92m↓7.48%[0m) [1.28% of initial]
[Iter 2160/20000] Loss: 0.0030731 (Best: 0.0016791 @iter1996) ([92m↓4.92%[0m) [1.22% of initial]
[Iter 2170/20000] Loss: 0.0030884 (Best: 0.0016791 @iter1996) ([91m↑0.50%[0m) [1.23% of initial]
[Iter 2180/20000] Loss: 0.0026912 (Best: 0.0016791 @iter1996) ([92m↓12.86%[0m) [1.07% of initial]
[Iter 2190/20000] Loss: 0.0028580 (Best: 0.0016791 @iter1996) ([91m↑6.20%[0m) [1.14% of initial]
Iter:2199, L1 loss=0.002187, Total loss=0.002632, Time:56
[Iter 2200/20000] Loss: 0.0027970 (Best: 0.0016791 @iter1996) ([92m↓2.13%[0m) [1.11% of initial]
[Iter 2210/20000] Loss: 0.0092121 (Best: 0.0016791 @iter1996) ([91m↑229.35%[0m) [3.66% of initial]
[Iter 2220/20000] Loss: 0.0051930 (Best: 0.0016791 @iter1996) ([92m↓43.63%[0m) [2.06% of initial]
[Iter 2230/20000] Loss: 0.0035410 (Best: 0.0016791 @iter1996) ([92m↓31.81%[0m) [1.41% of initial]
[Iter 2240/20000] Loss: 0.0032001 (Best: 0.0016791 @iter1996) ([92m↓9.63%[0m) [1.27% of initial]
[Iter 2250/20000] Loss: 0.0028183 (Best: 0.0016791 @iter1996) ([92m↓11.93%[0m) [1.12% of initial]
[Iter 2260/20000] Loss: 0.0024740 (Best: 0.0016791 @iter1996) ([92m↓12.22%[0m) [0.98% of initial]
[Iter 2270/20000] Loss: 0.0025925 (Best: 0.0016791 @iter1996) ([91m↑4.79%[0m) [1.03% of initial]
[Iter 2280/20000] Loss: 0.0022354 (Best: 0.0016791 @iter1996) ([92m↓13.77%[0m) [0.89% of initial]
[Iter 2290/20000] Loss: 0.0021849 (Best: 0.0016791 @iter1996) ([92m↓2.26%[0m) [0.87% of initial]
Iter:2299, L1 loss=0.001747, Total loss=0.002044, Time:58
[Iter 2300/20000] Loss: 0.0023542 (Best: 0.0016791 @iter1996) ([91m↑7.75%[0m) [0.94% of initial]
[Iter 2310/20000] Loss: 0.0022131 (Best: 0.0016791 @iter1996) ([92m↓5.99%[0m) [0.88% of initial]
[Iter 2320/20000] Loss: 0.0019629 (Best: 0.0016791 @iter1996) ([92m↓11.30%[0m) [0.78% of initial]
[Iter 2330/20000] Loss: 0.0019410 (Best: 0.0016791 @iter1996) ([92m↓1.12%[0m) [0.77% of initial]
[Iter 2340/20000] Loss: 0.0020331 (Best: 0.0016791 @iter1996) ([91m↑4.74%[0m) [0.81% of initial]
[Iter 2350/20000] Loss: 0.0019773 (Best: 0.0016791 @iter1996) ([92m↓2.75%[0m) [0.79% of initial]
[Iter 2360/20000] Loss: 0.0018718 (Best: 0.0016791 @iter1996) ([92m↓5.33%[0m) [0.74% of initial]
[Iter 2370/20000] Loss: 0.0019430 (Best: 0.0016791 @iter1996) ([91m↑3.81%[0m) [0.77% of initial]
[Iter 2380/20000] Loss: 0.0020244 (Best: 0.0016791 @iter1996) ([91m↑4.19%[0m) [0.80% of initial]
[Iter 2390/20000] Loss: 0.0020573 (Best: 0.0016791 @iter1996) ([91m↑1.63%[0m) [0.82% of initial]
Iter:2399, L1 loss=0.001605, Total loss=0.001756, Time:59
[Iter 2400/20000] Loss: 0.0018243 (Best: 0.0016791 @iter1996) ([92m↓11.33%[0m) [0.72% of initial]
[Iter 2410/20000] Loss: 0.0054990 (Best: 0.0016791 @iter1996) ([91m↑201.44%[0m) [2.18% of initial]
[Iter 2420/20000] Loss: 0.0035335 (Best: 0.0016791 @iter1996) ([92m↓35.74%[0m) [1.40% of initial]
[Iter 2430/20000] Loss: 0.0027769 (Best: 0.0016791 @iter1996) ([92m↓21.41%[0m) [1.10% of initial]
[Iter 2440/20000] Loss: 0.0023620 (Best: 0.0016791 @iter1996) ([92m↓14.94%[0m) [0.94% of initial]
[Iter 2450/20000] Loss: 0.0022457 (Best: 0.0016791 @iter1996) ([92m↓4.92%[0m) [0.89% of initial]
[Iter 2460/20000] Loss: 0.0020618 (Best: 0.0016791 @iter1996) ([92m↓8.19%[0m) [0.82% of initial]
[Iter 2470/20000] Loss: 0.0020555 (Best: 0.0016547 @iter2464) ([92m↓0.31%[0m) [0.82% of initial]
[Iter 2480/20000] Loss: 0.0019607 (Best: 0.0016547 @iter2464) ([92m↓4.61%[0m) [0.78% of initial]
[Iter 2490/20000] Loss: 0.0018060 (Best: 0.0016245 @iter2489) ([92m↓7.89%[0m) [0.72% of initial]
Iter:2499, L1 loss=0.001542, Total loss=0.001654, Time:72
[Iter 2500/20000] Loss: 0.0017189 (Best: 0.0016162 @iter2491) ([92m↓4.83%[0m) [0.68% of initial]
Pruning 515 points (0.8%) from gaussian0 at iteration 2500
Pruning 503 points (0.8%) from gaussian1 at iteration 2500
[Iter 2510/20000] Loss: 0.0030353 (Best: 0.0016162 @iter2491) ([91m↑76.59%[0m) [1.21% of initial]
[Iter 2520/20000] Loss: 0.0022207 (Best: 0.0016162 @iter2491) ([92m↓26.84%[0m) [0.88% of initial]
[Iter 2530/20000] Loss: 0.0018019 (Best: 0.0016162 @iter2491) ([92m↓18.86%[0m) [0.72% of initial]
[Iter 2540/20000] Loss: 0.0017410 (Best: 0.0015894 @iter2533) ([92m↓3.38%[0m) [0.69% of initial]
[Iter 2550/20000] Loss: 0.0017804 (Best: 0.0014668 @iter2548) ([91m↑2.26%[0m) [0.71% of initial]
[Iter 2560/20000] Loss: 0.0016287 (Best: 0.0014491 @iter2558) ([92m↓8.52%[0m) [0.65% of initial]
[Iter 2570/20000] Loss: 0.0018163 (Best: 0.0014491 @iter2558) ([91m↑11.52%[0m) [0.72% of initial]
[Iter 2580/20000] Loss: 0.0016663 (Best: 0.0014027 @iter2578) ([92m↓8.26%[0m) [0.66% of initial]
[Iter 2590/20000] Loss: 0.0016972 (Best: 0.0014027 @iter2578) ([91m↑1.86%[0m) [0.67% of initial]
Iter:2599, L1 loss=0.001366, Total loss=0.001463, Time:69
[Iter 2600/20000] Loss: 0.0016274 (Best: 0.0013654 @iter2597) ([92m↓4.11%[0m) [0.65% of initial]
[Iter 2610/20000] Loss: 0.0054181 (Best: 0.0013654 @iter2597) ([91m↑232.92%[0m) [2.15% of initial]
[Iter 2620/20000] Loss: 0.0035456 (Best: 0.0013654 @iter2597) ([92m↓34.56%[0m) [1.41% of initial]
[Iter 2630/20000] Loss: 0.0025500 (Best: 0.0013654 @iter2597) ([92m↓28.08%[0m) [1.01% of initial]
[Iter 2640/20000] Loss: 0.0020880 (Best: 0.0013654 @iter2597) ([92m↓18.12%[0m) [0.83% of initial]
[Iter 2650/20000] Loss: 0.0017616 (Best: 0.0013654 @iter2597) ([92m↓15.63%[0m) [0.70% of initial]
[Iter 2660/20000] Loss: 0.0018320 (Best: 0.0013654 @iter2597) ([91m↑4.00%[0m) [0.73% of initial]
[Iter 2670/20000] Loss: 0.0017523 (Best: 0.0013654 @iter2597) ([92m↓4.35%[0m) [0.70% of initial]
[Iter 2680/20000] Loss: 0.0015147 (Best: 0.0013654 @iter2597) ([92m↓13.56%[0m) [0.60% of initial]
[Iter 2690/20000] Loss: 0.0014829 (Best: 0.0013366 @iter2686) ([92m↓2.10%[0m) [0.59% of initial]
Iter:2699, L1 loss=0.001391, Total loss=0.001415, Time:73
[Iter 2700/20000] Loss: 0.0016579 (Best: 0.0013366 @iter2686) ([91m↑11.80%[0m) [0.66% of initial]
[Iter 2710/20000] Loss: 0.0014782 (Best: 0.0013366 @iter2686) ([92m↓10.84%[0m) [0.59% of initial]
[Iter 2720/20000] Loss: 0.0013888 (Best: 0.0012852 @iter2715) ([92m↓6.04%[0m) [0.55% of initial]
[Iter 2730/20000] Loss: 0.0013203 (Best: 0.0011864 @iter2725) ([92m↓4.94%[0m) [0.52% of initial]
[Iter 2740/20000] Loss: 0.0011963 (Best: 0.0011240 @iter2740) ([92m↓9.39%[0m) [0.48% of initial]
[Iter 2750/20000] Loss: 0.0013845 (Best: 0.0011240 @iter2740) ([91m↑15.73%[0m) [0.55% of initial]
[Iter 2760/20000] Loss: 0.0014804 (Best: 0.0011240 @iter2740) ([91m↑6.92%[0m) [0.59% of initial]
[Iter 2770/20000] Loss: 0.0014954 (Best: 0.0011240 @iter2740) ([91m↑1.01%[0m) [0.59% of initial]
[Iter 2780/20000] Loss: 0.0013765 (Best: 0.0011240 @iter2740) ([92m↓7.95%[0m) [0.55% of initial]
[Iter 2790/20000] Loss: 0.0014547 (Best: 0.0011240 @iter2740) ([91m↑5.68%[0m) [0.58% of initial]
Iter:2799, L1 loss=0.001452, Total loss=0.001519, Time:89
[Iter 2800/20000] Loss: 0.0014252 (Best: 0.0011240 @iter2740) ([92m↓2.03%[0m) [0.57% of initial]
[Iter 2810/20000] Loss: 0.0045293 (Best: 0.0011240 @iter2740) ([91m↑217.80%[0m) [1.80% of initial]
[Iter 2820/20000] Loss: 0.0029526 (Best: 0.0011240 @iter2740) ([92m↓34.81%[0m) [1.17% of initial]
[Iter 2830/20000] Loss: 0.0020425 (Best: 0.0011240 @iter2740) ([92m↓30.82%[0m) [0.81% of initial]
[Iter 2840/20000] Loss: 0.0017229 (Best: 0.0011240 @iter2740) ([92m↓15.65%[0m) [0.68% of initial]
[Iter 2850/20000] Loss: 0.0015521 (Best: 0.0011240 @iter2740) ([92m↓9.91%[0m) [0.62% of initial]
[Iter 2860/20000] Loss: 0.0015896 (Best: 0.0011240 @iter2740) ([91m↑2.42%[0m) [0.63% of initial]
[Iter 2870/20000] Loss: 0.0014441 (Best: 0.0011240 @iter2740) ([92m↓9.15%[0m) [0.57% of initial]
[Iter 2880/20000] Loss: 0.0014168 (Best: 0.0011240 @iter2740) ([92m↓1.89%[0m) [0.56% of initial]
[Iter 2890/20000] Loss: 0.0013304 (Best: 0.0011240 @iter2740) ([92m↓6.10%[0m) [0.53% of initial]
Iter:2899, L1 loss=0.001129, Total loss=0.001155, Time:54
[Iter 2900/20000] Loss: 0.0012828 (Best: 0.0011240 @iter2740) ([92m↓3.58%[0m) [0.51% of initial]
[Iter 2910/20000] Loss: 0.0013838 (Best: 0.0011240 @iter2740) ([91m↑7.88%[0m) [0.55% of initial]
[Iter 2920/20000] Loss: 0.0014162 (Best: 0.0011240 @iter2740) ([91m↑2.34%[0m) [0.56% of initial]
[Iter 2930/20000] Loss: 0.0013247 (Best: 0.0011240 @iter2740) ([92m↓6.46%[0m) [0.53% of initial]
[Iter 2940/20000] Loss: 0.0012359 (Best: 0.0011012 @iter2932) ([92m↓6.71%[0m) [0.49% of initial]
[Iter 2950/20000] Loss: 0.0011831 (Best: 0.0010781 @iter2950) ([92m↓4.27%[0m) [0.47% of initial]
[Iter 2960/20000] Loss: 0.0012527 (Best: 0.0010781 @iter2950) ([91m↑5.89%[0m) [0.50% of initial]
[Iter 2970/20000] Loss: 0.0011644 (Best: 0.0010194 @iter2969) ([92m↓7.05%[0m) [0.46% of initial]
[Iter 2980/20000] Loss: 0.0011024 (Best: 0.0010194 @iter2969) ([92m↓5.32%[0m) [0.44% of initial]
[Iter 2990/20000] Loss: 0.0011142 (Best: 0.0009864 @iter2983) ([91m↑1.07%[0m) [0.44% of initial]
Iter:2999, L1 loss=0.0009581, Total loss=0.0009571, Time:66
[Iter 3000/20000] Loss: 0.0011018 (Best: 0.0009571 @iter2999) ([92m↓1.11%[0m) [0.44% of initial]
Pruning 297 points (0.4%) from gaussian0 at iteration 3000
Pruning 309 points (0.4%) from gaussian1 at iteration 3000
[Iter 3010/20000] Loss: 0.0040343 (Best: 0.0009571 @iter2999) ([91m↑266.15%[0m) [1.60% of initial]
[Iter 3020/20000] Loss: 0.0029298 (Best: 0.0009571 @iter2999) ([92m↓27.38%[0m) [1.16% of initial]
[Iter 3030/20000] Loss: 0.0021326 (Best: 0.0009571 @iter2999) ([92m↓27.21%[0m) [0.85% of initial]
[Iter 3040/20000] Loss: 0.0016843 (Best: 0.0009571 @iter2999) ([92m↓21.02%[0m) [0.67% of initial]
[Iter 3050/20000] Loss: 0.0015874 (Best: 0.0009571 @iter2999) ([92m↓5.76%[0m) [0.63% of initial]
[Iter 3060/20000] Loss: 0.0014802 (Best: 0.0009571 @iter2999) ([92m↓6.75%[0m) [0.59% of initial]
[Iter 3070/20000] Loss: 0.0013404 (Best: 0.0009571 @iter2999) ([92m↓9.44%[0m) [0.53% of initial]
[Iter 3080/20000] Loss: 0.0013398 (Best: 0.0009571 @iter2999) ([92m↓0.04%[0m) [0.53% of initial]
[Iter 3090/20000] Loss: 0.0013112 (Best: 0.0009571 @iter2999) ([92m↓2.14%[0m) [0.52% of initial]
Iter:3099, L1 loss=0.001206, Total loss=0.001191, Time:96
[Iter 3100/20000] Loss: 0.0012320 (Best: 0.0009571 @iter2999) ([92m↓6.04%[0m) [0.49% of initial]
[Iter 3110/20000] Loss: 0.0013063 (Best: 0.0009571 @iter2999) ([91m↑6.03%[0m) [0.52% of initial]
[Iter 3120/20000] Loss: 0.0012679 (Best: 0.0009571 @iter2999) ([92m↓2.93%[0m) [0.50% of initial]
[Iter 3130/20000] Loss: 0.0011704 (Best: 0.0009571 @iter2999) ([92m↓7.69%[0m) [0.47% of initial]
[Iter 3140/20000] Loss: 0.0011442 (Best: 0.0009571 @iter2999) ([92m↓2.24%[0m) [0.45% of initial]
[Iter 3150/20000] Loss: 0.0011710 (Best: 0.0009571 @iter2999) ([91m↑2.35%[0m) [0.47% of initial]
[Iter 3160/20000] Loss: 0.0011225 (Best: 0.0009571 @iter2999) ([92m↓4.15%[0m) [0.45% of initial]
[Iter 3170/20000] Loss: 0.0011218 (Best: 0.0009571 @iter2999) ([92m↓0.06%[0m) [0.45% of initial]
[Iter 3180/20000] Loss: 0.0011978 (Best: 0.0009571 @iter2999) ([91m↑6.77%[0m) [0.48% of initial]
[Iter 3190/20000] Loss: 0.0011430 (Best: 0.0009571 @iter2999) ([92m↓4.57%[0m) [0.45% of initial]
Iter:3199, L1 loss=0.001084, Total loss=0.001068, Time:52
[Iter 3200/20000] Loss: 0.0010945 (Best: 0.0009571 @iter2999) ([92m↓4.24%[0m) [0.43% of initial]
[Iter 3210/20000] Loss: 0.0040214 (Best: 0.0009571 @iter2999) ([91m↑267.43%[0m) [1.60% of initial]
[Iter 3220/20000] Loss: 0.0026962 (Best: 0.0009571 @iter2999) ([92m↓32.95%[0m) [1.07% of initial]
[Iter 3230/20000] Loss: 0.0018451 (Best: 0.0009571 @iter2999) ([92m↓31.57%[0m) [0.73% of initial]
[Iter 3240/20000] Loss: 0.0017106 (Best: 0.0009571 @iter2999) ([92m↓7.29%[0m) [0.68% of initial]
[Iter 3250/20000] Loss: 0.0013714 (Best: 0.0009571 @iter2999) ([92m↓19.83%[0m) [0.54% of initial]
[Iter 3260/20000] Loss: 0.0012668 (Best: 0.0009571 @iter2999) ([92m↓7.63%[0m) [0.50% of initial]
[Iter 3270/20000] Loss: 0.0012463 (Best: 0.0009571 @iter2999) ([92m↓1.61%[0m) [0.50% of initial]
[Iter 3280/20000] Loss: 0.0012796 (Best: 0.0009571 @iter2999) ([91m↑2.67%[0m) [0.51% of initial]
[Iter 3290/20000] Loss: 0.0010739 (Best: 0.0009571 @iter2999) ([92m↓16.08%[0m) [0.43% of initial]
Iter:3299, L1 loss=0.001503, Total loss=0.001491, Time:85
[Iter 3300/20000] Loss: 0.0013144 (Best: 0.0009571 @iter2999) ([91m↑22.40%[0m) [0.52% of initial]
[Iter 3310/20000] Loss: 0.0010617 (Best: 0.0009571 @iter2999) ([92m↓19.23%[0m) [0.42% of initial]
[Iter 3320/20000] Loss: 0.0011492 (Best: 0.0009571 @iter2999) ([91m↑8.25%[0m) [0.46% of initial]
[Iter 3330/20000] Loss: 0.0012186 (Best: 0.0009571 @iter2999) ([91m↑6.04%[0m) [0.48% of initial]
[Iter 3340/20000] Loss: 0.0012715 (Best: 0.0009571 @iter2999) ([91m↑4.34%[0m) [0.51% of initial]
[Iter 3350/20000] Loss: 0.0011282 (Best: 0.0009571 @iter2999) ([92m↓11.27%[0m) [0.45% of initial]
[Iter 3360/20000] Loss: 0.0013196 (Best: 0.0009571 @iter2999) ([91m↑16.97%[0m) [0.52% of initial]
[Iter 3370/20000] Loss: 0.0010510 (Best: 0.0009445 @iter3370) ([92m↓20.36%[0m) [0.42% of initial]
[Iter 3380/20000] Loss: 0.0010073 (Best: 0.0009194 @iter3379) ([92m↓4.15%[0m) [0.40% of initial]
[Iter 3390/20000] Loss: 0.0012334 (Best: 0.0009194 @iter3379) ([91m↑22.45%[0m) [0.49% of initial]
Iter:3399, L1 loss=0.001348, Total loss=0.001338, Time:73
[Iter 3400/20000] Loss: 0.0012275 (Best: 0.0009194 @iter3379) ([92m↓0.48%[0m) [0.49% of initial]
[Iter 3410/20000] Loss: 0.0034697 (Best: 0.0009194 @iter3379) ([91m↑182.66%[0m) [1.38% of initial]
[Iter 3420/20000] Loss: 0.0022261 (Best: 0.0009194 @iter3379) ([92m↓35.84%[0m) [0.88% of initial]
[Iter 3430/20000] Loss: 0.0015455 (Best: 0.0009194 @iter3379) ([92m↓30.57%[0m) [0.61% of initial]
[Iter 3440/20000] Loss: 0.0014529 (Best: 0.0009194 @iter3379) ([92m↓5.99%[0m) [0.58% of initial]
[Iter 3450/20000] Loss: 0.0013433 (Best: 0.0009194 @iter3379) ([92m↓7.54%[0m) [0.53% of initial]
[Iter 3460/20000] Loss: 0.0012675 (Best: 0.0009194 @iter3379) ([92m↓5.65%[0m) [0.50% of initial]
[Iter 3470/20000] Loss: 0.0011898 (Best: 0.0009194 @iter3379) ([92m↓6.13%[0m) [0.47% of initial]
[Iter 3480/20000] Loss: 0.0011401 (Best: 0.0009194 @iter3379) ([92m↓4.18%[0m) [0.45% of initial]
[Iter 3490/20000] Loss: 0.0010660 (Best: 0.0009194 @iter3379) ([92m↓6.50%[0m) [0.42% of initial]
Iter:3499, L1 loss=0.0008815, Total loss=0.0008573, Time:81
[Iter 3500/20000] Loss: 0.0009164 (Best: 0.0008573 @iter3499) ([92m↓14.03%[0m) [0.36% of initial]
Pruning 253 points (0.3%) from gaussian0 at iteration 3500
Pruning 257 points (0.3%) from gaussian1 at iteration 3500
[Iter 3510/20000] Loss: 0.0020271 (Best: 0.0008573 @iter3499) ([91m↑121.20%[0m) [0.81% of initial]
[Iter 3520/20000] Loss: 0.0014660 (Best: 0.0008573 @iter3499) ([92m↓27.68%[0m) [0.58% of initial]
[Iter 3530/20000] Loss: 0.0011994 (Best: 0.0008573 @iter3499) ([92m↓18.19%[0m) [0.48% of initial]
[Iter 3540/20000] Loss: 0.0012969 (Best: 0.0008573 @iter3499) ([91m↑8.12%[0m) [0.52% of initial]
[Iter 3550/20000] Loss: 0.0012291 (Best: 0.0008573 @iter3499) ([92m↓5.22%[0m) [0.49% of initial]
[Iter 3560/20000] Loss: 0.0011134 (Best: 0.0008573 @iter3499) ([92m↓9.42%[0m) [0.44% of initial]
[Iter 3570/20000] Loss: 0.0011773 (Best: 0.0008573 @iter3499) ([91m↑5.74%[0m) [0.47% of initial]
[Iter 3580/20000] Loss: 0.0009523 (Best: 0.0008573 @iter3499) ([92m↓19.11%[0m) [0.38% of initial]
[Iter 3590/20000] Loss: 0.0009467 (Best: 0.0008573 @iter3499) ([92m↓0.59%[0m) [0.38% of initial]
Iter:3599, L1 loss=0.0009011, Total loss=0.000894, Time:66
[Iter 3600/20000] Loss: 0.0009440 (Best: 0.0008265 @iter3598) ([92m↓0.29%[0m) [0.38% of initial]
[Iter 3610/20000] Loss: 0.0035480 (Best: 0.0008265 @iter3598) ([91m↑275.87%[0m) [1.41% of initial]
[Iter 3620/20000] Loss: 0.0025318 (Best: 0.0008265 @iter3598) ([92m↓28.64%[0m) [1.01% of initial]
[Iter 3630/20000] Loss: 0.0016642 (Best: 0.0008265 @iter3598) ([92m↓34.27%[0m) [0.66% of initial]
[Iter 3640/20000] Loss: 0.0013109 (Best: 0.0008265 @iter3598) ([92m↓21.23%[0m) [0.52% of initial]
[Iter 3650/20000] Loss: 0.0012523 (Best: 0.0008265 @iter3598) ([92m↓4.47%[0m) [0.50% of initial]
[Iter 3660/20000] Loss: 0.0011184 (Best: 0.0008265 @iter3598) ([92m↓10.69%[0m) [0.44% of initial]
[Iter 3670/20000] Loss: 0.0010088 (Best: 0.0008265 @iter3598) ([92m↓9.80%[0m) [0.40% of initial]
[Iter 3680/20000] Loss: 0.0011312 (Best: 0.0008265 @iter3598) ([91m↑12.13%[0m) [0.45% of initial]
[Iter 3690/20000] Loss: 0.0013153 (Best: 0.0008265 @iter3598) ([91m↑16.28%[0m) [0.52% of initial]
Iter:3699, L1 loss=0.001192, Total loss=0.00114, Time:62
[Iter 3700/20000] Loss: 0.0011563 (Best: 0.0008265 @iter3598) ([92m↓12.09%[0m) [0.46% of initial]
[Iter 3710/20000] Loss: 0.0009817 (Best: 0.0008265 @iter3598) ([92m↓15.10%[0m) [0.39% of initial]
[Iter 3720/20000] Loss: 0.0010617 (Best: 0.0007979 @iter3712) ([91m↑8.15%[0m) [0.42% of initial]
[Iter 3730/20000] Loss: 0.0009356 (Best: 0.0007979 @iter3712) ([92m↓11.88%[0m) [0.37% of initial]
[Iter 3740/20000] Loss: 0.0009395 (Best: 0.0007979 @iter3712) ([91m↑0.41%[0m) [0.37% of initial]
[Iter 3750/20000] Loss: 0.0009960 (Best: 0.0007979 @iter3712) ([91m↑6.01%[0m) [0.40% of initial]
[Iter 3760/20000] Loss: 0.0009568 (Best: 0.0007979 @iter3712) ([92m↓3.94%[0m) [0.38% of initial]
[Iter 3770/20000] Loss: 0.0009610 (Best: 0.0007979 @iter3712) ([91m↑0.44%[0m) [0.38% of initial]
[Iter 3780/20000] Loss: 0.0009419 (Best: 0.0007666 @iter3775) ([92m↓1.99%[0m) [0.37% of initial]
[Iter 3790/20000] Loss: 0.0008082 (Best: 0.0007559 @iter3785) ([92m↓14.20%[0m) [0.32% of initial]
Iter:3799, L1 loss=0.0009785, Total loss=0.0009208, Time:64
[Iter 3800/20000] Loss: 0.0008886 (Best: 0.0007559 @iter3785) ([91m↑9.96%[0m) [0.35% of initial]
[Iter 3810/20000] Loss: 0.0031446 (Best: 0.0007559 @iter3785) ([91m↑253.86%[0m) [1.25% of initial]
[Iter 3820/20000] Loss: 0.0020708 (Best: 0.0007559 @iter3785) ([92m↓34.15%[0m) [0.82% of initial]
[Iter 3830/20000] Loss: 0.0014130 (Best: 0.0007559 @iter3785) ([92m↓31.76%[0m) [0.56% of initial]
[Iter 3840/20000] Loss: 0.0014377 (Best: 0.0007559 @iter3785) ([91m↑1.74%[0m) [0.57% of initial]
[Iter 3850/20000] Loss: 0.0011577 (Best: 0.0007559 @iter3785) ([92m↓19.48%[0m) [0.46% of initial]
[Iter 3860/20000] Loss: 0.0010854 (Best: 0.0007559 @iter3785) ([92m↓6.25%[0m) [0.43% of initial]
[Iter 3870/20000] Loss: 0.0009367 (Best: 0.0007559 @iter3785) ([92m↓13.70%[0m) [0.37% of initial]
[Iter 3880/20000] Loss: 0.0009601 (Best: 0.0007559 @iter3785) ([91m↑2.50%[0m) [0.38% of initial]
[Iter 3890/20000] Loss: 0.0008402 (Best: 0.0007544 @iter3883) ([92m↓12.49%[0m) [0.33% of initial]
Iter:3899, L1 loss=0.0009161, Total loss=0.0009009, Time:89
[Iter 3900/20000] Loss: 0.0008413 (Best: 0.0007084 @iter3898) ([91m↑0.14%[0m) [0.33% of initial]
[Iter 3910/20000] Loss: 0.0009280 (Best: 0.0007084 @iter3898) ([91m↑10.31%[0m) [0.37% of initial]
[Iter 3920/20000] Loss: 0.0009281 (Best: 0.0007084 @iter3898) ([91m↑0.01%[0m) [0.37% of initial]
[Iter 3930/20000] Loss: 0.0009461 (Best: 0.0007084 @iter3898) ([91m↑1.94%[0m) [0.38% of initial]
[Iter 3940/20000] Loss: 0.0008591 (Best: 0.0007084 @iter3898) ([92m↓9.19%[0m) [0.34% of initial]
[Iter 3950/20000] Loss: 0.0008840 (Best: 0.0007084 @iter3898) ([91m↑2.90%[0m) [0.35% of initial]
[Iter 3960/20000] Loss: 0.0009312 (Best: 0.0007084 @iter3898) ([91m↑5.33%[0m) [0.37% of initial]
[Iter 3970/20000] Loss: 0.0008667 (Best: 0.0007084 @iter3898) ([92m↓6.93%[0m) [0.34% of initial]
[Iter 3980/20000] Loss: 0.0011384 (Best: 0.0007084 @iter3898) ([91m↑31.35%[0m) [0.45% of initial]
[Iter 3990/20000] Loss: 0.0009146 (Best: 0.0007084 @iter3898) ([92m↓19.66%[0m) [0.36% of initial]
Iter:3999, L1 loss=0.0009473, Total loss=0.000911, Time:74
[Iter 4000/20000] Loss: 0.0008757 (Best: 0.0007084 @iter3898) ([92m↓4.24%[0m) [0.35% of initial]
Pruning 264 points (0.3%) from gaussian0 at iteration 4000
Pruning 261 points (0.2%) from gaussian1 at iteration 4000
[Iter 4010/20000] Loss: 0.0034195 (Best: 0.0007084 @iter3898) ([91m↑290.47%[0m) [1.36% of initial]
[Iter 4020/20000] Loss: 0.0023024 (Best: 0.0007084 @iter3898) ([92m↓32.67%[0m) [0.91% of initial]
[Iter 4030/20000] Loss: 0.0014381 (Best: 0.0007084 @iter3898) ([92m↓37.54%[0m) [0.57% of initial]
[Iter 4040/20000] Loss: 0.0011737 (Best: 0.0007084 @iter3898) ([92m↓18.38%[0m) [0.47% of initial]
[Iter 4050/20000] Loss: 0.0010423 (Best: 0.0007084 @iter3898) ([92m↓11.20%[0m) [0.41% of initial]
[Iter 4060/20000] Loss: 0.0009811 (Best: 0.0007084 @iter3898) ([92m↓5.87%[0m) [0.39% of initial]
[Iter 4070/20000] Loss: 0.0008611 (Best: 0.0007084 @iter3898) ([92m↓12.24%[0m) [0.34% of initial]
[Iter 4080/20000] Loss: 0.0009228 (Best: 0.0007084 @iter3898) ([91m↑7.17%[0m) [0.37% of initial]
[Iter 4090/20000] Loss: 0.0008011 (Best: 0.0007084 @iter3898) ([92m↓13.19%[0m) [0.32% of initial]
Iter:4099, L1 loss=0.0008578, Total loss=0.0008089, Time:81
[Iter 4100/20000] Loss: 0.0007892 (Best: 0.0007084 @iter3898) ([92m↓1.49%[0m) [0.31% of initial]
[Iter 4110/20000] Loss: 0.0008798 (Best: 0.0007084 @iter3898) ([91m↑11.49%[0m) [0.35% of initial]
[Iter 4120/20000] Loss: 0.0008974 (Best: 0.0007084 @iter3898) ([91m↑2.00%[0m) [0.36% of initial]
[Iter 4130/20000] Loss: 0.0009975 (Best: 0.0007084 @iter3898) ([91m↑11.16%[0m) [0.40% of initial]
[Iter 4140/20000] Loss: 0.0009705 (Best: 0.0007084 @iter3898) ([92m↓2.71%[0m) [0.39% of initial]
[Iter 4150/20000] Loss: 0.0008236 (Best: 0.0007084 @iter3898) ([92m↓15.14%[0m) [0.33% of initial]
[Iter 4160/20000] Loss: 0.0009706 (Best: 0.0007084 @iter3898) ([91m↑17.85%[0m) [0.39% of initial]
[Iter 4170/20000] Loss: 0.0008575 (Best: 0.0007084 @iter3898) ([92m↓11.65%[0m) [0.34% of initial]
[Iter 4180/20000] Loss: 0.0008753 (Best: 0.0007084 @iter3898) ([91m↑2.08%[0m) [0.35% of initial]
[Iter 4190/20000] Loss: 0.0009046 (Best: 0.0007084 @iter3898) ([91m↑3.34%[0m) [0.36% of initial]
Iter:4199, L1 loss=0.0008948, Total loss=0.0008515, Time:76
[Iter 4200/20000] Loss: 0.0009316 (Best: 0.0007084 @iter3898) ([91m↑2.99%[0m) [0.37% of initial]
[Iter 4210/20000] Loss: 0.0027748 (Best: 0.0007084 @iter3898) ([91m↑197.84%[0m) [1.10% of initial]
[Iter 4220/20000] Loss: 0.0017866 (Best: 0.0007084 @iter3898) ([92m↓35.61%[0m) [0.71% of initial]
[Iter 4230/20000] Loss: 0.0012261 (Best: 0.0007084 @iter3898) ([92m↓31.37%[0m) [0.49% of initial]
[Iter 4240/20000] Loss: 0.0009863 (Best: 0.0007084 @iter3898) ([92m↓19.56%[0m) [0.39% of initial]
[Iter 4250/20000] Loss: 0.0009784 (Best: 0.0007084 @iter3898) ([92m↓0.80%[0m) [0.39% of initial]
[Iter 4260/20000] Loss: 0.0010667 (Best: 0.0007084 @iter3898) ([91m↑9.03%[0m) [0.42% of initial]
[Iter 4270/20000] Loss: 0.0009681 (Best: 0.0007084 @iter3898) ([92m↓9.24%[0m) [0.38% of initial]
[Iter 4280/20000] Loss: 0.0008437 (Best: 0.0007084 @iter3898) ([92m↓12.85%[0m) [0.34% of initial]
[Iter 4290/20000] Loss: 0.0008129 (Best: 0.0007084 @iter3898) ([92m↓3.66%[0m) [0.32% of initial]
Iter:4299, L1 loss=0.0008992, Total loss=0.0008635, Time:102
[Iter 4300/20000] Loss: 0.0008086 (Best: 0.0007084 @iter3898) ([92m↓0.53%[0m) [0.32% of initial]
[Iter 4310/20000] Loss: 0.0007711 (Best: 0.0007058 @iter4310) ([92m↓4.64%[0m) [0.31% of initial]
[Iter 4320/20000] Loss: 0.0009359 (Best: 0.0007058 @iter4310) ([91m↑21.37%[0m) [0.37% of initial]
[Iter 4330/20000] Loss: 0.0008195 (Best: 0.0007058 @iter4310) ([92m↓12.43%[0m) [0.33% of initial]
[Iter 4340/20000] Loss: 0.0007757 (Best: 0.0006717 @iter4336) ([92m↓5.35%[0m) [0.31% of initial]
[Iter 4350/20000] Loss: 0.0007548 (Best: 0.0006717 @iter4336) ([92m↓2.69%[0m) [0.30% of initial]
[Iter 4360/20000] Loss: 0.0007791 (Best: 0.0006717 @iter4336) ([91m↑3.21%[0m) [0.31% of initial]
[Iter 4370/20000] Loss: 0.0007797 (Best: 0.0006717 @iter4336) ([91m↑0.09%[0m) [0.31% of initial]
[Iter 4380/20000] Loss: 0.0008507 (Best: 0.0006717 @iter4336) ([91m↑9.10%[0m) [0.34% of initial]
[Iter 4390/20000] Loss: 0.0007454 (Best: 0.0006717 @iter4336) ([92m↓12.38%[0m) [0.30% of initial]
Iter:4399, L1 loss=0.0007439, Total loss=0.0006935, Time:57
[Iter 4400/20000] Loss: 0.0007282 (Best: 0.0006446 @iter4396) ([92m↓2.31%[0m) [0.29% of initial]
[Iter 4410/20000] Loss: 0.0027410 (Best: 0.0006446 @iter4396) ([91m↑276.39%[0m) [1.09% of initial]
[Iter 4420/20000] Loss: 0.0015553 (Best: 0.0006446 @iter4396) ([92m↓43.26%[0m) [0.62% of initial]
[Iter 4430/20000] Loss: 0.0011853 (Best: 0.0006446 @iter4396) ([92m↓23.79%[0m) [0.47% of initial]
[Iter 4440/20000] Loss: 0.0009648 (Best: 0.0006446 @iter4396) ([92m↓18.60%[0m) [0.38% of initial]
[Iter 4450/20000] Loss: 0.0008441 (Best: 0.0006446 @iter4396) ([92m↓12.52%[0m) [0.34% of initial]
[Iter 4460/20000] Loss: 0.0008410 (Best: 0.0006446 @iter4396) ([92m↓0.36%[0m) [0.33% of initial]
[Iter 4470/20000] Loss: 0.0009074 (Best: 0.0006446 @iter4396) ([91m↑7.89%[0m) [0.36% of initial]
[Iter 4480/20000] Loss: 0.0008616 (Best: 0.0006446 @iter4396) ([92m↓5.05%[0m) [0.34% of initial]
[Iter 4490/20000] Loss: 0.0008412 (Best: 0.0006446 @iter4396) ([92m↓2.37%[0m) [0.33% of initial]
Iter:4499, L1 loss=0.001011, Total loss=0.0009059, Time:74
[Iter 4500/20000] Loss: 0.0009612 (Best: 0.0006446 @iter4396) ([91m↑14.27%[0m) [0.38% of initial]
Pruning 352 points (0.3%) from gaussian0 at iteration 4500
Pruning 261 points (0.2%) from gaussian1 at iteration 4500
[Iter 4510/20000] Loss: 0.0015680 (Best: 0.0006446 @iter4396) ([91m↑63.13%[0m) [0.62% of initial]
[Iter 4520/20000] Loss: 0.0012123 (Best: 0.0006446 @iter4396) ([92m↓22.69%[0m) [0.48% of initial]
[Iter 4530/20000] Loss: 0.0011470 (Best: 0.0006446 @iter4396) ([92m↓5.38%[0m) [0.46% of initial]
[Iter 4540/20000] Loss: 0.0009252 (Best: 0.0006446 @iter4396) ([92m↓19.34%[0m) [0.37% of initial]
[Iter 4550/20000] Loss: 0.0008283 (Best: 0.0006446 @iter4396) ([92m↓10.48%[0m) [0.33% of initial]
[Iter 4560/20000] Loss: 0.0008368 (Best: 0.0006446 @iter4396) ([91m↑1.03%[0m) [0.33% of initial]
[Iter 4570/20000] Loss: 0.0007340 (Best: 0.0006446 @iter4396) ([92m↓12.28%[0m) [0.29% of initial]
[Iter 4580/20000] Loss: 0.0007280 (Best: 0.0006446 @iter4396) ([92m↓0.82%[0m) [0.29% of initial]
[Iter 4590/20000] Loss: 0.0008037 (Best: 0.0006446 @iter4396) ([91m↑10.39%[0m) [0.32% of initial]
Iter:4599, L1 loss=0.0008336, Total loss=0.000791, Time:85
[Iter 4600/20000] Loss: 0.0007660 (Best: 0.0006446 @iter4396) ([92m↓4.69%[0m) [0.30% of initial]
[Iter 4610/20000] Loss: 0.0029508 (Best: 0.0006446 @iter4396) ([91m↑285.22%[0m) [1.17% of initial]
[Iter 4620/20000] Loss: 0.0018369 (Best: 0.0006446 @iter4396) ([92m↓37.75%[0m) [0.73% of initial]
[Iter 4630/20000] Loss: 0.0012068 (Best: 0.0006446 @iter4396) ([92m↓34.30%[0m) [0.48% of initial]
[Iter 4640/20000] Loss: 0.0009716 (Best: 0.0006446 @iter4396) ([92m↓19.49%[0m) [0.39% of initial]
[Iter 4650/20000] Loss: 0.0008472 (Best: 0.0006446 @iter4396) ([92m↓12.80%[0m) [0.34% of initial]
[Iter 4660/20000] Loss: 0.0007460 (Best: 0.0006446 @iter4396) ([92m↓11.94%[0m) [0.30% of initial]
[Iter 4670/20000] Loss: 0.0007276 (Best: 0.0006446 @iter4396) ([92m↓2.46%[0m) [0.29% of initial]
[Iter 4680/20000] Loss: 0.0007158 (Best: 0.0006324 @iter4672) ([92m↓1.62%[0m) [0.28% of initial]
[Iter 4690/20000] Loss: 0.0006891 (Best: 0.0006281 @iter4681) ([92m↓3.73%[0m) [0.27% of initial]
Iter:4699, L1 loss=0.000804, Total loss=0.0007097, Time:82
[Iter 4700/20000] Loss: 0.0007407 (Best: 0.0006281 @iter4681) ([91m↑7.48%[0m) [0.29% of initial]
[Iter 4710/20000] Loss: 0.0006712 (Best: 0.0006281 @iter4681) ([92m↓9.38%[0m) [0.27% of initial]
[Iter 4720/20000] Loss: 0.0007261 (Best: 0.0005852 @iter4711) ([91m↑8.18%[0m) [0.29% of initial]
[Iter 4730/20000] Loss: 0.0007234 (Best: 0.0005852 @iter4711) ([92m↓0.37%[0m) [0.29% of initial]
[Iter 4740/20000] Loss: 0.0008058 (Best: 0.0005852 @iter4711) ([91m↑11.40%[0m) [0.32% of initial]
[Iter 4750/20000] Loss: 0.0008142 (Best: 0.0005852 @iter4711) ([91m↑1.04%[0m) [0.32% of initial]
[Iter 4760/20000] Loss: 0.0007337 (Best: 0.0005852 @iter4711) ([92m↓9.90%[0m) [0.29% of initial]
[Iter 4770/20000] Loss: 0.0007637 (Best: 0.0005852 @iter4711) ([91m↑4.10%[0m) [0.30% of initial]
[Iter 4780/20000] Loss: 0.0008208 (Best: 0.0005852 @iter4711) ([91m↑7.47%[0m) [0.33% of initial]
[Iter 4790/20000] Loss: 0.0007372 (Best: 0.0005852 @iter4711) ([92m↓10.17%[0m) [0.29% of initial]
Iter:4799, L1 loss=0.0007846, Total loss=0.0007248, Time:74
[Iter 4800/20000] Loss: 0.0008435 (Best: 0.0005852 @iter4711) ([91m↑14.41%[0m) [0.34% of initial]
[Iter 4810/20000] Loss: 0.0023948 (Best: 0.0005852 @iter4711) ([91m↑183.92%[0m) [0.95% of initial]
[Iter 4820/20000] Loss: 0.0015448 (Best: 0.0005852 @iter4711) ([92m↓35.50%[0m) [0.61% of initial]
[Iter 4830/20000] Loss: 0.0011913 (Best: 0.0005852 @iter4711) ([92m↓22.88%[0m) [0.47% of initial]
[Iter 4840/20000] Loss: 0.0009171 (Best: 0.0005852 @iter4711) ([92m↓23.02%[0m) [0.36% of initial]
[Iter 4850/20000] Loss: 0.0007426 (Best: 0.0005852 @iter4711) ([92m↓19.03%[0m) [0.30% of initial]
[Iter 4860/20000] Loss: 0.0007727 (Best: 0.0005852 @iter4711) ([91m↑4.05%[0m) [0.31% of initial]
[Iter 4870/20000] Loss: 0.0007042 (Best: 0.0005852 @iter4711) ([92m↓8.87%[0m) [0.28% of initial]
[Iter 4880/20000] Loss: 0.0007410 (Best: 0.0005852 @iter4711) ([91m↑5.23%[0m) [0.29% of initial]
[Iter 4890/20000] Loss: 0.0006984 (Best: 0.0005852 @iter4711) ([92m↓5.76%[0m) [0.28% of initial]
Iter:4899, L1 loss=0.000786, Total loss=0.0007826, Time:84
[Iter 4900/20000] Loss: 0.0007016 (Best: 0.0005852 @iter4711) ([91m↑0.46%[0m) [0.28% of initial]
[Iter 4910/20000] Loss: 0.0008481 (Best: 0.0005852 @iter4711) ([91m↑20.88%[0m) [0.34% of initial]
[Iter 4920/20000] Loss: 0.0007461 (Best: 0.0005852 @iter4711) ([92m↓12.02%[0m) [0.30% of initial]
[Iter 4930/20000] Loss: 0.0006735 (Best: 0.0005852 @iter4711) ([92m↓9.74%[0m) [0.27% of initial]
[Iter 4940/20000] Loss: 0.0007057 (Best: 0.0005852 @iter4711) ([91m↑4.78%[0m) [0.28% of initial]
[Iter 4950/20000] Loss: 0.0006231 (Best: 0.0005563 @iter4949) ([92m↓11.70%[0m) [0.25% of initial]
[Iter 4960/20000] Loss: 0.0006570 (Best: 0.0005494 @iter4957) ([91m↑5.45%[0m) [0.26% of initial]
[Iter 4970/20000] Loss: 0.0006800 (Best: 0.0005494 @iter4957) ([91m↑3.50%[0m) [0.27% of initial]
[Iter 4980/20000] Loss: 0.0006937 (Best: 0.0005494 @iter4957) ([91m↑2.01%[0m) [0.28% of initial]
[Iter 4990/20000] Loss: 0.0006486 (Best: 0.0005494 @iter4957) ([92m↓6.49%[0m) [0.26% of initial]
Iter:4999, L1 loss=0.000656, Total loss=0.0006194, Time:65
[Iter 5000/20000] Loss: 0.0006116 (Best: 0.0005494 @iter4957) ([92m↓5.71%[0m) [0.24% of initial]
Pruning 317 points (0.3%) from gaussian0 at iteration 5000
Pruning 238 points (0.2%) from gaussian1 at iteration 5000
[Iter 5010/20000] Loss: 0.0026260 (Best: 0.0005494 @iter4957) ([91m↑329.37%[0m) [1.04% of initial]
[Iter 5020/20000] Loss: 0.0016778 (Best: 0.0005494 @iter4957) ([92m↓36.11%[0m) [0.67% of initial]
[Iter 5030/20000] Loss: 0.0010882 (Best: 0.0005494 @iter4957) ([92m↓35.14%[0m) [0.43% of initial]
[Iter 5040/20000] Loss: 0.0010447 (Best: 0.0005494 @iter4957) ([92m↓4.00%[0m) [0.42% of initial]
[Iter 5050/20000] Loss: 0.0008985 (Best: 0.0005494 @iter4957) ([92m↓13.99%[0m) [0.36% of initial]
[Iter 5060/20000] Loss: 0.0007339 (Best: 0.0005494 @iter4957) ([92m↓18.32%[0m) [0.29% of initial]
[Iter 5070/20000] Loss: 0.0007766 (Best: 0.0005494 @iter4957) ([91m↑5.82%[0m) [0.31% of initial]
[Iter 5080/20000] Loss: 0.0006871 (Best: 0.0005494 @iter4957) ([92m↓11.53%[0m) [0.27% of initial]
[Iter 5090/20000] Loss: 0.0007211 (Best: 0.0005494 @iter4957) ([91m↑4.96%[0m) [0.29% of initial]
Iter:5099, L1 loss=0.0007666, Total loss=0.0006913, Time:90
[Iter 5100/20000] Loss: 0.0007548 (Best: 0.0005494 @iter4957) ([91m↑4.66%[0m) [0.30% of initial]
[Iter 5110/20000] Loss: 0.0007374 (Best: 0.0005494 @iter4957) ([92m↓2.30%[0m) [0.29% of initial]
[Iter 5120/20000] Loss: 0.0007365 (Best: 0.0005494 @iter4957) ([92m↓0.12%[0m) [0.29% of initial]
[Iter 5130/20000] Loss: 0.0007489 (Best: 0.0005494 @iter4957) ([91m↑1.69%[0m) [0.30% of initial]
[Iter 5140/20000] Loss: 0.0006708 (Best: 0.0005494 @iter4957) ([92m↓10.43%[0m) [0.27% of initial]
[Iter 5150/20000] Loss: 0.0006773 (Best: 0.0005494 @iter4957) ([91m↑0.97%[0m) [0.27% of initial]
[Iter 5160/20000] Loss: 0.0006701 (Best: 0.0005494 @iter4957) ([92m↓1.06%[0m) [0.27% of initial]
[Iter 5170/20000] Loss: 0.0007330 (Best: 0.0005494 @iter4957) ([91m↑9.38%[0m) [0.29% of initial]
[Iter 5180/20000] Loss: 0.0006783 (Best: 0.0005494 @iter4957) ([92m↓7.46%[0m) [0.27% of initial]
[Iter 5190/20000] Loss: 0.0006971 (Best: 0.0005494 @iter4957) ([91m↑2.77%[0m) [0.28% of initial]
Iter:5199, L1 loss=0.0007476, Total loss=0.0007229, Time:87
[Iter 5200/20000] Loss: 0.0006705 (Best: 0.0005494 @iter4957) ([92m↓3.81%[0m) [0.27% of initial]
[Iter 5210/20000] Loss: 0.0026996 (Best: 0.0005494 @iter4957) ([91m↑302.60%[0m) [1.07% of initial]
[Iter 5220/20000] Loss: 0.0016544 (Best: 0.0005494 @iter4957) ([92m↓38.72%[0m) [0.66% of initial]
[Iter 5230/20000] Loss: 0.0010909 (Best: 0.0005494 @iter4957) ([92m↓34.06%[0m) [0.43% of initial]
[Iter 5240/20000] Loss: 0.0008365 (Best: 0.0005494 @iter4957) ([92m↓23.32%[0m) [0.33% of initial]
[Iter 5250/20000] Loss: 0.0009828 (Best: 0.0005494 @iter4957) ([91m↑17.49%[0m) [0.39% of initial]
[Iter 5260/20000] Loss: 0.0008170 (Best: 0.0005494 @iter4957) ([92m↓16.87%[0m) [0.32% of initial]
[Iter 5270/20000] Loss: 0.0007357 (Best: 0.0005494 @iter4957) ([92m↓9.95%[0m) [0.29% of initial]
[Iter 5280/20000] Loss: 0.0008149 (Best: 0.0005494 @iter4957) ([91m↑10.77%[0m) [0.32% of initial]
[Iter 5290/20000] Loss: 0.0007741 (Best: 0.0005494 @iter4957) ([92m↓5.00%[0m) [0.31% of initial]
Iter:5299, L1 loss=0.0008117, Total loss=0.0008298, Time:96
[Iter 5300/20000] Loss: 0.0008556 (Best: 0.0005494 @iter4957) ([91m↑10.52%[0m) [0.34% of initial]
[Iter 5310/20000] Loss: 0.0008532 (Best: 0.0005494 @iter4957) ([92m↓0.28%[0m) [0.34% of initial]
[Iter 5320/20000] Loss: 0.0007470 (Best: 0.0005494 @iter4957) ([92m↓12.45%[0m) [0.30% of initial]
[Iter 5330/20000] Loss: 0.0006291 (Best: 0.0005494 @iter4957) ([92m↓15.79%[0m) [0.25% of initial]
[Iter 5340/20000] Loss: 0.0006650 (Best: 0.0005494 @iter4957) ([91m↑5.71%[0m) [0.26% of initial]
[Iter 5350/20000] Loss: 0.0006778 (Best: 0.0005358 @iter5344) ([91m↑1.93%[0m) [0.27% of initial]
[Iter 5360/20000] Loss: 0.0007107 (Best: 0.0005358 @iter5344) ([91m↑4.86%[0m) [0.28% of initial]
[Iter 5370/20000] Loss: 0.0007101 (Best: 0.0005358 @iter5344) ([92m↓0.08%[0m) [0.28% of initial]
[Iter 5380/20000] Loss: 0.0006982 (Best: 0.0005358 @iter5344) ([92m↓1.69%[0m) [0.28% of initial]
[Iter 5390/20000] Loss: 0.0007205 (Best: 0.0005358 @iter5344) ([91m↑3.20%[0m) [0.29% of initial]
Iter:5399, L1 loss=0.0006516, Total loss=0.0006419, Time:68
[Iter 5400/20000] Loss: 0.0007279 (Best: 0.0005358 @iter5344) ([91m↑1.02%[0m) [0.29% of initial]
[Iter 5410/20000] Loss: 0.0021378 (Best: 0.0005358 @iter5344) ([91m↑193.71%[0m) [0.85% of initial]
[Iter 5420/20000] Loss: 0.0014195 (Best: 0.0005358 @iter5344) ([92m↓33.60%[0m) [0.56% of initial]
[Iter 5430/20000] Loss: 0.0009352 (Best: 0.0005358 @iter5344) ([92m↓34.12%[0m) [0.37% of initial]
[Iter 5440/20000] Loss: 0.0008406 (Best: 0.0005358 @iter5344) ([92m↓10.11%[0m) [0.33% of initial]
[Iter 5450/20000] Loss: 0.0007049 (Best: 0.0005358 @iter5344) ([92m↓16.15%[0m) [0.28% of initial]
[Iter 5460/20000] Loss: 0.0007881 (Best: 0.0005358 @iter5344) ([91m↑11.82%[0m) [0.31% of initial]
[Iter 5470/20000] Loss: 0.0006721 (Best: 0.0005358 @iter5344) ([92m↓14.73%[0m) [0.27% of initial]
[Iter 5480/20000] Loss: 0.0006295 (Best: 0.0005270 @iter5476) ([92m↓6.34%[0m) [0.25% of initial]
[Iter 5490/20000] Loss: 0.0006604 (Best: 0.0005270 @iter5476) ([91m↑4.92%[0m) [0.26% of initial]
Iter:5499, L1 loss=0.0006962, Total loss=0.0006718, Time:77
[Iter 5500/20000] Loss: 0.0006209 (Best: 0.0005270 @iter5476) ([92m↓5.98%[0m) [0.25% of initial]
Pruning 613 points (0.5%) from gaussian0 at iteration 5500
Pruning 200 points (0.2%) from gaussian1 at iteration 5500
[Iter 5510/20000] Loss: 0.0011774 (Best: 0.0005270 @iter5476) ([91m↑89.62%[0m) [0.47% of initial]
[Iter 5520/20000] Loss: 0.0008727 (Best: 0.0005270 @iter5476) ([92m↓25.88%[0m) [0.35% of initial]
[Iter 5530/20000] Loss: 0.0007993 (Best: 0.0005270 @iter5476) ([92m↓8.41%[0m) [0.32% of initial]
[Iter 5540/20000] Loss: 0.0007267 (Best: 0.0005270 @iter5476) ([92m↓9.08%[0m) [0.29% of initial]
[Iter 5550/20000] Loss: 0.0006995 (Best: 0.0005270 @iter5476) ([92m↓3.75%[0m) [0.28% of initial]
[Iter 5560/20000] Loss: 0.0006424 (Best: 0.0005270 @iter5476) ([92m↓8.16%[0m) [0.26% of initial]
[Iter 5570/20000] Loss: 0.0006290 (Best: 0.0005270 @iter5476) ([92m↓2.08%[0m) [0.25% of initial]
[Iter 5580/20000] Loss: 0.0007442 (Best: 0.0005270 @iter5476) ([91m↑18.31%[0m) [0.30% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 2000, 'end_sample_pseudo': 10000}
[Iter 5590/20000] Loss: 0.0007916 (Best: 0.0005270 @iter5476) ([91m↑6.37%[0m) [0.31% of initial]
Iter:5599, L1 loss=0.0006288, Total loss=0.0006058, Time:76
[Iter 5600/20000] Loss: 0.0006215 (Best: 0.0005270 @iter5476) ([92m↓21.49%[0m) [0.25% of initial]
[Iter 5610/20000] Loss: 0.0026135 (Best: 0.0005270 @iter5476) ([91m↑320.54%[0m) [1.04% of initial]
[Iter 5620/20000] Loss: 0.0014384 (Best: 0.0005270 @iter5476) ([92m↓44.96%[0m) [0.57% of initial]
[Iter 5630/20000] Loss: 0.0010238 (Best: 0.0005270 @iter5476) ([92m↓28.82%[0m) [0.41% of initial]
[Iter 5640/20000] Loss: 0.0008619 (Best: 0.0005270 @iter5476) ([92m↓15.82%[0m) [0.34% of initial]
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 5650/20000] Loss: 0.0007153 (Best: 0.0005270 @iter5476) ([92m↓17.01%[0m) [0.28% of initial]
[Iter 5660/20000] Loss: 0.0006867 (Best: 0.0005270 @iter5476) ([92m↓4.00%[0m) [0.27% of initial]
[Iter 5670/20000] Loss: 0.0006830 (Best: 0.0005270 @iter5476) ([92m↓0.54%[0m) [0.27% of initial]
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746109 (Best: 0.1692742 @iter20) ([92m↓19.87%[0m) [69.37% of initial]
[Iter 5680/20000] Loss: 0.0006294 (Best: 0.0005270 @iter5476) ([92m↓7.84%[0m) [0.25% of initial]
[Iter 30/20000] Loss: 0.1374359 (Best: 0.1328018 @iter30) ([92m↓21.29%[0m) [54.60% of initial]
[Iter 5690/20000] Loss: 0.0006932 (Best: 0.0005270 @iter5476) ([91m↑10.14%[0m) [0.28% of initial]
[Iter 40/20000] Loss: 0.1129258 (Best: 0.1107272 @iter40) ([92m↓17.83%[0m) [44.86% of initial]
Iter:5699, L1 loss=0.0006283, Total loss=0.0005613, Time:76
[Iter 5700/20000] Loss: 0.0005852 (Best: 0.0005270 @iter5476) ([92m↓15.59%[0m) [0.23% of initial]
[Iter 50/20000] Loss: 0.0993547 (Best: 0.0966755 @iter49) ([92m↓12.02%[0m) [39.47% of initial]
[Iter 5710/20000] Loss: 0.0007200 (Best: 0.0005037 @iter5701) ([91m↑23.04%[0m) [0.29% of initial]
[Iter 60/20000] Loss: 0.0931327 (Best: 0.0906817 @iter60) ([92m↓6.26%[0m) [37.00% of initial]
[Iter 5720/20000] Loss: 0.0006529 (Best: 0.0005037 @iter5701) ([92m↓9.31%[0m) [0.26% of initial]
[Iter 70/20000] Loss: 0.0898582 (Best: 0.0872546 @iter69) ([92m↓3.52%[0m) [35.70% of initial]
[Iter 80/20000] Loss: 0.0859405 (Best: 0.0831309 @iter79) ([92m↓4.36%[0m) [34.14% of initial]
[Iter 5730/20000] Loss: 0.0006738 (Best: 0.0005037 @iter5701) ([91m↑3.20%[0m) [0.27% of initial]
[Iter 90/20000] Loss: 0.0816491 (Best: 0.0794354 @iter90) ([92m↓4.99%[0m) [32.44% of initial]
[Iter 5740/20000] Loss: 0.0005837 (Best: 0.0005037 @iter5701) ([92m↓13.36%[0m) [0.23% of initial]
Iter:99, L1 loss=0.05796, Total loss=0.07967, Time:51
[Iter 100/20000] Loss: 0.0791425 (Best: 0.0767306 @iter97) ([92m↓3.07%[0m) [31.44% of initial]
[Iter 5750/20000] Loss: 0.0005880 (Best: 0.0005037 @iter5701) ([91m↑0.74%[0m) [0.23% of initial]
[Iter 110/20000] Loss: 0.0751300 (Best: 0.0731555 @iter106) ([92m↓5.07%[0m) [29.85% of initial]
[Iter 5760/20000] Loss: 0.0005806 (Best: 0.0005037 @iter5701) ([92m↓1.26%[0m) [0.23% of initial]
[Iter 120/20000] Loss: 0.0713436 (Best: 0.0684937 @iter118) ([92m↓5.04%[0m) [28.34% of initial]
[Iter 5770/20000] Loss: 0.0005283 (Best: 0.0004711 @iter5770) ([92m↓9.02%[0m) [0.21% of initial]
[Iter 130/20000] Loss: 0.0666315 (Best: 0.0641412 @iter130) ([92m↓6.60%[0m) [26.47% of initial]
[Iter 140/20000] Loss: 0.0644116 (Best: 0.0612704 @iter139) ([92m↓3.33%[0m) [25.59% of initial]
[Iter 5780/20000] Loss: 0.0005385 (Best: 0.0004711 @iter5770) ([91m↑1.93%[0m) [0.21% of initial]
[Iter 150/20000] Loss: 0.0602161 (Best: 0.0581087 @iter150) ([92m↓6.51%[0m) [23.92% of initial]
[Iter 5790/20000] Loss: 0.0005795 (Best: 0.0004711 @iter5770) ([91m↑7.62%[0m) [0.23% of initial]
[Iter 160/20000] Loss: 0.0574518 (Best: 0.0557289 @iter159) ([92m↓4.59%[0m) [22.83% of initial]
Iter:5799, L1 loss=0.0005974, Total loss=0.0005699, Time:72
[Iter 5800/20000] Loss: 0.0005522 (Best: 0.0004529 @iter5797) ([92m↓4.71%[0m) [0.22% of initial]
[Iter 170/20000] Loss: 0.0558569 (Best: 0.0532808 @iter166) ([92m↓2.78%[0m) [22.19% of initial]
[Iter 180/20000] Loss: 0.0530322 (Best: 0.0502805 @iter178) ([92m↓5.06%[0m) [21.07% of initial]
[Iter 5810/20000] Loss: 0.0018369 (Best: 0.0004529 @iter5797) ([91m↑232.64%[0m) [0.73% of initial]
[Iter 190/20000] Loss: 0.0498389 (Best: 0.0476732 @iter188) ([92m↓6.02%[0m) [19.80% of initial]
[Iter 5820/20000] Loss: 0.0013220 (Best: 0.0004529 @iter5797) ([92m↓28.03%[0m) [0.53% of initial]
Iter:199, L1 loss=0.03451, Total loss=0.04972, Time:33
[Iter 200/20000] Loss: 0.0468808 (Best: 0.0448198 @iter200) ([92m↓5.94%[0m) [18.63% of initial]
[Iter 5830/20000] Loss: 0.0009190 (Best: 0.0004529 @iter5797) ([92m↓30.48%[0m) [0.37% of initial]
[Iter 210/20000] Loss: 0.0459937 (Best: 0.0430720 @iter208) ([92m↓1.89%[0m) [18.27% of initial]
[Iter 220/20000] Loss: 0.0431309 (Best: 0.0410409 @iter217) ([92m↓6.22%[0m) [17.14% of initial]
[Iter 5840/20000] Loss: 0.0007551 (Best: 0.0004529 @iter5797) ([92m↓17.83%[0m) [0.30% of initial]
[Iter 230/20000] Loss: 0.0413312 (Best: 0.0390734 @iter230) ([92m↓4.17%[0m) [16.42% of initial]
[Iter 5850/20000] Loss: 0.0007367 (Best: 0.0004529 @iter5797) ([92m↓2.44%[0m) [0.29% of initial]
[Iter 240/20000] Loss: 0.0395087 (Best: 0.0375734 @iter240) ([92m↓4.41%[0m) [15.70% of initial]
[Iter 5860/20000] Loss: 0.0006004 (Best: 0.0004529 @iter5797) ([92m↓18.49%[0m) [0.24% of initial]
[Iter 250/20000] Loss: 0.0371092 (Best: 0.0357959 @iter250) ([92m↓6.07%[0m) [14.74% of initial]
[Iter 5870/20000] Loss: 0.0006968 (Best: 0.0004529 @iter5797) ([91m↑16.05%[0m) [0.28% of initial]
[Iter 260/20000] Loss: 0.0376823 (Best: 0.0348842 @iter256) ([91m↑1.54%[0m) [14.97% of initial]
[Iter 5880/20000] Loss: 0.0006378 (Best: 0.0004529 @iter5797) ([92m↓8.47%[0m) [0.25% of initial]
[Iter 270/20000] Loss: 0.0346020 (Best: 0.0327102 @iter270) ([92m↓8.17%[0m) [13.75% of initial]
[Iter 280/20000] Loss: 0.0330593 (Best: 0.0310243 @iter278) ([92m↓4.46%[0m) [13.13% of initial]
[Iter 5890/20000] Loss: 0.0006182 (Best: 0.0004529 @iter5797) ([92m↓3.08%[0m) [0.25% of initial]
[Iter 290/20000] Loss: 0.0327595 (Best: 0.0300510 @iter286) ([92m↓0.91%[0m) [13.02% of initial]
Iter:5899, L1 loss=0.0006, Total loss=0.0005865, Time:87
[Iter 5900/20000] Loss: 0.0005790 (Best: 0.0004529 @iter5797) ([92m↓6.33%[0m) [0.23% of initial]
Iter:299, L1 loss=0.0215, Total loss=0.03296, Time:49
[Iter 300/20000] Loss: 0.0309293 (Best: 0.0284248 @iter298) ([92m↓5.59%[0m) [12.29% of initial]
[Iter 5910/20000] Loss: 0.0006165 (Best: 0.0004529 @iter5797) ([91m↑6.48%[0m) [0.24% of initial]
[Iter 310/20000] Loss: 0.0294093 (Best: 0.0274591 @iter308) ([92m↓4.91%[0m) [11.68% of initial]
[Iter 320/20000] Loss: 0.0274608 (Best: 0.0260402 @iter319) ([92m↓6.63%[0m) [10.91% of initial]
[Iter 5920/20000] Loss: 0.0005827 (Best: 0.0004529 @iter5797) ([92m↓5.48%[0m) [0.23% of initial]
[Iter 330/20000] Loss: 0.0269544 (Best: 0.0252236 @iter330) ([92m↓1.84%[0m) [10.71% of initial]
[Iter 5930/20000] Loss: 0.0004993 (Best: 0.0004529 @iter5797) ([92m↓14.31%[0m) [0.20% of initial]
[Iter 340/20000] Loss: 0.0251085 (Best: 0.0235819 @iter340) ([92m↓6.85%[0m) [9.98% of initial]
[Iter 5940/20000] Loss: 0.0006668 (Best: 0.0004529 @iter5797) ([91m↑33.53%[0m) [0.26% of initial]
[Iter 350/20000] Loss: 0.0244513 (Best: 0.0227157 @iter350) ([92m↓2.62%[0m) [9.71% of initial]
[Iter 5950/20000] Loss: 0.0005515 (Best: 0.0004529 @iter5797) ([92m↓17.29%[0m) [0.22% of initial]
[Iter 360/20000] Loss: 0.0238477 (Best: 0.0219708 @iter359) ([92m↓2.47%[0m) [9.47% of initial]
[Iter 5960/20000] Loss: 0.0005891 (Best: 0.0004529 @iter5797) ([91m↑6.82%[0m) [0.23% of initial]
[Iter 370/20000] Loss: 0.0223283 (Best: 0.0207578 @iter370) ([92m↓6.37%[0m) [8.87% of initial]
[Iter 380/20000] Loss: 0.0214420 (Best: 0.0201993 @iter380) ([92m↓3.97%[0m) [8.52% of initial]
[Iter 5970/20000] Loss: 0.0006889 (Best: 0.0004529 @iter5797) ([91m↑16.94%[0m) [0.27% of initial]
[Iter 390/20000] Loss: 0.0212331 (Best: 0.0195652 @iter389) ([92m↓0.97%[0m) [8.44% of initial]
[Iter 5980/20000] Loss: 0.0005986 (Best: 0.0004529 @iter5797) ([92m↓13.10%[0m) [0.24% of initial]
Iter:399, L1 loss=0.01428, Total loss=0.02276, Time:37
[Iter 400/20000] Loss: 0.0216549 (Best: 0.0190335 @iter398) ([91m↑1.99%[0m) [8.60% of initial]
[Iter 5990/20000] Loss: 0.0006240 (Best: 0.0004529 @iter5797) ([91m↑4.24%[0m) [0.25% of initial]
[Iter 410/20000] Loss: 0.0190399 (Best: 0.0178221 @iter409) ([92m↓12.08%[0m) [7.56% of initial]
Iter:5999, L1 loss=0.0006494, Total loss=0.0006406, Time:78
[Iter 420/20000] Loss: 0.0196432 (Best: 0.0172956 @iter418) ([91m↑3.17%[0m) [7.80% of initial]
[Iter 6000/20000] Loss: 0.0006150 (Best: 0.0004529 @iter5797) ([92m↓1.45%[0m) [0.24% of initial]
[Iter 430/20000] Loss: 0.0195748 (Best: 0.0172786 @iter424) ([92m↓0.35%[0m) [7.78% of initial]
Pruning 429 points (0.3%) from gaussian0 at iteration 6000
Pruning 168 points (0.1%) from gaussian1 at iteration 6000
[Iter 440/20000] Loss: 0.0181348 (Best: 0.0158813 @iter439) ([92m↓7.36%[0m) [7.20% of initial]
[Iter 6010/20000] Loss: 0.0601412 (Best: 0.0004529 @iter5797) ([91m↑9679.11%[0m) [23.89% of initial]
[Iter 450/20000] Loss: 0.0172051 (Best: 0.0152497 @iter448) ([92m↓5.13%[0m) [6.84% of initial]
[Iter 6020/20000] Loss: 0.0310131 (Best: 0.0004529 @iter5797) ([92m↓48.43%[0m) [12.32% of initial]
[Iter 460/20000] Loss: 0.0157122 (Best: 0.0143362 @iter460) ([92m↓8.68%[0m) [6.24% of initial]
[Iter 470/20000] Loss: 0.0151253 (Best: 0.0141474 @iter469) ([92m↓3.74%[0m) [6.01% of initial]
[Iter 6030/20000] Loss: 0.0112974 (Best: 0.0004529 @iter5797) ([92m↓63.57%[0m) [4.49% of initial]
[Iter 480/20000] Loss: 0.0149587 (Best: 0.0134643 @iter479) ([92m↓1.10%[0m) [5.94% of initial]
[Iter 6040/20000] Loss: 0.0056260 (Best: 0.0004529 @iter5797) ([92m↓50.20%[0m) [2.24% of initial]
[Iter 490/20000] Loss: 0.0151670 (Best: 0.0129343 @iter487) ([91m↑1.39%[0m) [6.03% of initial]
[Iter 6050/20000] Loss: 0.0034279 (Best: 0.0004529 @iter5797) ([92m↓39.07%[0m) [1.36% of initial]
Iter:499, L1 loss=0.008743, Total loss=0.01593, Time:51
[Iter 500/20000] Loss: 0.0151512 (Best: 0.0129343 @iter487) ([92m↓0.10%[0m) [6.02% of initial]
[Iter 6060/20000] Loss: 0.0025462 (Best: 0.0004529 @iter5797) ([92m↓25.72%[0m) [1.01% of initial]
[Iter 510/20000] Loss: 0.0137855 (Best: 0.0122912 @iter505) ([92m↓9.01%[0m) [5.48% of initial]
[Iter 520/20000] Loss: 0.0135885 (Best: 0.0122912 @iter505) ([92m↓1.43%[0m) [5.40% of initial]
[Iter 6070/20000] Loss: 0.0018574 (Best: 0.0004529 @iter5797) ([92m↓27.05%[0m) [0.74% of initial]
[Iter 530/20000] Loss: 0.0128986 (Best: 0.0117946 @iter529) ([92m↓5.08%[0m) [5.12% of initial]
[Iter 6080/20000] Loss: 0.0015856 (Best: 0.0004529 @iter5797) ([92m↓14.63%[0m) [0.63% of initial]
[Iter 540/20000] Loss: 0.0133155 (Best: 0.0117946 @iter529) ([91m↑3.23%[0m) [5.29% of initial]
[Iter 6090/20000] Loss: 0.0013309 (Best: 0.0004529 @iter5797) ([92m↓16.06%[0m) [0.53% of initial]
[Iter 550/20000] Loss: 0.0120590 (Best: 0.0110559 @iter550) ([92m↓9.44%[0m) [4.79% of initial]
[Iter 560/20000] Loss: 0.0125920 (Best: 0.0110559 @iter550) ([91m↑4.42%[0m) [5.00% of initial]
Iter:6099, L1 loss=0.001176, Total loss=0.001268, Time:96
[Iter 6100/20000] Loss: 0.0011987 (Best: 0.0004529 @iter5797) ([92m↓9.93%[0m) [0.48% of initial]
[Iter 570/20000] Loss: 0.0121026 (Best: 0.0105503 @iter568) ([92m↓3.89%[0m) [4.81% of initial]
[Iter 6110/20000] Loss: 0.0011683 (Best: 0.0004529 @iter5797) ([92m↓2.54%[0m) [0.46% of initial]
[Iter 580/20000] Loss: 0.0121267 (Best: 0.0104434 @iter571) ([91m↑0.20%[0m) [4.82% of initial]
[Iter 6120/20000] Loss: 0.0010920 (Best: 0.0004529 @iter5797) ([92m↓6.53%[0m) [0.43% of initial]
[Iter 590/20000] Loss: 0.0109102 (Best: 0.0102662 @iter590) ([92m↓10.03%[0m) [4.33% of initial]
Iter:599, L1 loss=0.006889, Total loss=0.01285, Time:42
[Iter 600/20000] Loss: 0.0119636 (Best: 0.0102662 @iter590) ([91m↑9.66%[0m) [4.75% of initial]
[Iter 6130/20000] Loss: 0.0010155 (Best: 0.0004529 @iter5797) ([92m↓7.01%[0m) [0.40% of initial]
[Iter 610/20000] Loss: 0.0238184 (Best: 0.0102662 @iter590) ([91m↑99.09%[0m) [9.46% of initial]
[Iter 6140/20000] Loss: 0.0009373 (Best: 0.0004529 @iter5797) ([92m↓7.70%[0m) [0.37% of initial]
[Iter 620/20000] Loss: 0.0149823 (Best: 0.0102662 @iter590) ([92m↓37.10%[0m) [5.95% of initial]
[Iter 6150/20000] Loss: 0.0009246 (Best: 0.0004529 @iter5797) ([92m↓1.35%[0m) [0.37% of initial]
[Iter 630/20000] Loss: 0.0123212 (Best: 0.0102662 @iter590) ([92m↓17.76%[0m) [4.90% of initial]
[Iter 6160/20000] Loss: 0.0008461 (Best: 0.0004529 @iter5797) ([92m↓8.49%[0m) [0.34% of initial]
[Iter 640/20000] Loss: 0.0106068 (Best: 0.0098423 @iter640) ([92m↓13.91%[0m) [4.21% of initial]
[Iter 6170/20000] Loss: 0.0009022 (Best: 0.0004529 @iter5797) ([91m↑6.63%[0m) [0.36% of initial]
[Iter 650/20000] Loss: 0.0101028 (Best: 0.0093777 @iter650) ([92m↓4.75%[0m) [4.01% of initial]
[Iter 660/20000] Loss: 0.0101890 (Best: 0.0089150 @iter658) ([91m↑0.85%[0m) [4.05% of initial]
[Iter 6180/20000] Loss: 0.0009332 (Best: 0.0004529 @iter5797) ([91m↑3.44%[0m) [0.37% of initial]
[Iter 670/20000] Loss: 0.0097533 (Best: 0.0085853 @iter667) ([92m↓4.28%[0m) [3.87% of initial]
[Iter 6190/20000] Loss: 0.0008088 (Best: 0.0004529 @iter5797) ([92m↓13.33%[0m) [0.32% of initial]
[Iter 680/20000] Loss: 0.0090451 (Best: 0.0082836 @iter679) ([92m↓7.26%[0m) [3.59% of initial]
Iter:6199, L1 loss=0.0007881, Total loss=0.000801, Time:85
[Iter 6200/20000] Loss: 0.0008164 (Best: 0.0004529 @iter5797) ([91m↑0.94%[0m) [0.32% of initial]
[Iter 690/20000] Loss: 0.0088480 (Best: 0.0080711 @iter689) ([92m↓2.18%[0m) [3.52% of initial]
Iter:699, L1 loss=0.005647, Total loss=0.008436, Time:29
[Iter 700/20000] Loss: 0.0090303 (Best: 0.0079568 @iter694) ([91m↑2.06%[0m) [3.59% of initial]
[Iter 6210/20000] Loss: 0.0018881 (Best: 0.0004529 @iter5797) ([91m↑131.26%[0m) [0.75% of initial]
[Iter 710/20000] Loss: 0.0084673 (Best: 0.0078363 @iter707) ([92m↓6.23%[0m) [3.36% of initial]
[Iter 720/20000] Loss: 0.0085415 (Best: 0.0076586 @iter719) ([91m↑0.88%[0m) [3.39% of initial]
[Iter 6220/20000] Loss: 0.0013625 (Best: 0.0004529 @iter5797) ([92m↓27.83%[0m) [0.54% of initial]
[Iter 730/20000] Loss: 0.0078605 (Best: 0.0074146 @iter730) ([92m↓7.97%[0m) [3.12% of initial]
[Iter 6230/20000] Loss: 0.0011936 (Best: 0.0004529 @iter5797) ([92m↓12.40%[0m) [0.47% of initial]
[Iter 740/20000] Loss: 0.0078110 (Best: 0.0072547 @iter736) ([92m↓0.63%[0m) [3.10% of initial]
[Iter 6240/20000] Loss: 0.0009778 (Best: 0.0004529 @iter5797) ([92m↓18.08%[0m) [0.39% of initial]
[Iter 750/20000] Loss: 0.0079466 (Best: 0.0071534 @iter745) ([91m↑1.74%[0m) [3.16% of initial]
[Iter 6250/20000] Loss: 0.0008846 (Best: 0.0004529 @iter5797) ([92m↓9.54%[0m) [0.35% of initial]
[Iter 760/20000] Loss: 0.0082256 (Best: 0.0070650 @iter758) ([91m↑3.51%[0m) [3.27% of initial]
[Iter 770/20000] Loss: 0.0077375 (Best: 0.0067835 @iter769) ([92m↓5.93%[0m) [3.07% of initial]
[Iter 6260/20000] Loss: 0.0009705 (Best: 0.0004529 @iter5797) ([91m↑9.72%[0m) [0.39% of initial]
[Iter 780/20000] Loss: 0.0076601 (Best: 0.0067835 @iter769) ([92m↓1.00%[0m) [3.04% of initial]
[Iter 6270/20000] Loss: 0.0008454 (Best: 0.0004529 @iter5797) ([92m↓12.90%[0m) [0.34% of initial]
[Iter 790/20000] Loss: 0.0074961 (Best: 0.0066484 @iter781) ([92m↓2.14%[0m) [2.98% of initial]
Iter:799, L1 loss=0.004262, Total loss=0.006704, Time:25
[Iter 6280/20000] Loss: 0.0008711 (Best: 0.0004529 @iter5797) ([91m↑3.05%[0m) [0.35% of initial]
[Iter 800/20000] Loss: 0.0075328 (Best: 0.0066484 @iter781) ([91m↑0.49%[0m) [2.99% of initial]
[Iter 6290/20000] Loss: 0.0008065 (Best: 0.0004529 @iter5797) ([92m↓7.42%[0m) [0.32% of initial]
[Iter 810/20000] Loss: 0.0150630 (Best: 0.0066484 @iter781) ([91m↑99.97%[0m) [5.98% of initial]
Iter:6299, L1 loss=0.0008002, Total loss=0.0008128, Time:108
[Iter 820/20000] Loss: 0.0098480 (Best: 0.0066484 @iter781) ([92m↓34.62%[0m) [3.91% of initial]
[Iter 6300/20000] Loss: 0.0008947 (Best: 0.0004529 @iter5797) ([91m↑10.94%[0m) [0.36% of initial]
[Iter 830/20000] Loss: 0.0088363 (Best: 0.0066484 @iter781) ([92m↓10.27%[0m) [3.51% of initial]
[Iter 6310/20000] Loss: 0.0007976 (Best: 0.0004529 @iter5797) ([92m↓10.85%[0m) [0.32% of initial]
[Iter 840/20000] Loss: 0.0078245 (Best: 0.0066484 @iter781) ([92m↓11.45%[0m) [3.11% of initial]
[Iter 6320/20000] Loss: 0.0008447 (Best: 0.0004529 @iter5797) ([91m↑5.90%[0m) [0.34% of initial]
[Iter 850/20000] Loss: 0.0073812 (Best: 0.0066145 @iter847) ([92m↓5.67%[0m) [2.93% of initial]
[Iter 6330/20000] Loss: 0.0008196 (Best: 0.0004529 @iter5797) ([92m↓2.97%[0m) [0.33% of initial]
[Iter 860/20000] Loss: 0.0072294 (Best: 0.0061923 @iter859) ([92m↓2.06%[0m) [2.87% of initial]
[Iter 870/20000] Loss: 0.0069473 (Best: 0.0061923 @iter859) ([92m↓3.90%[0m) [2.76% of initial]
[Iter 6340/20000] Loss: 0.0007164 (Best: 0.0004529 @iter5797) ([92m↓12.59%[0m) [0.28% of initial]
[Iter 880/20000] Loss: 0.0064113 (Best: 0.0058331 @iter874) ([92m↓7.71%[0m) [2.55% of initial]
[Iter 6350/20000] Loss: 0.0007447 (Best: 0.0004529 @iter5797) ([91m↑3.96%[0m) [0.30% of initial]
[Iter 890/20000] Loss: 0.0064204 (Best: 0.0058331 @iter874) ([91m↑0.14%[0m) [2.55% of initial]
Iter:899, L1 loss=0.003786, Total loss=0.005674, Time:52
[Iter 6360/20000] Loss: 0.0007846 (Best: 0.0004529 @iter5797) ([91m↑5.35%[0m) [0.31% of initial]
[Iter 900/20000] Loss: 0.0066767 (Best: 0.0056740 @iter899) ([91m↑3.99%[0m) [2.65% of initial]
[Iter 910/20000] Loss: 0.0066747 (Best: 0.0055805 @iter904) ([92m↓0.03%[0m) [2.65% of initial]
[Iter 6370/20000] Loss: 0.0007598 (Best: 0.0004529 @iter5797) ([92m↓3.16%[0m) [0.30% of initial]
[Iter 920/20000] Loss: 0.0061475 (Best: 0.0055342 @iter916) ([92m↓7.90%[0m) [2.44% of initial]
[Iter 6380/20000] Loss: 0.0007018 (Best: 0.0004529 @iter5797) ([92m↓7.63%[0m) [0.28% of initial]
[Iter 930/20000] Loss: 0.0059331 (Best: 0.0054829 @iter930) ([92m↓3.49%[0m) [2.36% of initial]
[Iter 6390/20000] Loss: 0.0007451 (Best: 0.0004529 @iter5797) ([91m↑6.17%[0m) [0.30% of initial]
[Iter 940/20000] Loss: 0.0062117 (Best: 0.0053072 @iter935) ([91m↑4.70%[0m) [2.47% of initial]
Iter:6399, L1 loss=0.0007226, Total loss=0.0006983, Time:92
[Iter 950/20000] Loss: 0.0060520 (Best: 0.0052811 @iter941) ([92m↓2.57%[0m) [2.40% of initial]
[Iter 6400/20000] Loss: 0.0007575 (Best: 0.0004529 @iter5797) ([91m↑1.66%[0m) [0.30% of initial]
[Iter 960/20000] Loss: 0.0058740 (Best: 0.0051385 @iter959) ([92m↓2.94%[0m) [2.33% of initial]
[Iter 6410/20000] Loss: 0.0012728 (Best: 0.0004529 @iter5797) ([91m↑68.04%[0m) [0.51% of initial]
[Iter 970/20000] Loss: 0.0058476 (Best: 0.0049984 @iter967) ([92m↓0.45%[0m) [2.32% of initial]
[Iter 980/20000] Loss: 0.0062205 (Best: 0.0049984 @iter967) ([91m↑6.38%[0m) [2.47% of initial]
[Iter 6420/20000] Loss: 0.0011743 (Best: 0.0004529 @iter5797) ([92m↓7.74%[0m) [0.47% of initial]
[Iter 990/20000] Loss: 0.0061054 (Best: 0.0049984 @iter967) ([92m↓1.85%[0m) [2.43% of initial]
[Iter 6430/20000] Loss: 0.0010374 (Best: 0.0004529 @iter5797) ([92m↓11.66%[0m) [0.41% of initial]
Iter:999, L1 loss=0.004529, Total loss=0.007167, Time:36
[Iter 1000/20000] Loss: 0.0060474 (Best: 0.0049984 @iter967) ([92m↓0.95%[0m) [2.40% of initial]
[Iter 6440/20000] Loss: 0.0008873 (Best: 0.0004529 @iter5797) ([92m↓14.47%[0m) [0.35% of initial]
[Iter 1010/20000] Loss: 0.0114605 (Best: 0.0049984 @iter967) ([91m↑89.51%[0m) [4.55% of initial]
[Iter 6450/20000] Loss: 0.0008309 (Best: 0.0004529 @iter5797) ([92m↓6.36%[0m) [0.33% of initial]
[Iter 1020/20000] Loss: 0.0080936 (Best: 0.0049984 @iter967) ([92m↓29.38%[0m) [3.22% of initial]
[Iter 1030/20000] Loss: 0.0072597 (Best: 0.0049984 @iter967) ([92m↓10.30%[0m) [2.88% of initial]
[Iter 6460/20000] Loss: 0.0007603 (Best: 0.0004529 @iter5797) ([92m↓8.49%[0m) [0.30% of initial]
[Iter 1040/20000] Loss: 0.0057112 (Best: 0.0049984 @iter967) ([92m↓21.33%[0m) [2.27% of initial]
[Iter 6470/20000] Loss: 0.0007566 (Best: 0.0004529 @iter5797) ([92m↓0.48%[0m) [0.30% of initial]
[Iter 1050/20000] Loss: 0.0058543 (Best: 0.0049984 @iter967) ([91m↑2.51%[0m) [2.33% of initial]
[Iter 6480/20000] Loss: 0.0007538 (Best: 0.0004529 @iter5797) ([92m↓0.38%[0m) [0.30% of initial]
[Iter 1060/20000] Loss: 0.0055969 (Best: 0.0049391 @iter1059) ([92m↓4.40%[0m) [2.22% of initial]
[Iter 6490/20000] Loss: 0.0007124 (Best: 0.0004529 @iter5797) ([92m↓5.49%[0m) [0.28% of initial]
[Iter 1070/20000] Loss: 0.0053448 (Best: 0.0046056 @iter1063) ([92m↓4.50%[0m) [2.12% of initial]
[Iter 1080/20000] Loss: 0.0049744 (Best: 0.0045755 @iter1080) ([92m↓6.93%[0m) [1.98% of initial]
Iter:6499, L1 loss=0.0007925, Total loss=0.0007984, Time:116
[Iter 6500/20000] Loss: 0.0007799 (Best: 0.0004529 @iter5797) ([91m↑9.48%[0m) [0.31% of initial]
Pruning 276 points (0.2%) from gaussian0 at iteration 6500
[Iter 1090/20000] Loss: 0.0048544 (Best: 0.0042006 @iter1084) ([92m↓2.41%[0m) [1.93% of initial]
Pruning 198 points (0.2%) from gaussian1 at iteration 6500
Iter:1099, L1 loss=0.002942, Total loss=0.004259, Time:27
[Iter 1100/20000] Loss: 0.0047126 (Best: 0.0042006 @iter1084) ([92m↓2.92%[0m) [1.87% of initial]
[Iter 6510/20000] Loss: 0.0016669 (Best: 0.0004529 @iter5797) ([91m↑113.72%[0m) [0.66% of initial]
[Iter 1110/20000] Loss: 0.0050536 (Best: 0.0042006 @iter1084) ([91m↑7.24%[0m) [2.01% of initial]
[Iter 6520/20000] Loss: 0.0011588 (Best: 0.0004529 @iter5797) ([92m↓30.48%[0m) [0.46% of initial]
[Iter 1120/20000] Loss: 0.0048668 (Best: 0.0042006 @iter1084) ([92m↓3.70%[0m) [1.93% of initial]
[Iter 1130/20000] Loss: 0.0045759 (Best: 0.0040654 @iter1129) ([92m↓5.98%[0m) [1.82% of initial]
[Iter 6530/20000] Loss: 0.0010718 (Best: 0.0004529 @iter5797) ([92m↓7.51%[0m) [0.43% of initial]
[Iter 1140/20000] Loss: 0.0048037 (Best: 0.0039486 @iter1135) ([91m↑4.98%[0m) [1.91% of initial]
[Iter 6540/20000] Loss: 0.0008726 (Best: 0.0004529 @iter5797) ([92m↓18.59%[0m) [0.35% of initial]
[Iter 1150/20000] Loss: 0.0041802 (Best: 0.0037852 @iter1150) ([92m↓12.98%[0m) [1.66% of initial]
[Iter 6550/20000] Loss: 0.0007902 (Best: 0.0004529 @iter5797) ([92m↓9.44%[0m) [0.31% of initial]
[Iter 1160/20000] Loss: 0.0046510 (Best: 0.0037852 @iter1150) ([91m↑11.26%[0m) [1.85% of initial]
[Iter 1170/20000] Loss: 0.0045290 (Best: 0.0037852 @iter1150) ([92m↓2.62%[0m) [1.80% of initial]
[Iter 6560/20000] Loss: 0.0007051 (Best: 0.0004529 @iter5797) ([92m↓10.77%[0m) [0.28% of initial]
[Iter 1180/20000] Loss: 0.0043754 (Best: 0.0037852 @iter1150) ([92m↓3.39%[0m) [1.74% of initial]
[Iter 6570/20000] Loss: 0.0007828 (Best: 0.0004529 @iter5797) ([91m↑11.03%[0m) [0.31% of initial]
[Iter 1190/20000] Loss: 0.0046924 (Best: 0.0036755 @iter1183) ([91m↑7.24%[0m) [1.86% of initial]
[Iter 6580/20000] Loss: 0.0007498 (Best: 0.0004529 @iter5797) ([92m↓4.22%[0m) [0.30% of initial]
Iter:1199, L1 loss=0.003618, Total loss=0.004909, Time:55
[Iter 1200/20000] Loss: 0.0044222 (Best: 0.0035842 @iter1198) ([92m↓5.76%[0m) [1.76% of initial]
[Iter 6590/20000] Loss: 0.0006927 (Best: 0.0004529 @iter5797) ([92m↓7.61%[0m) [0.28% of initial]
[Iter 1210/20000] Loss: 0.0098271 (Best: 0.0035842 @iter1198) ([91m↑122.22%[0m) [3.90% of initial]
Iter:6599, L1 loss=0.0007231, Total loss=0.0007207, Time:87
[Iter 6600/20000] Loss: 0.0007160 (Best: 0.0004529 @iter5797) ([91m↑3.36%[0m) [0.28% of initial]
[Iter 1220/20000] Loss: 0.0066900 (Best: 0.0035842 @iter1198) ([92m↓31.92%[0m) [2.66% of initial]
[Iter 1230/20000] Loss: 0.0055149 (Best: 0.0035842 @iter1198) ([92m↓17.57%[0m) [2.19% of initial]
[Iter 6610/20000] Loss: 0.0012036 (Best: 0.0004529 @iter5797) ([91m↑68.10%[0m) [0.48% of initial]
[Iter 1240/20000] Loss: 0.0051693 (Best: 0.0035842 @iter1198) ([92m↓6.27%[0m) [2.05% of initial]
[Iter 6620/20000] Loss: 0.0009250 (Best: 0.0004529 @iter5797) ([92m↓23.15%[0m) [0.37% of initial]
[Iter 1250/20000] Loss: 0.0044959 (Best: 0.0035842 @iter1198) ([92m↓13.03%[0m) [1.79% of initial]
[Iter 1260/20000] Loss: 0.0045777 (Best: 0.0035842 @iter1198) ([91m↑1.82%[0m) [1.82% of initial]
[Iter 6630/20000] Loss: 0.0008084 (Best: 0.0004529 @iter5797) ([92m↓12.61%[0m) [0.32% of initial]
[Iter 1270/20000] Loss: 0.0045279 (Best: 0.0035842 @iter1198) ([92m↓1.09%[0m) [1.80% of initial]
[Iter 6640/20000] Loss: 0.0007353 (Best: 0.0004529 @iter5797) ([92m↓9.03%[0m) [0.29% of initial]
[Iter 1280/20000] Loss: 0.0044591 (Best: 0.0034796 @iter1276) ([92m↓1.52%[0m) [1.77% of initial]
[Iter 6650/20000] Loss: 0.0007221 (Best: 0.0004529 @iter5797) ([92m↓1.80%[0m) [0.29% of initial]
[Iter 1290/20000] Loss: 0.0043862 (Best: 0.0034796 @iter1276) ([92m↓1.63%[0m) [1.74% of initial]
Iter:1299, L1 loss=0.002832, Total loss=0.00375, Time:65
[Iter 6660/20000] Loss: 0.0007779 (Best: 0.0004529 @iter5797) ([91m↑7.72%[0m) [0.31% of initial]
[Iter 1300/20000] Loss: 0.0040168 (Best: 0.0033754 @iter1291) ([92m↓8.42%[0m) [1.60% of initial]
[Iter 1310/20000] Loss: 0.0039383 (Best: 0.0031796 @iter1306) ([92m↓1.95%[0m) [1.56% of initial]
[Iter 6670/20000] Loss: 0.0007564 (Best: 0.0004529 @iter5797) ([92m↓2.76%[0m) [0.30% of initial]
[Iter 1320/20000] Loss: 0.0038832 (Best: 0.0031796 @iter1306) ([92m↓1.40%[0m) [1.54% of initial]
[Iter 6680/20000] Loss: 0.0007621 (Best: 0.0004529 @iter5797) ([91m↑0.76%[0m) [0.30% of initial]
[Iter 1330/20000] Loss: 0.0037836 (Best: 0.0031796 @iter1306) ([92m↓2.56%[0m) [1.50% of initial]
[Iter 6690/20000] Loss: 0.0007308 (Best: 0.0004529 @iter5797) ([92m↓4.11%[0m) [0.29% of initial]
[Iter 1340/20000] Loss: 0.0040865 (Best: 0.0031796 @iter1306) ([91m↑8.00%[0m) [1.62% of initial]
Iter:6699, L1 loss=0.0007368, Total loss=0.0007036, Time:109
[Iter 1350/20000] Loss: 0.0038794 (Best: 0.0031796 @iter1306) ([92m↓5.07%[0m) [1.54% of initial]
[Iter 6700/20000] Loss: 0.0006866 (Best: 0.0004529 @iter5797) ([92m↓6.05%[0m) [0.27% of initial]
[Iter 1360/20000] Loss: 0.0032074 (Best: 0.0029003 @iter1360) ([92m↓17.32%[0m) [1.27% of initial]
[Iter 6710/20000] Loss: 0.0007366 (Best: 0.0004529 @iter5797) ([91m↑7.28%[0m) [0.29% of initial]
[Iter 1370/20000] Loss: 0.0035133 (Best: 0.0029003 @iter1360) ([91m↑9.54%[0m) [1.40% of initial]
[Iter 6720/20000] Loss: 0.0006935 (Best: 0.0004529 @iter5797) ([92m↓5.85%[0m) [0.28% of initial]
[Iter 1380/20000] Loss: 0.0036631 (Best: 0.0029003 @iter1360) ([91m↑4.26%[0m) [1.46% of initial]
[Iter 1390/20000] Loss: 0.0034563 (Best: 0.0028475 @iter1388) ([92m↓5.65%[0m) [1.37% of initial]
[Iter 6730/20000] Loss: 0.0006476 (Best: 0.0004529 @iter5797) ([92m↓6.62%[0m) [0.26% of initial]
Iter:1399, L1 loss=0.002426, Total loss=0.003224, Time:49
[Iter 1400/20000] Loss: 0.0031030 (Best: 0.0027935 @iter1400) ([92m↓10.22%[0m) [1.23% of initial]
[Iter 6740/20000] Loss: 0.0006865 (Best: 0.0004529 @iter5797) ([91m↑6.00%[0m) [0.27% of initial]
[Iter 1410/20000] Loss: 0.0088910 (Best: 0.0027935 @iter1400) ([91m↑186.53%[0m) [3.53% of initial]
[Iter 6750/20000] Loss: 0.0006898 (Best: 0.0004529 @iter5797) ([91m↑0.48%[0m) [0.27% of initial]
[Iter 1420/20000] Loss: 0.0053468 (Best: 0.0027935 @iter1400) ([92m↓39.86%[0m) [2.12% of initial]
[Iter 6760/20000] Loss: 0.0006673 (Best: 0.0004529 @iter5797) ([92m↓3.26%[0m) [0.27% of initial]
[Iter 1430/20000] Loss: 0.0049269 (Best: 0.0027935 @iter1400) ([92m↓7.85%[0m) [1.96% of initial]
[Iter 6770/20000] Loss: 0.0006654 (Best: 0.0004529 @iter5797) ([92m↓0.29%[0m) [0.26% of initial]
[Iter 1440/20000] Loss: 0.0040996 (Best: 0.0027935 @iter1400) ([92m↓16.79%[0m) [1.63% of initial]
[Iter 6780/20000] Loss: 0.0006286 (Best: 0.0004529 @iter5797) ([92m↓5.54%[0m) [0.25% of initial]
[Iter 1450/20000] Loss: 0.0039433 (Best: 0.0027935 @iter1400) ([92m↓3.81%[0m) [1.57% of initial]
[Iter 1460/20000] Loss: 0.0036988 (Best: 0.0027935 @iter1400) ([92m↓6.20%[0m) [1.47% of initial]
[Iter 6790/20000] Loss: 0.0006824 (Best: 0.0004529 @iter5797) ([91m↑8.57%[0m) [0.27% of initial]
[Iter 1470/20000] Loss: 0.0035621 (Best: 0.0027935 @iter1400) ([92m↓3.70%[0m) [1.42% of initial]
Iter:6799, L1 loss=0.0006435, Total loss=0.0006286, Time:105
[Iter 6800/20000] Loss: 0.0006230 (Best: 0.0004529 @iter5797) ([92m↓8.71%[0m) [0.25% of initial]
[Iter 1480/20000] Loss: 0.0032475 (Best: 0.0027232 @iter1471) ([92m↓8.83%[0m) [1.29% of initial]
[Iter 1490/20000] Loss: 0.0029829 (Best: 0.0025894 @iter1483) ([92m↓8.15%[0m) [1.19% of initial]
[Iter 6810/20000] Loss: 0.0010537 (Best: 0.0004529 @iter5797) ([91m↑69.13%[0m) [0.42% of initial]
Iter:1499, L1 loss=0.002959, Total loss=0.003727, Time:45
[Iter 1500/20000] Loss: 0.0031769 (Best: 0.0025382 @iter1498) ([91m↑6.50%[0m) [1.26% of initial]
[Iter 6820/20000] Loss: 0.0009469 (Best: 0.0004529 @iter5797) ([92m↓10.13%[0m) [0.38% of initial]
[Iter 1510/20000] Loss: 0.0032524 (Best: 0.0025382 @iter1498) ([91m↑2.38%[0m) [1.29% of initial]
[Iter 6830/20000] Loss: 0.0007885 (Best: 0.0004529 @iter5797) ([92m↓16.73%[0m) [0.31% of initial]
[Iter 1520/20000] Loss: 0.0029186 (Best: 0.0025382 @iter1498) ([92m↓10.26%[0m) [1.16% of initial]
[Iter 6840/20000] Loss: 0.0007243 (Best: 0.0004529 @iter5797) ([92m↓8.14%[0m) [0.29% of initial]
[Iter 1530/20000] Loss: 0.0029091 (Best: 0.0025382 @iter1498) ([92m↓0.33%[0m) [1.16% of initial]
[Iter 1540/20000] Loss: 0.0031775 (Best: 0.0024503 @iter1538) ([91m↑9.23%[0m) [1.26% of initial]
[Iter 6850/20000] Loss: 0.0007167 (Best: 0.0004529 @iter5797) ([92m↓1.05%[0m) [0.28% of initial]
[Iter 1550/20000] Loss: 0.0029182 (Best: 0.0023691 @iter1549) ([92m↓8.16%[0m) [1.16% of initial]
[Iter 6860/20000] Loss: 0.0006736 (Best: 0.0004529 @iter5797) ([92m↓6.01%[0m) [0.27% of initial]
[Iter 1560/20000] Loss: 0.0030803 (Best: 0.0023691 @iter1549) ([91m↑5.56%[0m) [1.22% of initial]
[Iter 6870/20000] Loss: 0.0006716 (Best: 0.0004529 @iter5797) ([92m↓0.30%[0m) [0.27% of initial]
[Iter 1570/20000] Loss: 0.0027804 (Best: 0.0023691 @iter1549) ([92m↓9.74%[0m) [1.10% of initial]
[Iter 6880/20000] Loss: 0.0006531 (Best: 0.0004529 @iter5797) ([92m↓2.75%[0m) [0.26% of initial]
[Iter 1580/20000] Loss: 0.0029116 (Best: 0.0023691 @iter1549) ([91m↑4.72%[0m) [1.16% of initial]
[Iter 1590/20000] Loss: 0.0028602 (Best: 0.0022663 @iter1582) ([92m↓1.77%[0m) [1.14% of initial]
[Iter 6890/20000] Loss: 0.0007408 (Best: 0.0004529 @iter5797) ([91m↑13.44%[0m) [0.29% of initial]
Iter:1599, L1 loss=0.002311, Total loss=0.002738, Time:36
[Iter 1600/20000] Loss: 0.0026758 (Best: 0.0022663 @iter1582) ([92m↓6.45%[0m) [1.06% of initial]
Iter:6899, L1 loss=0.0007414, Total loss=0.0007667, Time:112
[Iter 6900/20000] Loss: 0.0007459 (Best: 0.0004529 @iter5797) ([91m↑0.69%[0m) [0.30% of initial]
[Iter 1610/20000] Loss: 0.0077959 (Best: 0.0022663 @iter1582) ([91m↑191.35%[0m) [3.10% of initial]
[Iter 6910/20000] Loss: 0.0007317 (Best: 0.0004529 @iter5797) ([92m↓1.91%[0m) [0.29% of initial]
[Iter 1620/20000] Loss: 0.0056835 (Best: 0.0022663 @iter1582) ([92m↓27.10%[0m) [2.26% of initial]
[Iter 6920/20000] Loss: 0.0006872 (Best: 0.0004529 @iter5797) ([92m↓6.08%[0m) [0.27% of initial]
[Iter 1630/20000] Loss: 0.0043686 (Best: 0.0022663 @iter1582) ([92m↓23.14%[0m) [1.74% of initial]
[Iter 6930/20000] Loss: 0.0006873 (Best: 0.0004529 @iter5797) ([91m↑0.02%[0m) [0.27% of initial]
[Iter 1640/20000] Loss: 0.0034285 (Best: 0.0022663 @iter1582) ([92m↓21.52%[0m) [1.36% of initial]
[Iter 1650/20000] Loss: 0.0030209 (Best: 0.0022663 @iter1582) ([92m↓11.89%[0m) [1.20% of initial]
[Iter 6940/20000] Loss: 0.0006222 (Best: 0.0004529 @iter5797) ([92m↓9.48%[0m) [0.25% of initial]
[Iter 1660/20000] Loss: 0.0028952 (Best: 0.0022663 @iter1582) ([92m↓4.16%[0m) [1.15% of initial]
[Iter 6950/20000] Loss: 0.0006287 (Best: 0.0004529 @iter5797) ([91m↑1.05%[0m) [0.25% of initial]
[Iter 1670/20000] Loss: 0.0024250 (Best: 0.0021908 @iter1669) ([92m↓16.24%[0m) [0.96% of initial]
[Iter 6960/20000] Loss: 0.0006067 (Best: 0.0004529 @iter5797) ([92m↓3.49%[0m) [0.24% of initial]
[Iter 1680/20000] Loss: 0.0025802 (Best: 0.0021908 @iter1669) ([91m↑6.40%[0m) [1.03% of initial]
[Iter 6970/20000] Loss: 0.0006779 (Best: 0.0004529 @iter5797) ([91m↑11.73%[0m) [0.27% of initial]
[Iter 1690/20000] Loss: 0.0026325 (Best: 0.0021908 @iter1669) ([91m↑2.02%[0m) [1.05% of initial]
Iter:1699, L1 loss=0.001971, Total loss=0.002306, Time:33
[Iter 1700/20000] Loss: 0.0026840 (Best: 0.0020382 @iter1693) ([91m↑1.96%[0m) [1.07% of initial]
[Iter 6980/20000] Loss: 0.0006900 (Best: 0.0004529 @iter5797) ([91m↑1.79%[0m) [0.27% of initial]
[Iter 1710/20000] Loss: 0.0025621 (Best: 0.0020374 @iter1705) ([92m↓4.54%[0m) [1.02% of initial]
[Iter 6990/20000] Loss: 0.0006356 (Best: 0.0004529 @iter5797) ([92m↓7.89%[0m) [0.25% of initial]
[Iter 1720/20000] Loss: 0.0025042 (Best: 0.0020374 @iter1705) ([92m↓2.26%[0m) [0.99% of initial]
Iter:6999, L1 loss=0.00076, Total loss=0.0007514, Time:110
[Iter 7000/20000] Loss: 0.0006544 (Best: 0.0004529 @iter5797) ([91m↑2.96%[0m) [0.26% of initial]
[Iter 1730/20000] Loss: 0.0021907 (Best: 0.0018953 @iter1729) ([92m↓12.52%[0m) [0.87% of initial]
Pruning 210 points (0.2%) from gaussian0 at iteration 7000
Pruning 176 points (0.1%) from gaussian1 at iteration 7000
[Iter 1740/20000] Loss: 0.0022314 (Best: 0.0018953 @iter1729) ([91m↑1.86%[0m) [0.89% of initial]
[Iter 7010/20000] Loss: 0.0015515 (Best: 0.0004529 @iter5797) ([91m↑137.08%[0m) [0.62% of initial]
[Iter 1750/20000] Loss: 0.0021590 (Best: 0.0018953 @iter1729) ([92m↓3.24%[0m) [0.86% of initial]
[Iter 1760/20000] Loss: 0.0024598 (Best: 0.0018953 @iter1729) ([91m↑13.93%[0m) [0.98% of initial]
[Iter 7020/20000] Loss: 0.0010753 (Best: 0.0004529 @iter5797) ([92m↓30.69%[0m) [0.43% of initial]
[Iter 1770/20000] Loss: 0.0024533 (Best: 0.0018953 @iter1729) ([92m↓0.27%[0m) [0.97% of initial]
[Iter 7030/20000] Loss: 0.0008319 (Best: 0.0004529 @iter5797) ([92m↓22.64%[0m) [0.33% of initial]
[Iter 1780/20000] Loss: 0.0023637 (Best: 0.0018953 @iter1729) ([92m↓3.65%[0m) [0.94% of initial]
[Iter 7040/20000] Loss: 0.0007166 (Best: 0.0004529 @iter5797) ([92m↓13.86%[0m) [0.28% of initial]
[Iter 1790/20000] Loss: 0.0023073 (Best: 0.0018953 @iter1729) ([92m↓2.39%[0m) [0.92% of initial]
Iter:1799, L1 loss=0.002151, Total loss=0.002381, Time:44
[Iter 7050/20000] Loss: 0.0006998 (Best: 0.0004529 @iter5797) ([92m↓2.35%[0m) [0.28% of initial]
[Iter 1800/20000] Loss: 0.0021604 (Best: 0.0017527 @iter1798) ([92m↓6.37%[0m) [0.86% of initial]
[Iter 7060/20000] Loss: 0.0007065 (Best: 0.0004529 @iter5797) ([91m↑0.97%[0m) [0.28% of initial]
[Iter 1810/20000] Loss: 0.0068374 (Best: 0.0017527 @iter1798) ([91m↑216.49%[0m) [2.72% of initial]
[Iter 1820/20000] Loss: 0.0045158 (Best: 0.0017527 @iter1798) ([92m↓33.95%[0m) [1.79% of initial]
[Iter 7070/20000] Loss: 0.0006476 (Best: 0.0004529 @iter5797) ([92m↓8.34%[0m) [0.26% of initial]
[Iter 1830/20000] Loss: 0.0034179 (Best: 0.0017527 @iter1798) ([92m↓24.31%[0m) [1.36% of initial]
[Iter 7080/20000] Loss: 0.0006573 (Best: 0.0004529 @iter5797) ([91m↑1.49%[0m) [0.26% of initial]
[Iter 1840/20000] Loss: 0.0025375 (Best: 0.0017527 @iter1798) ([92m↓25.76%[0m) [1.01% of initial]
[Iter 7090/20000] Loss: 0.0006811 (Best: 0.0004529 @iter5797) ([91m↑3.62%[0m) [0.27% of initial]
[Iter 1850/20000] Loss: 0.0025931 (Best: 0.0017527 @iter1798) ([91m↑2.19%[0m) [1.03% of initial]
Iter:7099, L1 loss=0.000628, Total loss=0.000621, Time:94
[Iter 7100/20000] Loss: 0.0006424 (Best: 0.0004529 @iter5797) ([92m↓5.67%[0m) [0.26% of initial]
[Iter 1860/20000] Loss: 0.0023562 (Best: 0.0017527 @iter1798) ([92m↓9.14%[0m) [0.94% of initial]
[Iter 1870/20000] Loss: 0.0021932 (Best: 0.0017527 @iter1798) ([92m↓6.92%[0m) [0.87% of initial]
[Iter 7110/20000] Loss: 0.0006650 (Best: 0.0004529 @iter5797) ([91m↑3.51%[0m) [0.26% of initial]
[Iter 1880/20000] Loss: 0.0020953 (Best: 0.0016802 @iter1876) ([92m↓4.46%[0m) [0.83% of initial]
[Iter 7120/20000] Loss: 0.0006281 (Best: 0.0004529 @iter5797) ([92m↓5.54%[0m) [0.25% of initial]
[Iter 1890/20000] Loss: 0.0019721 (Best: 0.0016802 @iter1876) ([92m↓5.88%[0m) [0.78% of initial]
[Iter 7130/20000] Loss: 0.0006221 (Best: 0.0004529 @iter5797) ([92m↓0.96%[0m) [0.25% of initial]
Iter:1899, L1 loss=0.002194, Total loss=0.00236, Time:70
[Iter 1900/20000] Loss: 0.0021992 (Best: 0.0016301 @iter1894) ([91m↑11.51%[0m) [0.87% of initial]
[Iter 7140/20000] Loss: 0.0007006 (Best: 0.0004529 @iter5797) ([91m↑12.62%[0m) [0.28% of initial]
[Iter 1910/20000] Loss: 0.0021666 (Best: 0.0016301 @iter1894) ([92m↓1.48%[0m) [0.86% of initial]
[Iter 1920/20000] Loss: 0.0022123 (Best: 0.0016301 @iter1894) ([91m↑2.11%[0m) [0.88% of initial]
[Iter 7150/20000] Loss: 0.0006553 (Best: 0.0004529 @iter5797) ([92m↓6.47%[0m) [0.26% of initial]
[Iter 1930/20000] Loss: 0.0019374 (Best: 0.0016301 @iter1894) ([92m↓12.42%[0m) [0.77% of initial]
[Iter 7160/20000] Loss: 0.0006551 (Best: 0.0004529 @iter5797) ([92m↓0.03%[0m) [0.26% of initial]
[Iter 1940/20000] Loss: 0.0021507 (Best: 0.0016301 @iter1894) ([91m↑11.01%[0m) [0.85% of initial]
[Iter 7170/20000] Loss: 0.0006553 (Best: 0.0004529 @iter5797) ([91m↑0.03%[0m) [0.26% of initial]
[Iter 1950/20000] Loss: 0.0022598 (Best: 0.0016301 @iter1894) ([91m↑5.07%[0m) [0.90% of initial]
[Iter 7180/20000] Loss: 0.0006623 (Best: 0.0004529 @iter5797) ([91m↑1.07%[0m) [0.26% of initial]
[Iter 1960/20000] Loss: 0.0021469 (Best: 0.0016301 @iter1894) ([92m↓4.99%[0m) [0.85% of initial]
[Iter 1970/20000] Loss: 0.0020396 (Best: 0.0016301 @iter1894) ([92m↓5.00%[0m) [0.81% of initial]
[Iter 7190/20000] Loss: 0.0005951 (Best: 0.0004529 @iter5797) ([92m↓10.14%[0m) [0.24% of initial]
[Iter 1980/20000] Loss: 0.0018907 (Best: 0.0016301 @iter1894) ([92m↓7.30%[0m) [0.75% of initial]
Iter:7199, L1 loss=0.0006414, Total loss=0.0006281, Time:120
[Iter 7200/20000] Loss: 0.0006254 (Best: 0.0004529 @iter5797) ([91m↑5.08%[0m) [0.25% of initial]
[Iter 1990/20000] Loss: 0.0018047 (Best: 0.0015528 @iter1987) ([92m↓4.55%[0m) [0.72% of initial]
Iter:1999, L1 loss=0.001366, Total loss=0.001474, Time:44
[Iter 7210/20000] Loss: 0.0011476 (Best: 0.0004529 @iter5797) ([91m↑83.51%[0m) [0.46% of initial]
[Iter 2000] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2000] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2000/20000] Loss: 0.0018009 (Best: 0.0014738 @iter1999) ([92m↓0.21%[0m) [0.72% of initial]
Testing Speed: 70.81004261462917 fps
Testing Time: 0.7061145305633545 s

[ITER 2000] Evaluating test: SSIM = 0.8449282217025758, PSNR = 17.39425340652466
Testing Speed: 85.91422855543189 fps
Testing Time: 0.03491854667663574 s

[ITER 2000] Evaluating train: SSIM = 0.9999554753303528, PSNR = 49.70533498128255
Iter:2000, total_points:42721
[Iter 2001] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2001] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2002] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7220/20000] Loss: 0.0010826 (Best: 0.0004529 @iter5797) ([92m↓5.67%[0m) [0.43% of initial]
[Iter 2002] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2003] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2003] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2004] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2004] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2005] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2005] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2006] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2006] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2007] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2007] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2008] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2008] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2009] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2009] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2010] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2010] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2010/20000] Loss: 0.1472015 (Best: 0.0014738 @iter1999) ([91m↑8073.86%[0m) [58.48% of initial]
[Iter 2011] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2011] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2012] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2012] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7230/20000] Loss: 0.0008809 (Best: 0.0004529 @iter5797) ([92m↓18.64%[0m) [0.35% of initial]
[Iter 2013] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2013] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2014] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2014] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2015] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2015] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2016] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2016] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2017] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2017] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2018] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2018] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2019] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2019] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2020] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2020] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2020/20000] Loss: 0.0324968 (Best: 0.0014738 @iter1999) ([92m↓77.92%[0m) [12.91% of initial]
[Iter 2021] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2021] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2022] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2022] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7240/20000] Loss: 0.0007216 (Best: 0.0004529 @iter5797) ([92m↓18.07%[0m) [0.29% of initial]
[Iter 2023] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2023] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2024] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2024] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2025] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2025] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2026] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2026] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2027] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2027] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2028] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2028] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2029] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2029] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2030] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2030] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2030/20000] Loss: 0.0127357 (Best: 0.0014738 @iter1999) ([92m↓60.81%[0m) [5.06% of initial]
[Iter 2031] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2031] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2032] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2032] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7250/20000] Loss: 0.0006448 (Best: 0.0004529 @iter5797) ([92m↓10.65%[0m) [0.26% of initial]
[Iter 2033] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2033] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2034] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2034] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2035] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2035] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2036] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2036] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2037] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2037] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2038] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2038] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2039] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2039] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2040] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2040] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2040/20000] Loss: 0.0073429 (Best: 0.0014738 @iter1999) ([92m↓42.34%[0m) [2.92% of initial]
[Iter 2041] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2041] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2042] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2042] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7260/20000] Loss: 0.0006202 (Best: 0.0004529 @iter5797) ([92m↓3.82%[0m) [0.25% of initial]
[Iter 2043] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2043] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2044] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2044] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2045] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2045] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2046] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2046] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2047] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2047] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2048] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2048] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2049] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2049] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2050] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2050] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2050/20000] Loss: 0.0052560 (Best: 0.0014738 @iter1999) ([92m↓28.42%[0m) [2.09% of initial]
[Iter 2051] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2051] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2052] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2052] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7270/20000] Loss: 0.0005815 (Best: 0.0004529 @iter5797) ([92m↓6.23%[0m) [0.23% of initial]
[Iter 2053] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2053] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2054] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2054] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2055] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2055] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2056] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2056] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2057] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2057] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2058] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2058] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2059] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2059] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2060] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2060] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2060/20000] Loss: 0.0045520 (Best: 0.0014738 @iter1999) ([92m↓13.40%[0m) [1.81% of initial]
[Iter 2061] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2061] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2062] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7280/20000] Loss: 0.0005696 (Best: 0.0004529 @iter5797) ([92m↓2.06%[0m) [0.23% of initial]
[Iter 2062] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2063] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2063] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2064] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2064] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2065] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2065] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2066] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2066] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2067] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2067] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2068] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2068] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2069] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2069] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2070] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2070] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2070/20000] Loss: 0.0037540 (Best: 0.0014738 @iter1999) ([92m↓17.53%[0m) [1.49% of initial]
[Iter 2071] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2071] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7290/20000] Loss: 0.0005998 (Best: 0.0004529 @iter5797) ([91m↑5.31%[0m) [0.24% of initial]
[Iter 2072] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2072] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2073] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2073] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2074] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2074] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2075] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2075] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2076] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2076] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2077] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2077] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2078] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2078] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2079] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2079] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2080] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2080] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2080/20000] Loss: 0.0032978 (Best: 0.0014738 @iter1999) ([92m↓12.15%[0m) [1.31% of initial]
Iter:7299, L1 loss=0.0007095, Total loss=0.0006769, Time:88
[Iter 2081] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2081] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7300/20000] Loss: 0.0006065 (Best: 0.0004529 @iter5797) ([91m↑1.11%[0m) [0.24% of initial]
[Iter 2082] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2082] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2083] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2083] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2084] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2084] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2085] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2085] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2086] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2086] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2087] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2087] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2088] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2088] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2089] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2089] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2090] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2090] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2090/20000] Loss: 0.0028990 (Best: 0.0014738 @iter1999) ([92m↓12.09%[0m) [1.15% of initial]
[Iter 2091] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2091] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7310/20000] Loss: 0.0006082 (Best: 0.0004529 @iter5797) ([91m↑0.28%[0m) [0.24% of initial]
[Iter 2092] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2092] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2093] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2093] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2094] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2094] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2095] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2095] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2096] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2096] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2097] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2097] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2098] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2098] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2099] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2099] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2099, L1 loss=0.001961, Total loss=0.002262, Time:80
[Iter 2100] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2100] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2100/20000] Loss: 0.0024375 (Best: 0.0014738 @iter1999) ([92m↓15.92%[0m) [0.97% of initial]
[Iter 2101] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2101] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7320/20000] Loss: 0.0006929 (Best: 0.0004529 @iter5797) ([91m↑13.93%[0m) [0.28% of initial]
[Iter 2102] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2102] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2103] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2103] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2104] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2104] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2105] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2105] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2106] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2106] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2107] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2107] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2108] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2108] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2109] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2109] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2110] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2110] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2110/20000] Loss: 0.0023564 (Best: 0.0014738 @iter1999) ([92m↓3.33%[0m) [0.94% of initial]
[Iter 2111] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2111] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7330/20000] Loss: 0.0006737 (Best: 0.0004529 @iter5797) ([92m↓2.77%[0m) [0.27% of initial]
[Iter 2112] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2112] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2113] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2113] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2114] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2114] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2115] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2115] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2116] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2116] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2117] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2117] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2118] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2118] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2119] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2119] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2120] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2120] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2120/20000] Loss: 0.0021872 (Best: 0.0014738 @iter1999) ([92m↓7.18%[0m) [0.87% of initial]
[Iter 2121] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2121] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7340/20000] Loss: 0.0006221 (Best: 0.0004529 @iter5797) ([92m↓7.66%[0m) [0.25% of initial]
[Iter 2122] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2122] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2123] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2123] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2124] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2124] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2125] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2125] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2126] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2126] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2127] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2127] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2128] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2128] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2129] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2129] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2130] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2130] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2130/20000] Loss: 0.0023136 (Best: 0.0014738 @iter1999) ([91m↑5.78%[0m) [0.92% of initial]
[Iter 2131] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2131] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7350/20000] Loss: 0.0006541 (Best: 0.0004529 @iter5797) ([91m↑5.15%[0m) [0.26% of initial]
[Iter 2132] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2132] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2133] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2133] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2134] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2134] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2135] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2135] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2136] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2136] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2137] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2137] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2138] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2138] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2139] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2139] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2140] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2140] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2140/20000] Loss: 0.0018871 (Best: 0.0014738 @iter1999) ([92m↓18.43%[0m) [0.75% of initial]
[Iter 2141] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2141] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7360/20000] Loss: 0.0006495 (Best: 0.0004529 @iter5797) ([92m↓0.71%[0m) [0.26% of initial]
[Iter 2142] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2142] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2143] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2143] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2144] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2144] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2145] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2145] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2146] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2146] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2147] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2147] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2148] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2148] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2149] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2149] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2150] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2150] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2150/20000] Loss: 0.0023276 (Best: 0.0014738 @iter1999) ([91m↑23.34%[0m) [0.92% of initial]
[Iter 2151] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2151] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7370/20000] Loss: 0.0005960 (Best: 0.0004529 @iter5797) ([92m↓8.23%[0m) [0.24% of initial]
[Iter 2152] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2152] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2153] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2153] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2154] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2154] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2155] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2155] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2156] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2156] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2157] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2157] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2158] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2158] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2159] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2159] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2160] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2160] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2160/20000] Loss: 0.0022684 (Best: 0.0014738 @iter1999) ([92m↓2.55%[0m) [0.90% of initial]
[Iter 2161] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2161] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7380/20000] Loss: 0.0007198 (Best: 0.0004529 @iter5797) ([91m↑20.76%[0m) [0.29% of initial]
[Iter 2162] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2162] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2163] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2163] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2164] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2164] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2165] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2165] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2166] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2166] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2167] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2167] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2168] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2168] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2169] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2169] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2170] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2170] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2170/20000] Loss: 0.0021639 (Best: 0.0014738 @iter1999) ([92m↓4.61%[0m) [0.86% of initial]
[Iter 2171] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2171] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7390/20000] Loss: 0.0007131 (Best: 0.0004529 @iter5797) ([92m↓0.93%[0m) [0.28% of initial]
[Iter 2172] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2172] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2173] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2173] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2174] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2174] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2175] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2175] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2176] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2176] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2177] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2177] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2178] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2178] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2179] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2179] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2180] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2180] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2180/20000] Loss: 0.0016690 (Best: 0.0014648 @iter2180) ([92m↓22.87%[0m) [0.66% of initial]
Iter:7399, L1 loss=0.0007336, Total loss=0.000658, Time:114
[Iter 2181] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2181] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7400/20000] Loss: 0.0007437 (Best: 0.0004529 @iter5797) ([91m↑4.29%[0m) [0.30% of initial]
[Iter 2182] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2182] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2183] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2183] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2184] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2184] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2185] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2185] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2186] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2186] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2187] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2187] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2188] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2188] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2189] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2189] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2190] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2190] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2190/20000] Loss: 0.0019569 (Best: 0.0014648 @iter2180) ([91m↑17.25%[0m) [0.78% of initial]
[Iter 2191] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2191] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2192] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2192] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2193] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2193] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2194] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2194] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7410/20000] Loss: 0.0013093 (Best: 0.0004529 @iter5797) ([91m↑76.05%[0m) [0.52% of initial]
[Iter 2195] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2195] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2196] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2196] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2197] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2197] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2198] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2198] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2199] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2199] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2199, L1 loss=0.001942, Total loss=0.002187, Time:109
[Iter 2200] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2200] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2200/20000] Loss: 0.0021390 (Best: 0.0014648 @iter2180) ([91m↑9.31%[0m) [0.85% of initial]
[Iter 7420/20000] Loss: 0.0009955 (Best: 0.0004529 @iter5797) ([92m↓23.96%[0m) [0.40% of initial]
[Iter 2201] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2201] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2202] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2202] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2203] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2203] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2204] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2204] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2205] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2205] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2206] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2206] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2207] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2207] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2208] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2208] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2209] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2209] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2210] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2210] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2210/20000] Loss: 0.0071244 (Best: 0.0014648 @iter2180) ([91m↑233.07%[0m) [2.83% of initial]
[Iter 7430/20000] Loss: 0.0008255 (Best: 0.0004529 @iter5797) ([92m↓17.07%[0m) [0.33% of initial]
[Iter 2211] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2211] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2212] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2212] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2213] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2213] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2214] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2214] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2215] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2215] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2216] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2216] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2217] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2217] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2218] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2218] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2219] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2219] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2220] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2220] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7440/20000] Loss: 0.0007475 (Best: 0.0004529 @iter5797) ([92m↓9.45%[0m) [0.30% of initial]
[Iter 2220/20000] Loss: 0.0041495 (Best: 0.0014648 @iter2180) ([92m↓41.76%[0m) [1.65% of initial]
[Iter 2221] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2221] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2222] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2222] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2223] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2223] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2224] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2224] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2225] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2225] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2226] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2226] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2227] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2227] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2228] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2228] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2229] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2229] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7450/20000] Loss: 0.0006740 (Best: 0.0004529 @iter5797) ([92m↓9.83%[0m) [0.27% of initial]
[Iter 2230] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2230] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2230/20000] Loss: 0.0027026 (Best: 0.0014648 @iter2180) ([92m↓34.87%[0m) [1.07% of initial]
[Iter 2231] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2231] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2232] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2232] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2233] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2233] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2234] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2234] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2235] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2235] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2236] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2236] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2237] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2237] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2238] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2238] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2239] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2239] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7460/20000] Loss: 0.0006576 (Best: 0.0004529 @iter5797) ([92m↓2.44%[0m) [0.26% of initial]
[Iter 2240] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2240] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2240/20000] Loss: 0.0025612 (Best: 0.0014648 @iter2180) ([92m↓5.23%[0m) [1.02% of initial]
[Iter 2241] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2241] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2242] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2242] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2243] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2243] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2244] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2244] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2245] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2245] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2246] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2246] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2247] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2247] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2248] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2248] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2249] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2249] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7470/20000] Loss: 0.0006208 (Best: 0.0004529 @iter5797) ([92m↓5.59%[0m) [0.25% of initial]
[Iter 2250] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2250] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2250/20000] Loss: 0.0021013 (Best: 0.0014648 @iter2180) ([92m↓17.96%[0m) [0.83% of initial]
[Iter 2251] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2251] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2252] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2252] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2253] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2253] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2254] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2254] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2255] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2255] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2256] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2256] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2257] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2257] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2258] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2258] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2259] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2259] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7480/20000] Loss: 0.0005974 (Best: 0.0004529 @iter5797) ([92m↓3.77%[0m) [0.24% of initial]
[Iter 2260] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2260] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2260/20000] Loss: 0.0020596 (Best: 0.0014648 @iter2180) ([92m↓1.98%[0m) [0.82% of initial]
[Iter 2261] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2261] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2262] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2262] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2263] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2263] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2264] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2264] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2265] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2265] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2266] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2266] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2267] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2267] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2268] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2268] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2269] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2269] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7490/20000] Loss: 0.0005530 (Best: 0.0004529 @iter5797) ([92m↓7.43%[0m) [0.22% of initial]
[Iter 2270] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2270] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2270/20000] Loss: 0.0019077 (Best: 0.0014648 @iter2180) ([92m↓7.37%[0m) [0.76% of initial]
[Iter 2271] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2271] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2272] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2272] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2273] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2273] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2274] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2274] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2275] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2275] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2276] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2276] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2277] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2277] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2278] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2278] Co-reg loss between gs1 and gs0: 0.0000000
Iter:7499, L1 loss=0.0006114, Total loss=0.0005586, Time:100
[Iter 2279] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2279] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7500/20000] Loss: 0.0005902 (Best: 0.0004529 @iter5797) ([91m↑6.72%[0m) [0.23% of initial]
[Iter 2280] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2280] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2280/20000] Loss: 0.0017417 (Best: 0.0014648 @iter2180) ([92m↓8.70%[0m) [0.69% of initial]
[Iter 2281] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2281] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2282] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2282] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2283] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2283] Co-reg loss between gs1 and gs0: 0.0000000
Pruning 218 points (0.2%) from gaussian0 at iteration 7500
[Iter 2284] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2284] Co-reg loss between gs1 and gs0: 0.0000000
Pruning 102 points (0.1%) from gaussian1 at iteration 7500
[Iter 2285] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2285] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2286] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2286] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2287] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2287] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2288] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2288] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2289] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2289] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2290] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2290] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2290/20000] Loss: 0.0015507 (Best: 0.0013648 @iter2290) ([92m↓10.97%[0m) [0.62% of initial]
[Iter 2291] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2291] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2292] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2292] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2293] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2293] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2294] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2294] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7510/20000] Loss: 0.0013635 (Best: 0.0004529 @iter5797) ([91m↑131.02%[0m) [0.54% of initial]
[Iter 2295] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2295] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2296] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2296] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2297] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2297] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2298] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2298] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2299] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2299] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2299, L1 loss=0.001282, Total loss=0.001364, Time:103
[Iter 2300] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2300] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2300/20000] Loss: 0.0015681 (Best: 0.0013554 @iter2296) ([91m↑1.12%[0m) [0.62% of initial]
[Iter 2301] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2301] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2302] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2302] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2303] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2303] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2304] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2304] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7520/20000] Loss: 0.0009184 (Best: 0.0004529 @iter5797) ([92m↓32.64%[0m) [0.36% of initial]
[Iter 2305] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2305] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2306] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2306] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2307] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2307] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2308] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2308] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2309] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2309] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2310] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2310] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2310/20000] Loss: 0.0014494 (Best: 0.0013377 @iter2309) ([92m↓7.57%[0m) [0.58% of initial]
[Iter 2311] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2311] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2312] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2312] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2313] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2313] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7530/20000] Loss: 0.0007350 (Best: 0.0004529 @iter5797) ([92m↓19.97%[0m) [0.29% of initial]
[Iter 2314] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2314] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2315] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2315] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2316] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2316] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2317] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2317] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2318] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2318] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2319] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2319] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2320] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2320] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2320/20000] Loss: 0.0013097 (Best: 0.0011636 @iter2320) ([92m↓9.64%[0m) [0.52% of initial]
[Iter 2321] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2321] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2322] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2322] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2323] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2323] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7540/20000] Loss: 0.0005783 (Best: 0.0004529 @iter5797) ([92m↓21.31%[0m) [0.23% of initial]
[Iter 2324] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2324] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2325] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2325] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2326] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2326] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2327] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2327] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2328] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2328] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2329] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2329] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2330] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2330] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2330/20000] Loss: 0.0016136 (Best: 0.0011636 @iter2320) ([91m↑23.21%[0m) [0.64% of initial]
[Iter 2331] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2331] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2332] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2332] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2333] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2333] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7550/20000] Loss: 0.0005644 (Best: 0.0004529 @iter5797) ([92m↓2.41%[0m) [0.22% of initial]
[Iter 2334] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2334] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2335] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2335] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2336] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2336] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2337] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2337] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2338] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2338] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2339] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2339] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2340] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2340] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2340/20000] Loss: 0.0016599 (Best: 0.0011636 @iter2320) ([91m↑2.87%[0m) [0.66% of initial]
[Iter 2341] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2341] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2342] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2342] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2343] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2343] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7560/20000] Loss: 0.0005537 (Best: 0.0004529 @iter5797) ([92m↓1.89%[0m) [0.22% of initial]
[Iter 2344] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2344] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2345] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2345] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2346] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2346] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2347] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2347] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2348] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2348] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2349] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2349] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2350] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2350] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2350/20000] Loss: 0.0020770 (Best: 0.0011636 @iter2320) ([91m↑25.13%[0m) [0.83% of initial]
[Iter 2351] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2351] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2352] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2352] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7570/20000] Loss: 0.0005689 (Best: 0.0004529 @iter5797) ([91m↑2.75%[0m) [0.23% of initial]
[Iter 2353] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2353] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2354] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2354] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2355] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2355] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2356] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2356] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2357] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2357] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2358] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2358] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2359] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2359] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2360] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2360] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2360/20000] Loss: 0.0015465 (Best: 0.0011636 @iter2320) ([92m↓25.54%[0m) [0.61% of initial]
[Iter 2361] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2361] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2362] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2362] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7580/20000] Loss: 0.0005783 (Best: 0.0004529 @iter5797) ([91m↑1.66%[0m) [0.23% of initial]
[Iter 2363] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2363] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2364] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2364] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2365] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2365] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2366] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2366] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2367] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2367] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2368] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2368] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2369] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2369] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2370] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2370] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2370/20000] Loss: 0.0014908 (Best: 0.0011636 @iter2320) ([92m↓3.61%[0m) [0.59% of initial]
[Iter 2371] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2371] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2372] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2372] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7590/20000] Loss: 0.0005966 (Best: 0.0004529 @iter5797) ([91m↑3.16%[0m) [0.24% of initial]
[Iter 2373] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2373] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2374] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2374] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2375] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2375] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2376] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2376] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2377] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2377] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2378] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2378] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2379] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2379] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2380] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2380] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2380/20000] Loss: 0.0015509 (Best: 0.0011636 @iter2320) ([91m↑4.03%[0m) [0.62% of initial]
[Iter 2381] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2381] Co-reg loss between gs1 and gs0: 0.0000000
Iter:7599, L1 loss=0.0005857, Total loss=0.0005291, Time:94
[Iter 2382] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2382] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7600/20000] Loss: 0.0005501 (Best: 0.0004529 @iter5797) ([92m↓7.80%[0m) [0.22% of initial]
[Iter 2383] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2383] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2384] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2384] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2385] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2385] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2386] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2386] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2387] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2387] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2388] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2388] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2389] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2389] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2390] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2390] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2390/20000] Loss: 0.0014760 (Best: 0.0011501 @iter2386) ([92m↓4.82%[0m) [0.59% of initial]
[Iter 2391] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2391] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2392] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2392] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2393] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2393] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2394] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2394] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2395] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2395] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7610/20000] Loss: 0.0012389 (Best: 0.0004529 @iter5797) ([91m↑125.23%[0m) [0.49% of initial]
[Iter 2396] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2396] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2397] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2397] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2398] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2398] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2399] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2399] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2399, L1 loss=0.001573, Total loss=0.001639, Time:106
[Iter 2400] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2400] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2400/20000] Loss: 0.0014561 (Best: 0.0011501 @iter2386) ([92m↓1.35%[0m) [0.58% of initial]
[Iter 2401] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2401] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7620/20000] Loss: 0.0009195 (Best: 0.0004529 @iter5797) ([92m↓25.78%[0m) [0.37% of initial]
[Iter 2402] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2402] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2403] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2403] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2404] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2404] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2405] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2405] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2406] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2406] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2407] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2407] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2408] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2408] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2409] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2409] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2410] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2410] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2410/20000] Loss: 0.0054926 (Best: 0.0011501 @iter2386) ([91m↑277.23%[0m) [2.18% of initial]
[Iter 7630/20000] Loss: 0.0007963 (Best: 0.0004529 @iter5797) ([92m↓13.40%[0m) [0.32% of initial]
[Iter 2411] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2411] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2412] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2412] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2413] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2413] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2414] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2414] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2415] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2415] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2416] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2416] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2417] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2417] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2418] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2418] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2419] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2419] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2420] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2420] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2420/20000] Loss: 0.0032021 (Best: 0.0011501 @iter2386) ([92m↓41.70%[0m) [1.27% of initial]
[Iter 7640/20000] Loss: 0.0006714 (Best: 0.0004529 @iter5797) ([92m↓15.69%[0m) [0.27% of initial]
[Iter 2421] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2421] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2422] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2422] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2423] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2423] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2424] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2424] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2425] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2425] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2426] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2426] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2427] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2427] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2428] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2428] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2429] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2429] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7650/20000] Loss: 0.0006146 (Best: 0.0004529 @iter5797) ([92m↓8.46%[0m) [0.24% of initial]
[Iter 2430] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2430] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2430/20000] Loss: 0.0024763 (Best: 0.0011501 @iter2386) ([92m↓22.67%[0m) [0.98% of initial]
[Iter 2431] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2431] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2432] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2432] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2433] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2433] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2434] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2434] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2435] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2435] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2436] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2436] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2437] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2437] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2438] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2438] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2439] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2439] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7660/20000] Loss: 0.0005361 (Best: 0.0004529 @iter5797) ([92m↓12.77%[0m) [0.21% of initial]
[Iter 2440] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2440] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2440/20000] Loss: 0.0020625 (Best: 0.0011501 @iter2386) ([92m↓16.71%[0m) [0.82% of initial]
[Iter 2441] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2441] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2442] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2442] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2443] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2443] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2444] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2444] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2445] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2445] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2446] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2446] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2447] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2447] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2448] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2448] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2449] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7670/20000] Loss: 0.0005179 (Best: 0.0004529 @iter5797) ([92m↓3.39%[0m) [0.21% of initial]
[Iter 2449] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2450] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2450] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2450/20000] Loss: 0.0020944 (Best: 0.0011501 @iter2386) ([91m↑1.54%[0m) [0.83% of initial]
[Iter 2451] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2451] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2452] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2452] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2453] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2453] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2454] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2454] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2455] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2455] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2456] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2456] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2457] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2457] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2458] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2458] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7680/20000] Loss: 0.0005563 (Best: 0.0004529 @iter5797) ([91m↑7.41%[0m) [0.22% of initial]
[Iter 2459] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2459] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2460] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2460] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2460/20000] Loss: 0.0019475 (Best: 0.0011501 @iter2386) ([92m↓7.01%[0m) [0.77% of initial]
[Iter 2461] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2461] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2462] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2462] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2463] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2463] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2464] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2464] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2465] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2465] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2466] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2466] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2467] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2467] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2468] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7690/20000] Loss: 0.0005185 (Best: 0.0004529 @iter5797) ([92m↓6.80%[0m) [0.21% of initial]
[Iter 2468] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2469] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2469] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2470] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2470] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2470/20000] Loss: 0.0017430 (Best: 0.0011501 @iter2386) ([92m↓10.50%[0m) [0.69% of initial]
[Iter 2471] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2471] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2472] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2472] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2473] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2473] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2474] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2474] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2475] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2475] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2476] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2476] Co-reg loss between gs1 and gs0: 0.0000000
Iter:7699, L1 loss=0.0005405, Total loss=0.0005122, Time:61
[Iter 2477] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2477] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7700/20000] Loss: 0.0005231 (Best: 0.0004529 @iter5797) ([91m↑0.88%[0m) [0.21% of initial]
[Iter 2478] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2478] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2479] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2479] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2480] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2480] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2480/20000] Loss: 0.0014476 (Best: 0.0011501 @iter2386) ([92m↓16.94%[0m) [0.58% of initial]
[Iter 2481] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2481] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2482] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2482] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2483] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2483] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2484] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2484] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2485] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2485] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2486] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2486] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2487] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2487] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7710/20000] Loss: 0.0005016 (Best: 0.0004529 @iter5797) ([92m↓4.10%[0m) [0.20% of initial]
[Iter 2488] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2488] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2489] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2489] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2490] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2490] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2490/20000] Loss: 0.0014799 (Best: 0.0011472 @iter2488) ([91m↑2.23%[0m) [0.59% of initial]
[Iter 2491] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2491] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2492] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2492] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2493] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2493] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2494] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2494] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2495] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2495] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2496] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2496] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7720/20000] Loss: 0.0005065 (Best: 0.0004459 @iter7714) ([91m↑0.98%[0m) [0.20% of initial]
[Iter 2497] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2497] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2498] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2498] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2499] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2499] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2499, L1 loss=0.001178, Total loss=0.001204, Time:96
[Iter 2500] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2500] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2500/20000] Loss: 0.0014156 (Best: 0.0011472 @iter2488) ([92m↓4.35%[0m) [0.56% of initial]
[Iter 2501] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2501] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2502] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2502] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2503] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2503] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2504] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2504] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2505] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2505] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2506] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2506] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7730/20000] Loss: 0.0005111 (Best: 0.0004459 @iter7714) ([91m↑0.91%[0m) [0.20% of initial]
[Iter 2507] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2507] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2508] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2508] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2509] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2509] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2510] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2510] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2510/20000] Loss: 0.0013068 (Best: 0.0010299 @iter2506) ([92m↓7.69%[0m) [0.52% of initial]
[Iter 2511] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2511] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2512] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2512] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2513] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2513] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2514] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2514] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2515] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2515] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2516] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2516] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7740/20000] Loss: 0.0005166 (Best: 0.0004459 @iter7714) ([91m↑1.08%[0m) [0.21% of initial]
[Iter 2517] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2517] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2518] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2518] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2519] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2519] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2520] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2520] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2520/20000] Loss: 0.0012783 (Best: 0.0010299 @iter2506) ([92m↓2.18%[0m) [0.51% of initial]
[Iter 2521] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2521] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2522] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2522] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2523] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2523] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2524] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2524] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2525] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2525] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7750/20000] Loss: 0.0005559 (Best: 0.0004459 @iter7714) ([91m↑7.61%[0m) [0.22% of initial]
[Iter 2526] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2526] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2527] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2527] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2528] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2528] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2529] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2529] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2530] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2530] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2530/20000] Loss: 0.0012043 (Best: 0.0009552 @iter2527) ([92m↓5.79%[0m) [0.48% of initial]
[Iter 2531] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2531] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2532] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2532] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2533] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2533] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2534] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2534] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2535] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2535] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7760/20000] Loss: 0.0005902 (Best: 0.0004459 @iter7714) ([91m↑6.16%[0m) [0.23% of initial]
[Iter 2536] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2536] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2537] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2537] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2538] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2538] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2539] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2539] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2540] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2540] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2540/20000] Loss: 0.0012147 (Best: 0.0009418 @iter2539) ([91m↑0.87%[0m) [0.48% of initial]
[Iter 2541] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2541] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2542] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2542] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2543] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2543] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2544] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2544] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2545] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2545] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7770/20000] Loss: 0.0005709 (Best: 0.0004459 @iter7714) ([92m↓3.27%[0m) [0.23% of initial]
[Iter 2546] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2546] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2547] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2547] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2548] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2548] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2549] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2549] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2550] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2550] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2550/20000] Loss: 0.0011325 (Best: 0.0009418 @iter2539) ([92m↓6.77%[0m) [0.45% of initial]
[Iter 2551] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2551] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2552] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2552] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2553] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2553] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2554] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2554] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2555] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2555] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7780/20000] Loss: 0.0005654 (Best: 0.0004459 @iter7714) ([92m↓0.96%[0m) [0.22% of initial]
[Iter 2556] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2556] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2557] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2557] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2558] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2558] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2559] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2559] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2560] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2560] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2560/20000] Loss: 0.0011874 (Best: 0.0009119 @iter2551) ([91m↑4.84%[0m) [0.47% of initial]
[Iter 2561] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2561] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2562] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2562] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2563] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2563] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2564] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2564] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7790/20000] Loss: 0.0005690 (Best: 0.0004459 @iter7714) ([91m↑0.64%[0m) [0.23% of initial]
[Iter 2565] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2565] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2566] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2566] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2567] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2567] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2568] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2568] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2569] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2569] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2570] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2570] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2570/20000] Loss: 0.0010413 (Best: 0.0009119 @iter2551) ([92m↓12.30%[0m) [0.41% of initial]
[Iter 2571] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2571] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2572] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2572] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2573] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2573] Co-reg loss between gs1 and gs0: 0.0000000
Iter:7799, L1 loss=0.0005487, Total loss=0.0005246, Time:104
[Iter 2574] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2574] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7800/20000] Loss: 0.0005743 (Best: 0.0004459 @iter7714) ([91m↑0.93%[0m) [0.23% of initial]
[Iter 2575] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2575] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2576] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2576] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2577] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2577] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2578] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2578] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2579] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2579] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2580] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2580] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2580/20000] Loss: 0.0011750 (Best: 0.0009119 @iter2551) ([91m↑12.84%[0m) [0.47% of initial]
[Iter 2581] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2581] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2582] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2582] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2583] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2583] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2584] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2584] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2585] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2585] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2586] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2586] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2587] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2587] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2588] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7810/20000] Loss: 0.0011065 (Best: 0.0004459 @iter7714) ([91m↑92.66%[0m) [0.44% of initial]
[Iter 2588] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2589] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2589] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2590] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2590] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2590/20000] Loss: 0.0010668 (Best: 0.0009119 @iter2551) ([92m↓9.21%[0m) [0.42% of initial]
[Iter 2591] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2591] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2592] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2592] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2593] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2593] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2594] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2594] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2595] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2595] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2596] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2596] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2597] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2597] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7820/20000] Loss: 0.0008887 (Best: 0.0004459 @iter7714) ([92m↓19.68%[0m) [0.35% of initial]
[Iter 2598] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2598] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2599] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2599] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2599, L1 loss=0.0008924, Total loss=0.000907, Time:106
[Iter 2600] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2600] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2600/20000] Loss: 0.0011330 (Best: 0.0009070 @iter2599) ([91m↑6.21%[0m) [0.45% of initial]
[Iter 2601] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2601] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2602] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2602] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7830/20000] Loss: 0.0007679 (Best: 0.0004459 @iter7714) ([92m↓13.60%[0m) [0.31% of initial]
[Iter 2603] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2603] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2604] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2604] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2605] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2605] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2606] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2606] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2607] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2607] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2608] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2608] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2609] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2609] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2610] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2610] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2610/20000] Loss: 0.0053582 (Best: 0.0009070 @iter2599) ([91m↑372.93%[0m) [2.13% of initial]
[Iter 2611] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2611] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2612] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2612] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7840/20000] Loss: 0.0006695 (Best: 0.0004459 @iter7714) ([92m↓12.82%[0m) [0.27% of initial]
[Iter 2613] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2613] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2614] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2614] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2615] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2615] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2616] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2616] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2617] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2617] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2618] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2618] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2619] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2619] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2620] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2620] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2620/20000] Loss: 0.0034049 (Best: 0.0009070 @iter2599) ([92m↓36.46%[0m) [1.35% of initial]
[Iter 2621] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2621] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7850/20000] Loss: 0.0006424 (Best: 0.0004459 @iter7714) ([92m↓4.04%[0m) [0.26% of initial]
[Iter 2622] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2622] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2623] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2623] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2624] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2624] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2625] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2625] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2626] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2626] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2627] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2627] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2628] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2628] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2629] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2629] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2630] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2630] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7860/20000] Loss: 0.0006394 (Best: 0.0004459 @iter7714) ([92m↓0.47%[0m) [0.25% of initial]
[Iter 2630/20000] Loss: 0.0022462 (Best: 0.0009070 @iter2599) ([92m↓34.03%[0m) [0.89% of initial]
[Iter 2631] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2631] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2632] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2632] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2633] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2633] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2634] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2634] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2635] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2635] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2636] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2636] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2637] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2637] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2638] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2638] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2639] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2639] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7870/20000] Loss: 0.0006029 (Best: 0.0004459 @iter7714) ([92m↓5.71%[0m) [0.24% of initial]
[Iter 2640] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2640] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2640/20000] Loss: 0.0017349 (Best: 0.0009070 @iter2599) ([92m↓22.76%[0m) [0.69% of initial]
[Iter 2641] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2641] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2642] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2642] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2643] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2643] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2644] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2644] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2645] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2645] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2646] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2646] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2647] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2647] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2648] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2648] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7880/20000] Loss: 0.0005539 (Best: 0.0004459 @iter7714) ([92m↓8.12%[0m) [0.22% of initial]
[Iter 2649] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2649] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2650] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2650] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2650/20000] Loss: 0.0015029 (Best: 0.0009070 @iter2599) ([92m↓13.37%[0m) [0.60% of initial]
[Iter 2651] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2651] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2652] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2652] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2653] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2653] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2654] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2654] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2655] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2655] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2656] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2656] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2657] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2657] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7890/20000] Loss: 0.0006196 (Best: 0.0004459 @iter7714) ([91m↑11.86%[0m) [0.25% of initial]
[Iter 2658] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2658] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2659] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2659] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2660] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2660] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2660/20000] Loss: 0.0014771 (Best: 0.0009070 @iter2599) ([92m↓1.72%[0m) [0.59% of initial]
[Iter 2661] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2661] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2662] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2662] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2663] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2663] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2664] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2664] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2665] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2665] Co-reg loss between gs1 and gs0: 0.0000000
Iter:7899, L1 loss=0.0006326, Total loss=0.0005775, Time:67
[Iter 2666] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2666] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7900/20000] Loss: 0.0005611 (Best: 0.0004459 @iter7714) ([92m↓9.44%[0m) [0.22% of initial]
[Iter 2667] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2667] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2668] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2668] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2669] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2669] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2670] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2670] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2670/20000] Loss: 0.0013161 (Best: 0.0009070 @iter2599) ([92m↓10.90%[0m) [0.52% of initial]
[Iter 2671] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2671] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2672] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2672] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2673] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2673] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2674] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2674] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2675] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2675] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7910/20000] Loss: 0.0005702 (Best: 0.0004459 @iter7714) ([91m↑1.62%[0m) [0.23% of initial]
[Iter 2676] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2676] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2677] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2677] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2678] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2678] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2679] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2679] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2680] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2680] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2680/20000] Loss: 0.0013495 (Best: 0.0009070 @iter2599) ([91m↑2.54%[0m) [0.54% of initial]
[Iter 2681] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2681] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2682] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2682] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2683] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2683] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2684] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2684] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2685] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 7920/20000] Loss: 0.0006401 (Best: 0.0004459 @iter7714) ([91m↑12.27%[0m) [0.25% of initial]
[Iter 2685] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2686] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2686] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2687] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2687] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2688] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2688] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2689] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2689] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2690] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2690] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2690/20000] Loss: 0.0012683 (Best: 0.0009070 @iter2599) ([92m↓6.02%[0m) [0.50% of initial]
[Iter 2691] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2691] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2692] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2692] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2693] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2693] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2694] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2694] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7930/20000] Loss: 0.0005630 (Best: 0.0004459 @iter7714) ([92m↓12.05%[0m) [0.22% of initial]
[Iter 2695] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2695] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2696] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2696] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2697] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2697] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2698] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2698] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2699] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2699] Co-reg loss between gs1 and gs0: 0.0000000
Iter:2699, L1 loss=0.001021, Total loss=0.0009959, Time:75
[Iter 2700] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2700] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2700/20000] Loss: 0.0012160 (Best: 0.0009070 @iter2599) ([92m↓4.12%[0m) [0.48% of initial]
[Iter 2701] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2701] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2702] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2702] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2703] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2703] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7940/20000] Loss: 0.0005303 (Best: 0.0004459 @iter7714) ([92m↓5.80%[0m) [0.21% of initial]
[Iter 2704] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2704] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2705] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2705] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2706] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2706] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2707] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2707] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2708] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2708] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2709] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2709] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2710] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2710] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2710/20000] Loss: 0.0012570 (Best: 0.0009070 @iter2599) ([91m↑3.37%[0m) [0.50% of initial]
[Iter 2711] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2711] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2712] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2712] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7950/20000] Loss: 0.0005202 (Best: 0.0004459 @iter7714) ([92m↓1.91%[0m) [0.21% of initial]
[Iter 2713] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2713] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2714] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2714] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2715] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2715] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2716] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2716] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2717] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2717] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2718] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2718] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2719] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2719] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2720] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2720] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2720/20000] Loss: 0.0011090 (Best: 0.0009070 @iter2599) ([92m↓11.78%[0m) [0.44% of initial]
[Iter 2721] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2721] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7960/20000] Loss: 0.0005864 (Best: 0.0004459 @iter7714) ([91m↑12.74%[0m) [0.23% of initial]
[Iter 2722] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2722] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2723] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2723] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2724] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2724] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2725] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2725] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2726] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2726] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2727] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2727] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2728] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2728] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2729] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2729] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2730] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2730] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2730/20000] Loss: 0.0012242 (Best: 0.0008879 @iter2722) ([91m↑10.39%[0m) [0.49% of initial]
[Iter 7970/20000] Loss: 0.0005809 (Best: 0.0004459 @iter7714) ([92m↓0.94%[0m) [0.23% of initial]
[Iter 2731] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2731] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2732] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2732] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2733] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2733] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2734] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2734] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2735] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2735] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2736] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2736] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2737] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2737] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2738] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2738] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2739] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2739] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7980/20000] Loss: 0.0006101 (Best: 0.0004459 @iter7714) ([91m↑5.03%[0m) [0.24% of initial]
[Iter 2740] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2740] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2740/20000] Loss: 0.0012773 (Best: 0.0008879 @iter2722) ([91m↑4.33%[0m) [0.51% of initial]
[Iter 2741] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2741] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2742] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2742] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2743] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2743] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2744] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2744] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2745] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2745] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2746] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2746] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2747] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2747] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2748] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2748] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2749] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2749] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 7990/20000] Loss: 0.0005569 (Best: 0.0004459 @iter7714) ([92m↓8.72%[0m) [0.22% of initial]
[Iter 2750] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2750] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2750/20000] Loss: 0.0011640 (Best: 0.0008879 @iter2722) ([92m↓8.87%[0m) [0.46% of initial]
[Iter 2751] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2751] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2752] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2752] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2753] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2753] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2754] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2754] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2755] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2755] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2756] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2756] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2757] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2757] Co-reg loss between gs1 and gs0: 0.0000000
Iter:7999, L1 loss=0.0005575, Total loss=0.0005346, Time:102
[Iter 2758] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2758] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 8000/20000] Loss: 0.0005321 (Best: 0.0004459 @iter7714) ([92m↓4.46%[0m) [0.21% of initial]
[Iter 2759] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2759] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2760] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2760] Co-reg loss between gs1 and gs0: 0.0000000
[Iter 2760/20000] Loss: 0.0014048 (Best: 0.0008879 @iter2722) ([91m↑20.69%[0m) [0.56% of initial]
[Iter 2761] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2761] Co-reg loss between gs1 and gs0: 0.0000000
Pruning 330 points (0.3%) from gaussian0 at iteration 8000
[Iter 2762] Co-reg loss between gs0 and gs1: 0.0000000
[Iter 2762] Co-reg loss between gs1 and gs0: 0.0000000
Pruning 122 points (0.1%) from gaussian1 at iteration 8000
