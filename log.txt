Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Iter:99, L1 loss=0.05724, Total loss=0.07876, Time:14
Iter:199, L1 loss=0.0344, Total loss=0.04979, Time:13
Iter:299, L1 loss=0.02211, Total loss=0.03344, Time:13
Iter:399, L1 loss=0.01344, Total loss=0.02137, Time:8
Iter:499, L1 loss=0.008442, Total loss=0.01517, Time:13
Iter:599, L1 loss=0.006814, Total loss=0.0118, Time:9
Iter:699, L1 loss=0.005665, Total loss=0.009678, Time:9
Iter:799, L1 loss=0.005006, Total loss=0.008088, Time:13
Iter:899, L1 loss=0.003726, Total loss=0.005711, Time:13
Iter:999, L1 loss=0.00447, Total loss=0.006746, Time:12
Iter:1099, L1 loss=0.003391, Total loss=0.005109, Time:11
Iter:1199, L1 loss=0.003447, Total loss=0.004956, Time:13
Iter:1299, L1 loss=0.002725, Total loss=0.003588, Time:11
Iter:1399, L1 loss=0.002296, Total loss=0.002899, Time:13
Iter:1499, L1 loss=0.002552, Total loss=0.003298, Time:14
Iter:1599, L1 loss=0.002679, Total loss=0.003367, Time:11
Iter:1699, L1 loss=0.002572, Total loss=0.003219, Time:11
Iter:1799, L1 loss=0.001685, Total loss=0.001878, Time:15
Iter:1899, L1 loss=0.001719, Total loss=0.001961, Time:15
Iter:1999, L1 loss=0.001495, Total loss=0.001825, Time:14
Testing Speed: 232.60337178349602 fps
Testing Time: 0.21495819091796875 s

[ITER 2000] Evaluating test: SSIM = 0.8523035597801208, PSNR = 17.89594018936157
Testing Speed: 264.4691243852201 fps
Testing Time: 0.01134347915649414 s

[ITER 2000] Evaluating train: SSIM = 0.9999495546023051, PSNR = 48.407441457112625
Iter:2000, total_points:42307
Iter:2099, L1 loss=0.001586, Total loss=0.00167, Time:13
Iter:2199, L1 loss=0.001425, Total loss=0.001538, Time:15
Iter:2299, L1 loss=0.001361, Total loss=0.001513, Time:16
Iter:2399, L1 loss=0.00122, Total loss=0.001268, Time:13
Iter:2499, L1 loss=0.001178, Total loss=0.001229, Time:16
Iter:2599, L1 loss=0.001003, Total loss=0.00103, Time:15
Iter:2699, L1 loss=0.001149, Total loss=0.001179, Time:14
Iter:2799, L1 loss=0.001243, Total loss=0.001256, Time:16
Iter:2899, L1 loss=0.0008724, Total loss=0.0008436, Time:16
Iter:2999, L1 loss=0.0007018, Total loss=0.0006691, Time:17
Iter:3099, L1 loss=0.0008893, Total loss=0.0008751, Time:15
Iter:3199, L1 loss=0.0007627, Total loss=0.0007432, Time:15
Iter:3299, L1 loss=0.001269, Total loss=0.001258, Time:18
Iter:3399, L1 loss=0.00118, Total loss=0.001247, Time:18
Iter:3499, L1 loss=0.0006467, Total loss=0.00062, Time:19
Iter:3599, L1 loss=0.0006355, Total loss=0.0005817, Time:19
Iter:3699, L1 loss=0.001023, Total loss=0.000943, Time:18
Iter:3799, L1 loss=0.0007808, Total loss=0.0007401, Time:19
Iter:3899, L1 loss=0.0007424, Total loss=0.0006813, Time:20
Iter:3999, L1 loss=0.0008476, Total loss=0.0007745, Time:20
Iter:4099, L1 loss=0.000955, Total loss=0.0009384, Time:25
Iter:4199, L1 loss=0.0007765, Total loss=0.0007352, Time:22
Iter:4299, L1 loss=0.0008438, Total loss=0.0007938, Time:26
Iter:4399, L1 loss=0.0005786, Total loss=0.0005268, Time:26
Iter:4499, L1 loss=0.0007967, Total loss=0.0007482, Time:26
Iter:4599, L1 loss=0.0006712, Total loss=0.0006169, Time:26
Iter:4699, L1 loss=0.000607, Total loss=0.0005596, Time:25
Iter:4799, L1 loss=0.0005986, Total loss=0.0005477, Time:26
Iter:4899, L1 loss=0.000659, Total loss=0.0005755, Time:25
Iter:4999, L1 loss=0.0005059, Total loss=0.0004477, Time:27
Iter:5099, L1 loss=0.0005907, Total loss=0.0005129, Time:27
Iter:5199, L1 loss=0.0005408, Total loss=0.0004812, Time:27
Iter:5299, L1 loss=0.0006348, Total loss=0.0005375, Time:27
Iter:5399, L1 loss=0.0005166, Total loss=0.000426, Time:28
Iter:5499, L1 loss=0.0005198, Total loss=0.0004835, Time:28
Iter:5599, L1 loss=0.0004713, Total loss=0.0004164, Time:27
Iter:5699, L1 loss=0.0004889, Total loss=0.0004444, Time:27
Iter:5799, L1 loss=0.0004453, Total loss=0.000397, Time:28
Iter:5899, L1 loss=0.0004812, Total loss=0.0004241, Time:25
Iter:5999, L1 loss=0.0004717, Total loss=0.0004155, Time:25
Iter:6099, L1 loss=0.0004513, Total loss=0.0003996, Time:23
Iter:6199, L1 loss=0.0003857, Total loss=0.0003308, Time:24
Iter:6299, L1 loss=0.0005063, Total loss=0.0004601, Time:25
Iter:6399, L1 loss=0.0004382, Total loss=0.0003889, Time:25
Iter:6499, L1 loss=0.0005152, Total loss=0.0004645, Time:24
Iter:6599, L1 loss=0.0004187, Total loss=0.0003702, Time:24
Iter:6699, L1 loss=0.0004783, Total loss=0.0004212, Time:25
Iter:6799, L1 loss=0.0003596, Total loss=0.0003069, Time:26
Iter:6899, L1 loss=0.0004742, Total loss=0.0004197, Time:25
Iter:6999, L1 loss=0.0004685, Total loss=0.0004293, Time:24
Iter:7099, L1 loss=0.0004339, Total loss=0.0003744, Time:29
Iter:7199, L1 loss=0.000374, Total loss=0.0003278, Time:29
Iter:7299, L1 loss=0.0004398, Total loss=0.0003914, Time:26
Iter:7399, L1 loss=0.0005606, Total loss=0.0004383, Time:29
Iter:7499, L1 loss=0.0003999, Total loss=0.0003504, Time:29
Iter:7599, L1 loss=0.0003626, Total loss=0.0003137, Time:30
Iter:7699, L1 loss=0.000337, Total loss=0.0002931, Time:25
Iter:7799, L1 loss=0.0003467, Total loss=0.0003055, Time:26
Iter:7899, L1 loss=0.0004065, Total loss=0.0003607, Time:25
Iter:7999, L1 loss=0.0003744, Total loss=0.0003238, Time:28
Iter:8099, L1 loss=0.0005297, Total loss=0.0004776, Time:32
Iter:8199, L1 loss=0.000487, Total loss=0.0004319, Time:31
Iter:8299, L1 loss=0.0003785, Total loss=0.0003302, Time:30
Iter:8399, L1 loss=0.0003566, Total loss=0.0003064, Time:33
Iter:8499, L1 loss=0.000439, Total loss=0.0003848, Time:31
Iter:8599, L1 loss=0.0003104, Total loss=0.0002635, Time:30
Iter:8699, L1 loss=0.0003606, Total loss=0.0003182, Time:32
Iter:8799, L1 loss=0.0004147, Total loss=0.0003635, Time:31
Iter:8899, L1 loss=0.0003271, Total loss=0.0002886, Time:30
Iter:8999, L1 loss=0.0003149, Total loss=0.0002709, Time:28
Iter:9099, L1 loss=0.0004465, Total loss=0.0003815, Time:31
Iter:9199, L1 loss=0.0003206, Total loss=0.0002911, Time:31
Iter:9299, L1 loss=0.0003016, Total loss=0.0002498, Time:28
Iter:9399, L1 loss=0.0004391, Total loss=0.0003671, Time:31
Iter:9499, L1 loss=0.0003331, Total loss=0.0002792, Time:30
Iter:9599, L1 loss=0.0003941, Total loss=0.0003497, Time:30
Iter:9699, L1 loss=0.0004889, Total loss=0.000414, Time:27
Iter:9799, L1 loss=0.0003028, Total loss=0.0002585, Time:31
Iter:9899, L1 loss=0.0004588, Total loss=0.0003546, Time:30
Iter:9999, L1 loss=0.0004926, Total loss=0.0004419, Time:31
Iter:10099, L1 loss=0.0002988, Total loss=0.0002563, Time:30
Iter:10199, L1 loss=0.0003408, Total loss=0.0002862, Time:31
Iter:10299, L1 loss=0.0002803, Total loss=0.0002477, Time:31
Iter:10399, L1 loss=0.0002891, Total loss=0.0002442, Time:31
Iter:10499, L1 loss=0.000288, Total loss=0.0002404, Time:28
Iter:10599, L1 loss=0.0002687, Total loss=0.000233, Time:30
Iter:10699, L1 loss=0.0003083, Total loss=0.0002678, Time:30
Iter:10799, L1 loss=0.0002668, Total loss=0.000231, Time:27
Iter:10899, L1 loss=0.0003279, Total loss=0.0002914, Time:31
Iter:10999, L1 loss=0.0002984, Total loss=0.0002487, Time:30
Iter:11099, L1 loss=0.0002956, Total loss=0.000249, Time:31
Iter:11199, L1 loss=0.0002896, Total loss=0.0002436, Time:32
Iter:11299, L1 loss=0.0002445, Total loss=0.0002143, Time:26
Iter:11399, L1 loss=0.0003176, Total loss=0.0002663, Time:30
Iter:11499, L1 loss=0.000385, Total loss=0.0003163, Time:29
Iter:11599, L1 loss=0.000273, Total loss=0.0002251, Time:30
Iter:11699, L1 loss=0.0002393, Total loss=0.0002088, Time:27
Iter:11799, L1 loss=0.000269, Total loss=0.0002254, Time:26
Iter:11899, L1 loss=0.0002931, Total loss=0.0002349, Time:31
Iter:11999, L1 loss=0.000243, Total loss=0.0002085, Time:30
Iter:12099, L1 loss=0.0005629, Total loss=0.0004567, Time:29
Iter:12199, L1 loss=0.000337, Total loss=0.000299, Time:32
Iter:12299, L1 loss=0.0003609, Total loss=0.0003142, Time:32
Iter:12399, L1 loss=0.0002521, Total loss=0.0002191, Time:31
Iter:12499, L1 loss=0.0003061, Total loss=0.0002393, Time:29
Iter:12599, L1 loss=0.0003578, Total loss=0.0003086, Time:32
Iter:12699, L1 loss=0.0002996, Total loss=0.0002664, Time:33
Iter:12799, L1 loss=0.000275, Total loss=0.0002156, Time:33
Iter:12899, L1 loss=0.0002581, Total loss=0.000206, Time:33
Iter:12999, L1 loss=0.000228, Total loss=0.0002017, Time:33
Iter:13099, L1 loss=0.0002748, Total loss=0.0002217, Time:33
Iter:13199, L1 loss=0.0002671, Total loss=0.0002291, Time:33
Iter:13299, L1 loss=0.000227, Total loss=0.0001865, Time:29
Iter:13399, L1 loss=0.000228, Total loss=0.0001908, Time:33
Iter:13499, L1 loss=0.0002637, Total loss=0.000222, Time:32
Iter:13599, L1 loss=0.0002417, Total loss=0.0002005, Time:31
Iter:13699, L1 loss=0.0002844, Total loss=0.0002404, Time:28
Iter:13799, L1 loss=0.0002688, Total loss=0.0002288, Time:31
Iter:13899, L1 loss=0.000293, Total loss=0.0002526, Time:32
Iter:13999, L1 loss=0.0002232, Total loss=0.0001879, Time:31
Iter:14099, L1 loss=0.000254, Total loss=0.0002058, Time:28
Iter:14199, L1 loss=0.0002246, Total loss=0.000194, Time:31
Iter:14299, L1 loss=0.000231, Total loss=0.0001917, Time:31
Iter:14399, L1 loss=0.0002118, Total loss=0.0001747, Time:28
Iter:14499, L1 loss=0.0002318, Total loss=0.0002032, Time:31
Iter:14599, L1 loss=0.00026, Total loss=0.000217, Time:31
Iter:14699, L1 loss=0.0002375, Total loss=0.0002036, Time:30
Iter:14799, L1 loss=0.0003409, Total loss=0.0002763, Time:27
Iter:14899, L1 loss=0.0002126, Total loss=0.0001797, Time:31
Iter:14999, L1 loss=0.000319, Total loss=0.0002575, Time:31
Iter:15099, L1 loss=0.0001921, Total loss=0.000165, Time:29
Iter:15199, L1 loss=0.0002116, Total loss=0.0001759, Time:29
Iter:15299, L1 loss=0.000229, Total loss=0.0002036, Time:33
Iter:15399, L1 loss=0.0001839, Total loss=0.0001618, Time:32
Iter:15499, L1 loss=0.0002376, Total loss=0.0001883, Time:30
Iter:15599, L1 loss=0.0002028, Total loss=0.0001715, Time:30
Iter:15699, L1 loss=0.0002148, Total loss=0.0001744, Time:31
Iter:15799, L1 loss=0.0001905, Total loss=0.0001572, Time:28
Iter:15899, L1 loss=0.0001778, Total loss=0.000149, Time:26
Iter:15999, L1 loss=0.0002109, Total loss=0.0001738, Time:27
Iter:16099, L1 loss=0.0003108, Total loss=0.0002674, Time:28
Iter:16199, L1 loss=0.0002941, Total loss=0.0002509, Time:28
Iter:16299, L1 loss=0.000316, Total loss=0.0002486, Time:32
Iter:16399, L1 loss=0.0002187, Total loss=0.0001815, Time:31
Iter:16499, L1 loss=0.0002516, Total loss=0.0002389, Time:32
Iter:16599, L1 loss=0.0002315, Total loss=0.0001875, Time:28
Iter:16699, L1 loss=0.0002251, Total loss=0.0001938, Time:31
Iter:16799, L1 loss=0.0002606, Total loss=0.0002125, Time:27
Iter:16899, L1 loss=0.0002623, Total loss=0.0002115, Time:32
Iter:16999, L1 loss=0.0002153, Total loss=0.0001864, Time:28
Iter:17099, L1 loss=0.0002045, Total loss=0.000161, Time:33
Iter:17199, L1 loss=0.0001946, Total loss=0.0001674, Time:31
Iter:17299, L1 loss=0.0002156, Total loss=0.0001791, Time:31
Iter:17399, L1 loss=0.0002059, Total loss=0.0001654, Time:32
Iter:17499, L1 loss=0.0001963, Total loss=0.0001686, Time:31
Iter:17599, L1 loss=0.0002088, Total loss=0.000181, Time:31
Iter:17699, L1 loss=0.0001843, Total loss=0.0001522, Time:28
Iter:17799, L1 loss=0.0003292, Total loss=0.0002682, Time:33
Iter:17899, L1 loss=0.0001841, Total loss=0.0001594, Time:31
Iter:17999, L1 loss=0.000183, Total loss=0.0001482, Time:28
Iter:18099, L1 loss=0.0002902, Total loss=0.0002518, Time:31
Iter:18199, L1 loss=0.0001956, Total loss=0.0001692, Time:32
Iter:18299, L1 loss=0.0002808, Total loss=0.0002251, Time:32
Iter:18399, L1 loss=0.000193, Total loss=0.0001622, Time:29
Iter:18499, L1 loss=0.0002007, Total loss=0.0001688, Time:27
Iter:18599, L1 loss=0.0002509, Total loss=0.0001885, Time:28
Iter:18699, L1 loss=0.0001812, Total loss=0.0001489, Time:31
Iter:18799, L1 loss=0.0001766, Total loss=0.0001397, Time:31
Iter:18899, L1 loss=0.0001907, Total loss=0.0001682, Time:27
Iter:18999, L1 loss=0.0001702, Total loss=0.0001408, Time:31
Iter:19099, L1 loss=0.0001982, Total loss=0.0001628, Time:31
Iter:19199, L1 loss=0.0002636, Total loss=0.0001944, Time:30
Iter:19299, L1 loss=0.0001783, Total loss=0.000148, Time:30
Iter:19399, L1 loss=0.0001872, Total loss=0.0001552, Time:30
Iter:19499, L1 loss=0.0002107, Total loss=0.000179, Time:27
Iter:19599, L1 loss=0.000198, Total loss=0.0001662, Time:28
Iter:19699, L1 loss=0.0001898, Total loss=0.0001645, Time:30
Iter:19799, L1 loss=0.0001923, Total loss=0.0001608, Time:31
Iter:19899, L1 loss=0.0002077, Total loss=0.0001764, Time:30
Iter:19999, L1 loss=0.0001657, Total loss=0.0001416, Time:30
Testing Speed: 136.2222216448372 fps
Testing Time: 0.3670473098754883 s

[ITER 20000] Evaluating test: SSIM = 0.8506614017486572, PSNR = 18.51963394165039
Testing Speed: 149.42123950552778 fps
Testing Time: 0.02007746696472168 s

[ITER 20000] Evaluating train: SSIM = 0.9999996622403462, PSNR = 69.42729949951172
Iter:20000, total_points:199287

[ITER 20000] Saving Gaussians
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...

Starting training...
Total iterations: 20000
Total iterations: 20000
==================================================
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693031 @iter20) ([92mâ†“19.84%[0m) [69.39% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693031 @iter20) ([92mâ†“19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327880 @iter30) ([92mâ†“21.29%[0m) [54.62% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327880 @iter30) ([92mâ†“21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123930 (Best: 0.1098392 @iter40) ([92mâ†“18.25%[0m) [44.65% of initial]
[Iter 40/20000] Loss: 0.1123930 (Best: 0.1098392 @iter40) ([92mâ†“18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993453 (Best: 0.0965435 @iter49) ([92mâ†“11.61%[0m) [39.47% of initial]
[Iter 50/20000] Loss: 0.0993453 (Best: 0.0965435 @iter49) ([92mâ†“11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936766 (Best: 0.0908527 @iter59) ([92mâ†“5.71%[0m) [37.22% of initial]
[Iter 60/20000] Loss: 0.0936766 (Best: 0.0908527 @iter59) ([92mâ†“5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884504 (Best: 0.0869384 @iter70) ([92mâ†“5.58%[0m) [35.14% of initial]
[Iter 70/20000] Loss: 0.0884504 (Best: 0.0869384 @iter70) ([92mâ†“5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851861 (Best: 0.0831026 @iter80) ([92mâ†“3.69%[0m) [33.84% of initial]
[Iter 80/20000] Loss: 0.0851861 (Best: 0.0831026 @iter80) ([92mâ†“3.69%[0m) [33.84% of initial]
[Iter 90/20000] Loss: 0.0824127 (Best: 0.0801649 @iter88) ([92mâ†“3.26%[0m) [32.74% of initial]
[Iter 90/20000] Loss: 0.0824127 (Best: 0.0801649 @iter88) ([92mâ†“3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07878, Time:14
Iter:99, L1 loss=0.05723, Total loss=0.07878, Time:14
[Iter 100/20000] Loss: 0.0786700 (Best: 0.0766176 @iter97) ([92mâ†“4.54%[0m) [31.25% of initial]
[Iter 100/20000] Loss: 0.0786700 (Best: 0.0766176 @iter97) ([92mâ†“4.54%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753264 (Best: 0.0731388 @iter106) ([92mâ†“4.25%[0m) [29.93% of initial]
[Iter 110/20000] Loss: 0.0753264 (Best: 0.0731388 @iter106) ([92mâ†“4.25%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714306 (Best: 0.0685537 @iter118) ([92mâ†“5.17%[0m) [28.38% of initial]
[Iter 120/20000] Loss: 0.0714306 (Best: 0.0685537 @iter118) ([92mâ†“5.17%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0666951 (Best: 0.0641874 @iter130) ([92mâ†“6.63%[0m) [26.50% of initial]
[Iter 130/20000] Loss: 0.0666951 (Best: 0.0641874 @iter130) ([92mâ†“6.63%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635276 (Best: 0.0612695 @iter140) ([92mâ†“4.75%[0m) [25.24% of initial]
[Iter 140/20000] Loss: 0.0635276 (Best: 0.0612695 @iter140) ([92mâ†“4.75%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612530 (Best: 0.0583437 @iter148) ([92mâ†“3.58%[0m) [24.34% of initial]
[Iter 150/20000] Loss: 0.0612530 (Best: 0.0583437 @iter148) ([92mâ†“3.58%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590401 (Best: 0.0559317 @iter157) ([92mâ†“3.61%[0m) [23.46% of initial]
[Iter 160/20000] Loss: 0.0590401 (Best: 0.0559317 @iter157) ([92mâ†“3.61%[0m) [23.46% of initial]
[Iter 170/20000] Loss: 0.0563388 (Best: 0.0534640 @iter167) ([92mâ†“4.58%[0m) [22.38% of initial]
[Iter 170/20000] Loss: 0.0563388 (Best: 0.0534640 @iter167) ([92mâ†“4.58%[0m) [22.38% of initial]
[Iter 180/20000] Loss: 0.0523150 (Best: 0.0500024 @iter179) ([92mâ†“7.14%[0m) [20.78% of initial]
[Iter 180/20000] Loss: 0.0523150 (Best: 0.0500024 @iter179) ([92mâ†“7.14%[0m) [20.78% of initial]
[Iter 190/20000] Loss: 0.0495360 (Best: 0.0478174 @iter188) ([92mâ†“5.31%[0m) [19.68% of initial]
[Iter 190/20000] Loss: 0.0495360 (Best: 0.0478174 @iter188) ([92mâ†“5.31%[0m) [19.68% of initial]
Iter:199, L1 loss=0.0344, Total loss=0.04975, Time:15
Iter:199, L1 loss=0.0344, Total loss=0.04975, Time:15
[Iter 200/20000] Loss: 0.0477899 (Best: 0.0456806 @iter198) ([92mâ†“3.52%[0m) [18.99% of initial]
[Iter 200/20000] Loss: 0.0477899 (Best: 0.0456806 @iter198) ([92mâ†“3.52%[0m) [18.99% of initial]
[Iter 210/20000] Loss: 0.0451126 (Best: 0.0429467 @iter209) ([92mâ†“5.60%[0m) [17.92% of initial]
[Iter 210/20000] Loss: 0.0451126 (Best: 0.0429467 @iter209) ([92mâ†“5.60%[0m) [17.92% of initial]
[Iter 220/20000] Loss: 0.0440793 (Best: 0.0411946 @iter219) ([92mâ†“2.29%[0m) [17.51% of initial]
[Iter 220/20000] Loss: 0.0440793 (Best: 0.0411946 @iter219) ([92mâ†“2.29%[0m) [17.51% of initial]
[Iter 230/20000] Loss: 0.0423805 (Best: 0.0399105 @iter227) ([92mâ†“3.85%[0m) [16.84% of initial]
[Iter 230/20000] Loss: 0.0423805 (Best: 0.0399105 @iter227) ([92mâ†“3.85%[0m) [16.84% of initial]
[Iter 240/20000] Loss: 0.0402768 (Best: 0.0377957 @iter238) ([92mâ†“4.96%[0m) [16.00% of initial]
[Iter 240/20000] Loss: 0.0402768 (Best: 0.0377957 @iter238) ([92mâ†“4.96%[0m) [16.00% of initial]
[Iter 250/20000] Loss: 0.0379678 (Best: 0.0362037 @iter248) ([92mâ†“5.73%[0m) [15.08% of initial]
[Iter 250/20000] Loss: 0.0379678 (Best: 0.0362037 @iter248) ([92mâ†“5.73%[0m) [15.08% of initial]
[Iter 260/20000] Loss: 0.0358894 (Best: 0.0343046 @iter260) ([92mâ†“5.47%[0m) [14.26% of initial]
[Iter 260/20000] Loss: 0.0358894 (Best: 0.0343046 @iter260) ([92mâ†“5.47%[0m) [14.26% of initial]
[Iter 270/20000] Loss: 0.0350643 (Best: 0.0329351 @iter269) ([92mâ†“2.30%[0m) [13.93% of initial]
[Iter 270/20000] Loss: 0.0350643 (Best: 0.0329351 @iter269) ([92mâ†“2.30%[0m) [13.93% of initial]
[Iter 280/20000] Loss: 0.0346071 (Best: 0.0318444 @iter277) ([92mâ†“1.30%[0m) [13.75% of initial]
[Iter 280/20000] Loss: 0.0346071 (Best: 0.0318444 @iter277) ([92mâ†“1.30%[0m) [13.75% of initial]
[Iter 290/20000] Loss: 0.0330132 (Best: 0.0304691 @iter287) ([92mâ†“4.61%[0m) [13.12% of initial]
[Iter 290/20000] Loss: 0.0330132 (Best: 0.0304691 @iter287) ([92mâ†“4.61%[0m) [13.12% of initial]
Iter:299, L1 loss=0.02227, Total loss=0.03323, Time:14
Iter:299, L1 loss=0.02227, Total loss=0.03323, Time:14
[Iter 300/20000] Loss: 0.0307210 (Best: 0.0289390 @iter300) ([92mâ†“6.94%[0m) [12.21% of initial]
[Iter 300/20000] Loss: 0.0307210 (Best: 0.0289390 @iter300) ([92mâ†“6.94%[0m) [12.21% of initial]
[Iter 310/20000] Loss: 0.0291664 (Best: 0.0271414 @iter310) ([92mâ†“5.06%[0m) [11.59% of initial]
[Iter 310/20000] Loss: 0.0291664 (Best: 0.0271414 @iter310) ([92mâ†“5.06%[0m) [11.59% of initial]
[Iter 320/20000] Loss: 0.0278591 (Best: 0.0263752 @iter320) ([92mâ†“4.48%[0m) [11.07% of initial]
[Iter 320/20000] Loss: 0.0278591 (Best: 0.0263752 @iter320) ([92mâ†“4.48%[0m) [11.07% of initial]
[Iter 330/20000] Loss: 0.0274840 (Best: 0.0255639 @iter330) ([92mâ†“1.35%[0m) [10.92% of initial]
[Iter 330/20000] Loss: 0.0274840 (Best: 0.0255639 @iter330) ([92mâ†“1.35%[0m) [10.92% of initial]
[Iter 340/20000] Loss: 0.0251910 (Best: 0.0240706 @iter340) ([92mâ†“8.34%[0m) [10.01% of initial]
[Iter 340/20000] Loss: 0.0251910 (Best: 0.0240706 @iter340) ([92mâ†“8.34%[0m) [10.01% of initial]
[Iter 350/20000] Loss: 0.0257059 (Best: 0.0233537 @iter349) ([91mâ†‘2.04%[0m) [10.21% of initial]
[Iter 350/20000] Loss: 0.0257059 (Best: 0.0233537 @iter349) ([91mâ†‘2.04%[0m) [10.21% of initial]
[Iter 360/20000] Loss: 0.0243030 (Best: 0.0223619 @iter358) ([92mâ†“5.46%[0m) [9.66% of initial]
[Iter 360/20000] Loss: 0.0243030 (Best: 0.0223619 @iter358) ([92mâ†“5.46%[0m) [9.66% of initial]
[Iter 370/20000] Loss: 0.0238550 (Best: 0.0216121 @iter368) ([92mâ†“1.84%[0m) [9.48% of initial]
[Iter 370/20000] Loss: 0.0238550 (Best: 0.0216121 @iter368) ([92mâ†“1.84%[0m) [9.48% of initial]
[Iter 380/20000] Loss: 0.0217723 (Best: 0.0206253 @iter379) ([92mâ†“8.73%[0m) [8.65% of initial]
[Iter 380/20000] Loss: 0.0217723 (Best: 0.0206253 @iter379) ([92mâ†“8.73%[0m) [8.65% of initial]
[Iter 390/20000] Loss: 0.0212732 (Best: 0.0198484 @iter385) ([92mâ†“2.29%[0m) [8.45% of initial]
[Iter 390/20000] Loss: 0.0212732 (Best: 0.0198484 @iter385) ([92mâ†“2.29%[0m) [8.45% of initial]
Iter:399, L1 loss=0.01368, Total loss=0.02116, Time:15
Iter:399, L1 loss=0.01368, Total loss=0.02116, Time:15
[Iter 400/20000] Loss: 0.0203142 (Best: 0.0188691 @iter400) ([92mâ†“4.51%[0m) [8.07% of initial]
[Iter 400/20000] Loss: 0.0203142 (Best: 0.0188691 @iter400) ([92mâ†“4.51%[0m) [8.07% of initial]
[Iter 410/20000] Loss: 0.0192205 (Best: 0.0182095 @iter410) ([92mâ†“5.38%[0m) [7.64% of initial]
[Iter 410/20000] Loss: 0.0192205 (Best: 0.0182095 @iter410) ([92mâ†“5.38%[0m) [7.64% of initial]
[Iter 420/20000] Loss: 0.0200487 (Best: 0.0179178 @iter413) ([91mâ†‘4.31%[0m) [7.97% of initial]
[Iter 420/20000] Loss: 0.0200487 (Best: 0.0179178 @iter413) ([91mâ†‘4.31%[0m) [7.97% of initial]
[Iter 430/20000] Loss: 0.0178783 (Best: 0.0169955 @iter430) ([92mâ†“10.83%[0m) [7.10% of initial]
[Iter 430/20000] Loss: 0.0178783 (Best: 0.0169955 @iter430) ([92mâ†“10.83%[0m) [7.10% of initial]
[Iter 440/20000] Loss: 0.0181216 (Best: 0.0163775 @iter438) ([91mâ†‘1.36%[0m) [7.20% of initial]
[Iter 440/20000] Loss: 0.0181216 (Best: 0.0163775 @iter438) ([91mâ†‘1.36%[0m) [7.20% of initial]
[Iter 450/20000] Loss: 0.0171034 (Best: 0.0152643 @iter449) ([92mâ†“5.62%[0m) [6.80% of initial]
[Iter 450/20000] Loss: 0.0171034 (Best: 0.0152643 @iter449) ([92mâ†“5.62%[0m) [6.80% of initial]
[Iter 460/20000] Loss: 0.0163657 (Best: 0.0146089 @iter458) ([92mâ†“4.31%[0m) [6.50% of initial]
[Iter 460/20000] Loss: 0.0163657 (Best: 0.0146089 @iter458) ([92mâ†“4.31%[0m) [6.50% of initial]
[Iter 470/20000] Loss: 0.0149304 (Best: 0.0138979 @iter470) ([92mâ†“8.77%[0m) [5.93% of initial]
[Iter 470/20000] Loss: 0.0149304 (Best: 0.0138979 @iter470) ([92mâ†“8.77%[0m) [5.93% of initial]
[Iter 480/20000] Loss: 0.0155361 (Best: 0.0134709 @iter475) ([91mâ†‘4.06%[0m) [6.17% of initial]
[Iter 480/20000] Loss: 0.0155361 (Best: 0.0134709 @iter475) ([91mâ†‘4.06%[0m) [6.17% of initial]
[Iter 490/20000] Loss: 0.0138112 (Best: 0.0125381 @iter490) ([92mâ†“11.10%[0m) [5.49% of initial]
[Iter 490/20000] Loss: 0.0138112 (Best: 0.0125381 @iter490) ([92mâ†“11.10%[0m) [5.49% of initial]
Iter:499, L1 loss=0.008315, Total loss=0.01456, Time:13
Iter:499, L1 loss=0.008315, Total loss=0.01456, Time:13
[Iter 500/20000] Loss: 0.0138060 (Best: 0.0124244 @iter493) ([92mâ†“0.04%[0m) [5.48% of initial]
[Iter 500/20000] Loss: 0.0138060 (Best: 0.0124244 @iter493) ([92mâ†“0.04%[0m) [5.48% of initial]
[Iter 510/20000] Loss: 0.0134649 (Best: 0.0120804 @iter507) ([92mâ†“2.47%[0m) [5.35% of initial]
[Iter 510/20000] Loss: 0.0134649 (Best: 0.0120804 @iter507) ([92mâ†“2.47%[0m) [5.35% of initial]
[Iter 520/20000] Loss: 0.0128722 (Best: 0.0115923 @iter514) ([92mâ†“4.40%[0m) [5.11% of initial]
[Iter 520/20000] Loss: 0.0128722 (Best: 0.0115923 @iter514) ([92mâ†“4.40%[0m) [5.11% of initial]
[Iter 530/20000] Loss: 0.0129946 (Best: 0.0115923 @iter514) ([91mâ†‘0.95%[0m) [5.16% of initial]
[Iter 530/20000] Loss: 0.0129946 (Best: 0.0115923 @iter514) ([91mâ†‘0.95%[0m) [5.16% of initial]
[Iter 540/20000] Loss: 0.0126180 (Best: 0.0112063 @iter538) ([92mâ†“2.90%[0m) [5.01% of initial]
[Iter 540/20000] Loss: 0.0126180 (Best: 0.0112063 @iter538) ([92mâ†“2.90%[0m) [5.01% of initial]
[Iter 550/20000] Loss: 0.0120649 (Best: 0.0108897 @iter548) ([92mâ†“4.38%[0m) [4.79% of initial]
[Iter 550/20000] Loss: 0.0120649 (Best: 0.0108897 @iter548) ([92mâ†“4.38%[0m) [4.79% of initial]
[Iter 560/20000] Loss: 0.0127218 (Best: 0.0108897 @iter548) ([91mâ†‘5.44%[0m) [5.05% of initial]
[Iter 560/20000] Loss: 0.0127218 (Best: 0.0108897 @iter548) ([91mâ†‘5.44%[0m) [5.05% of initial]
[Iter 570/20000] Loss: 0.0119315 (Best: 0.0105568 @iter569) ([92mâ†“6.21%[0m) [4.74% of initial]
[Iter 570/20000] Loss: 0.0119315 (Best: 0.0105568 @iter569) ([92mâ†“6.21%[0m) [4.74% of initial]
[Iter 580/20000] Loss: 0.0117174 (Best: 0.0103750 @iter572) ([92mâ†“1.79%[0m) [4.66% of initial]
[Iter 580/20000] Loss: 0.0117174 (Best: 0.0103750 @iter572) ([92mâ†“1.79%[0m) [4.66% of initial]
[Iter 590/20000] Loss: 0.0116257 (Best: 0.0103601 @iter583) ([92mâ†“0.78%[0m) [4.62% of initial]
[Iter 590/20000] Loss: 0.0116257 (Best: 0.0103601 @iter583) ([92mâ†“0.78%[0m) [4.62% of initial]
Iter:599, L1 loss=0.006954, Total loss=0.01233, Time:11
Iter:599, L1 loss=0.006954, Total loss=0.01233, Time:11
[Iter 600/20000] Loss: 0.0113687 (Best: 0.0101016 @iter598) ([92mâ†“2.21%[0m) [4.52% of initial]
[Iter 600/20000] Loss: 0.0113687 (Best: 0.0101016 @iter598) ([92mâ†“2.21%[0m) [4.52% of initial]
[Iter 610/20000] Loss: 0.0218150 (Best: 0.0101016 @iter598) ([91mâ†‘91.89%[0m) [8.67% of initial]
[Iter 610/20000] Loss: 0.0218150 (Best: 0.0101016 @iter598) ([91mâ†‘91.89%[0m) [8.67% of initial]
[Iter 620/20000] Loss: 0.0147221 (Best: 0.0101016 @iter598) ([92mâ†“32.51%[0m) [5.85% of initial]
[Iter 620/20000] Loss: 0.0147221 (Best: 0.0101016 @iter598) ([92mâ†“32.51%[0m) [5.85% of initial]
[Iter 630/20000] Loss: 0.0124683 (Best: 0.0101016 @iter598) ([92mâ†“15.31%[0m) [4.95% of initial]
[Iter 630/20000] Loss: 0.0124683 (Best: 0.0101016 @iter598) ([92mâ†“15.31%[0m) [4.95% of initial]
[Iter 640/20000] Loss: 0.0106826 (Best: 0.0097433 @iter640) ([92mâ†“14.32%[0m) [4.24% of initial]
[Iter 640/20000] Loss: 0.0106826 (Best: 0.0097433 @iter640) ([92mâ†“14.32%[0m) [4.24% of initial]
[Iter 650/20000] Loss: 0.0108664 (Best: 0.0094847 @iter646) ([91mâ†‘1.72%[0m) [4.32% of initial]
[Iter 650/20000] Loss: 0.0108664 (Best: 0.0094847 @iter646) ([91mâ†‘1.72%[0m) [4.32% of initial]
[Iter 660/20000] Loss: 0.0104396 (Best: 0.0090039 @iter655) ([92mâ†“3.93%[0m) [4.15% of initial]
[Iter 660/20000] Loss: 0.0104396 (Best: 0.0090039 @iter655) ([92mâ†“3.93%[0m) [4.15% of initial]
[Iter 670/20000] Loss: 0.0096440 (Best: 0.0086746 @iter667) ([92mâ†“7.62%[0m) [3.83% of initial]
[Iter 670/20000] Loss: 0.0096440 (Best: 0.0086746 @iter667) ([92mâ†“7.62%[0m) [3.83% of initial]
[Iter 680/20000] Loss: 0.0092896 (Best: 0.0085333 @iter680) ([92mâ†“3.67%[0m) [3.69% of initial]
[Iter 680/20000] Loss: 0.0092896 (Best: 0.0085333 @iter680) ([92mâ†“3.67%[0m) [3.69% of initial]
[Iter 690/20000] Loss: 0.0093479 (Best: 0.0080952 @iter682) ([91mâ†‘0.63%[0m) [3.71% of initial]
[Iter 690/20000] Loss: 0.0093479 (Best: 0.0080952 @iter682) ([91mâ†‘0.63%[0m) [3.71% of initial]
Iter:699, L1 loss=0.005645, Total loss=0.009931, Time:13
Iter:699, L1 loss=0.005645, Total loss=0.009931, Time:13
[Iter 700/20000] Loss: 0.0090446 (Best: 0.0080371 @iter695) ([92mâ†“3.25%[0m) [3.59% of initial]
[Iter 700/20000] Loss: 0.0090446 (Best: 0.0080371 @iter695) ([92mâ†“3.25%[0m) [3.59% of initial]
[Iter 710/20000] Loss: 0.0084209 (Best: 0.0078206 @iter710) ([92mâ†“6.90%[0m) [3.35% of initial]
[Iter 710/20000] Loss: 0.0084209 (Best: 0.0078206 @iter710) ([92mâ†“6.90%[0m) [3.35% of initial]
[Iter 720/20000] Loss: 0.0084288 (Best: 0.0076561 @iter715) ([91mâ†‘0.09%[0m) [3.35% of initial]
[Iter 720/20000] Loss: 0.0084288 (Best: 0.0076561 @iter715) ([91mâ†‘0.09%[0m) [3.35% of initial]
[Iter 730/20000] Loss: 0.0085844 (Best: 0.0072767 @iter727) ([91mâ†‘1.85%[0m) [3.41% of initial]
[Iter 730/20000] Loss: 0.0085844 (Best: 0.0072767 @iter727) ([91mâ†‘1.85%[0m) [3.41% of initial]
[Iter 740/20000] Loss: 0.0086158 (Best: 0.0072767 @iter727) ([91mâ†‘0.37%[0m) [3.42% of initial]
[Iter 740/20000] Loss: 0.0086158 (Best: 0.0072767 @iter727) ([91mâ†‘0.37%[0m) [3.42% of initial]
[Iter 750/20000] Loss: 0.0082090 (Best: 0.0070241 @iter748) ([92mâ†“4.72%[0m) [3.26% of initial]
[Iter 750/20000] Loss: 0.0082090 (Best: 0.0070241 @iter748) ([92mâ†“4.72%[0m) [3.26% of initial]
[Iter 760/20000] Loss: 0.0074935 (Best: 0.0070044 @iter754) ([92mâ†“8.72%[0m) [2.98% of initial]
[Iter 760/20000] Loss: 0.0074935 (Best: 0.0070044 @iter754) ([92mâ†“8.72%[0m) [2.98% of initial]
[Iter 770/20000] Loss: 0.0076322 (Best: 0.0069560 @iter764) ([91mâ†‘1.85%[0m) [3.03% of initial]
[Iter 770/20000] Loss: 0.0076322 (Best: 0.0069560 @iter764) ([91mâ†‘1.85%[0m) [3.03% of initial]
[Iter 780/20000] Loss: 0.0078663 (Best: 0.0067595 @iter778) ([91mâ†‘3.07%[0m) [3.13% of initial]
[Iter 780/20000] Loss: 0.0078663 (Best: 0.0067595 @iter778) ([91mâ†‘3.07%[0m) [3.13% of initial]
[Iter 790/20000] Loss: 0.0075725 (Best: 0.0066825 @iter787) ([92mâ†“3.74%[0m) [3.01% of initial]
[Iter 790/20000] Loss: 0.0075725 (Best: 0.0066825 @iter787) ([92mâ†“3.74%[0m) [3.01% of initial]
Iter:799, L1 loss=0.005003, Total loss=0.008577, Time:13
Iter:799, L1 loss=0.005003, Total loss=0.008577, Time:13
[Iter 800/20000] Loss: 0.0077045 (Best: 0.0066825 @iter787) ([91mâ†‘1.74%[0m) [3.06% of initial]
[Iter 800/20000] Loss: 0.0077045 (Best: 0.0066825 @iter787) ([91mâ†‘1.74%[0m) [3.06% of initial]
[Iter 810/20000] Loss: 0.0157766 (Best: 0.0066825 @iter787) ([91mâ†‘104.77%[0m) [6.27% of initial]
[Iter 810/20000] Loss: 0.0157766 (Best: 0.0066825 @iter787) ([91mâ†‘104.77%[0m) [6.27% of initial]
[Iter 820/20000] Loss: 0.0106748 (Best: 0.0066825 @iter787) ([92mâ†“32.34%[0m) [4.24% of initial]
[Iter 820/20000] Loss: 0.0106748 (Best: 0.0066825 @iter787) ([92mâ†“32.34%[0m) [4.24% of initial]
[Iter 830/20000] Loss: 0.0089570 (Best: 0.0066825 @iter787) ([92mâ†“16.09%[0m) [3.56% of initial]
[Iter 830/20000] Loss: 0.0089570 (Best: 0.0066825 @iter787) ([92mâ†“16.09%[0m) [3.56% of initial]
[Iter 840/20000] Loss: 0.0080939 (Best: 0.0066825 @iter787) ([92mâ†“9.64%[0m) [3.22% of initial]
[Iter 840/20000] Loss: 0.0080939 (Best: 0.0066825 @iter787) ([92mâ†“9.64%[0m) [3.22% of initial]
[Iter 850/20000] Loss: 0.0075539 (Best: 0.0066441 @iter847) ([92mâ†“6.67%[0m) [3.00% of initial]
[Iter 850/20000] Loss: 0.0075539 (Best: 0.0066441 @iter847) ([92mâ†“6.67%[0m) [3.00% of initial]
[Iter 860/20000] Loss: 0.0070855 (Best: 0.0061816 @iter856) ([92mâ†“6.20%[0m) [2.81% of initial]
[Iter 860/20000] Loss: 0.0070855 (Best: 0.0061816 @iter856) ([92mâ†“6.20%[0m) [2.81% of initial]
[Iter 870/20000] Loss: 0.0067098 (Best: 0.0060721 @iter862) ([92mâ†“5.30%[0m) [2.67% of initial]
[Iter 870/20000] Loss: 0.0067098 (Best: 0.0060721 @iter862) ([92mâ†“5.30%[0m) [2.67% of initial]
[Iter 880/20000] Loss: 0.0067138 (Best: 0.0060175 @iter872) ([91mâ†‘0.06%[0m) [2.67% of initial]
[Iter 880/20000] Loss: 0.0067138 (Best: 0.0060175 @iter872) ([91mâ†‘0.06%[0m) [2.67% of initial]
[Iter 890/20000] Loss: 0.0063600 (Best: 0.0057006 @iter887) ([92mâ†“5.27%[0m) [2.53% of initial]
[Iter 890/20000] Loss: 0.0063600 (Best: 0.0057006 @iter887) ([92mâ†“5.27%[0m) [2.53% of initial]
Iter:899, L1 loss=0.003705, Total loss=0.005563, Time:14
Iter:899, L1 loss=0.003705, Total loss=0.005563, Time:14
[Iter 900/20000] Loss: 0.0064237 (Best: 0.0055635 @iter899) ([91mâ†‘1.00%[0m) [2.55% of initial]
[Iter 900/20000] Loss: 0.0064237 (Best: 0.0055635 @iter899) ([91mâ†‘1.00%[0m) [2.55% of initial]
[Iter 910/20000] Loss: 0.0065461 (Best: 0.0054166 @iter907) ([91mâ†‘1.91%[0m) [2.60% of initial]
[Iter 910/20000] Loss: 0.0065461 (Best: 0.0054166 @iter907) ([91mâ†‘1.91%[0m) [2.60% of initial]
[Iter 920/20000] Loss: 0.0058887 (Best: 0.0052917 @iter916) ([92mâ†“10.04%[0m) [2.34% of initial]
[Iter 920/20000] Loss: 0.0058887 (Best: 0.0052917 @iter916) ([92mâ†“10.04%[0m) [2.34% of initial]
[Iter 930/20000] Loss: 0.0061841 (Best: 0.0052397 @iter928) ([91mâ†‘5.02%[0m) [2.46% of initial]
[Iter 930/20000] Loss: 0.0061841 (Best: 0.0052397 @iter928) ([91mâ†‘5.02%[0m) [2.46% of initial]
[Iter 940/20000] Loss: 0.0062588 (Best: 0.0050953 @iter938) ([91mâ†‘1.21%[0m) [2.49% of initial]
[Iter 940/20000] Loss: 0.0062588 (Best: 0.0050953 @iter938) ([91mâ†‘1.21%[0m) [2.49% of initial]
[Iter 950/20000] Loss: 0.0057767 (Best: 0.0050953 @iter938) ([92mâ†“7.70%[0m) [2.30% of initial]
[Iter 950/20000] Loss: 0.0057767 (Best: 0.0050953 @iter938) ([92mâ†“7.70%[0m) [2.30% of initial]
[Iter 960/20000] Loss: 0.0059417 (Best: 0.0050953 @iter938) ([91mâ†‘2.86%[0m) [2.36% of initial]
[Iter 960/20000] Loss: 0.0059417 (Best: 0.0050953 @iter938) ([91mâ†‘2.86%[0m) [2.36% of initial]
[Iter 970/20000] Loss: 0.0058643 (Best: 0.0049995 @iter964) ([92mâ†“1.30%[0m) [2.33% of initial]
[Iter 970/20000] Loss: 0.0058643 (Best: 0.0049995 @iter964) ([92mâ†“1.30%[0m) [2.33% of initial]
[Iter 980/20000] Loss: 0.0059217 (Best: 0.0049995 @iter964) ([91mâ†‘0.98%[0m) [2.35% of initial]
[Iter 980/20000] Loss: 0.0059217 (Best: 0.0049995 @iter964) ([91mâ†‘0.98%[0m) [2.35% of initial]
[Iter 990/20000] Loss: 0.0059092 (Best: 0.0049785 @iter988) ([92mâ†“0.21%[0m) [2.35% of initial]
[Iter 990/20000] Loss: 0.0059092 (Best: 0.0049785 @iter988) ([92mâ†“0.21%[0m) [2.35% of initial]
Iter:999, L1 loss=0.004417, Total loss=0.006591, Time:13
Iter:999, L1 loss=0.004417, Total loss=0.006591, Time:13
[Iter 1000/20000] Loss: 0.0061891 (Best: 0.0049785 @iter988) ([91mâ†‘4.74%[0m) [2.46% of initial]
[Iter 1000/20000] Loss: 0.0061891 (Best: 0.0049785 @iter988) ([91mâ†‘4.74%[0m) [2.46% of initial]
[Iter 1010/20000] Loss: 0.0119219 (Best: 0.0049785 @iter988) ([91mâ†‘92.63%[0m) [4.74% of initial]
[Iter 1010/20000] Loss: 0.0119219 (Best: 0.0049785 @iter988) ([91mâ†‘92.63%[0m) [4.74% of initial]
[Iter 1020/20000] Loss: 0.0084147 (Best: 0.0049785 @iter988) ([92mâ†“29.42%[0m) [3.34% of initial]
[Iter 1020/20000] Loss: 0.0084147 (Best: 0.0049785 @iter988) ([92mâ†“29.42%[0m) [3.34% of initial]
[Iter 1030/20000] Loss: 0.0067732 (Best: 0.0049785 @iter988) ([92mâ†“19.51%[0m) [2.69% of initial]
[Iter 1030/20000] Loss: 0.0067732 (Best: 0.0049785 @iter988) ([92mâ†“19.51%[0m) [2.69% of initial]
[Iter 1040/20000] Loss: 0.0059919 (Best: 0.0049785 @iter988) ([92mâ†“11.53%[0m) [2.38% of initial]
[Iter 1040/20000] Loss: 0.0059919 (Best: 0.0049785 @iter988) ([92mâ†“11.53%[0m) [2.38% of initial]
[Iter 1050/20000] Loss: 0.0058304 (Best: 0.0049785 @iter988) ([92mâ†“2.70%[0m) [2.32% of initial]
[Iter 1050/20000] Loss: 0.0058304 (Best: 0.0049785 @iter988) ([92mâ†“2.70%[0m) [2.32% of initial]
[Iter 1060/20000] Loss: 0.0057052 (Best: 0.0048423 @iter1051) ([92mâ†“2.15%[0m) [2.27% of initial]
[Iter 1060/20000] Loss: 0.0057052 (Best: 0.0048423 @iter1051) ([92mâ†“2.15%[0m) [2.27% of initial]
[Iter 1070/20000] Loss: 0.0054270 (Best: 0.0044673 @iter1066) ([92mâ†“4.88%[0m) [2.16% of initial]
[Iter 1070/20000] Loss: 0.0054270 (Best: 0.0044673 @iter1066) ([92mâ†“4.88%[0m) [2.16% of initial]
[Iter 1080/20000] Loss: 0.0052490 (Best: 0.0044624 @iter1075) ([92mâ†“3.28%[0m) [2.09% of initial]
[Iter 1080/20000] Loss: 0.0052490 (Best: 0.0044624 @iter1075) ([92mâ†“3.28%[0m) [2.09% of initial]
[Iter 1090/20000] Loss: 0.0050781 (Best: 0.0044526 @iter1082) ([92mâ†“3.26%[0m) [2.02% of initial]
[Iter 1090/20000] Loss: 0.0050781 (Best: 0.0044526 @iter1082) ([92mâ†“3.26%[0m) [2.02% of initial]
Iter:1099, L1 loss=0.003366, Total loss=0.005153, Time:13
Iter:1099, L1 loss=0.003366, Total loss=0.005153, Time:13
[Iter 1100/20000] Loss: 0.0050017 (Best: 0.0042022 @iter1093) ([92mâ†“1.51%[0m) [1.99% of initial]
[Iter 1100/20000] Loss: 0.0050017 (Best: 0.0042022 @iter1093) ([92mâ†“1.51%[0m) [1.99% of initial]
[Iter 1110/20000] Loss: 0.0050290 (Best: 0.0042022 @iter1093) ([91mâ†‘0.55%[0m) [2.00% of initial]
[Iter 1110/20000] Loss: 0.0050290 (Best: 0.0042022 @iter1093) ([91mâ†‘0.55%[0m) [2.00% of initial]
[Iter 1120/20000] Loss: 0.0049670 (Best: 0.0041100 @iter1117) ([92mâ†“1.23%[0m) [1.97% of initial]
[Iter 1120/20000] Loss: 0.0049670 (Best: 0.0041100 @iter1117) ([92mâ†“1.23%[0m) [1.97% of initial]
[Iter 1130/20000] Loss: 0.0052191 (Best: 0.0041100 @iter1117) ([91mâ†‘5.07%[0m) [2.07% of initial]
[Iter 1130/20000] Loss: 0.0052191 (Best: 0.0041100 @iter1117) ([91mâ†‘5.07%[0m) [2.07% of initial]
[Iter 1140/20000] Loss: 0.0048011 (Best: 0.0040585 @iter1135) ([92mâ†“8.01%[0m) [1.91% of initial]
[Iter 1140/20000] Loss: 0.0048011 (Best: 0.0040585 @iter1135) ([92mâ†“8.01%[0m) [1.91% of initial]
[Iter 1150/20000] Loss: 0.0044463 (Best: 0.0039652 @iter1145) ([92mâ†“7.39%[0m) [1.77% of initial]
[Iter 1150/20000] Loss: 0.0044463 (Best: 0.0039652 @iter1145) ([92mâ†“7.39%[0m) [1.77% of initial]
[Iter 1160/20000] Loss: 0.0049878 (Best: 0.0039652 @iter1145) ([91mâ†‘12.18%[0m) [1.98% of initial]
[Iter 1160/20000] Loss: 0.0049878 (Best: 0.0039652 @iter1145) ([91mâ†‘12.18%[0m) [1.98% of initial]
[Iter 1170/20000] Loss: 0.0046104 (Best: 0.0039652 @iter1145) ([92mâ†“7.57%[0m) [1.83% of initial]
[Iter 1170/20000] Loss: 0.0046104 (Best: 0.0039652 @iter1145) ([92mâ†“7.57%[0m) [1.83% of initial]
[Iter 1180/20000] Loss: 0.0042875 (Best: 0.0039009 @iter1180) ([92mâ†“7.01%[0m) [1.70% of initial]
[Iter 1180/20000] Loss: 0.0042875 (Best: 0.0039009 @iter1180) ([92mâ†“7.01%[0m) [1.70% of initial]
[Iter 1190/20000] Loss: 0.0045635 (Best: 0.0038843 @iter1186) ([91mâ†‘6.44%[0m) [1.81% of initial]
[Iter 1190/20000] Loss: 0.0045635 (Best: 0.0038843 @iter1186) ([91mâ†‘6.44%[0m) [1.81% of initial]
Iter:1199, L1 loss=0.003426, Total loss=0.004866, Time:10
Iter:1199, L1 loss=0.003426, Total loss=0.004866, Time:10
[Iter 1200/20000] Loss: 0.0045477 (Best: 0.0037491 @iter1195) ([92mâ†“0.35%[0m) [1.81% of initial]
[Iter 1200/20000] Loss: 0.0045477 (Best: 0.0037491 @iter1195) ([92mâ†“0.35%[0m) [1.81% of initial]
[Iter 1210/20000] Loss: 0.0109541 (Best: 0.0037491 @iter1195) ([91mâ†‘140.87%[0m) [4.35% of initial]
[Iter 1210/20000] Loss: 0.0109541 (Best: 0.0037491 @iter1195) ([91mâ†‘140.87%[0m) [4.35% of initial]
[Iter 1220/20000] Loss: 0.0070703 (Best: 0.0037491 @iter1195) ([92mâ†“35.46%[0m) [2.81% of initial]
[Iter 1220/20000] Loss: 0.0070703 (Best: 0.0037491 @iter1195) ([92mâ†“35.46%[0m) [2.81% of initial]
[Iter 1230/20000] Loss: 0.0059922 (Best: 0.0037491 @iter1195) ([92mâ†“15.25%[0m) [2.38% of initial]
[Iter 1230/20000] Loss: 0.0059922 (Best: 0.0037491 @iter1195) ([92mâ†“15.25%[0m) [2.38% of initial]
[Iter 1240/20000] Loss: 0.0054752 (Best: 0.0037491 @iter1195) ([92mâ†“8.63%[0m) [2.18% of initial]
[Iter 1240/20000] Loss: 0.0054752 (Best: 0.0037491 @iter1195) ([92mâ†“8.63%[0m) [2.18% of initial]
[Iter 1250/20000] Loss: 0.0048716 (Best: 0.0037491 @iter1195) ([92mâ†“11.02%[0m) [1.94% of initial]
[Iter 1250/20000] Loss: 0.0048716 (Best: 0.0037491 @iter1195) ([92mâ†“11.02%[0m) [1.94% of initial]
[Iter 1260/20000] Loss: 0.0045982 (Best: 0.0037491 @iter1195) ([92mâ†“5.61%[0m) [1.83% of initial]
[Iter 1260/20000] Loss: 0.0045982 (Best: 0.0037491 @iter1195) ([92mâ†“5.61%[0m) [1.83% of initial]
[Iter 1270/20000] Loss: 0.0041154 (Best: 0.0037491 @iter1195) ([92mâ†“10.50%[0m) [1.64% of initial]
[Iter 1270/20000] Loss: 0.0041154 (Best: 0.0037491 @iter1195) ([92mâ†“10.50%[0m) [1.64% of initial]
[Iter 1280/20000] Loss: 0.0043320 (Best: 0.0034406 @iter1273) ([91mâ†‘5.26%[0m) [1.72% of initial]
[Iter 1280/20000] Loss: 0.0043320 (Best: 0.0034406 @iter1273) ([91mâ†‘5.26%[0m) [1.72% of initial]
[Iter 1290/20000] Loss: 0.0043017 (Best: 0.0034406 @iter1273) ([92mâ†“0.70%[0m) [1.71% of initial]
[Iter 1290/20000] Loss: 0.0043017 (Best: 0.0034406 @iter1273) ([92mâ†“0.70%[0m) [1.71% of initial]
Iter:1299, L1 loss=0.002798, Total loss=0.00382, Time:13
Iter:1299, L1 loss=0.002798, Total loss=0.00382, Time:13
[Iter 1300/20000] Loss: 0.0040387 (Best: 0.0034406 @iter1273) ([92mâ†“6.11%[0m) [1.60% of initial]
[Iter 1300/20000] Loss: 0.0040387 (Best: 0.0034406 @iter1273) ([92mâ†“6.11%[0m) [1.60% of initial]
[Iter 1310/20000] Loss: 0.0040355 (Best: 0.0034337 @iter1301) ([92mâ†“0.08%[0m) [1.60% of initial]
[Iter 1310/20000] Loss: 0.0040355 (Best: 0.0034337 @iter1301) ([92mâ†“0.08%[0m) [1.60% of initial]
[Iter 1320/20000] Loss: 0.0039112 (Best: 0.0031813 @iter1319) ([92mâ†“3.08%[0m) [1.55% of initial]
[Iter 1320/20000] Loss: 0.0039112 (Best: 0.0031813 @iter1319) ([92mâ†“3.08%[0m) [1.55% of initial]
[Iter 1330/20000] Loss: 0.0039328 (Best: 0.0031390 @iter1321) ([91mâ†‘0.55%[0m) [1.56% of initial]
[Iter 1330/20000] Loss: 0.0039328 (Best: 0.0031390 @iter1321) ([91mâ†‘0.55%[0m) [1.56% of initial]
[Iter 1340/20000] Loss: 0.0037215 (Best: 0.0031390 @iter1321) ([92mâ†“5.37%[0m) [1.48% of initial]
[Iter 1340/20000] Loss: 0.0037215 (Best: 0.0031390 @iter1321) ([92mâ†“5.37%[0m) [1.48% of initial]
[Iter 1350/20000] Loss: 0.0037146 (Best: 0.0031390 @iter1321) ([92mâ†“0.19%[0m) [1.48% of initial]
[Iter 1350/20000] Loss: 0.0037146 (Best: 0.0031390 @iter1321) ([92mâ†“0.19%[0m) [1.48% of initial]
[Iter 1360/20000] Loss: 0.0038512 (Best: 0.0031390 @iter1321) ([91mâ†‘3.68%[0m) [1.53% of initial]
[Iter 1360/20000] Loss: 0.0038512 (Best: 0.0031390 @iter1321) ([91mâ†‘3.68%[0m) [1.53% of initial]
[Iter 1370/20000] Loss: 0.0036475 (Best: 0.0031390 @iter1321) ([92mâ†“5.29%[0m) [1.45% of initial]
[Iter 1370/20000] Loss: 0.0036475 (Best: 0.0031390 @iter1321) ([92mâ†“5.29%[0m) [1.45% of initial]
[Iter 1380/20000] Loss: 0.0039128 (Best: 0.0031082 @iter1375) ([91mâ†‘7.27%[0m) [1.55% of initial]
[Iter 1380/20000] Loss: 0.0039128 (Best: 0.0031082 @iter1375) ([91mâ†‘7.27%[0m) [1.55% of initial]
[Iter 1390/20000] Loss: 0.0037640 (Best: 0.0031082 @iter1375) ([92mâ†“3.80%[0m) [1.50% of initial]
[Iter 1390/20000] Loss: 0.0037640 (Best: 0.0031082 @iter1375) ([92mâ†“3.80%[0m) [1.50% of initial]
Iter:1399, L1 loss=0.002275, Total loss=0.003007, Time:11
Iter:1399, L1 loss=0.002275, Total loss=0.003007, Time:11
[Iter 1400/20000] Loss: 0.0034410 (Best: 0.0030020 @iter1394) ([92mâ†“8.58%[0m) [1.37% of initial]
[Iter 1400/20000] Loss: 0.0034410 (Best: 0.0030020 @iter1394) ([92mâ†“8.58%[0m) [1.37% of initial]
[Iter 1410/20000] Loss: 0.0088258 (Best: 0.0030020 @iter1394) ([91mâ†‘156.49%[0m) [3.51% of initial]
[Iter 1410/20000] Loss: 0.0088258 (Best: 0.0030020 @iter1394) ([91mâ†‘156.49%[0m) [3.51% of initial]
[Iter 1420/20000] Loss: 0.0057154 (Best: 0.0030020 @iter1394) ([92mâ†“35.24%[0m) [2.27% of initial]
[Iter 1420/20000] Loss: 0.0057154 (Best: 0.0030020 @iter1394) ([92mâ†“35.24%[0m) [2.27% of initial]
[Iter 1430/20000] Loss: 0.0048303 (Best: 0.0030020 @iter1394) ([92mâ†“15.49%[0m) [1.92% of initial]
[Iter 1430/20000] Loss: 0.0048303 (Best: 0.0030020 @iter1394) ([92mâ†“15.49%[0m) [1.92% of initial]
[Iter 1440/20000] Loss: 0.0043855 (Best: 0.0030020 @iter1394) ([92mâ†“9.21%[0m) [1.74% of initial]
[Iter 1440/20000] Loss: 0.0043855 (Best: 0.0030020 @iter1394) ([92mâ†“9.21%[0m) [1.74% of initial]
[Iter 1450/20000] Loss: 0.0035099 (Best: 0.0030020 @iter1394) ([92mâ†“19.96%[0m) [1.39% of initial]
[Iter 1450/20000] Loss: 0.0035099 (Best: 0.0030020 @iter1394) ([92mâ†“19.96%[0m) [1.39% of initial]
[Iter 1460/20000] Loss: 0.0035351 (Best: 0.0029076 @iter1459) ([91mâ†‘0.72%[0m) [1.40% of initial]
[Iter 1460/20000] Loss: 0.0035351 (Best: 0.0029076 @iter1459) ([91mâ†‘0.72%[0m) [1.40% of initial]
[Iter 1470/20000] Loss: 0.0034121 (Best: 0.0029076 @iter1459) ([92mâ†“3.48%[0m) [1.36% of initial]
[Iter 1470/20000] Loss: 0.0034121 (Best: 0.0029076 @iter1459) ([92mâ†“3.48%[0m) [1.36% of initial]
[Iter 1480/20000] Loss: 0.0032993 (Best: 0.0027681 @iter1480) ([92mâ†“3.31%[0m) [1.31% of initial]
[Iter 1480/20000] Loss: 0.0032993 (Best: 0.0027681 @iter1480) ([92mâ†“3.31%[0m) [1.31% of initial]
[Iter 1490/20000] Loss: 0.0032108 (Best: 0.0027681 @iter1480) ([92mâ†“2.68%[0m) [1.28% of initial]
[Iter 1490/20000] Loss: 0.0032108 (Best: 0.0027681 @iter1480) ([92mâ†“2.68%[0m) [1.28% of initial]
Iter:1499, L1 loss=0.002628, Total loss=0.003301, Time:13
Iter:1499, L1 loss=0.002628, Total loss=0.003301, Time:13
[Iter 1500/20000] Loss: 0.0031942 (Best: 0.0027681 @iter1480) ([92mâ†“0.52%[0m) [1.27% of initial]
[Iter 1500/20000] Loss: 0.0031942 (Best: 0.0027681 @iter1480) ([92mâ†“0.52%[0m) [1.27% of initial]
[Iter 1510/20000] Loss: 0.0030330 (Best: 0.0025855 @iter1504) ([92mâ†“5.05%[0m) [1.20% of initial]
[Iter 1510/20000] Loss: 0.0030330 (Best: 0.0025855 @iter1504) ([92mâ†“5.05%[0m) [1.20% of initial]
[Iter 1520/20000] Loss: 0.0030070 (Best: 0.0025770 @iter1520) ([92mâ†“0.86%[0m) [1.19% of initial]
[Iter 1520/20000] Loss: 0.0030070 (Best: 0.0025770 @iter1520) ([92mâ†“0.86%[0m) [1.19% of initial]
[Iter 1530/20000] Loss: 0.0031093 (Best: 0.0025667 @iter1526) ([91mâ†‘3.40%[0m) [1.24% of initial]
[Iter 1530/20000] Loss: 0.0031093 (Best: 0.0025667 @iter1526) ([91mâ†‘3.40%[0m) [1.24% of initial]
[Iter 1540/20000] Loss: 0.0030313 (Best: 0.0025667 @iter1526) ([92mâ†“2.51%[0m) [1.20% of initial]
[Iter 1540/20000] Loss: 0.0030313 (Best: 0.0025667 @iter1526) ([92mâ†“2.51%[0m) [1.20% of initial]
[Iter 1550/20000] Loss: 0.0030381 (Best: 0.0025667 @iter1526) ([91mâ†‘0.22%[0m) [1.21% of initial]
[Iter 1550/20000] Loss: 0.0030381 (Best: 0.0025667 @iter1526) ([91mâ†‘0.22%[0m) [1.21% of initial]
[Iter 1560/20000] Loss: 0.0032427 (Best: 0.0025116 @iter1558) ([91mâ†‘6.73%[0m) [1.29% of initial]
[Iter 1560/20000] Loss: 0.0032427 (Best: 0.0025116 @iter1558) ([91mâ†‘6.73%[0m) [1.29% of initial]
[Iter 1570/20000] Loss: 0.0028689 (Best: 0.0025116 @iter1558) ([92mâ†“11.53%[0m) [1.14% of initial]
[Iter 1570/20000] Loss: 0.0028689 (Best: 0.0025116 @iter1558) ([92mâ†“11.53%[0m) [1.14% of initial]
[Iter 1580/20000] Loss: 0.0028212 (Best: 0.0023468 @iter1573) ([92mâ†“1.67%[0m) [1.12% of initial]
[Iter 1580/20000] Loss: 0.0028212 (Best: 0.0023468 @iter1573) ([92mâ†“1.67%[0m) [1.12% of initial]
[Iter 1590/20000] Loss: 0.0027021 (Best: 0.0023468 @iter1573) ([92mâ†“4.22%[0m) [1.07% of initial]
[Iter 1590/20000] Loss: 0.0027021 (Best: 0.0023468 @iter1573) ([92mâ†“4.22%[0m) [1.07% of initial]
Iter:1599, L1 loss=0.00271, Total loss=0.003367, Time:13
Iter:1599, L1 loss=0.00271, Total loss=0.003367, Time:13
[Iter 1600/20000] Loss: 0.0030720 (Best: 0.0022941 @iter1591) ([91mâ†‘13.69%[0m) [1.22% of initial]
[Iter 1600/20000] Loss: 0.0030720 (Best: 0.0022941 @iter1591) ([91mâ†‘13.69%[0m) [1.22% of initial]
[Iter 1610/20000] Loss: 0.0083737 (Best: 0.0022941 @iter1591) ([91mâ†‘172.58%[0m) [3.33% of initial]
[Iter 1610/20000] Loss: 0.0083737 (Best: 0.0022941 @iter1591) ([91mâ†‘172.58%[0m) [3.33% of initial]
[Iter 1620/20000] Loss: 0.0053207 (Best: 0.0022941 @iter1591) ([92mâ†“36.46%[0m) [2.11% of initial]
[Iter 1620/20000] Loss: 0.0053207 (Best: 0.0022941 @iter1591) ([92mâ†“36.46%[0m) [2.11% of initial]
[Iter 1630/20000] Loss: 0.0040729 (Best: 0.0022941 @iter1591) ([92mâ†“23.45%[0m) [1.62% of initial]
[Iter 1630/20000] Loss: 0.0040729 (Best: 0.0022941 @iter1591) ([92mâ†“23.45%[0m) [1.62% of initial]
[Iter 1640/20000] Loss: 0.0038738 (Best: 0.0022941 @iter1591) ([92mâ†“4.89%[0m) [1.54% of initial]
[Iter 1640/20000] Loss: 0.0038738 (Best: 0.0022941 @iter1591) ([92mâ†“4.89%[0m) [1.54% of initial]
[Iter 1650/20000] Loss: 0.0033793 (Best: 0.0022941 @iter1591) ([92mâ†“12.77%[0m) [1.34% of initial]
[Iter 1650/20000] Loss: 0.0033793 (Best: 0.0022941 @iter1591) ([92mâ†“12.77%[0m) [1.34% of initial]
[Iter 1660/20000] Loss: 0.0029043 (Best: 0.0022941 @iter1591) ([92mâ†“14.06%[0m) [1.15% of initial]
[Iter 1660/20000] Loss: 0.0029043 (Best: 0.0022941 @iter1591) ([92mâ†“14.06%[0m) [1.15% of initial]
[Iter 1670/20000] Loss: 0.0026979 (Best: 0.0022461 @iter1669) ([92mâ†“7.11%[0m) [1.07% of initial]
[Iter 1670/20000] Loss: 0.0026979 (Best: 0.0022461 @iter1669) ([92mâ†“7.11%[0m) [1.07% of initial]
[Iter 1680/20000] Loss: 0.0028724 (Best: 0.0022461 @iter1669) ([91mâ†‘6.47%[0m) [1.14% of initial]
[Iter 1680/20000] Loss: 0.0028724 (Best: 0.0022461 @iter1669) ([91mâ†‘6.47%[0m) [1.14% of initial]
[Iter 1690/20000] Loss: 0.0030466 (Best: 0.0022461 @iter1669) ([91mâ†‘6.06%[0m) [1.21% of initial]
[Iter 1690/20000] Loss: 0.0030466 (Best: 0.0022461 @iter1669) ([91mâ†‘6.06%[0m) [1.21% of initial]
Iter:1699, L1 loss=0.002568, Total loss=0.003164, Time:14
Iter:1699, L1 loss=0.002568, Total loss=0.003164, Time:14
[Iter 1700/20000] Loss: 0.0027774 (Best: 0.0022461 @iter1669) ([92mâ†“8.83%[0m) [1.10% of initial]
[Iter 1700/20000] Loss: 0.0027774 (Best: 0.0022461 @iter1669) ([92mâ†“8.83%[0m) [1.10% of initial]
[Iter 1710/20000] Loss: 0.0029364 (Best: 0.0022461 @iter1669) ([91mâ†‘5.73%[0m) [1.17% of initial]
[Iter 1710/20000] Loss: 0.0029364 (Best: 0.0022461 @iter1669) ([91mâ†‘5.73%[0m) [1.17% of initial]
[Iter 1720/20000] Loss: 0.0025260 (Best: 0.0022289 @iter1715) ([92mâ†“13.98%[0m) [1.00% of initial]
[Iter 1720/20000] Loss: 0.0025260 (Best: 0.0022289 @iter1715) ([92mâ†“13.98%[0m) [1.00% of initial]
[Iter 1730/20000] Loss: 0.0026393 (Best: 0.0022289 @iter1715) ([91mâ†‘4.49%[0m) [1.05% of initial]
[Iter 1730/20000] Loss: 0.0026393 (Best: 0.0022289 @iter1715) ([91mâ†‘4.49%[0m) [1.05% of initial]
[Iter 1740/20000] Loss: 0.0026273 (Best: 0.0022271 @iter1738) ([92mâ†“0.46%[0m) [1.04% of initial]
[Iter 1740/20000] Loss: 0.0026273 (Best: 0.0022271 @iter1738) ([92mâ†“0.46%[0m) [1.04% of initial]
[Iter 1750/20000] Loss: 0.0023780 (Best: 0.0021381 @iter1742) ([92mâ†“9.49%[0m) [0.94% of initial]
[Iter 1750/20000] Loss: 0.0023780 (Best: 0.0021381 @iter1742) ([92mâ†“9.49%[0m) [0.94% of initial]
[Iter 1760/20000] Loss: 0.0026346 (Best: 0.0021381 @iter1742) ([91mâ†‘10.79%[0m) [1.05% of initial]
[Iter 1760/20000] Loss: 0.0026346 (Best: 0.0021381 @iter1742) ([91mâ†‘10.79%[0m) [1.05% of initial]
[Iter 1770/20000] Loss: 0.0024193 (Best: 0.0020959 @iter1762) ([92mâ†“8.17%[0m) [0.96% of initial]
[Iter 1770/20000] Loss: 0.0024193 (Best: 0.0020959 @iter1762) ([92mâ†“8.17%[0m) [0.96% of initial]
[Iter 1780/20000] Loss: 0.0024524 (Best: 0.0020845 @iter1771) ([91mâ†‘1.37%[0m) [0.97% of initial]
[Iter 1780/20000] Loss: 0.0024524 (Best: 0.0020845 @iter1771) ([91mâ†‘1.37%[0m) [0.97% of initial]
[Iter 1790/20000] Loss: 0.0021747 (Best: 0.0018077 @iter1789) ([92mâ†“11.32%[0m) [0.86% of initial]
[Iter 1790/20000] Loss: 0.0021747 (Best: 0.0018077 @iter1789) ([92mâ†“11.32%[0m) [0.86% of initial]
Iter:1799, L1 loss=0.001693, Total loss=0.001925, Time:14
Iter:1799, L1 loss=0.001693, Total loss=0.001925, Time:14
[Iter 1800/20000] Loss: 0.0021650 (Best: 0.0018077 @iter1789) ([92mâ†“0.44%[0m) [0.86% of initial]
[Iter 1800/20000] Loss: 0.0021650 (Best: 0.0018077 @iter1789) ([92mâ†“0.44%[0m) [0.86% of initial]
[Iter 1810/20000] Loss: 0.0076185 (Best: 0.0018077 @iter1789) ([91mâ†‘251.89%[0m) [3.03% of initial]
[Iter 1810/20000] Loss: 0.0076185 (Best: 0.0018077 @iter1789) ([91mâ†‘251.89%[0m) [3.03% of initial]
[Iter 1820/20000] Loss: 0.0044429 (Best: 0.0018077 @iter1789) ([92mâ†“41.68%[0m) [1.77% of initial]
[Iter 1820/20000] Loss: 0.0044429 (Best: 0.0018077 @iter1789) ([92mâ†“41.68%[0m) [1.77% of initial]
[Iter 1830/20000] Loss: 0.0039384 (Best: 0.0018077 @iter1789) ([92mâ†“11.36%[0m) [1.56% of initial]
[Iter 1830/20000] Loss: 0.0039384 (Best: 0.0018077 @iter1789) ([92mâ†“11.36%[0m) [1.56% of initial]
[Iter 1840/20000] Loss: 0.0027575 (Best: 0.0018077 @iter1789) ([92mâ†“29.98%[0m) [1.10% of initial]
[Iter 1840/20000] Loss: 0.0027575 (Best: 0.0018077 @iter1789) ([92mâ†“29.98%[0m) [1.10% of initial]
[Iter 1850/20000] Loss: 0.0026272 (Best: 0.0018077 @iter1789) ([92mâ†“4.73%[0m) [1.04% of initial]
[Iter 1850/20000] Loss: 0.0026272 (Best: 0.0018077 @iter1789) ([92mâ†“4.73%[0m) [1.04% of initial]
[Iter 1860/20000] Loss: 0.0023710 (Best: 0.0018077 @iter1789) ([92mâ†“9.75%[0m) [0.94% of initial]
[Iter 1860/20000] Loss: 0.0023710 (Best: 0.0018077 @iter1789) ([92mâ†“9.75%[0m) [0.94% of initial]
[Iter 1870/20000] Loss: 0.0022475 (Best: 0.0018077 @iter1789) ([92mâ†“5.21%[0m) [0.89% of initial]
[Iter 1870/20000] Loss: 0.0022475 (Best: 0.0018077 @iter1789) ([92mâ†“5.21%[0m) [0.89% of initial]
[Iter 1880/20000] Loss: 0.0021118 (Best: 0.0018077 @iter1789) ([92mâ†“6.03%[0m) [0.84% of initial]
[Iter 1880/20000] Loss: 0.0021118 (Best: 0.0018077 @iter1789) ([92mâ†“6.03%[0m) [0.84% of initial]
[Iter 1890/20000] Loss: 0.0018878 (Best: 0.0017169 @iter1890) ([92mâ†“10.61%[0m) [0.75% of initial]
[Iter 1890/20000] Loss: 0.0018878 (Best: 0.0017169 @iter1890) ([92mâ†“10.61%[0m) [0.75% of initial]
Iter:1899, L1 loss=0.001756, Total loss=0.001889, Time:13
Iter:1899, L1 loss=0.001756, Total loss=0.001889, Time:13
[Iter 1900/20000] Loss: 0.0019664 (Best: 0.0015890 @iter1891) ([91mâ†‘4.16%[0m) [0.78% of initial]
[Iter 1900/20000] Loss: 0.0019664 (Best: 0.0015890 @iter1891) ([91mâ†‘4.16%[0m) [0.78% of initial]
[Iter 1910/20000] Loss: 0.0020467 (Best: 0.0015890 @iter1891) ([91mâ†‘4.09%[0m) [0.81% of initial]
[Iter 1910/20000] Loss: 0.0020467 (Best: 0.0015890 @iter1891) ([91mâ†‘4.09%[0m) [0.81% of initial]
[Iter 1920/20000] Loss: 0.0020881 (Best: 0.0015890 @iter1891) ([91mâ†‘2.02%[0m) [0.83% of initial]
[Iter 1920/20000] Loss: 0.0020881 (Best: 0.0015890 @iter1891) ([91mâ†‘2.02%[0m) [0.83% of initial]
[Iter 1930/20000] Loss: 0.0017517 (Best: 0.0015675 @iter1930) ([92mâ†“16.11%[0m) [0.70% of initial]
[Iter 1930/20000] Loss: 0.0017517 (Best: 0.0015675 @iter1930) ([92mâ†“16.11%[0m) [0.70% of initial]
[Iter 1940/20000] Loss: 0.0019250 (Best: 0.0015619 @iter1939) ([91mâ†‘9.89%[0m) [0.76% of initial]
[Iter 1940/20000] Loss: 0.0019250 (Best: 0.0015619 @iter1939) ([91mâ†‘9.89%[0m) [0.76% of initial]
[Iter 1950/20000] Loss: 0.0020812 (Best: 0.0015619 @iter1939) ([91mâ†‘8.11%[0m) [0.83% of initial]
[Iter 1950/20000] Loss: 0.0020812 (Best: 0.0015619 @iter1939) ([91mâ†‘8.11%[0m) [0.83% of initial]
[Iter 1960/20000] Loss: 0.0018402 (Best: 0.0015619 @iter1939) ([92mâ†“11.58%[0m) [0.73% of initial]
[Iter 1960/20000] Loss: 0.0018402 (Best: 0.0015619 @iter1939) ([92mâ†“11.58%[0m) [0.73% of initial]
[Iter 1970/20000] Loss: 0.0016844 (Best: 0.0014912 @iter1963) ([92mâ†“8.46%[0m) [0.67% of initial]
[Iter 1970/20000] Loss: 0.0016844 (Best: 0.0014912 @iter1963) ([92mâ†“8.46%[0m) [0.67% of initial]
[Iter 1980/20000] Loss: 0.0020318 (Best: 0.0014912 @iter1963) ([91mâ†‘20.62%[0m) [0.81% of initial]
[Iter 1980/20000] Loss: 0.0020318 (Best: 0.0014912 @iter1963) ([91mâ†‘20.62%[0m) [0.81% of initial]
[Iter 1990/20000] Loss: 0.0017726 (Best: 0.0014912 @iter1963) ([92mâ†“12.76%[0m) [0.70% of initial]
[Iter 1990/20000] Loss: 0.0017726 (Best: 0.0014912 @iter1963) ([92mâ†“12.76%[0m) [0.70% of initial]
Iter:1999, L1 loss=0.001496, Total loss=0.001688, Time:14
Iter:1999, L1 loss=0.001496, Total loss=0.001688, Time:14
[Iter 2000/20000] Loss: 0.0019066 (Best: 0.0014440 @iter1996) ([91mâ†‘7.56%[0m) [0.76% of initial]
[Iter 2000/20000] Loss: 0.0019066 (Best: 0.0014440 @iter1996) ([91mâ†‘7.56%[0m) [0.76% of initial]
Testing Speed: 230.08004493750877 fps
Testing Speed: 230.08004493750877 fps
Testing Time: 0.217315673828125 s
Testing Time: 0.217315673828125 s

[ITER 2000] Evaluating test: SSIM = 0.8517311704158783, PSNR = 17.86451017379761

[ITER 2000] Evaluating test: SSIM = 0.8517311704158783, PSNR = 17.86451017379761
Testing Speed: 266.1979733017411 fps
Testing Speed: 266.1979733017411 fps
Testing Time: 0.011269807815551758 s
Testing Time: 0.011269807815551758 s

[ITER 2000] Evaluating train: SSIM = 0.9999508460362752, PSNR = 49.11960983276367

[ITER 2000] Evaluating train: SSIM = 0.9999508460362752, PSNR = 49.11960983276367
Iter:2000, total_points:43188
Iter:2000, total_points:43188
[Iter 2010/20000] Loss: 0.0066659 (Best: 0.0014440 @iter1996) ([91mâ†‘249.61%[0m) [2.65% of initial]
[Iter 2010/20000] Loss: 0.0066659 (Best: 0.0014440 @iter1996) ([91mâ†‘249.61%[0m) [2.65% of initial]
[Iter 2020/20000] Loss: 0.0037287 (Best: 0.0014440 @iter1996) ([92mâ†“44.06%[0m) [1.48% of initial]
[Iter 2020/20000] Loss: 0.0037287 (Best: 0.0014440 @iter1996) ([92mâ†“44.06%[0m) [1.48% of initial]
[Iter 2030/20000] Loss: 0.0028463 (Best: 0.0014440 @iter1996) ([92mâ†“23.67%[0m) [1.13% of initial]
[Iter 2030/20000] Loss: 0.0028463 (Best: 0.0014440 @iter1996) ([92mâ†“23.67%[0m) [1.13% of initial]
[Iter 2040/20000] Loss: 0.0024982 (Best: 0.0014440 @iter1996) ([92mâ†“12.23%[0m) [0.99% of initial]
[Iter 2040/20000] Loss: 0.0024982 (Best: 0.0014440 @iter1996) ([92mâ†“12.23%[0m) [0.99% of initial]
[Iter 2050/20000] Loss: 0.0020582 (Best: 0.0014440 @iter1996) ([92mâ†“17.61%[0m) [0.82% of initial]
[Iter 2050/20000] Loss: 0.0020582 (Best: 0.0014440 @iter1996) ([92mâ†“17.61%[0m) [0.82% of initial]
[Iter 2060/20000] Loss: 0.0017213 (Best: 0.0014440 @iter1996) ([92mâ†“16.37%[0m) [0.68% of initial]
[Iter 2060/20000] Loss: 0.0017213 (Best: 0.0014440 @iter1996) ([92mâ†“16.37%[0m) [0.68% of initial]
[Iter 2070/20000] Loss: 0.0019735 (Best: 0.0014440 @iter1996) ([91mâ†‘14.65%[0m) [0.78% of initial]
[Iter 2070/20000] Loss: 0.0019735 (Best: 0.0014440 @iter1996) ([91mâ†‘14.65%[0m) [0.78% of initial]
[Iter 2080/20000] Loss: 0.0018752 (Best: 0.0014440 @iter1996) ([92mâ†“4.98%[0m) [0.74% of initial]
[Iter 2080/20000] Loss: 0.0018752 (Best: 0.0014440 @iter1996) ([92mâ†“4.98%[0m) [0.74% of initial]
[Iter 2090/20000] Loss: 0.0018079 (Best: 0.0014129 @iter2089) ([92mâ†“3.59%[0m) [0.72% of initial]
[Iter 2090/20000] Loss: 0.0018079 (Best: 0.0014129 @iter2089) ([92mâ†“3.59%[0m) [0.72% of initial]
Iter:2099, L1 loss=0.001594, Total loss=0.0017, Time:15
Iter:2099, L1 loss=0.001594, Total loss=0.0017, Time:15
[Iter 2100/20000] Loss: 0.0016948 (Best: 0.0014129 @iter2089) ([92mâ†“6.26%[0m) [0.67% of initial]
[Iter 2100/20000] Loss: 0.0016948 (Best: 0.0014129 @iter2089) ([92mâ†“6.26%[0m) [0.67% of initial]
[Iter 2110/20000] Loss: 0.0015839 (Best: 0.0014129 @iter2089) ([92mâ†“6.54%[0m) [0.63% of initial]
[Iter 2110/20000] Loss: 0.0015839 (Best: 0.0014129 @iter2089) ([92mâ†“6.54%[0m) [0.63% of initial]
[Iter 2120/20000] Loss: 0.0014286 (Best: 0.0012930 @iter2120) ([92mâ†“9.80%[0m) [0.57% of initial]
[Iter 2120/20000] Loss: 0.0014286 (Best: 0.0012930 @iter2120) ([92mâ†“9.80%[0m) [0.57% of initial]
[Iter 2130/20000] Loss: 0.0015920 (Best: 0.0012231 @iter2125) ([91mâ†‘11.44%[0m) [0.63% of initial]
[Iter 2130/20000] Loss: 0.0015920 (Best: 0.0012231 @iter2125) ([91mâ†‘11.44%[0m) [0.63% of initial]
[Iter 2140/20000] Loss: 0.0017049 (Best: 0.0012231 @iter2125) ([91mâ†‘7.09%[0m) [0.68% of initial]
[Iter 2140/20000] Loss: 0.0017049 (Best: 0.0012231 @iter2125) ([91mâ†‘7.09%[0m) [0.68% of initial]
[Iter 2150/20000] Loss: 0.0017383 (Best: 0.0012231 @iter2125) ([91mâ†‘1.96%[0m) [0.69% of initial]
[Iter 2150/20000] Loss: 0.0017383 (Best: 0.0012231 @iter2125) ([91mâ†‘1.96%[0m) [0.69% of initial]
[Iter 2160/20000] Loss: 0.0015923 (Best: 0.0012231 @iter2125) ([92mâ†“8.40%[0m) [0.63% of initial]
[Iter 2160/20000] Loss: 0.0015923 (Best: 0.0012231 @iter2125) ([92mâ†“8.40%[0m) [0.63% of initial]
[Iter 2170/20000] Loss: 0.0016146 (Best: 0.0012231 @iter2125) ([91mâ†‘1.40%[0m) [0.64% of initial]
[Iter 2170/20000] Loss: 0.0016146 (Best: 0.0012231 @iter2125) ([91mâ†‘1.40%[0m) [0.64% of initial]
[Iter 2180/20000] Loss: 0.0013476 (Best: 0.0012231 @iter2125) ([92mâ†“16.54%[0m) [0.54% of initial]
[Iter 2180/20000] Loss: 0.0013476 (Best: 0.0012231 @iter2125) ([92mâ†“16.54%[0m) [0.54% of initial]
[Iter 2190/20000] Loss: 0.0015892 (Best: 0.0012231 @iter2125) ([91mâ†‘17.93%[0m) [0.63% of initial]
[Iter 2190/20000] Loss: 0.0015892 (Best: 0.0012231 @iter2125) ([91mâ†‘17.93%[0m) [0.63% of initial]
Iter:2199, L1 loss=0.001458, Total loss=0.001526, Time:16
Iter:2199, L1 loss=0.001458, Total loss=0.001526, Time:16
[Iter 2200/20000] Loss: 0.0015879 (Best: 0.0012231 @iter2125) ([92mâ†“0.08%[0m) [0.63% of initial]
[Iter 2200/20000] Loss: 0.0015879 (Best: 0.0012231 @iter2125) ([92mâ†“0.08%[0m) [0.63% of initial]
[Iter 2210/20000] Loss: 0.0079680 (Best: 0.0012231 @iter2125) ([91mâ†‘401.80%[0m) [3.17% of initial]
[Iter 2210/20000] Loss: 0.0079680 (Best: 0.0012231 @iter2125) ([91mâ†‘401.80%[0m) [3.17% of initial]
[Iter 2220/20000] Loss: 0.0043428 (Best: 0.0012231 @iter2125) ([92mâ†“45.50%[0m) [1.73% of initial]
[Iter 2220/20000] Loss: 0.0043428 (Best: 0.0012231 @iter2125) ([92mâ†“45.50%[0m) [1.73% of initial]
[Iter 2230/20000] Loss: 0.0026793 (Best: 0.0012231 @iter2125) ([92mâ†“38.31%[0m) [1.06% of initial]
[Iter 2230/20000] Loss: 0.0026793 (Best: 0.0012231 @iter2125) ([92mâ†“38.31%[0m) [1.06% of initial]
[Iter 2240/20000] Loss: 0.0022858 (Best: 0.0012231 @iter2125) ([92mâ†“14.69%[0m) [0.91% of initial]
[Iter 2240/20000] Loss: 0.0022858 (Best: 0.0012231 @iter2125) ([92mâ†“14.69%[0m) [0.91% of initial]
[Iter 2250/20000] Loss: 0.0021165 (Best: 0.0012231 @iter2125) ([92mâ†“7.41%[0m) [0.84% of initial]
[Iter 2250/20000] Loss: 0.0021165 (Best: 0.0012231 @iter2125) ([92mâ†“7.41%[0m) [0.84% of initial]
[Iter 2260/20000] Loss: 0.0017172 (Best: 0.0012231 @iter2125) ([92mâ†“18.86%[0m) [0.68% of initial]
[Iter 2260/20000] Loss: 0.0017172 (Best: 0.0012231 @iter2125) ([92mâ†“18.86%[0m) [0.68% of initial]
[Iter 2270/20000] Loss: 0.0018301 (Best: 0.0012231 @iter2125) ([91mâ†‘6.57%[0m) [0.73% of initial]
[Iter 2270/20000] Loss: 0.0018301 (Best: 0.0012231 @iter2125) ([91mâ†‘6.57%[0m) [0.73% of initial]
[Iter 2280/20000] Loss: 0.0014707 (Best: 0.0012231 @iter2125) ([92mâ†“19.64%[0m) [0.58% of initial]
[Iter 2280/20000] Loss: 0.0014707 (Best: 0.0012231 @iter2125) ([92mâ†“19.64%[0m) [0.58% of initial]
[Iter 2290/20000] Loss: 0.0014241 (Best: 0.0011960 @iter2285) ([92mâ†“3.17%[0m) [0.57% of initial]
[Iter 2290/20000] Loss: 0.0014241 (Best: 0.0011960 @iter2285) ([92mâ†“3.17%[0m) [0.57% of initial]
Iter:2299, L1 loss=0.001281, Total loss=0.001478, Time:15
Iter:2299, L1 loss=0.001281, Total loss=0.001478, Time:15
[Iter 2300/20000] Loss: 0.0017630 (Best: 0.0011960 @iter2285) ([91mâ†‘23.80%[0m) [0.70% of initial]
[Iter 2300/20000] Loss: 0.0017630 (Best: 0.0011960 @iter2285) ([91mâ†‘23.80%[0m) [0.70% of initial]
[Iter 2310/20000] Loss: 0.0015605 (Best: 0.0011960 @iter2285) ([92mâ†“11.49%[0m) [0.62% of initial]
[Iter 2310/20000] Loss: 0.0015605 (Best: 0.0011960 @iter2285) ([92mâ†“11.49%[0m) [0.62% of initial]
[Iter 2320/20000] Loss: 0.0013107 (Best: 0.0011700 @iter2320) ([92mâ†“16.01%[0m) [0.52% of initial]
[Iter 2320/20000] Loss: 0.0013107 (Best: 0.0011700 @iter2320) ([92mâ†“16.01%[0m) [0.52% of initial]
[Iter 2330/20000] Loss: 0.0012913 (Best: 0.0011132 @iter2327) ([92mâ†“1.47%[0m) [0.51% of initial]
[Iter 2330/20000] Loss: 0.0012913 (Best: 0.0011132 @iter2327) ([92mâ†“1.47%[0m) [0.51% of initial]
[Iter 2340/20000] Loss: 0.0013510 (Best: 0.0011050 @iter2338) ([91mâ†‘4.62%[0m) [0.54% of initial]
[Iter 2340/20000] Loss: 0.0013510 (Best: 0.0011050 @iter2338) ([91mâ†‘4.62%[0m) [0.54% of initial]
[Iter 2350/20000] Loss: 0.0015044 (Best: 0.0011050 @iter2338) ([91mâ†‘11.36%[0m) [0.60% of initial]
[Iter 2350/20000] Loss: 0.0015044 (Best: 0.0011050 @iter2338) ([91mâ†‘11.36%[0m) [0.60% of initial]
[Iter 2360/20000] Loss: 0.0013122 (Best: 0.0011050 @iter2338) ([92mâ†“12.78%[0m) [0.52% of initial]
[Iter 2360/20000] Loss: 0.0013122 (Best: 0.0011050 @iter2338) ([92mâ†“12.78%[0m) [0.52% of initial]
[Iter 2370/20000] Loss: 0.0014097 (Best: 0.0011050 @iter2338) ([91mâ†‘7.43%[0m) [0.56% of initial]
[Iter 2370/20000] Loss: 0.0014097 (Best: 0.0011050 @iter2338) ([91mâ†‘7.43%[0m) [0.56% of initial]
[Iter 2380/20000] Loss: 0.0014880 (Best: 0.0011050 @iter2338) ([91mâ†‘5.56%[0m) [0.59% of initial]
[Iter 2380/20000] Loss: 0.0014880 (Best: 0.0011050 @iter2338) ([91mâ†‘5.56%[0m) [0.59% of initial]
[Iter 2390/20000] Loss: 0.0016085 (Best: 0.0011050 @iter2338) ([91mâ†‘8.10%[0m) [0.64% of initial]
[Iter 2390/20000] Loss: 0.0016085 (Best: 0.0011050 @iter2338) ([91mâ†‘8.10%[0m) [0.64% of initial]
Iter:2399, L1 loss=0.00123, Total loss=0.001306, Time:14
Iter:2399, L1 loss=0.00123, Total loss=0.001306, Time:14
[Iter 2400/20000] Loss: 0.0013480 (Best: 0.0011050 @iter2338) ([92mâ†“16.20%[0m) [0.54% of initial]
[Iter 2400/20000] Loss: 0.0013480 (Best: 0.0011050 @iter2338) ([92mâ†“16.20%[0m) [0.54% of initial]
[Iter 2410/20000] Loss: 0.0061113 (Best: 0.0011050 @iter2338) ([91mâ†‘353.36%[0m) [2.43% of initial]
[Iter 2410/20000] Loss: 0.0061113 (Best: 0.0011050 @iter2338) ([91mâ†‘353.36%[0m) [2.43% of initial]
[Iter 2420/20000] Loss: 0.0034878 (Best: 0.0011050 @iter2338) ([92mâ†“42.93%[0m) [1.39% of initial]
[Iter 2420/20000] Loss: 0.0034878 (Best: 0.0011050 @iter2338) ([92mâ†“42.93%[0m) [1.39% of initial]
[Iter 2430/20000] Loss: 0.0025936 (Best: 0.0011050 @iter2338) ([92mâ†“25.64%[0m) [1.03% of initial]
[Iter 2430/20000] Loss: 0.0025936 (Best: 0.0011050 @iter2338) ([92mâ†“25.64%[0m) [1.03% of initial]
[Iter 2440/20000] Loss: 0.0020421 (Best: 0.0011050 @iter2338) ([92mâ†“21.26%[0m) [0.81% of initial]
[Iter 2440/20000] Loss: 0.0020421 (Best: 0.0011050 @iter2338) ([92mâ†“21.26%[0m) [0.81% of initial]
[Iter 2450/20000] Loss: 0.0019604 (Best: 0.0011050 @iter2338) ([92mâ†“4.00%[0m) [0.78% of initial]
[Iter 2450/20000] Loss: 0.0019604 (Best: 0.0011050 @iter2338) ([92mâ†“4.00%[0m) [0.78% of initial]
[Iter 2460/20000] Loss: 0.0016919 (Best: 0.0011050 @iter2338) ([92mâ†“13.69%[0m) [0.67% of initial]
[Iter 2460/20000] Loss: 0.0016919 (Best: 0.0011050 @iter2338) ([92mâ†“13.69%[0m) [0.67% of initial]
[Iter 2470/20000] Loss: 0.0016763 (Best: 0.0011050 @iter2338) ([92mâ†“0.92%[0m) [0.67% of initial]
[Iter 2470/20000] Loss: 0.0016763 (Best: 0.0011050 @iter2338) ([92mâ†“0.92%[0m) [0.67% of initial]
[Iter 2480/20000] Loss: 0.0016986 (Best: 0.0011050 @iter2338) ([91mâ†‘1.33%[0m) [0.67% of initial]
[Iter 2480/20000] Loss: 0.0016986 (Best: 0.0011050 @iter2338) ([91mâ†‘1.33%[0m) [0.67% of initial]
[Iter 2490/20000] Loss: 0.0014873 (Best: 0.0011050 @iter2338) ([92mâ†“12.44%[0m) [0.59% of initial]
[Iter 2490/20000] Loss: 0.0014873 (Best: 0.0011050 @iter2338) ([92mâ†“12.44%[0m) [0.59% of initial]
Iter:2499, L1 loss=0.00121, Total loss=0.001238, Time:17
Iter:2499, L1 loss=0.00121, Total loss=0.001238, Time:17
[Iter 2500/20000] Loss: 0.0013036 (Best: 0.0011050 @iter2338) ([92mâ†“12.35%[0m) [0.52% of initial]
[Iter 2500/20000] Loss: 0.0013036 (Best: 0.0011050 @iter2338) ([92mâ†“12.35%[0m) [0.52% of initial]
[Iter 2510/20000] Loss: 0.0013616 (Best: 0.0010396 @iter2504) ([91mâ†‘4.46%[0m) [0.54% of initial]
[Iter 2510/20000] Loss: 0.0013616 (Best: 0.0010396 @iter2504) ([91mâ†‘4.46%[0m) [0.54% of initial]
[Iter 2520/20000] Loss: 0.0012312 (Best: 0.0009997 @iter2519) ([92mâ†“9.58%[0m) [0.49% of initial]
[Iter 2520/20000] Loss: 0.0012312 (Best: 0.0009997 @iter2519) ([92mâ†“9.58%[0m) [0.49% of initial]
[Iter 2530/20000] Loss: 0.0011107 (Best: 0.0009715 @iter2528) ([92mâ†“9.79%[0m) [0.44% of initial]
[Iter 2530/20000] Loss: 0.0011107 (Best: 0.0009715 @iter2528) ([92mâ†“9.79%[0m) [0.44% of initial]
[Iter 2540/20000] Loss: 0.0012009 (Best: 0.0009715 @iter2528) ([91mâ†‘8.12%[0m) [0.48% of initial]
[Iter 2540/20000] Loss: 0.0012009 (Best: 0.0009715 @iter2528) ([91mâ†‘8.12%[0m) [0.48% of initial]
[Iter 2550/20000] Loss: 0.0014044 (Best: 0.0009715 @iter2528) ([91mâ†‘16.95%[0m) [0.56% of initial]
[Iter 2550/20000] Loss: 0.0014044 (Best: 0.0009715 @iter2528) ([91mâ†‘16.95%[0m) [0.56% of initial]
[Iter 2560/20000] Loss: 0.0011707 (Best: 0.0009707 @iter2557) ([92mâ†“16.64%[0m) [0.47% of initial]
[Iter 2560/20000] Loss: 0.0011707 (Best: 0.0009707 @iter2557) ([92mâ†“16.64%[0m) [0.47% of initial]
[Iter 2570/20000] Loss: 0.0014235 (Best: 0.0009707 @iter2557) ([91mâ†‘21.59%[0m) [0.57% of initial]
[Iter 2570/20000] Loss: 0.0014235 (Best: 0.0009707 @iter2557) ([91mâ†‘21.59%[0m) [0.57% of initial]
[Iter 2580/20000] Loss: 0.0012661 (Best: 0.0009270 @iter2578) ([92mâ†“11.06%[0m) [0.50% of initial]
[Iter 2580/20000] Loss: 0.0012661 (Best: 0.0009270 @iter2578) ([92mâ†“11.06%[0m) [0.50% of initial]
[Iter 2590/20000] Loss: 0.0013089 (Best: 0.0009270 @iter2578) ([91mâ†‘3.38%[0m) [0.52% of initial]
[Iter 2590/20000] Loss: 0.0013089 (Best: 0.0009270 @iter2578) ([91mâ†‘3.38%[0m) [0.52% of initial]
Iter:2599, L1 loss=0.001054, Total loss=0.001008, Time:16
Iter:2599, L1 loss=0.001054, Total loss=0.001008, Time:16
[Iter 2600/20000] Loss: 0.0011908 (Best: 0.0009210 @iter2594) ([92mâ†“9.02%[0m) [0.47% of initial]
[Iter 2600/20000] Loss: 0.0011908 (Best: 0.0009210 @iter2594) ([92mâ†“9.02%[0m) [0.47% of initial]
[Iter 2610/20000] Loss: 0.0060264 (Best: 0.0009210 @iter2594) ([91mâ†‘406.07%[0m) [2.39% of initial]
[Iter 2610/20000] Loss: 0.0060264 (Best: 0.0009210 @iter2594) ([91mâ†‘406.07%[0m) [2.39% of initial]
[Iter 2620/20000] Loss: 0.0033234 (Best: 0.0009210 @iter2594) ([92mâ†“44.85%[0m) [1.32% of initial]
[Iter 2620/20000] Loss: 0.0033234 (Best: 0.0009210 @iter2594) ([92mâ†“44.85%[0m) [1.32% of initial]
[Iter 2630/20000] Loss: 0.0022542 (Best: 0.0009210 @iter2594) ([92mâ†“32.17%[0m) [0.90% of initial]
[Iter 2630/20000] Loss: 0.0022542 (Best: 0.0009210 @iter2594) ([92mâ†“32.17%[0m) [0.90% of initial]
[Iter 2640/20000] Loss: 0.0017778 (Best: 0.0009210 @iter2594) ([92mâ†“21.14%[0m) [0.71% of initial]
[Iter 2640/20000] Loss: 0.0017778 (Best: 0.0009210 @iter2594) ([92mâ†“21.14%[0m) [0.71% of initial]
[Iter 2650/20000] Loss: 0.0014611 (Best: 0.0009210 @iter2594) ([92mâ†“17.81%[0m) [0.58% of initial]
[Iter 2650/20000] Loss: 0.0014611 (Best: 0.0009210 @iter2594) ([92mâ†“17.81%[0m) [0.58% of initial]
[Iter 2660/20000] Loss: 0.0016189 (Best: 0.0009210 @iter2594) ([91mâ†‘10.80%[0m) [0.64% of initial]
[Iter 2660/20000] Loss: 0.0016189 (Best: 0.0009210 @iter2594) ([91mâ†‘10.80%[0m) [0.64% of initial]
[Iter 2670/20000] Loss: 0.0015562 (Best: 0.0009210 @iter2594) ([92mâ†“3.87%[0m) [0.62% of initial]
[Iter 2670/20000] Loss: 0.0015562 (Best: 0.0009210 @iter2594) ([92mâ†“3.87%[0m) [0.62% of initial]
[Iter 2680/20000] Loss: 0.0012256 (Best: 0.0009210 @iter2594) ([92mâ†“21.24%[0m) [0.49% of initial]
[Iter 2680/20000] Loss: 0.0012256 (Best: 0.0009210 @iter2594) ([92mâ†“21.24%[0m) [0.49% of initial]
[Iter 2690/20000] Loss: 0.0011885 (Best: 0.0009210 @iter2594) ([92mâ†“3.03%[0m) [0.47% of initial]
[Iter 2690/20000] Loss: 0.0011885 (Best: 0.0009210 @iter2594) ([92mâ†“3.03%[0m) [0.47% of initial]
Iter:2699, L1 loss=0.00114, Total loss=0.001157, Time:16
Iter:2699, L1 loss=0.00114, Total loss=0.001157, Time:16
[Iter 2700/20000] Loss: 0.0014467 (Best: 0.0009210 @iter2594) ([91mâ†‘21.73%[0m) [0.57% of initial]
[Iter 2700/20000] Loss: 0.0014467 (Best: 0.0009210 @iter2594) ([91mâ†‘21.73%[0m) [0.57% of initial]
[Iter 2710/20000] Loss: 0.0012612 (Best: 0.0009210 @iter2594) ([92mâ†“12.82%[0m) [0.50% of initial]
[Iter 2710/20000] Loss: 0.0012612 (Best: 0.0009210 @iter2594) ([92mâ†“12.82%[0m) [0.50% of initial]
[Iter 2720/20000] Loss: 0.0011277 (Best: 0.0009210 @iter2594) ([92mâ†“10.59%[0m) [0.45% of initial]
[Iter 2720/20000] Loss: 0.0011277 (Best: 0.0009210 @iter2594) ([92mâ†“10.59%[0m) [0.45% of initial]
[Iter 2730/20000] Loss: 0.0010149 (Best: 0.0008751 @iter2727) ([92mâ†“10.00%[0m) [0.40% of initial]
[Iter 2730/20000] Loss: 0.0010149 (Best: 0.0008751 @iter2727) ([92mâ†“10.00%[0m) [0.40% of initial]
[Iter 2740/20000] Loss: 0.0008781 (Best: 0.0007820 @iter2740) ([92mâ†“13.48%[0m) [0.35% of initial]
[Iter 2740/20000] Loss: 0.0008781 (Best: 0.0007820 @iter2740) ([92mâ†“13.48%[0m) [0.35% of initial]
[Iter 2750/20000] Loss: 0.0011353 (Best: 0.0007820 @iter2740) ([91mâ†‘29.29%[0m) [0.45% of initial]
[Iter 2750/20000] Loss: 0.0011353 (Best: 0.0007820 @iter2740) ([91mâ†‘29.29%[0m) [0.45% of initial]
[Iter 2760/20000] Loss: 0.0011704 (Best: 0.0007820 @iter2740) ([91mâ†‘3.09%[0m) [0.46% of initial]
[Iter 2760/20000] Loss: 0.0011704 (Best: 0.0007820 @iter2740) ([91mâ†‘3.09%[0m) [0.46% of initial]
[Iter 2770/20000] Loss: 0.0012931 (Best: 0.0007820 @iter2740) ([91mâ†‘10.49%[0m) [0.51% of initial]
[Iter 2770/20000] Loss: 0.0012931 (Best: 0.0007820 @iter2740) ([91mâ†‘10.49%[0m) [0.51% of initial]
[Iter 2780/20000] Loss: 0.0011058 (Best: 0.0007820 @iter2740) ([92mâ†“14.48%[0m) [0.44% of initial]
[Iter 2780/20000] Loss: 0.0011058 (Best: 0.0007820 @iter2740) ([92mâ†“14.48%[0m) [0.44% of initial]
[Iter 2790/20000] Loss: 0.0011605 (Best: 0.0007820 @iter2740) ([91mâ†‘4.95%[0m) [0.46% of initial]
[Iter 2790/20000] Loss: 0.0011605 (Best: 0.0007820 @iter2740) ([91mâ†‘4.95%[0m) [0.46% of initial]
Iter:2799, L1 loss=0.001278, Total loss=0.001304, Time:16
Iter:2799, L1 loss=0.001278, Total loss=0.001304, Time:16
[Iter 2800/20000] Loss: 0.0011854 (Best: 0.0007820 @iter2740) ([91mâ†‘2.15%[0m) [0.47% of initial]
[Iter 2800/20000] Loss: 0.0011854 (Best: 0.0007820 @iter2740) ([91mâ†‘2.15%[0m) [0.47% of initial]
[Iter 2810/20000] Loss: 0.0050917 (Best: 0.0007820 @iter2740) ([91mâ†‘329.52%[0m) [2.02% of initial]
[Iter 2810/20000] Loss: 0.0050917 (Best: 0.0007820 @iter2740) ([91mâ†‘329.52%[0m) [2.02% of initial]
[Iter 2820/20000] Loss: 0.0027653 (Best: 0.0007820 @iter2740) ([92mâ†“45.69%[0m) [1.10% of initial]
[Iter 2820/20000] Loss: 0.0027653 (Best: 0.0007820 @iter2740) ([92mâ†“45.69%[0m) [1.10% of initial]
[Iter 2830/20000] Loss: 0.0018263 (Best: 0.0007820 @iter2740) ([92mâ†“33.95%[0m) [0.73% of initial]
[Iter 2830/20000] Loss: 0.0018263 (Best: 0.0007820 @iter2740) ([92mâ†“33.95%[0m) [0.73% of initial]
[Iter 2840/20000] Loss: 0.0015724 (Best: 0.0007820 @iter2740) ([92mâ†“13.90%[0m) [0.62% of initial]
[Iter 2840/20000] Loss: 0.0015724 (Best: 0.0007820 @iter2740) ([92mâ†“13.90%[0m) [0.62% of initial]
[Iter 2850/20000] Loss: 0.0013431 (Best: 0.0007820 @iter2740) ([92mâ†“14.58%[0m) [0.53% of initial]
[Iter 2850/20000] Loss: 0.0013431 (Best: 0.0007820 @iter2740) ([92mâ†“14.58%[0m) [0.53% of initial]
[Iter 2860/20000] Loss: 0.0014726 (Best: 0.0007820 @iter2740) ([91mâ†‘9.64%[0m) [0.59% of initial]
[Iter 2860/20000] Loss: 0.0014726 (Best: 0.0007820 @iter2740) ([91mâ†‘9.64%[0m) [0.59% of initial]
[Iter 2870/20000] Loss: 0.0012416 (Best: 0.0007820 @iter2740) ([92mâ†“15.69%[0m) [0.49% of initial]
[Iter 2870/20000] Loss: 0.0012416 (Best: 0.0007820 @iter2740) ([92mâ†“15.69%[0m) [0.49% of initial]
[Iter 2880/20000] Loss: 0.0011669 (Best: 0.0007820 @iter2740) ([92mâ†“6.02%[0m) [0.46% of initial]
[Iter 2880/20000] Loss: 0.0011669 (Best: 0.0007820 @iter2740) ([92mâ†“6.02%[0m) [0.46% of initial]
[Iter 2890/20000] Loss: 0.0011449 (Best: 0.0007820 @iter2740) ([92mâ†“1.88%[0m) [0.45% of initial]
[Iter 2890/20000] Loss: 0.0011449 (Best: 0.0007820 @iter2740) ([92mâ†“1.88%[0m) [0.45% of initial]
Iter:2899, L1 loss=0.0008878, Total loss=0.0008848, Time:19
Iter:2899, L1 loss=0.0008878, Total loss=0.0008848, Time:19
[Iter 2900/20000] Loss: 0.0010884 (Best: 0.0007820 @iter2740) ([92mâ†“4.94%[0m) [0.43% of initial]
[Iter 2900/20000] Loss: 0.0010884 (Best: 0.0007820 @iter2740) ([92mâ†“4.94%[0m) [0.43% of initial]
[Iter 2910/20000] Loss: 0.0011314 (Best: 0.0007820 @iter2740) ([91mâ†‘3.94%[0m) [0.45% of initial]
[Iter 2910/20000] Loss: 0.0011314 (Best: 0.0007820 @iter2740) ([91mâ†‘3.94%[0m) [0.45% of initial]
[Iter 2920/20000] Loss: 0.0011826 (Best: 0.0007820 @iter2740) ([91mâ†‘4.53%[0m) [0.47% of initial]
[Iter 2920/20000] Loss: 0.0011826 (Best: 0.0007820 @iter2740) ([91mâ†‘4.53%[0m) [0.47% of initial]
[Iter 2930/20000] Loss: 0.0011536 (Best: 0.0007820 @iter2740) ([92mâ†“2.45%[0m) [0.46% of initial]
[Iter 2930/20000] Loss: 0.0011536 (Best: 0.0007820 @iter2740) ([92mâ†“2.45%[0m) [0.46% of initial]
[Iter 2940/20000] Loss: 0.0009692 (Best: 0.0007820 @iter2740) ([92mâ†“15.98%[0m) [0.39% of initial]
[Iter 2940/20000] Loss: 0.0009692 (Best: 0.0007820 @iter2740) ([92mâ†“15.98%[0m) [0.39% of initial]
[Iter 2950/20000] Loss: 0.0009331 (Best: 0.0007767 @iter2950) ([92mâ†“3.73%[0m) [0.37% of initial]
[Iter 2950/20000] Loss: 0.0009331 (Best: 0.0007767 @iter2950) ([92mâ†“3.73%[0m) [0.37% of initial]
[Iter 2960/20000] Loss: 0.0010308 (Best: 0.0007767 @iter2950) ([91mâ†‘10.48%[0m) [0.41% of initial]
[Iter 2960/20000] Loss: 0.0010308 (Best: 0.0007767 @iter2950) ([91mâ†‘10.48%[0m) [0.41% of initial]
[Iter 2970/20000] Loss: 0.0009184 (Best: 0.0007197 @iter2969) ([92mâ†“10.91%[0m) [0.36% of initial]
[Iter 2970/20000] Loss: 0.0009184 (Best: 0.0007197 @iter2969) ([92mâ†“10.91%[0m) [0.36% of initial]
[Iter 2980/20000] Loss: 0.0008411 (Best: 0.0007197 @iter2969) ([92mâ†“8.42%[0m) [0.33% of initial]
[Iter 2980/20000] Loss: 0.0008411 (Best: 0.0007197 @iter2969) ([92mâ†“8.42%[0m) [0.33% of initial]
[Iter 2990/20000] Loss: 0.0009022 (Best: 0.0006887 @iter2983) ([91mâ†‘7.26%[0m) [0.36% of initial]
[Iter 2990/20000] Loss: 0.0009022 (Best: 0.0006887 @iter2983) ([91mâ†‘7.26%[0m) [0.36% of initial]
Iter:2999, L1 loss=0.0007087, Total loss=0.0006713, Time:18
Iter:2999, L1 loss=0.0007087, Total loss=0.0006713, Time:18
[Iter 3000/20000] Loss: 0.0008657 (Best: 0.0006713 @iter2999) ([92mâ†“4.04%[0m) [0.34% of initial]
[Iter 3000/20000] Loss: 0.0008657 (Best: 0.0006713 @iter2999) ([92mâ†“4.04%[0m) [0.34% of initial]
[Iter 3010/20000] Loss: 0.0046394 (Best: 0.0006713 @iter2999) ([91mâ†‘435.91%[0m) [1.84% of initial]
[Iter 3010/20000] Loss: 0.0046394 (Best: 0.0006713 @iter2999) ([91mâ†‘435.91%[0m) [1.84% of initial]
[Iter 3020/20000] Loss: 0.0027093 (Best: 0.0006713 @iter2999) ([92mâ†“41.60%[0m) [1.08% of initial]
[Iter 3020/20000] Loss: 0.0027093 (Best: 0.0006713 @iter2999) ([92mâ†“41.60%[0m) [1.08% of initial]
[Iter 3030/20000] Loss: 0.0021167 (Best: 0.0006713 @iter2999) ([92mâ†“21.87%[0m) [0.84% of initial]
[Iter 3030/20000] Loss: 0.0021167 (Best: 0.0006713 @iter2999) ([92mâ†“21.87%[0m) [0.84% of initial]
[Iter 3040/20000] Loss: 0.0016990 (Best: 0.0006713 @iter2999) ([92mâ†“19.73%[0m) [0.67% of initial]
[Iter 3040/20000] Loss: 0.0016990 (Best: 0.0006713 @iter2999) ([92mâ†“19.73%[0m) [0.67% of initial]
[Iter 3050/20000] Loss: 0.0014227 (Best: 0.0006713 @iter2999) ([92mâ†“16.26%[0m) [0.57% of initial]
[Iter 3050/20000] Loss: 0.0014227 (Best: 0.0006713 @iter2999) ([92mâ†“16.26%[0m) [0.57% of initial]
[Iter 3060/20000] Loss: 0.0013843 (Best: 0.0006713 @iter2999) ([92mâ†“2.70%[0m) [0.55% of initial]
[Iter 3060/20000] Loss: 0.0013843 (Best: 0.0006713 @iter2999) ([92mâ†“2.70%[0m) [0.55% of initial]
[Iter 3070/20000] Loss: 0.0011546 (Best: 0.0006713 @iter2999) ([92mâ†“16.59%[0m) [0.46% of initial]
[Iter 3070/20000] Loss: 0.0011546 (Best: 0.0006713 @iter2999) ([92mâ†“16.59%[0m) [0.46% of initial]
[Iter 3080/20000] Loss: 0.0011452 (Best: 0.0006713 @iter2999) ([92mâ†“0.81%[0m) [0.45% of initial]
[Iter 3080/20000] Loss: 0.0011452 (Best: 0.0006713 @iter2999) ([92mâ†“0.81%[0m) [0.45% of initial]
[Iter 3090/20000] Loss: 0.0010643 (Best: 0.0006713 @iter2999) ([92mâ†“7.07%[0m) [0.42% of initial]
[Iter 3090/20000] Loss: 0.0010643 (Best: 0.0006713 @iter2999) ([92mâ†“7.07%[0m) [0.42% of initial]
Iter:3099, L1 loss=0.0009215, Total loss=0.000855, Time:18
Iter:3099, L1 loss=0.0009215, Total loss=0.000855, Time:18
[Iter 3100/20000] Loss: 0.0010017 (Best: 0.0006713 @iter2999) ([92mâ†“5.88%[0m) [0.40% of initial]
[Iter 3100/20000] Loss: 0.0010017 (Best: 0.0006713 @iter2999) ([92mâ†“5.88%[0m) [0.40% of initial]
[Iter 3110/20000] Loss: 0.0010856 (Best: 0.0006713 @iter2999) ([91mâ†‘8.37%[0m) [0.43% of initial]
[Iter 3110/20000] Loss: 0.0010856 (Best: 0.0006713 @iter2999) ([91mâ†‘8.37%[0m) [0.43% of initial]
[Iter 3120/20000] Loss: 0.0010447 (Best: 0.0006713 @iter2999) ([92mâ†“3.76%[0m) [0.42% of initial]
[Iter 3120/20000] Loss: 0.0010447 (Best: 0.0006713 @iter2999) ([92mâ†“3.76%[0m) [0.42% of initial]
[Iter 3130/20000] Loss: 0.0008586 (Best: 0.0006713 @iter2999) ([92mâ†“17.82%[0m) [0.34% of initial]
[Iter 3130/20000] Loss: 0.0008586 (Best: 0.0006713 @iter2999) ([92mâ†“17.82%[0m) [0.34% of initial]
[Iter 3140/20000] Loss: 0.0008658 (Best: 0.0006713 @iter2999) ([91mâ†‘0.84%[0m) [0.34% of initial]
[Iter 3140/20000] Loss: 0.0008658 (Best: 0.0006713 @iter2999) ([91mâ†‘0.84%[0m) [0.34% of initial]
[Iter 3150/20000] Loss: 0.0008860 (Best: 0.0006713 @iter2999) ([91mâ†‘2.33%[0m) [0.35% of initial]
[Iter 3150/20000] Loss: 0.0008860 (Best: 0.0006713 @iter2999) ([91mâ†‘2.33%[0m) [0.35% of initial]
[Iter 3160/20000] Loss: 0.0008144 (Best: 0.0006713 @iter2999) ([92mâ†“8.08%[0m) [0.32% of initial]
[Iter 3160/20000] Loss: 0.0008144 (Best: 0.0006713 @iter2999) ([92mâ†“8.08%[0m) [0.32% of initial]
[Iter 3170/20000] Loss: 0.0008377 (Best: 0.0006713 @iter2999) ([91mâ†‘2.86%[0m) [0.33% of initial]
[Iter 3170/20000] Loss: 0.0008377 (Best: 0.0006713 @iter2999) ([91mâ†‘2.86%[0m) [0.33% of initial]
[Iter 3180/20000] Loss: 0.0008571 (Best: 0.0006713 @iter2999) ([91mâ†‘2.32%[0m) [0.34% of initial]
[Iter 3180/20000] Loss: 0.0008571 (Best: 0.0006713 @iter2999) ([91mâ†‘2.32%[0m) [0.34% of initial]
[Iter 3190/20000] Loss: 0.0008445 (Best: 0.0006713 @iter2999) ([92mâ†“1.47%[0m) [0.34% of initial]
[Iter 3190/20000] Loss: 0.0008445 (Best: 0.0006713 @iter2999) ([92mâ†“1.47%[0m) [0.34% of initial]
Iter:3199, L1 loss=0.0007892, Total loss=0.0007318, Time:18
Iter:3199, L1 loss=0.0007892, Total loss=0.0007318, Time:18
[Iter 3200/20000] Loss: 0.0008220 (Best: 0.0006418 @iter3196) ([92mâ†“2.66%[0m) [0.33% of initial]
[Iter 3200/20000] Loss: 0.0008220 (Best: 0.0006418 @iter3196) ([92mâ†“2.66%[0m) [0.33% of initial]
[Iter 3210/20000] Loss: 0.0052154 (Best: 0.0006418 @iter3196) ([91mâ†‘534.43%[0m) [2.07% of initial]
[Iter 3210/20000] Loss: 0.0052154 (Best: 0.0006418 @iter3196) ([91mâ†‘534.43%[0m) [2.07% of initial]
[Iter 3220/20000] Loss: 0.0028213 (Best: 0.0006418 @iter3196) ([92mâ†“45.90%[0m) [1.12% of initial]
[Iter 3220/20000] Loss: 0.0028213 (Best: 0.0006418 @iter3196) ([92mâ†“45.90%[0m) [1.12% of initial]
[Iter 3230/20000] Loss: 0.0017170 (Best: 0.0006418 @iter3196) ([92mâ†“39.14%[0m) [0.68% of initial]
[Iter 3230/20000] Loss: 0.0017170 (Best: 0.0006418 @iter3196) ([92mâ†“39.14%[0m) [0.68% of initial]
[Iter 3240/20000] Loss: 0.0015272 (Best: 0.0006418 @iter3196) ([92mâ†“11.05%[0m) [0.61% of initial]
[Iter 3240/20000] Loss: 0.0015272 (Best: 0.0006418 @iter3196) ([92mâ†“11.05%[0m) [0.61% of initial]
[Iter 3250/20000] Loss: 0.0011228 (Best: 0.0006418 @iter3196) ([92mâ†“26.48%[0m) [0.45% of initial]
[Iter 3250/20000] Loss: 0.0011228 (Best: 0.0006418 @iter3196) ([92mâ†“26.48%[0m) [0.45% of initial]
[Iter 3260/20000] Loss: 0.0009681 (Best: 0.0006418 @iter3196) ([92mâ†“13.77%[0m) [0.38% of initial]
[Iter 3260/20000] Loss: 0.0009681 (Best: 0.0006418 @iter3196) ([92mâ†“13.77%[0m) [0.38% of initial]
[Iter 3270/20000] Loss: 0.0010060 (Best: 0.0006418 @iter3196) ([91mâ†‘3.91%[0m) [0.40% of initial]
[Iter 3270/20000] Loss: 0.0010060 (Best: 0.0006418 @iter3196) ([91mâ†‘3.91%[0m) [0.40% of initial]
[Iter 3280/20000] Loss: 0.0010620 (Best: 0.0006418 @iter3196) ([91mâ†‘5.57%[0m) [0.42% of initial]
[Iter 3280/20000] Loss: 0.0010620 (Best: 0.0006418 @iter3196) ([91mâ†‘5.57%[0m) [0.42% of initial]
[Iter 3290/20000] Loss: 0.0008013 (Best: 0.0006418 @iter3196) ([92mâ†“24.55%[0m) [0.32% of initial]
[Iter 3290/20000] Loss: 0.0008013 (Best: 0.0006418 @iter3196) ([92mâ†“24.55%[0m) [0.32% of initial]
Iter:3299, L1 loss=0.001253, Total loss=0.001328, Time:15
Iter:3299, L1 loss=0.001253, Total loss=0.001328, Time:15
[Iter 3300/20000] Loss: 0.0010777 (Best: 0.0006418 @iter3196) ([91mâ†‘34.49%[0m) [0.43% of initial]
[Iter 3300/20000] Loss: 0.0010777 (Best: 0.0006418 @iter3196) ([91mâ†‘34.49%[0m) [0.43% of initial]
[Iter 3310/20000] Loss: 0.0008085 (Best: 0.0006418 @iter3196) ([92mâ†“24.98%[0m) [0.32% of initial]
[Iter 3310/20000] Loss: 0.0008085 (Best: 0.0006418 @iter3196) ([92mâ†“24.98%[0m) [0.32% of initial]
[Iter 3320/20000] Loss: 0.0009283 (Best: 0.0006418 @iter3196) ([91mâ†‘14.82%[0m) [0.37% of initial]
[Iter 3320/20000] Loss: 0.0009283 (Best: 0.0006418 @iter3196) ([91mâ†‘14.82%[0m) [0.37% of initial]
[Iter 3330/20000] Loss: 0.0009393 (Best: 0.0006418 @iter3196) ([91mâ†‘1.18%[0m) [0.37% of initial]
[Iter 3330/20000] Loss: 0.0009393 (Best: 0.0006418 @iter3196) ([91mâ†‘1.18%[0m) [0.37% of initial]
[Iter 3340/20000] Loss: 0.0010740 (Best: 0.0006418 @iter3196) ([91mâ†‘14.35%[0m) [0.43% of initial]
[Iter 3340/20000] Loss: 0.0010740 (Best: 0.0006418 @iter3196) ([91mâ†‘14.35%[0m) [0.43% of initial]
[Iter 3350/20000] Loss: 0.0008690 (Best: 0.0006418 @iter3196) ([92mâ†“19.09%[0m) [0.35% of initial]
[Iter 3350/20000] Loss: 0.0008690 (Best: 0.0006418 @iter3196) ([92mâ†“19.09%[0m) [0.35% of initial]
[Iter 3360/20000] Loss: 0.0011032 (Best: 0.0006418 @iter3196) ([91mâ†‘26.95%[0m) [0.44% of initial]
[Iter 3360/20000] Loss: 0.0011032 (Best: 0.0006418 @iter3196) ([91mâ†‘26.95%[0m) [0.44% of initial]
[Iter 3370/20000] Loss: 0.0007862 (Best: 0.0006418 @iter3196) ([92mâ†“28.74%[0m) [0.31% of initial]
[Iter 3370/20000] Loss: 0.0007862 (Best: 0.0006418 @iter3196) ([92mâ†“28.74%[0m) [0.31% of initial]
[Iter 3380/20000] Loss: 0.0007741 (Best: 0.0006289 @iter3379) ([92mâ†“1.54%[0m) [0.31% of initial]
[Iter 3380/20000] Loss: 0.0007741 (Best: 0.0006289 @iter3379) ([92mâ†“1.54%[0m) [0.31% of initial]
[Iter 3390/20000] Loss: 0.0010080 (Best: 0.0006289 @iter3379) ([91mâ†‘30.23%[0m) [0.40% of initial]
[Iter 3390/20000] Loss: 0.0010080 (Best: 0.0006289 @iter3379) ([91mâ†‘30.23%[0m) [0.40% of initial]
Iter:3399, L1 loss=0.001241, Total loss=0.00124, Time:18
Iter:3399, L1 loss=0.001241, Total loss=0.00124, Time:18
[Iter 3400/20000] Loss: 0.0010314 (Best: 0.0006289 @iter3379) ([91mâ†‘2.32%[0m) [0.41% of initial]
[Iter 3400/20000] Loss: 0.0010314 (Best: 0.0006289 @iter3379) ([91mâ†‘2.32%[0m) [0.41% of initial]
[Iter 3410/20000] Loss: 0.0043589 (Best: 0.0006289 @iter3379) ([91mâ†‘322.61%[0m) [1.73% of initial]
[Iter 3410/20000] Loss: 0.0043589 (Best: 0.0006289 @iter3379) ([91mâ†‘322.61%[0m) [1.73% of initial]
[Iter 3420/20000] Loss: 0.0023098 (Best: 0.0006289 @iter3379) ([92mâ†“47.01%[0m) [0.92% of initial]
[Iter 3420/20000] Loss: 0.0023098 (Best: 0.0006289 @iter3379) ([92mâ†“47.01%[0m) [0.92% of initial]
[Iter 3430/20000] Loss: 0.0015330 (Best: 0.0006289 @iter3379) ([92mâ†“33.63%[0m) [0.61% of initial]
[Iter 3430/20000] Loss: 0.0015330 (Best: 0.0006289 @iter3379) ([92mâ†“33.63%[0m) [0.61% of initial]
[Iter 3440/20000] Loss: 0.0013342 (Best: 0.0006289 @iter3379) ([92mâ†“12.96%[0m) [0.53% of initial]
[Iter 3440/20000] Loss: 0.0013342 (Best: 0.0006289 @iter3379) ([92mâ†“12.96%[0m) [0.53% of initial]
[Iter 3450/20000] Loss: 0.0011990 (Best: 0.0006289 @iter3379) ([92mâ†“10.14%[0m) [0.48% of initial]
[Iter 3450/20000] Loss: 0.0011990 (Best: 0.0006289 @iter3379) ([92mâ†“10.14%[0m) [0.48% of initial]
[Iter 3460/20000] Loss: 0.0010892 (Best: 0.0006289 @iter3379) ([92mâ†“9.16%[0m) [0.43% of initial]
[Iter 3460/20000] Loss: 0.0010892 (Best: 0.0006289 @iter3379) ([92mâ†“9.16%[0m) [0.43% of initial]
[Iter 3470/20000] Loss: 0.0009957 (Best: 0.0006289 @iter3379) ([92mâ†“8.58%[0m) [0.40% of initial]
[Iter 3470/20000] Loss: 0.0009957 (Best: 0.0006289 @iter3379) ([92mâ†“8.58%[0m) [0.40% of initial]
[Iter 3480/20000] Loss: 0.0009311 (Best: 0.0006289 @iter3379) ([92mâ†“6.49%[0m) [0.37% of initial]
[Iter 3480/20000] Loss: 0.0009311 (Best: 0.0006289 @iter3379) ([92mâ†“6.49%[0m) [0.37% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92mâ†“19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374906 (Best: 0.1327878 @iter30) ([92mâ†“21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123922 (Best: 0.1098378 @iter40) ([92mâ†“18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993461 (Best: 0.0965453 @iter49) ([92mâ†“11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936759 (Best: 0.0908450 @iter59) ([92mâ†“5.71%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884556 (Best: 0.0869402 @iter70) ([92mâ†“5.57%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851898 (Best: 0.0831016 @iter80) ([92mâ†“3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824184 (Best: 0.0801595 @iter88) ([92mâ†“3.25%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07877, Time:13
[Iter 100/20000] Loss: 0.0786774 (Best: 0.0766314 @iter97) ([92mâ†“4.54%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753295 (Best: 0.0731336 @iter106) ([92mâ†“4.26%[0m) [29.93% of initial]
[Iter 120/20000] Loss: 0.0714518 (Best: 0.0685731 @iter118) ([92mâ†“5.15%[0m) [28.39% of initial]
[Iter 130/20000] Loss: 0.0667159 (Best: 0.0642162 @iter130) ([92mâ†“6.63%[0m) [26.51% of initial]
[Iter 140/20000] Loss: 0.0635590 (Best: 0.0613103 @iter140) ([92mâ†“4.73%[0m) [25.25% of initial]
[Iter 150/20000] Loss: 0.0613015 (Best: 0.0584095 @iter148) ([92mâ†“3.55%[0m) [24.35% of initial]
[Iter 160/20000] Loss: 0.0590986 (Best: 0.0559598 @iter157) ([92mâ†“3.59%[0m) [23.48% of initial]
[Iter 170/20000] Loss: 0.0564072 (Best: 0.0535446 @iter167) ([92mâ†“4.55%[0m) [22.41% of initial]
[Iter 180/20000] Loss: 0.0523819 (Best: 0.0500636 @iter179) ([92mâ†“7.14%[0m) [20.81% of initial]
[Iter 190/20000] Loss: 0.0495916 (Best: 0.0478368 @iter188) ([92mâ†“5.33%[0m) [19.70% of initial]
Iter:199, L1 loss=0.03439, Total loss=0.04979, Time:13
[Iter 200/20000] Loss: 0.0478299 (Best: 0.0457557 @iter198) ([92mâ†“3.55%[0m) [19.00% of initial]
[Iter 210/20000] Loss: 0.0450539 (Best: 0.0428284 @iter209) ([92mâ†“5.80%[0m) [17.90% of initial]
[Iter 220/20000] Loss: 0.0440717 (Best: 0.0412574 @iter219) ([92mâ†“2.18%[0m) [17.51% of initial]
[Iter 230/20000] Loss: 0.0422844 (Best: 0.0398593 @iter227) ([92mâ†“4.06%[0m) [16.80% of initial]
[Iter 240/20000] Loss: 0.0402716 (Best: 0.0377602 @iter238) ([92mâ†“4.76%[0m) [16.00% of initial]
[Iter 250/20000] Loss: 0.0379821 (Best: 0.0362288 @iter248) ([92mâ†“5.68%[0m) [15.09% of initial]
[Iter 260/20000] Loss: 0.0359069 (Best: 0.0343433 @iter260) ([92mâ†“5.46%[0m) [14.27% of initial]
[Iter 270/20000] Loss: 0.0349451 (Best: 0.0328457 @iter269) ([92mâ†“2.68%[0m) [13.88% of initial]
[Iter 280/20000] Loss: 0.0346833 (Best: 0.0316945 @iter277) ([92mâ†“0.75%[0m) [13.78% of initial]
[Iter 290/20000] Loss: 0.0331149 (Best: 0.0304131 @iter287) ([92mâ†“4.52%[0m) [13.16% of initial]
Iter:299, L1 loss=0.02212, Total loss=0.03347, Time:13
[Iter 300/20000] Loss: 0.0308962 (Best: 0.0289975 @iter300) ([92mâ†“6.70%[0m) [12.27% of initial]
[Iter 310/20000] Loss: 0.0294044 (Best: 0.0274145 @iter310) ([92mâ†“4.83%[0m) [11.68% of initial]
[Iter 320/20000] Loss: 0.0279572 (Best: 0.0266253 @iter320) ([92mâ†“4.92%[0m) [11.11% of initial]
[Iter 330/20000] Loss: 0.0275480 (Best: 0.0256602 @iter330) ([92mâ†“1.46%[0m) [10.94% of initial]
[Iter 340/20000] Loss: 0.0255335 (Best: 0.0244979 @iter340) ([92mâ†“7.31%[0m) [10.14% of initial]
[Iter 350/20000] Loss: 0.0261390 (Best: 0.0235734 @iter349) ([91mâ†‘2.37%[0m) [10.38% of initial]
[Iter 360/20000] Loss: 0.0248085 (Best: 0.0227957 @iter358) ([92mâ†“5.09%[0m) [9.86% of initial]
[Iter 370/20000] Loss: 0.0245300 (Best: 0.0222807 @iter368) ([92mâ†“1.12%[0m) [9.75% of initial]
[Iter 380/20000] Loss: 0.0221990 (Best: 0.0210888 @iter379) ([92mâ†“9.50%[0m) [8.82% of initial]
[Iter 390/20000] Loss: 0.0216734 (Best: 0.0202980 @iter385) ([92mâ†“2.37%[0m) [8.61% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179126 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693029 @iter20) ([92mâ†“19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374910 (Best: 0.1327884 @iter30) ([92mâ†“21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123923 (Best: 0.1098377 @iter40) ([92mâ†“18.25%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993442 (Best: 0.0965458 @iter49) ([92mâ†“11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936773 (Best: 0.0908518 @iter59) ([92mâ†“5.70%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884541 (Best: 0.0869403 @iter70) ([92mâ†“5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851913 (Best: 0.0831070 @iter80) ([92mâ†“3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824093 (Best: 0.0801457 @iter88) ([92mâ†“3.27%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07877, Time:15
[Iter 100/20000] Loss: 0.0786736 (Best: 0.0766262 @iter97) ([92mâ†“4.53%[0m) [31.26% of initial]
[Iter 110/20000] Loss: 0.0753214 (Best: 0.0731315 @iter106) ([92mâ†“4.26%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714356 (Best: 0.0685524 @iter118) ([92mâ†“5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0667052 (Best: 0.0641990 @iter130) ([92mâ†“6.62%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635378 (Best: 0.0612905 @iter140) ([92mâ†“4.75%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612754 (Best: 0.0583912 @iter148) ([92mâ†“3.56%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590545 (Best: 0.0559516 @iter157) ([92mâ†“3.62%[0m) [23.46% of initial]
[Iter 170/20000] Loss: 0.0563547 (Best: 0.0535233 @iter167) ([92mâ†“4.57%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0523423 (Best: 0.0500117 @iter179) ([92mâ†“7.12%[0m) [20.80% of initial]
[Iter 190/20000] Loss: 0.0495550 (Best: 0.0478360 @iter188) ([92mâ†“5.33%[0m) [19.69% of initial]
Iter:199, L1 loss=0.0345, Total loss=0.04972, Time:15
[Iter 200/20000] Loss: 0.0478118 (Best: 0.0456420 @iter198) ([92mâ†“3.52%[0m) [19.00% of initial]
[Iter 210/20000] Loss: 0.0450592 (Best: 0.0428094 @iter209) ([92mâ†“5.76%[0m) [17.90% of initial]
[Iter 220/20000] Loss: 0.0440960 (Best: 0.0412433 @iter219) ([92mâ†“2.14%[0m) [17.52% of initial]
[Iter 230/20000] Loss: 0.0423347 (Best: 0.0399214 @iter227) ([92mâ†“3.99%[0m) [16.82% of initial]
[Iter 240/20000] Loss: 0.0402544 (Best: 0.0377645 @iter238) ([92mâ†“4.91%[0m) [15.99% of initial]
[Iter 250/20000] Loss: 0.0378963 (Best: 0.0362103 @iter248) ([92mâ†“5.86%[0m) [15.06% of initial]
[Iter 260/20000] Loss: 0.0358194 (Best: 0.0343163 @iter260) ([92mâ†“5.48%[0m) [14.23% of initial]
[Iter 270/20000] Loss: 0.0349925 (Best: 0.0328234 @iter269) ([92mâ†“2.31%[0m) [13.90% of initial]
[Iter 280/20000] Loss: 0.0346987 (Best: 0.0318360 @iter277) ([92mâ†“0.84%[0m) [13.79% of initial]
[Iter 290/20000] Loss: 0.0329342 (Best: 0.0303293 @iter287) ([92mâ†“5.09%[0m) [13.08% of initial]
Iter:299, L1 loss=0.02213, Total loss=0.03328, Time:14
[Iter 300/20000] Loss: 0.0307077 (Best: 0.0288353 @iter300) ([92mâ†“6.76%[0m) [12.20% of initial]
[Iter 310/20000] Loss: 0.0293528 (Best: 0.0274127 @iter310) ([92mâ†“4.41%[0m) [11.66% of initial]
[Iter 320/20000] Loss: 0.0278957 (Best: 0.0264356 @iter320) ([92mâ†“4.96%[0m) [11.08% of initial]
[Iter 330/20000] Loss: 0.0274280 (Best: 0.0255223 @iter330) ([92mâ†“1.68%[0m) [10.90% of initial]
[Iter 340/20000] Loss: 0.0254151 (Best: 0.0242836 @iter340) ([92mâ†“7.34%[0m) [10.10% of initial]
[Iter 350/20000] Loss: 0.0262118 (Best: 0.0236180 @iter349) ([91mâ†‘3.13%[0m) [10.41% of initial]
[Iter 360/20000] Loss: 0.0247579 (Best: 0.0228129 @iter358) ([92mâ†“5.55%[0m) [9.84% of initial]
[Iter 370/20000] Loss: 0.0245303 (Best: 0.0220905 @iter368) ([92mâ†“0.92%[0m) [9.75% of initial]
[Iter 380/20000] Loss: 0.0222081 (Best: 0.0208801 @iter379) ([92mâ†“9.47%[0m) [8.82% of initial]
[Iter 390/20000] Loss: 0.0215881 (Best: 0.0201034 @iter385) ([92mâ†“2.79%[0m) [8.58% of initial]
Iter:399, L1 loss=0.0135, Total loss=0.02074, Time:14
[Iter 400/20000] Loss: 0.0201813 (Best: 0.0188199 @iter400) ([92mâ†“6.52%[0m) [8.02% of initial]
[Iter 410/20000] Loss: 0.0194163 (Best: 0.0184918 @iter410) ([92mâ†“3.79%[0m) [7.71% of initial]
[Iter 420/20000] Loss: 0.0196879 (Best: 0.0176556 @iter418) ([91mâ†‘1.40%[0m) [7.82% of initial]
[Iter 430/20000] Loss: 0.0176803 (Best: 0.0168277 @iter430) ([92mâ†“10.20%[0m) [7.02% of initial]
[Iter 440/20000] Loss: 0.0179882 (Best: 0.0163067 @iter438) ([91mâ†‘1.74%[0m) [7.15% of initial]
[Iter 450/20000] Loss: 0.0169663 (Best: 0.0150741 @iter449) ([92mâ†“5.68%[0m) [6.74% of initial]
[Iter 460/20000] Loss: 0.0163023 (Best: 0.0145428 @iter458) ([92mâ†“3.91%[0m) [6.48% of initial]
[Iter 470/20000] Loss: 0.0150412 (Best: 0.0141654 @iter470) ([92mâ†“7.74%[0m) [5.98% of initial]
[Iter 480/20000] Loss: 0.0145188 (Best: 0.0132563 @iter479) ([92mâ†“3.47%[0m) [5.77% of initial]
[Iter 490/20000] Loss: 0.0133655 (Best: 0.0123795 @iter490) ([92mâ†“7.94%[0m) [5.31% of initial]
Iter:499, L1 loss=0.009606, Total loss=0.01424, Time:14
[Iter 500/20000] Loss: 0.0133361 (Best: 0.0123666 @iter498) ([92mâ†“0.22%[0m) [5.30% of initial]
[Iter 510/20000] Loss: 0.0129957 (Best: 0.0116650 @iter508) ([92mâ†“2.55%[0m) [5.16% of initial]
[Iter 520/20000] Loss: 0.0125337 (Best: 0.0112668 @iter514) ([92mâ†“3.55%[0m) [4.98% of initial]
[Iter 530/20000] Loss: 0.0124352 (Best: 0.0112668 @iter514) ([92mâ†“0.79%[0m) [4.94% of initial]
[Iter 540/20000] Loss: 0.0123632 (Best: 0.0110053 @iter538) ([92mâ†“0.58%[0m) [4.91% of initial]
[Iter 550/20000] Loss: 0.0120421 (Best: 0.0108774 @iter548) ([92mâ†“2.60%[0m) [4.78% of initial]
[Iter 560/20000] Loss: 0.0121320 (Best: 0.0105929 @iter556) ([91mâ†‘0.75%[0m) [4.82% of initial]
[Iter 570/20000] Loss: 0.0115544 (Best: 0.0103515 @iter569) ([92mâ†“4.76%[0m) [4.59% of initial]
[Iter 580/20000] Loss: 0.0112463 (Best: 0.0101078 @iter578) ([92mâ†“2.67%[0m) [4.47% of initial]
[Iter 590/20000] Loss: 0.0111812 (Best: 0.0098618 @iter583) ([92mâ†“0.58%[0m) [4.44% of initial]
Iter:599, L1 loss=0.006972, Total loss=0.01181, Time:14
[Iter 600/20000] Loss: 0.0108481 (Best: 0.0098265 @iter598) ([92mâ†“2.98%[0m) [4.31% of initial]
[Iter 610/20000] Loss: 0.0219235 (Best: 0.0098265 @iter598) ([91mâ†‘102.10%[0m) [8.71% of initial]
[Iter 620/20000] Loss: 0.0139308 (Best: 0.0098265 @iter598) ([92mâ†“36.46%[0m) [5.53% of initial]
[Iter 630/20000] Loss: 0.0113820 (Best: 0.0098265 @iter598) ([92mâ†“18.30%[0m) [4.52% of initial]
[Iter 640/20000] Loss: 0.0097134 (Best: 0.0087348 @iter640) ([92mâ†“14.66%[0m) [3.86% of initial]
[Iter 650/20000] Loss: 0.0101924 (Best: 0.0087348 @iter640) ([91mâ†‘4.93%[0m) [4.05% of initial]
[Iter 660/20000] Loss: 0.0098577 (Best: 0.0086701 @iter655) ([92mâ†“3.28%[0m) [3.92% of initial]
[Iter 670/20000] Loss: 0.0095230 (Best: 0.0085171 @iter662) ([92mâ†“3.40%[0m) [3.78% of initial]
[Iter 680/20000] Loss: 0.0087994 (Best: 0.0081828 @iter680) ([92mâ†“7.60%[0m) [3.50% of initial]
[Iter 690/20000] Loss: 0.0090191 (Best: 0.0078638 @iter685) ([91mâ†‘2.50%[0m) [3.58% of initial]
Iter:699, L1 loss=0.005709, Total loss=0.009483, Time:14
[Iter 700/20000] Loss: 0.0086682 (Best: 0.0077984 @iter695) ([92mâ†“3.89%[0m) [3.44% of initial]
[Iter 710/20000] Loss: 0.0081832 (Best: 0.0075088 @iter703) ([92mâ†“5.60%[0m) [3.25% of initial]
[Iter 720/20000] Loss: 0.0083543 (Best: 0.0075088 @iter703) ([91mâ†‘2.09%[0m) [3.32% of initial]
[Iter 730/20000] Loss: 0.0084563 (Best: 0.0072739 @iter727) ([91mâ†‘1.22%[0m) [3.36% of initial]
[Iter 740/20000] Loss: 0.0085234 (Best: 0.0072609 @iter736) ([91mâ†‘0.79%[0m) [3.39% of initial]
[Iter 750/20000] Original Loss: 0.0079809 Pseudo Loss: 0.0006230 (7.81% of original) (Best: 0.0070075 @iter748) ([92mâ†“6.36%[0m) [3.17% of initial]
[Iter 760/20000] Original Loss: 0.0075642 Pseudo Loss: 0.0006230 (8.24% of original) (Best: 0.0069672 @iter751) ([92mâ†“5.22%[0m) [3.01% of initial]
[Iter 770/20000] Original Loss: 0.0075694 Pseudo Loss: 0.0006230 (8.23% of original) (Best: 0.0069672 @iter751) ([91mâ†‘0.07%[0m) [3.01% of initial]
[Iter 780/20000] Original Loss: 0.0077240 Pseudo Loss: 0.0006230 (8.07% of original) (Best: 0.0066586 @iter778) ([91mâ†‘2.04%[0m) [3.07% of initial]
[Iter 790/20000] Original Loss: 0.0075748 Pseudo Loss: 0.0006230 (8.22% of original) (Best: 0.0065663 @iter787) ([92mâ†“1.93%[0m) [3.01% of initial]
Iter:799, L1 loss=0.005173, Total loss=0.008172, Time:13
[Iter 800/20000] Original Loss: 0.0073677 Pseudo Loss: 0.0009475 (12.86% of original) (Best: 0.0065663 @iter787) ([92mâ†“2.73%[0m) [2.93% of initial]
[Iter 810/20000] Original Loss: 0.0176260 Pseudo Loss: 0.0009475 (5.38% of original) (Best: 0.0065663 @iter787) ([91mâ†‘139.24%[0m) [7.00% of initial]
[Iter 820/20000] Original Loss: 0.0110942 Pseudo Loss: 0.0009475 (8.54% of original) (Best: 0.0065663 @iter787) ([92mâ†“37.06%[0m) [4.41% of initial]
[Iter 830/20000] Original Loss: 0.0089393 Pseudo Loss: 0.0009475 (10.60% of original) (Best: 0.0065663 @iter787) ([92mâ†“19.42%[0m) [3.55% of initial]
[Iter 840/20000] Original Loss: 0.0080431 Pseudo Loss: 0.0009475 (11.78% of original) (Best: 0.0065663 @iter787) ([92mâ†“10.03%[0m) [3.20% of initial]
[Iter 850/20000] Original Loss: 0.0074344 Pseudo Loss: 0.0009475 (12.74% of original) (Best: 0.0065663 @iter787) ([92mâ†“7.57%[0m) [2.95% of initial]
[Iter 860/20000] Original Loss: 0.0069914 Pseudo Loss: 0.0009475 (13.55% of original) (Best: 0.0061829 @iter856) ([92mâ†“5.96%[0m) [2.78% of initial]
[Iter 870/20000] Original Loss: 0.0066168 Pseudo Loss: 0.0009475 (14.32% of original) (Best: 0.0060683 @iter862) ([92mâ†“5.36%[0m) [2.63% of initial]
[Iter 880/20000] Original Loss: 0.0066689 Pseudo Loss: 0.0009475 (14.21% of original) (Best: 0.0058796 @iter875) ([91mâ†‘0.79%[0m) [2.65% of initial]
[Iter 890/20000] Original Loss: 0.0063531 Pseudo Loss: 0.0009475 (14.91% of original) (Best: 0.0057174 @iter884) ([92mâ†“4.73%[0m) [2.52% of initial]
Iter:899, L1 loss=0.003843, Total loss=0.005669, Time:13
[Iter 900/20000] Original Loss: 0.0064935 Pseudo Loss: 0.0009475 (14.59% of original) (Best: 0.0056691 @iter899) ([91mâ†‘2.21%[0m) [2.58% of initial]
[Iter 910/20000] Original Loss: 0.0064959 Pseudo Loss: 0.0009475 (14.59% of original) (Best: 0.0054179 @iter907) ([91mâ†‘0.04%[0m) [2.58% of initial]
[Iter 920/20000] Original Loss: 0.0059476 Pseudo Loss: 0.0009475 (15.93% of original) (Best: 0.0053485 @iter919) ([92mâ†“8.44%[0m) [2.36% of initial]
[Iter 930/20000] Original Loss: 0.0062029 Pseudo Loss: 0.0009475 (15.27% of original) (Best: 0.0052557 @iter925) ([91mâ†‘4.29%[0m) [2.46% of initial]
[Iter 940/20000] Original Loss: 0.0062181 Pseudo Loss: 0.0009475 (15.24% of original) (Best: 0.0051307 @iter938) ([91mâ†‘0.24%[0m) [2.47% of initial]
[Iter 950/20000] Original Loss: 0.0057619 Pseudo Loss: 0.0009475 (16.44% of original) (Best: 0.0051307 @iter938) ([92mâ†“7.34%[0m) [2.29% of initial]
[Iter 960/20000] Original Loss: 0.0059027 Pseudo Loss: 0.0009475 (16.05% of original) (Best: 0.0051307 @iter938) ([91mâ†‘2.44%[0m) [2.35% of initial]
[Iter 970/20000] Original Loss: 0.0058900 Pseudo Loss: 0.0009475 (16.09% of original) (Best: 0.0051088 @iter964) ([92mâ†“0.21%[0m) [2.34% of initial]
[Iter 980/20000] Original Loss: 0.0059316 Pseudo Loss: 0.0009475 (15.97% of original) (Best: 0.0051088 @iter964) ([91mâ†‘0.71%[0m) [2.36% of initial]
[Iter 990/20000] Original Loss: 0.0060478 Pseudo Loss: 0.0009475 (15.67% of original) (Best: 0.0051088 @iter964) ([91mâ†‘1.96%[0m) [2.40% of initial]
Iter:999, L1 loss=0.004458, Total loss=0.006571, Time:13
[Iter 1000/20000] Original Loss: 0.0062016 Pseudo Loss: 0.0009475 (15.28% of original) (Best: 0.0051088 @iter964) ([91mâ†‘2.54%[0m) [2.46% of initial]
[Iter 1010/20000] Original Loss: 0.0119825 Pseudo Loss: 0.0009475 (7.91% of original) (Best: 0.0051088 @iter964) ([91mâ†‘93.22%[0m) [4.76% of initial]
[Iter 1020/20000] Original Loss: 0.0082529 Pseudo Loss: 0.0009475 (11.48% of original) (Best: 0.0051088 @iter964) ([92mâ†“31.13%[0m) [3.28% of initial]
[Iter 1030/20000] Original Loss: 0.0066951 Pseudo Loss: 0.0009475 (14.15% of original) (Best: 0.0051088 @iter964) ([92mâ†“18.87%[0m) [2.66% of initial]
[Iter 1040/20000] Original Loss: 0.0058962 Pseudo Loss: 0.0009475 (16.07% of original) (Best: 0.0051088 @iter964) ([92mâ†“11.93%[0m) [2.34% of initial]
[Iter 1050/20000] Original Loss: 0.0057196 Pseudo Loss: 0.0009475 (16.57% of original) (Best: 0.0049610 @iter1049) ([92mâ†“2.99%[0m) [2.27% of initial]
[Iter 1060/20000] Original Loss: 0.0056073 Pseudo Loss: 0.0009475 (16.90% of original) (Best: 0.0047969 @iter1051) ([92mâ†“1.96%[0m) [2.23% of initial]
[Iter 1070/20000] Original Loss: 0.0053432 Pseudo Loss: 0.0009475 (17.73% of original) (Best: 0.0044006 @iter1066) ([92mâ†“4.71%[0m) [2.12% of initial]
[Iter 1080/20000] Original Loss: 0.0051923 Pseudo Loss: 0.0011391 (21.94% of original) (Best: 0.0044006 @iter1066) ([92mâ†“2.82%[0m) [2.06% of initial]
[Iter 1090/20000] Original Loss: 0.0049910 Pseudo Loss: 0.0011391 (22.82% of original) (Best: 0.0044006 @iter1066) ([92mâ†“3.88%[0m) [1.98% of initial]
Iter:1099, L1 loss=0.003416, Total loss=0.004976, Time:14
[Iter 1100/20000] Original Loss: 0.0048783 Pseudo Loss: 0.0011391 (23.35% of original) (Best: 0.0041829 @iter1093) ([92mâ†“2.26%[0m) [1.94% of initial]
[Iter 1110/20000] Original Loss: 0.0049788 Pseudo Loss: 0.0011391 (22.88% of original) (Best: 0.0041829 @iter1093) ([91mâ†‘2.06%[0m) [1.98% of initial]
[Iter 1120/20000] Original Loss: 0.0049953 Pseudo Loss: 0.0011391 (22.80% of original) (Best: 0.0040554 @iter1117) ([91mâ†‘0.33%[0m) [1.98% of initial]
[Iter 1130/20000] Original Loss: 0.0051960 Pseudo Loss: 0.0011391 (21.92% of original) (Best: 0.0040554 @iter1117) ([91mâ†‘4.02%[0m) [2.06% of initial]
[Iter 1140/20000] Original Loss: 0.0047054 Pseudo Loss: 0.0011391 (24.21% of original) (Best: 0.0040135 @iter1135) ([92mâ†“9.44%[0m) [1.87% of initial]
[Iter 1150/20000] Original Loss: 0.0043500 Pseudo Loss: 0.0011391 (26.19% of original) (Best: 0.0039109 @iter1145) ([92mâ†“7.55%[0m) [1.73% of initial]
[Iter 1160/20000] Original Loss: 0.0049763 Pseudo Loss: 0.0011391 (22.89% of original) (Best: 0.0039109 @iter1145) ([91mâ†‘14.40%[0m) [1.98% of initial]
[Iter 1170/20000] Original Loss: 0.0045984 Pseudo Loss: 0.0011391 (24.77% of original) (Best: 0.0039109 @iter1145) ([92mâ†“7.59%[0m) [1.83% of initial]
[Iter 1180/20000] Original Loss: 0.0042943 Pseudo Loss: 0.0011391 (26.53% of original) (Best: 0.0038771 @iter1180) ([92mâ†“6.61%[0m) [1.71% of initial]
[Iter 1190/20000] Original Loss: 0.0046151 Pseudo Loss: 0.0011391 (24.68% of original) (Best: 0.0038657 @iter1186) ([91mâ†‘7.47%[0m) [1.83% of initial]
Iter:1199, L1 loss=0.003455, Total loss=0.004822, Time:12
[Iter 1200/20000] Original Loss: 0.0045219 Pseudo Loss: 0.0011391 (25.19% of original) (Best: 0.0037503 @iter1195) ([92mâ†“2.02%[0m) [1.80% of initial]
[Iter 1210/20000] Original Loss: 0.0104866 Pseudo Loss: 0.0011391 (10.86% of original) (Best: 0.0037503 @iter1195) ([91mâ†‘131.91%[0m) [4.17% of initial]
[Iter 1220/20000] Original Loss: 0.0070417 Pseudo Loss: 0.0011391 (16.18% of original) (Best: 0.0037503 @iter1195) ([92mâ†“32.85%[0m) [2.80% of initial]
[Iter 1230/20000] Original Loss: 0.0059679 Pseudo Loss: 0.0011391 (19.09% of original) (Best: 0.0037503 @iter1195) ([92mâ†“15.25%[0m) [2.37% of initial]
[Iter 1240/20000] Original Loss: 0.0053647 Pseudo Loss: 0.0011391 (21.23% of original) (Best: 0.0037503 @iter1195) ([92mâ†“10.11%[0m) [2.13% of initial]
[Iter 1250/20000] Original Loss: 0.0047608 Pseudo Loss: 0.0011391 (23.93% of original) (Best: 0.0037503 @iter1195) ([92mâ†“11.26%[0m) [1.89% of initial]
[Iter 1260/20000] Original Loss: 0.0045834 Pseudo Loss: 0.0011391 (24.85% of original) (Best: 0.0036406 @iter1258) ([92mâ†“3.73%[0m) [1.82% of initial]
[Iter 1270/20000] Original Loss: 0.0040941 Pseudo Loss: 0.0011391 (27.82% of original) (Best: 0.0036406 @iter1258) ([92mâ†“10.67%[0m) [1.63% of initial]
[Iter 1280/20000] Original Loss: 0.0042822 Pseudo Loss: 0.0011391 (26.60% of original) (Best: 0.0034541 @iter1273) ([91mâ†‘4.59%[0m) [1.70% of initial]
[Iter 1290/20000] Original Loss: 0.0041553 Pseudo Loss: 0.0011391 (27.41% of original) (Best: 0.0033003 @iter1285) ([92mâ†“2.96%[0m) [1.65% of initial]
Iter:1299, L1 loss=0.002749, Total loss=0.003566, Time:15
[Iter 1300/20000] Original Loss: 0.0039019 Pseudo Loss: 0.0011391 (29.19% of original) (Best: 0.0033003 @iter1285) ([92mâ†“6.10%[0m) [1.55% of initial]
[Iter 1310/20000] Original Loss: 0.0039406 Pseudo Loss: 0.0011391 (28.91% of original) (Best: 0.0033003 @iter1285) ([91mâ†‘0.99%[0m) [1.57% of initial]
[Iter 1320/20000] Original Loss: 0.0038208 Pseudo Loss: 0.0011391 (29.81% of original) (Best: 0.0030676 @iter1319) ([92mâ†“3.04%[0m) [1.52% of initial]
[Iter 1330/20000] Original Loss: 0.0038777 Pseudo Loss: 0.0011391 (29.37% of original) (Best: 0.0030050 @iter1321) ([91mâ†‘1.49%[0m) [1.54% of initial]
[Iter 1340/20000] Original Loss: 0.0036198 Pseudo Loss: 0.0011391 (31.47% of original) (Best: 0.0030050 @iter1321) ([92mâ†“6.65%[0m) [1.44% of initial]
[Iter 1350/20000] Original Loss: 0.0036390 Pseudo Loss: 0.0011391 (31.30% of original) (Best: 0.0030050 @iter1321) ([91mâ†‘0.53%[0m) [1.45% of initial]
[Iter 1360/20000] Original Loss: 0.0037657 Pseudo Loss: 0.0011391 (30.25% of original) (Best: 0.0030050 @iter1321) ([91mâ†‘3.48%[0m) [1.50% of initial]
[Iter 1370/20000] Original Loss: 0.0036094 Pseudo Loss: 0.0011391 (31.56% of original) (Best: 0.0030050 @iter1321) ([92mâ†“4.15%[0m) [1.43% of initial]
[Iter 1380/20000] Original Loss: 0.0039169 Pseudo Loss: 0.0011391 (29.08% of original) (Best: 0.0030050 @iter1321) ([91mâ†‘8.52%[0m) [1.56% of initial]
[Iter 1390/20000] Original Loss: 0.0036564 Pseudo Loss: 0.0011391 (31.15% of original) (Best: 0.0030050 @iter1321) ([92mâ†“6.65%[0m) [1.45% of initial]
Iter:1399, L1 loss=0.002306, Total loss=0.002896, Time:13
[Iter 1400/20000] Original Loss: 0.0033707 Pseudo Loss: 0.0011391 (33.79% of original) (Best: 0.0028955 @iter1399) ([92mâ†“7.81%[0m) [1.34% of initial]
[Iter 1410/20000] Original Loss: 0.0086703 Pseudo Loss: 0.0011391 (13.14% of original) (Best: 0.0028955 @iter1399) ([91mâ†‘157.22%[0m) [3.44% of initial]
[Iter 1420/20000] Original Loss: 0.0057129 Pseudo Loss: 0.0011391 (19.94% of original) (Best: 0.0028955 @iter1399) ([92mâ†“34.11%[0m) [2.27% of initial]
[Iter 1430/20000] Original Loss: 0.0048587 Pseudo Loss: 0.0011391 (23.44% of original) (Best: 0.0028955 @iter1399) ([92mâ†“14.95%[0m) [1.93% of initial]
[Iter 1440/20000] Original Loss: 0.0043162 Pseudo Loss: 0.0011391 (26.39% of original) (Best: 0.0028955 @iter1399) ([92mâ†“11.16%[0m) [1.71% of initial]
[Iter 1450/20000] Original Loss: 0.0035330 Pseudo Loss: 0.0011391 (32.24% of original) (Best: 0.0028955 @iter1399) ([92mâ†“18.14%[0m) [1.40% of initial]
[Iter 1460/20000] Original Loss: 0.0035091 Pseudo Loss: 0.0011391 (32.46% of original) (Best: 0.0028955 @iter1399) ([92mâ†“0.68%[0m) [1.39% of initial]
[Iter 1470/20000] Original Loss: 0.0033763 Pseudo Loss: 0.0011391 (33.74% of original) (Best: 0.0028955 @iter1399) ([92mâ†“3.78%[0m) [1.34% of initial]
[Iter 1480/20000] Original Loss: 0.0032763 Pseudo Loss: 0.0011391 (34.77% of original) (Best: 0.0027453 @iter1480) ([92mâ†“2.96%[0m) [1.30% of initial]
[Iter 1490/20000] Original Loss: 0.0031771 Pseudo Loss: 0.0011391 (35.85% of original) (Best: 0.0027453 @iter1480) ([92mâ†“3.03%[0m) [1.26% of initial]
Iter:1499, L1 loss=0.002584, Total loss=0.003304, Time:14
[Iter 1500/20000] Original Loss: 0.0031552 Pseudo Loss: 0.0011391 (36.10% of original) (Best: 0.0027453 @iter1480) ([92mâ†“0.69%[0m) [1.25% of initial]
[Iter 1510/20000] Original Loss: 0.0030085 Pseudo Loss: 0.0011391 (37.86% of original) (Best: 0.0025772 @iter1504) ([92mâ†“4.65%[0m) [1.20% of initial]
[Iter 1520/20000] Original Loss: 0.0030063 Pseudo Loss: 0.0011391 (37.89% of original) (Best: 0.0025659 @iter1520) ([92mâ†“0.07%[0m) [1.19% of initial]
[Iter 1530/20000] Original Loss: 0.0031075 Pseudo Loss: 0.0011391 (36.66% of original) (Best: 0.0025559 @iter1526) ([91mâ†‘3.37%[0m) [1.23% of initial]
[Iter 1540/20000] Original Loss: 0.0030107 Pseudo Loss: 0.0011391 (37.83% of original) (Best: 0.0025559 @iter1526) ([92mâ†“3.12%[0m) [1.20% of initial]
[Iter 1550/20000] Original Loss: 0.0029342 Pseudo Loss: 0.0011391 (38.82% of original) (Best: 0.0025559 @iter1526) ([92mâ†“2.54%[0m) [1.17% of initial]
[Iter 1560/20000] Original Loss: 0.0031681 Pseudo Loss: 0.0011391 (35.95% of original) (Best: 0.0024920 @iter1558) ([91mâ†‘7.97%[0m) [1.26% of initial]
[Iter 1570/20000] Original Loss: 0.0027489 Pseudo Loss: 0.0011391 (41.44% of original) (Best: 0.0024230 @iter1569) ([92mâ†“13.23%[0m) [1.09% of initial]
[Iter 1580/20000] Original Loss: 0.0027600 Pseudo Loss: 0.0011391 (41.27% of original) (Best: 0.0022971 @iter1573) ([91mâ†‘0.40%[0m) [1.10% of initial]
[Iter 1590/20000] Original Loss: 0.0026558 Pseudo Loss: 0.0011391 (42.89% of original) (Best: 0.0022971 @iter1573) ([92mâ†“3.78%[0m) [1.06% of initial]
Iter:1599, L1 loss=0.002683, Total loss=0.003327, Time:13
[Iter 1600/20000] Original Loss: 0.0030132 Pseudo Loss: 0.0011391 (37.80% of original) (Best: 0.0022443 @iter1591) ([91mâ†‘13.46%[0m) [1.20% of initial]
[Iter 1610/20000] Original Loss: 0.0082661 Pseudo Loss: 0.0011391 (13.78% of original) (Best: 0.0022443 @iter1591) ([91mâ†‘174.33%[0m) [3.28% of initial]
[Iter 1620/20000] Original Loss: 0.0052745 Pseudo Loss: 0.0011391 (21.60% of original) (Best: 0.0022443 @iter1591) ([92mâ†“36.19%[0m) [2.10% of initial]
[Iter 1630/20000] Original Loss: 0.0039519 Pseudo Loss: 0.0021582 (54.61% of original) (Best: 0.0022443 @iter1591) ([92mâ†“25.07%[0m) [1.57% of initial]
[Iter 1640/20000] Original Loss: 0.0037665 Pseudo Loss: 0.0021582 (57.30% of original) (Best: 0.0022443 @iter1591) ([92mâ†“4.69%[0m) [1.50% of initial]
[Iter 1650/20000] Original Loss: 0.0032976 Pseudo Loss: 0.0021582 (65.45% of original) (Best: 0.0022443 @iter1591) ([92mâ†“12.45%[0m) [1.31% of initial]
[Iter 1660/20000] Original Loss: 0.0028874 Pseudo Loss: 0.0021582 (74.75% of original) (Best: 0.0022443 @iter1591) ([92mâ†“12.44%[0m) [1.15% of initial]
[Iter 1670/20000] Original Loss: 0.0027063 Pseudo Loss: 0.0021582 (79.75% of original) (Best: 0.0022443 @iter1591) ([92mâ†“6.27%[0m) [1.08% of initial]
[Iter 1680/20000] Original Loss: 0.0029185 Pseudo Loss: 0.0021582 (73.95% of original) (Best: 0.0022443 @iter1591) ([91mâ†‘7.84%[0m) [1.16% of initial]
[Iter 1690/20000] Original Loss: 0.0030863 Pseudo Loss: 0.0021582 (69.93% of original) (Best: 0.0022443 @iter1591) ([91mâ†‘5.75%[0m) [1.23% of initial]
Iter:1699, L1 loss=0.002653, Total loss=0.00314, Time:14
[Iter 1700/20000] Original Loss: 0.0027895 Pseudo Loss: 0.0021582 (77.37% of original) (Best: 0.0022443 @iter1591) ([92mâ†“9.62%[0m) [1.11% of initial]
[Iter 1710/20000] Original Loss: 0.0031226 Pseudo Loss: 0.0021582 (69.12% of original) (Best: 0.0022443 @iter1591) ([91mâ†‘11.94%[0m) [1.24% of initial]
[Iter 1720/20000] Original Loss: 0.0025835 Pseudo Loss: 0.0021582 (83.54% of original) (Best: 0.0022443 @iter1591) ([92mâ†“17.26%[0m) [1.03% of initial]
[Iter 1730/20000] Original Loss: 0.0025578 Pseudo Loss: 0.0021582 (84.38% of original) (Best: 0.0022443 @iter1591) ([92mâ†“1.00%[0m) [1.02% of initial]
[Iter 1740/20000] Original Loss: 0.0025782 Pseudo Loss: 0.0021582 (83.71% of original) (Best: 0.0021903 @iter1738) ([91mâ†‘0.80%[0m) [1.02% of initial]
[Iter 1750/20000] Original Loss: 0.0023107 Pseudo Loss: 0.0021582 (93.40% of original) (Best: 0.0020655 @iter1750) ([92mâ†“10.38%[0m) [0.92% of initial]
[Iter 1760/20000] Original Loss: 0.0025915 Pseudo Loss: 0.0021582 (83.28% of original) (Best: 0.0020655 @iter1750) ([91mâ†‘12.15%[0m) [1.03% of initial]
[Iter 1770/20000] Original Loss: 0.0023933 Pseudo Loss: 0.0021582 (90.18% of original) (Best: 0.0020548 @iter1762) ([92mâ†“7.65%[0m) [0.95% of initial]
[Iter 1780/20000] Original Loss: 0.0024263 Pseudo Loss: 0.0021582 (88.95% of original) (Best: 0.0020548 @iter1762) ([91mâ†‘1.38%[0m) [0.96% of initial]
[Iter 1790/20000] Original Loss: 0.0021545 Pseudo Loss: 0.0021582 (100.17% of original) (Best: 0.0018186 @iter1789) ([92mâ†“11.20%[0m) [0.86% of initial]
Iter:1799, L1 loss=0.001697, Total loss=0.001901, Time:13
[Iter 1800/20000] Original Loss: 0.0021872 Pseudo Loss: 0.0021582 (98.67% of original) (Best: 0.0018186 @iter1789) ([91mâ†‘1.52%[0m) [0.87% of initial]
[Iter 1810/20000] Original Loss: 0.0076745 Pseudo Loss: 0.0021582 (28.12% of original) (Best: 0.0018186 @iter1789) ([91mâ†‘250.88%[0m) [3.05% of initial]
[Iter 1820/20000] Original Loss: 0.0046133 Pseudo Loss: 0.0021582 (46.78% of original) (Best: 0.0018186 @iter1789) ([92mâ†“39.89%[0m) [1.83% of initial]
[Iter 1830/20000] Original Loss: 0.0040230 Pseudo Loss: 0.0021582 (53.65% of original) (Best: 0.0018186 @iter1789) ([92mâ†“12.80%[0m) [1.60% of initial]
[Iter 1840/20000] Original Loss: 0.0027763 Pseudo Loss: 0.0021582 (77.74% of original) (Best: 0.0018186 @iter1789) ([92mâ†“30.99%[0m) [1.10% of initial]
[Iter 1850/20000] Original Loss: 0.0025899 Pseudo Loss: 0.0021582 (83.33% of original) (Best: 0.0018186 @iter1789) ([92mâ†“6.71%[0m) [1.03% of initial]
[Iter 1860/20000] Original Loss: 0.0023493 Pseudo Loss: 0.0021582 (91.87% of original) (Best: 0.0018186 @iter1789) ([92mâ†“9.29%[0m) [0.93% of initial]
[Iter 1870/20000] Original Loss: 0.0021850 Pseudo Loss: 0.0021582 (98.78% of original) (Best: 0.0018151 @iter1867) ([92mâ†“6.99%[0m) [0.87% of initial]
[Iter 1880/20000] Original Loss: 0.0020894 Pseudo Loss: 0.0021582 (103.30% of original) (Best: 0.0018151 @iter1867) ([92mâ†“4.38%[0m) [0.83% of initial]
[Iter 1890/20000] Original Loss: 0.0019199 Pseudo Loss: 0.0021582 (112.41% of original) (Best: 0.0017793 @iter1887) ([92mâ†“8.11%[0m) [0.76% of initial]
Iter:1899, L1 loss=0.001769, Total loss=0.002015, Time:14
[Iter 1900/20000] Original Loss: 0.0020387 Pseudo Loss: 0.0021582 (105.86% of original) (Best: 0.0016294 @iter1891) ([91mâ†‘6.19%[0m) [0.81% of initial]
[Iter 1910/20000] Original Loss: 0.0020801 Pseudo Loss: 0.0021582 (103.76% of original) (Best: 0.0016294 @iter1891) ([91mâ†‘2.03%[0m) [0.83% of initial]
[Iter 1920/20000] Original Loss: 0.0020956 Pseudo Loss: 0.0021582 (102.99% of original) (Best: 0.0016294 @iter1891) ([91mâ†‘0.74%[0m) [0.83% of initial]
[Iter 1930/20000] Original Loss: 0.0017826 Pseudo Loss: 0.0021582 (121.07% of original) (Best: 0.0015834 @iter1930) ([92mâ†“14.93%[0m) [0.71% of initial]
[Iter 1940/20000] Original Loss: 0.0018688 Pseudo Loss: 0.0021582 (115.49% of original) (Best: 0.0015336 @iter1939) ([91mâ†‘4.84%[0m) [0.74% of initial]
[Iter 1950/20000] Original Loss: 0.0020481 Pseudo Loss: 0.0021582 (105.38% of original) (Best: 0.0015336 @iter1939) ([91mâ†‘9.59%[0m) [0.81% of initial]
[Iter 1960/20000] Original Loss: 0.0018784 Pseudo Loss: 0.0021582 (114.90% of original) (Best: 0.0015336 @iter1939) ([92mâ†“8.29%[0m) [0.75% of initial]
[Iter 1970/20000] Original Loss: 0.0017125 Pseudo Loss: 0.0021582 (126.03% of original) (Best: 0.0015336 @iter1939) ([92mâ†“8.83%[0m) [0.68% of initial]
[Iter 1980/20000] Original Loss: 0.0020425 Pseudo Loss: 0.0021582 (105.67% of original) (Best: 0.0015336 @iter1939) ([91mâ†‘19.27%[0m) [0.81% of initial]
[Iter 1990/20000] Original Loss: 0.0017953 Pseudo Loss: 0.0021582 (120.22% of original) (Best: 0.0015336 @iter1939) ([92mâ†“12.10%[0m) [0.71% of initial]
Iter:1999, L1 loss=0.001605, Total loss=0.001973, Time:14
[Iter 2000/20000] Original Loss: 0.0020271 Pseudo Loss: 0.0021582 (106.47% of original) (Best: 0.0015336 @iter1939) ([91mâ†‘12.91%[0m) [0.81% of initial]
Testing Speed: 197.1400316604436 fps
Testing Time: 0.25362682342529297 s

[ITER 2000] Evaluating test: SSIM = 0.8478951263427734, PSNR = 17.5193744468689
Testing Speed: 180.88772605733016 fps
Testing Time: 0.01658487319946289 s

[ITER 2000] Evaluating train: SSIM = 0.9999496738115946, PSNR = 48.31907272338867
Iter:2000, total_points:43029
[Iter 2010/20000] Original Loss: 0.0066683 Pseudo Loss: 0.0021582 (32.37% of original) (Best: 0.0015336 @iter1939) ([91mâ†‘228.96%[0m) [2.65% of initial]
[Iter 2020/20000] Original Loss: 0.0037955 Pseudo Loss: 0.0021582 (56.86% of original) (Best: 0.0015336 @iter1939) ([92mâ†“43.08%[0m) [1.51% of initial]
[Iter 2030/20000] Original Loss: 0.0028327 Pseudo Loss: 0.0021582 (76.19% of original) (Best: 0.0015336 @iter1939) ([92mâ†“25.37%[0m) [1.13% of initial]
[Iter 2040/20000] Original Loss: 0.0024956 Pseudo Loss: 0.0021582 (86.48% of original) (Best: 0.0015336 @iter1939) ([92mâ†“11.90%[0m) [0.99% of initial]
[Iter 2050/20000] Original Loss: 0.0021104 Pseudo Loss: 0.0021582 (102.27% of original) (Best: 0.0015336 @iter1939) ([92mâ†“15.44%[0m) [0.84% of initial]
[Iter 2060/20000] Original Loss: 0.0018543 Pseudo Loss: 0.0021582 (116.39% of original) (Best: 0.0015336 @iter1939) ([92mâ†“12.14%[0m) [0.74% of initial]
[Iter 2070/20000] Original Loss: 0.0020073 Pseudo Loss: 0.0021582 (107.52% of original) (Best: 0.0015336 @iter1939) ([91mâ†‘8.25%[0m) [0.80% of initial]
[Iter 2080/20000] Original Loss: 0.0019970 Pseudo Loss: 0.0021582 (108.08% of original) (Best: 0.0015336 @iter1939) ([92mâ†“0.51%[0m) [0.79% of initial]
[Iter 2090/20000] Original Loss: 0.0018941 Pseudo Loss: 0.0021582 (113.95% of original) (Best: 0.0015223 @iter2087) ([92mâ†“5.15%[0m) [0.75% of initial]
Iter:2099, L1 loss=0.001603, Total loss=0.001741, Time:14
[Iter 2100/20000] Original Loss: 0.0017347 Pseudo Loss: 0.0021582 (124.41% of original) (Best: 0.0015223 @iter2087) ([92mâ†“8.41%[0m) [0.69% of initial]
[Iter 2110/20000] Original Loss: 0.0017356 Pseudo Loss: 0.0021582 (124.35% of original) (Best: 0.0014791 @iter2101) ([91mâ†‘0.05%[0m) [0.69% of initial]
[Iter 2120/20000] Original Loss: 0.0014621 Pseudo Loss: 0.0021582 (147.62% of original) (Best: 0.0013332 @iter2120) ([92mâ†“15.76%[0m) [0.58% of initial]
[Iter 2130/20000] Original Loss: 0.0016182 Pseudo Loss: 0.0021582 (133.37% of original) (Best: 0.0013010 @iter2125) ([91mâ†‘10.68%[0m) [0.64% of initial]
[Iter 2140/20000] Original Loss: 0.0017596 Pseudo Loss: 0.0021582 (122.66% of original) (Best: 0.0013010 @iter2125) ([91mâ†‘8.74%[0m) [0.70% of initial]
[Iter 2150/20000] Original Loss: 0.0018168 Pseudo Loss: 0.0021582 (118.79% of original) (Best: 0.0013010 @iter2125) ([91mâ†‘3.25%[0m) [0.72% of initial]
[Iter 2160/20000] Original Loss: 0.0016130 Pseudo Loss: 0.0021582 (133.80% of original) (Best: 0.0013010 @iter2125) ([92mâ†“11.22%[0m) [0.64% of initial]
[Iter 2170/20000] Original Loss: 0.0016499 Pseudo Loss: 0.0021582 (130.81% of original) (Best: 0.0013010 @iter2125) ([91mâ†‘2.29%[0m) [0.66% of initial]
[Iter 2180/20000] Original Loss: 0.0013512 Pseudo Loss: 0.0021582 (159.73% of original) (Best: 0.0012242 @iter2180) ([92mâ†“18.10%[0m) [0.54% of initial]
[Iter 2190/20000] Original Loss: 0.0016139 Pseudo Loss: 0.0021582 (133.73% of original) (Best: 0.0012242 @iter2180) ([91mâ†‘19.44%[0m) [0.64% of initial]
Iter:2199, L1 loss=0.001371, Total loss=0.00153, Time:14
[Iter 2200/20000] Original Loss: 0.0016833 Pseudo Loss: 0.0021582 (128.22% of original) (Best: 0.0012242 @iter2180) ([91mâ†‘4.30%[0m) [0.67% of initial]
[Iter 2210/20000] Original Loss: 0.0075845 Pseudo Loss: 0.0021582 (28.46% of original) (Best: 0.0012242 @iter2180) ([91mâ†‘350.58%[0m) [3.01% of initial]
[Iter 2220/20000] Original Loss: 0.0042555 Pseudo Loss: 0.0021582 (50.72% of original) (Best: 0.0012242 @iter2180) ([92mâ†“43.89%[0m) [1.69% of initial]
[Iter 2230/20000] Original Loss: 0.0027029 Pseudo Loss: 0.0021582 (79.85% of original) (Best: 0.0012242 @iter2180) ([92mâ†“36.48%[0m) [1.07% of initial]
[Iter 2240/20000] Original Loss: 0.0023134 Pseudo Loss: 0.0021582 (93.29% of original) (Best: 0.0012242 @iter2180) ([92mâ†“14.41%[0m) [0.92% of initial]
[Iter 2250/20000] Original Loss: 0.0021240 Pseudo Loss: 0.0021582 (101.61% of original) (Best: 0.0012242 @iter2180) ([92mâ†“8.19%[0m) [0.84% of initial]
[Iter 2260/20000] Original Loss: 0.0017317 Pseudo Loss: 0.0021582 (124.63% of original) (Best: 0.0012242 @iter2180) ([92mâ†“18.47%[0m) [0.69% of initial]
[Iter 2270/20000] Original Loss: 0.0018084 Pseudo Loss: 0.0021582 (119.35% of original) (Best: 0.0012242 @iter2180) ([91mâ†‘4.43%[0m) [0.72% of initial]
[Iter 2280/20000] Original Loss: 0.0014682 Pseudo Loss: 0.0021582 (146.99% of original) (Best: 0.0012242 @iter2180) ([92mâ†“18.81%[0m) [0.58% of initial]
[Iter 2290/20000] Original Loss: 0.0014167 Pseudo Loss: 0.0021582 (152.34% of original) (Best: 0.0012177 @iter2285) ([92mâ†“3.51%[0m) [0.56% of initial]
Iter:2299, L1 loss=0.001299, Total loss=0.001447, Time:15
[Iter 2300/20000] Original Loss: 0.0017147 Pseudo Loss: 0.0021582 (125.87% of original) (Best: 0.0012177 @iter2285) ([91mâ†‘21.03%[0m) [0.68% of initial]
[Iter 2310/20000] Original Loss: 0.0015584 Pseudo Loss: 0.0021582 (138.49% of original) (Best: 0.0012177 @iter2285) ([92mâ†“9.11%[0m) [0.62% of initial]
[Iter 2320/20000] Original Loss: 0.0013179 Pseudo Loss: 0.0021582 (163.76% of original) (Best: 0.0011661 @iter2320) ([92mâ†“15.43%[0m) [0.52% of initial]
[Iter 2330/20000] Original Loss: 0.0013347 Pseudo Loss: 0.0021582 (161.71% of original) (Best: 0.0011577 @iter2329) ([91mâ†‘1.27%[0m) [0.53% of initial]
[Iter 2340/20000] Original Loss: 0.0013609 Pseudo Loss: 0.0021582 (158.59% of original) (Best: 0.0011378 @iter2338) ([91mâ†‘1.96%[0m) [0.54% of initial]
[Iter 2350/20000] Original Loss: 0.0015297 Pseudo Loss: 0.0021582 (141.09% of original) (Best: 0.0011378 @iter2338) ([91mâ†‘12.40%[0m) [0.61% of initial]
[Iter 2360/20000] Original Loss: 0.0013211 Pseudo Loss: 0.0021582 (163.36% of original) (Best: 0.0011006 @iter2359) ([92mâ†“13.63%[0m) [0.52% of initial]
[Iter 2370/20000] Original Loss: 0.0014354 Pseudo Loss: 0.0021582 (150.36% of original) (Best: 0.0011006 @iter2359) ([91mâ†‘8.65%[0m) [0.57% of initial]
[Iter 2380/20000] Original Loss: 0.0014842 Pseudo Loss: 0.0019614 (132.16% of original) (Best: 0.0011006 @iter2359) ([91mâ†‘3.40%[0m) [0.59% of initial]
[Iter 2390/20000] Original Loss: 0.0016105 Pseudo Loss: 0.0019614 (121.79% of original) (Best: 0.0011006 @iter2359) ([91mâ†‘8.51%[0m) [0.64% of initial]
Iter:2399, L1 loss=0.001229, Total loss=0.001309, Time:15
[Iter 2400/20000] Original Loss: 0.0013510 Pseudo Loss: 0.0019614 (145.18% of original) (Best: 0.0011006 @iter2359) ([92mâ†“16.11%[0m) [0.54% of initial]
[Iter 2410/20000] Original Loss: 0.0060932 Pseudo Loss: 0.0019614 (32.19% of original) (Best: 0.0011006 @iter2359) ([91mâ†‘351.01%[0m) [2.42% of initial]
[Iter 2420/20000] Original Loss: 0.0034902 Pseudo Loss: 0.0019614 (56.20% of original) (Best: 0.0011006 @iter2359) ([92mâ†“42.72%[0m) [1.39% of initial]
[Iter 2430/20000] Original Loss: 0.0025237 Pseudo Loss: 0.0019614 (77.72% of original) (Best: 0.0011006 @iter2359) ([92mâ†“27.69%[0m) [1.00% of initial]
[Iter 2440/20000] Original Loss: 0.0020381 Pseudo Loss: 0.0019614 (96.24% of original) (Best: 0.0011006 @iter2359) ([92mâ†“19.24%[0m) [0.81% of initial]
[Iter 2450/20000] Original Loss: 0.0019578 Pseudo Loss: 0.0019614 (100.19% of original) (Best: 0.0011006 @iter2359) ([92mâ†“3.94%[0m) [0.78% of initial]
[Iter 2460/20000] Original Loss: 0.0016858 Pseudo Loss: 0.0019614 (116.35% of original) (Best: 0.0011006 @iter2359) ([92mâ†“13.89%[0m) [0.67% of initial]
[Iter 2470/20000] Original Loss: 0.0016333 Pseudo Loss: 0.0019614 (120.09% of original) (Best: 0.0011006 @iter2359) ([92mâ†“3.12%[0m) [0.65% of initial]
[Iter 2480/20000] Original Loss: 0.0016483 Pseudo Loss: 0.0019614 (119.00% of original) (Best: 0.0011006 @iter2359) ([91mâ†‘0.92%[0m) [0.65% of initial]
[Iter 2490/20000] Original Loss: 0.0014734 Pseudo Loss: 0.0019614 (133.13% of original) (Best: 0.0011006 @iter2359) ([92mâ†“10.62%[0m) [0.59% of initial]
Iter:2499, L1 loss=0.001205, Total loss=0.001214, Time:16
[Iter 2500/20000] Original Loss: 0.0013296 Pseudo Loss: 0.0019614 (147.52% of original) (Best: 0.0011006 @iter2359) ([92mâ†“9.76%[0m) [0.53% of initial]
[Iter 2510/20000] Original Loss: 0.0013639 Pseudo Loss: 0.0019614 (143.81% of original) (Best: 0.0010516 @iter2504) ([91mâ†‘2.58%[0m) [0.54% of initial]
[Iter 2520/20000] Original Loss: 0.0012573 Pseudo Loss: 0.0019614 (156.01% of original) (Best: 0.0010516 @iter2504) ([92mâ†“7.82%[0m) [0.50% of initial]
[Iter 2530/20000] Original Loss: 0.0011183 Pseudo Loss: 0.0019614 (175.40% of original) (Best: 0.0009786 @iter2528) ([92mâ†“11.06%[0m) [0.44% of initial]
[Iter 2540/20000] Original Loss: 0.0012267 Pseudo Loss: 0.0019614 (159.90% of original) (Best: 0.0009786 @iter2528) ([91mâ†‘9.69%[0m) [0.49% of initial]
[Iter 2550/20000] Original Loss: 0.0014369 Pseudo Loss: 0.0019614 (136.50% of original) (Best: 0.0009786 @iter2528) ([91mâ†‘17.14%[0m) [0.57% of initial]
[Iter 2560/20000] Original Loss: 0.0011931 Pseudo Loss: 0.0019614 (164.39% of original) (Best: 0.0009786 @iter2528) ([92mâ†“16.97%[0m) [0.47% of initial]
[Iter 2570/20000] Original Loss: 0.0014066 Pseudo Loss: 0.0019614 (139.45% of original) (Best: 0.0009786 @iter2528) ([91mâ†‘17.89%[0m) [0.56% of initial]
[Iter 2580/20000] Original Loss: 0.0012611 Pseudo Loss: 0.0019614 (155.54% of original) (Best: 0.0009781 @iter2578) ([92mâ†“10.34%[0m) [0.50% of initial]
[Iter 2590/20000] Original Loss: 0.0013450 Pseudo Loss: 0.0019614 (145.84% of original) (Best: 0.0009654 @iter2584) ([91mâ†‘6.65%[0m) [0.53% of initial]
Iter:2599, L1 loss=0.00103, Total loss=0.001084, Time:16
[Iter 2600/20000] Original Loss: 0.0012225 Pseudo Loss: 0.0019614 (160.45% of original) (Best: 0.0009654 @iter2584) ([92mâ†“9.11%[0m) [0.49% of initial]
[Iter 2610/20000] Original Loss: 0.0062556 Pseudo Loss: 0.0019614 (31.35% of original) (Best: 0.0009654 @iter2584) ([91mâ†‘411.72%[0m) [2.49% of initial]
[Iter 2620/20000] Original Loss: 0.0033023 Pseudo Loss: 0.0019614 (59.40% of original) (Best: 0.0009654 @iter2584) ([92mâ†“47.21%[0m) [1.31% of initial]
[Iter 2630/20000] Original Loss: 0.0022505 Pseudo Loss: 0.0019614 (87.16% of original) (Best: 0.0009654 @iter2584) ([92mâ†“31.85%[0m) [0.89% of initial]
[Iter 2640/20000] Original Loss: 0.0017598 Pseudo Loss: 0.0019614 (111.46% of original) (Best: 0.0009654 @iter2584) ([92mâ†“21.80%[0m) [0.70% of initial]
[Iter 2650/20000] Original Loss: 0.0014602 Pseudo Loss: 0.0019614 (134.32% of original) (Best: 0.0009654 @iter2584) ([92mâ†“17.02%[0m) [0.58% of initial]
[Iter 2660/20000] Original Loss: 0.0016229 Pseudo Loss: 0.0019614 (120.86% of original) (Best: 0.0009654 @iter2584) ([91mâ†‘11.14%[0m) [0.64% of initial]
[Iter 2670/20000] Original Loss: 0.0015679 Pseudo Loss: 0.0027651 (176.36% of original) (Best: 0.0009654 @iter2584) ([92mâ†“3.39%[0m) [0.62% of initial]
[Iter 2680/20000] Original Loss: 0.0012234 Pseudo Loss: 0.0027651 (226.01% of original) (Best: 0.0009654 @iter2584) ([92mâ†“21.97%[0m) [0.49% of initial]
[Iter 2690/20000] Original Loss: 0.0011785 Pseudo Loss: 0.0027651 (234.62% of original) (Best: 0.0009654 @iter2584) ([92mâ†“3.67%[0m) [0.47% of initial]
Iter:2699, L1 loss=0.001128, Total loss=0.001149, Time:16
[Iter 2700/20000] Original Loss: 0.0014444 Pseudo Loss: 0.0027651 (191.43% of original) (Best: 0.0009654 @iter2584) ([91mâ†‘22.56%[0m) [0.57% of initial]
[Iter 2710/20000] Original Loss: 0.0012418 Pseudo Loss: 0.0027651 (222.66% of original) (Best: 0.0009654 @iter2584) ([92mâ†“14.03%[0m) [0.49% of initial]
[Iter 2720/20000] Original Loss: 0.0011099 Pseudo Loss: 0.0027651 (249.12% of original) (Best: 0.0009654 @iter2584) ([92mâ†“10.62%[0m) [0.44% of initial]
[Iter 2730/20000] Original Loss: 0.0010123 Pseudo Loss: 0.0027565 (272.31% of original) (Best: 0.0008650 @iter2725) ([92mâ†“8.80%[0m) [0.40% of initial]
[Iter 2740/20000] Original Loss: 0.0008836 Pseudo Loss: 0.0027565 (311.97% of original) (Best: 0.0007981 @iter2740) ([92mâ†“12.71%[0m) [0.35% of initial]
[Iter 2750/20000] Original Loss: 0.0011270 Pseudo Loss: 0.0027565 (244.60% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘27.54%[0m) [0.45% of initial]
[Iter 2760/20000] Original Loss: 0.0012449 Pseudo Loss: 0.0027565 (221.42% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘10.47%[0m) [0.49% of initial]
[Iter 2770/20000] Original Loss: 0.0013686 Pseudo Loss: 0.0027565 (201.42% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘9.93%[0m) [0.54% of initial]
[Iter 2780/20000] Original Loss: 0.0011094 Pseudo Loss: 0.0027565 (248.47% of original) (Best: 0.0007981 @iter2740) ([92mâ†“18.94%[0m) [0.44% of initial]
[Iter 2790/20000] Original Loss: 0.0011580 Pseudo Loss: 0.0027565 (238.05% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘4.38%[0m) [0.46% of initial]
Iter:2799, L1 loss=0.001308, Total loss=0.001288, Time:16
[Iter 2800/20000] Original Loss: 0.0011408 Pseudo Loss: 0.0027565 (241.64% of original) (Best: 0.0007981 @iter2740) ([92mâ†“1.48%[0m) [0.45% of initial]
[Iter 2810/20000] Original Loss: 0.0052028 Pseudo Loss: 0.0027565 (52.98% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘356.08%[0m) [2.07% of initial]
[Iter 2820/20000] Original Loss: 0.0027497 Pseudo Loss: 0.0027565 (100.25% of original) (Best: 0.0007981 @iter2740) ([92mâ†“47.15%[0m) [1.09% of initial]
[Iter 2830/20000] Original Loss: 0.0017900 Pseudo Loss: 0.0027565 (153.99% of original) (Best: 0.0007981 @iter2740) ([92mâ†“34.90%[0m) [0.71% of initial]
[Iter 2840/20000] Original Loss: 0.0015124 Pseudo Loss: 0.0027565 (182.26% of original) (Best: 0.0007981 @iter2740) ([92mâ†“15.51%[0m) [0.60% of initial]
[Iter 2850/20000] Original Loss: 0.0012920 Pseudo Loss: 0.0027565 (213.35% of original) (Best: 0.0007981 @iter2740) ([92mâ†“14.57%[0m) [0.51% of initial]
[Iter 2860/20000] Original Loss: 0.0014040 Pseudo Loss: 0.0027565 (196.33% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘8.67%[0m) [0.56% of initial]
[Iter 2870/20000] Original Loss: 0.0011937 Pseudo Loss: 0.0027565 (230.93% of original) (Best: 0.0007981 @iter2740) ([92mâ†“14.98%[0m) [0.47% of initial]
[Iter 2880/20000] Original Loss: 0.0011784 Pseudo Loss: 0.0027565 (233.91% of original) (Best: 0.0007981 @iter2740) ([92mâ†“1.27%[0m) [0.47% of initial]
[Iter 2890/20000] Original Loss: 0.0011178 Pseudo Loss: 0.0027565 (246.59% of original) (Best: 0.0007981 @iter2740) ([92mâ†“5.14%[0m) [0.44% of initial]
Iter:2899, L1 loss=0.0008918, Total loss=0.0008703, Time:17
[Iter 2900/20000] Original Loss: 0.0010531 Pseudo Loss: 0.0027565 (261.75% of original) (Best: 0.0007981 @iter2740) ([92mâ†“5.79%[0m) [0.42% of initial]
[Iter 2910/20000] Original Loss: 0.0011174 Pseudo Loss: 0.0027565 (246.68% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘6.11%[0m) [0.44% of initial]
[Iter 2920/20000] Original Loss: 0.0011767 Pseudo Loss: 0.0027565 (234.25% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘5.31%[0m) [0.47% of initial]
[Iter 2930/20000] Original Loss: 0.0011121 Pseudo Loss: 0.0027565 (247.87% of original) (Best: 0.0007981 @iter2740) ([92mâ†“5.49%[0m) [0.44% of initial]
[Iter 2940/20000] Original Loss: 0.0009580 Pseudo Loss: 0.0027565 (287.74% of original) (Best: 0.0007981 @iter2740) ([92mâ†“13.86%[0m) [0.38% of initial]
[Iter 2950/20000] Original Loss: 0.0009534 Pseudo Loss: 0.0027565 (289.13% of original) (Best: 0.0007981 @iter2740) ([92mâ†“0.48%[0m) [0.38% of initial]
[Iter 2960/20000] Original Loss: 0.0010173 Pseudo Loss: 0.0027565 (270.96% of original) (Best: 0.0007981 @iter2740) ([91mâ†‘6.71%[0m) [0.40% of initial]
[Iter 2970/20000] Original Loss: 0.0009059 Pseudo Loss: 0.0027565 (304.27% of original) (Best: 0.0007457 @iter2969) ([92mâ†“10.95%[0m) [0.36% of initial]
[Iter 2980/20000] Original Loss: 0.0008273 Pseudo Loss: 0.0027565 (333.19% of original) (Best: 0.0007412 @iter2977) ([92mâ†“8.68%[0m) [0.33% of initial]
[Iter 2990/20000] Original Loss: 0.0008748 Pseudo Loss: 0.0027565 (315.10% of original) (Best: 0.0007015 @iter2983) ([91mâ†‘5.74%[0m) [0.35% of initial]
Iter:2999, L1 loss=0.0007107, Total loss=0.000675, Time:16
[Iter 3000/20000] Original Loss: 0.0008374 Pseudo Loss: 0.0027565 (329.16% of original) (Best: 0.0006750 @iter2999) ([92mâ†“4.27%[0m) [0.33% of initial]
[Iter 3010/20000] Original Loss: 0.0050904 Pseudo Loss: 0.0027565 (54.15% of original) (Best: 0.0006750 @iter2999) ([91mâ†‘507.86%[0m) [2.02% of initial]
[Iter 3020/20000] Original Loss: 0.0028085 Pseudo Loss: 0.0027565 (98.15% of original) (Best: 0.0006750 @iter2999) ([92mâ†“44.83%[0m) [1.12% of initial]
[Iter 3030/20000] Original Loss: 0.0022045 Pseudo Loss: 0.0027565 (125.04% of original) (Best: 0.0006750 @iter2999) ([92mâ†“21.51%[0m) [0.88% of initial]
[Iter 3040/20000] Original Loss: 0.0017386 Pseudo Loss: 0.0027565 (158.55% of original) (Best: 0.0006750 @iter2999) ([92mâ†“21.14%[0m) [0.69% of initial]
[Iter 3050/20000] Original Loss: 0.0014633 Pseudo Loss: 0.0027565 (188.38% of original) (Best: 0.0006750 @iter2999) ([92mâ†“15.84%[0m) [0.58% of initial]
[Iter 3060/20000] Original Loss: 0.0013949 Pseudo Loss: 0.0027565 (197.62% of original) (Best: 0.0006750 @iter2999) ([92mâ†“4.68%[0m) [0.55% of initial]
[Iter 3070/20000] Original Loss: 0.0011309 Pseudo Loss: 0.0023083 (204.12% of original) (Best: 0.0006750 @iter2999) ([92mâ†“18.92%[0m) [0.45% of initial]
[Iter 3080/20000] Original Loss: 0.0011547 Pseudo Loss: 0.0023083 (199.90% of original) (Best: 0.0006750 @iter2999) ([91mâ†‘2.11%[0m) [0.46% of initial]
[Iter 3090/20000] Original Loss: 0.0010851 Pseudo Loss: 0.0023083 (212.73% of original) (Best: 0.0006750 @iter2999) ([92mâ†“6.03%[0m) [0.43% of initial]
Iter:3099, L1 loss=0.0008991, Total loss=0.000898, Time:17
[Iter 3100/20000] Original Loss: 0.0010021 Pseudo Loss: 0.0023083 (230.36% of original) (Best: 0.0006750 @iter2999) ([92mâ†“7.65%[0m) [0.40% of initial]
[Iter 3110/20000] Original Loss: 0.0011305 Pseudo Loss: 0.0023083 (204.20% of original) (Best: 0.0006750 @iter2999) ([91mâ†‘12.81%[0m) [0.45% of initial]
[Iter 3120/20000] Original Loss: 0.0010797 Pseudo Loss: 0.0023083 (213.79% of original) (Best: 0.0006750 @iter2999) ([92mâ†“4.49%[0m) [0.43% of initial]
[Iter 3130/20000] Original Loss: 0.0008631 Pseudo Loss: 0.0023083 (267.46% of original) (Best: 0.0006750 @iter2999) ([92mâ†“20.07%[0m) [0.34% of initial]
[Iter 3140/20000] Original Loss: 0.0008223 Pseudo Loss: 0.0023083 (280.72% of original) (Best: 0.0006733 @iter3139) ([92mâ†“4.72%[0m) [0.33% of initial]
[Iter 3150/20000] Original Loss: 0.0008538 Pseudo Loss: 0.0023083 (270.36% of original) (Best: 0.0006733 @iter3139) ([91mâ†‘3.83%[0m) [0.34% of initial]
[Iter 3160/20000] Original Loss: 0.0008223 Pseudo Loss: 0.0023083 (280.71% of original) (Best: 0.0006733 @iter3139) ([92mâ†“3.69%[0m) [0.33% of initial]
[Iter 3170/20000] Original Loss: 0.0008330 Pseudo Loss: 0.0023083 (277.11% of original) (Best: 0.0006733 @iter3139) ([91mâ†‘1.30%[0m) [0.33% of initial]
[Iter 3180/20000] Original Loss: 0.0009086 Pseudo Loss: 0.0023083 (254.05% of original) (Best: 0.0006733 @iter3139) ([91mâ†‘9.08%[0m) [0.36% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 10] Gaussian 0 vs 1:
  Original Loss: 0.2126908
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 10] Gaussian 1 vs 0:
  Original Loss: 0.2126908
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693032 @iter20) ([92mâ†“19.84%[0m) [69.39% of initial]
[Iter 20] Gaussian 0 vs 1:
  Original Loss: 0.1693032
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1693032 (Pseudo: 0.00%)
[Iter 20] Gaussian 1 vs 0:
  Original Loss: 0.1693031
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1693031 (Pseudo: 0.00%)
[Iter 30/20000] Loss: 0.1374904 (Best: 0.1327874 @iter30) ([92mâ†“21.29%[0m) [54.62% of initial]
[Iter 30] Gaussian 0 vs 1:
  Original Loss: 0.1327874
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1327874 (Pseudo: 0.00%)
[Iter 30] Gaussian 1 vs 0:
  Original Loss: 0.1327881
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1327881 (Pseudo: 0.00%)
[Iter 40/20000] Loss: 0.1123929 (Best: 0.1098391 @iter40) ([92mâ†“18.25%[0m) [44.65% of initial]
[Iter 40] Gaussian 0 vs 1:
  Original Loss: 0.1098391
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1098391 (Pseudo: 0.00%)
[Iter 40] Gaussian 1 vs 0:
  Original Loss: 0.1098367
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.1098367 (Pseudo: 0.00%)
[Iter 50/20000] Loss: 0.0993467 (Best: 0.0965446 @iter49) ([92mâ†“11.61%[0m) [39.47% of initial]
[Iter 50] Gaussian 0 vs 1:
  Original Loss: 0.0994881
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0994881 (Pseudo: 0.00%)
[Iter 50] Gaussian 1 vs 0:
  Original Loss: 0.0994867
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0994867 (Pseudo: 0.00%)
[Iter 60/20000] Loss: 0.0936726 (Best: 0.0908473 @iter59) ([92mâ†“5.71%[0m) [37.22% of initial]
[Iter 60] Gaussian 0 vs 1:
  Original Loss: 0.0940218
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0940218 (Pseudo: 0.00%)
[Iter 60] Gaussian 1 vs 0:
  Original Loss: 0.0940245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0940245 (Pseudo: 0.00%)
[Iter 70/20000] Loss: 0.0884486 (Best: 0.0869353 @iter70) ([92mâ†“5.58%[0m) [35.14% of initial]
[Iter 70] Gaussian 0 vs 1:
  Original Loss: 0.0869353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0869353 (Pseudo: 0.00%)
[Iter 70] Gaussian 1 vs 0:
  Original Loss: 0.0869347
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0869347 (Pseudo: 0.00%)
[Iter 80/20000] Loss: 0.0851862 (Best: 0.0831028 @iter80) ([92mâ†“3.69%[0m) [33.84% of initial]
[Iter 80] Gaussian 0 vs 1:
  Original Loss: 0.0831028
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0831028 (Pseudo: 0.00%)
[Iter 80] Gaussian 1 vs 0:
  Original Loss: 0.0831017
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0831017 (Pseudo: 0.00%)
[Iter 90/20000] Loss: 0.0824125 (Best: 0.0801463 @iter88) ([92mâ†“3.26%[0m) [32.74% of initial]
[Iter 90] Gaussian 0 vs 1:
  Original Loss: 0.0823522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0823522 (Pseudo: 0.00%)
[Iter 90] Gaussian 1 vs 0:
  Original Loss: 0.0823472
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0823472 (Pseudo: 0.00%)
Iter:99, L1 loss=0.05723, Total loss=0.07875, Time:14
[Iter 100/20000] Loss: 0.0786595 (Best: 0.0766176 @iter97) ([92mâ†“4.55%[0m) [31.25% of initial]
[Iter 100] Gaussian 0 vs 1:
  Original Loss: 0.0782890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0782890 (Pseudo: 0.00%)
[Iter 100] Gaussian 1 vs 0:
  Original Loss: 0.0782995
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0782995 (Pseudo: 0.00%)
[Iter 110/20000] Loss: 0.0753305 (Best: 0.0731322 @iter106) ([92mâ†“4.23%[0m) [29.93% of initial]
[Iter 110] Gaussian 0 vs 1:
  Original Loss: 0.0744890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0744890 (Pseudo: 0.00%)
[Iter 110] Gaussian 1 vs 0:
  Original Loss: 0.0744969
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0744969 (Pseudo: 0.00%)
[Iter 120/20000] Loss: 0.0714365 (Best: 0.0685671 @iter118) ([92mâ†“5.17%[0m) [28.38% of initial]
[Iter 120] Gaussian 0 vs 1:
  Original Loss: 0.0723054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0723054 (Pseudo: 0.00%)
[Iter 120] Gaussian 1 vs 0:
  Original Loss: 0.0723218
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0723218 (Pseudo: 0.00%)
[Iter 130/20000] Loss: 0.0667060 (Best: 0.0642167 @iter130) ([92mâ†“6.62%[0m) [26.50% of initial]
[Iter 130] Gaussian 0 vs 1:
  Original Loss: 0.0642167
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0642167 (Pseudo: 0.00%)
[Iter 130] Gaussian 1 vs 0:
  Original Loss: 0.0642049
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0642049 (Pseudo: 0.00%)
[Iter 140/20000] Loss: 0.0635588 (Best: 0.0613106 @iter140) ([92mâ†“4.72%[0m) [25.25% of initial]
[Iter 140] Gaussian 0 vs 1:
  Original Loss: 0.0613106
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0613106 (Pseudo: 0.00%)
[Iter 140] Gaussian 1 vs 0:
  Original Loss: 0.0612862
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0612862 (Pseudo: 0.00%)
[Iter 150/20000] Loss: 0.0612936 (Best: 0.0584034 @iter148) ([92mâ†“3.56%[0m) [24.35% of initial]
[Iter 150] Gaussian 0 vs 1:
  Original Loss: 0.0605803
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0605803 (Pseudo: 0.00%)
[Iter 150] Gaussian 1 vs 0:
  Original Loss: 0.0605246
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0605246 (Pseudo: 0.00%)
[Iter 160/20000] Loss: 0.0590792 (Best: 0.0559436 @iter157) ([92mâ†“3.61%[0m) [23.47% of initial]
[Iter 160] Gaussian 0 vs 1:
  Original Loss: 0.0600219
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0600219 (Pseudo: 0.00%)
[Iter 160] Gaussian 1 vs 0:
  Original Loss: 0.0599866
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0599866 (Pseudo: 0.00%)
[Iter 170/20000] Loss: 0.0563707 (Best: 0.0535459 @iter167) ([92mâ†“4.58%[0m) [22.40% of initial]
[Iter 170] Gaussian 0 vs 1:
  Original Loss: 0.0574144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0574144 (Pseudo: 0.00%)
[Iter 170] Gaussian 1 vs 0:
  Original Loss: 0.0573768
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0573768 (Pseudo: 0.00%)
[Iter 180/20000] Loss: 0.0523170 (Best: 0.0499551 @iter179) ([92mâ†“7.19%[0m) [20.79% of initial]
[Iter 180] Gaussian 0 vs 1:
  Original Loss: 0.0518869
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0518869 (Pseudo: 0.00%)
[Iter 180] Gaussian 1 vs 0:
  Original Loss: 0.0518797
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0518797 (Pseudo: 0.00%)
[Iter 190/20000] Loss: 0.0495569 (Best: 0.0478060 @iter188) ([92mâ†“5.28%[0m) [19.69% of initial]
[Iter 190] Gaussian 0 vs 1:
  Original Loss: 0.0490611
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0490611 (Pseudo: 0.00%)
[Iter 190] Gaussian 1 vs 0:
  Original Loss: 0.0490043
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0490043 (Pseudo: 0.00%)
Iter:199, L1 loss=0.03439, Total loss=0.04972, Time:13
[Iter 200/20000] Loss: 0.0478035 (Best: 0.0456395 @iter198) ([92mâ†“3.54%[0m) [18.99% of initial]
[Iter 200] Gaussian 0 vs 1:
  Original Loss: 0.0467061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0467061 (Pseudo: 0.00%)
[Iter 200] Gaussian 1 vs 0:
  Original Loss: 0.0466626
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0466626 (Pseudo: 0.00%)
[Iter 210/20000] Loss: 0.0451214 (Best: 0.0429170 @iter209) ([92mâ†“5.61%[0m) [17.93% of initial]
[Iter 210] Gaussian 0 vs 1:
  Original Loss: 0.0449412
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0449412 (Pseudo: 0.00%)
[Iter 210] Gaussian 1 vs 0:
  Original Loss: 0.0448964
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0448964 (Pseudo: 0.00%)
[Iter 220/20000] Loss: 0.0441093 (Best: 0.0412987 @iter219) ([92mâ†“2.24%[0m) [17.52% of initial]
[Iter 220] Gaussian 0 vs 1:
  Original Loss: 0.0454830
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0454830 (Pseudo: 0.00%)
[Iter 220] Gaussian 1 vs 0:
  Original Loss: 0.0454687
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0454687 (Pseudo: 0.00%)
[Iter 230/20000] Loss: 0.0423580 (Best: 0.0399695 @iter227) ([92mâ†“3.97%[0m) [16.83% of initial]
[Iter 230] Gaussian 0 vs 1:
  Original Loss: 0.0410731
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0410731 (Pseudo: 0.00%)
[Iter 230] Gaussian 1 vs 0:
  Original Loss: 0.0410271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0410271 (Pseudo: 0.00%)
[Iter 240/20000] Loss: 0.0403109 (Best: 0.0378554 @iter238) ([92mâ†“4.83%[0m) [16.02% of initial]
[Iter 240] Gaussian 0 vs 1:
  Original Loss: 0.0394540
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0394540 (Pseudo: 0.00%)
[Iter 240] Gaussian 1 vs 0:
  Original Loss: 0.0393807
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0393807 (Pseudo: 0.00%)
[Iter 250/20000] Loss: 0.0380480 (Best: 0.0364345 @iter248) ([92mâ†“5.61%[0m) [15.12% of initial]
[Iter 250] Gaussian 0 vs 1:
  Original Loss: 0.0376637
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0376637 (Pseudo: 0.00%)
[Iter 250] Gaussian 1 vs 0:
  Original Loss: 0.0375876
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0375876 (Pseudo: 0.00%)
[Iter 260/20000] Loss: 0.0359541 (Best: 0.0344145 @iter260) ([92mâ†“5.50%[0m) [14.28% of initial]
[Iter 260] Gaussian 0 vs 1:
  Original Loss: 0.0344145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0344145 (Pseudo: 0.00%)
[Iter 260] Gaussian 1 vs 0:
  Original Loss: 0.0343649
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0343649 (Pseudo: 0.00%)
[Iter 270/20000] Loss: 0.0351133 (Best: 0.0329082 @iter269) ([92mâ†“2.34%[0m) [13.95% of initial]
[Iter 270] Gaussian 0 vs 1:
  Original Loss: 0.0349457
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0349457 (Pseudo: 0.00%)
[Iter 270] Gaussian 1 vs 0:
  Original Loss: 0.0346965
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0346965 (Pseudo: 0.00%)
[Iter 280/20000] Loss: 0.0348929 (Best: 0.0320895 @iter277) ([92mâ†“0.63%[0m) [13.86% of initial]
[Iter 280] Gaussian 0 vs 1:
  Original Loss: 0.0360350
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0360350 (Pseudo: 0.00%)
[Iter 280] Gaussian 1 vs 0:
  Original Loss: 0.0358975
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0358975 (Pseudo: 0.00%)
[Iter 290/20000] Loss: 0.0332877 (Best: 0.0307509 @iter287) ([92mâ†“4.60%[0m) [13.22% of initial]
[Iter 290] Gaussian 0 vs 1:
  Original Loss: 0.0321821
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0321821 (Pseudo: 0.00%)
[Iter 290] Gaussian 1 vs 0:
  Original Loss: 0.0320641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0320641 (Pseudo: 0.00%)
Iter:299, L1 loss=0.02223, Total loss=0.03345, Time:13
[Iter 300/20000] Loss: 0.0308694 (Best: 0.0289517 @iter300) ([92mâ†“7.26%[0m) [12.26% of initial]
[Iter 300] Gaussian 0 vs 1:
  Original Loss: 0.0289517
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0289517 (Pseudo: 0.00%)
[Iter 300] Gaussian 1 vs 0:
  Original Loss: 0.0288728
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0288728 (Pseudo: 0.00%)
[Iter 310/20000] Loss: 0.0294541 (Best: 0.0275258 @iter310) ([92mâ†“4.58%[0m) [11.70% of initial]
[Iter 310] Gaussian 0 vs 1:
  Original Loss: 0.0275258
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0275258 (Pseudo: 0.00%)
[Iter 310] Gaussian 1 vs 0:
  Original Loss: 0.0274410
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0274410 (Pseudo: 0.00%)
[Iter 320/20000] Loss: 0.0281077 (Best: 0.0268069 @iter320) ([92mâ†“4.57%[0m) [11.17% of initial]
[Iter 320] Gaussian 0 vs 1:
  Original Loss: 0.0268069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0268069 (Pseudo: 0.00%)
[Iter 320] Gaussian 1 vs 0:
  Original Loss: 0.0264823
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0264823 (Pseudo: 0.00%)
[Iter 330/20000] Loss: 0.0273802 (Best: 0.0254291 @iter330) ([92mâ†“2.59%[0m) [10.88% of initial]
[Iter 330] Gaussian 0 vs 1:
  Original Loss: 0.0254291
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0254291 (Pseudo: 0.00%)
[Iter 330] Gaussian 1 vs 0:
  Original Loss: 0.0255578
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0255578 (Pseudo: 0.00%)
[Iter 340/20000] Loss: 0.0252536 (Best: 0.0241521 @iter340) ([92mâ†“7.77%[0m) [10.03% of initial]
[Iter 340] Gaussian 0 vs 1:
  Original Loss: 0.0241521
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0241521 (Pseudo: 0.00%)
[Iter 340] Gaussian 1 vs 0:
  Original Loss: 0.0240770
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0240770 (Pseudo: 0.00%)
[Iter 350/20000] Loss: 0.0257944 (Best: 0.0230991 @iter349) ([91mâ†‘2.14%[0m) [10.25% of initial]
[Iter 350] Gaussian 0 vs 1:
  Original Loss: 0.0271488
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0271488 (Pseudo: 0.00%)
[Iter 350] Gaussian 1 vs 0:
  Original Loss: 0.0272299
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0272299 (Pseudo: 0.00%)
[Iter 360/20000] Loss: 0.0242940 (Best: 0.0222765 @iter358) ([92mâ†“5.82%[0m) [9.65% of initial]
[Iter 360] Gaussian 0 vs 1:
  Original Loss: 0.0238383
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0238383 (Pseudo: 0.00%)
[Iter 360] Gaussian 1 vs 0:
  Original Loss: 0.0239671
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0239671 (Pseudo: 0.00%)
[Iter 370/20000] Loss: 0.0241734 (Best: 0.0218732 @iter361) ([92mâ†“0.50%[0m) [9.60% of initial]
[Iter 370] Gaussian 0 vs 1:
  Original Loss: 0.0253446
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0253446 (Pseudo: 0.00%)
[Iter 370] Gaussian 1 vs 0:
  Original Loss: 0.0250924
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0250924 (Pseudo: 0.00%)
[Iter 380/20000] Loss: 0.0217383 (Best: 0.0206792 @iter379) ([92mâ†“10.07%[0m) [8.64% of initial]
[Iter 380] Gaussian 0 vs 1:
  Original Loss: 0.0220522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0220522 (Pseudo: 0.00%)
[Iter 380] Gaussian 1 vs 0:
  Original Loss: 0.0221860
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0221860 (Pseudo: 0.00%)
[Iter 390/20000] Loss: 0.0213690 (Best: 0.0199424 @iter390) ([92mâ†“1.70%[0m) [8.49% of initial]
[Iter 390] Gaussian 0 vs 1:
  Original Loss: 0.0199424
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0199424 (Pseudo: 0.00%)
[Iter 390] Gaussian 1 vs 0:
  Original Loss: 0.0200245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0200245 (Pseudo: 0.00%)
Iter:399, L1 loss=0.01349, Total loss=0.02106, Time:13
[Iter 400/20000] Loss: 0.0203755 (Best: 0.0189369 @iter400) ([92mâ†“4.65%[0m) [8.09% of initial]
[Iter 400] Gaussian 0 vs 1:
  Original Loss: 0.0189369
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0189369 (Pseudo: 0.00%)
[Iter 400] Gaussian 1 vs 0:
  Original Loss: 0.0189504
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0189504 (Pseudo: 0.00%)
[Iter 410/20000] Loss: 0.0192299 (Best: 0.0182271 @iter410) ([92mâ†“5.62%[0m) [7.64% of initial]
[Iter 410] Gaussian 0 vs 1:
  Original Loss: 0.0182271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0182271 (Pseudo: 0.00%)
[Iter 410] Gaussian 1 vs 0:
  Original Loss: 0.0184672
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0184672 (Pseudo: 0.00%)
[Iter 420/20000] Loss: 0.0196615 (Best: 0.0175988 @iter418) ([91mâ†‘2.24%[0m) [7.81% of initial]
[Iter 420] Gaussian 0 vs 1:
  Original Loss: 0.0208778
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0208778 (Pseudo: 0.00%)
[Iter 420] Gaussian 1 vs 0:
  Original Loss: 0.0213819
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0213819 (Pseudo: 0.00%)
[Iter 430/20000] Loss: 0.0175741 (Best: 0.0166156 @iter430) ([92mâ†“10.62%[0m) [6.98% of initial]
[Iter 430] Gaussian 0 vs 1:
  Original Loss: 0.0166156
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0166156 (Pseudo: 0.00%)
[Iter 430] Gaussian 1 vs 0:
  Original Loss: 0.0168131
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0168131 (Pseudo: 0.00%)
[Iter 440/20000] Loss: 0.0178229 (Best: 0.0162050 @iter438) ([91mâ†‘1.42%[0m) [7.08% of initial]
[Iter 440] Gaussian 0 vs 1:
  Original Loss: 0.0185417
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0185417 (Pseudo: 0.00%)
[Iter 440] Gaussian 1 vs 0:
  Original Loss: 0.0190324
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0190324 (Pseudo: 0.00%)
[Iter 450/20000] Loss: 0.0168776 (Best: 0.0151192 @iter449) ([92mâ†“5.30%[0m) [6.71% of initial]
[Iter 450] Gaussian 0 vs 1:
  Original Loss: 0.0179629
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0179629 (Pseudo: 0.00%)
[Iter 450] Gaussian 1 vs 0:
  Original Loss: 0.0183206
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0183206 (Pseudo: 0.00%)
[Iter 460/20000] Loss: 0.0169664 (Best: 0.0149961 @iter458) ([91mâ†‘0.53%[0m) [6.74% of initial]
[Iter 460] Gaussian 0 vs 1:
  Original Loss: 0.0176798
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0176798 (Pseudo: 0.00%)
[Iter 460] Gaussian 1 vs 0:
  Original Loss: 0.0169604
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0169604 (Pseudo: 0.00%)
[Iter 470/20000] Loss: 0.0151849 (Best: 0.0141054 @iter470) ([92mâ†“10.50%[0m) [6.03% of initial]
[Iter 470] Gaussian 0 vs 1:
  Original Loss: 0.0141054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0141054 (Pseudo: 0.00%)
[Iter 470] Gaussian 1 vs 0:
  Original Loss: 0.0141022
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0141022 (Pseudo: 0.00%)
[Iter 480/20000] Loss: 0.0147504 (Best: 0.0131768 @iter479) ([92mâ†“2.86%[0m) [5.86% of initial]
[Iter 480] Gaussian 0 vs 1:
  Original Loss: 0.0149577
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0149577 (Pseudo: 0.00%)
[Iter 480] Gaussian 1 vs 0:
  Original Loss: 0.0156600
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0156600 (Pseudo: 0.00%)
[Iter 490/20000] Loss: 0.0136229 (Best: 0.0125717 @iter490) ([92mâ†“7.64%[0m) [5.41% of initial]
[Iter 490] Gaussian 0 vs 1:
  Original Loss: 0.0125717
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0125717 (Pseudo: 0.00%)
[Iter 490] Gaussian 1 vs 0:
  Original Loss: 0.0129172
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0129172 (Pseudo: 0.00%)
Iter:499, L1 loss=0.008572, Total loss=0.01473, Time:13
[Iter 500/20000] Loss: 0.0138864 (Best: 0.0125717 @iter490) ([91mâ†‘1.93%[0m) [5.52% of initial]
[Iter 500] Gaussian 0 vs 1:
  Original Loss: 0.0135728
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0135728 (Pseudo: 0.00%)
[Iter 500] Gaussian 1 vs 0:
  Original Loss: 0.0138634
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0138634 (Pseudo: 0.00%)
[Iter 510/20000] Loss: 0.0137117 (Best: 0.0122981 @iter508) ([92mâ†“1.26%[0m) [5.45% of initial]
[Iter 510] Gaussian 0 vs 1:
  Original Loss: 0.0138867
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0138867 (Pseudo: 0.00%)
[Iter 510] Gaussian 1 vs 0:
  Original Loss: 0.0140105
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0140105 (Pseudo: 0.00%)
[Iter 520/20000] Loss: 0.0130142 (Best: 0.0118542 @iter514) ([92mâ†“5.09%[0m) [5.17% of initial]
[Iter 520] Gaussian 0 vs 1:
  Original Loss: 0.0130147
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0130147 (Pseudo: 0.00%)
[Iter 520] Gaussian 1 vs 0:
  Original Loss: 0.0137921
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0137921 (Pseudo: 0.00%)
[Iter 530/20000] Loss: 0.0125349 (Best: 0.0113220 @iter529) ([92mâ†“3.68%[0m) [4.98% of initial]
[Iter 530] Gaussian 0 vs 1:
  Original Loss: 0.0127368
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0127368 (Pseudo: 0.00%)
[Iter 530] Gaussian 1 vs 0:
  Original Loss: 0.0128324
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0128324 (Pseudo: 0.00%)
[Iter 540/20000] Loss: 0.0123509 (Best: 0.0109954 @iter538) ([92mâ†“1.47%[0m) [4.91% of initial]
[Iter 540] Gaussian 0 vs 1:
  Original Loss: 0.0123127
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0123127 (Pseudo: 0.00%)
[Iter 540] Gaussian 1 vs 0:
  Original Loss: 0.0124902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0124902 (Pseudo: 0.00%)
[Iter 550/20000] Loss: 0.0120223 (Best: 0.0108873 @iter548) ([92mâ†“2.66%[0m) [4.78% of initial]
[Iter 550] Gaussian 0 vs 1:
  Original Loss: 0.0120178
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0120178 (Pseudo: 0.00%)
[Iter 550] Gaussian 1 vs 0:
  Original Loss: 0.0120192
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0120192 (Pseudo: 0.00%)
[Iter 560/20000] Loss: 0.0120279 (Best: 0.0107718 @iter554) ([91mâ†‘0.05%[0m) [4.78% of initial]
[Iter 560] Gaussian 0 vs 1:
  Original Loss: 0.0117566
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0117566 (Pseudo: 0.00%)
[Iter 560] Gaussian 1 vs 0:
  Original Loss: 0.0120415
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0120415 (Pseudo: 0.00%)
[Iter 570/20000] Loss: 0.0116612 (Best: 0.0105740 @iter569) ([92mâ†“3.05%[0m) [4.63% of initial]
[Iter 570] Gaussian 0 vs 1:
  Original Loss: 0.0125414
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0125414 (Pseudo: 0.00%)
[Iter 570] Gaussian 1 vs 0:
  Original Loss: 0.0124742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0124742 (Pseudo: 0.00%)
[Iter 580/20000] Loss: 0.0111474 (Best: 0.0102315 @iter578) ([92mâ†“4.41%[0m) [4.43% of initial]
[Iter 580] Gaussian 0 vs 1:
  Original Loss: 0.0111191
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0111191 (Pseudo: 0.00%)
[Iter 580] Gaussian 1 vs 0:
  Original Loss: 0.0112327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0112327 (Pseudo: 0.00%)
[Iter 590/20000] Loss: 0.0112633 (Best: 0.0101339 @iter581) ([91mâ†‘1.04%[0m) [4.47% of initial]
[Iter 590] Gaussian 0 vs 1:
  Original Loss: 0.0110161
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0110161 (Pseudo: 0.00%)
[Iter 590] Gaussian 1 vs 0:
  Original Loss: 0.0115692
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0115692 (Pseudo: 0.00%)
Iter:599, L1 loss=0.007102, Total loss=0.01171, Time:12
[Iter 600/20000] Loss: 0.0109169 (Best: 0.0099806 @iter597) ([92mâ†“3.08%[0m) [4.34% of initial]
[Iter 600] Gaussian 0 vs 1:
  Original Loss: 0.0109069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0109069 (Pseudo: 0.00%)
[Iter 600] Gaussian 1 vs 0:
  Original Loss: 0.0112734
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0112734 (Pseudo: 0.00%)
[Iter 610/20000] Loss: 0.0226870 (Best: 0.0099806 @iter597) ([91mâ†‘107.82%[0m) [9.01% of initial]
[Iter 610] Gaussian 0 vs 1:
  Original Loss: 0.0201165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0201165 (Pseudo: 0.00%)
[Iter 610] Gaussian 1 vs 0:
  Original Loss: 0.0185503
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0185503 (Pseudo: 0.00%)
[Iter 620/20000] Loss: 0.0142463 (Best: 0.0099806 @iter597) ([92mâ†“37.20%[0m) [5.66% of initial]
[Iter 620] Gaussian 0 vs 1:
  Original Loss: 0.0128440
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0128440 (Pseudo: 0.00%)
[Iter 620] Gaussian 1 vs 0:
  Original Loss: 0.0127735
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0127735 (Pseudo: 0.00%)
[Iter 630/20000] Loss: 0.0121296 (Best: 0.0099806 @iter597) ([92mâ†“14.86%[0m) [4.82% of initial]
[Iter 630] Gaussian 0 vs 1:
  Original Loss: 0.0111938
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0111938 (Pseudo: 0.00%)
[Iter 630] Gaussian 1 vs 0:
  Original Loss: 0.0115964
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0115964 (Pseudo: 0.00%)
[Iter 640/20000] Loss: 0.0103583 (Best: 0.0093827 @iter640) ([92mâ†“14.60%[0m) [4.12% of initial]
[Iter 640] Gaussian 0 vs 1:
  Original Loss: 0.0093827
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0093827 (Pseudo: 0.00%)
[Iter 640] Gaussian 1 vs 0:
  Original Loss: 0.0096929
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0096929 (Pseudo: 0.00%)
[Iter 650/20000] Loss: 0.0106687 (Best: 0.0090992 @iter646) ([91mâ†‘3.00%[0m) [4.24% of initial]
[Iter 650] Gaussian 0 vs 1:
  Original Loss: 0.0106487
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0106487 (Pseudo: 0.00%)
[Iter 650] Gaussian 1 vs 0:
  Original Loss: 0.0104906
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0104906 (Pseudo: 0.00%)
[Iter 660/20000] Loss: 0.0100758 (Best: 0.0088308 @iter655) ([92mâ†“5.56%[0m) [4.00% of initial]
[Iter 660] Gaussian 0 vs 1:
  Original Loss: 0.0107269
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0107269 (Pseudo: 0.00%)
[Iter 660] Gaussian 1 vs 0:
  Original Loss: 0.0105760
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0105760 (Pseudo: 0.00%)
[Iter 670/20000] Loss: 0.0096225 (Best: 0.0085632 @iter667) ([92mâ†“4.50%[0m) [3.82% of initial]
[Iter 670] Gaussian 0 vs 1:
  Original Loss: 0.0095038
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0095038 (Pseudo: 0.00%)
[Iter 670] Gaussian 1 vs 0:
  Original Loss: 0.0095573
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0095573 (Pseudo: 0.00%)
[Iter 680/20000] Loss: 0.0089444 (Best: 0.0083295 @iter680) ([92mâ†“7.05%[0m) [3.55% of initial]
[Iter 680] Gaussian 0 vs 1:
  Original Loss: 0.0083295
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0083295 (Pseudo: 0.00%)
[Iter 680] Gaussian 1 vs 0:
  Original Loss: 0.0084241
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0084241 (Pseudo: 0.00%)
[Iter 690/20000] Loss: 0.0091424 (Best: 0.0079674 @iter682) ([91mâ†‘2.21%[0m) [3.63% of initial]
[Iter 690] Gaussian 0 vs 1:
  Original Loss: 0.0086427
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0086427 (Pseudo: 0.00%)
[Iter 690] Gaussian 1 vs 0:
  Original Loss: 0.0091220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0091220 (Pseudo: 0.00%)
Iter:699, L1 loss=0.005858, Total loss=0.009582, Time:12
[Iter 700/20000] Loss: 0.0090638 (Best: 0.0079674 @iter682) ([92mâ†“0.86%[0m) [3.60% of initial]
[Iter 700] Gaussian 0 vs 1:
  Original Loss: 0.0090543
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0090543 (Pseudo: 0.00%)
[Iter 700] Gaussian 1 vs 0:
  Original Loss: 0.0089196
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0089196 (Pseudo: 0.00%)
[Iter 710/20000] Loss: 0.0084859 (Best: 0.0079323 @iter710) ([92mâ†“6.38%[0m) [3.37% of initial]
[Iter 710] Gaussian 0 vs 1:
  Original Loss: 0.0079323
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0079323 (Pseudo: 0.00%)
[Iter 710] Gaussian 1 vs 0:
  Original Loss: 0.0078393
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0078393 (Pseudo: 0.00%)
[Iter 720/20000] Loss: 0.0084705 (Best: 0.0077359 @iter715) ([92mâ†“0.18%[0m) [3.37% of initial]
[Iter 720] Gaussian 0 vs 1:
  Original Loss: 0.0079169
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0079169 (Pseudo: 0.00%)
[Iter 720] Gaussian 1 vs 0:
  Original Loss: 0.0078790
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0078790 (Pseudo: 0.00%)
[Iter 730/20000] Loss: 0.0085133 (Best: 0.0074094 @iter727) ([91mâ†‘0.50%[0m) [3.38% of initial]
[Iter 730] Gaussian 0 vs 1:
  Original Loss: 0.0084818
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0084818 (Pseudo: 0.00%)
[Iter 730] Gaussian 1 vs 0:
  Original Loss: 0.0085123
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0085123 (Pseudo: 0.00%)
[Iter 740/20000] Loss: 0.0084903 (Best: 0.0073121 @iter733) ([92mâ†“0.27%[0m) [3.37% of initial]
[Iter 740] Gaussian 0 vs 1:
  Original Loss: 0.0085625
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0085625 (Pseudo: 0.00%)
[Iter 740] Gaussian 1 vs 0:
  Original Loss: 0.0087329
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0087329 (Pseudo: 0.00%)
[Iter 750/20000] Loss: 0.0080259 (Best: 0.0069940 @iter748) ([92mâ†“5.47%[0m) [3.19% of initial]
[Iter 750] Gaussian 0 vs 1:
  Original Loss: 0.0080502
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0080502 (Pseudo: 0.00%)
[Iter 750] Gaussian 1 vs 0:
  Original Loss: 0.0081641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0081641 (Pseudo: 0.00%)
[Iter 760/20000] Loss: 0.0073984 (Best: 0.0069245 @iter751) ([92mâ†“7.82%[0m) [2.94% of initial]
[Iter 760] Gaussian 0 vs 1:
  Original Loss: 0.0070047
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0070047 (Pseudo: 0.00%)
[Iter 760] Gaussian 1 vs 0:
  Original Loss: 0.0070974
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0070974 (Pseudo: 0.00%)
[Iter 770/20000] Loss: 0.0077021 (Best: 0.0069245 @iter751) ([91mâ†‘4.10%[0m) [3.06% of initial]
[Iter 770] Gaussian 0 vs 1:
  Original Loss: 0.0080962
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0080962 (Pseudo: 0.00%)
[Iter 770] Gaussian 1 vs 0:
  Original Loss: 0.0079177
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0079177 (Pseudo: 0.00%)
[Iter 780/20000] Loss: 0.0078750 (Best: 0.0068429 @iter778) ([91mâ†‘2.24%[0m) [3.13% of initial]
[Iter 780] Gaussian 0 vs 1:
  Original Loss: 0.0084408
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0084408 (Pseudo: 0.00%)
[Iter 780] Gaussian 1 vs 0:
  Original Loss: 0.0083337
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0083337 (Pseudo: 0.00%)
[Iter 790/20000] Loss: 0.0077143 (Best: 0.0066965 @iter787) ([92mâ†“2.04%[0m) [3.06% of initial]
[Iter 790] Gaussian 0 vs 1:
  Original Loss: 0.0077066
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0077066 (Pseudo: 0.00%)
[Iter 790] Gaussian 1 vs 0:
  Original Loss: 0.0075599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0075599 (Pseudo: 0.00%)
Iter:799, L1 loss=0.005002, Total loss=0.008045, Time:12
[Iter 800/20000] Loss: 0.0073670 (Best: 0.0066757 @iter800) ([92mâ†“4.50%[0m) [2.93% of initial]
[Iter 800] Gaussian 0 vs 1:
  Original Loss: 0.0066757
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066757 (Pseudo: 0.00%)
[Iter 800] Gaussian 1 vs 0:
  Original Loss: 0.0067306
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067306 (Pseudo: 0.00%)
[Iter 810/20000] Loss: 0.0155931 (Best: 0.0066757 @iter800) ([91mâ†‘111.66%[0m) [6.19% of initial]
[Iter 810] Gaussian 0 vs 1:
  Original Loss: 0.0143672
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0143672 (Pseudo: 0.00%)
[Iter 810] Gaussian 1 vs 0:
  Original Loss: 0.0140984
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0140984 (Pseudo: 0.00%)
[Iter 820/20000] Loss: 0.0108039 (Best: 0.0066757 @iter800) ([92mâ†“30.71%[0m) [4.29% of initial]
[Iter 820] Gaussian 0 vs 1:
  Original Loss: 0.0106544
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0106544 (Pseudo: 0.00%)
[Iter 820] Gaussian 1 vs 0:
  Original Loss: 0.0108468
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0108468 (Pseudo: 0.00%)
[Iter 830/20000] Loss: 0.0088772 (Best: 0.0066757 @iter800) ([92mâ†“17.83%[0m) [3.53% of initial]
[Iter 830] Gaussian 0 vs 1:
  Original Loss: 0.0093897
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0093897 (Pseudo: 0.00%)
[Iter 830] Gaussian 1 vs 0:
  Original Loss: 0.0090073
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0090073 (Pseudo: 0.00%)
[Iter 840/20000] Loss: 0.0080064 (Best: 0.0066757 @iter800) ([92mâ†“9.81%[0m) [3.18% of initial]
[Iter 840] Gaussian 0 vs 1:
  Original Loss: 0.0087939
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0087939 (Pseudo: 0.00%)
[Iter 840] Gaussian 1 vs 0:
  Original Loss: 0.0086543
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0086543 (Pseudo: 0.00%)
[Iter 850/20000] Loss: 0.0074728 (Best: 0.0066110 @iter841) ([92mâ†“6.66%[0m) [2.97% of initial]
[Iter 850] Gaussian 0 vs 1:
  Original Loss: 0.0072854
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0072854 (Pseudo: 0.00%)
[Iter 850] Gaussian 1 vs 0:
  Original Loss: 0.0073029
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0073029 (Pseudo: 0.00%)
[Iter 860/20000] Loss: 0.0069943 (Best: 0.0062077 @iter856) ([92mâ†“6.40%[0m) [2.78% of initial]
[Iter 860] Gaussian 0 vs 1:
  Original Loss: 0.0070418
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0070418 (Pseudo: 0.00%)
[Iter 860] Gaussian 1 vs 0:
  Original Loss: 0.0071603
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0071603 (Pseudo: 0.00%)
[Iter 870/20000] Loss: 0.0067155 (Best: 0.0060387 @iter862) ([92mâ†“3.99%[0m) [2.67% of initial]
[Iter 870] Gaussian 0 vs 1:
  Original Loss: 0.0062320
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062320 (Pseudo: 0.00%)
[Iter 870] Gaussian 1 vs 0:
  Original Loss: 0.0063596
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063596 (Pseudo: 0.00%)
[Iter 880/20000] Loss: 0.0067303 (Best: 0.0059206 @iter872) ([91mâ†‘0.22%[0m) [2.67% of initial]
[Iter 880] Gaussian 0 vs 1:
  Original Loss: 0.0066641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066641 (Pseudo: 0.00%)
[Iter 880] Gaussian 1 vs 0:
  Original Loss: 0.0067342
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067342 (Pseudo: 0.00%)
[Iter 890/20000] Loss: 0.0062558 (Best: 0.0056485 @iter884) ([92mâ†“7.05%[0m) [2.49% of initial]
[Iter 890] Gaussian 0 vs 1:
  Original Loss: 0.0057310
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0057310 (Pseudo: 0.00%)
[Iter 890] Gaussian 1 vs 0:
  Original Loss: 0.0059526
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0059526 (Pseudo: 0.00%)
Iter:899, L1 loss=0.003776, Total loss=0.005591, Time:13
[Iter 900/20000] Loss: 0.0064417 (Best: 0.0055795 @iter896) ([91mâ†‘2.97%[0m) [2.56% of initial]
[Iter 900] Gaussian 0 vs 1:
  Original Loss: 0.0065312
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0065312 (Pseudo: 0.00%)
[Iter 900] Gaussian 1 vs 0:
  Original Loss: 0.0066473
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066473 (Pseudo: 0.00%)
[Iter 910/20000] Loss: 0.0065861 (Best: 0.0053523 @iter907) ([91mâ†‘2.24%[0m) [2.62% of initial]
[Iter 910] Gaussian 0 vs 1:
  Original Loss: 0.0069971
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0069971 (Pseudo: 0.00%)
[Iter 910] Gaussian 1 vs 0:
  Original Loss: 0.0068304
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0068304 (Pseudo: 0.00%)
[Iter 920/20000] Loss: 0.0059679 (Best: 0.0052495 @iter916) ([92mâ†“9.39%[0m) [2.37% of initial]
[Iter 920] Gaussian 0 vs 1:
  Original Loss: 0.0060867
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060867 (Pseudo: 0.00%)
[Iter 920] Gaussian 1 vs 0:
  Original Loss: 0.0062539
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062539 (Pseudo: 0.00%)
[Iter 930/20000] Loss: 0.0063876 (Best: 0.0052495 @iter916) ([91mâ†‘7.03%[0m) [2.54% of initial]
[Iter 930] Gaussian 0 vs 1:
  Original Loss: 0.0068599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0068599 (Pseudo: 0.00%)
[Iter 930] Gaussian 1 vs 0:
  Original Loss: 0.0067122
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067122 (Pseudo: 0.00%)
[Iter 940/20000] Loss: 0.0064095 (Best: 0.0051416 @iter938) ([91mâ†‘0.34%[0m) [2.55% of initial]
[Iter 940] Gaussian 0 vs 1:
  Original Loss: 0.0067858
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067858 (Pseudo: 0.00%)
[Iter 940] Gaussian 1 vs 0:
  Original Loss: 0.0066155
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066155 (Pseudo: 0.00%)
[Iter 950/20000] Loss: 0.0059223 (Best: 0.0051416 @iter938) ([92mâ†“7.60%[0m) [2.35% of initial]
[Iter 950] Gaussian 0 vs 1:
  Original Loss: 0.0055614
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0055614 (Pseudo: 0.00%)
[Iter 950] Gaussian 1 vs 0:
  Original Loss: 0.0058549
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058549 (Pseudo: 0.00%)
[Iter 960/20000] Loss: 0.0060871 (Best: 0.0051416 @iter938) ([91mâ†‘2.78%[0m) [2.42% of initial]
[Iter 960] Gaussian 0 vs 1:
  Original Loss: 0.0062680
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062680 (Pseudo: 0.00%)
[Iter 960] Gaussian 1 vs 0:
  Original Loss: 0.0063805
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063805 (Pseudo: 0.00%)
[Iter 970/20000] Loss: 0.0059262 (Best: 0.0051416 @iter938) ([92mâ†“2.64%[0m) [2.35% of initial]
[Iter 970] Gaussian 0 vs 1:
  Original Loss: 0.0057799
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0057799 (Pseudo: 0.00%)
[Iter 970] Gaussian 1 vs 0:
  Original Loss: 0.0058966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058966 (Pseudo: 0.00%)
[Iter 980/20000] Loss: 0.0061291 (Best: 0.0050736 @iter979) ([91mâ†‘3.42%[0m) [2.44% of initial]
[Iter 980] Gaussian 0 vs 1:
  Original Loss: 0.0069057
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0069057 (Pseudo: 0.00%)
[Iter 980] Gaussian 1 vs 0:
  Original Loss: 0.0066209
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0066209 (Pseudo: 0.00%)
[Iter 990/20000] Loss: 0.0061184 (Best: 0.0050736 @iter979) ([92mâ†“0.17%[0m) [2.43% of initial]
[Iter 990] Gaussian 0 vs 1:
  Original Loss: 0.0061681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061681 (Pseudo: 0.00%)
[Iter 990] Gaussian 1 vs 0:
  Original Loss: 0.0064471
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0064471 (Pseudo: 0.00%)
Iter:999, L1 loss=0.004395, Total loss=0.006974, Time:13
[Iter 1000/20000] Loss: 0.0064544 (Best: 0.0050736 @iter979) ([91mâ†‘5.49%[0m) [2.56% of initial]
[Iter 1000] Gaussian 0 vs 1:
  Original Loss: 0.0067566
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067566 (Pseudo: 0.00%)
[Iter 1000] Gaussian 1 vs 0:
  Original Loss: 0.0063786
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063786 (Pseudo: 0.00%)
[Iter 1010/20000] Loss: 0.0114101 (Best: 0.0050736 @iter979) ([91mâ†‘76.78%[0m) [4.53% of initial]
[Iter 1010] Gaussian 0 vs 1:
  Original Loss: 0.0110085
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0110085 (Pseudo: 0.00%)
[Iter 1010] Gaussian 1 vs 0:
  Original Loss: 0.0111303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0111303 (Pseudo: 0.00%)
[Iter 1020/20000] Loss: 0.0084174 (Best: 0.0050736 @iter979) ([92mâ†“26.23%[0m) [3.34% of initial]
[Iter 1020] Gaussian 0 vs 1:
  Original Loss: 0.0080219
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0080219 (Pseudo: 0.00%)
[Iter 1020] Gaussian 1 vs 0:
  Original Loss: 0.0078563
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0078563 (Pseudo: 0.00%)
[Iter 1030/20000] Loss: 0.0069297 (Best: 0.0050736 @iter979) ([92mâ†“17.67%[0m) [2.75% of initial]
[Iter 1030] Gaussian 0 vs 1:
  Original Loss: 0.0060526
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060526 (Pseudo: 0.00%)
[Iter 1030] Gaussian 1 vs 0:
  Original Loss: 0.0062755
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062755 (Pseudo: 0.00%)
[Iter 1040/20000] Loss: 0.0061052 (Best: 0.0050736 @iter979) ([92mâ†“11.90%[0m) [2.43% of initial]
[Iter 1040] Gaussian 0 vs 1:
  Original Loss: 0.0060792
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060792 (Pseudo: 0.00%)
[Iter 1040] Gaussian 1 vs 0:
  Original Loss: 0.0063612
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063612 (Pseudo: 0.00%)
[Iter 1050/20000] Loss: 0.0059193 (Best: 0.0050736 @iter979) ([92mâ†“3.04%[0m) [2.35% of initial]
[Iter 1050] Gaussian 0 vs 1:
  Original Loss: 0.0060871
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060871 (Pseudo: 0.00%)
[Iter 1050] Gaussian 1 vs 0:
  Original Loss: 0.0062946
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062946 (Pseudo: 0.00%)
[Iter 1060/20000] Loss: 0.0058083 (Best: 0.0048987 @iter1055) ([92mâ†“1.88%[0m) [2.31% of initial]
[Iter 1060] Gaussian 0 vs 1:
  Original Loss: 0.0060189
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060189 (Pseudo: 0.00%)
[Iter 1060] Gaussian 1 vs 0:
  Original Loss: 0.0060832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060832 (Pseudo: 0.00%)
[Iter 1070/20000] Loss: 0.0055100 (Best: 0.0045490 @iter1066) ([92mâ†“5.13%[0m) [2.19% of initial]
[Iter 1070] Gaussian 0 vs 1:
  Original Loss: 0.0061190
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061190 (Pseudo: 0.00%)
[Iter 1070] Gaussian 1 vs 0:
  Original Loss: 0.0061778
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061778 (Pseudo: 0.00%)
[Iter 1080/20000] Loss: 0.0052826 (Best: 0.0045490 @iter1066) ([92mâ†“4.13%[0m) [2.10% of initial]
[Iter 1080] Gaussian 0 vs 1:
  Original Loss: 0.0049614
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049614 (Pseudo: 0.00%)
[Iter 1080] Gaussian 1 vs 0:
  Original Loss: 0.0051746
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051746 (Pseudo: 0.00%)
[Iter 1090/20000] Loss: 0.0051041 (Best: 0.0045490 @iter1066) ([92mâ†“3.38%[0m) [2.03% of initial]
[Iter 1090] Gaussian 0 vs 1:
  Original Loss: 0.0049920
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049920 (Pseudo: 0.00%)
[Iter 1090] Gaussian 1 vs 0:
  Original Loss: 0.0053022
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0053022 (Pseudo: 0.00%)
Iter:1099, L1 loss=0.003567, Total loss=0.005011, Time:13
[Iter 1100/20000] Loss: 0.0050463 (Best: 0.0042903 @iter1093) ([92mâ†“1.13%[0m) [2.00% of initial]
[Iter 1100] Gaussian 0 vs 1:
  Original Loss: 0.0048681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048681 (Pseudo: 0.00%)
[Iter 1100] Gaussian 1 vs 0:
  Original Loss: 0.0047489
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047489 (Pseudo: 0.00%)
[Iter 1110/20000] Loss: 0.0050618 (Best: 0.0042903 @iter1093) ([91mâ†‘0.31%[0m) [2.01% of initial]
[Iter 1110] Gaussian 0 vs 1:
  Original Loss: 0.0047674
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047674 (Pseudo: 0.00%)
[Iter 1110] Gaussian 1 vs 0:
  Original Loss: 0.0047834
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047834 (Pseudo: 0.00%)
[Iter 1120/20000] Loss: 0.0050564 (Best: 0.0042158 @iter1117) ([92mâ†“0.11%[0m) [2.01% of initial]
[Iter 1120] Gaussian 0 vs 1:
  Original Loss: 0.0049531
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049531 (Pseudo: 0.00%)
[Iter 1120] Gaussian 1 vs 0:
  Original Loss: 0.0050849
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0050849 (Pseudo: 0.00%)
[Iter 1130/20000] Loss: 0.0053555 (Best: 0.0042158 @iter1117) ([91mâ†‘5.91%[0m) [2.13% of initial]
[Iter 1130] Gaussian 0 vs 1:
  Original Loss: 0.0057057
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0057057 (Pseudo: 0.00%)
[Iter 1130] Gaussian 1 vs 0:
  Original Loss: 0.0056902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0056902 (Pseudo: 0.00%)
[Iter 1140/20000] Loss: 0.0048608 (Best: 0.0041515 @iter1135) ([92mâ†“9.24%[0m) [1.93% of initial]
[Iter 1140] Gaussian 0 vs 1:
  Original Loss: 0.0048785
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048785 (Pseudo: 0.00%)
[Iter 1140] Gaussian 1 vs 0:
  Original Loss: 0.0052467
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0052467 (Pseudo: 0.00%)
[Iter 1150/20000] Loss: 0.0045524 (Best: 0.0040602 @iter1145) ([92mâ†“6.35%[0m) [1.81% of initial]
[Iter 1150] Gaussian 0 vs 1:
  Original Loss: 0.0041553
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041553 (Pseudo: 0.00%)
[Iter 1150] Gaussian 1 vs 0:
  Original Loss: 0.0041444
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041444 (Pseudo: 0.00%)
[Iter 1160/20000] Loss: 0.0053142 (Best: 0.0040602 @iter1145) ([91mâ†‘16.73%[0m) [2.11% of initial]
[Iter 1160] Gaussian 0 vs 1:
  Original Loss: 0.0052046
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0052046 (Pseudo: 0.00%)
[Iter 1160] Gaussian 1 vs 0:
  Original Loss: 0.0051235
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051235 (Pseudo: 0.00%)
[Iter 1170/20000] Loss: 0.0048004 (Best: 0.0040602 @iter1145) ([92mâ†“9.67%[0m) [1.91% of initial]
[Iter 1170] Gaussian 0 vs 1:
  Original Loss: 0.0044588
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044588 (Pseudo: 0.00%)
[Iter 1170] Gaussian 1 vs 0:
  Original Loss: 0.0044537
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044537 (Pseudo: 0.00%)
[Iter 1180/20000] Loss: 0.0044208 (Best: 0.0040134 @iter1180) ([92mâ†“7.91%[0m) [1.76% of initial]
[Iter 1180] Gaussian 0 vs 1:
  Original Loss: 0.0040134
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040134 (Pseudo: 0.00%)
[Iter 1180] Gaussian 1 vs 0:
  Original Loss: 0.0039972
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039972 (Pseudo: 0.00%)
[Iter 1190/20000] Loss: 0.0047045 (Best: 0.0039785 @iter1183) ([91mâ†‘6.42%[0m) [1.87% of initial]
[Iter 1190] Gaussian 0 vs 1:
  Original Loss: 0.0044426
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044426 (Pseudo: 0.00%)
[Iter 1190] Gaussian 1 vs 0:
  Original Loss: 0.0045378
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0045378 (Pseudo: 0.00%)
Iter:1199, L1 loss=0.003503, Total loss=0.005189, Time:12
[Iter 1200/20000] Loss: 0.0047256 (Best: 0.0038068 @iter1195) ([91mâ†‘0.45%[0m) [1.88% of initial]
[Iter 1200] Gaussian 0 vs 1:
  Original Loss: 0.0046813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046813 (Pseudo: 0.00%)
[Iter 1200] Gaussian 1 vs 0:
  Original Loss: 0.0047296
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047296 (Pseudo: 0.00%)
[Iter 1210/20000] Loss: 0.0109549 (Best: 0.0038068 @iter1195) ([91mâ†‘131.82%[0m) [4.35% of initial]
[Iter 1210] Gaussian 0 vs 1:
  Original Loss: 0.0099916
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0099916 (Pseudo: 0.00%)
[Iter 1210] Gaussian 1 vs 0:
  Original Loss: 0.0096570
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0096570 (Pseudo: 0.00%)
[Iter 1220/20000] Loss: 0.0068332 (Best: 0.0038068 @iter1195) ([92mâ†“37.62%[0m) [2.71% of initial]
[Iter 1220] Gaussian 0 vs 1:
  Original Loss: 0.0060282
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060282 (Pseudo: 0.00%)
[Iter 1220] Gaussian 1 vs 0:
  Original Loss: 0.0063220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063220 (Pseudo: 0.00%)
[Iter 1230/20000] Loss: 0.0060294 (Best: 0.0038068 @iter1195) ([92mâ†“11.76%[0m) [2.40% of initial]
[Iter 1230] Gaussian 0 vs 1:
  Original Loss: 0.0063008
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0063008 (Pseudo: 0.00%)
[Iter 1230] Gaussian 1 vs 0:
  Original Loss: 0.0064186
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0064186 (Pseudo: 0.00%)
[Iter 1240/20000] Loss: 0.0054698 (Best: 0.0038068 @iter1195) ([92mâ†“9.28%[0m) [2.17% of initial]
[Iter 1240] Gaussian 0 vs 1:
  Original Loss: 0.0055870
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0055870 (Pseudo: 0.00%)
[Iter 1240] Gaussian 1 vs 0:
  Original Loss: 0.0056606
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0056606 (Pseudo: 0.00%)
[Iter 1250/20000] Loss: 0.0048943 (Best: 0.0038068 @iter1195) ([92mâ†“10.52%[0m) [1.94% of initial]
[Iter 1250] Gaussian 0 vs 1:
  Original Loss: 0.0048327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048327 (Pseudo: 0.00%)
[Iter 1250] Gaussian 1 vs 0:
  Original Loss: 0.0047515
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047515 (Pseudo: 0.00%)
[Iter 1260/20000] Loss: 0.0046114 (Best: 0.0037392 @iter1258) ([92mâ†“5.78%[0m) [1.83% of initial]
[Iter 1260] Gaussian 0 vs 1:
  Original Loss: 0.0051861
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051861 (Pseudo: 0.00%)
[Iter 1260] Gaussian 1 vs 0:
  Original Loss: 0.0052220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0052220 (Pseudo: 0.00%)
[Iter 1270/20000] Loss: 0.0040766 (Best: 0.0037022 @iter1269) ([92mâ†“11.60%[0m) [1.62% of initial]
[Iter 1270] Gaussian 0 vs 1:
  Original Loss: 0.0040252
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040252 (Pseudo: 0.00%)
[Iter 1270] Gaussian 1 vs 0:
  Original Loss: 0.0042140
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0042140 (Pseudo: 0.00%)
[Iter 1280/20000] Loss: 0.0043350 (Best: 0.0033428 @iter1273) ([91mâ†‘6.34%[0m) [1.72% of initial]
[Iter 1280] Gaussian 0 vs 1:
  Original Loss: 0.0041768
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041768 (Pseudo: 0.00%)
[Iter 1280] Gaussian 1 vs 0:
  Original Loss: 0.0043471
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043471 (Pseudo: 0.00%)
[Iter 1290/20000] Loss: 0.0042305 (Best: 0.0033112 @iter1285) ([92mâ†“2.41%[0m) [1.68% of initial]
[Iter 1290] Gaussian 0 vs 1:
  Original Loss: 0.0047379
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0047379 (Pseudo: 0.00%)
[Iter 1290] Gaussian 1 vs 0:
  Original Loss: 0.0048158
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0048158 (Pseudo: 0.00%)
Iter:1299, L1 loss=0.002804, Total loss=0.003782, Time:13
[Iter 1300/20000] Loss: 0.0040906 (Best: 0.0033112 @iter1285) ([92mâ†“3.31%[0m) [1.63% of initial]
[Iter 1300] Gaussian 0 vs 1:
  Original Loss: 0.0041029
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041029 (Pseudo: 0.00%)
[Iter 1300] Gaussian 1 vs 0:
  Original Loss: 0.0039666
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039666 (Pseudo: 0.00%)
[Iter 1310/20000] Loss: 0.0041188 (Best: 0.0033112 @iter1285) ([91mâ†‘0.69%[0m) [1.64% of initial]
[Iter 1310] Gaussian 0 vs 1:
  Original Loss: 0.0038565
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038565 (Pseudo: 0.00%)
[Iter 1310] Gaussian 1 vs 0:
  Original Loss: 0.0038989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038989 (Pseudo: 0.00%)
[Iter 1320/20000] Loss: 0.0039904 (Best: 0.0031883 @iter1319) ([92mâ†“3.12%[0m) [1.59% of initial]
[Iter 1320] Gaussian 0 vs 1:
  Original Loss: 0.0046733
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046733 (Pseudo: 0.00%)
[Iter 1320] Gaussian 1 vs 0:
  Original Loss: 0.0045786
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0045786 (Pseudo: 0.00%)
[Iter 1330/20000] Loss: 0.0039792 (Best: 0.0031157 @iter1321) ([92mâ†“0.28%[0m) [1.58% of initial]
[Iter 1330] Gaussian 0 vs 1:
  Original Loss: 0.0041166
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041166 (Pseudo: 0.00%)
[Iter 1330] Gaussian 1 vs 0:
  Original Loss: 0.0041100
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041100 (Pseudo: 0.00%)
[Iter 1340/20000] Loss: 0.0037062 (Best: 0.0031157 @iter1321) ([92mâ†“6.86%[0m) [1.47% of initial]
[Iter 1340] Gaussian 0 vs 1:
  Original Loss: 0.0033376
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033376 (Pseudo: 0.00%)
[Iter 1340] Gaussian 1 vs 0:
  Original Loss: 0.0033620
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033620 (Pseudo: 0.00%)
[Iter 1350/20000] Loss: 0.0037873 (Best: 0.0031157 @iter1321) ([91mâ†‘2.19%[0m) [1.50% of initial]
[Iter 1350] Gaussian 0 vs 1:
  Original Loss: 0.0033853
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033853 (Pseudo: 0.00%)
[Iter 1350] Gaussian 1 vs 0:
  Original Loss: 0.0033520
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033520 (Pseudo: 0.00%)
[Iter 1360/20000] Loss: 0.0038166 (Best: 0.0031157 @iter1321) ([91mâ†‘0.77%[0m) [1.52% of initial]
[Iter 1360] Gaussian 0 vs 1:
  Original Loss: 0.0035835
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035835 (Pseudo: 0.00%)
[Iter 1360] Gaussian 1 vs 0:
  Original Loss: 0.0037782
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0037782 (Pseudo: 0.00%)
[Iter 1370/20000] Loss: 0.0037579 (Best: 0.0031157 @iter1321) ([92mâ†“1.54%[0m) [1.49% of initial]
[Iter 1370] Gaussian 0 vs 1:
  Original Loss: 0.0033161
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033161 (Pseudo: 0.00%)
[Iter 1370] Gaussian 1 vs 0:
  Original Loss: 0.0033149
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033149 (Pseudo: 0.00%)
[Iter 1380/20000] Loss: 0.0039391 (Best: 0.0031157 @iter1321) ([91mâ†‘4.82%[0m) [1.56% of initial]
[Iter 1380] Gaussian 0 vs 1:
  Original Loss: 0.0039523
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039523 (Pseudo: 0.00%)
[Iter 1380] Gaussian 1 vs 0:
  Original Loss: 0.0039351
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039351 (Pseudo: 0.00%)
[Iter 1390/20000] Loss: 0.0037141 (Best: 0.0031157 @iter1321) ([92mâ†“5.71%[0m) [1.48% of initial]
[Iter 1390] Gaussian 0 vs 1:
  Original Loss: 0.0035930
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035930 (Pseudo: 0.00%)
[Iter 1390] Gaussian 1 vs 0:
  Original Loss: 0.0035677
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035677 (Pseudo: 0.00%)
Iter:1399, L1 loss=0.002301, Total loss=0.002911, Time:13
[Iter 1400/20000] Loss: 0.0034058 (Best: 0.0029115 @iter1399) ([92mâ†“8.30%[0m) [1.35% of initial]
[Iter 1400] Gaussian 0 vs 1:
  Original Loss: 0.0034453
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0034453 (Pseudo: 0.00%)
[Iter 1400] Gaussian 1 vs 0:
  Original Loss: 0.0035088
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035088 (Pseudo: 0.00%)
[Iter 1410/20000] Loss: 0.0090438 (Best: 0.0029115 @iter1399) ([91mâ†‘165.54%[0m) [3.59% of initial]
[Iter 1410] Gaussian 0 vs 1:
  Original Loss: 0.0085932
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0085932 (Pseudo: 0.00%)
[Iter 1410] Gaussian 1 vs 0:
  Original Loss: 0.0081792
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0081792 (Pseudo: 0.00%)
[Iter 1420/20000] Loss: 0.0061622 (Best: 0.0029115 @iter1399) ([92mâ†“31.86%[0m) [2.45% of initial]
[Iter 1420] Gaussian 0 vs 1:
  Original Loss: 0.0058311
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058311 (Pseudo: 0.00%)
[Iter 1420] Gaussian 1 vs 0:
  Original Loss: 0.0055593
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0055593 (Pseudo: 0.00%)
[Iter 1430/20000] Loss: 0.0050902 (Best: 0.0029115 @iter1399) ([92mâ†“17.40%[0m) [2.02% of initial]
[Iter 1430] Gaussian 0 vs 1:
  Original Loss: 0.0043874
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043874 (Pseudo: 0.00%)
[Iter 1430] Gaussian 1 vs 0:
  Original Loss: 0.0043331
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043331 (Pseudo: 0.00%)
[Iter 1440/20000] Loss: 0.0045893 (Best: 0.0029115 @iter1399) ([92mâ†“9.84%[0m) [1.82% of initial]
[Iter 1440] Gaussian 0 vs 1:
  Original Loss: 0.0046832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046832 (Pseudo: 0.00%)
[Iter 1440] Gaussian 1 vs 0:
  Original Loss: 0.0044418
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044418 (Pseudo: 0.00%)
[Iter 1450/20000] Loss: 0.0035705 (Best: 0.0029115 @iter1399) ([92mâ†“22.20%[0m) [1.42% of initial]
[Iter 1450] Gaussian 0 vs 1:
  Original Loss: 0.0031571
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0031571 (Pseudo: 0.00%)
[Iter 1450] Gaussian 1 vs 0:
  Original Loss: 0.0031602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0031602 (Pseudo: 0.00%)
[Iter 1460/20000] Loss: 0.0035775 (Best: 0.0029115 @iter1399) ([91mâ†‘0.20%[0m) [1.42% of initial]
[Iter 1460] Gaussian 0 vs 1:
  Original Loss: 0.0035905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035905 (Pseudo: 0.00%)
[Iter 1460] Gaussian 1 vs 0:
  Original Loss: 0.0036434
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036434 (Pseudo: 0.00%)
[Iter 1470/20000] Loss: 0.0034702 (Best: 0.0029115 @iter1399) ([92mâ†“3.00%[0m) [1.38% of initial]
[Iter 1470] Gaussian 0 vs 1:
  Original Loss: 0.0031478
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0031478 (Pseudo: 0.00%)
[Iter 1470] Gaussian 1 vs 0:
  Original Loss: 0.0030841
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030841 (Pseudo: 0.00%)
[Iter 1480/20000] Loss: 0.0033700 (Best: 0.0028405 @iter1480) ([92mâ†“2.89%[0m) [1.34% of initial]
[Iter 1480] Gaussian 0 vs 1:
  Original Loss: 0.0028405
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028405 (Pseudo: 0.00%)
[Iter 1480] Gaussian 1 vs 0:
  Original Loss: 0.0027969
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027969 (Pseudo: 0.00%)
[Iter 1490/20000] Loss: 0.0032900 (Best: 0.0028405 @iter1480) ([92mâ†“2.37%[0m) [1.31% of initial]
[Iter 1490] Gaussian 0 vs 1:
  Original Loss: 0.0033119
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033119 (Pseudo: 0.00%)
[Iter 1490] Gaussian 1 vs 0:
  Original Loss: 0.0033185
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033185 (Pseudo: 0.00%)
Iter:1499, L1 loss=0.002554, Total loss=0.003328, Time:13
[Iter 1500/20000] Loss: 0.0032415 (Best: 0.0028405 @iter1480) ([92mâ†“1.47%[0m) [1.29% of initial]
[Iter 1500] Gaussian 0 vs 1:
  Original Loss: 0.0029587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029587 (Pseudo: 0.00%)
[Iter 1500] Gaussian 1 vs 0:
  Original Loss: 0.0029637
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029637 (Pseudo: 0.00%)
[Iter 1510/20000] Loss: 0.0031027 (Best: 0.0026108 @iter1504) ([92mâ†“4.28%[0m) [1.23% of initial]
[Iter 1510] Gaussian 0 vs 1:
  Original Loss: 0.0028233
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028233 (Pseudo: 0.00%)
[Iter 1510] Gaussian 1 vs 0:
  Original Loss: 0.0028236
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028236 (Pseudo: 0.00%)
[Iter 1520/20000] Loss: 0.0030697 (Best: 0.0026014 @iter1520) ([92mâ†“1.06%[0m) [1.22% of initial]
[Iter 1520] Gaussian 0 vs 1:
  Original Loss: 0.0026014
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026014 (Pseudo: 0.00%)
[Iter 1520] Gaussian 1 vs 0:
  Original Loss: 0.0026043
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026043 (Pseudo: 0.00%)
[Iter 1530/20000] Loss: 0.0032212 (Best: 0.0025709 @iter1526) ([91mâ†‘4.94%[0m) [1.28% of initial]
[Iter 1530] Gaussian 0 vs 1:
  Original Loss: 0.0032503
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032503 (Pseudo: 0.00%)
[Iter 1530] Gaussian 1 vs 0:
  Original Loss: 0.0032234
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032234 (Pseudo: 0.00%)
[Iter 1540/20000] Loss: 0.0031142 (Best: 0.0025709 @iter1526) ([92mâ†“3.32%[0m) [1.24% of initial]
[Iter 1540] Gaussian 0 vs 1:
  Original Loss: 0.0029162
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029162 (Pseudo: 0.00%)
[Iter 1540] Gaussian 1 vs 0:
  Original Loss: 0.0029088
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029088 (Pseudo: 0.00%)
[Iter 1550/20000] Loss: 0.0030425 (Best: 0.0025709 @iter1526) ([92mâ†“2.30%[0m) [1.21% of initial]
[Iter 1550] Gaussian 0 vs 1:
  Original Loss: 0.0029399
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029399 (Pseudo: 0.00%)
[Iter 1550] Gaussian 1 vs 0:
  Original Loss: 0.0030088
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030088 (Pseudo: 0.00%)
[Iter 1560/20000] Loss: 0.0032830 (Best: 0.0025565 @iter1558) ([91mâ†‘7.90%[0m) [1.30% of initial]
[Iter 1560] Gaussian 0 vs 1:
  Original Loss: 0.0039155
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039155 (Pseudo: 0.00%)
[Iter 1560] Gaussian 1 vs 0:
  Original Loss: 0.0039436
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0039436 (Pseudo: 0.00%)
[Iter 1570/20000] Loss: 0.0028300 (Best: 0.0024806 @iter1569) ([92mâ†“13.80%[0m) [1.12% of initial]
[Iter 1570] Gaussian 0 vs 1:
  Original Loss: 0.0027057
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027057 (Pseudo: 0.00%)
[Iter 1570] Gaussian 1 vs 0:
  Original Loss: 0.0028462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028462 (Pseudo: 0.00%)
[Iter 1580/20000] Loss: 0.0028738 (Best: 0.0023563 @iter1573) ([91mâ†‘1.55%[0m) [1.14% of initial]
[Iter 1580] Gaussian 0 vs 1:
  Original Loss: 0.0029608
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029608 (Pseudo: 0.00%)
[Iter 1580] Gaussian 1 vs 0:
  Original Loss: 0.0032560
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032560 (Pseudo: 0.00%)
[Iter 1590/20000] Loss: 0.0027756 (Best: 0.0023563 @iter1573) ([92mâ†“3.42%[0m) [1.10% of initial]
[Iter 1590] Gaussian 0 vs 1:
  Original Loss: 0.0025154
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025154 (Pseudo: 0.00%)
[Iter 1590] Gaussian 1 vs 0:
  Original Loss: 0.0026211
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026211 (Pseudo: 0.00%)
Iter:1599, L1 loss=0.002751, Total loss=0.003428, Time:13
[Iter 1600/20000] Loss: 0.0031057 (Best: 0.0023563 @iter1573) ([91mâ†‘11.89%[0m) [1.23% of initial]
[Iter 1600] Gaussian 0 vs 1:
  Original Loss: 0.0033145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033145 (Pseudo: 0.00%)
[Iter 1600] Gaussian 1 vs 0:
  Original Loss: 0.0033184
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033184 (Pseudo: 0.00%)
[Iter 1610/20000] Loss: 0.0086785 (Best: 0.0023563 @iter1573) ([91mâ†‘179.44%[0m) [3.45% of initial]
[Iter 1610] Gaussian 0 vs 1:
  Original Loss: 0.0076747
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0076747 (Pseudo: 0.00%)
[Iter 1610] Gaussian 1 vs 0:
  Original Loss: 0.0075440
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0075440 (Pseudo: 0.00%)
[Iter 1620/20000] Loss: 0.0054409 (Best: 0.0023563 @iter1573) ([92mâ†“37.31%[0m) [2.16% of initial]
[Iter 1620] Gaussian 0 vs 1:
  Original Loss: 0.0058999
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0058999 (Pseudo: 0.00%)
[Iter 1620] Gaussian 1 vs 0:
  Original Loss: 0.0062347
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0062347 (Pseudo: 0.00%)
[Iter 1630/20000] Loss: 0.0044811 (Best: 0.0023563 @iter1573) ([92mâ†“17.64%[0m) [1.78% of initial]
[Iter 1630] Gaussian 0 vs 1:
  Original Loss: 0.0040060
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040060 (Pseudo: 0.00%)
[Iter 1630] Gaussian 1 vs 0:
  Original Loss: 0.0036977
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036977 (Pseudo: 0.00%)
[Iter 1640/20000] Loss: 0.0039505 (Best: 0.0023563 @iter1573) ([92mâ†“11.84%[0m) [1.57% of initial]
[Iter 1640] Gaussian 0 vs 1:
  Original Loss: 0.0043569
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0043569 (Pseudo: 0.00%)
[Iter 1640] Gaussian 1 vs 0:
  Original Loss: 0.0042930
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0042930 (Pseudo: 0.00%)
[Iter 1650/20000] Loss: 0.0034588 (Best: 0.0023563 @iter1573) ([92mâ†“12.45%[0m) [1.37% of initial]
[Iter 1650] Gaussian 0 vs 1:
  Original Loss: 0.0034012
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0034012 (Pseudo: 0.00%)
[Iter 1650] Gaussian 1 vs 0:
  Original Loss: 0.0033312
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033312 (Pseudo: 0.00%)
[Iter 1660/20000] Loss: 0.0029397 (Best: 0.0023563 @iter1573) ([92mâ†“15.01%[0m) [1.17% of initial]
[Iter 1660] Gaussian 0 vs 1:
  Original Loss: 0.0025669
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025669 (Pseudo: 0.00%)
[Iter 1660] Gaussian 1 vs 0:
  Original Loss: 0.0025496
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025496 (Pseudo: 0.00%)
[Iter 1670/20000] Loss: 0.0027867 (Best: 0.0023075 @iter1669) ([92mâ†“5.20%[0m) [1.11% of initial]
[Iter 1670] Gaussian 0 vs 1:
  Original Loss: 0.0028154
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028154 (Pseudo: 0.00%)
[Iter 1670] Gaussian 1 vs 0:
  Original Loss: 0.0028748
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028748 (Pseudo: 0.00%)
[Iter 1680/20000] Loss: 0.0029164 (Best: 0.0023075 @iter1669) ([91mâ†‘4.66%[0m) [1.16% of initial]
[Iter 1680] Gaussian 0 vs 1:
  Original Loss: 0.0027675
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027675 (Pseudo: 0.00%)
[Iter 1680] Gaussian 1 vs 0:
  Original Loss: 0.0028827
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028827 (Pseudo: 0.00%)
[Iter 1690/20000] Loss: 0.0030069 (Best: 0.0023075 @iter1669) ([91mâ†‘3.10%[0m) [1.19% of initial]
[Iter 1690] Gaussian 0 vs 1:
  Original Loss: 0.0027275
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027275 (Pseudo: 0.00%)
[Iter 1690] Gaussian 1 vs 0:
  Original Loss: 0.0029747
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029747 (Pseudo: 0.00%)
Iter:1699, L1 loss=0.0026, Total loss=0.00316, Time:14
[Iter 1700/20000] Loss: 0.0027997 (Best: 0.0023075 @iter1669) ([92mâ†“6.89%[0m) [1.11% of initial]
[Iter 1700] Gaussian 0 vs 1:
  Original Loss: 0.0023884
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023884 (Pseudo: 0.00%)
[Iter 1700] Gaussian 1 vs 0:
  Original Loss: 0.0024271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024271 (Pseudo: 0.00%)
[Iter 1710/20000] Loss: 0.0030678 (Best: 0.0023075 @iter1669) ([91mâ†‘9.58%[0m) [1.22% of initial]
[Iter 1710] Gaussian 0 vs 1:
  Original Loss: 0.0032399
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032399 (Pseudo: 0.00%)
[Iter 1710] Gaussian 1 vs 0:
  Original Loss: 0.0034713
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0034713 (Pseudo: 0.00%)
[Iter 1720/20000] Loss: 0.0025782 (Best: 0.0023075 @iter1669) ([92mâ†“15.96%[0m) [1.02% of initial]
[Iter 1720] Gaussian 0 vs 1:
  Original Loss: 0.0023834
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023834 (Pseudo: 0.00%)
[Iter 1720] Gaussian 1 vs 0:
  Original Loss: 0.0024817
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024817 (Pseudo: 0.00%)
[Iter 1730/20000] Loss: 0.0026438 (Best: 0.0023075 @iter1669) ([91mâ†‘2.54%[0m) [1.05% of initial]
[Iter 1730] Gaussian 0 vs 1:
  Original Loss: 0.0023442
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023442 (Pseudo: 0.00%)
[Iter 1730] Gaussian 1 vs 0:
  Original Loss: 0.0024086
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024086 (Pseudo: 0.00%)
[Iter 1740/20000] Loss: 0.0025877 (Best: 0.0021688 @iter1738) ([92mâ†“2.12%[0m) [1.03% of initial]
[Iter 1740] Gaussian 0 vs 1:
  Original Loss: 0.0024534
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024534 (Pseudo: 0.00%)
[Iter 1740] Gaussian 1 vs 0:
  Original Loss: 0.0025344
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025344 (Pseudo: 0.00%)
[Iter 1750/20000] Loss: 0.0023591 (Best: 0.0021193 @iter1750) ([92mâ†“8.83%[0m) [0.94% of initial]
[Iter 1750] Gaussian 0 vs 1:
  Original Loss: 0.0021193
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021193 (Pseudo: 0.00%)
[Iter 1750] Gaussian 1 vs 0:
  Original Loss: 0.0021068
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021068 (Pseudo: 0.00%)
[Iter 1760/20000] Loss: 0.0026394 (Best: 0.0021193 @iter1750) ([91mâ†‘11.89%[0m) [1.05% of initial]
[Iter 1760] Gaussian 0 vs 1:
  Original Loss: 0.0025693
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025693 (Pseudo: 0.00%)
[Iter 1760] Gaussian 1 vs 0:
  Original Loss: 0.0025467
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025467 (Pseudo: 0.00%)
[Iter 1770/20000] Loss: 0.0024132 (Best: 0.0021016 @iter1762) ([92mâ†“8.57%[0m) [0.96% of initial]
[Iter 1770] Gaussian 0 vs 1:
  Original Loss: 0.0023258
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023258 (Pseudo: 0.00%)
[Iter 1770] Gaussian 1 vs 0:
  Original Loss: 0.0024920
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024920 (Pseudo: 0.00%)
[Iter 1780/20000] Loss: 0.0025756 (Best: 0.0020700 @iter1771) ([91mâ†‘6.73%[0m) [1.02% of initial]
[Iter 1780] Gaussian 0 vs 1:
  Original Loss: 0.0028361
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028361 (Pseudo: 0.00%)
[Iter 1780] Gaussian 1 vs 0:
  Original Loss: 0.0026267
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026267 (Pseudo: 0.00%)
[Iter 1790/20000] Loss: 0.0021820 (Best: 0.0019079 @iter1786) ([92mâ†“15.28%[0m) [0.87% of initial]
[Iter 1790] Gaussian 0 vs 1:
  Original Loss: 0.0021447
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021447 (Pseudo: 0.00%)
[Iter 1790] Gaussian 1 vs 0:
  Original Loss: 0.0022336
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022336 (Pseudo: 0.00%)
Iter:1799, L1 loss=0.001723, Total loss=0.00191, Time:14
[Iter 1800/20000] Loss: 0.0021893 (Best: 0.0019079 @iter1786) ([91mâ†‘0.34%[0m) [0.87% of initial]
[Iter 1800] Gaussian 0 vs 1:
  Original Loss: 0.0021596
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021596 (Pseudo: 0.00%)
[Iter 1800] Gaussian 1 vs 0:
  Original Loss: 0.0022137
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022137 (Pseudo: 0.00%)
[Iter 1810/20000] Loss: 0.0076617 (Best: 0.0019079 @iter1786) ([91mâ†‘249.95%[0m) [3.04% of initial]
[Iter 1810] Gaussian 0 vs 1:
  Original Loss: 0.0067294
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067294 (Pseudo: 0.00%)
[Iter 1810] Gaussian 1 vs 0:
  Original Loss: 0.0065935
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0065935 (Pseudo: 0.00%)
[Iter 1820/20000] Loss: 0.0046328 (Best: 0.0019079 @iter1786) ([92mâ†“39.53%[0m) [1.84% of initial]
[Iter 1820] Gaussian 0 vs 1:
  Original Loss: 0.0046501
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046501 (Pseudo: 0.00%)
[Iter 1820] Gaussian 1 vs 0:
  Original Loss: 0.0044780
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044780 (Pseudo: 0.00%)
[Iter 1830/20000] Loss: 0.0040344 (Best: 0.0019079 @iter1786) ([92mâ†“12.92%[0m) [1.60% of initial]
[Iter 1830] Gaussian 0 vs 1:
  Original Loss: 0.0038599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038599 (Pseudo: 0.00%)
[Iter 1830] Gaussian 1 vs 0:
  Original Loss: 0.0038179
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038179 (Pseudo: 0.00%)
[Iter 1840/20000] Loss: 0.0027951 (Best: 0.0019079 @iter1786) ([92mâ†“30.72%[0m) [1.11% of initial]
[Iter 1840] Gaussian 0 vs 1:
  Original Loss: 0.0024393
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024393 (Pseudo: 0.00%)
[Iter 1840] Gaussian 1 vs 0:
  Original Loss: 0.0024789
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024789 (Pseudo: 0.00%)
[Iter 1850/20000] Loss: 0.0026447 (Best: 0.0019079 @iter1786) ([92mâ†“5.38%[0m) [1.05% of initial]
[Iter 1850] Gaussian 0 vs 1:
  Original Loss: 0.0024306
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024306 (Pseudo: 0.00%)
[Iter 1850] Gaussian 1 vs 0:
  Original Loss: 0.0025061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025061 (Pseudo: 0.00%)
[Iter 1860/20000] Loss: 0.0024080 (Best: 0.0019079 @iter1786) ([92mâ†“8.95%[0m) [0.96% of initial]
[Iter 1860] Gaussian 0 vs 1:
  Original Loss: 0.0022176
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022176 (Pseudo: 0.00%)
[Iter 1860] Gaussian 1 vs 0:
  Original Loss: 0.0023248
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023248 (Pseudo: 0.00%)
[Iter 1870/20000] Loss: 0.0022293 (Best: 0.0018235 @iter1867) ([92mâ†“7.42%[0m) [0.89% of initial]
[Iter 1870] Gaussian 0 vs 1:
  Original Loss: 0.0020194
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020194 (Pseudo: 0.00%)
[Iter 1870] Gaussian 1 vs 0:
  Original Loss: 0.0020681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020681 (Pseudo: 0.00%)
[Iter 1880/20000] Loss: 0.0021073 (Best: 0.0018235 @iter1867) ([92mâ†“5.47%[0m) [0.84% of initial]
[Iter 1880] Gaussian 0 vs 1:
  Original Loss: 0.0018463
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018463 (Pseudo: 0.00%)
[Iter 1880] Gaussian 1 vs 0:
  Original Loss: 0.0018810
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018810 (Pseudo: 0.00%)
[Iter 1890/20000] Loss: 0.0018982 (Best: 0.0017544 @iter1890) ([92mâ†“9.92%[0m) [0.75% of initial]
[Iter 1890] Gaussian 0 vs 1:
  Original Loss: 0.0017544
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017544 (Pseudo: 0.00%)
[Iter 1890] Gaussian 1 vs 0:
  Original Loss: 0.0018244
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018244 (Pseudo: 0.00%)
Iter:1899, L1 loss=0.001802, Total loss=0.001931, Time:14
[Iter 1900/20000] Loss: 0.0020137 (Best: 0.0016192 @iter1891) ([91mâ†‘6.09%[0m) [0.80% of initial]
[Iter 1900] Gaussian 0 vs 1:
  Original Loss: 0.0018894
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018894 (Pseudo: 0.00%)
[Iter 1900] Gaussian 1 vs 0:
  Original Loss: 0.0019089
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019089 (Pseudo: 0.00%)
[Iter 1910/20000] Loss: 0.0020443 (Best: 0.0016192 @iter1891) ([91mâ†‘1.52%[0m) [0.81% of initial]
[Iter 1910] Gaussian 0 vs 1:
  Original Loss: 0.0018147
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018147 (Pseudo: 0.00%)
[Iter 1910] Gaussian 1 vs 0:
  Original Loss: 0.0018719
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018719 (Pseudo: 0.00%)
[Iter 1920/20000] Loss: 0.0020844 (Best: 0.0016192 @iter1891) ([91mâ†‘1.96%[0m) [0.83% of initial]
[Iter 1920] Gaussian 0 vs 1:
  Original Loss: 0.0021109
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021109 (Pseudo: 0.00%)
[Iter 1920] Gaussian 1 vs 0:
  Original Loss: 0.0021875
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021875 (Pseudo: 0.00%)
[Iter 1930/20000] Loss: 0.0017584 (Best: 0.0015703 @iter1930) ([92mâ†“15.64%[0m) [0.70% of initial]
[Iter 1930] Gaussian 0 vs 1:
  Original Loss: 0.0015703
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015703 (Pseudo: 0.00%)
[Iter 1930] Gaussian 1 vs 0:
  Original Loss: 0.0016237
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016237 (Pseudo: 0.00%)
[Iter 1940/20000] Loss: 0.0019079 (Best: 0.0015630 @iter1939) ([91mâ†‘8.50%[0m) [0.76% of initial]
[Iter 1940] Gaussian 0 vs 1:
  Original Loss: 0.0019935
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019935 (Pseudo: 0.00%)
[Iter 1940] Gaussian 1 vs 0:
  Original Loss: 0.0020324
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020324 (Pseudo: 0.00%)
[Iter 1950/20000] Loss: 0.0020725 (Best: 0.0015630 @iter1939) ([91mâ†‘8.63%[0m) [0.82% of initial]
[Iter 1950] Gaussian 0 vs 1:
  Original Loss: 0.0018989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018989 (Pseudo: 0.00%)
[Iter 1950] Gaussian 1 vs 0:
  Original Loss: 0.0018829
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018829 (Pseudo: 0.00%)
[Iter 1960/20000] Loss: 0.0018455 (Best: 0.0015630 @iter1939) ([92mâ†“10.95%[0m) [0.73% of initial]
[Iter 1960] Gaussian 0 vs 1:
  Original Loss: 0.0017291
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017291 (Pseudo: 0.00%)
[Iter 1960] Gaussian 1 vs 0:
  Original Loss: 0.0017443
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017443 (Pseudo: 0.00%)
[Iter 1970/20000] Loss: 0.0016843 (Best: 0.0015053 @iter1963) ([92mâ†“8.74%[0m) [0.67% of initial]
[Iter 1970] Gaussian 0 vs 1:
  Original Loss: 0.0016038
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016038 (Pseudo: 0.00%)
[Iter 1970] Gaussian 1 vs 0:
  Original Loss: 0.0016612
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016612 (Pseudo: 0.00%)
[Iter 1980/20000] Loss: 0.0020370 (Best: 0.0015053 @iter1963) ([91mâ†‘20.94%[0m) [0.81% of initial]
[Iter 1980] Gaussian 0 vs 1:
  Original Loss: 0.0024244
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024244 (Pseudo: 0.00%)
[Iter 1980] Gaussian 1 vs 0:
  Original Loss: 0.0024139
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024139 (Pseudo: 0.00%)
[Iter 1990/20000] Loss: 0.0017610 (Best: 0.0015053 @iter1963) ([92mâ†“13.55%[0m) [0.70% of initial]
[Iter 1990] Gaussian 0 vs 1:
  Original Loss: 0.0016106
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016106 (Pseudo: 0.00%)
[Iter 1990] Gaussian 1 vs 0:
  Original Loss: 0.0016746
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016746 (Pseudo: 0.00%)
Iter:1999, L1 loss=0.001565, Total loss=0.001666, Time:14
[Iter 2000/20000] Loss: 0.0018758 (Best: 0.0014433 @iter1996) ([91mâ†‘6.51%[0m) [0.75% of initial]
Testing Speed: 232.01330245947253 fps
Testing Time: 0.21550488471984863 s

[ITER 2000] Evaluating test: SSIM = 0.8421867966651917, PSNR = 17.482737598419188
Testing Speed: 271.1191743336709 fps
Testing Time: 0.011065244674682617 s

[ITER 2000] Evaluating train: SSIM = 0.9999533891677856, PSNR = 49.29673131306966
Iter:2000, total_points:42649
[Iter 2000] Gaussian 0 vs 1:
  Original Loss: 0.0020144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020144 (Pseudo: 0.00%)
[Iter 2000] Gaussian 1 vs 0:
  Original Loss: 0.0020813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020813 (Pseudo: 0.00%)
[Iter 2010/20000] Loss: 0.0068129 (Best: 0.0014433 @iter1996) ([91mâ†‘263.21%[0m) [2.71% of initial]
[Iter 2010] Gaussian 0 vs 1:
  Original Loss: 0.0061866
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0061866 (Pseudo: 0.00%)
[Iter 2010] Gaussian 1 vs 0:
  Original Loss: 0.0060190
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0060190 (Pseudo: 0.00%)
[Iter 2020/20000] Loss: 0.0037290 (Best: 0.0014433 @iter1996) ([92mâ†“45.27%[0m) [1.48% of initial]
[Iter 2020] Gaussian 0 vs 1:
  Original Loss: 0.0033068
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033068 (Pseudo: 0.00%)
[Iter 2020] Gaussian 1 vs 0:
  Original Loss: 0.0033086
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033086 (Pseudo: 0.00%)
[Iter 2030/20000] Loss: 0.0027863 (Best: 0.0014433 @iter1996) ([92mâ†“25.28%[0m) [1.11% of initial]
[Iter 2030] Gaussian 0 vs 1:
  Original Loss: 0.0024480
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024480 (Pseudo: 0.00%)
[Iter 2030] Gaussian 1 vs 0:
  Original Loss: 0.0024404
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024404 (Pseudo: 0.00%)
[Iter 2040/20000] Loss: 0.0024637 (Best: 0.0014433 @iter1996) ([92mâ†“11.58%[0m) [0.98% of initial]
[Iter 2040] Gaussian 0 vs 1:
  Original Loss: 0.0026871
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026871 (Pseudo: 0.00%)
[Iter 2040] Gaussian 1 vs 0:
  Original Loss: 0.0027984
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027984 (Pseudo: 0.00%)
[Iter 2050/20000] Loss: 0.0020773 (Best: 0.0014433 @iter1996) ([92mâ†“15.68%[0m) [0.83% of initial]
[Iter 2050] Gaussian 0 vs 1:
  Original Loss: 0.0017442
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017442 (Pseudo: 0.00%)
[Iter 2050] Gaussian 1 vs 0:
  Original Loss: 0.0018063
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018063 (Pseudo: 0.00%)
[Iter 2060/20000] Loss: 0.0017279 (Best: 0.0014433 @iter1996) ([92mâ†“16.82%[0m) [0.69% of initial]
[Iter 2060] Gaussian 0 vs 1:
  Original Loss: 0.0015585
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015585 (Pseudo: 0.00%)
[Iter 2060] Gaussian 1 vs 0:
  Original Loss: 0.0015658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015658 (Pseudo: 0.00%)
[Iter 2070/20000] Loss: 0.0019507 (Best: 0.0014433 @iter1996) ([91mâ†‘12.90%[0m) [0.78% of initial]
[Iter 2070] Gaussian 0 vs 1:
  Original Loss: 0.0021781
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021781 (Pseudo: 0.00%)
[Iter 2070] Gaussian 1 vs 0:
  Original Loss: 0.0023145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023145 (Pseudo: 0.00%)
[Iter 2080/20000] Loss: 0.0018921 (Best: 0.0014433 @iter1996) ([92mâ†“3.00%[0m) [0.75% of initial]
[Iter 2080] Gaussian 0 vs 1:
  Original Loss: 0.0020830
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020830 (Pseudo: 0.00%)
[Iter 2080] Gaussian 1 vs 0:
  Original Loss: 0.0021600
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021600 (Pseudo: 0.00%)
[Iter 2090/20000] Loss: 0.0018262 (Best: 0.0014433 @iter1996) ([92mâ†“3.49%[0m) [0.73% of initial]
[Iter 2090] Gaussian 0 vs 1:
  Original Loss: 0.0020341
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020341 (Pseudo: 0.00%)
[Iter 2090] Gaussian 1 vs 0:
  Original Loss: 0.0021387
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021387 (Pseudo: 0.00%)
Iter:2099, L1 loss=0.001594, Total loss=0.001751, Time:14
[Iter 2100/20000] Loss: 0.0017001 (Best: 0.0014433 @iter1996) ([92mâ†“6.90%[0m) [0.68% of initial]
[Iter 2100] Gaussian 0 vs 1:
  Original Loss: 0.0015966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015966 (Pseudo: 0.00%)
[Iter 2100] Gaussian 1 vs 0:
  Original Loss: 0.0016208
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016208 (Pseudo: 0.00%)
[Iter 2110/20000] Loss: 0.0016327 (Best: 0.0014320 @iter2101) ([92mâ†“3.96%[0m) [0.65% of initial]
[Iter 2110] Gaussian 0 vs 1:
  Original Loss: 0.0015009
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015009 (Pseudo: 0.00%)
[Iter 2110] Gaussian 1 vs 0:
  Original Loss: 0.0014759
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014759 (Pseudo: 0.00%)
[Iter 2120/20000] Loss: 0.0014301 (Best: 0.0013033 @iter2120) ([92mâ†“12.41%[0m) [0.57% of initial]
[Iter 2120] Gaussian 0 vs 1:
  Original Loss: 0.0013033
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013033 (Pseudo: 0.00%)
[Iter 2120] Gaussian 1 vs 0:
  Original Loss: 0.0013208
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013208 (Pseudo: 0.00%)
[Iter 2130/20000] Loss: 0.0015714 (Best: 0.0012233 @iter2125) ([91mâ†‘9.88%[0m) [0.62% of initial]
[Iter 2130] Gaussian 0 vs 1:
  Original Loss: 0.0016318
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016318 (Pseudo: 0.00%)
[Iter 2130] Gaussian 1 vs 0:
  Original Loss: 0.0017009
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017009 (Pseudo: 0.00%)
[Iter 2140/20000] Loss: 0.0017211 (Best: 0.0012233 @iter2125) ([91mâ†‘9.52%[0m) [0.68% of initial]
[Iter 2140] Gaussian 0 vs 1:
  Original Loss: 0.0018433
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018433 (Pseudo: 0.00%)
[Iter 2140] Gaussian 1 vs 0:
  Original Loss: 0.0019330
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019330 (Pseudo: 0.00%)
[Iter 2150/20000] Loss: 0.0017331 (Best: 0.0012233 @iter2125) ([91mâ†‘0.70%[0m) [0.69% of initial]
[Iter 2150] Gaussian 0 vs 1:
  Original Loss: 0.0015225
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015225 (Pseudo: 0.00%)
[Iter 2150] Gaussian 1 vs 0:
  Original Loss: 0.0016663
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016663 (Pseudo: 0.00%)
[Iter 2160/20000] Loss: 0.0015552 (Best: 0.0012233 @iter2125) ([92mâ†“10.27%[0m) [0.62% of initial]
[Iter 2160] Gaussian 0 vs 1:
  Original Loss: 0.0013719
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013719 (Pseudo: 0.00%)
[Iter 2160] Gaussian 1 vs 0:
  Original Loss: 0.0014847
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014847 (Pseudo: 0.00%)
[Iter 2170/20000] Loss: 0.0016037 (Best: 0.0012233 @iter2125) ([91mâ†‘3.12%[0m) [0.64% of initial]
[Iter 2170] Gaussian 0 vs 1:
  Original Loss: 0.0016857
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016857 (Pseudo: 0.00%)
[Iter 2170] Gaussian 1 vs 0:
  Original Loss: 0.0017707
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017707 (Pseudo: 0.00%)
[Iter 2180/20000] Loss: 0.0013268 (Best: 0.0011927 @iter2180) ([92mâ†“17.27%[0m) [0.53% of initial]
[Iter 2180] Gaussian 0 vs 1:
  Original Loss: 0.0011927
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011927 (Pseudo: 0.00%)
[Iter 2180] Gaussian 1 vs 0:
  Original Loss: 0.0012543
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012543 (Pseudo: 0.00%)
[Iter 2190/20000] Loss: 0.0015875 (Best: 0.0011927 @iter2180) ([91mâ†‘19.66%[0m) [0.63% of initial]
[Iter 2190] Gaussian 0 vs 1:
  Original Loss: 0.0018445
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018445 (Pseudo: 0.00%)
[Iter 2190] Gaussian 1 vs 0:
  Original Loss: 0.0019063
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019063 (Pseudo: 0.00%)
Iter:2199, L1 loss=0.001456, Total loss=0.001527, Time:14
[Iter 2200/20000] Loss: 0.0016030 (Best: 0.0011927 @iter2180) ([91mâ†‘0.98%[0m) [0.64% of initial]
[Iter 2200] Gaussian 0 vs 1:
  Original Loss: 0.0017738
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017738 (Pseudo: 0.00%)
[Iter 2200] Gaussian 1 vs 0:
  Original Loss: 0.0018243
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018243 (Pseudo: 0.00%)
[Iter 2210/20000] Loss: 0.0077410 (Best: 0.0011927 @iter2180) ([91mâ†‘382.90%[0m) [3.08% of initial]
[Iter 2210] Gaussian 0 vs 1:
  Original Loss: 0.0077021
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0077021 (Pseudo: 0.00%)
[Iter 2210] Gaussian 1 vs 0:
  Original Loss: 0.0071833
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0071833 (Pseudo: 0.00%)
[Iter 2220/20000] Loss: 0.0042461 (Best: 0.0011927 @iter2180) ([92mâ†“45.15%[0m) [1.69% of initial]
[Iter 2220] Gaussian 0 vs 1:
  Original Loss: 0.0038329
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038329 (Pseudo: 0.00%)
[Iter 2220] Gaussian 1 vs 0:
  Original Loss: 0.0038107
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038107 (Pseudo: 0.00%)
[Iter 2230/20000] Loss: 0.0026631 (Best: 0.0011927 @iter2180) ([92mâ†“37.28%[0m) [1.06% of initial]
[Iter 2230] Gaussian 0 vs 1:
  Original Loss: 0.0022700
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022700 (Pseudo: 0.00%)
[Iter 2230] Gaussian 1 vs 0:
  Original Loss: 0.0023216
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023216 (Pseudo: 0.00%)
[Iter 2240/20000] Loss: 0.0023037 (Best: 0.0011927 @iter2180) ([92mâ†“13.49%[0m) [0.92% of initial]
[Iter 2240] Gaussian 0 vs 1:
  Original Loss: 0.0020780
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020780 (Pseudo: 0.00%)
[Iter 2240] Gaussian 1 vs 0:
  Original Loss: 0.0021179
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021179 (Pseudo: 0.00%)
[Iter 2250/20000] Loss: 0.0021170 (Best: 0.0011927 @iter2180) ([92mâ†“8.11%[0m) [0.84% of initial]
[Iter 2250] Gaussian 0 vs 1:
  Original Loss: 0.0022340
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0022340 (Pseudo: 0.00%)
[Iter 2250] Gaussian 1 vs 0:
  Original Loss: 0.0023895
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023895 (Pseudo: 0.00%)
[Iter 2260/20000] Loss: 0.0017067 (Best: 0.0011927 @iter2180) ([92mâ†“19.38%[0m) [0.68% of initial]
[Iter 2260] Gaussian 0 vs 1:
  Original Loss: 0.0015235
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015235 (Pseudo: 0.00%)
[Iter 2260] Gaussian 1 vs 0:
  Original Loss: 0.0015706
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015706 (Pseudo: 0.00%)
[Iter 2270/20000] Loss: 0.0018361 (Best: 0.0011927 @iter2180) ([91mâ†‘7.58%[0m) [0.73% of initial]
[Iter 2270] Gaussian 0 vs 1:
  Original Loss: 0.0020544
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020544 (Pseudo: 0.00%)
[Iter 2270] Gaussian 1 vs 0:
  Original Loss: 0.0020416
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020416 (Pseudo: 0.00%)
[Iter 2280/20000] Loss: 0.0014657 (Best: 0.0011927 @iter2180) ([92mâ†“20.17%[0m) [0.58% of initial]
[Iter 2280] Gaussian 0 vs 1:
  Original Loss: 0.0013803
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013803 (Pseudo: 0.00%)
[Iter 2280] Gaussian 1 vs 0:
  Original Loss: 0.0013969
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013969 (Pseudo: 0.00%)
[Iter 2290/20000] Loss: 0.0014081 (Best: 0.0011847 @iter2287) ([92mâ†“3.93%[0m) [0.56% of initial]
[Iter 2290] Gaussian 0 vs 1:
  Original Loss: 0.0012662
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012662 (Pseudo: 0.00%)
[Iter 2290] Gaussian 1 vs 0:
  Original Loss: 0.0012692
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012692 (Pseudo: 0.00%)
Iter:2299, L1 loss=0.001383, Total loss=0.001363, Time:15
[Iter 2300/20000] Loss: 0.0016795 (Best: 0.0011847 @iter2287) ([91mâ†‘19.27%[0m) [0.67% of initial]
[Iter 2300] Gaussian 0 vs 1:
  Original Loss: 0.0018161
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018161 (Pseudo: 0.00%)
[Iter 2300] Gaussian 1 vs 0:
  Original Loss: 0.0018484
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018484 (Pseudo: 0.00%)
[Iter 2310/20000] Loss: 0.0015421 (Best: 0.0011847 @iter2287) ([92mâ†“8.18%[0m) [0.61% of initial]
[Iter 2310] Gaussian 0 vs 1:
  Original Loss: 0.0014799
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014799 (Pseudo: 0.00%)
[Iter 2310] Gaussian 1 vs 0:
  Original Loss: 0.0014633
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014633 (Pseudo: 0.00%)
[Iter 2320/20000] Loss: 0.0013266 (Best: 0.0011847 @iter2287) ([92mâ†“13.98%[0m) [0.53% of initial]
[Iter 2320] Gaussian 0 vs 1:
  Original Loss: 0.0012061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012061 (Pseudo: 0.00%)
[Iter 2320] Gaussian 1 vs 0:
  Original Loss: 0.0012197
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012197 (Pseudo: 0.00%)
[Iter 2330/20000] Loss: 0.0012977 (Best: 0.0011217 @iter2327) ([92mâ†“2.17%[0m) [0.52% of initial]
[Iter 2330] Gaussian 0 vs 1:
  Original Loss: 0.0012593
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012593 (Pseudo: 0.00%)
[Iter 2330] Gaussian 1 vs 0:
  Original Loss: 0.0013112
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013112 (Pseudo: 0.00%)
[Iter 2340/20000] Loss: 0.0013585 (Best: 0.0011087 @iter2338) ([91mâ†‘4.69%[0m) [0.54% of initial]
[Iter 2340] Gaussian 0 vs 1:
  Original Loss: 0.0012499
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012499 (Pseudo: 0.00%)
[Iter 2340] Gaussian 1 vs 0:
  Original Loss: 0.0012602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012602 (Pseudo: 0.00%)
[Iter 2350/20000] Loss: 0.0014826 (Best: 0.0011087 @iter2338) ([91mâ†‘9.14%[0m) [0.59% of initial]
[Iter 2350] Gaussian 0 vs 1:
  Original Loss: 0.0013784
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013784 (Pseudo: 0.00%)
[Iter 2350] Gaussian 1 vs 0:
  Original Loss: 0.0014920
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014920 (Pseudo: 0.00%)
[Iter 2360/20000] Loss: 0.0012897 (Best: 0.0011040 @iter2359) ([92mâ†“13.01%[0m) [0.51% of initial]
[Iter 2360] Gaussian 0 vs 1:
  Original Loss: 0.0013252
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013252 (Pseudo: 0.00%)
[Iter 2360] Gaussian 1 vs 0:
  Original Loss: 0.0013850
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013850 (Pseudo: 0.00%)
[Iter 2370/20000] Loss: 0.0014302 (Best: 0.0011040 @iter2359) ([91mâ†‘10.90%[0m) [0.57% of initial]
[Iter 2370] Gaussian 0 vs 1:
  Original Loss: 0.0012327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012327 (Pseudo: 0.00%)
[Iter 2370] Gaussian 1 vs 0:
  Original Loss: 0.0012409
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012409 (Pseudo: 0.00%)
[Iter 2380/20000] Loss: 0.0015188 (Best: 0.0011040 @iter2359) ([91mâ†‘6.19%[0m) [0.60% of initial]
[Iter 2380] Gaussian 0 vs 1:
  Original Loss: 0.0016113
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016113 (Pseudo: 0.00%)
[Iter 2380] Gaussian 1 vs 0:
  Original Loss: 0.0016115
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016115 (Pseudo: 0.00%)
[Iter 2390/20000] Loss: 0.0016539 (Best: 0.0011040 @iter2359) ([91mâ†‘8.90%[0m) [0.66% of initial]
[Iter 2390] Gaussian 0 vs 1:
  Original Loss: 0.0018041
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018041 (Pseudo: 0.00%)
[Iter 2390] Gaussian 1 vs 0:
  Original Loss: 0.0018221
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018221 (Pseudo: 0.00%)
Iter:2399, L1 loss=0.001238, Total loss=0.001247, Time:15
[Iter 2400/20000] Loss: 0.0013403 (Best: 0.0011040 @iter2359) ([92mâ†“18.96%[0m) [0.53% of initial]
[Iter 2400] Gaussian 0 vs 1:
  Original Loss: 0.0012132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012132 (Pseudo: 0.00%)
[Iter 2400] Gaussian 1 vs 0:
  Original Loss: 0.0011974
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011974 (Pseudo: 0.00%)
[Iter 2410/20000] Loss: 0.0058970 (Best: 0.0011040 @iter2359) ([91mâ†‘339.99%[0m) [2.34% of initial]
[Iter 2410] Gaussian 0 vs 1:
  Original Loss: 0.0050345
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0050345 (Pseudo: 0.00%)
[Iter 2410] Gaussian 1 vs 0:
  Original Loss: 0.0049764
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0049764 (Pseudo: 0.00%)
[Iter 2420/20000] Loss: 0.0034625 (Best: 0.0011040 @iter2359) ([92mâ†“41.28%[0m) [1.38% of initial]
[Iter 2420] Gaussian 0 vs 1:
  Original Loss: 0.0030360
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030360 (Pseudo: 0.00%)
[Iter 2420] Gaussian 1 vs 0:
  Original Loss: 0.0028888
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028888 (Pseudo: 0.00%)
[Iter 2430/20000] Loss: 0.0025139 (Best: 0.0011040 @iter2359) ([92mâ†“27.40%[0m) [1.00% of initial]
[Iter 2430] Gaussian 0 vs 1:
  Original Loss: 0.0026456
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026456 (Pseudo: 0.00%)
[Iter 2430] Gaussian 1 vs 0:
  Original Loss: 0.0026165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026165 (Pseudo: 0.00%)
[Iter 2440/20000] Loss: 0.0019958 (Best: 0.0011040 @iter2359) ([92mâ†“20.61%[0m) [0.79% of initial]
[Iter 2440] Gaussian 0 vs 1:
  Original Loss: 0.0016754
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016754 (Pseudo: 0.00%)
[Iter 2440] Gaussian 1 vs 0:
  Original Loss: 0.0016822
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016822 (Pseudo: 0.00%)
[Iter 2450/20000] Loss: 0.0019416 (Best: 0.0011040 @iter2359) ([92mâ†“2.72%[0m) [0.77% of initial]
[Iter 2450] Gaussian 0 vs 1:
  Original Loss: 0.0020349
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020349 (Pseudo: 0.00%)
[Iter 2450] Gaussian 1 vs 0:
  Original Loss: 0.0020311
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020311 (Pseudo: 0.00%)
[Iter 2460/20000] Loss: 0.0016926 (Best: 0.0011040 @iter2359) ([92mâ†“12.82%[0m) [0.67% of initial]
[Iter 2460] Gaussian 0 vs 1:
  Original Loss: 0.0015314
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015314 (Pseudo: 0.00%)
[Iter 2460] Gaussian 1 vs 0:
  Original Loss: 0.0015056
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015056 (Pseudo: 0.00%)
[Iter 2470/20000] Loss: 0.0016547 (Best: 0.0011040 @iter2359) ([92mâ†“2.24%[0m) [0.66% of initial]
[Iter 2470] Gaussian 0 vs 1:
  Original Loss: 0.0016678
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016678 (Pseudo: 0.00%)
[Iter 2470] Gaussian 1 vs 0:
  Original Loss: 0.0016647
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016647 (Pseudo: 0.00%)
[Iter 2480/20000] Loss: 0.0016521 (Best: 0.0011040 @iter2359) ([92mâ†“0.16%[0m) [0.66% of initial]
[Iter 2480] Gaussian 0 vs 1:
  Original Loss: 0.0014433
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014433 (Pseudo: 0.00%)
[Iter 2480] Gaussian 1 vs 0:
  Original Loss: 0.0014422
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014422 (Pseudo: 0.00%)
[Iter 2490/20000] Loss: 0.0014473 (Best: 0.0011040 @iter2359) ([92mâ†“12.40%[0m) [0.58% of initial]
[Iter 2490] Gaussian 0 vs 1:
  Original Loss: 0.0013627
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013627 (Pseudo: 0.00%)
[Iter 2490] Gaussian 1 vs 0:
  Original Loss: 0.0015037
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015037 (Pseudo: 0.00%)
Iter:2499, L1 loss=0.001207, Total loss=0.001236, Time:16
[Iter 2500/20000] Loss: 0.0012990 (Best: 0.0011040 @iter2359) ([92mâ†“10.25%[0m) [0.52% of initial]
[Iter 2500] Gaussian 0 vs 1:
  Original Loss: 0.0011932
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011932 (Pseudo: 0.00%)
[Iter 2500] Gaussian 1 vs 0:
  Original Loss: 0.0012108
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012108 (Pseudo: 0.00%)
[Iter 2510/20000] Loss: 0.0013522 (Best: 0.0010299 @iter2504) ([91mâ†‘4.09%[0m) [0.54% of initial]
[Iter 2510] Gaussian 0 vs 1:
  Original Loss: 0.0015869
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015869 (Pseudo: 0.00%)
[Iter 2510] Gaussian 1 vs 0:
  Original Loss: 0.0015752
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015752 (Pseudo: 0.00%)
[Iter 2520/20000] Loss: 0.0012072 (Best: 0.0009926 @iter2519) ([92mâ†“10.72%[0m) [0.48% of initial]
[Iter 2520] Gaussian 0 vs 1:
  Original Loss: 0.0012450
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012450 (Pseudo: 0.00%)
[Iter 2520] Gaussian 1 vs 0:
  Original Loss: 0.0012666
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012666 (Pseudo: 0.00%)
[Iter 2530/20000] Loss: 0.0010637 (Best: 0.0009588 @iter2528) ([92mâ†“11.89%[0m) [0.42% of initial]
[Iter 2530] Gaussian 0 vs 1:
  Original Loss: 0.0009593
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009593 (Pseudo: 0.00%)
[Iter 2530] Gaussian 1 vs 0:
  Original Loss: 0.0009933
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009933 (Pseudo: 0.00%)
[Iter 2540/20000] Loss: 0.0011748 (Best: 0.0009588 @iter2528) ([91mâ†‘10.45%[0m) [0.47% of initial]
[Iter 2540] Gaussian 0 vs 1:
  Original Loss: 0.0011936
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011936 (Pseudo: 0.00%)
[Iter 2540] Gaussian 1 vs 0:
  Original Loss: 0.0011846
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011846 (Pseudo: 0.00%)
[Iter 2550/20000] Loss: 0.0014118 (Best: 0.0009588 @iter2528) ([91mâ†‘20.17%[0m) [0.56% of initial]
[Iter 2550] Gaussian 0 vs 1:
  Original Loss: 0.0015145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015145 (Pseudo: 0.00%)
[Iter 2550] Gaussian 1 vs 0:
  Original Loss: 0.0014685
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014685 (Pseudo: 0.00%)
[Iter 2560/20000] Loss: 0.0011933 (Best: 0.0009588 @iter2528) ([92mâ†“15.48%[0m) [0.47% of initial]
[Iter 2560] Gaussian 0 vs 1:
  Original Loss: 0.0010902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010902 (Pseudo: 0.00%)
[Iter 2560] Gaussian 1 vs 0:
  Original Loss: 0.0010795
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010795 (Pseudo: 0.00%)
[Iter 2570/20000] Loss: 0.0014361 (Best: 0.0009588 @iter2528) ([91mâ†‘20.34%[0m) [0.57% of initial]
[Iter 2570] Gaussian 0 vs 1:
  Original Loss: 0.0015116
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015116 (Pseudo: 0.00%)
[Iter 2570] Gaussian 1 vs 0:
  Original Loss: 0.0014185
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014185 (Pseudo: 0.00%)
[Iter 2580/20000] Loss: 0.0012441 (Best: 0.0009550 @iter2578) ([92mâ†“13.36%[0m) [0.49% of initial]
[Iter 2580] Gaussian 0 vs 1:
  Original Loss: 0.0012727
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012727 (Pseudo: 0.00%)
[Iter 2580] Gaussian 1 vs 0:
  Original Loss: 0.0012890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012890 (Pseudo: 0.00%)
[Iter 2590/20000] Loss: 0.0013065 (Best: 0.0009482 @iter2584) ([91mâ†‘5.02%[0m) [0.52% of initial]
[Iter 2590] Gaussian 0 vs 1:
  Original Loss: 0.0013726
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013726 (Pseudo: 0.00%)
[Iter 2590] Gaussian 1 vs 0:
  Original Loss: 0.0013809
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013809 (Pseudo: 0.00%)
Iter:2599, L1 loss=0.001045, Total loss=0.001041, Time:15
[Iter 2600/20000] Loss: 0.0012026 (Best: 0.0009432 @iter2594) ([92mâ†“7.96%[0m) [0.48% of initial]
[Iter 2600] Gaussian 0 vs 1:
  Original Loss: 0.0013100
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013100 (Pseudo: 0.00%)
[Iter 2600] Gaussian 1 vs 0:
  Original Loss: 0.0013116
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013116 (Pseudo: 0.00%)
[Iter 2610/20000] Loss: 0.0060346 (Best: 0.0009432 @iter2594) ([91mâ†‘401.79%[0m) [2.40% of initial]
[Iter 2610] Gaussian 0 vs 1:
  Original Loss: 0.0054844
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0054844 (Pseudo: 0.00%)
[Iter 2610] Gaussian 1 vs 0:
  Original Loss: 0.0054556
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0054556 (Pseudo: 0.00%)
[Iter 2620/20000] Loss: 0.0033043 (Best: 0.0009432 @iter2594) ([92mâ†“45.24%[0m) [1.31% of initial]
[Iter 2620] Gaussian 0 vs 1:
  Original Loss: 0.0028631
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0028631 (Pseudo: 0.00%)
[Iter 2620] Gaussian 1 vs 0:
  Original Loss: 0.0027693
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027693 (Pseudo: 0.00%)
[Iter 2630/20000] Loss: 0.0021755 (Best: 0.0009432 @iter2594) ([92mâ†“34.16%[0m) [0.86% of initial]
[Iter 2630] Gaussian 0 vs 1:
  Original Loss: 0.0021562
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021562 (Pseudo: 0.00%)
[Iter 2630] Gaussian 1 vs 0:
  Original Loss: 0.0021418
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021418 (Pseudo: 0.00%)
[Iter 2640/20000] Loss: 0.0017024 (Best: 0.0009432 @iter2594) ([92mâ†“21.75%[0m) [0.68% of initial]
[Iter 2640] Gaussian 0 vs 1:
  Original Loss: 0.0015691
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015691 (Pseudo: 0.00%)
[Iter 2640] Gaussian 1 vs 0:
  Original Loss: 0.0016036
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016036 (Pseudo: 0.00%)
[Iter 2650/20000] Loss: 0.0013940 (Best: 0.0009432 @iter2594) ([92mâ†“18.12%[0m) [0.55% of initial]
[Iter 2650] Gaussian 0 vs 1:
  Original Loss: 0.0011346
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011346 (Pseudo: 0.00%)
[Iter 2650] Gaussian 1 vs 0:
  Original Loss: 0.0011632
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011632 (Pseudo: 0.00%)
[Iter 2660/20000] Loss: 0.0016448 (Best: 0.0009432 @iter2594) ([91mâ†‘17.99%[0m) [0.65% of initial]
[Iter 2660] Gaussian 0 vs 1:
  Original Loss: 0.0014212
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014212 (Pseudo: 0.00%)
[Iter 2660] Gaussian 1 vs 0:
  Original Loss: 0.0014193
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014193 (Pseudo: 0.00%)
[Iter 2670/20000] Loss: 0.0015510 (Best: 0.0009432 @iter2594) ([92mâ†“5.70%[0m) [0.62% of initial]
[Iter 2670] Gaussian 0 vs 1:
  Original Loss: 0.0016066
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016066 (Pseudo: 0.00%)
[Iter 2670] Gaussian 1 vs 0:
  Original Loss: 0.0016605
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016605 (Pseudo: 0.00%)
[Iter 2680/20000] Loss: 0.0011958 (Best: 0.0009432 @iter2594) ([92mâ†“22.90%[0m) [0.48% of initial]
[Iter 2680] Gaussian 0 vs 1:
  Original Loss: 0.0009974
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009974 (Pseudo: 0.00%)
[Iter 2680] Gaussian 1 vs 0:
  Original Loss: 0.0010313
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010313 (Pseudo: 0.00%)
[Iter 2690/20000] Loss: 0.0011470 (Best: 0.0009432 @iter2594) ([92mâ†“4.08%[0m) [0.46% of initial]
[Iter 2690] Gaussian 0 vs 1:
  Original Loss: 0.0009736
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009736 (Pseudo: 0.00%)
[Iter 2690] Gaussian 1 vs 0:
  Original Loss: 0.0010132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010132 (Pseudo: 0.00%)
Iter:2699, L1 loss=0.001131, Total loss=0.001151, Time:16
[Iter 2700/20000] Loss: 0.0014518 (Best: 0.0009432 @iter2594) ([91mâ†‘26.58%[0m) [0.58% of initial]
[Iter 2700] Gaussian 0 vs 1:
  Original Loss: 0.0017480
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017480 (Pseudo: 0.00%)
[Iter 2700] Gaussian 1 vs 0:
  Original Loss: 0.0017357
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017357 (Pseudo: 0.00%)
[Iter 2710/20000] Loss: 0.0012212 (Best: 0.0009432 @iter2594) ([92mâ†“15.89%[0m) [0.49% of initial]
[Iter 2710] Gaussian 0 vs 1:
  Original Loss: 0.0012359
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012359 (Pseudo: 0.00%)
[Iter 2710] Gaussian 1 vs 0:
  Original Loss: 0.0013093
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013093 (Pseudo: 0.00%)
[Iter 2720/20000] Loss: 0.0010870 (Best: 0.0009219 @iter2713) ([92mâ†“10.99%[0m) [0.43% of initial]
[Iter 2720] Gaussian 0 vs 1:
  Original Loss: 0.0010622
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010622 (Pseudo: 0.00%)
[Iter 2720] Gaussian 1 vs 0:
  Original Loss: 0.0010742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010742 (Pseudo: 0.00%)
[Iter 2730/20000] Loss: 0.0009880 (Best: 0.0008396 @iter2725) ([92mâ†“9.11%[0m) [0.39% of initial]
[Iter 2730] Gaussian 0 vs 1:
  Original Loss: 0.0009129
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009129 (Pseudo: 0.00%)
[Iter 2730] Gaussian 1 vs 0:
  Original Loss: 0.0009658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009658 (Pseudo: 0.00%)
[Iter 2740/20000] Loss: 0.0008605 (Best: 0.0007722 @iter2740) ([92mâ†“12.90%[0m) [0.34% of initial]
[Iter 2740] Gaussian 0 vs 1:
  Original Loss: 0.0007722
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007722 (Pseudo: 0.00%)
[Iter 2740] Gaussian 1 vs 0:
  Original Loss: 0.0007967
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007967 (Pseudo: 0.00%)
[Iter 2750/20000] Loss: 0.0011328 (Best: 0.0007722 @iter2740) ([91mâ†‘31.64%[0m) [0.45% of initial]
[Iter 2750] Gaussian 0 vs 1:
  Original Loss: 0.0013024
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013024 (Pseudo: 0.00%)
[Iter 2750] Gaussian 1 vs 0:
  Original Loss: 0.0013330
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013330 (Pseudo: 0.00%)
[Iter 2760/20000] Loss: 0.0012262 (Best: 0.0007722 @iter2740) ([91mâ†‘8.24%[0m) [0.49% of initial]
[Iter 2760] Gaussian 0 vs 1:
  Original Loss: 0.0014355
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014355 (Pseudo: 0.00%)
[Iter 2760] Gaussian 1 vs 0:
  Original Loss: 0.0013993
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013993 (Pseudo: 0.00%)
[Iter 2770/20000] Loss: 0.0013790 (Best: 0.0007722 @iter2740) ([91mâ†‘12.46%[0m) [0.55% of initial]
[Iter 2770] Gaussian 0 vs 1:
  Original Loss: 0.0013902
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013902 (Pseudo: 0.00%)
[Iter 2770] Gaussian 1 vs 0:
  Original Loss: 0.0012885
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012885 (Pseudo: 0.00%)
[Iter 2780/20000] Loss: 0.0010937 (Best: 0.0007722 @iter2740) ([92mâ†“20.69%[0m) [0.43% of initial]
[Iter 2780] Gaussian 0 vs 1:
  Original Loss: 0.0012486
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012486 (Pseudo: 0.00%)
[Iter 2780] Gaussian 1 vs 0:
  Original Loss: 0.0012622
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012622 (Pseudo: 0.00%)
[Iter 2790/20000] Loss: 0.0011173 (Best: 0.0007722 @iter2740) ([91mâ†‘2.15%[0m) [0.44% of initial]
[Iter 2790] Gaussian 0 vs 1:
  Original Loss: 0.0011622
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011622 (Pseudo: 0.00%)
[Iter 2790] Gaussian 1 vs 0:
  Original Loss: 0.0012055
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012055 (Pseudo: 0.00%)
Iter:2799, L1 loss=0.001276, Total loss=0.001244, Time:16
[Iter 2800/20000] Loss: 0.0011216 (Best: 0.0007722 @iter2740) ([91mâ†‘0.39%[0m) [0.45% of initial]
[Iter 2800] Gaussian 0 vs 1:
  Original Loss: 0.0010034
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010034 (Pseudo: 0.00%)
[Iter 2800] Gaussian 1 vs 0:
  Original Loss: 0.0010019
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010019 (Pseudo: 0.00%)
[Iter 2810/20000] Loss: 0.0049751 (Best: 0.0007722 @iter2740) ([91mâ†‘343.57%[0m) [1.98% of initial]
[Iter 2810] Gaussian 0 vs 1:
  Original Loss: 0.0040502
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040502 (Pseudo: 0.00%)
[Iter 2810] Gaussian 1 vs 0:
  Original Loss: 0.0041810
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041810 (Pseudo: 0.00%)
[Iter 2820/20000] Loss: 0.0027285 (Best: 0.0007722 @iter2740) ([92mâ†“45.16%[0m) [1.08% of initial]
[Iter 2820] Gaussian 0 vs 1:
  Original Loss: 0.0025647
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025647 (Pseudo: 0.00%)
[Iter 2820] Gaussian 1 vs 0:
  Original Loss: 0.0025614
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025614 (Pseudo: 0.00%)
[Iter 2830/20000] Loss: 0.0017562 (Best: 0.0007722 @iter2740) ([92mâ†“35.63%[0m) [0.70% of initial]
[Iter 2830] Gaussian 0 vs 1:
  Original Loss: 0.0015239
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015239 (Pseudo: 0.00%)
[Iter 2830] Gaussian 1 vs 0:
  Original Loss: 0.0015956
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015956 (Pseudo: 0.00%)
[Iter 2840/20000] Loss: 0.0014863 (Best: 0.0007722 @iter2740) ([92mâ†“15.37%[0m) [0.59% of initial]
[Iter 2840] Gaussian 0 vs 1:
  Original Loss: 0.0015330
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015330 (Pseudo: 0.00%)
[Iter 2840] Gaussian 1 vs 0:
  Original Loss: 0.0015765
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015765 (Pseudo: 0.00%)
[Iter 2850/20000] Loss: 0.0012870 (Best: 0.0007722 @iter2740) ([92mâ†“13.41%[0m) [0.51% of initial]
[Iter 2850] Gaussian 0 vs 1:
  Original Loss: 0.0013079
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013079 (Pseudo: 0.00%)
[Iter 2850] Gaussian 1 vs 0:
  Original Loss: 0.0013613
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013613 (Pseudo: 0.00%)
[Iter 2860/20000] Loss: 0.0013964 (Best: 0.0007722 @iter2740) ([91mâ†‘8.50%[0m) [0.55% of initial]
[Iter 2860] Gaussian 0 vs 1:
  Original Loss: 0.0014240
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014240 (Pseudo: 0.00%)
[Iter 2860] Gaussian 1 vs 0:
  Original Loss: 0.0014602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014602 (Pseudo: 0.00%)
[Iter 2870/20000] Loss: 0.0011742 (Best: 0.0007722 @iter2740) ([92mâ†“15.91%[0m) [0.47% of initial]
[Iter 2870] Gaussian 0 vs 1:
  Original Loss: 0.0011198
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011198 (Pseudo: 0.00%)
[Iter 2870] Gaussian 1 vs 0:
  Original Loss: 0.0011681
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011681 (Pseudo: 0.00%)
[Iter 2880/20000] Loss: 0.0011453 (Best: 0.0007722 @iter2740) ([92mâ†“2.46%[0m) [0.45% of initial]
[Iter 2880] Gaussian 0 vs 1:
  Original Loss: 0.0011432
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011432 (Pseudo: 0.00%)
[Iter 2880] Gaussian 1 vs 0:
  Original Loss: 0.0012069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012069 (Pseudo: 0.00%)
[Iter 2890/20000] Loss: 0.0010832 (Best: 0.0007722 @iter2740) ([92mâ†“5.42%[0m) [0.43% of initial]
[Iter 2890] Gaussian 0 vs 1:
  Original Loss: 0.0010850
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010850 (Pseudo: 0.00%)
[Iter 2890] Gaussian 1 vs 0:
  Original Loss: 0.0011750
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011750 (Pseudo: 0.00%)
Iter:2899, L1 loss=0.0008849, Total loss=0.0008418, Time:17
[Iter 2900/20000] Loss: 0.0010200 (Best: 0.0007722 @iter2740) ([92mâ†“5.83%[0m) [0.41% of initial]
[Iter 2900] Gaussian 0 vs 1:
  Original Loss: 0.0010767
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010767 (Pseudo: 0.00%)
[Iter 2900] Gaussian 1 vs 0:
  Original Loss: 0.0011505
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011505 (Pseudo: 0.00%)
[Iter 2910/20000] Loss: 0.0011039 (Best: 0.0007722 @iter2740) ([91mâ†‘8.22%[0m) [0.44% of initial]
[Iter 2910] Gaussian 0 vs 1:
  Original Loss: 0.0010608
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010608 (Pseudo: 0.00%)
[Iter 2910] Gaussian 1 vs 0:
  Original Loss: 0.0011112
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011112 (Pseudo: 0.00%)
[Iter 2920/20000] Loss: 0.0012353 (Best: 0.0007722 @iter2740) ([91mâ†‘11.90%[0m) [0.49% of initial]
[Iter 2920] Gaussian 0 vs 1:
  Original Loss: 0.0012004
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012004 (Pseudo: 0.00%)
[Iter 2920] Gaussian 1 vs 0:
  Original Loss: 0.0012262
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012262 (Pseudo: 0.00%)
[Iter 2930/20000] Loss: 0.0011199 (Best: 0.0007722 @iter2740) ([92mâ†“9.34%[0m) [0.44% of initial]
[Iter 2930] Gaussian 0 vs 1:
  Original Loss: 0.0011639
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011639 (Pseudo: 0.00%)
[Iter 2930] Gaussian 1 vs 0:
  Original Loss: 0.0012480
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012480 (Pseudo: 0.00%)
[Iter 2940/20000] Loss: 0.0009712 (Best: 0.0007722 @iter2740) ([92mâ†“13.28%[0m) [0.39% of initial]
[Iter 2940] Gaussian 0 vs 1:
  Original Loss: 0.0009994
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009994 (Pseudo: 0.00%)
[Iter 2940] Gaussian 1 vs 0:
  Original Loss: 0.0009678
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009678 (Pseudo: 0.00%)
[Iter 2950/20000] Loss: 0.0009147 (Best: 0.0007722 @iter2740) ([92mâ†“5.82%[0m) [0.36% of initial]
[Iter 2950] Gaussian 0 vs 1:
  Original Loss: 0.0007887
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007887 (Pseudo: 0.00%)
[Iter 2950] Gaussian 1 vs 0:
  Original Loss: 0.0007735
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007735 (Pseudo: 0.00%)
[Iter 2960/20000] Loss: 0.0009734 (Best: 0.0007722 @iter2740) ([91mâ†‘6.41%[0m) [0.39% of initial]
[Iter 2960] Gaussian 0 vs 1:
  Original Loss: 0.0010943
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010943 (Pseudo: 0.00%)
[Iter 2960] Gaussian 1 vs 0:
  Original Loss: 0.0011494
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011494 (Pseudo: 0.00%)
[Iter 2970/20000] Loss: 0.0008822 (Best: 0.0007206 @iter2969) ([92mâ†“9.36%[0m) [0.35% of initial]
[Iter 2970] Gaussian 0 vs 1:
  Original Loss: 0.0010197
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010197 (Pseudo: 0.00%)
[Iter 2970] Gaussian 1 vs 0:
  Original Loss: 0.0010784
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010784 (Pseudo: 0.00%)
[Iter 2980/20000] Loss: 0.0008343 (Best: 0.0007159 @iter2977) ([92mâ†“5.44%[0m) [0.33% of initial]
[Iter 2980] Gaussian 0 vs 1:
  Original Loss: 0.0008194
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008194 (Pseudo: 0.00%)
[Iter 2980] Gaussian 1 vs 0:
  Original Loss: 0.0008404
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008404 (Pseudo: 0.00%)
[Iter 2990/20000] Loss: 0.0008444 (Best: 0.0006816 @iter2983) ([91mâ†‘1.21%[0m) [0.34% of initial]
[Iter 2990] Gaussian 0 vs 1:
  Original Loss: 0.0008154
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008154 (Pseudo: 0.00%)
[Iter 2990] Gaussian 1 vs 0:
  Original Loss: 0.0008080
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008080 (Pseudo: 0.00%)
Iter:2999, L1 loss=0.0006996, Total loss=0.0006523, Time:16
[Iter 3000/20000] Loss: 0.0008215 (Best: 0.0006523 @iter2999) ([92mâ†“2.71%[0m) [0.33% of initial]
[Iter 3000] Gaussian 0 vs 1:
  Original Loss: 0.0009780
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009780 (Pseudo: 0.00%)
[Iter 3000] Gaussian 1 vs 0:
  Original Loss: 0.0010524
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010524 (Pseudo: 0.00%)
[Iter 3010/20000] Loss: 0.0045499 (Best: 0.0006523 @iter2999) ([91mâ†‘453.84%[0m) [1.81% of initial]
[Iter 3010] Gaussian 0 vs 1:
  Original Loss: 0.0035326
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0035326 (Pseudo: 0.00%)
[Iter 3010] Gaussian 1 vs 0:
  Original Loss: 0.0036303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036303 (Pseudo: 0.00%)
[Iter 3020/20000] Loss: 0.0026290 (Best: 0.0006523 @iter2999) ([92mâ†“42.22%[0m) [1.04% of initial]
[Iter 3020] Gaussian 0 vs 1:
  Original Loss: 0.0027240
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027240 (Pseudo: 0.00%)
[Iter 3020] Gaussian 1 vs 0:
  Original Loss: 0.0027112
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0027112 (Pseudo: 0.00%)
[Iter 3030/20000] Loss: 0.0020890 (Best: 0.0006523 @iter2999) ([92mâ†“20.54%[0m) [0.83% of initial]
[Iter 3030] Gaussian 0 vs 1:
  Original Loss: 0.0024617
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024617 (Pseudo: 0.00%)
[Iter 3030] Gaussian 1 vs 0:
  Original Loss: 0.0024983
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024983 (Pseudo: 0.00%)
[Iter 3040/20000] Loss: 0.0017030 (Best: 0.0006523 @iter2999) ([92mâ†“18.48%[0m) [0.68% of initial]
[Iter 3040] Gaussian 0 vs 1:
  Original Loss: 0.0014865
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014865 (Pseudo: 0.00%)
[Iter 3040] Gaussian 1 vs 0:
  Original Loss: 0.0014183
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014183 (Pseudo: 0.00%)
[Iter 3050/20000] Loss: 0.0014198 (Best: 0.0006523 @iter2999) ([92mâ†“16.63%[0m) [0.56% of initial]
[Iter 3050] Gaussian 0 vs 1:
  Original Loss: 0.0015042
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015042 (Pseudo: 0.00%)
[Iter 3050] Gaussian 1 vs 0:
  Original Loss: 0.0015727
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015727 (Pseudo: 0.00%)
[Iter 3060/20000] Loss: 0.0013639 (Best: 0.0006523 @iter2999) ([92mâ†“3.94%[0m) [0.54% of initial]
[Iter 3060] Gaussian 0 vs 1:
  Original Loss: 0.0011491
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011491 (Pseudo: 0.00%)
[Iter 3060] Gaussian 1 vs 0:
  Original Loss: 0.0011235
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011235 (Pseudo: 0.00%)
[Iter 3070/20000] Loss: 0.0011124 (Best: 0.0006523 @iter2999) ([92mâ†“18.44%[0m) [0.44% of initial]
[Iter 3070] Gaussian 0 vs 1:
  Original Loss: 0.0010832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010832 (Pseudo: 0.00%)
[Iter 3070] Gaussian 1 vs 0:
  Original Loss: 0.0011705
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011705 (Pseudo: 0.00%)
[Iter 3080/20000] Loss: 0.0011266 (Best: 0.0006523 @iter2999) ([91mâ†‘1.27%[0m) [0.45% of initial]
[Iter 3080] Gaussian 0 vs 1:
  Original Loss: 0.0012836
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012836 (Pseudo: 0.00%)
[Iter 3080] Gaussian 1 vs 0:
  Original Loss: 0.0013310
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013310 (Pseudo: 0.00%)
[Iter 3090/20000] Loss: 0.0010788 (Best: 0.0006523 @iter2999) ([92mâ†“4.24%[0m) [0.43% of initial]
[Iter 3090] Gaussian 0 vs 1:
  Original Loss: 0.0011962
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011962 (Pseudo: 0.00%)
[Iter 3090] Gaussian 1 vs 0:
  Original Loss: 0.0011747
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011747 (Pseudo: 0.00%)
Iter:3099, L1 loss=0.000894, Total loss=0.0008774, Time:17
[Iter 3100/20000] Loss: 0.0009867 (Best: 0.0006523 @iter2999) ([92mâ†“8.54%[0m) [0.39% of initial]
[Iter 3100] Gaussian 0 vs 1:
  Original Loss: 0.0009876
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009876 (Pseudo: 0.00%)
[Iter 3100] Gaussian 1 vs 0:
  Original Loss: 0.0010478
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010478 (Pseudo: 0.00%)
[Iter 3110/20000] Loss: 0.0010857 (Best: 0.0006523 @iter2999) ([91mâ†‘10.03%[0m) [0.43% of initial]
[Iter 3110] Gaussian 0 vs 1:
  Original Loss: 0.0012822
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012822 (Pseudo: 0.00%)
[Iter 3110] Gaussian 1 vs 0:
  Original Loss: 0.0013810
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013810 (Pseudo: 0.00%)
[Iter 3120/20000] Loss: 0.0010291 (Best: 0.0006523 @iter2999) ([92mâ†“5.21%[0m) [0.41% of initial]
[Iter 3120] Gaussian 0 vs 1:
  Original Loss: 0.0011599
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011599 (Pseudo: 0.00%)
[Iter 3120] Gaussian 1 vs 0:
  Original Loss: 0.0012107
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012107 (Pseudo: 0.00%)
[Iter 3130/20000] Loss: 0.0008298 (Best: 0.0006523 @iter2999) ([92mâ†“19.37%[0m) [0.33% of initial]
[Iter 3130] Gaussian 0 vs 1:
  Original Loss: 0.0007245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007245 (Pseudo: 0.00%)
[Iter 3130] Gaussian 1 vs 0:
  Original Loss: 0.0007683
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007683 (Pseudo: 0.00%)
[Iter 3140/20000] Loss: 0.0007993 (Best: 0.0006523 @iter2999) ([92mâ†“3.67%[0m) [0.32% of initial]
[Iter 3140] Gaussian 0 vs 1:
  Original Loss: 0.0008534
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008534 (Pseudo: 0.00%)
[Iter 3140] Gaussian 1 vs 0:
  Original Loss: 0.0009095
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009095 (Pseudo: 0.00%)
[Iter 3150/20000] Loss: 0.0008259 (Best: 0.0006523 @iter2999) ([91mâ†‘3.32%[0m) [0.33% of initial]
[Iter 3150] Gaussian 0 vs 1:
  Original Loss: 0.0009833
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009833 (Pseudo: 0.00%)
[Iter 3150] Gaussian 1 vs 0:
  Original Loss: 0.0010638
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010638 (Pseudo: 0.00%)
[Iter 3160/20000] Loss: 0.0007774 (Best: 0.0006523 @iter2999) ([92mâ†“5.87%[0m) [0.31% of initial]
[Iter 3160] Gaussian 0 vs 1:
  Original Loss: 0.0006655
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006655 (Pseudo: 0.00%)
[Iter 3160] Gaussian 1 vs 0:
  Original Loss: 0.0006967
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006967 (Pseudo: 0.00%)
[Iter 3170/20000] Loss: 0.0007989 (Best: 0.0006523 @iter2999) ([91mâ†‘2.77%[0m) [0.32% of initial]
[Iter 3170] Gaussian 0 vs 1:
  Original Loss: 0.0008361
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008361 (Pseudo: 0.00%)
[Iter 3170] Gaussian 1 vs 0:
  Original Loss: 0.0009053
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009053 (Pseudo: 0.00%)
[Iter 3180/20000] Loss: 0.0008501 (Best: 0.0006523 @iter2999) ([91mâ†‘6.41%[0m) [0.34% of initial]
[Iter 3180] Gaussian 0 vs 1:
  Original Loss: 0.0008853
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008853 (Pseudo: 0.00%)
[Iter 3180] Gaussian 1 vs 0:
  Original Loss: 0.0009093
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009093 (Pseudo: 0.00%)
[Iter 3190/20000] Loss: 0.0008299 (Best: 0.0006523 @iter2999) ([92mâ†“2.38%[0m) [0.33% of initial]
[Iter 3190] Gaussian 0 vs 1:
  Original Loss: 0.0007891
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007891 (Pseudo: 0.00%)
[Iter 3190] Gaussian 1 vs 0:
  Original Loss: 0.0007642
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007642 (Pseudo: 0.00%)
Iter:3199, L1 loss=0.0007921, Total loss=0.0007481, Time:17
[Iter 3200/20000] Loss: 0.0007863 (Best: 0.0006254 @iter3196) ([92mâ†“5.25%[0m) [0.31% of initial]
[Iter 3200] Gaussian 0 vs 1:
  Original Loss: 0.0008014
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008014 (Pseudo: 0.00%)
[Iter 3200] Gaussian 1 vs 0:
  Original Loss: 0.0008506
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008506 (Pseudo: 0.00%)
[Iter 3210/20000] Loss: 0.0049806 (Best: 0.0006254 @iter3196) ([91mâ†‘533.39%[0m) [1.98% of initial]
[Iter 3210] Gaussian 0 vs 1:
  Original Loss: 0.0046798
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0046798 (Pseudo: 0.00%)
[Iter 3210] Gaussian 1 vs 0:
  Original Loss: 0.0051557
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0051557 (Pseudo: 0.00%)
[Iter 3220/20000] Loss: 0.0026567 (Best: 0.0006254 @iter3196) ([92mâ†“46.66%[0m) [1.06% of initial]
[Iter 3220] Gaussian 0 vs 1:
  Original Loss: 0.0023684
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023684 (Pseudo: 0.00%)
[Iter 3220] Gaussian 1 vs 0:
  Original Loss: 0.0025743
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0025743 (Pseudo: 0.00%)
[Iter 3230/20000] Loss: 0.0016267 (Best: 0.0006254 @iter3196) ([92mâ†“38.77%[0m) [0.65% of initial]
[Iter 3230] Gaussian 0 vs 1:
  Original Loss: 0.0016169
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016169 (Pseudo: 0.00%)
[Iter 3230] Gaussian 1 vs 0:
  Original Loss: 0.0016387
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016387 (Pseudo: 0.00%)
[Iter 3240/20000] Loss: 0.0014270 (Best: 0.0006254 @iter3196) ([92mâ†“12.27%[0m) [0.57% of initial]
[Iter 3240] Gaussian 0 vs 1:
  Original Loss: 0.0014442
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014442 (Pseudo: 0.00%)
[Iter 3240] Gaussian 1 vs 0:
  Original Loss: 0.0015464
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015464 (Pseudo: 0.00%)
[Iter 3250/20000] Loss: 0.0010709 (Best: 0.0006254 @iter3196) ([92mâ†“24.95%[0m) [0.43% of initial]
[Iter 3250] Gaussian 0 vs 1:
  Original Loss: 0.0009927
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009927 (Pseudo: 0.00%)
[Iter 3250] Gaussian 1 vs 0:
  Original Loss: 0.0010079
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010079 (Pseudo: 0.00%)
[Iter 3260/20000] Loss: 0.0009502 (Best: 0.0006254 @iter3196) ([92mâ†“11.27%[0m) [0.38% of initial]
[Iter 3260] Gaussian 0 vs 1:
  Original Loss: 0.0008659
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008659 (Pseudo: 0.00%)
[Iter 3260] Gaussian 1 vs 0:
  Original Loss: 0.0008868
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008868 (Pseudo: 0.00%)
[Iter 3270/20000] Loss: 0.0009700 (Best: 0.0006254 @iter3196) ([91mâ†‘2.09%[0m) [0.39% of initial]
[Iter 3270] Gaussian 0 vs 1:
  Original Loss: 0.0011422
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011422 (Pseudo: 0.00%)
[Iter 3270] Gaussian 1 vs 0:
  Original Loss: 0.0012094
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012094 (Pseudo: 0.00%)
[Iter 3280/20000] Loss: 0.0010298 (Best: 0.0006254 @iter3196) ([91mâ†‘6.16%[0m) [0.41% of initial]
[Iter 3280] Gaussian 0 vs 1:
  Original Loss: 0.0009837
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009837 (Pseudo: 0.00%)
[Iter 3280] Gaussian 1 vs 0:
  Original Loss: 0.0009744
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009744 (Pseudo: 0.00%)
[Iter 3290/20000] Loss: 0.0007705 (Best: 0.0006254 @iter3196) ([92mâ†“25.17%[0m) [0.31% of initial]
[Iter 3290] Gaussian 0 vs 1:
  Original Loss: 0.0007109
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007109 (Pseudo: 0.00%)
[Iter 3290] Gaussian 1 vs 0:
  Original Loss: 0.0007140
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007140 (Pseudo: 0.00%)
Iter:3299, L1 loss=0.00122, Total loss=0.001178, Time:18
[Iter 3300/20000] Loss: 0.0010454 (Best: 0.0006254 @iter3196) ([91mâ†‘35.68%[0m) [0.42% of initial]
[Iter 3300] Gaussian 0 vs 1:
  Original Loss: 0.0010015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010015 (Pseudo: 0.00%)
[Iter 3300] Gaussian 1 vs 0:
  Original Loss: 0.0010017
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010017 (Pseudo: 0.00%)
[Iter 3310/20000] Loss: 0.0008255 (Best: 0.0006254 @iter3196) ([92mâ†“21.03%[0m) [0.33% of initial]
[Iter 3310] Gaussian 0 vs 1:
  Original Loss: 0.0007516
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007516 (Pseudo: 0.00%)
[Iter 3310] Gaussian 1 vs 0:
  Original Loss: 0.0007175
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007175 (Pseudo: 0.00%)
[Iter 3320/20000] Loss: 0.0009261 (Best: 0.0006254 @iter3196) ([91mâ†‘12.18%[0m) [0.37% of initial]
[Iter 3320] Gaussian 0 vs 1:
  Original Loss: 0.0009551
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009551 (Pseudo: 0.00%)
[Iter 3320] Gaussian 1 vs 0:
  Original Loss: 0.0010159
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010159 (Pseudo: 0.00%)
[Iter 3330/20000] Loss: 0.0009646 (Best: 0.0006254 @iter3196) ([91mâ†‘4.15%[0m) [0.38% of initial]
[Iter 3330] Gaussian 0 vs 1:
  Original Loss: 0.0010594
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010594 (Pseudo: 0.00%)
[Iter 3330] Gaussian 1 vs 0:
  Original Loss: 0.0011511
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011511 (Pseudo: 0.00%)
[Iter 3340/20000] Loss: 0.0010185 (Best: 0.0006254 @iter3196) ([91mâ†‘5.59%[0m) [0.40% of initial]
[Iter 3340] Gaussian 0 vs 1:
  Original Loss: 0.0009773
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009773 (Pseudo: 0.00%)
[Iter 3340] Gaussian 1 vs 0:
  Original Loss: 0.0010661
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010661 (Pseudo: 0.00%)
[Iter 3350/20000] Loss: 0.0008340 (Best: 0.0006254 @iter3196) ([92mâ†“18.12%[0m) [0.33% of initial]
[Iter 3350] Gaussian 0 vs 1:
  Original Loss: 0.0008964
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008964 (Pseudo: 0.00%)
[Iter 3350] Gaussian 1 vs 0:
  Original Loss: 0.0009398
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009398 (Pseudo: 0.00%)
[Iter 3360/20000] Loss: 0.0010132 (Best: 0.0006254 @iter3196) ([91mâ†‘21.49%[0m) [0.40% of initial]
[Iter 3360] Gaussian 0 vs 1:
  Original Loss: 0.0011661
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011661 (Pseudo: 0.00%)
[Iter 3360] Gaussian 1 vs 0:
  Original Loss: 0.0012574
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012574 (Pseudo: 0.00%)
[Iter 3370/20000] Loss: 0.0007542 (Best: 0.0006254 @iter3196) ([92mâ†“25.56%[0m) [0.30% of initial]
[Iter 3370] Gaussian 0 vs 1:
  Original Loss: 0.0006464
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006464 (Pseudo: 0.00%)
[Iter 3370] Gaussian 1 vs 0:
  Original Loss: 0.0006811
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006811 (Pseudo: 0.00%)
[Iter 3380/20000] Loss: 0.0007331 (Best: 0.0006254 @iter3196) ([92mâ†“2.81%[0m) [0.29% of initial]
[Iter 3380] Gaussian 0 vs 1:
  Original Loss: 0.0007587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007587 (Pseudo: 0.00%)
[Iter 3380] Gaussian 1 vs 0:
  Original Loss: 0.0008515
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008515 (Pseudo: 0.00%)
[Iter 3390/20000] Loss: 0.0009832 (Best: 0.0006254 @iter3196) ([91mâ†‘34.12%[0m) [0.39% of initial]
[Iter 3390] Gaussian 0 vs 1:
  Original Loss: 0.0009168
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009168 (Pseudo: 0.00%)
[Iter 3390] Gaussian 1 vs 0:
  Original Loss: 0.0008658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008658 (Pseudo: 0.00%)
Iter:3399, L1 loss=0.001184, Total loss=0.001165, Time:18
[Iter 3400/20000] Loss: 0.0010055 (Best: 0.0006254 @iter3196) ([91mâ†‘2.26%[0m) [0.40% of initial]
[Iter 3400] Gaussian 0 vs 1:
  Original Loss: 0.0008602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008602 (Pseudo: 0.00%)
[Iter 3400] Gaussian 1 vs 0:
  Original Loss: 0.0008400
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008400 (Pseudo: 0.00%)
[Iter 3410/20000] Loss: 0.0045627 (Best: 0.0006254 @iter3196) ([91mâ†‘353.79%[0m) [1.81% of initial]
[Iter 3410] Gaussian 0 vs 1:
  Original Loss: 0.0041822
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0041822 (Pseudo: 0.00%)
[Iter 3410] Gaussian 1 vs 0:
  Original Loss: 0.0038520
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0038520 (Pseudo: 0.00%)
[Iter 3420/20000] Loss: 0.0023096 (Best: 0.0006254 @iter3196) ([92mâ†“49.38%[0m) [0.92% of initial]
[Iter 3420] Gaussian 0 vs 1:
  Original Loss: 0.0020035
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0020035 (Pseudo: 0.00%)
[Iter 3420] Gaussian 1 vs 0:
  Original Loss: 0.0023234
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023234 (Pseudo: 0.00%)
[Iter 3430/20000] Loss: 0.0014949 (Best: 0.0006254 @iter3196) ([92mâ†“35.27%[0m) [0.59% of initial]
[Iter 3430] Gaussian 0 vs 1:
  Original Loss: 0.0013054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013054 (Pseudo: 0.00%)
[Iter 3430] Gaussian 1 vs 0:
  Original Loss: 0.0013495
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013495 (Pseudo: 0.00%)
[Iter 3440/20000] Loss: 0.0012414 (Best: 0.0006254 @iter3196) ([92mâ†“16.96%[0m) [0.49% of initial]
[Iter 3440] Gaussian 0 vs 1:
  Original Loss: 0.0011336
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011336 (Pseudo: 0.00%)
[Iter 3440] Gaussian 1 vs 0:
  Original Loss: 0.0012015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012015 (Pseudo: 0.00%)
[Iter 3450/20000] Loss: 0.0011392 (Best: 0.0006254 @iter3196) ([92mâ†“8.23%[0m) [0.45% of initial]
[Iter 3450] Gaussian 0 vs 1:
  Original Loss: 0.0012144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012144 (Pseudo: 0.00%)
[Iter 3450] Gaussian 1 vs 0:
  Original Loss: 0.0012491
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012491 (Pseudo: 0.00%)
[Iter 3460/20000] Loss: 0.0010240 (Best: 0.0006254 @iter3196) ([92mâ†“10.12%[0m) [0.41% of initial]
[Iter 3460] Gaussian 0 vs 1:
  Original Loss: 0.0009443
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009443 (Pseudo: 0.00%)
[Iter 3460] Gaussian 1 vs 0:
  Original Loss: 0.0010317
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010317 (Pseudo: 0.00%)
[Iter 3470/20000] Loss: 0.0009663 (Best: 0.0006254 @iter3196) ([92mâ†“5.63%[0m) [0.38% of initial]
[Iter 3470] Gaussian 0 vs 1:
  Original Loss: 0.0009094
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009094 (Pseudo: 0.00%)
[Iter 3470] Gaussian 1 vs 0:
  Original Loss: 0.0009271
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009271 (Pseudo: 0.00%)
[Iter 3480/20000] Loss: 0.0008994 (Best: 0.0006254 @iter3196) ([92mâ†“6.92%[0m) [0.36% of initial]
[Iter 3480] Gaussian 0 vs 1:
  Original Loss: 0.0009657
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009657 (Pseudo: 0.00%)
[Iter 3480] Gaussian 1 vs 0:
  Original Loss: 0.0009375
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009375 (Pseudo: 0.00%)
[Iter 3490/20000] Loss: 0.0008619 (Best: 0.0006254 @iter3196) ([92mâ†“4.17%[0m) [0.34% of initial]
[Iter 3490] Gaussian 0 vs 1:
  Original Loss: 0.0009015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009015 (Pseudo: 0.00%)
[Iter 3490] Gaussian 1 vs 0:
  Original Loss: 0.0008519
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008519 (Pseudo: 0.00%)
Iter:3499, L1 loss=0.0006636, Total loss=0.0006071, Time:18
[Iter 3500/20000] Loss: 0.0006592 (Best: 0.0006071 @iter3499) ([92mâ†“23.51%[0m) [0.26% of initial]
[Iter 3500] Gaussian 0 vs 1:
  Original Loss: 0.0006228
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006228 (Pseudo: 0.00%)
[Iter 3500] Gaussian 1 vs 0:
  Original Loss: 0.0006255
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006255 (Pseudo: 0.00%)
[Iter 3510/20000] Loss: 0.0007230 (Best: 0.0006071 @iter3499) ([91mâ†‘9.67%[0m) [0.29% of initial]
[Iter 3510] Gaussian 0 vs 1:
  Original Loss: 0.0006634
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006634 (Pseudo: 0.00%)
[Iter 3510] Gaussian 1 vs 0:
  Original Loss: 0.0006789
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006789 (Pseudo: 0.00%)
[Iter 3520/20000] Loss: 0.0007205 (Best: 0.0005927 @iter3517) ([92mâ†“0.33%[0m) [0.29% of initial]
[Iter 3520] Gaussian 0 vs 1:
  Original Loss: 0.0007404
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007404 (Pseudo: 0.00%)
[Iter 3520] Gaussian 1 vs 0:
  Original Loss: 0.0007957
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007957 (Pseudo: 0.00%)
[Iter 3530/20000] Loss: 0.0007630 (Best: 0.0005927 @iter3517) ([91mâ†‘5.90%[0m) [0.30% of initial]
[Iter 3530] Gaussian 0 vs 1:
  Original Loss: 0.0008405
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008405 (Pseudo: 0.00%)
[Iter 3530] Gaussian 1 vs 0:
  Original Loss: 0.0009009
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009009 (Pseudo: 0.00%)
[Iter 3540/20000] Loss: 0.0010441 (Best: 0.0005927 @iter3517) ([91mâ†‘36.83%[0m) [0.41% of initial]
[Iter 3540] Gaussian 0 vs 1:
  Original Loss: 0.0011651
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011651 (Pseudo: 0.00%)
[Iter 3540] Gaussian 1 vs 0:
  Original Loss: 0.0012267
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012267 (Pseudo: 0.00%)
[Iter 3550/20000] Loss: 0.0010043 (Best: 0.0005927 @iter3517) ([92mâ†“3.81%[0m) [0.40% of initial]
[Iter 3550] Gaussian 0 vs 1:
  Original Loss: 0.0009668
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009668 (Pseudo: 0.00%)
[Iter 3550] Gaussian 1 vs 0:
  Original Loss: 0.0009232
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009232 (Pseudo: 0.00%)
[Iter 3560/20000] Loss: 0.0009004 (Best: 0.0005927 @iter3517) ([92mâ†“10.34%[0m) [0.36% of initial]
[Iter 3560] Gaussian 0 vs 1:
  Original Loss: 0.0008940
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008940 (Pseudo: 0.00%)
[Iter 3560] Gaussian 1 vs 0:
  Original Loss: 0.0008804
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008804 (Pseudo: 0.00%)
[Iter 3570/20000] Loss: 0.0009132 (Best: 0.0005927 @iter3517) ([91mâ†‘1.42%[0m) [0.36% of initial]
[Iter 3570] Gaussian 0 vs 1:
  Original Loss: 0.0011207
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011207 (Pseudo: 0.00%)
[Iter 3570] Gaussian 1 vs 0:
  Original Loss: 0.0011686
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011686 (Pseudo: 0.00%)
[Iter 3580/20000] Loss: 0.0007222 (Best: 0.0005927 @iter3517) ([92mâ†“20.92%[0m) [0.29% of initial]
[Iter 3580] Gaussian 0 vs 1:
  Original Loss: 0.0006439
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006439 (Pseudo: 0.00%)
[Iter 3580] Gaussian 1 vs 0:
  Original Loss: 0.0006277
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006277 (Pseudo: 0.00%)
[Iter 3590/20000] Loss: 0.0007093 (Best: 0.0005927 @iter3517) ([92mâ†“1.78%[0m) [0.28% of initial]
[Iter 3590] Gaussian 0 vs 1:
  Original Loss: 0.0006760
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006760 (Pseudo: 0.00%)
[Iter 3590] Gaussian 1 vs 0:
  Original Loss: 0.0006701
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006701 (Pseudo: 0.00%)
Iter:3599, L1 loss=0.0006328, Total loss=0.0005842, Time:18
[Iter 3600/20000] Loss: 0.0006901 (Best: 0.0005735 @iter3598) ([92mâ†“2.70%[0m) [0.27% of initial]
[Iter 3600] Gaussian 0 vs 1:
  Original Loss: 0.0008013
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008013 (Pseudo: 0.00%)
[Iter 3600] Gaussian 1 vs 0:
  Original Loss: 0.0008138
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008138 (Pseudo: 0.00%)
[Iter 3610/20000] Loss: 0.0046911 (Best: 0.0005735 @iter3598) ([91mâ†‘579.72%[0m) [1.86% of initial]
[Iter 3610] Gaussian 0 vs 1:
  Original Loss: 0.0036785
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0036785 (Pseudo: 0.00%)
[Iter 3610] Gaussian 1 vs 0:
  Original Loss: 0.0040060
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0040060 (Pseudo: 0.00%)
[Iter 3620/20000] Loss: 0.0026481 (Best: 0.0005735 @iter3598) ([92mâ†“43.55%[0m) [1.05% of initial]
[Iter 3620] Gaussian 0 vs 1:
  Original Loss: 0.0024166
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0024166 (Pseudo: 0.00%)
[Iter 3620] Gaussian 1 vs 0:
  Original Loss: 0.0023905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0023905 (Pseudo: 0.00%)
[Iter 3630/20000] Loss: 0.0015306 (Best: 0.0005735 @iter3598) ([92mâ†“42.20%[0m) [0.61% of initial]
[Iter 3630] Gaussian 0 vs 1:
  Original Loss: 0.0014425
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014425 (Pseudo: 0.00%)
[Iter 3630] Gaussian 1 vs 0:
  Original Loss: 0.0015558
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015558 (Pseudo: 0.00%)
[Iter 3640/20000] Loss: 0.0011170 (Best: 0.0005735 @iter3598) ([92mâ†“27.02%[0m) [0.44% of initial]
[Iter 3640] Gaussian 0 vs 1:
  Original Loss: 0.0010923
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010923 (Pseudo: 0.00%)
[Iter 3640] Gaussian 1 vs 0:
  Original Loss: 0.0011783
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011783 (Pseudo: 0.00%)
[Iter 3650/20000] Loss: 0.0011041 (Best: 0.0005735 @iter3598) ([92mâ†“1.16%[0m) [0.44% of initial]
[Iter 3650] Gaussian 0 vs 1:
  Original Loss: 0.0011730
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011730 (Pseudo: 0.00%)
[Iter 3650] Gaussian 1 vs 0:
  Original Loss: 0.0012402
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012402 (Pseudo: 0.00%)
[Iter 3660/20000] Loss: 0.0008812 (Best: 0.0005735 @iter3598) ([92mâ†“20.19%[0m) [0.35% of initial]
[Iter 3660] Gaussian 0 vs 1:
  Original Loss: 0.0009422
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009422 (Pseudo: 0.00%)
[Iter 3660] Gaussian 1 vs 0:
  Original Loss: 0.0009502
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009502 (Pseudo: 0.00%)
[Iter 3670/20000] Loss: 0.0007818 (Best: 0.0005735 @iter3598) ([92mâ†“11.27%[0m) [0.31% of initial]
[Iter 3670] Gaussian 0 vs 1:
  Original Loss: 0.0007069
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007069 (Pseudo: 0.00%)
[Iter 3670] Gaussian 1 vs 0:
  Original Loss: 0.0007167
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007167 (Pseudo: 0.00%)
[Iter 3680/20000] Loss: 0.0009581 (Best: 0.0005735 @iter3598) ([91mâ†‘22.54%[0m) [0.38% of initial]
[Iter 3680] Gaussian 0 vs 1:
  Original Loss: 0.0010227
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010227 (Pseudo: 0.00%)
[Iter 3680] Gaussian 1 vs 0:
  Original Loss: 0.0010757
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010757 (Pseudo: 0.00%)
[Iter 3690/20000] Loss: 0.0012407 (Best: 0.0005735 @iter3598) ([91mâ†‘29.50%[0m) [0.49% of initial]
[Iter 3690] Gaussian 0 vs 1:
  Original Loss: 0.0016362
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016362 (Pseudo: 0.00%)
[Iter 3690] Gaussian 1 vs 0:
  Original Loss: 0.0014205
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014205 (Pseudo: 0.00%)
Iter:3699, L1 loss=0.001052, Total loss=0.000964, Time:19
[Iter 3700/20000] Loss: 0.0010279 (Best: 0.0005735 @iter3598) ([92mâ†“17.15%[0m) [0.41% of initial]
[Iter 3700] Gaussian 0 vs 1:
  Original Loss: 0.0010231
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010231 (Pseudo: 0.00%)
[Iter 3700] Gaussian 1 vs 0:
  Original Loss: 0.0009627
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009627 (Pseudo: 0.00%)
[Iter 3710/20000] Loss: 0.0008029 (Best: 0.0005735 @iter3598) ([92mâ†“21.88%[0m) [0.32% of initial]
[Iter 3710] Gaussian 0 vs 1:
  Original Loss: 0.0008168
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008168 (Pseudo: 0.00%)
[Iter 3710] Gaussian 1 vs 0:
  Original Loss: 0.0008466
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008466 (Pseudo: 0.00%)
[Iter 3720/20000] Loss: 0.0008543 (Best: 0.0005735 @iter3598) ([91mâ†‘6.39%[0m) [0.34% of initial]
[Iter 3720] Gaussian 0 vs 1:
  Original Loss: 0.0007890
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007890 (Pseudo: 0.00%)
[Iter 3720] Gaussian 1 vs 0:
  Original Loss: 0.0007995
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007995 (Pseudo: 0.00%)
[Iter 3730/20000] Loss: 0.0007381 (Best: 0.0005735 @iter3598) ([92mâ†“13.59%[0m) [0.29% of initial]
[Iter 3730] Gaussian 0 vs 1:
  Original Loss: 0.0006716
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006716 (Pseudo: 0.00%)
[Iter 3730] Gaussian 1 vs 0:
  Original Loss: 0.0006608
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006608 (Pseudo: 0.00%)
[Iter 3740/20000] Loss: 0.0007469 (Best: 0.0005735 @iter3598) ([91mâ†‘1.19%[0m) [0.30% of initial]
[Iter 3740] Gaussian 0 vs 1:
  Original Loss: 0.0008076
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008076 (Pseudo: 0.00%)
[Iter 3740] Gaussian 1 vs 0:
  Original Loss: 0.0008363
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008363 (Pseudo: 0.00%)
[Iter 3750/20000] Loss: 0.0007782 (Best: 0.0005735 @iter3598) ([91mâ†‘4.18%[0m) [0.31% of initial]
[Iter 3750] Gaussian 0 vs 1:
  Original Loss: 0.0008450
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008450 (Pseudo: 0.00%)
[Iter 3750] Gaussian 1 vs 0:
  Original Loss: 0.0008558
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008558 (Pseudo: 0.00%)
[Iter 3760/20000] Loss: 0.0007585 (Best: 0.0005735 @iter3598) ([92mâ†“2.53%[0m) [0.30% of initial]
[Iter 3760] Gaussian 0 vs 1:
  Original Loss: 0.0007587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007587 (Pseudo: 0.00%)
[Iter 3760] Gaussian 1 vs 0:
  Original Loss: 0.0007966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007966 (Pseudo: 0.00%)
[Iter 3770/20000] Loss: 0.0007261 (Best: 0.0005735 @iter3598) ([92mâ†“4.27%[0m) [0.29% of initial]
[Iter 3770] Gaussian 0 vs 1:
  Original Loss: 0.0006828
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006828 (Pseudo: 0.00%)
[Iter 3770] Gaussian 1 vs 0:
  Original Loss: 0.0006987
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006987 (Pseudo: 0.00%)
[Iter 3780/20000] Loss: 0.0006760 (Best: 0.0005296 @iter3775) ([92mâ†“6.91%[0m) [0.27% of initial]
[Iter 3780] Gaussian 0 vs 1:
  Original Loss: 0.0007353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007353 (Pseudo: 0.00%)
[Iter 3780] Gaussian 1 vs 0:
  Original Loss: 0.0007602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007602 (Pseudo: 0.00%)
[Iter 3790/20000] Loss: 0.0005558 (Best: 0.0004960 @iter3790) ([92mâ†“17.77%[0m) [0.22% of initial]
[Iter 3790] Gaussian 0 vs 1:
  Original Loss: 0.0004960
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004960 (Pseudo: 0.00%)
[Iter 3790] Gaussian 1 vs 0:
  Original Loss: 0.0005037
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005037 (Pseudo: 0.00%)
Iter:3799, L1 loss=0.0007244, Total loss=0.0006896, Time:19
[Iter 3800/20000] Loss: 0.0006981 (Best: 0.0004960 @iter3790) ([91mâ†‘25.60%[0m) [0.28% of initial]
[Iter 3800] Gaussian 0 vs 1:
  Original Loss: 0.0006585
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006585 (Pseudo: 0.00%)
[Iter 3800] Gaussian 1 vs 0:
  Original Loss: 0.0006596
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006596 (Pseudo: 0.00%)
[Iter 3810/20000] Loss: 0.0050216 (Best: 0.0004960 @iter3790) ([91mâ†‘619.32%[0m) [2.00% of initial]
[Iter 3810] Gaussian 0 vs 1:
  Original Loss: 0.0055907
  Pseudo Loss: 0.0012824 (22.94% of original)
  Total Loss: 0.0068731 (Pseudo: 18.66%)
[Iter 3810] Gaussian 1 vs 0:
  Original Loss: 0.0043491
  Pseudo Loss: 0.0012824 (29.49% of original)
  Total Loss: 0.0056315 (Pseudo: 22.77%)
[Iter 3810] Pseudo Loss: 0.0018661
[Iter 3820/20000] Loss: 0.0024094 (Best: 0.0004960 @iter3790) ([92mâ†“52.02%[0m) [0.96% of initial]
[Iter 3820] Gaussian 0 vs 1:
  Original Loss: 0.0018961
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018961 (Pseudo: 0.00%)
[Iter 3820] Gaussian 1 vs 0:
  Original Loss: 0.0018700
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018700 (Pseudo: 0.00%)
[Iter 3830/20000] Loss: 0.0013805 (Best: 0.0004960 @iter3790) ([92mâ†“42.70%[0m) [0.55% of initial]
[Iter 3830] Gaussian 0 vs 1:
  Original Loss: 0.0013333
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013333 (Pseudo: 0.00%)
[Iter 3830] Gaussian 1 vs 0:
  Original Loss: 0.0013359
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013359 (Pseudo: 0.00%)
[Iter 3840/20000] Loss: 0.0013238 (Best: 0.0004960 @iter3790) ([92mâ†“4.11%[0m) [0.53% of initial]
[Iter 3840] Gaussian 0 vs 1:
  Original Loss: 0.0015472
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015472 (Pseudo: 0.00%)
[Iter 3840] Gaussian 1 vs 0:
  Original Loss: 0.0015910
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0015910 (Pseudo: 0.00%)
[Iter 3850/20000] Loss: 0.0009814 (Best: 0.0004960 @iter3790) ([92mâ†“25.86%[0m) [0.39% of initial]
[Iter 3850] Gaussian 0 vs 1:
  Original Loss: 0.0008981
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008981 (Pseudo: 0.00%)
[Iter 3850] Gaussian 1 vs 0:
  Original Loss: 0.0009928
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009928 (Pseudo: 0.00%)
[Iter 3860/20000] Loss: 0.0009118 (Best: 0.0004960 @iter3790) ([92mâ†“7.09%[0m) [0.36% of initial]
[Iter 3860] Gaussian 0 vs 1:
  Original Loss: 0.0008216
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008216 (Pseudo: 0.00%)
[Iter 3860] Gaussian 1 vs 0:
  Original Loss: 0.0008363
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008363 (Pseudo: 0.00%)
[Iter 3870/20000] Loss: 0.0007295 (Best: 0.0004960 @iter3790) ([92mâ†“19.99%[0m) [0.29% of initial]
[Iter 3870] Gaussian 0 vs 1:
  Original Loss: 0.0006749
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006749 (Pseudo: 0.00%)
[Iter 3870] Gaussian 1 vs 0:
  Original Loss: 0.0006944
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006944 (Pseudo: 0.00%)
[Iter 3880/20000] Loss: 0.0007598 (Best: 0.0004960 @iter3790) ([91mâ†‘4.15%[0m) [0.30% of initial]
[Iter 3880] Gaussian 0 vs 1:
  Original Loss: 0.0007800
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007800 (Pseudo: 0.00%)
[Iter 3880] Gaussian 1 vs 0:
  Original Loss: 0.0008151
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008151 (Pseudo: 0.00%)
[Iter 3890/20000] Loss: 0.0006401 (Best: 0.0004960 @iter3790) ([92mâ†“15.75%[0m) [0.25% of initial]
[Iter 3890] Gaussian 0 vs 1:
  Original Loss: 0.0006211
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006211 (Pseudo: 0.00%)
[Iter 3890] Gaussian 1 vs 0:
  Original Loss: 0.0006304
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006304 (Pseudo: 0.00%)
Iter:3899, L1 loss=0.0007058, Total loss=0.0006656, Time:20
[Iter 3900/20000] Loss: 0.0006498 (Best: 0.0004960 @iter3790) ([91mâ†‘1.51%[0m) [0.26% of initial]
[Iter 3900] Gaussian 0 vs 1:
  Original Loss: 0.0007110
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007110 (Pseudo: 0.00%)
[Iter 3900] Gaussian 1 vs 0:
  Original Loss: 0.0007462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007462 (Pseudo: 0.00%)
[Iter 3910/20000] Loss: 0.0007706 (Best: 0.0004960 @iter3790) ([91mâ†‘18.60%[0m) [0.31% of initial]
[Iter 3910] Gaussian 0 vs 1:
  Original Loss: 0.0007513
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007513 (Pseudo: 0.00%)
[Iter 3910] Gaussian 1 vs 0:
  Original Loss: 0.0007657
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007657 (Pseudo: 0.00%)
[Iter 3920/20000] Loss: 0.0007837 (Best: 0.0004960 @iter3790) ([91mâ†‘1.69%[0m) [0.31% of initial]
[Iter 3920] Gaussian 0 vs 1:
  Original Loss: 0.0007686
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007686 (Pseudo: 0.00%)
[Iter 3920] Gaussian 1 vs 0:
  Original Loss: 0.0008185
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008185 (Pseudo: 0.00%)
[Iter 3930/20000] Loss: 0.0007636 (Best: 0.0004960 @iter3790) ([92mâ†“2.57%[0m) [0.30% of initial]
[Iter 3930] Gaussian 0 vs 1:
  Original Loss: 0.0008273
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008273 (Pseudo: 0.00%)
[Iter 3930] Gaussian 1 vs 0:
  Original Loss: 0.0008852
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008852 (Pseudo: 0.00%)
[Iter 3940/20000] Loss: 0.0006308 (Best: 0.0004960 @iter3790) ([92mâ†“17.39%[0m) [0.25% of initial]
[Iter 3940] Gaussian 0 vs 1:
  Original Loss: 0.0005677
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005677 (Pseudo: 0.00%)
[Iter 3940] Gaussian 1 vs 0:
  Original Loss: 0.0005828
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005828 (Pseudo: 0.00%)
[Iter 3950/20000] Loss: 0.0007082 (Best: 0.0004960 @iter3790) ([91mâ†‘12.27%[0m) [0.28% of initial]
[Iter 3950] Gaussian 0 vs 1:
  Original Loss: 0.0007613
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007613 (Pseudo: 0.00%)
[Iter 3950] Gaussian 1 vs 0:
  Original Loss: 0.0007881
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007881 (Pseudo: 0.00%)
[Iter 3960/20000] Loss: 0.0006954 (Best: 0.0004960 @iter3790) ([92mâ†“1.80%[0m) [0.28% of initial]
[Iter 3960] Gaussian 0 vs 1:
  Original Loss: 0.0006245
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006245 (Pseudo: 0.00%)
[Iter 3960] Gaussian 1 vs 0:
  Original Loss: 0.0006529
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006529 (Pseudo: 0.00%)
[Iter 3970/20000] Loss: 0.0006448 (Best: 0.0004960 @iter3790) ([92mâ†“7.28%[0m) [0.26% of initial]
[Iter 3970] Gaussian 0 vs 1:
  Original Loss: 0.0006091
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006091 (Pseudo: 0.00%)
[Iter 3970] Gaussian 1 vs 0:
  Original Loss: 0.0006261
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006261 (Pseudo: 0.00%)
[Iter 3980/20000] Loss: 0.0008916 (Best: 0.0004960 @iter3790) ([91mâ†‘38.28%[0m) [0.35% of initial]
[Iter 3980] Gaussian 0 vs 1:
  Original Loss: 0.0011151
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011151 (Pseudo: 0.00%)
[Iter 3980] Gaussian 1 vs 0:
  Original Loss: 0.0011227
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011227 (Pseudo: 0.00%)
[Iter 3990/20000] Loss: 0.0006917 (Best: 0.0004960 @iter3790) ([92mâ†“22.42%[0m) [0.27% of initial]
[Iter 3990] Gaussian 0 vs 1:
  Original Loss: 0.0007158
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007158 (Pseudo: 0.00%)
[Iter 3990] Gaussian 1 vs 0:
  Original Loss: 0.0007824
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007824 (Pseudo: 0.00%)
Iter:3999, L1 loss=0.0008329, Total loss=0.000744, Time:19
[Iter 4000/20000] Loss: 0.0006823 (Best: 0.0004960 @iter3790) ([92mâ†“1.37%[0m) [0.27% of initial]
[Iter 4000] Gaussian 0 vs 1:
  Original Loss: 0.0006674
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006674 (Pseudo: 0.00%)
[Iter 4000] Gaussian 1 vs 0:
  Original Loss: 0.0007162
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007162 (Pseudo: 0.00%)
[Iter 4010/20000] Loss: 0.0830499 (Best: 0.0004960 @iter3790) ([91mâ†‘12072.75%[0m) [32.99% of initial]
[Iter 4010] Gaussian 0 vs 1:
  Original Loss: 0.0628251
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0628251 (Pseudo: 0.00%)
[Iter 4010] Gaussian 1 vs 0:
  Original Loss: 0.0669051
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0669051 (Pseudo: 0.00%)
[Iter 4020/20000] Loss: 0.0176885 (Best: 0.0004960 @iter3790) ([92mâ†“78.70%[0m) [7.03% of initial]
[Iter 4020] Gaussian 0 vs 1:
  Original Loss: 0.0171846
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0171846 (Pseudo: 0.00%)
[Iter 4020] Gaussian 1 vs 0:
  Original Loss: 0.0180868
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0180868 (Pseudo: 0.00%)
[Iter 4030/20000] Loss: 0.0079570 (Best: 0.0004960 @iter3790) ([92mâ†“55.02%[0m) [3.16% of initial]
[Iter 4030] Gaussian 0 vs 1:
  Original Loss: 0.0067906
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0067906 (Pseudo: 0.00%)
[Iter 4030] Gaussian 1 vs 0:
  Original Loss: 0.0072487
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0072487 (Pseudo: 0.00%)
[Iter 4040/20000] Loss: 0.0043407 (Best: 0.0004960 @iter3790) ([92mâ†“45.45%[0m) [1.72% of initial]
[Iter 4040] Gaussian 0 vs 1:
  Original Loss: 0.0042812
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0042812 (Pseudo: 0.00%)
[Iter 4040] Gaussian 1 vs 0:
  Original Loss: 0.0044462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0044462 (Pseudo: 0.00%)
[Iter 4050/20000] Loss: 0.0028533 (Best: 0.0004960 @iter3790) ([92mâ†“34.27%[0m) [1.13% of initial]
[Iter 4050] Gaussian 0 vs 1:
  Original Loss: 0.0032042
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0032042 (Pseudo: 0.00%)
[Iter 4050] Gaussian 1 vs 0:
  Original Loss: 0.0033310
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0033310 (Pseudo: 0.00%)
[Iter 4060/20000] Loss: 0.0019675 (Best: 0.0004960 @iter3790) ([92mâ†“31.04%[0m) [0.78% of initial]
[Iter 4060] Gaussian 0 vs 1:
  Original Loss: 0.0016984
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016984 (Pseudo: 0.00%)
[Iter 4060] Gaussian 1 vs 0:
  Original Loss: 0.0017168
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017168 (Pseudo: 0.00%)
[Iter 4070/20000] Loss: 0.0015495 (Best: 0.0004960 @iter3790) ([92mâ†“21.25%[0m) [0.62% of initial]
[Iter 4070] Gaussian 0 vs 1:
  Original Loss: 0.0013186
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013186 (Pseudo: 0.00%)
[Iter 4070] Gaussian 1 vs 0:
  Original Loss: 0.0013433
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013433 (Pseudo: 0.00%)
[Iter 4080/20000] Loss: 0.0014502 (Best: 0.0004960 @iter3790) ([92mâ†“6.41%[0m) [0.58% of initial]
[Iter 4080] Gaussian 0 vs 1:
  Original Loss: 0.0014219
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014219 (Pseudo: 0.00%)
[Iter 4080] Gaussian 1 vs 0:
  Original Loss: 0.0014111
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0014111 (Pseudo: 0.00%)
[Iter 4090/20000] Loss: 0.0011408 (Best: 0.0004960 @iter3790) ([92mâ†“21.33%[0m) [0.45% of initial]
[Iter 4090] Gaussian 0 vs 1:
  Original Loss: 0.0009300
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009300 (Pseudo: 0.00%)
[Iter 4090] Gaussian 1 vs 0:
  Original Loss: 0.0009206
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009206 (Pseudo: 0.00%)
Iter:4099, L1 loss=0.0009519, Total loss=0.0009221, Time:26
[Iter 4100/20000] Loss: 0.0009774 (Best: 0.0004960 @iter3790) ([92mâ†“14.33%[0m) [0.39% of initial]
[Iter 4100] Gaussian 0 vs 1:
  Original Loss: 0.0008976
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008976 (Pseudo: 0.00%)
[Iter 4100] Gaussian 1 vs 0:
  Original Loss: 0.0009014
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009014 (Pseudo: 0.00%)
[Iter 4110/20000] Loss: 0.0010797 (Best: 0.0004960 @iter3790) ([91mâ†‘10.47%[0m) [0.43% of initial]
[Iter 4110] Gaussian 0 vs 1:
  Original Loss: 0.0010649
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010649 (Pseudo: 0.00%)
[Iter 4110] Gaussian 1 vs 0:
  Original Loss: 0.0010803
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010803 (Pseudo: 0.00%)
[Iter 4120/20000] Loss: 0.0009807 (Best: 0.0004960 @iter3790) ([92mâ†“9.17%[0m) [0.39% of initial]
[Iter 4120] Gaussian 0 vs 1:
  Original Loss: 0.0008971
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008971 (Pseudo: 0.00%)
[Iter 4120] Gaussian 1 vs 0:
  Original Loss: 0.0009273
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009273 (Pseudo: 0.00%)
[Iter 4130/20000] Loss: 0.0011419 (Best: 0.0004960 @iter3790) ([91mâ†‘16.44%[0m) [0.45% of initial]
[Iter 4130] Gaussian 0 vs 1:
  Original Loss: 0.0011315
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011315 (Pseudo: 0.00%)
[Iter 4130] Gaussian 1 vs 0:
  Original Loss: 0.0011722
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011722 (Pseudo: 0.00%)
[Iter 4140/20000] Loss: 0.0010394 (Best: 0.0004960 @iter3790) ([92mâ†“8.98%[0m) [0.41% of initial]
[Iter 4140] Gaussian 0 vs 1:
  Original Loss: 0.0009517
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009517 (Pseudo: 0.00%)
[Iter 4140] Gaussian 1 vs 0:
  Original Loss: 0.0009529
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009529 (Pseudo: 0.00%)
[Iter 4150/20000] Loss: 0.0008622 (Best: 0.0004960 @iter3790) ([92mâ†“17.05%[0m) [0.34% of initial]
[Iter 4150] Gaussian 0 vs 1:
  Original Loss: 0.0009051
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009051 (Pseudo: 0.00%)
[Iter 4150] Gaussian 1 vs 0:
  Original Loss: 0.0009587
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009587 (Pseudo: 0.00%)
[Iter 4160/20000] Loss: 0.0009796 (Best: 0.0004960 @iter3790) ([91mâ†‘13.61%[0m) [0.39% of initial]
[Iter 4160] Gaussian 0 vs 1:
  Original Loss: 0.0010697
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010697 (Pseudo: 0.00%)
[Iter 4160] Gaussian 1 vs 0:
  Original Loss: 0.0010509
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010509 (Pseudo: 0.00%)
[Iter 4170/20000] Loss: 0.0008635 (Best: 0.0004960 @iter3790) ([92mâ†“11.85%[0m) [0.34% of initial]
[Iter 4170] Gaussian 0 vs 1:
  Original Loss: 0.0009053
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009053 (Pseudo: 0.00%)
[Iter 4170] Gaussian 1 vs 0:
  Original Loss: 0.0009302
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009302 (Pseudo: 0.00%)
[Iter 4180/20000] Loss: 0.0008697 (Best: 0.0004960 @iter3790) ([91mâ†‘0.72%[0m) [0.35% of initial]
[Iter 4180] Gaussian 0 vs 1:
  Original Loss: 0.0008946
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008946 (Pseudo: 0.00%)
[Iter 4180] Gaussian 1 vs 0:
  Original Loss: 0.0009215
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009215 (Pseudo: 0.00%)
[Iter 4190/20000] Loss: 0.0008247 (Best: 0.0004960 @iter3790) ([92mâ†“5.18%[0m) [0.33% of initial]
[Iter 4190] Gaussian 0 vs 1:
  Original Loss: 0.0008724
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008724 (Pseudo: 0.00%)
[Iter 4190] Gaussian 1 vs 0:
  Original Loss: 0.0008940
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008940 (Pseudo: 0.00%)
Iter:4199, L1 loss=0.0007909, Total loss=0.0007209, Time:25
[Iter 4200/20000] Loss: 0.0008706 (Best: 0.0004960 @iter3790) ([91mâ†‘5.57%[0m) [0.35% of initial]
[Iter 4200] Gaussian 0 vs 1:
  Original Loss: 0.0010202
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010202 (Pseudo: 0.00%)
[Iter 4200] Gaussian 1 vs 0:
  Original Loss: 0.0009940
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009940 (Pseudo: 0.00%)
[Iter 4210/20000] Loss: 0.0032216 (Best: 0.0004960 @iter3790) ([91mâ†‘270.04%[0m) [1.28% of initial]
[Iter 4210] Gaussian 0 vs 1:
  Original Loss: 0.0029205
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0029205 (Pseudo: 0.00%)
[Iter 4210] Gaussian 1 vs 0:
  Original Loss: 0.0026561
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0026561 (Pseudo: 0.00%)
[Iter 4220/20000] Loss: 0.0017691 (Best: 0.0004960 @iter3790) ([92mâ†“45.09%[0m) [0.70% of initial]
[Iter 4220] Gaussian 0 vs 1:
  Original Loss: 0.0017586
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017586 (Pseudo: 0.00%)
[Iter 4220] Gaussian 1 vs 0:
  Original Loss: 0.0018296
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018296 (Pseudo: 0.00%)
[Iter 4230/20000] Loss: 0.0011901 (Best: 0.0004960 @iter3790) ([92mâ†“32.73%[0m) [0.47% of initial]
[Iter 4230] Gaussian 0 vs 1:
  Original Loss: 0.0010829
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010829 (Pseudo: 0.00%)
[Iter 4230] Gaussian 1 vs 0:
  Original Loss: 0.0010628
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010628 (Pseudo: 0.00%)
[Iter 4240/20000] Loss: 0.0009523 (Best: 0.0004960 @iter3790) ([92mâ†“19.99%[0m) [0.38% of initial]
[Iter 4240] Gaussian 0 vs 1:
  Original Loss: 0.0008983
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008983 (Pseudo: 0.00%)
[Iter 4240] Gaussian 1 vs 0:
  Original Loss: 0.0009253
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009253 (Pseudo: 0.00%)
[Iter 4250/20000] Loss: 0.0008985 (Best: 0.0004960 @iter3790) ([92mâ†“5.64%[0m) [0.36% of initial]
[Iter 4250] Gaussian 0 vs 1:
  Original Loss: 0.0008312
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008312 (Pseudo: 0.00%)
[Iter 4250] Gaussian 1 vs 0:
  Original Loss: 0.0008220
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008220 (Pseudo: 0.00%)
[Iter 4260/20000] Loss: 0.0009440 (Best: 0.0004960 @iter3790) ([91mâ†‘5.06%[0m) [0.38% of initial]
[Iter 4260] Gaussian 0 vs 1:
  Original Loss: 0.0009777
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009777 (Pseudo: 0.00%)
[Iter 4260] Gaussian 1 vs 0:
  Original Loss: 0.0010602
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010602 (Pseudo: 0.00%)
[Iter 4270/20000] Loss: 0.0008684 (Best: 0.0004960 @iter3790) ([92mâ†“8.00%[0m) [0.35% of initial]
[Iter 4270] Gaussian 0 vs 1:
  Original Loss: 0.0008144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008144 (Pseudo: 0.00%)
[Iter 4270] Gaussian 1 vs 0:
  Original Loss: 0.0008384
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008384 (Pseudo: 0.00%)
[Iter 4280/20000] Loss: 0.0007053 (Best: 0.0004960 @iter3790) ([92mâ†“18.78%[0m) [0.28% of initial]
[Iter 4280] Gaussian 0 vs 1:
  Original Loss: 0.0006289
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006289 (Pseudo: 0.00%)
[Iter 4280] Gaussian 1 vs 0:
  Original Loss: 0.0006319
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006319 (Pseudo: 0.00%)
[Iter 4290/20000] Loss: 0.0006906 (Best: 0.0004960 @iter3790) ([92mâ†“2.09%[0m) [0.27% of initial]
[Iter 4290] Gaussian 0 vs 1:
  Original Loss: 0.0007308
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007308 (Pseudo: 0.00%)
[Iter 4290] Gaussian 1 vs 0:
  Original Loss: 0.0007305
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007305 (Pseudo: 0.00%)
Iter:4299, L1 loss=0.0008367, Total loss=0.0008201, Time:26
[Iter 4300/20000] Loss: 0.0006946 (Best: 0.0004960 @iter3790) ([91mâ†‘0.59%[0m) [0.28% of initial]
[Iter 4300] Gaussian 0 vs 1:
  Original Loss: 0.0005996
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005996 (Pseudo: 0.00%)
[Iter 4300] Gaussian 1 vs 0:
  Original Loss: 0.0006044
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006044 (Pseudo: 0.00%)
[Iter 4310/20000] Loss: 0.0006465 (Best: 0.0004960 @iter3790) ([92mâ†“6.93%[0m) [0.26% of initial]
[Iter 4310] Gaussian 0 vs 1:
  Original Loss: 0.0005864
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005864 (Pseudo: 0.00%)
[Iter 4310] Gaussian 1 vs 0:
  Original Loss: 0.0005957
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005957 (Pseudo: 0.00%)
[Iter 4320/20000] Loss: 0.0007737 (Best: 0.0004960 @iter3790) ([91mâ†‘19.68%[0m) [0.31% of initial]
[Iter 4320] Gaussian 0 vs 1:
  Original Loss: 0.0007814
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007814 (Pseudo: 0.00%)
[Iter 4320] Gaussian 1 vs 0:
  Original Loss: 0.0008116
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008116 (Pseudo: 0.00%)
[Iter 4330/20000] Loss: 0.0006661 (Best: 0.0004960 @iter3790) ([92mâ†“13.90%[0m) [0.26% of initial]
[Iter 4330] Gaussian 0 vs 1:
  Original Loss: 0.0006113
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006113 (Pseudo: 0.00%)
[Iter 4330] Gaussian 1 vs 0:
  Original Loss: 0.0006419
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006419 (Pseudo: 0.00%)
[Iter 4340/20000] Loss: 0.0006244 (Best: 0.0004960 @iter3790) ([92mâ†“6.27%[0m) [0.25% of initial]
[Iter 4340] Gaussian 0 vs 1:
  Original Loss: 0.0005908
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005908 (Pseudo: 0.00%)
[Iter 4340] Gaussian 1 vs 0:
  Original Loss: 0.0006147
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006147 (Pseudo: 0.00%)
[Iter 4350/20000] Loss: 0.0006223 (Best: 0.0004960 @iter3790) ([92mâ†“0.34%[0m) [0.25% of initial]
[Iter 4350] Gaussian 0 vs 1:
  Original Loss: 0.0006552
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006552 (Pseudo: 0.00%)
[Iter 4350] Gaussian 1 vs 0:
  Original Loss: 0.0006864
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006864 (Pseudo: 0.00%)
[Iter 4360/20000] Loss: 0.0006343 (Best: 0.0004960 @iter3790) ([91mâ†‘1.93%[0m) [0.25% of initial]
[Iter 4360] Gaussian 0 vs 1:
  Original Loss: 0.0006256
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006256 (Pseudo: 0.00%)
[Iter 4360] Gaussian 1 vs 0:
  Original Loss: 0.0006072
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006072 (Pseudo: 0.00%)
[Iter 4370/20000] Loss: 0.0006151 (Best: 0.0004960 @iter3790) ([92mâ†“3.01%[0m) [0.24% of initial]
[Iter 4370] Gaussian 0 vs 1:
  Original Loss: 0.0006500
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006500 (Pseudo: 0.00%)
[Iter 4370] Gaussian 1 vs 0:
  Original Loss: 0.0006691
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006691 (Pseudo: 0.00%)
[Iter 4380/20000] Loss: 0.0006585 (Best: 0.0004960 @iter3790) ([91mâ†‘7.06%[0m) [0.26% of initial]
[Iter 4380] Gaussian 0 vs 1:
  Original Loss: 0.0006323
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006323 (Pseudo: 0.00%)
[Iter 4380] Gaussian 1 vs 0:
  Original Loss: 0.0006524
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006524 (Pseudo: 0.00%)
[Iter 4390/20000] Loss: 0.0006000 (Best: 0.0004960 @iter3790) ([92mâ†“8.89%[0m) [0.24% of initial]
[Iter 4390] Gaussian 0 vs 1:
  Original Loss: 0.0005894
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005894 (Pseudo: 0.00%)
[Iter 4390] Gaussian 1 vs 0:
  Original Loss: 0.0005939
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005939 (Pseudo: 0.00%)
Iter:4399, L1 loss=0.0005902, Total loss=0.0005228, Time:25
[Iter 4400/20000] Loss: 0.0005862 (Best: 0.0004960 @iter3790) ([92mâ†“2.29%[0m) [0.23% of initial]
[Iter 4400] Gaussian 0 vs 1:
  Original Loss: 0.0005987
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005987 (Pseudo: 0.00%)
[Iter 4400] Gaussian 1 vs 0:
  Original Loss: 0.0006082
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006082 (Pseudo: 0.00%)
[Iter 4410/20000] Loss: 0.0028615 (Best: 0.0004960 @iter3790) ([91mâ†‘388.11%[0m) [1.14% of initial]
[Iter 4410] Gaussian 0 vs 1:
  Original Loss: 0.0030272
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030272 (Pseudo: 0.00%)
[Iter 4410] Gaussian 1 vs 0:
  Original Loss: 0.0030397
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0030397 (Pseudo: 0.00%)
[Iter 4420/20000] Loss: 0.0014503 (Best: 0.0004960 @iter3790) ([92mâ†“49.31%[0m) [0.58% of initial]
[Iter 4420] Gaussian 0 vs 1:
  Original Loss: 0.0012164
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012164 (Pseudo: 0.00%)
[Iter 4420] Gaussian 1 vs 0:
  Original Loss: 0.0012238
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012238 (Pseudo: 0.00%)
[Iter 4430/20000] Loss: 0.0010519 (Best: 0.0004960 @iter3790) ([92mâ†“27.48%[0m) [0.42% of initial]
[Iter 4430] Gaussian 0 vs 1:
  Original Loss: 0.0009973
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009973 (Pseudo: 0.00%)
[Iter 4430] Gaussian 1 vs 0:
  Original Loss: 0.0010715
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010715 (Pseudo: 0.00%)
[Iter 4440/20000] Loss: 0.0008089 (Best: 0.0004960 @iter3790) ([92mâ†“23.10%[0m) [0.32% of initial]
[Iter 4440] Gaussian 0 vs 1:
  Original Loss: 0.0008589
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008589 (Pseudo: 0.00%)
[Iter 4440] Gaussian 1 vs 0:
  Original Loss: 0.0008996
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008996 (Pseudo: 0.00%)
[Iter 4450/20000] Loss: 0.0006922 (Best: 0.0004960 @iter3790) ([92mâ†“14.43%[0m) [0.28% of initial]
[Iter 4450] Gaussian 0 vs 1:
  Original Loss: 0.0006378
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006378 (Pseudo: 0.00%)
[Iter 4450] Gaussian 1 vs 0:
  Original Loss: 0.0006858
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006858 (Pseudo: 0.00%)
[Iter 4460/20000] Loss: 0.0006666 (Best: 0.0004960 @iter3790) ([92mâ†“3.70%[0m) [0.26% of initial]
[Iter 4460] Gaussian 0 vs 1:
  Original Loss: 0.0006955
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006955 (Pseudo: 0.00%)
[Iter 4460] Gaussian 1 vs 0:
  Original Loss: 0.0007196
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007196 (Pseudo: 0.00%)
[Iter 4470/20000] Loss: 0.0007264 (Best: 0.0004960 @iter3790) ([91mâ†‘8.97%[0m) [0.29% of initial]
[Iter 4470] Gaussian 0 vs 1:
  Original Loss: 0.0008609
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008609 (Pseudo: 0.00%)
[Iter 4470] Gaussian 1 vs 0:
  Original Loss: 0.0008449
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008449 (Pseudo: 0.00%)
[Iter 4480/20000] Loss: 0.0006834 (Best: 0.0004960 @iter3790) ([92mâ†“5.92%[0m) [0.27% of initial]
[Iter 4480] Gaussian 0 vs 1:
  Original Loss: 0.0006641
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006641 (Pseudo: 0.00%)
[Iter 4480] Gaussian 1 vs 0:
  Original Loss: 0.0006770
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006770 (Pseudo: 0.00%)
[Iter 4490/20000] Loss: 0.0006792 (Best: 0.0004960 @iter3790) ([92mâ†“0.62%[0m) [0.27% of initial]
[Iter 4490] Gaussian 0 vs 1:
  Original Loss: 0.0006402
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006402 (Pseudo: 0.00%)
[Iter 4490] Gaussian 1 vs 0:
  Original Loss: 0.0006430
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006430 (Pseudo: 0.00%)
Iter:4499, L1 loss=0.0007677, Total loss=0.0007554, Time:25
[Iter 4500/20000] Loss: 0.0007754 (Best: 0.0004960 @iter3790) ([91mâ†‘14.16%[0m) [0.31% of initial]
[Iter 4500] Gaussian 0 vs 1:
  Original Loss: 0.0008015
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008015 (Pseudo: 0.00%)
[Iter 4500] Gaussian 1 vs 0:
  Original Loss: 0.0007658
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007658 (Pseudo: 0.00%)
[Iter 4510/20000] Loss: 0.0005671 (Best: 0.0004960 @iter3790) ([92mâ†“26.86%[0m) [0.23% of initial]
[Iter 4510] Gaussian 0 vs 1:
  Original Loss: 0.0004978
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004978 (Pseudo: 0.00%)
[Iter 4510] Gaussian 1 vs 0:
  Original Loss: 0.0005075
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005075 (Pseudo: 0.00%)
[Iter 4520/20000] Loss: 0.0005902 (Best: 0.0004960 @iter3790) ([91mâ†‘4.07%[0m) [0.23% of initial]
[Iter 4520] Gaussian 0 vs 1:
  Original Loss: 0.0005389
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005389 (Pseudo: 0.00%)
[Iter 4520] Gaussian 1 vs 0:
  Original Loss: 0.0005248
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005248 (Pseudo: 0.00%)
[Iter 4530/20000] Loss: 0.0006506 (Best: 0.0004960 @iter3790) ([91mâ†‘10.23%[0m) [0.26% of initial]
[Iter 4530] Gaussian 0 vs 1:
  Original Loss: 0.0007248
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007248 (Pseudo: 0.00%)
[Iter 4530] Gaussian 1 vs 0:
  Original Loss: 0.0007388
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007388 (Pseudo: 0.00%)
[Iter 4540/20000] Loss: 0.0005850 (Best: 0.0004960 @iter3790) ([92mâ†“10.09%[0m) [0.23% of initial]
[Iter 4540] Gaussian 0 vs 1:
  Original Loss: 0.0005693
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005693 (Pseudo: 0.00%)
[Iter 4540] Gaussian 1 vs 0:
  Original Loss: 0.0005809
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005809 (Pseudo: 0.00%)
[Iter 4550/20000] Loss: 0.0006076 (Best: 0.0004958 @iter4546) ([91mâ†‘3.87%[0m) [0.24% of initial]
[Iter 4550] Gaussian 0 vs 1:
  Original Loss: 0.0006686
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006686 (Pseudo: 0.00%)
[Iter 4550] Gaussian 1 vs 0:
  Original Loss: 0.0006609
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006609 (Pseudo: 0.00%)
[Iter 4560/20000] Loss: 0.0006277 (Best: 0.0004958 @iter4546) ([91mâ†‘3.31%[0m) [0.25% of initial]
[Iter 4560] Gaussian 0 vs 1:
  Original Loss: 0.0006137
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006137 (Pseudo: 0.00%)
[Iter 4560] Gaussian 1 vs 0:
  Original Loss: 0.0006441
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006441 (Pseudo: 0.00%)
[Iter 4570/20000] Loss: 0.0005608 (Best: 0.0004958 @iter4546) ([92mâ†“10.65%[0m) [0.22% of initial]
[Iter 4570] Gaussian 0 vs 1:
  Original Loss: 0.0005010
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005010 (Pseudo: 0.00%)
[Iter 4570] Gaussian 1 vs 0:
  Original Loss: 0.0005075
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005075 (Pseudo: 0.00%)
[Iter 4580/20000] Loss: 0.0005579 (Best: 0.0004958 @iter4546) ([92mâ†“0.53%[0m) [0.22% of initial]
[Iter 4580] Gaussian 0 vs 1:
  Original Loss: 0.0005346
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005346 (Pseudo: 0.00%)
[Iter 4580] Gaussian 1 vs 0:
  Original Loss: 0.0005462
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005462 (Pseudo: 0.00%)
[Iter 4590/20000] Loss: 0.0006025 (Best: 0.0004958 @iter4546) ([91mâ†‘8.01%[0m) [0.24% of initial]
[Iter 4590] Gaussian 0 vs 1:
  Original Loss: 0.0006562
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006562 (Pseudo: 0.00%)
[Iter 4590] Gaussian 1 vs 0:
  Original Loss: 0.0007002
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007002 (Pseudo: 0.00%)
Iter:4599, L1 loss=0.0006549, Total loss=0.000591, Time:25
[Iter 4600/20000] Loss: 0.0005809 (Best: 0.0004958 @iter4546) ([92mâ†“3.59%[0m) [0.23% of initial]
[Iter 4600] Gaussian 0 vs 1:
  Original Loss: 0.0005290
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005290 (Pseudo: 0.00%)
[Iter 4600] Gaussian 1 vs 0:
  Original Loss: 0.0005785
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005785 (Pseudo: 0.00%)
[Iter 4610/20000] Loss: 0.0023845 (Best: 0.0004958 @iter4546) ([91mâ†‘310.48%[0m) [0.95% of initial]
[Iter 4610] Gaussian 0 vs 1:
  Original Loss: 0.0021444
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021444 (Pseudo: 0.00%)
[Iter 4610] Gaussian 1 vs 0:
  Original Loss: 0.0021264
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0021264 (Pseudo: 0.00%)
[Iter 4620/20000] Loss: 0.0013882 (Best: 0.0004958 @iter4546) ([92mâ†“41.78%[0m) [0.55% of initial]
[Iter 4620] Gaussian 0 vs 1:
  Original Loss: 0.0013074
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013074 (Pseudo: 0.00%)
[Iter 4620] Gaussian 1 vs 0:
  Original Loss: 0.0013730
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013730 (Pseudo: 0.00%)
[Iter 4630/20000] Loss: 0.0009955 (Best: 0.0004958 @iter4546) ([92mâ†“28.29%[0m) [0.40% of initial]
[Iter 4630] Gaussian 0 vs 1:
  Original Loss: 0.0008966
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008966 (Pseudo: 0.00%)
[Iter 4630] Gaussian 1 vs 0:
  Original Loss: 0.0008770
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008770 (Pseudo: 0.00%)
[Iter 4640/20000] Loss: 0.0007858 (Best: 0.0004958 @iter4546) ([92mâ†“21.06%[0m) [0.31% of initial]
[Iter 4640] Gaussian 0 vs 1:
  Original Loss: 0.0007518
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007518 (Pseudo: 0.00%)
[Iter 4640] Gaussian 1 vs 0:
  Original Loss: 0.0007265
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007265 (Pseudo: 0.00%)
[Iter 4650/20000] Loss: 0.0006614 (Best: 0.0004958 @iter4546) ([92mâ†“15.83%[0m) [0.26% of initial]
[Iter 4650] Gaussian 0 vs 1:
  Original Loss: 0.0006522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006522 (Pseudo: 0.00%)
[Iter 4650] Gaussian 1 vs 0:
  Original Loss: 0.0006806
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006806 (Pseudo: 0.00%)
[Iter 4660/20000] Loss: 0.0005725 (Best: 0.0004958 @iter4546) ([92mâ†“13.45%[0m) [0.23% of initial]
[Iter 4660] Gaussian 0 vs 1:
  Original Loss: 0.0005074
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005074 (Pseudo: 0.00%)
[Iter 4660] Gaussian 1 vs 0:
  Original Loss: 0.0005063
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005063 (Pseudo: 0.00%)
[Iter 4670/20000] Loss: 0.0005406 (Best: 0.0004958 @iter4546) ([92mâ†“5.56%[0m) [0.21% of initial]
[Iter 4670] Gaussian 0 vs 1:
  Original Loss: 0.0005083
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005083 (Pseudo: 0.00%)
[Iter 4670] Gaussian 1 vs 0:
  Original Loss: 0.0005127
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005127 (Pseudo: 0.00%)
[Iter 4680/20000] Loss: 0.0005401 (Best: 0.0004723 @iter4672) ([92mâ†“0.11%[0m) [0.21% of initial]
[Iter 4680] Gaussian 0 vs 1:
  Original Loss: 0.0005231
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005231 (Pseudo: 0.00%)
[Iter 4680] Gaussian 1 vs 0:
  Original Loss: 0.0005377
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005377 (Pseudo: 0.00%)
[Iter 4690/20000] Loss: 0.0005031 (Best: 0.0004613 @iter4681) ([92mâ†“6.85%[0m) [0.20% of initial]
[Iter 4690] Gaussian 0 vs 1:
  Original Loss: 0.0004639
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004639 (Pseudo: 0.00%)
[Iter 4690] Gaussian 1 vs 0:
  Original Loss: 0.0004734
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004734 (Pseudo: 0.00%)
Iter:4699, L1 loss=0.0006205, Total loss=0.0005877, Time:26
[Iter 4700/20000] Loss: 0.0005593 (Best: 0.0004613 @iter4681) ([91mâ†‘11.19%[0m) [0.22% of initial]
[Iter 4700] Gaussian 0 vs 1:
  Original Loss: 0.0005397
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005397 (Pseudo: 0.00%)
[Iter 4700] Gaussian 1 vs 0:
  Original Loss: 0.0005435
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005435 (Pseudo: 0.00%)
[Iter 4710/20000] Loss: 0.0005006 (Best: 0.0004613 @iter4681) ([92mâ†“10.50%[0m) [0.20% of initial]
[Iter 4710] Gaussian 0 vs 1:
  Original Loss: 0.0004801
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004801 (Pseudo: 0.00%)
[Iter 4710] Gaussian 1 vs 0:
  Original Loss: 0.0004784
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004784 (Pseudo: 0.00%)
[Iter 4720/20000] Loss: 0.0005441 (Best: 0.0004274 @iter4711) ([91mâ†‘8.68%[0m) [0.22% of initial]
[Iter 4720] Gaussian 0 vs 1:
  Original Loss: 0.0005148
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005148 (Pseudo: 0.00%)
[Iter 4720] Gaussian 1 vs 0:
  Original Loss: 0.0005481
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005481 (Pseudo: 0.00%)
[Iter 4730/20000] Loss: 0.0005439 (Best: 0.0004274 @iter4711) ([92mâ†“0.02%[0m) [0.22% of initial]
[Iter 4730] Gaussian 0 vs 1:
  Original Loss: 0.0005787
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005787 (Pseudo: 0.00%)
[Iter 4730] Gaussian 1 vs 0:
  Original Loss: 0.0005923
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005923 (Pseudo: 0.00%)
[Iter 4740/20000] Loss: 0.0006026 (Best: 0.0004274 @iter4711) ([91mâ†‘10.79%[0m) [0.24% of initial]
[Iter 4740] Gaussian 0 vs 1:
  Original Loss: 0.0006525
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006525 (Pseudo: 0.00%)
[Iter 4740] Gaussian 1 vs 0:
  Original Loss: 0.0006744
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006744 (Pseudo: 0.00%)
[Iter 4750/20000] Loss: 0.0005872 (Best: 0.0004274 @iter4711) ([92mâ†“2.57%[0m) [0.23% of initial]
[Iter 4750] Gaussian 0 vs 1:
  Original Loss: 0.0005234
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005234 (Pseudo: 0.00%)
[Iter 4750] Gaussian 1 vs 0:
  Original Loss: 0.0005343
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005343 (Pseudo: 0.00%)
[Iter 4760/20000] Loss: 0.0005171 (Best: 0.0004274 @iter4711) ([92mâ†“11.94%[0m) [0.21% of initial]
[Iter 4760] Gaussian 0 vs 1:
  Original Loss: 0.0005165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005165 (Pseudo: 0.00%)
[Iter 4760] Gaussian 1 vs 0:
  Original Loss: 0.0005232
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005232 (Pseudo: 0.00%)
[Iter 4770/20000] Loss: 0.0005719 (Best: 0.0004274 @iter4711) ([91mâ†‘10.61%[0m) [0.23% of initial]
[Iter 4770] Gaussian 0 vs 1:
  Original Loss: 0.0006342
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006342 (Pseudo: 0.00%)
[Iter 4770] Gaussian 1 vs 0:
  Original Loss: 0.0006249
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006249 (Pseudo: 0.00%)
[Iter 4780/20000] Loss: 0.0005989 (Best: 0.0004274 @iter4711) ([91mâ†‘4.72%[0m) [0.24% of initial]
[Iter 4780] Gaussian 0 vs 1:
  Original Loss: 0.0006204
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006204 (Pseudo: 0.00%)
[Iter 4780] Gaussian 1 vs 0:
  Original Loss: 0.0006187
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006187 (Pseudo: 0.00%)
[Iter 4790/20000] Loss: 0.0005370 (Best: 0.0004274 @iter4711) ([92mâ†“10.34%[0m) [0.21% of initial]
[Iter 4790] Gaussian 0 vs 1:
  Original Loss: 0.0005410
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005410 (Pseudo: 0.00%)
[Iter 4790] Gaussian 1 vs 0:
  Original Loss: 0.0005353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005353 (Pseudo: 0.00%)
Iter:4799, L1 loss=0.0006151, Total loss=0.0005367, Time:26
[Iter 4800/20000] Loss: 0.0006011 (Best: 0.0004274 @iter4711) ([91mâ†‘11.93%[0m) [0.24% of initial]
[Iter 4800] Gaussian 0 vs 1:
  Original Loss: 0.0005989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005989 (Pseudo: 0.00%)
[Iter 4800] Gaussian 1 vs 0:
  Original Loss: 0.0006200
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006200 (Pseudo: 0.00%)
[Iter 4810/20000] Loss: 0.0022142 (Best: 0.0004274 @iter4711) ([91mâ†‘268.38%[0m) [0.88% of initial]
[Iter 4810] Gaussian 0 vs 1:
  Original Loss: 0.0019742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019742 (Pseudo: 0.00%)
[Iter 4810] Gaussian 1 vs 0:
  Original Loss: 0.0019924
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019924 (Pseudo: 0.00%)
[Iter 4820/20000] Loss: 0.0014381 (Best: 0.0004274 @iter4711) ([92mâ†“35.05%[0m) [0.57% of initial]
[Iter 4820] Gaussian 0 vs 1:
  Original Loss: 0.0013612
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0013612 (Pseudo: 0.00%)
[Iter 4820] Gaussian 1 vs 0:
  Original Loss: 0.0012232
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012232 (Pseudo: 0.00%)
[Iter 4830/20000] Loss: 0.0010098 (Best: 0.0004274 @iter4711) ([92mâ†“29.78%[0m) [0.40% of initial]
[Iter 4830] Gaussian 0 vs 1:
  Original Loss: 0.0011656
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011656 (Pseudo: 0.00%)
[Iter 4830] Gaussian 1 vs 0:
  Original Loss: 0.0012024
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012024 (Pseudo: 0.00%)
[Iter 4840/20000] Loss: 0.0007297 (Best: 0.0004274 @iter4711) ([92mâ†“27.74%[0m) [0.29% of initial]
[Iter 4840] Gaussian 0 vs 1:
  Original Loss: 0.0007068
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007068 (Pseudo: 0.00%)
[Iter 4840] Gaussian 1 vs 0:
  Original Loss: 0.0007453
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007453 (Pseudo: 0.00%)
[Iter 4850/20000] Loss: 0.0005775 (Best: 0.0004274 @iter4711) ([92mâ†“20.86%[0m) [0.23% of initial]
[Iter 4850] Gaussian 0 vs 1:
  Original Loss: 0.0005885
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005885 (Pseudo: 0.00%)
[Iter 4850] Gaussian 1 vs 0:
  Original Loss: 0.0005878
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005878 (Pseudo: 0.00%)
[Iter 4860/20000] Loss: 0.0005751 (Best: 0.0004274 @iter4711) ([92mâ†“0.42%[0m) [0.23% of initial]
[Iter 4860] Gaussian 0 vs 1:
  Original Loss: 0.0005606
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005606 (Pseudo: 0.00%)
[Iter 4860] Gaussian 1 vs 0:
  Original Loss: 0.0005522
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005522 (Pseudo: 0.00%)
[Iter 4870/20000] Loss: 0.0005010 (Best: 0.0004274 @iter4711) ([92mâ†“12.89%[0m) [0.20% of initial]
[Iter 4870] Gaussian 0 vs 1:
  Original Loss: 0.0004794
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004794 (Pseudo: 0.00%)
[Iter 4870] Gaussian 1 vs 0:
  Original Loss: 0.0004906
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004906 (Pseudo: 0.00%)
[Iter 4880/20000] Loss: 0.0005299 (Best: 0.0004274 @iter4711) ([91mâ†‘5.78%[0m) [0.21% of initial]
[Iter 4880] Gaussian 0 vs 1:
  Original Loss: 0.0005882
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005882 (Pseudo: 0.00%)
[Iter 4880] Gaussian 1 vs 0:
  Original Loss: 0.0006252
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006252 (Pseudo: 0.00%)
[Iter 4890/20000] Loss: 0.0005025 (Best: 0.0004274 @iter4711) ([92mâ†“5.18%[0m) [0.20% of initial]
[Iter 4890] Gaussian 0 vs 1:
  Original Loss: 0.0004738
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004738 (Pseudo: 0.00%)
[Iter 4890] Gaussian 1 vs 0:
  Original Loss: 0.0004713
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004713 (Pseudo: 0.00%)
Iter:4899, L1 loss=0.0006285, Total loss=0.0006064, Time:26
[Iter 4900/20000] Loss: 0.0005066 (Best: 0.0004274 @iter4711) ([91mâ†‘0.82%[0m) [0.20% of initial]
[Iter 4900] Gaussian 0 vs 1:
  Original Loss: 0.0004588
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004588 (Pseudo: 0.00%)
[Iter 4900] Gaussian 1 vs 0:
  Original Loss: 0.0004574
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004574 (Pseudo: 0.00%)
[Iter 4910/20000] Loss: 0.0006128 (Best: 0.0004274 @iter4711) ([91mâ†‘20.96%[0m) [0.24% of initial]
[Iter 4910] Gaussian 0 vs 1:
  Original Loss: 0.0006989
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006989 (Pseudo: 0.00%)
[Iter 4910] Gaussian 1 vs 0:
  Original Loss: 0.0007132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007132 (Pseudo: 0.00%)
[Iter 4920/20000] Loss: 0.0005358 (Best: 0.0004274 @iter4711) ([92mâ†“12.57%[0m) [0.21% of initial]
[Iter 4920] Gaussian 0 vs 1:
  Original Loss: 0.0005164
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005164 (Pseudo: 0.00%)
[Iter 4920] Gaussian 1 vs 0:
  Original Loss: 0.0005265
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005265 (Pseudo: 0.00%)
[Iter 4930/20000] Loss: 0.0004932 (Best: 0.0004274 @iter4711) ([92mâ†“7.94%[0m) [0.20% of initial]
[Iter 4930] Gaussian 0 vs 1:
  Original Loss: 0.0004460
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004460 (Pseudo: 0.00%)
[Iter 4930] Gaussian 1 vs 0:
  Original Loss: 0.0004301
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004301 (Pseudo: 0.00%)
[Iter 4940/20000] Loss: 0.0005007 (Best: 0.0004239 @iter4936) ([91mâ†‘1.51%[0m) [0.20% of initial]
[Iter 4940] Gaussian 0 vs 1:
  Original Loss: 0.0004696
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004696 (Pseudo: 0.00%)
[Iter 4940] Gaussian 1 vs 0:
  Original Loss: 0.0004740
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004740 (Pseudo: 0.00%)
[Iter 4950/20000] Loss: 0.0004395 (Best: 0.0003990 @iter4949) ([92mâ†“12.22%[0m) [0.17% of initial]
[Iter 4950] Gaussian 0 vs 1:
  Original Loss: 0.0004491
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004491 (Pseudo: 0.00%)
[Iter 4950] Gaussian 1 vs 0:
  Original Loss: 0.0004665
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004665 (Pseudo: 0.00%)
[Iter 4960/20000] Loss: 0.0004730 (Best: 0.0003919 @iter4957) ([91mâ†‘7.61%[0m) [0.19% of initial]
[Iter 4960] Gaussian 0 vs 1:
  Original Loss: 0.0004816
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004816 (Pseudo: 0.00%)
[Iter 4960] Gaussian 1 vs 0:
  Original Loss: 0.0004924
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004924 (Pseudo: 0.00%)
[Iter 4970/20000] Loss: 0.0004916 (Best: 0.0003919 @iter4957) ([91mâ†‘3.95%[0m) [0.20% of initial]
[Iter 4970] Gaussian 0 vs 1:
  Original Loss: 0.0005132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005132 (Pseudo: 0.00%)
[Iter 4970] Gaussian 1 vs 0:
  Original Loss: 0.0005291
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005291 (Pseudo: 0.00%)
[Iter 4980/20000] Loss: 0.0005039 (Best: 0.0003919 @iter4957) ([91mâ†‘2.51%[0m) [0.20% of initial]
[Iter 4980] Gaussian 0 vs 1:
  Original Loss: 0.0004982
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004982 (Pseudo: 0.00%)
[Iter 4980] Gaussian 1 vs 0:
  Original Loss: 0.0005025
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005025 (Pseudo: 0.00%)
[Iter 4990/20000] Loss: 0.0004720 (Best: 0.0003919 @iter4957) ([92mâ†“6.34%[0m) [0.19% of initial]
[Iter 4990] Gaussian 0 vs 1:
  Original Loss: 0.0004472
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004472 (Pseudo: 0.00%)
[Iter 4990] Gaussian 1 vs 0:
  Original Loss: 0.0004742
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004742 (Pseudo: 0.00%)
Iter:4999, L1 loss=0.0005039, Total loss=0.0004511, Time:26
[Iter 5000/20000] Loss: 0.0004504 (Best: 0.0003919 @iter4957) ([92mâ†“4.57%[0m) [0.18% of initial]
[Iter 5000] Gaussian 0 vs 1:
  Original Loss: 0.0004456
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004456 (Pseudo: 0.00%)
[Iter 5000] Gaussian 1 vs 0:
  Original Loss: 0.0004504
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004504 (Pseudo: 0.00%)
[Iter 5010/20000] Loss: 0.0020000 (Best: 0.0003919 @iter4957) ([91mâ†‘344.01%[0m) [0.79% of initial]
[Iter 5010] Gaussian 0 vs 1:
  Original Loss: 0.0017774
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017774 (Pseudo: 0.00%)
[Iter 5010] Gaussian 1 vs 0:
  Original Loss: 0.0018643
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018643 (Pseudo: 0.00%)
[Iter 5020/20000] Loss: 0.0012416 (Best: 0.0003919 @iter4957) ([92mâ†“37.92%[0m) [0.49% of initial]
[Iter 5020] Gaussian 0 vs 1:
  Original Loss: 0.0010813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010813 (Pseudo: 0.00%)
[Iter 5020] Gaussian 1 vs 0:
  Original Loss: 0.0011327
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0011327 (Pseudo: 0.00%)
[Iter 5030/20000] Loss: 0.0007899 (Best: 0.0003919 @iter4957) ([92mâ†“36.38%[0m) [0.31% of initial]
[Iter 5030] Gaussian 0 vs 1:
  Original Loss: 0.0007408
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007408 (Pseudo: 0.00%)
[Iter 5030] Gaussian 1 vs 0:
  Original Loss: 0.0007635
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007635 (Pseudo: 0.00%)
[Iter 5040/20000] Loss: 0.0007624 (Best: 0.0003919 @iter4957) ([92mâ†“3.49%[0m) [0.30% of initial]
[Iter 5040] Gaussian 0 vs 1:
  Original Loss: 0.0009047
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009047 (Pseudo: 0.00%)
[Iter 5040] Gaussian 1 vs 0:
  Original Loss: 0.0010128
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0010128 (Pseudo: 0.00%)
[Iter 5050/20000] Loss: 0.0006661 (Best: 0.0003919 @iter4957) ([92mâ†“12.62%[0m) [0.26% of initial]
[Iter 5050] Gaussian 0 vs 1:
  Original Loss: 0.0006240
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006240 (Pseudo: 0.00%)
[Iter 5050] Gaussian 1 vs 0:
  Original Loss: 0.0006461
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006461 (Pseudo: 0.00%)
[Iter 5060/20000] Loss: 0.0005100 (Best: 0.0003919 @iter4957) ([92mâ†“23.43%[0m) [0.20% of initial]
[Iter 5060] Gaussian 0 vs 1:
  Original Loss: 0.0004923
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004923 (Pseudo: 0.00%)
[Iter 5060] Gaussian 1 vs 0:
  Original Loss: 0.0004990
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004990 (Pseudo: 0.00%)
[Iter 5070/20000] Loss: 0.0005726 (Best: 0.0003919 @iter4957) ([91mâ†‘12.28%[0m) [0.23% of initial]
[Iter 5070] Gaussian 0 vs 1:
  Original Loss: 0.0005774
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005774 (Pseudo: 0.00%)
[Iter 5070] Gaussian 1 vs 0:
  Original Loss: 0.0006201
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006201 (Pseudo: 0.00%)
[Iter 5080/20000] Loss: 0.0004795 (Best: 0.0003919 @iter4957) ([92mâ†“16.27%[0m) [0.19% of initial]
[Iter 5080] Gaussian 0 vs 1:
  Original Loss: 0.0004328
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004328 (Pseudo: 0.00%)
[Iter 5080] Gaussian 1 vs 0:
  Original Loss: 0.0004625
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004625 (Pseudo: 0.00%)
[Iter 5090/20000] Loss: 0.0005054 (Best: 0.0003919 @iter4957) ([91mâ†‘5.39%[0m) [0.20% of initial]
[Iter 5090] Gaussian 0 vs 1:
  Original Loss: 0.0004937
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004937 (Pseudo: 0.00%)
[Iter 5090] Gaussian 1 vs 0:
  Original Loss: 0.0005162
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005162 (Pseudo: 0.00%)
Iter:5099, L1 loss=0.000589, Total loss=0.0005209, Time:26
[Iter 5100/20000] Loss: 0.0005343 (Best: 0.0003919 @iter4957) ([91mâ†‘5.73%[0m) [0.21% of initial]
[Iter 5100] Gaussian 0 vs 1:
  Original Loss: 0.0005605
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005605 (Pseudo: 0.00%)
[Iter 5100] Gaussian 1 vs 0:
  Original Loss: 0.0005813
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005813 (Pseudo: 0.00%)
[Iter 5110/20000] Loss: 0.0005233 (Best: 0.0003919 @iter4957) ([92mâ†“2.05%[0m) [0.21% of initial]
[Iter 5110] Gaussian 0 vs 1:
  Original Loss: 0.0005190
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005190 (Pseudo: 0.00%)
[Iter 5110] Gaussian 1 vs 0:
  Original Loss: 0.0005381
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005381 (Pseudo: 0.00%)
[Iter 5120/20000] Loss: 0.0005067 (Best: 0.0003919 @iter4957) ([92mâ†“3.18%[0m) [0.20% of initial]
[Iter 5120] Gaussian 0 vs 1:
  Original Loss: 0.0004883
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004883 (Pseudo: 0.00%)
[Iter 5120] Gaussian 1 vs 0:
  Original Loss: 0.0004883
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004883 (Pseudo: 0.00%)
[Iter 5130/20000] Loss: 0.0005346 (Best: 0.0003919 @iter4957) ([91mâ†‘5.52%[0m) [0.21% of initial]
[Iter 5130] Gaussian 0 vs 1:
  Original Loss: 0.0005585
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005585 (Pseudo: 0.00%)
[Iter 5130] Gaussian 1 vs 0:
  Original Loss: 0.0005183
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005183 (Pseudo: 0.00%)
[Iter 5140/20000] Loss: 0.0004594 (Best: 0.0003919 @iter4957) ([92mâ†“14.07%[0m) [0.18% of initial]
[Iter 5140] Gaussian 0 vs 1:
  Original Loss: 0.0004250
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004250 (Pseudo: 0.00%)
[Iter 5140] Gaussian 1 vs 0:
  Original Loss: 0.0004314
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004314 (Pseudo: 0.00%)
[Iter 5150/20000] Loss: 0.0004578 (Best: 0.0003919 @iter4957) ([92mâ†“0.37%[0m) [0.18% of initial]
[Iter 5150] Gaussian 0 vs 1:
  Original Loss: 0.0004697
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004697 (Pseudo: 0.00%)
[Iter 5150] Gaussian 1 vs 0:
  Original Loss: 0.0004655
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004655 (Pseudo: 0.00%)
[Iter 5160/20000] Loss: 0.0004514 (Best: 0.0003852 @iter5158) ([92mâ†“1.39%[0m) [0.18% of initial]
[Iter 5160] Gaussian 0 vs 1:
  Original Loss: 0.0005203
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005203 (Pseudo: 0.00%)
[Iter 5160] Gaussian 1 vs 0:
  Original Loss: 0.0005114
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005114 (Pseudo: 0.00%)
[Iter 5170/20000] Loss: 0.0004985 (Best: 0.0003852 @iter5158) ([91mâ†‘10.44%[0m) [0.20% of initial]
[Iter 5170] Gaussian 0 vs 1:
  Original Loss: 0.0004631
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004631 (Pseudo: 0.00%)
[Iter 5170] Gaussian 1 vs 0:
  Original Loss: 0.0004651
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004651 (Pseudo: 0.00%)
[Iter 5180/20000] Loss: 0.0004599 (Best: 0.0003852 @iter5158) ([92mâ†“7.74%[0m) [0.18% of initial]
[Iter 5180] Gaussian 0 vs 1:
  Original Loss: 0.0004285
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004285 (Pseudo: 0.00%)
[Iter 5180] Gaussian 1 vs 0:
  Original Loss: 0.0004279
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004279 (Pseudo: 0.00%)
[Iter 5190/20000] Loss: 0.0004641 (Best: 0.0003852 @iter5158) ([91mâ†‘0.91%[0m) [0.18% of initial]
[Iter 5190] Gaussian 0 vs 1:
  Original Loss: 0.0004652
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004652 (Pseudo: 0.00%)
[Iter 5190] Gaussian 1 vs 0:
  Original Loss: 0.0004603
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004603 (Pseudo: 0.00%)
Iter:5199, L1 loss=0.0005453, Total loss=0.0004728, Time:26
[Iter 5200/20000] Loss: 0.0004447 (Best: 0.0003852 @iter5158) ([92mâ†“4.19%[0m) [0.18% of initial]
[Iter 5200] Gaussian 0 vs 1:
  Original Loss: 0.0004282
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004282 (Pseudo: 0.00%)
[Iter 5200] Gaussian 1 vs 0:
  Original Loss: 0.0004426
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004426 (Pseudo: 0.00%)
[Iter 5210/20000] Loss: 0.0020439 (Best: 0.0003852 @iter5158) ([91mâ†‘359.63%[0m) [0.81% of initial]
[Iter 5210] Gaussian 0 vs 1:
  Original Loss: 0.0019072
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0019072 (Pseudo: 0.00%)
[Iter 5210] Gaussian 1 vs 0:
  Original Loss: 0.0017368
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017368 (Pseudo: 0.00%)
[Iter 5220/20000] Loss: 0.0010863 (Best: 0.0003852 @iter5158) ([92mâ†“46.85%[0m) [0.43% of initial]
[Iter 5220] Gaussian 0 vs 1:
  Original Loss: 0.0009518
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009518 (Pseudo: 0.00%)
[Iter 5220] Gaussian 1 vs 0:
  Original Loss: 0.0009353
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009353 (Pseudo: 0.00%)
[Iter 5230/20000] Loss: 0.0007540 (Best: 0.0003852 @iter5158) ([92mâ†“30.60%[0m) [0.30% of initial]
[Iter 5230] Gaussian 0 vs 1:
  Original Loss: 0.0006424
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006424 (Pseudo: 0.00%)
[Iter 5230] Gaussian 1 vs 0:
  Original Loss: 0.0006366
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006366 (Pseudo: 0.00%)
[Iter 5240/20000] Loss: 0.0005946 (Best: 0.0003852 @iter5158) ([92mâ†“21.13%[0m) [0.24% of initial]
[Iter 5240] Gaussian 0 vs 1:
  Original Loss: 0.0005735
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005735 (Pseudo: 0.00%)
[Iter 5240] Gaussian 1 vs 0:
  Original Loss: 0.0005707
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005707 (Pseudo: 0.00%)
[Iter 5250/20000] Loss: 0.0007194 (Best: 0.0003852 @iter5158) ([91mâ†‘20.97%[0m) [0.29% of initial]
[Iter 5250] Gaussian 0 vs 1:
  Original Loss: 0.0008054
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0008054 (Pseudo: 0.00%)
[Iter 5250] Gaussian 1 vs 0:
  Original Loss: 0.0007992
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007992 (Pseudo: 0.00%)
[Iter 5260/20000] Loss: 0.0005719 (Best: 0.0003852 @iter5158) ([92mâ†“20.50%[0m) [0.23% of initial]
[Iter 5260] Gaussian 0 vs 1:
  Original Loss: 0.0005432
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005432 (Pseudo: 0.00%)
[Iter 5260] Gaussian 1 vs 0:
  Original Loss: 0.0005679
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005679 (Pseudo: 0.00%)
[Iter 5270/20000] Loss: 0.0005244 (Best: 0.0003852 @iter5158) ([92mâ†“8.30%[0m) [0.21% of initial]
[Iter 5270] Gaussian 0 vs 1:
  Original Loss: 0.0004773
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004773 (Pseudo: 0.00%)
[Iter 5270] Gaussian 1 vs 0:
  Original Loss: 0.0004808
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004808 (Pseudo: 0.00%)
[Iter 5280/20000] Loss: 0.0005607 (Best: 0.0003852 @iter5158) ([91mâ†‘6.91%[0m) [0.22% of initial]
[Iter 5280] Gaussian 0 vs 1:
  Original Loss: 0.0006231
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006231 (Pseudo: 0.00%)
[Iter 5280] Gaussian 1 vs 0:
  Original Loss: 0.0006089
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006089 (Pseudo: 0.00%)
[Iter 5290/20000] Loss: 0.0005058 (Best: 0.0003852 @iter5158) ([92mâ†“9.79%[0m) [0.20% of initial]
[Iter 5290] Gaussian 0 vs 1:
  Original Loss: 0.0004949
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004949 (Pseudo: 0.00%)
[Iter 5290] Gaussian 1 vs 0:
  Original Loss: 0.0005125
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005125 (Pseudo: 0.00%)
Iter:5299, L1 loss=0.0006141, Total loss=0.000543, Time:27
[Iter 5300/20000] Loss: 0.0005946 (Best: 0.0003852 @iter5158) ([91mâ†‘17.57%[0m) [0.24% of initial]
[Iter 5300] Gaussian 0 vs 1:
  Original Loss: 0.0005704
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005704 (Pseudo: 0.00%)
[Iter 5300] Gaussian 1 vs 0:
  Original Loss: 0.0005799
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005799 (Pseudo: 0.00%)
[Iter 5310/20000] Loss: 0.0005659 (Best: 0.0003852 @iter5158) ([92mâ†“4.83%[0m) [0.22% of initial]
[Iter 5310] Gaussian 0 vs 1:
  Original Loss: 0.0006307
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006307 (Pseudo: 0.00%)
[Iter 5310] Gaussian 1 vs 0:
  Original Loss: 0.0006211
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006211 (Pseudo: 0.00%)
[Iter 5320/20000] Loss: 0.0005058 (Best: 0.0003852 @iter5158) ([92mâ†“10.61%[0m) [0.20% of initial]
[Iter 5320] Gaussian 0 vs 1:
  Original Loss: 0.0005329
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005329 (Pseudo: 0.00%)
[Iter 5320] Gaussian 1 vs 0:
  Original Loss: 0.0005365
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005365 (Pseudo: 0.00%)
[Iter 5330/20000] Loss: 0.0004408 (Best: 0.0003852 @iter5158) ([92mâ†“12.86%[0m) [0.18% of initial]
[Iter 5330] Gaussian 0 vs 1:
  Original Loss: 0.0004347
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004347 (Pseudo: 0.00%)
[Iter 5330] Gaussian 1 vs 0:
  Original Loss: 0.0004311
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004311 (Pseudo: 0.00%)
[Iter 5340/20000] Loss: 0.0004592 (Best: 0.0003852 @iter5158) ([91mâ†‘4.17%[0m) [0.18% of initial]
[Iter 5340] Gaussian 0 vs 1:
  Original Loss: 0.0004720
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004720 (Pseudo: 0.00%)
[Iter 5340] Gaussian 1 vs 0:
  Original Loss: 0.0004675
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004675 (Pseudo: 0.00%)
[Iter 5350/20000] Loss: 0.0005032 (Best: 0.0003743 @iter5344) ([91mâ†‘9.60%[0m) [0.20% of initial]
[Iter 5350] Gaussian 0 vs 1:
  Original Loss: 0.0005089
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005089 (Pseudo: 0.00%)
[Iter 5350] Gaussian 1 vs 0:
  Original Loss: 0.0004905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004905 (Pseudo: 0.00%)
[Iter 5360/20000] Loss: 0.0004787 (Best: 0.0003743 @iter5344) ([92mâ†“4.88%[0m) [0.19% of initial]
[Iter 5360] Gaussian 0 vs 1:
  Original Loss: 0.0005092
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005092 (Pseudo: 0.00%)
[Iter 5360] Gaussian 1 vs 0:
  Original Loss: 0.0005004
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005004 (Pseudo: 0.00%)
[Iter 5370/20000] Loss: 0.0004925 (Best: 0.0003743 @iter5344) ([91mâ†‘2.89%[0m) [0.20% of initial]
[Iter 5370] Gaussian 0 vs 1:
  Original Loss: 0.0005438
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005438 (Pseudo: 0.00%)
[Iter 5370] Gaussian 1 vs 0:
  Original Loss: 0.0005461
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005461 (Pseudo: 0.00%)
[Iter 5380/20000] Loss: 0.0004930 (Best: 0.0003743 @iter5344) ([91mâ†‘0.10%[0m) [0.20% of initial]
[Iter 5380] Gaussian 0 vs 1:
  Original Loss: 0.0004687
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004687 (Pseudo: 0.00%)
[Iter 5380] Gaussian 1 vs 0:
  Original Loss: 0.0004647
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004647 (Pseudo: 0.00%)
[Iter 5390/20000] Loss: 0.0005183 (Best: 0.0003743 @iter5344) ([91mâ†‘5.13%[0m) [0.21% of initial]
[Iter 5390] Gaussian 0 vs 1:
  Original Loss: 0.0005179
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005179 (Pseudo: 0.00%)
[Iter 5390] Gaussian 1 vs 0:
  Original Loss: 0.0005277
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005277 (Pseudo: 0.00%)
Iter:5399, L1 loss=0.0004904, Total loss=0.0004312, Time:27
[Iter 5400/20000] Loss: 0.0004932 (Best: 0.0003743 @iter5344) ([92mâ†“4.83%[0m) [0.20% of initial]
[Iter 5400] Gaussian 0 vs 1:
  Original Loss: 0.0005586
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005586 (Pseudo: 0.00%)
[Iter 5400] Gaussian 1 vs 0:
  Original Loss: 0.0005494
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005494 (Pseudo: 0.00%)
[Iter 5410/20000] Loss: 0.0019107 (Best: 0.0003743 @iter5344) ([91mâ†‘287.38%[0m) [0.76% of initial]
[Iter 5410] Gaussian 0 vs 1:
  Original Loss: 0.0017142
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0017142 (Pseudo: 0.00%)
[Iter 5410] Gaussian 1 vs 0:
  Original Loss: 0.0016123
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0016123 (Pseudo: 0.00%)
[Iter 5420/20000] Loss: 0.0013418 (Best: 0.0003743 @iter5344) ([92mâ†“29.78%[0m) [0.53% of initial]
[Iter 5420] Gaussian 0 vs 1:
  Original Loss: 0.0012715
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012715 (Pseudo: 0.00%)
[Iter 5420] Gaussian 1 vs 0:
  Original Loss: 0.0012866
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0012866 (Pseudo: 0.00%)
[Iter 5430/20000] Loss: 0.0007748 (Best: 0.0003743 @iter5344) ([92mâ†“42.26%[0m) [0.31% of initial]
[Iter 5430] Gaussian 0 vs 1:
  Original Loss: 0.0007303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007303 (Pseudo: 0.00%)
[Iter 5430] Gaussian 1 vs 0:
  Original Loss: 0.0007303
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007303 (Pseudo: 0.00%)
[Iter 5440/20000] Loss: 0.0006721 (Best: 0.0003743 @iter5344) ([92mâ†“13.26%[0m) [0.27% of initial]
[Iter 5440] Gaussian 0 vs 1:
  Original Loss: 0.0006718
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006718 (Pseudo: 0.00%)
[Iter 5440] Gaussian 1 vs 0:
  Original Loss: 0.0006512
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006512 (Pseudo: 0.00%)
[Iter 5450/20000] Loss: 0.0005434 (Best: 0.0003743 @iter5344) ([92mâ†“19.14%[0m) [0.22% of initial]
[Iter 5450] Gaussian 0 vs 1:
  Original Loss: 0.0005125
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005125 (Pseudo: 0.00%)
[Iter 5450] Gaussian 1 vs 0:
  Original Loss: 0.0005144
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005144 (Pseudo: 0.00%)
[Iter 5460/20000] Loss: 0.0005624 (Best: 0.0003743 @iter5344) ([91mâ†‘3.48%[0m) [0.22% of initial]
[Iter 5460] Gaussian 0 vs 1:
  Original Loss: 0.0006061
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006061 (Pseudo: 0.00%)
[Iter 5460] Gaussian 1 vs 0:
  Original Loss: 0.0005823
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005823 (Pseudo: 0.00%)
[Iter 5470/20000] Loss: 0.0004613 (Best: 0.0003743 @iter5344) ([92mâ†“17.98%[0m) [0.18% of initial]
[Iter 5470] Gaussian 0 vs 1:
  Original Loss: 0.0004414
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004414 (Pseudo: 0.00%)
[Iter 5470] Gaussian 1 vs 0:
  Original Loss: 0.0004537
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004537 (Pseudo: 0.00%)
[Iter 5480/20000] Loss: 0.0004350 (Best: 0.0003685 @iter5476) ([92mâ†“5.69%[0m) [0.17% of initial]
[Iter 5480] Gaussian 0 vs 1:
  Original Loss: 0.0004090
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004090 (Pseudo: 0.00%)
[Iter 5480] Gaussian 1 vs 0:
  Original Loss: 0.0004115
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004115 (Pseudo: 0.00%)
[Iter 5490/20000] Loss: 0.0004563 (Best: 0.0003685 @iter5476) ([91mâ†‘4.88%[0m) [0.18% of initial]
[Iter 5490] Gaussian 0 vs 1:
  Original Loss: 0.0004577
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004577 (Pseudo: 0.00%)
[Iter 5490] Gaussian 1 vs 0:
  Original Loss: 0.0004633
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004633 (Pseudo: 0.00%)
Iter:5499, L1 loss=0.0005348, Total loss=0.0004745, Time:27
[Iter 5500/20000] Loss: 0.0004167 (Best: 0.0003685 @iter5476) ([92mâ†“8.67%[0m) [0.17% of initial]
[Iter 5500] Gaussian 0 vs 1:
  Original Loss: 0.0003825
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0003825 (Pseudo: 0.00%)
[Iter 5500] Gaussian 1 vs 0:
  Original Loss: 0.0003892
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0003892 (Pseudo: 0.00%)
[Iter 5510/20000] Loss: 0.0004362 (Best: 0.0003685 @iter5476) ([91mâ†‘4.68%[0m) [0.17% of initial]
[Iter 5510] Gaussian 0 vs 1:
  Original Loss: 0.0004132
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004132 (Pseudo: 0.00%)
[Iter 5510] Gaussian 1 vs 0:
  Original Loss: 0.0004299
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004299 (Pseudo: 0.00%)
[Iter 5520/20000] Loss: 0.0004078 (Best: 0.0003685 @iter5476) ([92mâ†“6.52%[0m) [0.16% of initial]
[Iter 5520] Gaussian 0 vs 1:
  Original Loss: 0.0003905
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0003905 (Pseudo: 0.00%)
[Iter 5520] Gaussian 1 vs 0:
  Original Loss: 0.0004030
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004030 (Pseudo: 0.00%)
[Iter 5530/20000] Loss: 0.0004523 (Best: 0.0003577 @iter5521) ([91mâ†‘10.91%[0m) [0.18% of initial]
[Iter 5530] Gaussian 0 vs 1:
  Original Loss: 0.0004165
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004165 (Pseudo: 0.00%)
[Iter 5530] Gaussian 1 vs 0:
  Original Loss: 0.0004367
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004367 (Pseudo: 0.00%)
[Iter 5540/20000] Loss: 0.0004664 (Best: 0.0003577 @iter5521) ([91mâ†‘3.11%[0m) [0.19% of initial]
[Iter 5540] Gaussian 0 vs 1:
  Original Loss: 0.0004669
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004669 (Pseudo: 0.00%)
[Iter 5540] Gaussian 1 vs 0:
  Original Loss: 0.0004832
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004832 (Pseudo: 0.00%)
[Iter 5550/20000] Loss: 0.0004727 (Best: 0.0003577 @iter5521) ([91mâ†‘1.36%[0m) [0.19% of initial]
[Iter 5550] Gaussian 0 vs 1:
  Original Loss: 0.0004533
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004533 (Pseudo: 0.00%)
[Iter 5550] Gaussian 1 vs 0:
  Original Loss: 0.0004633
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004633 (Pseudo: 0.00%)
[Iter 5560/20000] Loss: 0.0004371 (Best: 0.0003577 @iter5521) ([92mâ†“7.54%[0m) [0.17% of initial]
[Iter 5560] Gaussian 0 vs 1:
  Original Loss: 0.0004031
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004031 (Pseudo: 0.00%)
[Iter 5560] Gaussian 1 vs 0:
  Original Loss: 0.0004050
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004050 (Pseudo: 0.00%)
[Iter 5570/20000] Loss: 0.0004412 (Best: 0.0003577 @iter5521) ([91mâ†‘0.95%[0m) [0.18% of initial]
[Iter 5570] Gaussian 0 vs 1:
  Original Loss: 0.0004672
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004672 (Pseudo: 0.00%)
[Iter 5570] Gaussian 1 vs 0:
  Original Loss: 0.0004568
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004568 (Pseudo: 0.00%)
[Iter 5580/20000] Loss: 0.0005043 (Best: 0.0003577 @iter5521) ([91mâ†‘14.31%[0m) [0.20% of initial]
[Iter 5580] Gaussian 0 vs 1:
  Original Loss: 0.0004983
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004983 (Pseudo: 0.00%)
[Iter 5580] Gaussian 1 vs 0:
  Original Loss: 0.0005098
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005098 (Pseudo: 0.00%)
[Iter 5590/20000] Loss: 0.0005611 (Best: 0.0003577 @iter5521) ([91mâ†‘11.25%[0m) [0.22% of initial]
[Iter 5590] Gaussian 0 vs 1:
  Original Loss: 0.0005269
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005269 (Pseudo: 0.00%)
[Iter 5590] Gaussian 1 vs 0:
  Original Loss: 0.0005320
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005320 (Pseudo: 0.00%)
Iter:5599, L1 loss=0.0004741, Total loss=0.0004166, Time:27
[Iter 5600/20000] Loss: 0.0004301 (Best: 0.0003577 @iter5521) ([92mâ†“23.34%[0m) [0.17% of initial]
[Iter 5600] Gaussian 0 vs 1:
  Original Loss: 0.0004087
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004087 (Pseudo: 0.00%)
[Iter 5600] Gaussian 1 vs 0:
  Original Loss: 0.0004172
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004172 (Pseudo: 0.00%)
[Iter 5610/20000] Loss: 0.0022138 (Best: 0.0003577 @iter5521) ([91mâ†‘414.70%[0m) [0.88% of initial]
[Iter 5610] Gaussian 0 vs 1:
  Original Loss: 0.0018313
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018313 (Pseudo: 0.00%)
[Iter 5610] Gaussian 1 vs 0:
  Original Loss: 0.0018145
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0018145 (Pseudo: 0.00%)
[Iter 5620/20000] Loss: 0.0010737 (Best: 0.0003577 @iter5521) ([92mâ†“51.50%[0m) [0.43% of initial]
[Iter 5620] Gaussian 0 vs 1:
  Original Loss: 0.0009233
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009233 (Pseudo: 0.00%)
[Iter 5620] Gaussian 1 vs 0:
  Original Loss: 0.0009362
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0009362 (Pseudo: 0.00%)
[Iter 5630/20000] Loss: 0.0008146 (Best: 0.0003577 @iter5521) ([92mâ†“24.13%[0m) [0.32% of initial]
[Iter 5630] Gaussian 0 vs 1:
  Original Loss: 0.0007819
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007819 (Pseudo: 0.00%)
[Iter 5630] Gaussian 1 vs 0:
  Original Loss: 0.0007545
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0007545 (Pseudo: 0.00%)
[Iter 5640/20000] Loss: 0.0006714 (Best: 0.0003577 @iter5521) ([92mâ†“17.58%[0m) [0.27% of initial]
[Iter 5640] Gaussian 0 vs 1:
  Original Loss: 0.0006103
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0006103 (Pseudo: 0.00%)
[Iter 5640] Gaussian 1 vs 0:
  Original Loss: 0.0005753
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005753 (Pseudo: 0.00%)
[Iter 5650/20000] Loss: 0.0005509 (Best: 0.0003577 @iter5521) ([92mâ†“17.96%[0m) [0.22% of initial]
[Iter 5650] Gaussian 0 vs 1:
  Original Loss: 0.0005030
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0005030 (Pseudo: 0.00%)
[Iter 5650] Gaussian 1 vs 0:
  Original Loss: 0.0004926
  Pseudo Loss: 0.0000000 (0.00% of original)
  Total Loss: 0.0004926 (Pseudo: 0.00%)
[Iter 5660/20000] Loss: 0.0005126 (Best: 0.0003577 @iter5521) ([92mâ†“6.95%[0m) [0.20% of initial]
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 10] Gaussian 0 vs 1:
  Original Loss: 0.2126908
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.020)
  Ratio to Original: 0.00%
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 10] Gaussian 1 vs 0:
  Original Loss: 0.2126908
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.020)
  Ratio to Original: 0.00%
  Total Loss: 0.2126908 (Pseudo: 0.00%)
[Iter 20/20000] Loss: 0.1746701 (Best: 0.1693031 @iter20) ([92mâ†“19.84%[0m) [69.39% of initial]
[Iter 20] Gaussian 0 vs 1:
  Original Loss: 0.1693031
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.040)
  Ratio to Original: 0.00%
  Total Loss: 0.1693031 (Pseudo: 0.00%)
[Iter 20] Gaussian 1 vs 0:
  Original Loss: 0.1693034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.040)
  Ratio to Original: 0.00%
  Total Loss: 0.1693034 (Pseudo: 0.00%)
[Iter 30/20000] Loss: 0.1374909 (Best: 0.1327888 @iter30) ([92mâ†“21.29%[0m) [54.62% of initial]
[Iter 30] Gaussian 0 vs 1:
  Original Loss: 0.1327888
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.060)
  Ratio to Original: 0.00%
  Total Loss: 0.1327888 (Pseudo: 0.00%)
[Iter 30] Gaussian 1 vs 0:
  Original Loss: 0.1327883
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.060)
  Ratio to Original: 0.00%
  Total Loss: 0.1327883 (Pseudo: 0.00%)
[Iter 40/20000] Loss: 0.1123920 (Best: 0.1098377 @iter40) ([92mâ†“18.25%[0m) [44.65% of initial]
[Iter 40] Gaussian 0 vs 1:
  Original Loss: 0.1098377
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.080)
  Ratio to Original: 0.00%
  Total Loss: 0.1098377 (Pseudo: 0.00%)
[Iter 40] Gaussian 1 vs 0:
  Original Loss: 0.1098365
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.080)
  Ratio to Original: 0.00%
  Total Loss: 0.1098365 (Pseudo: 0.00%)
[Iter 50/20000] Loss: 0.0993453 (Best: 0.0965455 @iter49) ([92mâ†“11.61%[0m) [39.47% of initial]
[Iter 50] Gaussian 0 vs 1:
  Original Loss: 0.0994871
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.100)
  Ratio to Original: 0.00%
  Total Loss: 0.0994871 (Pseudo: 0.00%)
[Iter 50] Gaussian 1 vs 0:
  Original Loss: 0.0994848
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.100)
  Ratio to Original: 0.00%
  Total Loss: 0.0994848 (Pseudo: 0.00%)
[Iter 60/20000] Loss: 0.0936756 (Best: 0.0908531 @iter59) ([92mâ†“5.71%[0m) [37.22% of initial]
[Iter 60] Gaussian 0 vs 1:
  Original Loss: 0.0940257
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.120)
  Ratio to Original: 0.00%
  Total Loss: 0.0940257 (Pseudo: 0.00%)
[Iter 60] Gaussian 1 vs 0:
  Original Loss: 0.0940318
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.120)
  Ratio to Original: 0.00%
  Total Loss: 0.0940318 (Pseudo: 0.00%)
[Iter 70/20000] Loss: 0.0884526 (Best: 0.0869432 @iter70) ([92mâ†“5.58%[0m) [35.14% of initial]
[Iter 70] Gaussian 0 vs 1:
  Original Loss: 0.0869432
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.140)
  Ratio to Original: 0.00%
  Total Loss: 0.0869432 (Pseudo: 0.00%)
[Iter 70] Gaussian 1 vs 0:
  Original Loss: 0.0869452
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.140)
  Ratio to Original: 0.00%
  Total Loss: 0.0869452 (Pseudo: 0.00%)
[Iter 80/20000] Loss: 0.0851848 (Best: 0.0830971 @iter80) ([92mâ†“3.69%[0m) [33.84% of initial]
[Iter 80] Gaussian 0 vs 1:
  Original Loss: 0.0830971
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.160)
  Ratio to Original: 0.00%
  Total Loss: 0.0830971 (Pseudo: 0.00%)
[Iter 80] Gaussian 1 vs 0:
  Original Loss: 0.0831055
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.160)
  Ratio to Original: 0.00%
  Total Loss: 0.0831055 (Pseudo: 0.00%)
[Iter 90/20000] Loss: 0.0824174 (Best: 0.0801601 @iter88) ([92mâ†“3.25%[0m) [32.74% of initial]
[Iter 90] Gaussian 0 vs 1:
  Original Loss: 0.0823502
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.180)
  Ratio to Original: 0.00%
  Total Loss: 0.0823502 (Pseudo: 0.00%)
[Iter 90] Gaussian 1 vs 0:
  Original Loss: 0.0823528
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.180)
  Ratio to Original: 0.00%
  Total Loss: 0.0823528 (Pseudo: 0.00%)
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:15
[Iter 100/20000] Loss: 0.0786689 (Best: 0.0766193 @iter97) ([92mâ†“4.55%[0m) [31.25% of initial]
[Iter 100] Gaussian 0 vs 1:
  Original Loss: 0.0783040
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.200)
  Ratio to Original: 0.00%
  Total Loss: 0.0783040 (Pseudo: 0.00%)
[Iter 100] Gaussian 1 vs 0:
  Original Loss: 0.0783039
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.200)
  Ratio to Original: 0.00%
  Total Loss: 0.0783039 (Pseudo: 0.00%)
[Iter 110/20000] Loss: 0.0753274 (Best: 0.0731456 @iter106) ([92mâ†“4.25%[0m) [29.93% of initial]
[Iter 110] Gaussian 0 vs 1:
  Original Loss: 0.0744795
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.220)
  Ratio to Original: 0.00%
  Total Loss: 0.0744795 (Pseudo: 0.00%)
[Iter 110] Gaussian 1 vs 0:
  Original Loss: 0.0744907
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.220)
  Ratio to Original: 0.00%
  Total Loss: 0.0744907 (Pseudo: 0.00%)
[Iter 120/20000] Loss: 0.0714338 (Best: 0.0685779 @iter118) ([92mâ†“5.17%[0m) [28.38% of initial]
[Iter 120] Gaussian 0 vs 1:
  Original Loss: 0.0722980
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.240)
  Ratio to Original: 0.00%
  Total Loss: 0.0722980 (Pseudo: 0.00%)
[Iter 120] Gaussian 1 vs 0:
  Original Loss: 0.0723168
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.240)
  Ratio to Original: 0.00%
  Total Loss: 0.0723168 (Pseudo: 0.00%)
[Iter 130/20000] Loss: 0.0667094 (Best: 0.0642144 @iter130) ([92mâ†“6.61%[0m) [26.50% of initial]
[Iter 130] Gaussian 0 vs 1:
  Original Loss: 0.0642144
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.260)
  Ratio to Original: 0.00%
  Total Loss: 0.0642144 (Pseudo: 0.00%)
[Iter 130] Gaussian 1 vs 0:
  Original Loss: 0.0642080
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.260)
  Ratio to Original: 0.00%
  Total Loss: 0.0642080 (Pseudo: 0.00%)
[Iter 140/20000] Loss: 0.0635396 (Best: 0.0612876 @iter140) ([92mâ†“4.75%[0m) [25.24% of initial]
[Iter 140] Gaussian 0 vs 1:
  Original Loss: 0.0612876
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.280)
  Ratio to Original: 0.00%
  Total Loss: 0.0612876 (Pseudo: 0.00%)
[Iter 140] Gaussian 1 vs 0:
  Original Loss: 0.0613061
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.280)
  Ratio to Original: 0.00%
  Total Loss: 0.0613061 (Pseudo: 0.00%)
[Iter 150/20000] Loss: 0.0612688 (Best: 0.0583680 @iter148) ([92mâ†“3.57%[0m) [24.34% of initial]
[Iter 150] Gaussian 0 vs 1:
  Original Loss: 0.0605453
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.300)
  Ratio to Original: 0.00%
  Total Loss: 0.0605453 (Pseudo: 0.00%)
[Iter 150] Gaussian 1 vs 0:
  Original Loss: 0.0605823
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.300)
  Ratio to Original: 0.00%
  Total Loss: 0.0605823 (Pseudo: 0.00%)
[Iter 160/20000] Loss: 0.0590484 (Best: 0.0559286 @iter157) ([92mâ†“3.62%[0m) [23.46% of initial]
[Iter 160] Gaussian 0 vs 1:
  Original Loss: 0.0599981
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.320)
  Ratio to Original: 0.00%
  Total Loss: 0.0599981 (Pseudo: 0.00%)
[Iter 160] Gaussian 1 vs 0:
  Original Loss: 0.0600279
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.320)
  Ratio to Original: 0.00%
  Total Loss: 0.0600279 (Pseudo: 0.00%)
[Iter 170/20000] Loss: 0.0563500 (Best: 0.0534931 @iter167) ([92mâ†“4.57%[0m) [22.39% of initial]
[Iter 170] Gaussian 0 vs 1:
  Original Loss: 0.0573921
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.340)
  Ratio to Original: 0.00%
  Total Loss: 0.0573921 (Pseudo: 0.00%)
[Iter 170] Gaussian 1 vs 0:
  Original Loss: 0.0574288
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.340)
  Ratio to Original: 0.00%
  Total Loss: 0.0574288 (Pseudo: 0.00%)
[Iter 180/20000] Loss: 0.0523277 (Best: 0.0500123 @iter179) ([92mâ†“7.14%[0m) [20.79% of initial]
[Iter 180] Gaussian 0 vs 1:
  Original Loss: 0.0518854
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.360)
  Ratio to Original: 0.00%
  Total Loss: 0.0518854 (Pseudo: 0.00%)
[Iter 180] Gaussian 1 vs 0:
  Original Loss: 0.0518935
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.360)
  Ratio to Original: 0.00%
  Total Loss: 0.0518935 (Pseudo: 0.00%)
[Iter 190/20000] Loss: 0.0494977 (Best: 0.0477921 @iter188) ([92mâ†“5.41%[0m) [19.66% of initial]
[Iter 190] Gaussian 0 vs 1:
  Original Loss: 0.0489988
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.380)
  Ratio to Original: 0.00%
  Total Loss: 0.0489988 (Pseudo: 0.00%)
[Iter 190] Gaussian 1 vs 0:
  Original Loss: 0.0490586
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.380)
  Ratio to Original: 0.00%
  Total Loss: 0.0490586 (Pseudo: 0.00%)
Iter:199, L1 loss=0.03443, Total loss=0.04979, Time:14
[Iter 200/20000] Loss: 0.0478234 (Best: 0.0456826 @iter198) ([92mâ†“3.38%[0m) [19.00% of initial]
[Iter 200] Gaussian 0 vs 1:
  Original Loss: 0.0467065
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.400)
  Ratio to Original: 0.00%
  Total Loss: 0.0467065 (Pseudo: 0.00%)
[Iter 200] Gaussian 1 vs 0:
  Original Loss: 0.0467326
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.400)
  Ratio to Original: 0.00%
  Total Loss: 0.0467326 (Pseudo: 0.00%)
[Iter 210/20000] Loss: 0.0450144 (Best: 0.0428364 @iter209) ([92mâ†“5.87%[0m) [17.88% of initial]
[Iter 210] Gaussian 0 vs 1:
  Original Loss: 0.0447366
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.420)
  Ratio to Original: 0.00%
  Total Loss: 0.0447366 (Pseudo: 0.00%)
[Iter 210] Gaussian 1 vs 0:
  Original Loss: 0.0447613
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.420)
  Ratio to Original: 0.00%
  Total Loss: 0.0447613 (Pseudo: 0.00%)
[Iter 220/20000] Loss: 0.0440382 (Best: 0.0411982 @iter219) ([92mâ†“2.17%[0m) [17.50% of initial]
[Iter 220] Gaussian 0 vs 1:
  Original Loss: 0.0454602
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.440)
  Ratio to Original: 0.00%
  Total Loss: 0.0454602 (Pseudo: 0.00%)
[Iter 220] Gaussian 1 vs 0:
  Original Loss: 0.0454481
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.440)
  Ratio to Original: 0.00%
  Total Loss: 0.0454481 (Pseudo: 0.00%)
[Iter 230/20000] Loss: 0.0422803 (Best: 0.0398412 @iter227) ([92mâ†“3.99%[0m) [16.80% of initial]
[Iter 230] Gaussian 0 vs 1:
  Original Loss: 0.0410086
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.460)
  Ratio to Original: 0.00%
  Total Loss: 0.0410086 (Pseudo: 0.00%)
[Iter 230] Gaussian 1 vs 0:
  Original Loss: 0.0410920
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.460)
  Ratio to Original: 0.00%
  Total Loss: 0.0410920 (Pseudo: 0.00%)
[Iter 240/20000] Loss: 0.0402027 (Best: 0.0377617 @iter238) ([92mâ†“4.91%[0m) [15.97% of initial]
[Iter 240] Gaussian 0 vs 1:
  Original Loss: 0.0393227
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.480)
  Ratio to Original: 0.00%
  Total Loss: 0.0393227 (Pseudo: 0.00%)
[Iter 240] Gaussian 1 vs 0:
  Original Loss: 0.0394214
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.480)
  Ratio to Original: 0.00%
  Total Loss: 0.0394214 (Pseudo: 0.00%)
[Iter 250/20000] Loss: 0.0379483 (Best: 0.0361903 @iter248) ([92mâ†“5.61%[0m) [15.08% of initial]
[Iter 250] Gaussian 0 vs 1:
  Original Loss: 0.0375778
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.500)
  Ratio to Original: 0.00%
  Total Loss: 0.0375778 (Pseudo: 0.00%)
[Iter 250] Gaussian 1 vs 0:
  Original Loss: 0.0376327
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.500)
  Ratio to Original: 0.00%
  Total Loss: 0.0376327 (Pseudo: 0.00%)
[Iter 260/20000] Loss: 0.0359141 (Best: 0.0343693 @iter260) ([92mâ†“5.36%[0m) [14.27% of initial]
[Iter 260] Gaussian 0 vs 1:
  Original Loss: 0.0343693
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.520)
  Ratio to Original: 0.00%
  Total Loss: 0.0343693 (Pseudo: 0.00%)
[Iter 260] Gaussian 1 vs 0:
  Original Loss: 0.0343404
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.520)
  Ratio to Original: 0.00%
  Total Loss: 0.0343404 (Pseudo: 0.00%)
[Iter 270/20000] Loss: 0.0349382 (Best: 0.0328604 @iter269) ([92mâ†“2.72%[0m) [13.88% of initial]
[Iter 270] Gaussian 0 vs 1:
  Original Loss: 0.0346533
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.540)
  Ratio to Original: 0.00%
  Total Loss: 0.0346533 (Pseudo: 0.00%)
[Iter 270] Gaussian 1 vs 0:
  Original Loss: 0.0347309
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.540)
  Ratio to Original: 0.00%
  Total Loss: 0.0347309 (Pseudo: 0.00%)
[Iter 280/20000] Loss: 0.0346945 (Best: 0.0319148 @iter277) ([92mâ†“0.70%[0m) [13.78% of initial]
[Iter 280] Gaussian 0 vs 1:
  Original Loss: 0.0358568
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.560)
  Ratio to Original: 0.00%
  Total Loss: 0.0358568 (Pseudo: 0.00%)
[Iter 280] Gaussian 1 vs 0:
  Original Loss: 0.0359731
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.560)
  Ratio to Original: 0.00%
  Total Loss: 0.0359731 (Pseudo: 0.00%)
[Iter 290/20000] Loss: 0.0331024 (Best: 0.0303852 @iter287) ([92mâ†“4.59%[0m) [13.15% of initial]
[Iter 290] Gaussian 0 vs 1:
  Original Loss: 0.0321202
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.580)
  Ratio to Original: 0.00%
  Total Loss: 0.0321202 (Pseudo: 0.00%)
[Iter 290] Gaussian 1 vs 0:
  Original Loss: 0.0321934
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.580)
  Ratio to Original: 0.00%
  Total Loss: 0.0321934 (Pseudo: 0.00%)
Iter:299, L1 loss=0.02221, Total loss=0.03345, Time:14
[Iter 300/20000] Loss: 0.0308937 (Best: 0.0290417 @iter300) ([92mâ†“6.67%[0m) [12.27% of initial]
[Iter 300] Gaussian 0 vs 1:
  Original Loss: 0.0290417
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.600)
  Ratio to Original: 0.00%
  Total Loss: 0.0290417 (Pseudo: 0.00%)
[Iter 300] Gaussian 1 vs 0:
  Original Loss: 0.0290223
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.600)
  Ratio to Original: 0.00%
  Total Loss: 0.0290223 (Pseudo: 0.00%)
[Iter 310/20000] Loss: 0.0293910 (Best: 0.0274530 @iter310) ([92mâ†“4.86%[0m) [11.68% of initial]
[Iter 310] Gaussian 0 vs 1:
  Original Loss: 0.0274530
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.620)
  Ratio to Original: 0.00%
  Total Loss: 0.0274530 (Pseudo: 0.00%)
[Iter 310] Gaussian 1 vs 0:
  Original Loss: 0.0274441
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.620)
  Ratio to Original: 0.00%
  Total Loss: 0.0274441 (Pseudo: 0.00%)
[Iter 320/20000] Loss: 0.0278181 (Best: 0.0263720 @iter320) ([92mâ†“5.35%[0m) [11.05% of initial]
[Iter 320] Gaussian 0 vs 1:
  Original Loss: 0.0263720
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.640)
  Ratio to Original: 0.00%
  Total Loss: 0.0263720 (Pseudo: 0.00%)
[Iter 320] Gaussian 1 vs 0:
  Original Loss: 0.0266206
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.640)
  Ratio to Original: 0.00%
  Total Loss: 0.0266206 (Pseudo: 0.00%)
[Iter 330/20000] Loss: 0.0275578 (Best: 0.0256517 @iter330) ([92mâ†“0.94%[0m) [10.95% of initial]
[Iter 330] Gaussian 0 vs 1:
  Original Loss: 0.0256517
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.660)
  Ratio to Original: 0.00%
  Total Loss: 0.0256517 (Pseudo: 0.00%)
[Iter 330] Gaussian 1 vs 0:
  Original Loss: 0.0258970
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.660)
  Ratio to Original: 0.00%
  Total Loss: 0.0258970 (Pseudo: 0.00%)
[Iter 340/20000] Loss: 0.0253621 (Best: 0.0242631 @iter340) ([92mâ†“7.97%[0m) [10.08% of initial]
[Iter 340] Gaussian 0 vs 1:
  Original Loss: 0.0242631
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.680)
  Ratio to Original: 0.00%
  Total Loss: 0.0242631 (Pseudo: 0.00%)
[Iter 340] Gaussian 1 vs 0:
  Original Loss: 0.0244139
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.680)
  Ratio to Original: 0.00%
  Total Loss: 0.0244139 (Pseudo: 0.00%)
[Iter 350/20000] Loss: 0.0260154 (Best: 0.0234693 @iter349) ([91mâ†‘2.58%[0m) [10.34% of initial]
[Iter 350] Gaussian 0 vs 1:
  Original Loss: 0.0273475
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.700)
  Ratio to Original: 0.00%
  Total Loss: 0.0273475 (Pseudo: 0.00%)
[Iter 350] Gaussian 1 vs 0:
  Original Loss: 0.0274214
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.700)
  Ratio to Original: 0.00%
  Total Loss: 0.0274214 (Pseudo: 0.00%)
[Iter 360/20000] Loss: 0.0244330 (Best: 0.0225299 @iter358) ([92mâ†“6.08%[0m) [9.71% of initial]
[Iter 360] Gaussian 0 vs 1:
  Original Loss: 0.0240026
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.720)
  Ratio to Original: 0.00%
  Total Loss: 0.0240026 (Pseudo: 0.00%)
[Iter 360] Gaussian 1 vs 0:
  Original Loss: 0.0245428
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.720)
  Ratio to Original: 0.00%
  Total Loss: 0.0245428 (Pseudo: 0.00%)
[Iter 370/20000] Loss: 0.0241634 (Best: 0.0219332 @iter368) ([92mâ†“1.10%[0m) [9.60% of initial]
[Iter 370] Gaussian 0 vs 1:
  Original Loss: 0.0253552
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.740)
  Ratio to Original: 0.00%
  Total Loss: 0.0253552 (Pseudo: 0.00%)
[Iter 370] Gaussian 1 vs 0:
  Original Loss: 0.0255873
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.740)
  Ratio to Original: 0.00%
  Total Loss: 0.0255873 (Pseudo: 0.00%)
[Iter 380/20000] Loss: 0.0219556 (Best: 0.0208685 @iter379) ([92mâ†“9.14%[0m) [8.72% of initial]
[Iter 380] Gaussian 0 vs 1:
  Original Loss: 0.0222538
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.760)
  Ratio to Original: 0.00%
  Total Loss: 0.0222538 (Pseudo: 0.00%)
[Iter 380] Gaussian 1 vs 0:
  Original Loss: 0.0228190
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.760)
  Ratio to Original: 0.00%
  Total Loss: 0.0228190 (Pseudo: 0.00%)
[Iter 390/20000] Loss: 0.0214535 (Best: 0.0198951 @iter385) ([92mâ†“2.29%[0m) [8.52% of initial]
[Iter 390] Gaussian 0 vs 1:
  Original Loss: 0.0200861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.780)
  Ratio to Original: 0.00%
  Total Loss: 0.0200861 (Pseudo: 0.00%)
[Iter 390] Gaussian 1 vs 0:
  Original Loss: 0.0203170
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.780)
  Ratio to Original: 0.00%
  Total Loss: 0.0203170 (Pseudo: 0.00%)
Iter:399, L1 loss=0.01372, Total loss=0.02121, Time:14
[Iter 400/20000] Loss: 0.0204162 (Best: 0.0189818 @iter400) ([92mâ†“4.83%[0m) [8.11% of initial]
[Iter 400] Gaussian 0 vs 1:
  Original Loss: 0.0189818
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.800)
  Ratio to Original: 0.00%
  Total Loss: 0.0189818 (Pseudo: 0.00%)
[Iter 400] Gaussian 1 vs 0:
  Original Loss: 0.0191063
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.800)
  Ratio to Original: 0.00%
  Total Loss: 0.0191063 (Pseudo: 0.00%)
[Iter 410/20000] Loss: 0.0194617 (Best: 0.0183653 @iter410) ([92mâ†“4.68%[0m) [7.73% of initial]
[Iter 410] Gaussian 0 vs 1:
  Original Loss: 0.0183653
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.820)
  Ratio to Original: 0.00%
  Total Loss: 0.0183653 (Pseudo: 0.00%)
[Iter 410] Gaussian 1 vs 0:
  Original Loss: 0.0185541
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.820)
  Ratio to Original: 0.00%
  Total Loss: 0.0185541 (Pseudo: 0.00%)
[Iter 420/20000] Loss: 0.0199603 (Best: 0.0177621 @iter418) ([91mâ†‘2.56%[0m) [7.93% of initial]
[Iter 420] Gaussian 0 vs 1:
  Original Loss: 0.0212062
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.840)
  Ratio to Original: 0.00%
  Total Loss: 0.0212062 (Pseudo: 0.00%)
[Iter 420] Gaussian 1 vs 0:
  Original Loss: 0.0213478
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.840)
  Ratio to Original: 0.00%
  Total Loss: 0.0213478 (Pseudo: 0.00%)
[Iter 430/20000] Loss: 0.0182680 (Best: 0.0173801 @iter430) ([92mâ†“8.48%[0m) [7.26% of initial]
[Iter 430] Gaussian 0 vs 1:
  Original Loss: 0.0173801
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.860)
  Ratio to Original: 0.00%
  Total Loss: 0.0173801 (Pseudo: 0.00%)
[Iter 430] Gaussian 1 vs 0:
  Original Loss: 0.0168240
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.860)
  Ratio to Original: 0.00%
  Total Loss: 0.0168240 (Pseudo: 0.00%)
[Iter 440/20000] Loss: 0.0188349 (Best: 0.0170196 @iter438) ([91mâ†‘3.10%[0m) [7.48% of initial]
[Iter 440] Gaussian 0 vs 1:
  Original Loss: 0.0197487
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.880)
  Ratio to Original: 0.00%
  Total Loss: 0.0197487 (Pseudo: 0.00%)
[Iter 440] Gaussian 1 vs 0:
  Original Loss: 0.0190885
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.880)
  Ratio to Original: 0.00%
  Total Loss: 0.0190885 (Pseudo: 0.00%)
[Iter 450/20000] Loss: 0.0180006 (Best: 0.0160581 @iter449) ([92mâ†“4.43%[0m) [7.15% of initial]
[Iter 450] Gaussian 0 vs 1:
  Original Loss: 0.0192332
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.900)
  Ratio to Original: 0.00%
  Total Loss: 0.0192332 (Pseudo: 0.00%)
[Iter 450] Gaussian 1 vs 0:
  Original Loss: 0.0188306
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.900)
  Ratio to Original: 0.00%
  Total Loss: 0.0188306 (Pseudo: 0.00%)
[Iter 460/20000] Loss: 0.0173075 (Best: 0.0153155 @iter458) ([92mâ†“3.85%[0m) [6.88% of initial]
[Iter 460] Gaussian 0 vs 1:
  Original Loss: 0.0180222
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.920)
  Ratio to Original: 0.00%
  Total Loss: 0.0180222 (Pseudo: 0.00%)
[Iter 460] Gaussian 1 vs 0:
  Original Loss: 0.0172426
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.920)
  Ratio to Original: 0.00%
  Total Loss: 0.0172426 (Pseudo: 0.00%)
[Iter 470/20000] Loss: 0.0158542 (Best: 0.0148551 @iter463) ([92mâ†“8.40%[0m) [6.30% of initial]
[Iter 470] Gaussian 0 vs 1:
  Original Loss: 0.0150190
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.940)
  Ratio to Original: 0.00%
  Total Loss: 0.0150190 (Pseudo: 0.00%)
[Iter 470] Gaussian 1 vs 0:
  Original Loss: 0.0138350
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.940)
  Ratio to Original: 0.00%
  Total Loss: 0.0138350 (Pseudo: 0.00%)
[Iter 480/20000] Loss: 0.0158497 (Best: 0.0144849 @iter479) ([92mâ†“0.03%[0m) [6.30% of initial]
[Iter 480] Gaussian 0 vs 1:
  Original Loss: 0.0160275
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.960)
  Ratio to Original: 0.00%
  Total Loss: 0.0160275 (Pseudo: 0.00%)
[Iter 480] Gaussian 1 vs 0:
  Original Loss: 0.0143497
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.960)
  Ratio to Original: 0.00%
  Total Loss: 0.0143497 (Pseudo: 0.00%)
[Iter 490/20000] Loss: 0.0148425 (Best: 0.0137517 @iter490) ([92mâ†“6.35%[0m) [5.90% of initial]
[Iter 490] Gaussian 0 vs 1:
  Original Loss: 0.0137517
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.980)
  Ratio to Original: 0.00%
  Total Loss: 0.0137517 (Pseudo: 0.00%)
[Iter 490] Gaussian 1 vs 0:
  Original Loss: 0.0130682
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 0.980)
  Ratio to Original: 0.00%
  Total Loss: 0.0130682 (Pseudo: 0.00%)
Iter:499, L1 loss=0.008805, Total loss=0.01551, Time:14
[Iter 500/20000] Loss: 0.0146356 (Best: 0.0135424 @iter493) ([92mâ†“1.39%[0m) [5.81% of initial]
[Iter 500] Gaussian 0 vs 1:
  Original Loss: 0.0142567
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0142567 (Pseudo: 0.00%)
[Iter 500] Gaussian 1 vs 0:
  Original Loss: 0.0137677
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0137677 (Pseudo: 0.00%)
[Iter 510/20000] Loss: 0.0141573 (Best: 0.0129006 @iter508) ([92mâ†“3.27%[0m) [5.62% of initial]
[Iter 510] Gaussian 0 vs 1:
  Original Loss: 0.0141517
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0141517 (Pseudo: 0.00%)
[Iter 510] Gaussian 1 vs 0:
  Original Loss: 0.0136837
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0136837 (Pseudo: 0.00%)
[Iter 520/20000] Loss: 0.0132030 (Best: 0.0123284 @iter514) ([92mâ†“6.74%[0m) [5.25% of initial]
[Iter 520] Gaussian 0 vs 1:
  Original Loss: 0.0130815
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0130815 (Pseudo: 0.00%)
[Iter 520] Gaussian 1 vs 0:
  Original Loss: 0.0129185
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0129185 (Pseudo: 0.00%)
[Iter 530/20000] Loss: 0.0125356 (Best: 0.0115212 @iter529) ([92mâ†“5.05%[0m) [4.98% of initial]
[Iter 530] Gaussian 0 vs 1:
  Original Loss: 0.0125486
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0125486 (Pseudo: 0.00%)
[Iter 530] Gaussian 1 vs 0:
  Original Loss: 0.0127318
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0127318 (Pseudo: 0.00%)
[Iter 540/20000] Loss: 0.0123495 (Best: 0.0110516 @iter538) ([92mâ†“1.48%[0m) [4.91% of initial]
[Iter 540] Gaussian 0 vs 1:
  Original Loss: 0.0121679
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0121679 (Pseudo: 0.00%)
[Iter 540] Gaussian 1 vs 0:
  Original Loss: 0.0125708
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0125708 (Pseudo: 0.00%)
[Iter 550/20000] Loss: 0.0121470 (Best: 0.0109409 @iter548) ([92mâ†“1.64%[0m) [4.83% of initial]
[Iter 550] Gaussian 0 vs 1:
  Original Loss: 0.0121311
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0121311 (Pseudo: 0.00%)
[Iter 550] Gaussian 1 vs 0:
  Original Loss: 0.0120861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0120861 (Pseudo: 0.00%)
[Iter 560/20000] Loss: 0.0123161 (Best: 0.0109401 @iter556) ([91mâ†‘1.39%[0m) [4.89% of initial]
[Iter 560] Gaussian 0 vs 1:
  Original Loss: 0.0120802
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0120802 (Pseudo: 0.00%)
[Iter 560] Gaussian 1 vs 0:
  Original Loss: 0.0118709
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0118709 (Pseudo: 0.00%)
[Iter 570/20000] Loss: 0.0117875 (Best: 0.0104893 @iter569) ([92mâ†“4.29%[0m) [4.68% of initial]
[Iter 570] Gaussian 0 vs 1:
  Original Loss: 0.0127352
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0127352 (Pseudo: 0.00%)
[Iter 570] Gaussian 1 vs 0:
  Original Loss: 0.0125608
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0125608 (Pseudo: 0.00%)
[Iter 580/20000] Loss: 0.0111491 (Best: 0.0101479 @iter578) ([92mâ†“5.42%[0m) [4.43% of initial]
[Iter 580] Gaussian 0 vs 1:
  Original Loss: 0.0110773
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0110773 (Pseudo: 0.00%)
[Iter 580] Gaussian 1 vs 0:
  Original Loss: 0.0111218
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0111218 (Pseudo: 0.00%)
[Iter 590/20000] Loss: 0.0112763 (Best: 0.0098980 @iter583) ([91mâ†‘1.14%[0m) [4.48% of initial]
[Iter 590] Gaussian 0 vs 1:
  Original Loss: 0.0111352
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0111352 (Pseudo: 0.00%)
[Iter 590] Gaussian 1 vs 0:
  Original Loss: 0.0110003
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0110003 (Pseudo: 0.00%)
Iter:599, L1 loss=0.006812, Total loss=0.01218, Time:13
[Iter 600/20000] Loss: 0.0114872 (Best: 0.0098980 @iter583) ([91mâ†‘1.87%[0m) [4.56% of initial]
[Iter 600] Gaussian 0 vs 1:
  Original Loss: 0.0117089
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0117089 (Pseudo: 0.00%)
[Iter 600] Gaussian 1 vs 0:
  Original Loss: 0.0108206
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0108206 (Pseudo: 0.00%)
[Iter 610/20000] Loss: 0.0197686 (Best: 0.0098980 @iter583) ([91mâ†‘72.09%[0m) [7.85% of initial]
[Iter 610] Gaussian 0 vs 1:
  Original Loss: 0.0173837
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0173837 (Pseudo: 0.00%)
[Iter 610] Gaussian 1 vs 0:
  Original Loss: 0.0179846
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0179846 (Pseudo: 0.00%)
[Iter 620/20000] Loss: 0.0143950 (Best: 0.0098980 @iter583) ([92mâ†“27.18%[0m) [5.72% of initial]
[Iter 620] Gaussian 0 vs 1:
  Original Loss: 0.0130906
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0130906 (Pseudo: 0.00%)
[Iter 620] Gaussian 1 vs 0:
  Original Loss: 0.0126280
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0126280 (Pseudo: 0.00%)
[Iter 630/20000] Loss: 0.0121635 (Best: 0.0098980 @iter583) ([92mâ†“15.50%[0m) [4.83% of initial]
[Iter 630] Gaussian 0 vs 1:
  Original Loss: 0.0113021
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0113021 (Pseudo: 0.00%)
[Iter 630] Gaussian 1 vs 0:
  Original Loss: 0.0112670
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0112670 (Pseudo: 0.00%)
[Iter 640/20000] Loss: 0.0105291 (Best: 0.0096385 @iter640) ([92mâ†“13.44%[0m) [4.18% of initial]
[Iter 640] Gaussian 0 vs 1:
  Original Loss: 0.0096385
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0096385 (Pseudo: 0.00%)
[Iter 640] Gaussian 1 vs 0:
  Original Loss: 0.0091983
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0091983 (Pseudo: 0.00%)
[Iter 650/20000] Loss: 0.0106195 (Best: 0.0093933 @iter646) ([91mâ†‘0.86%[0m) [4.22% of initial]
[Iter 650] Gaussian 0 vs 1:
  Original Loss: 0.0103663
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0103663 (Pseudo: 0.00%)
[Iter 650] Gaussian 1 vs 0:
  Original Loss: 0.0105366
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0105366 (Pseudo: 0.00%)
[Iter 660/20000] Loss: 0.0100114 (Best: 0.0088941 @iter655) ([92mâ†“5.73%[0m) [3.98% of initial]
[Iter 660] Gaussian 0 vs 1:
  Original Loss: 0.0106640
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0106640 (Pseudo: 0.00%)
[Iter 660] Gaussian 1 vs 0:
  Original Loss: 0.0106458
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0106458 (Pseudo: 0.00%)
[Iter 670/20000] Loss: 0.0095141 (Best: 0.0083938 @iter667) ([92mâ†“4.97%[0m) [3.78% of initial]
[Iter 670] Gaussian 0 vs 1:
  Original Loss: 0.0093781
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0093781 (Pseudo: 0.00%)
[Iter 670] Gaussian 1 vs 0:
  Original Loss: 0.0093635
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0093635 (Pseudo: 0.00%)
[Iter 680/20000] Loss: 0.0089247 (Best: 0.0083034 @iter680) ([92mâ†“6.19%[0m) [3.55% of initial]
[Iter 680] Gaussian 0 vs 1:
  Original Loss: 0.0083034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0083034 (Pseudo: 0.00%)
[Iter 680] Gaussian 1 vs 0:
  Original Loss: 0.0081034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0081034 (Pseudo: 0.00%)
[Iter 690/20000] Loss: 0.0092628 (Best: 0.0079286 @iter682) ([91mâ†‘3.79%[0m) [3.68% of initial]
[Iter 690] Gaussian 0 vs 1:
  Original Loss: 0.0087427
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087427 (Pseudo: 0.00%)
[Iter 690] Gaussian 1 vs 0:
  Original Loss: 0.0087921
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087921 (Pseudo: 0.00%)
Iter:699, L1 loss=0.005753, Total loss=0.009746, Time:14
[Iter 700/20000] Loss: 0.0089896 (Best: 0.0079143 @iter695) ([92mâ†“2.95%[0m) [3.57% of initial]
[Iter 700] Gaussian 0 vs 1:
  Original Loss: 0.0088658
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0088658 (Pseudo: 0.00%)
[Iter 700] Gaussian 1 vs 0:
  Original Loss: 0.0088044
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0088044 (Pseudo: 0.00%)
[Iter 710/20000] Loss: 0.0082676 (Best: 0.0076574 @iter710) ([92mâ†“8.03%[0m) [3.28% of initial]
[Iter 710] Gaussian 0 vs 1:
  Original Loss: 0.0076574
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0076574 (Pseudo: 0.00%)
[Iter 710] Gaussian 1 vs 0:
  Original Loss: 0.0076096
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0076096 (Pseudo: 0.00%)
[Iter 720/20000] Loss: 0.0084732 (Best: 0.0075350 @iter715) ([91mâ†‘2.49%[0m) [3.37% of initial]
[Iter 720] Gaussian 0 vs 1:
  Original Loss: 0.0079312
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079312 (Pseudo: 0.00%)
[Iter 720] Gaussian 1 vs 0:
  Original Loss: 0.0078905
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0078905 (Pseudo: 0.00%)
[Iter 730/20000] Loss: 0.0084763 (Best: 0.0074474 @iter724) ([91mâ†‘0.04%[0m) [3.37% of initial]
[Iter 730] Gaussian 0 vs 1:
  Original Loss: 0.0083475
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0083475 (Pseudo: 0.00%)
[Iter 730] Gaussian 1 vs 0:
  Original Loss: 0.0083282
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0083282 (Pseudo: 0.00%)
[Iter 740/20000] Loss: 0.0085226 (Best: 0.0074370 @iter733) ([91mâ†‘0.55%[0m) [3.39% of initial]
[Iter 740] Gaussian 0 vs 1:
  Original Loss: 0.0088001
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0088001 (Pseudo: 0.00%)
[Iter 740] Gaussian 1 vs 0:
  Original Loss: 0.0086915
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0086915 (Pseudo: 0.00%)
[Iter 750/20000] Loss: 0.0080038 (Best: 0.0068863 @iter748) ([92mâ†“6.09%[0m) [3.18% of initial]
[Iter 750] Gaussian 0 vs 1:
  Original Loss: 0.0079391
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079391 (Pseudo: 0.00%)
[Iter 750] Gaussian 1 vs 0:
  Original Loss: 0.0080232
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0080232 (Pseudo: 0.00%)
[Iter 760/20000] Loss: 0.0074151 (Best: 0.0068772 @iter754) ([92mâ†“7.36%[0m) [2.95% of initial]
[Iter 760] Gaussian 0 vs 1:
  Original Loss: 0.0069822
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069822 (Pseudo: 0.00%)
[Iter 760] Gaussian 1 vs 0:
  Original Loss: 0.0069306
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069306 (Pseudo: 0.00%)
[Iter 770/20000] Loss: 0.0076045 (Best: 0.0068772 @iter754) ([91mâ†‘2.55%[0m) [3.02% of initial]
[Iter 770] Gaussian 0 vs 1:
  Original Loss: 0.0079048
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079048 (Pseudo: 0.00%)
[Iter 770] Gaussian 1 vs 0:
  Original Loss: 0.0079583
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0079583 (Pseudo: 0.00%)
[Iter 780/20000] Loss: 0.0078148 (Best: 0.0066673 @iter775) ([91mâ†‘2.77%[0m) [3.10% of initial]
[Iter 780] Gaussian 0 vs 1:
  Original Loss: 0.0084307
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0084307 (Pseudo: 0.00%)
[Iter 780] Gaussian 1 vs 0:
  Original Loss: 0.0084941
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0084941 (Pseudo: 0.00%)
[Iter 790/20000] Loss: 0.0075900 (Best: 0.0065199 @iter787) ([92mâ†“2.88%[0m) [3.02% of initial]
[Iter 790] Gaussian 0 vs 1:
  Original Loss: 0.0075703
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0075703 (Pseudo: 0.00%)
[Iter 790] Gaussian 1 vs 0:
  Original Loss: 0.0075662
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0075662 (Pseudo: 0.00%)
Iter:799, L1 loss=0.005018, Total loss=0.008075, Time:14
[Iter 800/20000] Loss: 0.0072786 (Best: 0.0064637 @iter796) ([92mâ†“4.10%[0m) [2.89% of initial]
[Iter 800] Gaussian 0 vs 1:
  Original Loss: 0.0065196
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065196 (Pseudo: 0.00%)
[Iter 800] Gaussian 1 vs 0:
  Original Loss: 0.0066094
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066094 (Pseudo: 0.00%)
[Iter 810/20000] Loss: 0.0152791 (Best: 0.0064637 @iter796) ([91mâ†‘109.92%[0m) [6.07% of initial]
[Iter 810] Gaussian 0 vs 1:
  Original Loss: 0.0137210
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0137210 (Pseudo: 0.00%)
[Iter 810] Gaussian 1 vs 0:
  Original Loss: 0.0142203
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0142203 (Pseudo: 0.00%)
[Iter 820/20000] Loss: 0.0104260 (Best: 0.0064637 @iter796) ([92mâ†“31.76%[0m) [4.14% of initial]
[Iter 820] Gaussian 0 vs 1:
  Original Loss: 0.0102699
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0102699 (Pseudo: 0.00%)
[Iter 820] Gaussian 1 vs 0:
  Original Loss: 0.0103150
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0103150 (Pseudo: 0.00%)
[Iter 830/20000] Loss: 0.0089167 (Best: 0.0064637 @iter796) ([92mâ†“14.48%[0m) [3.54% of initial]
[Iter 830] Gaussian 0 vs 1:
  Original Loss: 0.0093644
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0093644 (Pseudo: 0.00%)
[Iter 830] Gaussian 1 vs 0:
  Original Loss: 0.0090817
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0090817 (Pseudo: 0.00%)
[Iter 840/20000] Loss: 0.0080015 (Best: 0.0064637 @iter796) ([92mâ†“10.26%[0m) [3.18% of initial]
[Iter 840] Gaussian 0 vs 1:
  Original Loss: 0.0087314
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087314 (Pseudo: 0.00%)
[Iter 840] Gaussian 1 vs 0:
  Original Loss: 0.0086397
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0086397 (Pseudo: 0.00%)
[Iter 850/20000] Loss: 0.0076434 (Best: 0.0064637 @iter796) ([92mâ†“4.47%[0m) [3.04% of initial]
[Iter 850] Gaussian 0 vs 1:
  Original Loss: 0.0076028
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0076028 (Pseudo: 0.00%)
[Iter 850] Gaussian 1 vs 0:
  Original Loss: 0.0073827
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0073827 (Pseudo: 0.00%)
[Iter 860/20000] Loss: 0.0071295 (Best: 0.0064116 @iter856) ([92mâ†“6.72%[0m) [2.83% of initial]
[Iter 860] Gaussian 0 vs 1:
  Original Loss: 0.0072083
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0072083 (Pseudo: 0.00%)
[Iter 860] Gaussian 1 vs 0:
  Original Loss: 0.0071205
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0071205 (Pseudo: 0.00%)
[Iter 870/20000] Loss: 0.0067272 (Best: 0.0061713 @iter862) ([92mâ†“5.64%[0m) [2.67% of initial]
[Iter 870] Gaussian 0 vs 1:
  Original Loss: 0.0062396
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062396 (Pseudo: 0.00%)
[Iter 870] Gaussian 1 vs 0:
  Original Loss: 0.0062096
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062096 (Pseudo: 0.00%)
[Iter 880/20000] Loss: 0.0067342 (Best: 0.0058690 @iter875) ([91mâ†‘0.10%[0m) [2.68% of initial]
[Iter 880] Gaussian 0 vs 1:
  Original Loss: 0.0068499
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0068499 (Pseudo: 0.00%)
[Iter 880] Gaussian 1 vs 0:
  Original Loss: 0.0067490
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0067490 (Pseudo: 0.00%)
[Iter 890/20000] Loss: 0.0062803 (Best: 0.0057235 @iter884) ([92mâ†“6.74%[0m) [2.50% of initial]
[Iter 890] Gaussian 0 vs 1:
  Original Loss: 0.0057370
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057370 (Pseudo: 0.00%)
[Iter 890] Gaussian 1 vs 0:
  Original Loss: 0.0057240
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057240 (Pseudo: 0.00%)
Iter:899, L1 loss=0.003652, Total loss=0.005587, Time:14
[Iter 900/20000] Loss: 0.0064505 (Best: 0.0055866 @iter899) ([91mâ†‘2.71%[0m) [2.56% of initial]
[Iter 900] Gaussian 0 vs 1:
  Original Loss: 0.0066263
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066263 (Pseudo: 0.00%)
[Iter 900] Gaussian 1 vs 0:
  Original Loss: 0.0066667
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066667 (Pseudo: 0.00%)
[Iter 910/20000] Loss: 0.0066189 (Best: 0.0054380 @iter907) ([91mâ†‘2.61%[0m) [2.63% of initial]
[Iter 910] Gaussian 0 vs 1:
  Original Loss: 0.0069898
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069898 (Pseudo: 0.00%)
[Iter 910] Gaussian 1 vs 0:
  Original Loss: 0.0068097
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0068097 (Pseudo: 0.00%)
[Iter 920/20000] Loss: 0.0059797 (Best: 0.0053167 @iter916) ([92mâ†“9.66%[0m) [2.38% of initial]
[Iter 920] Gaussian 0 vs 1:
  Original Loss: 0.0060827
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060827 (Pseudo: 0.00%)
[Iter 920] Gaussian 1 vs 0:
  Original Loss: 0.0060409
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060409 (Pseudo: 0.00%)
[Iter 930/20000] Loss: 0.0062437 (Best: 0.0052350 @iter925) ([91mâ†‘4.41%[0m) [2.48% of initial]
[Iter 930] Gaussian 0 vs 1:
  Original Loss: 0.0067163
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0067163 (Pseudo: 0.00%)
[Iter 930] Gaussian 1 vs 0:
  Original Loss: 0.0065603
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065603 (Pseudo: 0.00%)
[Iter 940/20000] Loss: 0.0063052 (Best: 0.0052350 @iter925) ([91mâ†‘0.99%[0m) [2.50% of initial]
[Iter 940] Gaussian 0 vs 1:
  Original Loss: 0.0066315
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066315 (Pseudo: 0.00%)
[Iter 940] Gaussian 1 vs 0:
  Original Loss: 0.0065329
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065329 (Pseudo: 0.00%)
[Iter 950/20000] Loss: 0.0059025 (Best: 0.0052204 @iter946) ([92mâ†“6.39%[0m) [2.35% of initial]
[Iter 950] Gaussian 0 vs 1:
  Original Loss: 0.0056459
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0056459 (Pseudo: 0.00%)
[Iter 950] Gaussian 1 vs 0:
  Original Loss: 0.0054311
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0054311 (Pseudo: 0.00%)
[Iter 960/20000] Loss: 0.0060538 (Best: 0.0052204 @iter946) ([91mâ†‘2.56%[0m) [2.41% of initial]
[Iter 960] Gaussian 0 vs 1:
  Original Loss: 0.0063931
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0063931 (Pseudo: 0.00%)
[Iter 960] Gaussian 1 vs 0:
  Original Loss: 0.0062423
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062423 (Pseudo: 0.00%)
[Iter 970/20000] Loss: 0.0060936 (Best: 0.0052204 @iter946) ([91mâ†‘0.66%[0m) [2.42% of initial]
[Iter 970] Gaussian 0 vs 1:
  Original Loss: 0.0060242
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060242 (Pseudo: 0.00%)
[Iter 970] Gaussian 1 vs 0:
  Original Loss: 0.0058642
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058642 (Pseudo: 0.00%)
[Iter 980/20000] Loss: 0.0062135 (Best: 0.0052204 @iter946) ([91mâ†‘1.97%[0m) [2.47% of initial]
[Iter 980] Gaussian 0 vs 1:
  Original Loss: 0.0066441
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066441 (Pseudo: 0.00%)
[Iter 980] Gaussian 1 vs 0:
  Original Loss: 0.0065955
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065955 (Pseudo: 0.00%)
[Iter 990/20000] Loss: 0.0063943 (Best: 0.0052204 @iter946) ([91mâ†‘2.91%[0m) [2.54% of initial]
[Iter 990] Gaussian 0 vs 1:
  Original Loss: 0.0065431
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0065431 (Pseudo: 0.00%)
[Iter 990] Gaussian 1 vs 0:
  Original Loss: 0.0061843
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061843 (Pseudo: 0.00%)
Iter:999, L1 loss=0.004345, Total loss=0.006774, Time:14
[Iter 1000/20000] Loss: 0.0064013 (Best: 0.0052204 @iter946) ([91mâ†‘0.11%[0m) [2.54% of initial]
[Iter 1000] Gaussian 0 vs 1:
  Original Loss: 0.0066241
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066241 (Pseudo: 0.00%)
[Iter 1000] Gaussian 1 vs 0:
  Original Loss: 0.0063582
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0063582 (Pseudo: 0.00%)
[Iter 1010/20000] Loss: 0.0118952 (Best: 0.0052204 @iter946) ([91mâ†‘85.83%[0m) [4.73% of initial]
[Iter 1010] Gaussian 0 vs 1:
  Original Loss: 0.0110860
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0110860 (Pseudo: 0.00%)
[Iter 1010] Gaussian 1 vs 0:
  Original Loss: 0.0111453
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0111453 (Pseudo: 0.00%)
[Iter 1020/20000] Loss: 0.0084708 (Best: 0.0052204 @iter946) ([92mâ†“28.79%[0m) [3.37% of initial]
[Iter 1020] Gaussian 0 vs 1:
  Original Loss: 0.0080464
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0080464 (Pseudo: 0.00%)
[Iter 1020] Gaussian 1 vs 0:
  Original Loss: 0.0077688
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0077688 (Pseudo: 0.00%)
[Iter 1030/20000] Loss: 0.0068693 (Best: 0.0052204 @iter946) ([92mâ†“18.91%[0m) [2.73% of initial]
[Iter 1030] Gaussian 0 vs 1:
  Original Loss: 0.0061249
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061249 (Pseudo: 0.00%)
[Iter 1030] Gaussian 1 vs 0:
  Original Loss: 0.0058401
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058401 (Pseudo: 0.00%)
[Iter 1040/20000] Loss: 0.0059400 (Best: 0.0052204 @iter946) ([92mâ†“13.53%[0m) [2.36% of initial]
[Iter 1040] Gaussian 0 vs 1:
  Original Loss: 0.0058220
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058220 (Pseudo: 0.00%)
[Iter 1040] Gaussian 1 vs 0:
  Original Loss: 0.0059611
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0059611 (Pseudo: 0.00%)
[Iter 1050/20000] Loss: 0.0058424 (Best: 0.0051647 @iter1049) ([92mâ†“1.64%[0m) [2.32% of initial]
[Iter 1050] Gaussian 0 vs 1:
  Original Loss: 0.0059484
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0059484 (Pseudo: 0.00%)
[Iter 1050] Gaussian 1 vs 0:
  Original Loss: 0.0059871
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0059871 (Pseudo: 0.00%)
[Iter 1060/20000] Loss: 0.0057332 (Best: 0.0049453 @iter1055) ([92mâ†“1.87%[0m) [2.28% of initial]
[Iter 1060] Gaussian 0 vs 1:
  Original Loss: 0.0058894
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058894 (Pseudo: 0.00%)
[Iter 1060] Gaussian 1 vs 0:
  Original Loss: 0.0057905
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057905 (Pseudo: 0.00%)
[Iter 1070/20000] Loss: 0.0054658 (Best: 0.0045379 @iter1066) ([92mâ†“4.66%[0m) [2.17% of initial]
[Iter 1070] Gaussian 0 vs 1:
  Original Loss: 0.0060349
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060349 (Pseudo: 0.00%)
[Iter 1070] Gaussian 1 vs 0:
  Original Loss: 0.0058870
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0058870 (Pseudo: 0.00%)
[Iter 1080/20000] Loss: 0.0051875 (Best: 0.0045379 @iter1066) ([92mâ†“5.09%[0m) [2.06% of initial]
[Iter 1080] Gaussian 0 vs 1:
  Original Loss: 0.0048912
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048912 (Pseudo: 0.00%)
[Iter 1080] Gaussian 1 vs 0:
  Original Loss: 0.0048083
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048083 (Pseudo: 0.00%)
[Iter 1090/20000] Loss: 0.0050573 (Best: 0.0044906 @iter1082) ([92mâ†“2.51%[0m) [2.01% of initial]
[Iter 1090] Gaussian 0 vs 1:
  Original Loss: 0.0049748
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049748 (Pseudo: 0.00%)
[Iter 1090] Gaussian 1 vs 0:
  Original Loss: 0.0049022
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049022 (Pseudo: 0.00%)
Iter:1099, L1 loss=0.003485, Total loss=0.004989, Time:14
[Iter 1100/20000] Loss: 0.0049005 (Best: 0.0042519 @iter1093) ([92mâ†“3.10%[0m) [1.95% of initial]
[Iter 1100] Gaussian 0 vs 1:
  Original Loss: 0.0045945
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045945 (Pseudo: 0.00%)
[Iter 1100] Gaussian 1 vs 0:
  Original Loss: 0.0046067
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046067 (Pseudo: 0.00%)
[Iter 1110/20000] Loss: 0.0050984 (Best: 0.0042519 @iter1093) ([91mâ†‘4.04%[0m) [2.03% of initial]
[Iter 1110] Gaussian 0 vs 1:
  Original Loss: 0.0048770
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048770 (Pseudo: 0.00%)
[Iter 1110] Gaussian 1 vs 0:
  Original Loss: 0.0047438
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047438 (Pseudo: 0.00%)
[Iter 1120/20000] Loss: 0.0050290 (Best: 0.0041586 @iter1117) ([92mâ†“1.36%[0m) [2.00% of initial]
[Iter 1120] Gaussian 0 vs 1:
  Original Loss: 0.0049384
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049384 (Pseudo: 0.00%)
[Iter 1120] Gaussian 1 vs 0:
  Original Loss: 0.0049461
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049461 (Pseudo: 0.00%)
[Iter 1130/20000] Loss: 0.0052986 (Best: 0.0041586 @iter1117) ([91mâ†‘5.36%[0m) [2.11% of initial]
[Iter 1130] Gaussian 0 vs 1:
  Original Loss: 0.0056109
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0056109 (Pseudo: 0.00%)
[Iter 1130] Gaussian 1 vs 0:
  Original Loss: 0.0054502
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0054502 (Pseudo: 0.00%)
[Iter 1140/20000] Loss: 0.0047730 (Best: 0.0041325 @iter1135) ([92mâ†“9.92%[0m) [1.90% of initial]
[Iter 1140] Gaussian 0 vs 1:
  Original Loss: 0.0047845
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047845 (Pseudo: 0.00%)
[Iter 1140] Gaussian 1 vs 0:
  Original Loss: 0.0048541
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048541 (Pseudo: 0.00%)
[Iter 1150/20000] Loss: 0.0045447 (Best: 0.0040237 @iter1145) ([92mâ†“4.78%[0m) [1.81% of initial]
[Iter 1150] Gaussian 0 vs 1:
  Original Loss: 0.0041806
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0041806 (Pseudo: 0.00%)
[Iter 1150] Gaussian 1 vs 0:
  Original Loss: 0.0040689
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040689 (Pseudo: 0.00%)
[Iter 1160/20000] Loss: 0.0050417 (Best: 0.0040237 @iter1145) ([91mâ†‘10.94%[0m) [2.00% of initial]
[Iter 1160] Gaussian 0 vs 1:
  Original Loss: 0.0048474
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0048474 (Pseudo: 0.00%)
[Iter 1160] Gaussian 1 vs 0:
  Original Loss: 0.0050079
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0050079 (Pseudo: 0.00%)
[Iter 1170/20000] Loss: 0.0046799 (Best: 0.0040237 @iter1145) ([92mâ†“7.18%[0m) [1.86% of initial]
[Iter 1170] Gaussian 0 vs 1:
  Original Loss: 0.0044233
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044233 (Pseudo: 0.00%)
[Iter 1170] Gaussian 1 vs 0:
  Original Loss: 0.0044434
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044434 (Pseudo: 0.00%)
[Iter 1180/20000] Loss: 0.0043715 (Best: 0.0039724 @iter1180) ([92mâ†“6.59%[0m) [1.74% of initial]
[Iter 1180] Gaussian 0 vs 1:
  Original Loss: 0.0039724
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039724 (Pseudo: 0.00%)
[Iter 1180] Gaussian 1 vs 0:
  Original Loss: 0.0039913
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039913 (Pseudo: 0.00%)
[Iter 1190/20000] Loss: 0.0046370 (Best: 0.0039724 @iter1180) ([91mâ†‘6.07%[0m) [1.84% of initial]
[Iter 1190] Gaussian 0 vs 1:
  Original Loss: 0.0044128
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044128 (Pseudo: 0.00%)
[Iter 1190] Gaussian 1 vs 0:
  Original Loss: 0.0043338
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043338 (Pseudo: 0.00%)
Iter:1199, L1 loss=0.003392, Total loss=0.004931, Time:14
[Iter 1200/20000] Loss: 0.0046300 (Best: 0.0038497 @iter1192) ([92mâ†“0.15%[0m) [1.84% of initial]
[Iter 1200] Gaussian 0 vs 1:
  Original Loss: 0.0046861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046861 (Pseudo: 0.00%)
[Iter 1200] Gaussian 1 vs 0:
  Original Loss: 0.0044913
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044913 (Pseudo: 0.00%)
[Iter 1210/20000] Loss: 0.0112805 (Best: 0.0038497 @iter1192) ([91mâ†‘143.64%[0m) [4.48% of initial]
[Iter 1210] Gaussian 0 vs 1:
  Original Loss: 0.0102415
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0102415 (Pseudo: 0.00%)
[Iter 1210] Gaussian 1 vs 0:
  Original Loss: 0.0097431
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0097431 (Pseudo: 0.00%)
[Iter 1220/20000] Loss: 0.0069370 (Best: 0.0038497 @iter1192) ([92mâ†“38.50%[0m) [2.76% of initial]
[Iter 1220] Gaussian 0 vs 1:
  Original Loss: 0.0061284
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061284 (Pseudo: 0.00%)
[Iter 1220] Gaussian 1 vs 0:
  Original Loss: 0.0061501
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061501 (Pseudo: 0.00%)
[Iter 1230/20000] Loss: 0.0060462 (Best: 0.0038497 @iter1192) ([92mâ†“12.84%[0m) [2.40% of initial]
[Iter 1230] Gaussian 0 vs 1:
  Original Loss: 0.0064972
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0064972 (Pseudo: 0.00%)
[Iter 1230] Gaussian 1 vs 0:
  Original Loss: 0.0061536
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0061536 (Pseudo: 0.00%)
[Iter 1240/20000] Loss: 0.0054401 (Best: 0.0038497 @iter1192) ([92mâ†“10.02%[0m) [2.16% of initial]
[Iter 1240] Gaussian 0 vs 1:
  Original Loss: 0.0055948
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0055948 (Pseudo: 0.00%)
[Iter 1240] Gaussian 1 vs 0:
  Original Loss: 0.0053289
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0053289 (Pseudo: 0.00%)
[Iter 1250/20000] Loss: 0.0047517 (Best: 0.0038497 @iter1192) ([92mâ†“12.65%[0m) [1.89% of initial]
[Iter 1250] Gaussian 0 vs 1:
  Original Loss: 0.0045857
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045857 (Pseudo: 0.00%)
[Iter 1250] Gaussian 1 vs 0:
  Original Loss: 0.0046398
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046398 (Pseudo: 0.00%)
[Iter 1260/20000] Loss: 0.0046090 (Best: 0.0037383 @iter1258) ([92mâ†“3.00%[0m) [1.83% of initial]
[Iter 1260] Gaussian 0 vs 1:
  Original Loss: 0.0051981
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0051981 (Pseudo: 0.00%)
[Iter 1260] Gaussian 1 vs 0:
  Original Loss: 0.0050528
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0050528 (Pseudo: 0.00%)
[Iter 1270/20000] Loss: 0.0041134 (Best: 0.0037324 @iter1269) ([92mâ†“10.75%[0m) [1.63% of initial]
[Iter 1270] Gaussian 0 vs 1:
  Original Loss: 0.0040533
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040533 (Pseudo: 0.00%)
[Iter 1270] Gaussian 1 vs 0:
  Original Loss: 0.0040810
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040810 (Pseudo: 0.00%)
[Iter 1280/20000] Loss: 0.0043556 (Best: 0.0033887 @iter1273) ([91mâ†‘5.89%[0m) [1.73% of initial]
[Iter 1280] Gaussian 0 vs 1:
  Original Loss: 0.0042083
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0042083 (Pseudo: 0.00%)
[Iter 1280] Gaussian 1 vs 0:
  Original Loss: 0.0043291
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043291 (Pseudo: 0.00%)
[Iter 1290/20000] Loss: 0.0042341 (Best: 0.0033288 @iter1288) ([92mâ†“2.79%[0m) [1.68% of initial]
[Iter 1290] Gaussian 0 vs 1:
  Original Loss: 0.0047543
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047543 (Pseudo: 0.00%)
[Iter 1290] Gaussian 1 vs 0:
  Original Loss: 0.0047068
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0047068 (Pseudo: 0.00%)
Iter:1299, L1 loss=0.002782, Total loss=0.003615, Time:13
[Iter 1300/20000] Loss: 0.0039849 (Best: 0.0033288 @iter1288) ([92mâ†“5.89%[0m) [1.58% of initial]
[Iter 1300] Gaussian 0 vs 1:
  Original Loss: 0.0039749
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039749 (Pseudo: 0.00%)
[Iter 1300] Gaussian 1 vs 0:
  Original Loss: 0.0041416
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0041416 (Pseudo: 0.00%)
[Iter 1310/20000] Loss: 0.0040037 (Best: 0.0033161 @iter1301) ([91mâ†‘0.47%[0m) [1.59% of initial]
[Iter 1310] Gaussian 0 vs 1:
  Original Loss: 0.0037666
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037666 (Pseudo: 0.00%)
[Iter 1310] Gaussian 1 vs 0:
  Original Loss: 0.0038018
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038018 (Pseudo: 0.00%)
[Iter 1320/20000] Loss: 0.0038967 (Best: 0.0031011 @iter1319) ([92mâ†“2.67%[0m) [1.55% of initial]
[Iter 1320] Gaussian 0 vs 1:
  Original Loss: 0.0045494
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045494 (Pseudo: 0.00%)
[Iter 1320] Gaussian 1 vs 0:
  Original Loss: 0.0044507
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044507 (Pseudo: 0.00%)
[Iter 1330/20000] Loss: 0.0039666 (Best: 0.0030481 @iter1321) ([91mâ†‘1.79%[0m) [1.58% of initial]
[Iter 1330] Gaussian 0 vs 1:
  Original Loss: 0.0041565
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0041565 (Pseudo: 0.00%)
[Iter 1330] Gaussian 1 vs 0:
  Original Loss: 0.0040524
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040524 (Pseudo: 0.00%)
[Iter 1340/20000] Loss: 0.0037236 (Best: 0.0030481 @iter1321) ([92mâ†“6.13%[0m) [1.48% of initial]
[Iter 1340] Gaussian 0 vs 1:
  Original Loss: 0.0033659
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0033659 (Pseudo: 0.00%)
[Iter 1340] Gaussian 1 vs 0:
  Original Loss: 0.0033322
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0033322 (Pseudo: 0.00%)
[Iter 1350/20000] Loss: 0.0037979 (Best: 0.0030481 @iter1321) ([91mâ†‘2.00%[0m) [1.51% of initial]
[Iter 1350] Gaussian 0 vs 1:
  Original Loss: 0.0033737
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0033737 (Pseudo: 0.00%)
[Iter 1350] Gaussian 1 vs 0:
  Original Loss: 0.0032764
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032764 (Pseudo: 0.00%)
[Iter 1360/20000] Loss: 0.0038875 (Best: 0.0030481 @iter1321) ([91mâ†‘2.36%[0m) [1.54% of initial]
[Iter 1360] Gaussian 0 vs 1:
  Original Loss: 0.0037958
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037958 (Pseudo: 0.00%)
[Iter 1360] Gaussian 1 vs 0:
  Original Loss: 0.0035427
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035427 (Pseudo: 0.00%)
[Iter 1370/20000] Loss: 0.0037024 (Best: 0.0030481 @iter1321) ([92mâ†“4.76%[0m) [1.47% of initial]
[Iter 1370] Gaussian 0 vs 1:
  Original Loss: 0.0032455
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032455 (Pseudo: 0.00%)
[Iter 1370] Gaussian 1 vs 0:
  Original Loss: 0.0031189
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031189 (Pseudo: 0.00%)
[Iter 1380/20000] Loss: 0.0039643 (Best: 0.0030481 @iter1321) ([91mâ†‘7.07%[0m) [1.57% of initial]
[Iter 1380] Gaussian 0 vs 1:
  Original Loss: 0.0039208
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039208 (Pseudo: 0.00%)
[Iter 1380] Gaussian 1 vs 0:
  Original Loss: 0.0038356
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038356 (Pseudo: 0.00%)
[Iter 1390/20000] Loss: 0.0037643 (Best: 0.0030481 @iter1321) ([92mâ†“5.05%[0m) [1.50% of initial]
[Iter 1390] Gaussian 0 vs 1:
  Original Loss: 0.0036368
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0036368 (Pseudo: 0.00%)
[Iter 1390] Gaussian 1 vs 0:
  Original Loss: 0.0034566
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034566 (Pseudo: 0.00%)
Iter:1399, L1 loss=0.002266, Total loss=0.002966, Time:13
[Iter 1400/20000] Loss: 0.0034687 (Best: 0.0029658 @iter1399) ([92mâ†“7.85%[0m) [1.38% of initial]
[Iter 1400] Gaussian 0 vs 1:
  Original Loss: 0.0035717
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035717 (Pseudo: 0.00%)
[Iter 1400] Gaussian 1 vs 0:
  Original Loss: 0.0034101
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034101 (Pseudo: 0.00%)
[Iter 1410/20000] Loss: 0.0090176 (Best: 0.0029658 @iter1399) ([91mâ†‘159.97%[0m) [3.58% of initial]
[Iter 1410] Gaussian 0 vs 1:
  Original Loss: 0.0087644
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0087644 (Pseudo: 0.00%)
[Iter 1410] Gaussian 1 vs 0:
  Original Loss: 0.0085339
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0085339 (Pseudo: 0.00%)
[Iter 1420/20000] Loss: 0.0060504 (Best: 0.0029658 @iter1399) ([92mâ†“32.90%[0m) [2.40% of initial]
[Iter 1420] Gaussian 0 vs 1:
  Original Loss: 0.0057289
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0057289 (Pseudo: 0.00%)
[Iter 1420] Gaussian 1 vs 0:
  Original Loss: 0.0056041
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0056041 (Pseudo: 0.00%)
[Iter 1430/20000] Loss: 0.0050223 (Best: 0.0029658 @iter1399) ([92mâ†“16.99%[0m) [2.00% of initial]
[Iter 1430] Gaussian 0 vs 1:
  Original Loss: 0.0043139
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043139 (Pseudo: 0.00%)
[Iter 1430] Gaussian 1 vs 0:
  Original Loss: 0.0043868
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043868 (Pseudo: 0.00%)
[Iter 1440/20000] Loss: 0.0044881 (Best: 0.0029658 @iter1399) ([92mâ†“10.64%[0m) [1.78% of initial]
[Iter 1440] Gaussian 0 vs 1:
  Original Loss: 0.0044477
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044477 (Pseudo: 0.00%)
[Iter 1440] Gaussian 1 vs 0:
  Original Loss: 0.0045174
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0045174 (Pseudo: 0.00%)
[Iter 1450/20000] Loss: 0.0035636 (Best: 0.0029658 @iter1399) ([92mâ†“20.60%[0m) [1.42% of initial]
[Iter 1450] Gaussian 0 vs 1:
  Original Loss: 0.0031826
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031826 (Pseudo: 0.00%)
[Iter 1450] Gaussian 1 vs 0:
  Original Loss: 0.0031111
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031111 (Pseudo: 0.00%)
[Iter 1460/20000] Loss: 0.0036491 (Best: 0.0029658 @iter1399) ([91mâ†‘2.40%[0m) [1.45% of initial]
[Iter 1460] Gaussian 0 vs 1:
  Original Loss: 0.0037542
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037542 (Pseudo: 0.00%)
[Iter 1460] Gaussian 1 vs 0:
  Original Loss: 0.0035345
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035345 (Pseudo: 0.00%)
[Iter 1470/20000] Loss: 0.0034877 (Best: 0.0029658 @iter1399) ([92mâ†“4.42%[0m) [1.39% of initial]
[Iter 1470] Gaussian 0 vs 1:
  Original Loss: 0.0031401
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031401 (Pseudo: 0.00%)
[Iter 1470] Gaussian 1 vs 0:
  Original Loss: 0.0030656
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0030656 (Pseudo: 0.00%)
[Iter 1480/20000] Loss: 0.0033352 (Best: 0.0027651 @iter1480) ([92mâ†“4.37%[0m) [1.33% of initial]
[Iter 1480] Gaussian 0 vs 1:
  Original Loss: 0.0027651
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027651 (Pseudo: 0.00%)
[Iter 1480] Gaussian 1 vs 0:
  Original Loss: 0.0027461
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027461 (Pseudo: 0.00%)
[Iter 1490/20000] Loss: 0.0032731 (Best: 0.0027651 @iter1480) ([92mâ†“1.86%[0m) [1.30% of initial]
[Iter 1490] Gaussian 0 vs 1:
  Original Loss: 0.0032476
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032476 (Pseudo: 0.00%)
[Iter 1490] Gaussian 1 vs 0:
  Original Loss: 0.0031494
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031494 (Pseudo: 0.00%)
Iter:1499, L1 loss=0.002505, Total loss=0.003348, Time:13
[Iter 1500/20000] Loss: 0.0032264 (Best: 0.0027651 @iter1480) ([92mâ†“1.43%[0m) [1.28% of initial]
[Iter 1500] Gaussian 0 vs 1:
  Original Loss: 0.0029305
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029305 (Pseudo: 0.00%)
[Iter 1500] Gaussian 1 vs 0:
  Original Loss: 0.0028685
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028685 (Pseudo: 0.00%)
[Iter 1510/20000] Loss: 0.0030767 (Best: 0.0025984 @iter1504) ([92mâ†“4.64%[0m) [1.22% of initial]
[Iter 1510] Gaussian 0 vs 1:
  Original Loss: 0.0027949
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027949 (Pseudo: 0.00%)
[Iter 1510] Gaussian 1 vs 0:
  Original Loss: 0.0027258
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027258 (Pseudo: 0.00%)
[Iter 1520/20000] Loss: 0.0030451 (Best: 0.0025810 @iter1520) ([92mâ†“1.03%[0m) [1.21% of initial]
[Iter 1520] Gaussian 0 vs 1:
  Original Loss: 0.0025810
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025810 (Pseudo: 0.00%)
[Iter 1520] Gaussian 1 vs 0:
  Original Loss: 0.0025351
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025351 (Pseudo: 0.00%)
[Iter 1530/20000] Loss: 0.0032258 (Best: 0.0025554 @iter1526) ([91mâ†‘5.93%[0m) [1.28% of initial]
[Iter 1530] Gaussian 0 vs 1:
  Original Loss: 0.0032819
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032819 (Pseudo: 0.00%)
[Iter 1530] Gaussian 1 vs 0:
  Original Loss: 0.0031134
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031134 (Pseudo: 0.00%)
[Iter 1540/20000] Loss: 0.0031101 (Best: 0.0025554 @iter1526) ([92mâ†“3.59%[0m) [1.24% of initial]
[Iter 1540] Gaussian 0 vs 1:
  Original Loss: 0.0028985
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028985 (Pseudo: 0.00%)
[Iter 1540] Gaussian 1 vs 0:
  Original Loss: 0.0027851
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027851 (Pseudo: 0.00%)
[Iter 1550/20000] Loss: 0.0031275 (Best: 0.0025554 @iter1526) ([91mâ†‘0.56%[0m) [1.24% of initial]
[Iter 1550] Gaussian 0 vs 1:
  Original Loss: 0.0030683
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0030683 (Pseudo: 0.00%)
[Iter 1550] Gaussian 1 vs 0:
  Original Loss: 0.0028907
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028907 (Pseudo: 0.00%)
[Iter 1560/20000] Loss: 0.0032943 (Best: 0.0025554 @iter1526) ([91mâ†‘5.33%[0m) [1.31% of initial]
[Iter 1560] Gaussian 0 vs 1:
  Original Loss: 0.0038661
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038661 (Pseudo: 0.00%)
[Iter 1560] Gaussian 1 vs 0:
  Original Loss: 0.0038242
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038242 (Pseudo: 0.00%)
[Iter 1570/20000] Loss: 0.0028161 (Best: 0.0025457 @iter1569) ([92mâ†“14.52%[0m) [1.12% of initial]
[Iter 1570] Gaussian 0 vs 1:
  Original Loss: 0.0026708
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026708 (Pseudo: 0.00%)
[Iter 1570] Gaussian 1 vs 0:
  Original Loss: 0.0026786
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026786 (Pseudo: 0.00%)
[Iter 1580/20000] Loss: 0.0028547 (Best: 0.0023658 @iter1573) ([91mâ†‘1.37%[0m) [1.13% of initial]
[Iter 1580] Gaussian 0 vs 1:
  Original Loss: 0.0029220
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029220 (Pseudo: 0.00%)
[Iter 1580] Gaussian 1 vs 0:
  Original Loss: 0.0029874
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029874 (Pseudo: 0.00%)
[Iter 1590/20000] Loss: 0.0027772 (Best: 0.0023658 @iter1573) ([92mâ†“2.72%[0m) [1.10% of initial]
[Iter 1590] Gaussian 0 vs 1:
  Original Loss: 0.0025625
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025625 (Pseudo: 0.00%)
[Iter 1590] Gaussian 1 vs 0:
  Original Loss: 0.0024796
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024796 (Pseudo: 0.00%)
Iter:1599, L1 loss=0.002648, Total loss=0.003395, Time:13
[Iter 1600/20000] Loss: 0.0030716 (Best: 0.0023415 @iter1591) ([91mâ†‘10.60%[0m) [1.22% of initial]
[Iter 1600] Gaussian 0 vs 1:
  Original Loss: 0.0032684
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032684 (Pseudo: 0.00%)
[Iter 1600] Gaussian 1 vs 0:
  Original Loss: 0.0032044
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032044 (Pseudo: 0.00%)
[Iter 1610/20000] Loss: 0.0084165 (Best: 0.0023415 @iter1591) ([91mâ†‘174.01%[0m) [3.34% of initial]
[Iter 1610] Gaussian 0 vs 1:
  Original Loss: 0.0072288
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0072288 (Pseudo: 0.00%)
[Iter 1610] Gaussian 1 vs 0:
  Original Loss: 0.0074115
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0074115 (Pseudo: 0.00%)
[Iter 1620/20000] Loss: 0.0054665 (Best: 0.0023415 @iter1591) ([92mâ†“35.05%[0m) [2.17% of initial]
[Iter 1620] Gaussian 0 vs 1:
  Original Loss: 0.0060430
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060430 (Pseudo: 0.00%)
[Iter 1620] Gaussian 1 vs 0:
  Original Loss: 0.0060418
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060418 (Pseudo: 0.00%)
[Iter 1630/20000] Loss: 0.0040720 (Best: 0.0023415 @iter1591) ([92mâ†“25.51%[0m) [1.62% of initial]
[Iter 1630] Gaussian 0 vs 1:
  Original Loss: 0.0035955
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035955 (Pseudo: 0.00%)
[Iter 1630] Gaussian 1 vs 0:
  Original Loss: 0.0035838
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0035838 (Pseudo: 0.00%)
[Iter 1640/20000] Loss: 0.0038469 (Best: 0.0023415 @iter1591) ([92mâ†“5.53%[0m) [1.53% of initial]
[Iter 1640] Gaussian 0 vs 1:
  Original Loss: 0.0043440
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043440 (Pseudo: 0.00%)
[Iter 1640] Gaussian 1 vs 0:
  Original Loss: 0.0043648
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0043648 (Pseudo: 0.00%)
[Iter 1650/20000] Loss: 0.0034028 (Best: 0.0023415 @iter1591) ([92mâ†“11.54%[0m) [1.35% of initial]
[Iter 1650] Gaussian 0 vs 1:
  Original Loss: 0.0034259
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034259 (Pseudo: 0.00%)
[Iter 1650] Gaussian 1 vs 0:
  Original Loss: 0.0034279
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0034279 (Pseudo: 0.00%)
[Iter 1660/20000] Loss: 0.0029348 (Best: 0.0023415 @iter1591) ([92mâ†“13.75%[0m) [1.17% of initial]
[Iter 1660] Gaussian 0 vs 1:
  Original Loss: 0.0025539
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025539 (Pseudo: 0.00%)
[Iter 1660] Gaussian 1 vs 0:
  Original Loss: 0.0024665
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024665 (Pseudo: 0.00%)
[Iter 1670/20000] Loss: 0.0027250 (Best: 0.0022377 @iter1669) ([92mâ†“7.15%[0m) [1.08% of initial]
[Iter 1670] Gaussian 0 vs 1:
  Original Loss: 0.0027261
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027261 (Pseudo: 0.00%)
[Iter 1670] Gaussian 1 vs 0:
  Original Loss: 0.0027722
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027722 (Pseudo: 0.00%)
[Iter 1680/20000] Loss: 0.0029824 (Best: 0.0022377 @iter1669) ([91mâ†‘9.45%[0m) [1.18% of initial]
[Iter 1680] Gaussian 0 vs 1:
  Original Loss: 0.0028817
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028817 (Pseudo: 0.00%)
[Iter 1680] Gaussian 1 vs 0:
  Original Loss: 0.0026041
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026041 (Pseudo: 0.00%)
[Iter 1690/20000] Loss: 0.0031696 (Best: 0.0022377 @iter1669) ([91mâ†‘6.28%[0m) [1.26% of initial]
[Iter 1690] Gaussian 0 vs 1:
  Original Loss: 0.0029565
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029565 (Pseudo: 0.00%)
[Iter 1690] Gaussian 1 vs 0:
  Original Loss: 0.0027443
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027443 (Pseudo: 0.00%)
Iter:1699, L1 loss=0.002619, Total loss=0.003281, Time:13
[Iter 1700/20000] Loss: 0.0028313 (Best: 0.0022377 @iter1669) ([92mâ†“10.67%[0m) [1.12% of initial]
[Iter 1700] Gaussian 0 vs 1:
  Original Loss: 0.0024241
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024241 (Pseudo: 0.00%)
[Iter 1700] Gaussian 1 vs 0:
  Original Loss: 0.0023661
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023661 (Pseudo: 0.00%)
[Iter 1710/20000] Loss: 0.0030485 (Best: 0.0022377 @iter1669) ([91mâ†‘7.67%[0m) [1.21% of initial]
[Iter 1710] Gaussian 0 vs 1:
  Original Loss: 0.0031695
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031695 (Pseudo: 0.00%)
[Iter 1710] Gaussian 1 vs 0:
  Original Loss: 0.0031918
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031918 (Pseudo: 0.00%)
[Iter 1720/20000] Loss: 0.0025166 (Best: 0.0022377 @iter1669) ([92mâ†“17.45%[0m) [1.00% of initial]
[Iter 1720] Gaussian 0 vs 1:
  Original Loss: 0.0022935
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022935 (Pseudo: 0.00%)
[Iter 1720] Gaussian 1 vs 0:
  Original Loss: 0.0022894
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022894 (Pseudo: 0.00%)
[Iter 1730/20000] Loss: 0.0025801 (Best: 0.0022285 @iter1726) ([91mâ†‘2.52%[0m) [1.03% of initial]
[Iter 1730] Gaussian 0 vs 1:
  Original Loss: 0.0023047
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023047 (Pseudo: 0.00%)
[Iter 1730] Gaussian 1 vs 0:
  Original Loss: 0.0022506
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022506 (Pseudo: 0.00%)
[Iter 1740/20000] Loss: 0.0024981 (Best: 0.0021822 @iter1738) ([92mâ†“3.18%[0m) [0.99% of initial]
[Iter 1740] Gaussian 0 vs 1:
  Original Loss: 0.0023131
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023131 (Pseudo: 0.00%)
[Iter 1740] Gaussian 1 vs 0:
  Original Loss: 0.0022769
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022769 (Pseudo: 0.00%)
[Iter 1750/20000] Loss: 0.0023554 (Best: 0.0020337 @iter1742) ([92mâ†“5.71%[0m) [0.94% of initial]
[Iter 1750] Gaussian 0 vs 1:
  Original Loss: 0.0020960
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020960 (Pseudo: 0.00%)
[Iter 1750] Gaussian 1 vs 0:
  Original Loss: 0.0020044
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020044 (Pseudo: 0.00%)
[Iter 1760/20000] Loss: 0.0027007 (Best: 0.0020337 @iter1742) ([91mâ†‘14.66%[0m) [1.07% of initial]
[Iter 1760] Gaussian 0 vs 1:
  Original Loss: 0.0026516
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026516 (Pseudo: 0.00%)
[Iter 1760] Gaussian 1 vs 0:
  Original Loss: 0.0024420
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024420 (Pseudo: 0.00%)
[Iter 1770/20000] Loss: 0.0024499 (Best: 0.0020337 @iter1742) ([92mâ†“9.29%[0m) [0.97% of initial]
[Iter 1770] Gaussian 0 vs 1:
  Original Loss: 0.0024179
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024179 (Pseudo: 0.00%)
[Iter 1770] Gaussian 1 vs 0:
  Original Loss: 0.0023375
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023375 (Pseudo: 0.00%)
[Iter 1780/20000] Loss: 0.0024942 (Best: 0.0020337 @iter1742) ([91mâ†‘1.81%[0m) [0.99% of initial]
[Iter 1780] Gaussian 0 vs 1:
  Original Loss: 0.0026557
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026557 (Pseudo: 0.00%)
[Iter 1780] Gaussian 1 vs 0:
  Original Loss: 0.0026901
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026901 (Pseudo: 0.00%)
[Iter 1790/20000] Loss: 0.0021947 (Best: 0.0017947 @iter1789) ([92mâ†“12.01%[0m) [0.87% of initial]
[Iter 1790] Gaussian 0 vs 1:
  Original Loss: 0.0022580
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022580 (Pseudo: 0.00%)
[Iter 1790] Gaussian 1 vs 0:
  Original Loss: 0.0021683
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021683 (Pseudo: 0.00%)
Iter:1799, L1 loss=0.001658, Total loss=0.001923, Time:13
[Iter 1800/20000] Loss: 0.0022046 (Best: 0.0017947 @iter1789) ([91mâ†‘0.45%[0m) [0.88% of initial]
[Iter 1800] Gaussian 0 vs 1:
  Original Loss: 0.0021755
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021755 (Pseudo: 0.00%)
[Iter 1800] Gaussian 1 vs 0:
  Original Loss: 0.0021331
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021331 (Pseudo: 0.00%)
[Iter 1810/20000] Loss: 0.0074789 (Best: 0.0017947 @iter1789) ([91mâ†‘239.25%[0m) [2.97% of initial]
[Iter 1810] Gaussian 0 vs 1:
  Original Loss: 0.0066157
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0066157 (Pseudo: 0.00%)
[Iter 1810] Gaussian 1 vs 0:
  Original Loss: 0.0069806
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0069806 (Pseudo: 0.00%)
[Iter 1820/20000] Loss: 0.0043898 (Best: 0.0017947 @iter1789) ([92mâ†“41.30%[0m) [1.74% of initial]
[Iter 1820] Gaussian 0 vs 1:
  Original Loss: 0.0044454
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0044454 (Pseudo: 0.00%)
[Iter 1820] Gaussian 1 vs 0:
  Original Loss: 0.0046795
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0046795 (Pseudo: 0.00%)
[Iter 1830/20000] Loss: 0.0039609 (Best: 0.0017947 @iter1789) ([92mâ†“9.77%[0m) [1.57% of initial]
[Iter 1830] Gaussian 0 vs 1:
  Original Loss: 0.0038922
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0038922 (Pseudo: 0.00%)
[Iter 1830] Gaussian 1 vs 0:
  Original Loss: 0.0036706
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0036706 (Pseudo: 0.00%)
[Iter 1840/20000] Loss: 0.0027439 (Best: 0.0017947 @iter1789) ([92mâ†“30.73%[0m) [1.09% of initial]
[Iter 1840] Gaussian 0 vs 1:
  Original Loss: 0.0023904
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023904 (Pseudo: 0.00%)
[Iter 1840] Gaussian 1 vs 0:
  Original Loss: 0.0023449
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023449 (Pseudo: 0.00%)
[Iter 1850/20000] Loss: 0.0026190 (Best: 0.0017947 @iter1789) ([92mâ†“4.55%[0m) [1.04% of initial]
[Iter 1850] Gaussian 0 vs 1:
  Original Loss: 0.0023982
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023982 (Pseudo: 0.00%)
[Iter 1850] Gaussian 1 vs 0:
  Original Loss: 0.0023577
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023577 (Pseudo: 0.00%)
[Iter 1860/20000] Loss: 0.0023776 (Best: 0.0017947 @iter1789) ([92mâ†“9.22%[0m) [0.94% of initial]
[Iter 1860] Gaussian 0 vs 1:
  Original Loss: 0.0021776
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021776 (Pseudo: 0.00%)
[Iter 1860] Gaussian 1 vs 0:
  Original Loss: 0.0021057
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021057 (Pseudo: 0.00%)
[Iter 1870/20000] Loss: 0.0022259 (Best: 0.0017947 @iter1789) ([92mâ†“6.38%[0m) [0.88% of initial]
[Iter 1870] Gaussian 0 vs 1:
  Original Loss: 0.0020362
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020362 (Pseudo: 0.00%)
[Iter 1870] Gaussian 1 vs 0:
  Original Loss: 0.0019076
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019076 (Pseudo: 0.00%)
[Iter 1880/20000] Loss: 0.0021042 (Best: 0.0017947 @iter1789) ([92mâ†“5.47%[0m) [0.84% of initial]
[Iter 1880] Gaussian 0 vs 1:
  Original Loss: 0.0018354
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018354 (Pseudo: 0.00%)
[Iter 1880] Gaussian 1 vs 0:
  Original Loss: 0.0017910
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017910 (Pseudo: 0.00%)
[Iter 1890/20000] Loss: 0.0019212 (Best: 0.0017709 @iter1890) ([92mâ†“8.70%[0m) [0.76% of initial]
[Iter 1890] Gaussian 0 vs 1:
  Original Loss: 0.0017709
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017709 (Pseudo: 0.00%)
[Iter 1890] Gaussian 1 vs 0:
  Original Loss: 0.0016648
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016648 (Pseudo: 0.00%)
Iter:1899, L1 loss=0.001697, Total loss=0.001929, Time:14
[Iter 1900/20000] Loss: 0.0019956 (Best: 0.0016208 @iter1891) ([91mâ†‘3.87%[0m) [0.79% of initial]
[Iter 1900] Gaussian 0 vs 1:
  Original Loss: 0.0018667
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018667 (Pseudo: 0.00%)
[Iter 1900] Gaussian 1 vs 0:
  Original Loss: 0.0017981
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017981 (Pseudo: 0.00%)
[Iter 1910/20000] Loss: 0.0020840 (Best: 0.0016208 @iter1891) ([91mâ†‘4.43%[0m) [0.83% of initial]
[Iter 1910] Gaussian 0 vs 1:
  Original Loss: 0.0018534
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018534 (Pseudo: 0.00%)
[Iter 1910] Gaussian 1 vs 0:
  Original Loss: 0.0017633
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017633 (Pseudo: 0.00%)
[Iter 1920/20000] Loss: 0.0021427 (Best: 0.0016208 @iter1891) ([91mâ†‘2.81%[0m) [0.85% of initial]
[Iter 1920] Gaussian 0 vs 1:
  Original Loss: 0.0021793
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021793 (Pseudo: 0.00%)
[Iter 1920] Gaussian 1 vs 0:
  Original Loss: 0.0020639
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020639 (Pseudo: 0.00%)
[Iter 1930/20000] Loss: 0.0017447 (Best: 0.0015654 @iter1930) ([92mâ†“18.57%[0m) [0.69% of initial]
[Iter 1930] Gaussian 0 vs 1:
  Original Loss: 0.0015654
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015654 (Pseudo: 0.00%)
[Iter 1930] Gaussian 1 vs 0:
  Original Loss: 0.0015368
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015368 (Pseudo: 0.00%)
[Iter 1940/20000] Loss: 0.0019357 (Best: 0.0015609 @iter1939) ([91mâ†‘10.95%[0m) [0.77% of initial]
[Iter 1940] Gaussian 0 vs 1:
  Original Loss: 0.0020470
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020470 (Pseudo: 0.00%)
[Iter 1940] Gaussian 1 vs 0:
  Original Loss: 0.0019336
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019336 (Pseudo: 0.00%)
[Iter 1950/20000] Loss: 0.0020685 (Best: 0.0015609 @iter1939) ([91mâ†‘6.86%[0m) [0.82% of initial]
[Iter 1950] Gaussian 0 vs 1:
  Original Loss: 0.0019119
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019119 (Pseudo: 0.00%)
[Iter 1950] Gaussian 1 vs 0:
  Original Loss: 0.0018449
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018449 (Pseudo: 0.00%)
[Iter 1960/20000] Loss: 0.0018813 (Best: 0.0015609 @iter1939) ([92mâ†“9.05%[0m) [0.75% of initial]
[Iter 1960] Gaussian 0 vs 1:
  Original Loss: 0.0017665
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017665 (Pseudo: 0.00%)
[Iter 1960] Gaussian 1 vs 0:
  Original Loss: 0.0017198
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017198 (Pseudo: 0.00%)
[Iter 1970/20000] Loss: 0.0017058 (Best: 0.0015387 @iter1963) ([92mâ†“9.33%[0m) [0.68% of initial]
[Iter 1970] Gaussian 0 vs 1:
  Original Loss: 0.0016120
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016120 (Pseudo: 0.00%)
[Iter 1970] Gaussian 1 vs 0:
  Original Loss: 0.0015693
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015693 (Pseudo: 0.00%)
[Iter 1980/20000] Loss: 0.0020655 (Best: 0.0015387 @iter1963) ([91mâ†‘21.09%[0m) [0.82% of initial]
[Iter 1980] Gaussian 0 vs 1:
  Original Loss: 0.0024446
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024446 (Pseudo: 0.00%)
[Iter 1980] Gaussian 1 vs 0:
  Original Loss: 0.0024964
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024964 (Pseudo: 0.00%)
[Iter 1990/20000] Loss: 0.0018055 (Best: 0.0015387 @iter1963) ([92mâ†“12.59%[0m) [0.72% of initial]
[Iter 1990] Gaussian 0 vs 1:
  Original Loss: 0.0016504
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016504 (Pseudo: 0.00%)
[Iter 1990] Gaussian 1 vs 0:
  Original Loss: 0.0016081
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016081 (Pseudo: 0.00%)
Iter:1999, L1 loss=0.001507, Total loss=0.001784, Time:14
[Iter 2000/20000] Loss: 0.0019725 (Best: 0.0014723 @iter1996) ([91mâ†‘9.25%[0m) [0.78% of initial]
Testing Speed: 235.2639207362767 fps
Testing Time: 0.21252727508544922 s

[ITER 2000] Evaluating test: SSIM = 0.851223840713501, PSNR = 17.758567562103273
Testing Speed: 269.97901602763534 fps
Testing Time: 0.011111974716186523 s

[ITER 2000] Evaluating train: SSIM = 0.9999455213546753, PSNR = 48.286462148030594
Iter:2000, total_points:42564
[Iter 2000] Gaussian 0 vs 1:
  Original Loss: 0.0021198
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021198 (Pseudo: 0.00%)
[Iter 2000] Gaussian 1 vs 0:
  Original Loss: 0.0021146
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021146 (Pseudo: 0.00%)
[Iter 2010/20000] Loss: 0.0068103 (Best: 0.0014723 @iter1996) ([91mâ†‘245.26%[0m) [2.71% of initial]
[Iter 2010] Gaussian 0 vs 1:
  Original Loss: 0.0062222
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0062222 (Pseudo: 0.00%)
[Iter 2010] Gaussian 1 vs 0:
  Original Loss: 0.0060457
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0060457 (Pseudo: 0.00%)
[Iter 2020/20000] Loss: 0.0036691 (Best: 0.0014723 @iter1996) ([92mâ†“46.12%[0m) [1.46% of initial]
[Iter 2020] Gaussian 0 vs 1:
  Original Loss: 0.0032271
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0032271 (Pseudo: 0.00%)
[Iter 2020] Gaussian 1 vs 0:
  Original Loss: 0.0031352
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0031352 (Pseudo: 0.00%)
[Iter 2030/20000] Loss: 0.0028172 (Best: 0.0014723 @iter1996) ([92mâ†“23.22%[0m) [1.12% of initial]
[Iter 2030] Gaussian 0 vs 1:
  Original Loss: 0.0025100
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0025100 (Pseudo: 0.00%)
[Iter 2030] Gaussian 1 vs 0:
  Original Loss: 0.0024845
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024845 (Pseudo: 0.00%)
[Iter 2040/20000] Loss: 0.0024673 (Best: 0.0014723 @iter1996) ([92mâ†“12.42%[0m) [0.98% of initial]
[Iter 2040] Gaussian 0 vs 1:
  Original Loss: 0.0027615
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027615 (Pseudo: 0.00%)
[Iter 2040] Gaussian 1 vs 0:
  Original Loss: 0.0027948
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027948 (Pseudo: 0.00%)
[Iter 2050/20000] Loss: 0.0020627 (Best: 0.0014723 @iter1996) ([92mâ†“16.40%[0m) [0.82% of initial]
[Iter 2050] Gaussian 0 vs 1:
  Original Loss: 0.0017278
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017278 (Pseudo: 0.00%)
[Iter 2050] Gaussian 1 vs 0:
  Original Loss: 0.0016704
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016704 (Pseudo: 0.00%)
[Iter 2060/20000] Loss: 0.0017035 (Best: 0.0014723 @iter1996) ([92mâ†“17.42%[0m) [0.68% of initial]
[Iter 2060] Gaussian 0 vs 1:
  Original Loss: 0.0015296
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015296 (Pseudo: 0.00%)
[Iter 2060] Gaussian 1 vs 0:
  Original Loss: 0.0015117
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015117 (Pseudo: 0.00%)
[Iter 2070/20000] Loss: 0.0019892 (Best: 0.0014723 @iter1996) ([91mâ†‘16.77%[0m) [0.79% of initial]
[Iter 2070] Gaussian 0 vs 1:
  Original Loss: 0.0022155
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022155 (Pseudo: 0.00%)
[Iter 2070] Gaussian 1 vs 0:
  Original Loss: 0.0022722
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022722 (Pseudo: 0.00%)
[Iter 2080/20000] Loss: 0.0018927 (Best: 0.0014723 @iter1996) ([92mâ†“4.85%[0m) [0.75% of initial]
[Iter 2080] Gaussian 0 vs 1:
  Original Loss: 0.0021175
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021175 (Pseudo: 0.00%)
[Iter 2080] Gaussian 1 vs 0:
  Original Loss: 0.0021208
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021208 (Pseudo: 0.00%)
[Iter 2090/20000] Loss: 0.0018186 (Best: 0.0013622 @iter2089) ([92mâ†“3.91%[0m) [0.72% of initial]
[Iter 2090] Gaussian 0 vs 1:
  Original Loss: 0.0020783
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020783 (Pseudo: 0.00%)
[Iter 2090] Gaussian 1 vs 0:
  Original Loss: 0.0021429
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021429 (Pseudo: 0.00%)
Iter:2099, L1 loss=0.00155, Total loss=0.001656, Time:15
[Iter 2100/20000] Loss: 0.0016712 (Best: 0.0013622 @iter2089) ([92mâ†“8.10%[0m) [0.66% of initial]
[Iter 2100] Gaussian 0 vs 1:
  Original Loss: 0.0015762
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015762 (Pseudo: 0.00%)
[Iter 2100] Gaussian 1 vs 0:
  Original Loss: 0.0015346
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015346 (Pseudo: 0.00%)
[Iter 2110/20000] Loss: 0.0015717 (Best: 0.0013622 @iter2089) ([92mâ†“5.96%[0m) [0.62% of initial]
[Iter 2110] Gaussian 0 vs 1:
  Original Loss: 0.0014118
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014118 (Pseudo: 0.00%)
[Iter 2110] Gaussian 1 vs 0:
  Original Loss: 0.0014029
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014029 (Pseudo: 0.00%)
[Iter 2120/20000] Loss: 0.0014321 (Best: 0.0013046 @iter2120) ([92mâ†“8.88%[0m) [0.57% of initial]
[Iter 2120] Gaussian 0 vs 1:
  Original Loss: 0.0013046
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013046 (Pseudo: 0.00%)
[Iter 2120] Gaussian 1 vs 0:
  Original Loss: 0.0012475
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012475 (Pseudo: 0.00%)
[Iter 2130/20000] Loss: 0.0015624 (Best: 0.0012257 @iter2125) ([91mâ†‘9.09%[0m) [0.62% of initial]
[Iter 2130] Gaussian 0 vs 1:
  Original Loss: 0.0015977
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015977 (Pseudo: 0.00%)
[Iter 2130] Gaussian 1 vs 0:
  Original Loss: 0.0014893
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014893 (Pseudo: 0.00%)
[Iter 2140/20000] Loss: 0.0017188 (Best: 0.0012257 @iter2125) ([91mâ†‘10.01%[0m) [0.68% of initial]
[Iter 2140] Gaussian 0 vs 1:
  Original Loss: 0.0018861
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018861 (Pseudo: 0.00%)
[Iter 2140] Gaussian 1 vs 0:
  Original Loss: 0.0018611
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018611 (Pseudo: 0.00%)
[Iter 2150/20000] Loss: 0.0017398 (Best: 0.0012257 @iter2125) ([91mâ†‘1.22%[0m) [0.69% of initial]
[Iter 2150] Gaussian 0 vs 1:
  Original Loss: 0.0014850
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014850 (Pseudo: 0.00%)
[Iter 2150] Gaussian 1 vs 0:
  Original Loss: 0.0014952
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014952 (Pseudo: 0.00%)
[Iter 2160/20000] Loss: 0.0015560 (Best: 0.0012257 @iter2125) ([92mâ†“10.56%[0m) [0.62% of initial]
[Iter 2160] Gaussian 0 vs 1:
  Original Loss: 0.0013665
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013665 (Pseudo: 0.00%)
[Iter 2160] Gaussian 1 vs 0:
  Original Loss: 0.0013760
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013760 (Pseudo: 0.00%)
[Iter 2170/20000] Loss: 0.0016294 (Best: 0.0012257 @iter2125) ([91mâ†‘4.71%[0m) [0.65% of initial]
[Iter 2170] Gaussian 0 vs 1:
  Original Loss: 0.0017304
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017304 (Pseudo: 0.00%)
[Iter 2170] Gaussian 1 vs 0:
  Original Loss: 0.0017111
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017111 (Pseudo: 0.00%)
[Iter 2180/20000] Loss: 0.0013234 (Best: 0.0012106 @iter2180) ([92mâ†“18.78%[0m) [0.53% of initial]
[Iter 2180] Gaussian 0 vs 1:
  Original Loss: 0.0012106
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012106 (Pseudo: 0.00%)
[Iter 2180] Gaussian 1 vs 0:
  Original Loss: 0.0011913
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011913 (Pseudo: 0.00%)
[Iter 2190/20000] Loss: 0.0016171 (Best: 0.0012106 @iter2180) ([91mâ†‘22.20%[0m) [0.64% of initial]
[Iter 2190] Gaussian 0 vs 1:
  Original Loss: 0.0019078
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019078 (Pseudo: 0.00%)
[Iter 2190] Gaussian 1 vs 0:
  Original Loss: 0.0019355
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019355 (Pseudo: 0.00%)
Iter:2199, L1 loss=0.001395, Total loss=0.001526, Time:16
[Iter 2200/20000] Loss: 0.0016219 (Best: 0.0012106 @iter2180) ([91mâ†‘0.30%[0m) [0.64% of initial]
[Iter 2200] Gaussian 0 vs 1:
  Original Loss: 0.0017914
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017914 (Pseudo: 0.00%)
[Iter 2200] Gaussian 1 vs 0:
  Original Loss: 0.0018305
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018305 (Pseudo: 0.00%)
[Iter 2210/20000] Loss: 0.0077354 (Best: 0.0012106 @iter2180) ([91mâ†‘376.92%[0m) [3.07% of initial]
[Iter 2210] Gaussian 0 vs 1:
  Original Loss: 0.0075031
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0075031 (Pseudo: 0.00%)
[Iter 2210] Gaussian 1 vs 0:
  Original Loss: 0.0072677
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0072677 (Pseudo: 0.00%)
[Iter 2220/20000] Loss: 0.0042164 (Best: 0.0012106 @iter2180) ([92mâ†“45.49%[0m) [1.68% of initial]
[Iter 2220] Gaussian 0 vs 1:
  Original Loss: 0.0037695
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037695 (Pseudo: 0.00%)
[Iter 2220] Gaussian 1 vs 0:
  Original Loss: 0.0037385
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0037385 (Pseudo: 0.00%)
[Iter 2230/20000] Loss: 0.0026705 (Best: 0.0012106 @iter2180) ([92mâ†“36.66%[0m) [1.06% of initial]
[Iter 2230] Gaussian 0 vs 1:
  Original Loss: 0.0022750
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022750 (Pseudo: 0.00%)
[Iter 2230] Gaussian 1 vs 0:
  Original Loss: 0.0022484
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022484 (Pseudo: 0.00%)
[Iter 2240/20000] Loss: 0.0023042 (Best: 0.0012106 @iter2180) ([92mâ†“13.72%[0m) [0.92% of initial]
[Iter 2240] Gaussian 0 vs 1:
  Original Loss: 0.0021141
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021141 (Pseudo: 0.00%)
[Iter 2240] Gaussian 1 vs 0:
  Original Loss: 0.0020571
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020571 (Pseudo: 0.00%)
[Iter 2250/20000] Loss: 0.0021345 (Best: 0.0012106 @iter2180) ([92mâ†“7.37%[0m) [0.85% of initial]
[Iter 2250] Gaussian 0 vs 1:
  Original Loss: 0.0023109
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0023109 (Pseudo: 0.00%)
[Iter 2250] Gaussian 1 vs 0:
  Original Loss: 0.0022848
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0022848 (Pseudo: 0.00%)
[Iter 2260/20000] Loss: 0.0016966 (Best: 0.0012106 @iter2180) ([92mâ†“20.51%[0m) [0.67% of initial]
[Iter 2260] Gaussian 0 vs 1:
  Original Loss: 0.0015034
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015034 (Pseudo: 0.00%)
[Iter 2260] Gaussian 1 vs 0:
  Original Loss: 0.0014815
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014815 (Pseudo: 0.00%)
[Iter 2270/20000] Loss: 0.0017942 (Best: 0.0012106 @iter2180) ([91mâ†‘5.75%[0m) [0.71% of initial]
[Iter 2270] Gaussian 0 vs 1:
  Original Loss: 0.0020060
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020060 (Pseudo: 0.00%)
[Iter 2270] Gaussian 1 vs 0:
  Original Loss: 0.0019895
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0019895 (Pseudo: 0.00%)
[Iter 2280/20000] Loss: 0.0014482 (Best: 0.0012106 @iter2180) ([92mâ†“19.28%[0m) [0.58% of initial]
[Iter 2280] Gaussian 0 vs 1:
  Original Loss: 0.0013402
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013402 (Pseudo: 0.00%)
[Iter 2280] Gaussian 1 vs 0:
  Original Loss: 0.0013338
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013338 (Pseudo: 0.00%)
[Iter 2290/20000] Loss: 0.0013923 (Best: 0.0011823 @iter2287) ([92mâ†“3.86%[0m) [0.55% of initial]
[Iter 2290] Gaussian 0 vs 1:
  Original Loss: 0.0012570
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012570 (Pseudo: 0.00%)
[Iter 2290] Gaussian 1 vs 0:
  Original Loss: 0.0012375
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012375 (Pseudo: 0.00%)
Iter:2299, L1 loss=0.001392, Total loss=0.0014, Time:17
[Iter 2300/20000] Loss: 0.0016849 (Best: 0.0011823 @iter2287) ([91mâ†‘21.02%[0m) [0.67% of initial]
[Iter 2300] Gaussian 0 vs 1:
  Original Loss: 0.0018119
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018119 (Pseudo: 0.00%)
[Iter 2300] Gaussian 1 vs 0:
  Original Loss: 0.0018945
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018945 (Pseudo: 0.00%)
[Iter 2310/20000] Loss: 0.0015445 (Best: 0.0011823 @iter2287) ([92mâ†“8.34%[0m) [0.61% of initial]
[Iter 2310] Gaussian 0 vs 1:
  Original Loss: 0.0015288
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015288 (Pseudo: 0.00%)
[Iter 2310] Gaussian 1 vs 0:
  Original Loss: 0.0014970
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014970 (Pseudo: 0.00%)
[Iter 2320/20000] Loss: 0.0013208 (Best: 0.0011823 @iter2287) ([92mâ†“14.48%[0m) [0.52% of initial]
[Iter 2320] Gaussian 0 vs 1:
  Original Loss: 0.0011849
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011849 (Pseudo: 0.00%)
[Iter 2320] Gaussian 1 vs 0:
  Original Loss: 0.0012192
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012192 (Pseudo: 0.00%)
[Iter 2330/20000] Loss: 0.0013487 (Best: 0.0011553 @iter2327) ([91mâ†‘2.11%[0m) [0.54% of initial]
[Iter 2330] Gaussian 0 vs 1:
  Original Loss: 0.0013315
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013315 (Pseudo: 0.00%)
[Iter 2330] Gaussian 1 vs 0:
  Original Loss: 0.0012790
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012790 (Pseudo: 0.00%)
[Iter 2340/20000] Loss: 0.0013611 (Best: 0.0010960 @iter2338) ([91mâ†‘0.92%[0m) [0.54% of initial]
[Iter 2340] Gaussian 0 vs 1:
  Original Loss: 0.0012546
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012546 (Pseudo: 0.00%)
[Iter 2340] Gaussian 1 vs 0:
  Original Loss: 0.0012285
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012285 (Pseudo: 0.00%)
[Iter 2350/20000] Loss: 0.0015030 (Best: 0.0010960 @iter2338) ([91mâ†‘10.42%[0m) [0.60% of initial]
[Iter 2350] Gaussian 0 vs 1:
  Original Loss: 0.0014497
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014497 (Pseudo: 0.00%)
[Iter 2350] Gaussian 1 vs 0:
  Original Loss: 0.0014125
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014125 (Pseudo: 0.00%)
[Iter 2360/20000] Loss: 0.0012858 (Best: 0.0010960 @iter2338) ([92mâ†“14.45%[0m) [0.51% of initial]
[Iter 2360] Gaussian 0 vs 1:
  Original Loss: 0.0013139
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013139 (Pseudo: 0.00%)
[Iter 2360] Gaussian 1 vs 0:
  Original Loss: 0.0012944
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012944 (Pseudo: 0.00%)
[Iter 2370/20000] Loss: 0.0014347 (Best: 0.0010960 @iter2338) ([91mâ†‘11.58%[0m) [0.57% of initial]
[Iter 2370] Gaussian 0 vs 1:
  Original Loss: 0.0012622
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012622 (Pseudo: 0.00%)
[Iter 2370] Gaussian 1 vs 0:
  Original Loss: 0.0011911
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011911 (Pseudo: 0.00%)
[Iter 2380/20000] Loss: 0.0014792 (Best: 0.0010960 @iter2338) ([91mâ†‘3.10%[0m) [0.59% of initial]
[Iter 2380] Gaussian 0 vs 1:
  Original Loss: 0.0016159
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016159 (Pseudo: 0.00%)
[Iter 2380] Gaussian 1 vs 0:
  Original Loss: 0.0016105
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016105 (Pseudo: 0.00%)
[Iter 2390/20000] Loss: 0.0016021 (Best: 0.0010960 @iter2338) ([91mâ†‘8.30%[0m) [0.64% of initial]
[Iter 2390] Gaussian 0 vs 1:
  Original Loss: 0.0018050
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0018050 (Pseudo: 0.00%)
[Iter 2390] Gaussian 1 vs 0:
  Original Loss: 0.0017708
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017708 (Pseudo: 0.00%)
Iter:2399, L1 loss=0.001198, Total loss=0.001263, Time:17
[Iter 2400/20000] Loss: 0.0013135 (Best: 0.0010960 @iter2338) ([92mâ†“18.01%[0m) [0.52% of initial]
[Iter 2400] Gaussian 0 vs 1:
  Original Loss: 0.0011973
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011973 (Pseudo: 0.00%)
[Iter 2400] Gaussian 1 vs 0:
  Original Loss: 0.0013144
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013144 (Pseudo: 0.00%)
[Iter 2410/20000] Loss: 0.0061524 (Best: 0.0010960 @iter2338) ([91mâ†‘368.39%[0m) [2.44% of initial]
[Iter 2410] Gaussian 0 vs 1:
  Original Loss: 0.0052609
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0052609 (Pseudo: 0.00%)
[Iter 2410] Gaussian 1 vs 0:
  Original Loss: 0.0049266
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0049266 (Pseudo: 0.00%)
[Iter 2420/20000] Loss: 0.0035401 (Best: 0.0010960 @iter2338) ([92mâ†“42.46%[0m) [1.41% of initial]
[Iter 2420] Gaussian 0 vs 1:
  Original Loss: 0.0029951
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0029951 (Pseudo: 0.00%)
[Iter 2420] Gaussian 1 vs 0:
  Original Loss: 0.0028760
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028760 (Pseudo: 0.00%)
[Iter 2430/20000] Loss: 0.0025813 (Best: 0.0010960 @iter2338) ([92mâ†“27.08%[0m) [1.03% of initial]
[Iter 2430] Gaussian 0 vs 1:
  Original Loss: 0.0026477
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0026477 (Pseudo: 0.00%)
[Iter 2430] Gaussian 1 vs 0:
  Original Loss: 0.0028132
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028132 (Pseudo: 0.00%)
[Iter 2440/20000] Loss: 0.0020488 (Best: 0.0010960 @iter2338) ([92mâ†“20.63%[0m) [0.81% of initial]
[Iter 2440] Gaussian 0 vs 1:
  Original Loss: 0.0017777
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017777 (Pseudo: 0.00%)
[Iter 2440] Gaussian 1 vs 0:
  Original Loss: 0.0017036
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017036 (Pseudo: 0.00%)
[Iter 2450/20000] Loss: 0.0019562 (Best: 0.0010960 @iter2338) ([92mâ†“4.52%[0m) [0.78% of initial]
[Iter 2450] Gaussian 0 vs 1:
  Original Loss: 0.0020311
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0020311 (Pseudo: 0.00%)
[Iter 2450] Gaussian 1 vs 0:
  Original Loss: 0.0021307
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021307 (Pseudo: 0.00%)
[Iter 2460/20000] Loss: 0.0016487 (Best: 0.0010960 @iter2338) ([92mâ†“15.72%[0m) [0.66% of initial]
[Iter 2460] Gaussian 0 vs 1:
  Original Loss: 0.0014915
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014915 (Pseudo: 0.00%)
[Iter 2460] Gaussian 1 vs 0:
  Original Loss: 0.0015004
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015004 (Pseudo: 0.00%)
[Iter 2470/20000] Loss: 0.0016327 (Best: 0.0010960 @iter2338) ([92mâ†“0.97%[0m) [0.65% of initial]
[Iter 2470] Gaussian 0 vs 1:
  Original Loss: 0.0016538
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016538 (Pseudo: 0.00%)
[Iter 2470] Gaussian 1 vs 0:
  Original Loss: 0.0017107
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017107 (Pseudo: 0.00%)
[Iter 2480/20000] Loss: 0.0016395 (Best: 0.0010960 @iter2338) ([91mâ†‘0.41%[0m) [0.65% of initial]
[Iter 2480] Gaussian 0 vs 1:
  Original Loss: 0.0014431
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014431 (Pseudo: 0.00%)
[Iter 2480] Gaussian 1 vs 0:
  Original Loss: 0.0014340
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014340 (Pseudo: 0.00%)
[Iter 2490/20000] Loss: 0.0014592 (Best: 0.0010960 @iter2338) ([92mâ†“10.99%[0m) [0.58% of initial]
[Iter 2490] Gaussian 0 vs 1:
  Original Loss: 0.0014358
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014358 (Pseudo: 0.00%)
[Iter 2490] Gaussian 1 vs 0:
  Original Loss: 0.0014134
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014134 (Pseudo: 0.00%)
Iter:2499, L1 loss=0.001231, Total loss=0.001227, Time:17
[Iter 2500/20000] Loss: 0.0013106 (Best: 0.0010960 @iter2338) ([92mâ†“10.19%[0m) [0.52% of initial]
[Iter 2500] Gaussian 0 vs 1:
  Original Loss: 0.0012209
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012209 (Pseudo: 0.00%)
[Iter 2500] Gaussian 1 vs 0:
  Original Loss: 0.0012528
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012528 (Pseudo: 0.00%)
[Iter 2510/20000] Loss: 0.0013585 (Best: 0.0010301 @iter2504) ([91mâ†‘3.66%[0m) [0.54% of initial]
[Iter 2510] Gaussian 0 vs 1:
  Original Loss: 0.0015743
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015743 (Pseudo: 0.00%)
[Iter 2510] Gaussian 1 vs 0:
  Original Loss: 0.0016330
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016330 (Pseudo: 0.00%)
[Iter 2520/20000] Loss: 0.0012036 (Best: 0.0010111 @iter2519) ([92mâ†“11.40%[0m) [0.48% of initial]
[Iter 2520] Gaussian 0 vs 1:
  Original Loss: 0.0012162
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012162 (Pseudo: 0.00%)
[Iter 2520] Gaussian 1 vs 0:
  Original Loss: 0.0012883
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012883 (Pseudo: 0.00%)
[Iter 2530/20000] Loss: 0.0010594 (Best: 0.0009340 @iter2528) ([92mâ†“11.98%[0m) [0.42% of initial]
[Iter 2530] Gaussian 0 vs 1:
  Original Loss: 0.0009551
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009551 (Pseudo: 0.00%)
[Iter 2530] Gaussian 1 vs 0:
  Original Loss: 0.0009538
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009538 (Pseudo: 0.00%)
[Iter 2540/20000] Loss: 0.0011869 (Best: 0.0009340 @iter2528) ([91mâ†‘12.03%[0m) [0.47% of initial]
[Iter 2540] Gaussian 0 vs 1:
  Original Loss: 0.0011876
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011876 (Pseudo: 0.00%)
[Iter 2540] Gaussian 1 vs 0:
  Original Loss: 0.0011839
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011839 (Pseudo: 0.00%)
[Iter 2550/20000] Loss: 0.0013671 (Best: 0.0009340 @iter2528) ([91mâ†‘15.19%[0m) [0.54% of initial]
[Iter 2550] Gaussian 0 vs 1:
  Original Loss: 0.0014048
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014048 (Pseudo: 0.00%)
[Iter 2550] Gaussian 1 vs 0:
  Original Loss: 0.0014457
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014457 (Pseudo: 0.00%)
[Iter 2560/20000] Loss: 0.0011793 (Best: 0.0009340 @iter2528) ([92mâ†“13.74%[0m) [0.47% of initial]
[Iter 2560] Gaussian 0 vs 1:
  Original Loss: 0.0010764
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010764 (Pseudo: 0.00%)
[Iter 2560] Gaussian 1 vs 0:
  Original Loss: 0.0010463
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010463 (Pseudo: 0.00%)
[Iter 2570/20000] Loss: 0.0013915 (Best: 0.0009340 @iter2528) ([91mâ†‘17.99%[0m) [0.55% of initial]
[Iter 2570] Gaussian 0 vs 1:
  Original Loss: 0.0013948
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013948 (Pseudo: 0.00%)
[Iter 2570] Gaussian 1 vs 0:
  Original Loss: 0.0013855
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013855 (Pseudo: 0.00%)
[Iter 2580/20000] Loss: 0.0012150 (Best: 0.0009128 @iter2578) ([92mâ†“12.69%[0m) [0.48% of initial]
[Iter 2580] Gaussian 0 vs 1:
  Original Loss: 0.0012350
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012350 (Pseudo: 0.00%)
[Iter 2580] Gaussian 1 vs 0:
  Original Loss: 0.0012421
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012421 (Pseudo: 0.00%)
[Iter 2590/20000] Loss: 0.0012754 (Best: 0.0009102 @iter2584) ([91mâ†‘4.97%[0m) [0.51% of initial]
[Iter 2590] Gaussian 0 vs 1:
  Original Loss: 0.0013607
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013607 (Pseudo: 0.00%)
[Iter 2590] Gaussian 1 vs 0:
  Original Loss: 0.0014092
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014092 (Pseudo: 0.00%)
Iter:2599, L1 loss=0.001014, Total loss=0.001012, Time:17
[Iter 2600/20000] Loss: 0.0011904 (Best: 0.0009102 @iter2584) ([92mâ†“6.67%[0m) [0.47% of initial]
[Iter 2600] Gaussian 0 vs 1:
  Original Loss: 0.0013056
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013056 (Pseudo: 0.00%)
[Iter 2600] Gaussian 1 vs 0:
  Original Loss: 0.0013334
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013334 (Pseudo: 0.00%)
[Iter 2610/20000] Loss: 0.0060108 (Best: 0.0009102 @iter2584) ([91mâ†‘404.96%[0m) [2.39% of initial]
[Iter 2610] Gaussian 0 vs 1:
  Original Loss: 0.0054474
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0054474 (Pseudo: 0.00%)
[Iter 2610] Gaussian 1 vs 0:
  Original Loss: 0.0052212
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0052212 (Pseudo: 0.00%)
[Iter 2620/20000] Loss: 0.0032401 (Best: 0.0009102 @iter2584) ([92mâ†“46.10%[0m) [1.29% of initial]
[Iter 2620] Gaussian 0 vs 1:
  Original Loss: 0.0028164
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0028164 (Pseudo: 0.00%)
[Iter 2620] Gaussian 1 vs 0:
  Original Loss: 0.0027265
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0027265 (Pseudo: 0.00%)
[Iter 2630/20000] Loss: 0.0021727 (Best: 0.0009102 @iter2584) ([92mâ†“32.94%[0m) [0.86% of initial]
[Iter 2630] Gaussian 0 vs 1:
  Original Loss: 0.0021922
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021922 (Pseudo: 0.00%)
[Iter 2630] Gaussian 1 vs 0:
  Original Loss: 0.0021198
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0021198 (Pseudo: 0.00%)
[Iter 2640/20000] Loss: 0.0017086 (Best: 0.0009102 @iter2584) ([92mâ†“21.36%[0m) [0.68% of initial]
[Iter 2640] Gaussian 0 vs 1:
  Original Loss: 0.0015578
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015578 (Pseudo: 0.00%)
[Iter 2640] Gaussian 1 vs 0:
  Original Loss: 0.0015522
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015522 (Pseudo: 0.00%)
[Iter 2650/20000] Loss: 0.0014132 (Best: 0.0009102 @iter2584) ([92mâ†“17.29%[0m) [0.56% of initial]
[Iter 2650] Gaussian 0 vs 1:
  Original Loss: 0.0011457
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011457 (Pseudo: 0.00%)
[Iter 2650] Gaussian 1 vs 0:
  Original Loss: 0.0011131
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011131 (Pseudo: 0.00%)
[Iter 2660/20000] Loss: 0.0016634 (Best: 0.0009102 @iter2584) ([91mâ†‘17.70%[0m) [0.66% of initial]
[Iter 2660] Gaussian 0 vs 1:
  Original Loss: 0.0014413
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014413 (Pseudo: 0.00%)
[Iter 2660] Gaussian 1 vs 0:
  Original Loss: 0.0014032
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014032 (Pseudo: 0.00%)
[Iter 2670/20000] Loss: 0.0016491 (Best: 0.0009102 @iter2584) ([92mâ†“0.86%[0m) [0.66% of initial]
[Iter 2670] Gaussian 0 vs 1:
  Original Loss: 0.0017100
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017100 (Pseudo: 0.00%)
[Iter 2670] Gaussian 1 vs 0:
  Original Loss: 0.0016796
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0016796 (Pseudo: 0.00%)
[Iter 2680/20000] Loss: 0.0012779 (Best: 0.0009102 @iter2584) ([92mâ†“22.51%[0m) [0.51% of initial]
[Iter 2680] Gaussian 0 vs 1:
  Original Loss: 0.0010734
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010734 (Pseudo: 0.00%)
[Iter 2680] Gaussian 1 vs 0:
  Original Loss: 0.0010524
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010524 (Pseudo: 0.00%)
[Iter 2690/20000] Loss: 0.0012013 (Best: 0.0009102 @iter2584) ([92mâ†“5.99%[0m) [0.48% of initial]
[Iter 2690] Gaussian 0 vs 1:
  Original Loss: 0.0010383
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010383 (Pseudo: 0.00%)
[Iter 2690] Gaussian 1 vs 0:
  Original Loss: 0.0009678
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009678 (Pseudo: 0.00%)
Iter:2699, L1 loss=0.001111, Total loss=0.001177, Time:18
[Iter 2700/20000] Loss: 0.0014546 (Best: 0.0009102 @iter2584) ([91mâ†‘21.09%[0m) [0.58% of initial]
[Iter 2700] Gaussian 0 vs 1:
  Original Loss: 0.0017281
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017281 (Pseudo: 0.00%)
[Iter 2700] Gaussian 1 vs 0:
  Original Loss: 0.0017053
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0017053 (Pseudo: 0.00%)
[Iter 2710/20000] Loss: 0.0012435 (Best: 0.0009102 @iter2584) ([92mâ†“14.51%[0m) [0.49% of initial]
[Iter 2710] Gaussian 0 vs 1:
  Original Loss: 0.0012896
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012896 (Pseudo: 0.00%)
[Iter 2710] Gaussian 1 vs 0:
  Original Loss: 0.0012699
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012699 (Pseudo: 0.00%)
[Iter 2720/20000] Loss: 0.0010938 (Best: 0.0009102 @iter2584) ([92mâ†“12.04%[0m) [0.43% of initial]
[Iter 2720] Gaussian 0 vs 1:
  Original Loss: 0.0010369
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010369 (Pseudo: 0.00%)
[Iter 2720] Gaussian 1 vs 0:
  Original Loss: 0.0010570
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0010570 (Pseudo: 0.00%)
[Iter 2730/20000] Loss: 0.0009833 (Best: 0.0008248 @iter2725) ([92mâ†“10.11%[0m) [0.39% of initial]
[Iter 2730] Gaussian 0 vs 1:
  Original Loss: 0.0009075
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009075 (Pseudo: 0.00%)
[Iter 2730] Gaussian 1 vs 0:
  Original Loss: 0.0009161
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009161 (Pseudo: 0.00%)
[Iter 2740/20000] Loss: 0.0008567 (Best: 0.0007618 @iter2740) ([92mâ†“12.87%[0m) [0.34% of initial]
[Iter 2740] Gaussian 0 vs 1:
  Original Loss: 0.0007618
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0007618 (Pseudo: 0.00%)
[Iter 2740] Gaussian 1 vs 0:
  Original Loss: 0.0007701
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0007701 (Pseudo: 0.00%)
[Iter 2750/20000] Loss: 0.0011315 (Best: 0.0007618 @iter2740) ([91mâ†‘32.07%[0m) [0.45% of initial]
[Iter 2750] Gaussian 0 vs 1:
  Original Loss: 0.0013268
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013268 (Pseudo: 0.00%)
[Iter 2750] Gaussian 1 vs 0:
  Original Loss: 0.0013694
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013694 (Pseudo: 0.00%)
[Iter 2760/20000] Loss: 0.0011649 (Best: 0.0007618 @iter2740) ([91mâ†‘2.96%[0m) [0.46% of initial]
[Iter 2760] Gaussian 0 vs 1:
  Original Loss: 0.0012803
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012803 (Pseudo: 0.00%)
[Iter 2760] Gaussian 1 vs 0:
  Original Loss: 0.0014127
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014127 (Pseudo: 0.00%)
[Iter 2770/20000] Loss: 0.0013065 (Best: 0.0007618 @iter2740) ([91mâ†‘12.15%[0m) [0.52% of initial]
[Iter 2770] Gaussian 0 vs 1:
  Original Loss: 0.0012820
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012820 (Pseudo: 0.00%)
[Iter 2770] Gaussian 1 vs 0:
  Original Loss: 0.0013043
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0013043 (Pseudo: 0.00%)
[Iter 2780/20000] Loss: 0.0010920 (Best: 0.0007618 @iter2740) ([92mâ†“16.41%[0m) [0.43% of initial]
[Iter 2780] Gaussian 0 vs 1:
  Original Loss: 0.0012728
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012728 (Pseudo: 0.00%)
[Iter 2780] Gaussian 1 vs 0:
  Original Loss: 0.0012630
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012630 (Pseudo: 0.00%)
[Iter 2790/20000] Loss: 0.0011261 (Best: 0.0007618 @iter2740) ([91mâ†‘3.12%[0m) [0.45% of initial]
[Iter 2790] Gaussian 0 vs 1:
  Original Loss: 0.0011587
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011587 (Pseudo: 0.00%)
[Iter 2790] Gaussian 1 vs 0:
  Original Loss: 0.0011701
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011701 (Pseudo: 0.00%)
Iter:2799, L1 loss=0.001261, Total loss=0.001296, Time:17
[Iter 2800/20000] Loss: 0.0011152 (Best: 0.0007618 @iter2740) ([92mâ†“0.97%[0m) [0.44% of initial]
[Iter 2800] Gaussian 0 vs 1:
  Original Loss: 0.0009635
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009635 (Pseudo: 0.00%)
[Iter 2800] Gaussian 1 vs 0:
  Original Loss: 0.0009860
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0009860 (Pseudo: 0.00%)
[Iter 2810/20000] Loss: 0.0049535 (Best: 0.0007618 @iter2740) ([91mâ†‘344.18%[0m) [1.97% of initial]
[Iter 2810] Gaussian 0 vs 1:
  Original Loss: 0.0040058
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0040058 (Pseudo: 0.00%)
[Iter 2810] Gaussian 1 vs 0:
  Original Loss: 0.0039270
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0039270 (Pseudo: 0.00%)
[Iter 2820/20000] Loss: 0.0026826 (Best: 0.0007618 @iter2740) ([92mâ†“45.84%[0m) [1.07% of initial]
[Iter 2820] Gaussian 0 vs 1:
  Original Loss: 0.0024844
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024844 (Pseudo: 0.00%)
[Iter 2820] Gaussian 1 vs 0:
  Original Loss: 0.0024523
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0024523 (Pseudo: 0.00%)
[Iter 2830/20000] Loss: 0.0017814 (Best: 0.0007618 @iter2740) ([92mâ†“33.59%[0m) [0.71% of initial]
[Iter 2830] Gaussian 0 vs 1:
  Original Loss: 0.0015890
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015890 (Pseudo: 0.00%)
[Iter 2830] Gaussian 1 vs 0:
  Original Loss: 0.0015108
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015108 (Pseudo: 0.00%)
[Iter 2840/20000] Loss: 0.0015067 (Best: 0.0007618 @iter2740) ([92mâ†“15.42%[0m) [0.60% of initial]
[Iter 2840] Gaussian 0 vs 1:
  Original Loss: 0.0015821
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015821 (Pseudo: 0.00%)
[Iter 2840] Gaussian 1 vs 0:
  Original Loss: 0.0015879
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0015879 (Pseudo: 0.00%)
[Iter 2850/20000] Loss: 0.0013013 (Best: 0.0007618 @iter2740) ([92mâ†“13.63%[0m) [0.52% of initial]
[Iter 2850] Gaussian 0 vs 1:
  Original Loss: 0.0012960
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012960 (Pseudo: 0.00%)
[Iter 2850] Gaussian 1 vs 0:
  Original Loss: 0.0012764
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0012764 (Pseudo: 0.00%)
[Iter 2860/20000] Loss: 0.0014410 (Best: 0.0007618 @iter2740) ([91mâ†‘10.73%[0m) [0.57% of initial]
[Iter 2860] Gaussian 0 vs 1:
  Original Loss: 0.0014827
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014827 (Pseudo: 0.00%)
[Iter 2860] Gaussian 1 vs 0:
  Original Loss: 0.0014960
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0014960 (Pseudo: 0.00%)
[Iter 2870/20000] Loss: 0.0012020 (Best: 0.0007618 @iter2740) ([92mâ†“16.59%[0m) [0.48% of initial]
[Iter 2870] Gaussian 0 vs 1:
  Original Loss: 0.0011101
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011101 (Pseudo: 0.00%)
[Iter 2870] Gaussian 1 vs 0:
  Original Loss: 0.0011716
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011716 (Pseudo: 0.00%)
[Iter 2880/20000] Loss: 0.0011502 (Best: 0.0007618 @iter2740) ([92mâ†“4.31%[0m) [0.46% of initial]
[Iter 2880] Gaussian 0 vs 1:
  Original Loss: 0.0011625
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011625 (Pseudo: 0.00%)
[Iter 2880] Gaussian 1 vs 0:
  Original Loss: 0.0011148
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011148 (Pseudo: 0.00%)
[Iter 2890/20000] Loss: 0.0011142 (Best: 0.0007618 @iter2740) ([92mâ†“3.13%[0m) [0.44% of initial]
[Iter 2890] Gaussian 0 vs 1:
  Original Loss: 0.0011306
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011306 (Pseudo: 0.00%)
[Iter 2890] Gaussian 1 vs 0:
  Original Loss: 0.0011609
  Raw Pseudo Loss: 0.0000000
  Scaled Pseudo Loss: 0.0000000 (scale: 1.000)
  Ratio to Original: 0.00%
  Total Loss: 0.0011609 (Pseudo: 0.00%)
Optimizing 
Training parameters: {'iterations': 20000, 'position_lr_init': 0.00019, 'position_lr_final': 1.9e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000, 'feature_lr': 0.002, 'opacity_lr': 0.008, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, 'lambda_dssim': 0.2, 'densification_interval': 200, 'opacity_reset_interval': 4000, 'densify_from_iter': 500, 'densify_until_iter': 8000, 'densify_grad_threshold': 2.6e-05, 'random_background': False, 'sample_pseudo_interval': 1, 'start_sample_pseudo': 0, 'end_sample_pseudo': 30000}
Create gaussians1
GsDict.keys() is dict_keys(['gs0', 'gs1'])

Starting training...
Total iterations: 20000
==================================================
[Iter 10/20000] Loss: 0.2179127 (Best: 0.2126908 @iter10) [100.00% of initial]
[Iter 20/20000] Loss: 0.1746702 (Best: 0.1693033 @iter20) ([92mâ†“19.84%[0m) [69.39% of initial]
[Iter 30/20000] Loss: 0.1374909 (Best: 0.1327883 @iter30) ([92mâ†“21.29%[0m) [54.62% of initial]
[Iter 40/20000] Loss: 0.1123912 (Best: 0.1098365 @iter40) ([92mâ†“18.26%[0m) [44.65% of initial]
[Iter 50/20000] Loss: 0.0993451 (Best: 0.0965456 @iter49) ([92mâ†“11.61%[0m) [39.47% of initial]
[Iter 60/20000] Loss: 0.0936794 (Best: 0.0908578 @iter59) ([92mâ†“5.70%[0m) [37.22% of initial]
[Iter 70/20000] Loss: 0.0884512 (Best: 0.0869382 @iter70) ([92mâ†“5.58%[0m) [35.14% of initial]
[Iter 80/20000] Loss: 0.0851907 (Best: 0.0831084 @iter80) ([92mâ†“3.69%[0m) [33.85% of initial]
[Iter 90/20000] Loss: 0.0824118 (Best: 0.0801456 @iter88) ([92mâ†“3.26%[0m) [32.74% of initial]
Iter:99, L1 loss=0.05723, Total loss=0.07876, Time:21
[Iter 100/20000] Loss: 0.0786623 (Best: 0.0766275 @iter97) ([92mâ†“4.55%[0m) [31.25% of initial]
[Iter 110/20000] Loss: 0.0753225 (Best: 0.0731347 @iter106) ([92mâ†“4.25%[0m) [29.92% of initial]
[Iter 120/20000] Loss: 0.0714331 (Best: 0.0685495 @iter118) ([92mâ†“5.16%[0m) [28.38% of initial]
[Iter 130/20000] Loss: 0.0666932 (Best: 0.0641878 @iter130) ([92mâ†“6.64%[0m) [26.50% of initial]
[Iter 140/20000] Loss: 0.0635410 (Best: 0.0613000 @iter140) ([92mâ†“4.73%[0m) [25.24% of initial]
[Iter 150/20000] Loss: 0.0612668 (Best: 0.0583680 @iter148) ([92mâ†“3.58%[0m) [24.34% of initial]
[Iter 160/20000] Loss: 0.0590264 (Best: 0.0559365 @iter157) ([92mâ†“3.66%[0m) [23.45% of initial]
[Iter 170/20000] Loss: 0.0563525 (Best: 0.0535271 @iter167) ([92mâ†“4.53%[0m) [22.39% of initial]
[Iter 180/20000] Loss: 0.0522929 (Best: 0.0499450 @iter179) ([92mâ†“7.20%[0m) [20.78% of initial]
[Iter 190/20000] Loss: 0.0495094 (Best: 0.0477999 @iter188) ([92mâ†“5.32%[0m) [19.67% of initial]
Iter:199, L1 loss=0.03443, Total loss=0.04965, Time:16
[Iter 200/20000] Loss: 0.0477494 (Best: 0.0455610 @iter198) ([92mâ†“3.55%[0m) [18.97% of initial]
